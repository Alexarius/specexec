{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "facebook/opt-2.7b", "model_1": "facebook/opt-13b", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 540, "seed": 0, "dataset": "oasst", "timestamp": "2025-04-10 17:30:29", "date": "250410", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.3, "tree_w": 8, "tree_size": 16, "t0": 0.4545, "t1": 0.2118, "tft": 2.1238, "input_0": 27, "input_1": 17, "min_CLP": -4.29, "draft_iters": 4.3, "mem_use": 34.38, "gen_rate": 3.0, "speed": 4.48, "text": "\"\\nA Dyson Sphere is a hypotheti"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6238, "t1": 0.23, "tft": 1.8911, "input_0": 33, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.9, "mem_use": 35.12, "gen_rate": 4.4, "speed": 5.13, "text": "\\nIf the universe is infinite, w"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 2.9, "tree_w": 9, "tree_size": 16, "t0": 0.4392, "t1": 0.24, "tft": 2.4043, "input_0": 24, "input_1": 17, "min_CLP": -4.16, "draft_iters": 3.9, "mem_use": 35.51, "gen_rate": 2.8, "speed": 4.18, "text": "\"Stellaris should be fine, but M"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.61, "t1": 0.21, "tft": 1.2023, "input_0": 53, "input_1": 17, "min_CLP": -1.44, "draft_iters": 17.0, "mem_use": 34.72, "gen_rate": 17.0, "speed": 9.35, "text": "\\ncan you please create a python"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.4067, "t1": 0.21, "tft": 1.2151, "input_0": 53, "input_1": 17, "min_CLP": -4.21, "draft_iters": 14.7, "mem_use": 34.39, "gen_rate": 14.7, "speed": 9.07, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.31, "t1": 0.24, "tft": 2.766, "input_0": 50, "input_1": 17, "min_CLP": -2.51, "draft_iters": 13.0, "mem_use": 35.68, "gen_rate": 13.0, "speed": 8.37, "text": "Sure! Here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.82, "t1": 0.25, "tft": 3.5616, "input_0": 37, "input_1": 17, "min_CLP": -3.69, "draft_iters": 7.7, "mem_use": 35.98, "gen_rate": 5.3, "speed": 4.98, "text": "There are a variety of other ima"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.77, "t1": 0.29, "tft": 4.7543, "input_0": 64, "input_1": 17, "min_CLP": -2.06, "draft_iters": 16.0, "mem_use": 37.09, "gen_rate": 16.0, "speed": 7.76, "text": "\"\\nRight now, the most important"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 1.105, "t1": 0.2425, "tft": 2.6816, "input_0": 43, "input_1": 17, "min_CLP": -4.02, "draft_iters": 10.8, "mem_use": 35.71, "gen_rate": 8.5, "speed": 6.31, "text": "\\nLegal status[INST]\\n\\nLegal st"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.575, "t1": 0.24, "tft": 2.3061, "input_0": 32, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.1, "mem_use": 35.47, "gen_rate": 3.5, "speed": 4.31, "text": "\\nThe most beginner friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.7167, "t1": 0.22, "tft": 1.5568, "input_0": 33, "input_1": 17, "min_CLP": -3.98, "draft_iters": 7.1, "mem_use": 34.73, "gen_rate": 4.2, "speed": 4.51, "text": "\\nWrite a program that takes a n"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.5282, "t1": 0.24, "tft": 2.5139, "input_0": 29, "input_1": 17, "min_CLP": -3.76, "draft_iters": 4.7, "mem_use": 35.66, "gen_rate": 3.1, "speed": 4.01, "text": "\\nI have edited the summary to c"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.559, "t1": 0.23, "tft": 2.0212, "input_0": 33, "input_1": 17, "min_CLP": -3.67, "draft_iters": 5.0, "mem_use": 35.28, "gen_rate": 3.6, "speed": 4.55, "text": "\"I'd be happy to help you out, b"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.002, "t1": 0.21, "tft": 1.1237, "input_0": 47, "input_1": 17, "min_CLP": -4.15, "draft_iters": 10.0, "mem_use": 34.62, "gen_rate": 7.2, "speed": 5.93, "text": "\\nThe capital of Australia is Ca"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6575, "t1": 0.25, "tft": 3.4583, "input_0": 36, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.9, "mem_use": 35.99, "gen_rate": 4.2, "speed": 4.67, "text": "\"If you only have an hour a day "}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.585, "t1": 0.215, "tft": 1.2425, "input_0": 50, "input_1": 17, "min_CLP": -3.53, "draft_iters": 17.0, "mem_use": 34.95, "gen_rate": 17.0, "speed": 9.47, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.5, "tree_w": 4, "tree_size": 16, "t0": 1.04, "t1": 0.21, "tft": 1.2171, "input_0": 46, "input_1": 17, "min_CLP": -3.74, "draft_iters": 10.5, "mem_use": 34.39, "gen_rate": 6.2, "speed": 4.91, "text": "\\nCan you explain the theory beh"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.36, "t1": 0.21, "tft": 2.1225, "input_0": 47, "input_1": 17, "min_CLP": -3.82, "draft_iters": 14.3, "mem_use": 34.38, "gen_rate": 14.3, "speed": 9.1, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 23, "tree_h": 7.3, "tree_w": 5, "tree_size": 16, "t0": 0.8267, "t1": 0.22, "tft": 1.5061, "input_0": 38, "input_1": 17, "min_CLP": -3.79, "draft_iters": 8.3, "mem_use": 34.68, "gen_rate": 3.8, "speed": 3.67, "text": "D-theanine is an inactive form o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6238, "t1": 0.21, "tft": 1.3031, "input_0": 37, "input_1": 17, "min_CLP": -3.9, "draft_iters": 5.9, "mem_use": 34.38, "gen_rate": 4.1, "speed": 4.94, "text": "\\nThe Balfour Declaration was a "}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.5533, "t1": 0.22, "tft": 1.4875, "input_0": 56, "input_1": 17, "min_CLP": -3.16, "draft_iters": 16.0, "mem_use": 34.85, "gen_rate": 16.0, "speed": 9.01, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.615, "t1": 0.21, "tft": 1.3758, "input_0": 55, "input_1": 17, "min_CLP": -2.27, "draft_iters": 17.0, "mem_use": 34.43, "gen_rate": 17.0, "speed": 9.29, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.608, "t1": 0.24, "tft": 2.7622, "input_0": 35, "input_1": 17, "min_CLP": -3.61, "draft_iters": 5.4, "mem_use": 35.61, "gen_rate": 3.6, "speed": 4.25, "text": "First, it is important to determ"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.545, "t1": 0.21, "tft": 1.3083, "input_0": 50, "input_1": 17, "min_CLP": -3.57, "draft_iters": 16.5, "mem_use": 34.77, "gen_rate": 12.0, "speed": 6.82, "text": "\\n[INST] <<SYS>>\\nCan you descri"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.605, "t1": 0.225, "tft": 1.8527, "input_0": 54, "input_1": 17, "min_CLP": -3.96, "draft_iters": 17.0, "mem_use": 34.96, "gen_rate": 17.0, "speed": 9.3, "text": "[INST] send mail to Sarah asking"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.74, "t1": 0.21, "tft": 1.2244, "input_0": 34, "input_1": 17, "min_CLP": -3.71, "draft_iters": 7.3, "mem_use": 34.46, "gen_rate": 3.8, "speed": 3.97, "text": "\\nWhat are some modern-day polit"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.5233, "t1": 0.22, "tft": 1.799, "input_0": 29, "input_1": 17, "min_CLP": -3.8, "draft_iters": 4.9, "mem_use": 34.74, "gen_rate": 3.6, "speed": 4.79, "text": "Austenite is a phase of stainles"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.7, "tree_w": 4, "tree_size": 16, "t0": 1.2, "t1": 0.22, "tft": 1.3454, "input_0": 44, "input_1": 17, "min_CLP": -3.26, "draft_iters": 12.7, "mem_use": 34.68, "gen_rate": 11.0, "speed": 7.76, "text": "\\nAbout the company:\\nHippoplais"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 8, "tree_size": 16, "t0": 0.7312, "t1": 0.24, "tft": 2.7091, "input_0": 29, "input_1": 17, "min_CLP": -3.93, "draft_iters": 7.1, "mem_use": 35.64, "gen_rate": 4.5, "speed": 4.63, "text": "\\nA humorous and random monologu"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.55, "t1": 0.21, "tft": 1.2201, "input_0": 49, "input_1": 17, "min_CLP": -3.84, "draft_iters": 16.5, "mem_use": 34.79, "gen_rate": 16.5, "speed": 9.34, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.1, "tree_w": 8, "tree_size": 16, "t0": 0.5367, "t1": 0.22, "tft": 1.6362, "input_0": 31, "input_1": 17, "min_CLP": -3.86, "draft_iters": 5.1, "mem_use": 34.74, "gen_rate": 3.7, "speed": 4.85, "text": "No. The game is not a game of pe"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 1.085, "t1": 0.225, "tft": 1.9469, "input_0": 44, "input_1": 17, "min_CLP": -4.34, "draft_iters": 11.0, "mem_use": 35.02, "gen_rate": 10.0, "speed": 7.62, "text": "[\\\\INST] you are a helpful, resp"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 2, "tree_size": 16, "t0": 1.14, "t1": 0.215, "tft": 1.7595, "input_0": 51, "input_1": 17, "min_CLP": -3.25, "draft_iters": 11.5, "mem_use": 34.63, "gen_rate": 9.5, "speed": 7.01, "text": "\"\\nAct as the Greek Goddess Aphr"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 4.0, "tree_w": 8, "tree_size": 16, "t0": 0.546, "t1": 0.239, "tft": 2.123, "input_0": 30, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.0, "mem_use": 35.47, "gen_rate": 4.1, "speed": 5.24, "text": "\"You can use Daiya cheese, a veg"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.1, "tree_w": 9, "tree_size": 16, "t0": 0.453, "t1": 0.238, "tft": 1.9158, "input_0": 25, "input_1": 17, "min_CLP": -3.93, "draft_iters": 4.1, "mem_use": 35.42, "gen_rate": 3.2, "speed": 4.64, "text": "This is a good question. Please "}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 5, "tree_size": 16, "t0": 0.6813, "t1": 0.29, "tft": 5.0727, "input_0": 34, "input_1": 17, "min_CLP": -3.61, "draft_iters": 5.5, "mem_use": 37.11, "gen_rate": 4.0, "speed": 4.11, "text": "Selenium is a great choice for t"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.4, "tree_w": 8, "tree_size": 16, "t0": 0.5562, "t1": 0.21, "tft": 1.2234, "input_0": 29, "input_1": 17, "min_CLP": -4.11, "draft_iters": 5.4, "mem_use": 35.49, "gen_rate": 4.5, "speed": 5.86, "text": "\"\\nI would like to buy this thin"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 4, "tree_size": 16, "t0": 0.955, "t1": 0.2183, "tft": 1.5033, "input_0": 43, "input_1": 17, "min_CLP": -3.84, "draft_iters": 9.5, "mem_use": 34.67, "gen_rate": 5.3, "speed": 4.55, "text": "\\nWhat is the first letter of th"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.548, "t1": 0.25, "tft": 3.029, "input_0": 28, "input_1": 17, "min_CLP": -3.86, "draft_iters": 4.9, "mem_use": 35.86, "gen_rate": 3.3, "speed": 4.15, "text": "\"\\nHello, I'm writing this messa"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.6062, "t1": 0.22, "tft": 1.7312, "input_0": 32, "input_1": 17, "min_CLP": -3.77, "draft_iters": 5.8, "mem_use": 34.89, "gen_rate": 4.1, "speed": 4.98, "text": "The Copenhagen interpretation of"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.3, "tree_w": 3, "tree_size": 16, "t0": 1.1867, "t1": 0.21, "tft": 1.1289, "input_0": 45, "input_1": 17, "min_CLP": -3.41, "draft_iters": 12.3, "mem_use": 34.51, "gen_rate": 12.0, "speed": 8.58, "text": "<</SYS>\\n\\n                     "}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 1.092, "t1": 0.242, "tft": 2.6989, "input_0": 38, "input_1": 17, "min_CLP": -3.38, "draft_iters": 11.0, "mem_use": 35.72, "gen_rate": 7.6, "speed": 5.69, "text": "\\nWrite a quote. Do not explain "}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.5442, "t1": 0.25, "tft": 3.3122, "input_0": 27, "input_1": 17, "min_CLP": -3.85, "draft_iters": 4.9, "mem_use": 35.97, "gen_rate": 2.7, "speed": 3.35, "text": "\\nThank you! I will look for tho"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.7286, "t1": 0.23, "tft": 2.0832, "input_0": 42, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.6, "mem_use": 35.19, "gen_rate": 4.7, "speed": 4.92, "text": "\"It depends on your needs. Sonar"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 38, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.5418, "t1": 0.22, "tft": 1.5649, "input_0": 30, "input_1": 17, "min_CLP": -4.06, "draft_iters": 5.0, "mem_use": 34.81, "gen_rate": 3.5, "speed": 4.53, "text": "You\\'re welcome! Thanks for the "}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 1, "tree_size": 16, "t0": 1.49, "t1": 0.22, "tft": 1.7656, "input_0": 67, "input_1": 17, "min_CLP": -3.53, "draft_iters": 15.0, "mem_use": 34.68, "gen_rate": 15.0, "speed": 8.78, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.51, "t1": 0.21, "tft": 1.3024, "input_0": 29, "input_1": 17, "min_CLP": -3.96, "draft_iters": 4.9, "mem_use": 34.4, "gen_rate": 3.3, "speed": 4.57, "text": "\\nI installed Windows XP and aft"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 2.9, "tree_w": 8, "tree_size": 16, "t0": 0.4927, "t1": 0.29, "tft": 5.0404, "input_0": 25, "input_1": 17, "min_CLP": -4.01, "draft_iters": 3.9, "mem_use": 37.16, "gen_rate": 3.0, "speed": 3.83, "text": "\\nI think you can make the situa"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.2, "tree_w": 9, "tree_size": 16, "t0": 0.4582, "t1": 0.23, "tft": 1.8135, "input_0": 27, "input_1": 17, "min_CLP": -4.36, "draft_iters": 4.2, "mem_use": 35.6, "gen_rate": 3.0, "speed": 4.35, "text": "\\nThe Void is a manifestation of"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.3, "tree_w": 8, "tree_size": 16, "t0": 0.5491, "t1": 0.22, "tft": 1.5548, "input_0": 27, "input_1": 17, "min_CLP": -3.99, "draft_iters": 5.3, "mem_use": 34.81, "gen_rate": 3.4, "speed": 4.38, "text": "\"\\nHow do you know that they are"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.2, "tree_w": 5, "tree_size": 16, "t0": 0.8137, "t1": 0.22, "tft": 1.6486, "input_0": 33, "input_1": 17, "min_CLP": -3.87, "draft_iters": 8.2, "mem_use": 34.81, "gen_rate": 4.4, "speed": 4.23, "text": "\\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\\\INST]\\nI will try "}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 5, "tree_size": 16, "t0": 0.8683, "t1": 0.24, "tft": 2.5933, "input_0": 37, "input_1": 17, "min_CLP": -3.4, "draft_iters": 8.3, "mem_use": 35.51, "gen_rate": 5.5, "speed": 4.98, "text": "\\nWhat are the effects of F-cent"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.9, "tree_w": 5, "tree_size": 16, "t0": 0.81, "t1": 0.2288, "tft": 1.7099, "input_0": 37, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.9, "mem_use": 35.07, "gen_rate": 5.1, "speed": 4.93, "text": "Here is a list of some important"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.6082, "t1": 0.23, "tft": 2.0961, "input_0": 34, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.6, "mem_use": 35.26, "gen_rate": 3.2, "speed": 3.78, "text": "\\nYes, of course technology can "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.2, "tree_w": 6, "tree_size": 16, "t0": 0.792, "t1": 0.21, "tft": 1.2975, "input_0": 33, "input_1": 17, "min_CLP": -3.79, "draft_iters": 8.2, "mem_use": 34.6, "gen_rate": 6.4, "speed": 6.36, "text": "Yes, both men and women wear sho"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.8, "tree_w": 7, "tree_size": 16, "t0": 0.63, "t1": 0.24, "tft": 2.5628, "input_0": 32, "input_1": 17, "min_CLP": -4.06, "draft_iters": 5.8, "mem_use": 35.56, "gen_rate": 2.7, "speed": 3.07, "text": "\"We'd like to create a pitch dec"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.645, "t1": 0.2625, "tft": 4.0063, "input_0": 32, "input_1": 17, "min_CLP": -4.14, "draft_iters": 5.6, "mem_use": 36.31, "gen_rate": 4.5, "speed": 4.94, "text": "\\nThe original question is ambig"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.7225, "t1": 0.27, "tft": 4.1778, "input_0": 34, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.4, "mem_use": 36.49, "gen_rate": 4.1, "speed": 4.15, "text": "\"Keras is a great choice for beg"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.5727, "t1": 0.23, "tft": 2.0215, "input_0": 31, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.3, "mem_use": 35.23, "gen_rate": 3.3, "speed": 4.07, "text": "\"My understanding of ChatGPT's o"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.63, "t1": 0.21, "tft": 1.2931, "input_0": 31, "input_1": 17, "min_CLP": -4.11, "draft_iters": 6.1, "mem_use": 34.59, "gen_rate": 4.6, "speed": 5.43, "text": "\\nThe best way to form a new hab"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.1, "tree_w": 7, "tree_size": 16, "t0": 0.6545, "t1": 0.24, "tft": 2.5344, "input_0": 31, "input_1": 17, "min_CLP": -4.13, "draft_iters": 6.1, "mem_use": 35.59, "gen_rate": 2.9, "speed": 3.25, "text": "\\ncan you make a house of cards "}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.81, "t1": 0.2514, "tft": 3.2411, "input_0": 34, "input_1": 17, "min_CLP": -3.91, "draft_iters": 7.6, "mem_use": 36.02, "gen_rate": 6.0, "speed": 5.64, "text": "[The general looks out at his ar"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 19, "tree_h": 3.0, "tree_w": 8, "tree_size": 16, "t0": 0.4433, "t1": 0.22, "tft": 1.4672, "input_0": 26, "input_1": 17, "min_CLP": -3.84, "draft_iters": 4.0, "mem_use": 34.98, "gen_rate": 3.2, "speed": 4.76, "text": "\"Haha, it's not that easy to rem"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6138, "t1": 0.22, "tft": 1.5577, "input_0": 35, "input_1": 17, "min_CLP": -4.07, "draft_iters": 5.9, "mem_use": 34.75, "gen_rate": 4.0, "speed": 4.79, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.5, "tree_w": 8, "tree_size": 16, "t0": 0.565, "t1": 0.22, "tft": 1.4334, "input_0": 28, "input_1": 17, "min_CLP": -3.94, "draft_iters": 5.5, "mem_use": 34.79, "gen_rate": 3.6, "speed": 4.59, "text": "\"[INST] While you are waiting fo"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.3, "tree_w": 7, "tree_size": 16, "t0": 0.507, "t1": 0.26, "tft": 3.984, "input_0": 28, "input_1": 17, "min_CLP": -3.95, "draft_iters": 4.3, "mem_use": 36.23, "gen_rate": 3.5, "speed": 4.55, "text": "Void pointers are used in C++ wh"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.7, "t1": 0.2562, "tft": 3.5061, "input_0": 38, "input_1": 17, "min_CLP": -3.61, "draft_iters": 6.1, "mem_use": 36.07, "gen_rate": 4.1, "speed": 4.32, "text": "\"Hello Mike, I'm sorry to hear t"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.625, "t1": 0.2425, "tft": 2.4789, "input_0": 33, "input_1": 17, "min_CLP": -3.55, "draft_iters": 5.6, "mem_use": 35.72, "gen_rate": 4.1, "speed": 4.75, "text": "If you created a web app using a"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.3467, "t1": 0.2167, "tft": 1.2321, "input_0": 51, "input_1": 17, "min_CLP": -3.48, "draft_iters": 14.0, "mem_use": 34.82, "gen_rate": 14.0, "speed": 8.96, "text": "<</SYS>\\n\\n[INST] <<SYS>>\\nYou a"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 1, "tree_size": 16, "t0": 1.41, "t1": 0.21, "tft": 1.307, "input_0": 50, "input_1": 17, "min_CLP": -4.09, "draft_iters": 15.0, "mem_use": 34.4, "gen_rate": 15.0, "speed": 9.23, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 34, "tree_h": 3.1, "tree_w": 9, "tree_size": 16, "t0": 0.4531, "t1": 0.24, "tft": 2.4254, "input_0": 24, "input_1": 17, "min_CLP": -4.16, "draft_iters": 4.1, "mem_use": 35.62, "gen_rate": 2.6, "speed": 3.77, "text": "\\nI think I have a good understa"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 11.5, "tree_w": 3, "tree_size": 16, "t0": 1.1825, "t1": 0.21, "tft": 0.9441, "input_0": 43, "input_1": 17, "min_CLP": -3.76, "draft_iters": 12.5, "mem_use": 34.78, "gen_rate": 10.2, "speed": 7.34, "text": "\\nWho made Berlin?\\n\\nWho made B"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.5709, "t1": 0.24, "tft": 2.7102, "input_0": 32, "input_1": 17, "min_CLP": -3.94, "draft_iters": 5.2, "mem_use": 35.54, "gen_rate": 3.4, "speed": 4.15, "text": "\\nA man goes to the hardware sto"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.554, "t1": 0.239, "tft": 2.5164, "input_0": 33, "input_1": 17, "min_CLP": -4.22, "draft_iters": 4.9, "mem_use": 35.46, "gen_rate": 3.2, "speed": 4.05, "text": "Taleb\\'s writing style has been "}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 1, "tree_size": 16, "t0": 1.4067, "t1": 0.21, "tft": 1.1169, "input_0": 54, "input_1": 17, "min_CLP": -3.81, "draft_iters": 14.7, "mem_use": 34.7, "gen_rate": 14.7, "speed": 9.05, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.5067, "t1": 0.2133, "tft": 1.0614, "input_0": 29, "input_1": 17, "min_CLP": -3.85, "draft_iters": 4.8, "mem_use": 34.55, "gen_rate": 3.6, "speed": 4.93, "text": "\"Here are two ways to find out y"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.6312, "t1": 0.215, "tft": 1.1933, "input_0": 31, "input_1": 17, "min_CLP": -3.98, "draft_iters": 6.1, "mem_use": 34.57, "gen_rate": 4.2, "speed": 5.02, "text": "\\nThe five second rule is a rule"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 7, "tree_size": 16, "t0": 0.6462, "t1": 0.21, "tft": 1.3995, "input_0": 29, "input_1": 17, "min_CLP": -3.88, "draft_iters": 6.5, "mem_use": 34.42, "gen_rate": 4.1, "speed": 4.8, "text": "\\n3\\n\\nI have a bag of chips. I "}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.8, "tree_w": 7, "tree_size": 16, "t0": 0.6122, "t1": 0.22, "tft": 1.9969, "input_0": 35, "input_1": 17, "min_CLP": -3.87, "draft_iters": 5.8, "mem_use": 34.82, "gen_rate": 4.0, "speed": 4.8, "text": "The algorithm of the Sieve of Er"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 3.0, "tree_w": 12, "tree_size": 16, "t0": 0.41, "t1": 0.22, "tft": 1.1494, "input_0": 20, "input_1": 17, "min_CLP": -3.95, "draft_iters": 4.0, "mem_use": 34.6, "gen_rate": 0.0, "speed": 0.0, "text": "No problem!"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.56, "t1": 0.21, "tft": 1.3231, "input_0": 54, "input_1": 17, "min_CLP": -2.8, "draft_iters": 16.5, "mem_use": 34.45, "gen_rate": 16.5, "speed": 9.31, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5767, "t1": 0.22, "tft": 1.5448, "input_0": 32, "input_1": 17, "min_CLP": -3.83, "draft_iters": 5.4, "mem_use": 34.76, "gen_rate": 3.7, "speed": 4.61, "text": "\"There are examples of sexual se"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.668, "t1": 0.23, "tft": 2.1637, "input_0": 36, "input_1": 17, "min_CLP": -3.58, "draft_iters": 6.2, "mem_use": 35.3, "gen_rate": 3.2, "speed": 3.55, "text": "AI assistants are becoming incre"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.715, "t1": 0.25, "tft": 2.9013, "input_0": 61, "input_1": 17, "min_CLP": -1.04, "draft_iters": 17.0, "mem_use": 35.79, "gen_rate": 17.0, "speed": 8.66, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.8, "tree_w": 5, "tree_size": 16, "t0": 0.63, "t1": 0.2288, "tft": 1.7443, "input_0": 36, "input_1": 17, "min_CLP": -3.64, "draft_iters": 5.8, "mem_use": 35.11, "gen_rate": 4.1, "speed": 4.81, "text": "The scp command can be used to c"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.6144, "t1": 0.24, "tft": 2.4991, "input_0": 34, "input_1": 17, "min_CLP": -4.34, "draft_iters": 5.7, "mem_use": 35.53, "gen_rate": 4.1, "speed": 4.82, "text": "\\nI have a question about how to"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.6912, "t1": 0.21, "tft": 1.1264, "input_0": 33, "input_1": 17, "min_CLP": -4.08, "draft_iters": 6.9, "mem_use": 34.74, "gen_rate": 4.1, "speed": 4.57, "text": "\\n[INST] <<SYS>>\\nNo. It would b"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.5822, "t1": 0.2122, "tft": 1.0885, "input_0": 34, "input_1": 17, "min_CLP": -3.53, "draft_iters": 5.6, "mem_use": 34.55, "gen_rate": 3.7, "speed": 4.6, "text": "Melbourne is the largest city in"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.585, "t1": 0.22, "tft": 1.2554, "input_0": 51, "input_1": 17, "min_CLP": -3.17, "draft_iters": 17.0, "mem_use": 34.68, "gen_rate": 17.0, "speed": 9.44, "text": "\"\\nDoes the 5 second rule actual"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 42, "tree_h": 5.4, "tree_w": 7, "tree_size": 16, "t0": 0.65, "t1": 0.212, "tft": 1.165, "input_0": 30, "input_1": 17, "min_CLP": -4.32, "draft_iters": 6.4, "mem_use": 34.54, "gen_rate": 4.2, "speed": 4.86, "text": "\"What do you get if you cross Si"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.5356, "t1": 0.21, "tft": 1.3138, "input_0": 33, "input_1": 17, "min_CLP": -3.91, "draft_iters": 5.0, "mem_use": 34.42, "gen_rate": 3.6, "speed": 4.75, "text": "\\nWhen you are learning a foreig"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.491, "t1": 0.21, "tft": 1.2171, "input_0": 30, "input_1": 17, "min_CLP": -3.91, "draft_iters": 4.6, "mem_use": 34.41, "gen_rate": 3.2, "speed": 4.55, "text": "\"\\nI don't know. I think it woul"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.7, "tree_w": 5, "tree_size": 16, "t0": 0.6171, "t1": 0.23, "tft": 2.5811, "input_0": 35, "input_1": 17, "min_CLP": -3.98, "draft_iters": 5.7, "mem_use": 35.25, "gen_rate": 4.7, "speed": 5.55, "text": "\\nMathematics is a study of patt"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.7, "tree_w": 7, "tree_size": 16, "t0": 0.5073, "t1": 0.2109, "tft": 1.3139, "input_0": 29, "input_1": 17, "min_CLP": -3.9, "draft_iters": 4.7, "mem_use": 34.6, "gen_rate": 3.1, "speed": 4.29, "text": "\"\\nI've been told that the Loire"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.3, "tree_w": 9, "tree_size": 16, "t0": 0.4542, "t1": 0.2133, "tft": 1.2379, "input_0": 25, "input_1": 17, "min_CLP": -4.04, "draft_iters": 4.3, "mem_use": 34.57, "gen_rate": 2.7, "speed": 3.99, "text": "\\nThe first person controller sc"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.535, "t1": 0.21, "tft": 1.2157, "input_0": 29, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.1, "mem_use": 34.4, "gen_rate": 3.2, "speed": 4.28, "text": "\\nI would like to learn guitar. "}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.6, "tree_w": 8, "tree_size": 16, "t0": 0.5733, "t1": 0.21, "tft": 1.089, "input_0": 30, "input_1": 17, "min_CLP": -4.02, "draft_iters": 5.6, "mem_use": 34.55, "gen_rate": 3.6, "speed": 4.52, "text": "\"[INST] I have been waiting to m"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.7175, "t1": 0.21, "tft": 1.2322, "input_0": 36, "input_1": 17, "min_CLP": -3.79, "draft_iters": 7.0, "mem_use": 34.48, "gen_rate": 4.6, "speed": 4.98, "text": "Gas-operated means that the rifl"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 0.944, "t1": 0.216, "tft": 1.2349, "input_0": 38, "input_1": 17, "min_CLP": -3.37, "draft_iters": 9.8, "mem_use": 34.61, "gen_rate": 6.6, "speed": 5.69, "text": "[INST] What is Ricky Gervais? [\\"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.1, "tree_w": 8, "tree_size": 16, "t0": 0.59, "t1": 0.27, "tft": 3.9717, "input_0": 30, "input_1": 17, "min_CLP": -3.83, "draft_iters": 5.1, "mem_use": 36.45, "gen_rate": 3.4, "speed": 3.91, "text": "\"I'm sorry, I don't think there'"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.6389, "t1": 0.2178, "tft": 1.1527, "input_0": 31, "input_1": 17, "min_CLP": -3.75, "draft_iters": 6.2, "mem_use": 35.18, "gen_rate": 3.8, "speed": 4.43, "text": "No, in most cases, people who fi"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.5, "tree_w": 6, "tree_size": 16, "t0": 0.8838, "t1": 0.26, "tft": 3.5381, "input_0": 36, "input_1": 17, "min_CLP": -3.72, "draft_iters": 8.5, "mem_use": 36.14, "gen_rate": 4.1, "speed": 3.62, "text": "[INST] \u6211\u53ef\u4ee5\u7b54\u6848 [\\\\INST]\\n[INST] \u6211\u662f"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 8.8, "tree_w": 5, "tree_size": 16, "t0": 0.96, "t1": 0.22, "tft": 1.3543, "input_0": 39, "input_1": 17, "min_CLP": -3.74, "draft_iters": 9.8, "mem_use": 35.02, "gen_rate": 9.4, "speed": 7.98, "text": "You are correct. In 1957, the BB"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 6.5, "tree_w": 6, "tree_size": 16, "t0": 0.7367, "t1": 0.2183, "tft": 1.194, "input_0": 31, "input_1": 17, "min_CLP": -3.96, "draft_iters": 7.5, "mem_use": 34.59, "gen_rate": 7.2, "speed": 7.53, "text": "You can read more about decorato"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.4133, "t1": 0.23, "tft": 2.0158, "input_0": 52, "input_1": 17, "min_CLP": -3.37, "draft_iters": 14.7, "mem_use": 35.26, "gen_rate": 14.7, "speed": 8.92, "text": "Berlin is a city in Germany, loc"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.8, "tree_w": 5, "tree_size": 16, "t0": 0.956, "t1": 0.212, "tft": 1.4461, "input_0": 38, "input_1": 17, "min_CLP": -3.94, "draft_iters": 9.8, "mem_use": 34.62, "gen_rate": 9.2, "speed": 7.85, "text": "[INST] What is the most efficien"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6386, "t1": 0.24, "tft": 2.5282, "input_0": 34, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.9, "mem_use": 35.6, "gen_rate": 4.6, "speed": 5.2, "text": "A self-sustaining business needs"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.0, "tree_w": 8, "tree_size": 16, "t0": 0.523, "t1": 0.22, "tft": 1.674, "input_0": 28, "input_1": 17, "min_CLP": -3.86, "draft_iters": 5.0, "mem_use": 34.87, "gen_rate": 3.4, "speed": 4.56, "text": "I am not sure I understand your "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.6633, "t1": 0.22, "tft": 1.1302, "input_0": 33, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.3, "mem_use": 34.67, "gen_rate": 5.5, "speed": 6.25, "text": "I\u2019m sorry, but I don\u2019t know much"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.5511, "t1": 0.22, "tft": 1.5576, "input_0": 29, "input_1": 17, "min_CLP": -3.91, "draft_iters": 5.2, "mem_use": 34.73, "gen_rate": 3.8, "speed": 4.9, "text": "There are a number of top APIs, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 0.964, "t1": 0.234, "tft": 2.3441, "input_0": 40, "input_1": 17, "min_CLP": -3.38, "draft_iters": 9.6, "mem_use": 35.4, "gen_rate": 8.8, "speed": 7.34, "text": "\"Yes, you can! Here is a poem to"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.2, "tree_w": 5, "tree_size": 16, "t0": 0.8017, "t1": 0.21, "tft": 1.218, "input_0": 35, "input_1": 17, "min_CLP": -3.86, "draft_iters": 8.2, "mem_use": 34.68, "gen_rate": 6.5, "speed": 6.41, "text": "\\nI am a _______________. [\\\\INS"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.0, "tree_w": 7, "tree_size": 16, "t0": 0.4427, "t1": 0.21, "tft": 1.1952, "input_0": 27, "input_1": 17, "min_CLP": -4.11, "draft_iters": 4.0, "mem_use": 34.41, "gen_rate": 3.1, "speed": 4.71, "text": "\\nAnswer:\\n\\nThat code is incorr"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.57, "t1": 0.23, "tft": 1.8443, "input_0": 54, "input_1": 17, "min_CLP": -2.81, "draft_iters": 16.5, "mem_use": 35.12, "gen_rate": 16.5, "speed": 9.17, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.6467, "t1": 0.22, "tft": 1.5573, "input_0": 29, "input_1": 17, "min_CLP": -3.87, "draft_iters": 6.4, "mem_use": 34.74, "gen_rate": 4.6, "speed": 5.28, "text": "The `@` symbol is used to denote"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 3.7, "tree_w": 7, "tree_size": 16, "t0": 0.5, "t1": 0.22, "tft": 1.3528, "input_0": 28, "input_1": 17, "min_CLP": -3.77, "draft_iters": 4.7, "mem_use": 34.8, "gen_rate": 2.8, "speed": 3.82, "text": "The `--arg` argument is a parame"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.6138, "t1": 0.24, "tft": 2.5677, "input_0": 32, "input_1": 17, "min_CLP": -3.62, "draft_iters": 5.6, "mem_use": 35.68, "gen_rate": 4.1, "speed": 4.81, "text": "\"It's good that your friends are"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.5489, "t1": 0.22, "tft": 1.3375, "input_0": 28, "input_1": 17, "min_CLP": -4.0, "draft_iters": 5.3, "mem_use": 34.81, "gen_rate": 3.8, "speed": 4.94, "text": "\\nAbout the project\\n\\nOpen Assi"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.7117, "t1": 0.23, "tft": 2.0154, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.7, "mem_use": 35.3, "gen_rate": 5.7, "speed": 6.0, "text": "The earliest fossil evidence of "}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 10.7, "tree_w": 3, "tree_size": 16, "t0": 1.1433, "t1": 0.21, "tft": 1.2071, "input_0": 47, "input_1": 17, "min_CLP": -4.08, "draft_iters": 11.7, "mem_use": 34.65, "gen_rate": 6.8, "speed": 5.05, "text": "\\nCan you think and feel like a "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.7, "tree_w": 2, "tree_size": 16, "t0": 1.1333, "t1": 0.2133, "tft": 2.0625, "input_0": 51, "input_1": 17, "min_CLP": -3.99, "draft_iters": 11.7, "mem_use": 34.51, "gen_rate": 11.3, "speed": 8.41, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.472, "t1": 0.219, "tft": 1.0603, "input_0": 27, "input_1": 17, "min_CLP": -4.07, "draft_iters": 4.4, "mem_use": 34.62, "gen_rate": 3.3, "speed": 4.81, "text": "\\nA man with two kids and a wife"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.535, "t1": 0.24, "tft": 2.5648, "input_0": 43, "input_1": 17, "min_CLP": -2.93, "draft_iters": 16.0, "mem_use": 35.51, "gen_rate": 16.0, "speed": 9.04, "text": "You are the sun that shines,\\nA "}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.79, "t1": 0.22, "tft": 1.6481, "input_0": 39, "input_1": 17, "min_CLP": -3.66, "draft_iters": 7.8, "mem_use": 34.73, "gen_rate": 6.6, "speed": 6.54, "text": "\\nWhat are the effects of L-thea"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.575, "t1": 0.21, "tft": 1.3157, "input_0": 55, "input_1": 17, "min_CLP": -2.83, "draft_iters": 16.5, "mem_use": 34.41, "gen_rate": 16.5, "speed": 9.24, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 0.7743, "t1": 0.21, "tft": 1.3955, "input_0": 38, "input_1": 17, "min_CLP": -3.74, "draft_iters": 7.7, "mem_use": 34.4, "gen_rate": 5.1, "speed": 5.21, "text": "\"I don't know what presidents da"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 9.6, "tree_w": 3, "tree_size": 16, "t0": 1.052, "t1": 0.214, "tft": 1.1521, "input_0": 46, "input_1": 17, "min_CLP": -4.0, "draft_iters": 10.6, "mem_use": 34.55, "gen_rate": 8.4, "speed": 6.64, "text": "\\nWhich of the following is the "}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.9017, "t1": 0.2217, "tft": 2.1124, "input_0": 43, "input_1": 17, "min_CLP": -3.41, "draft_iters": 9.0, "mem_use": 34.94, "gen_rate": 6.2, "speed": 5.47, "text": "Yes, the National Reconnaissance"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.4, "tree_w": 6, "tree_size": 16, "t0": 0.8257, "t1": 0.2186, "tft": 1.4773, "input_0": 35, "input_1": 17, "min_CLP": -3.74, "draft_iters": 8.4, "mem_use": 34.6, "gen_rate": 4.6, "speed": 4.38, "text": "Why is it frustrating to be a hu"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 2, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.8, "t1": 0.21, "tft": 1.1302, "input_0": 57, "input_1": 17, "min_CLP": -4.1, "draft_iters": 7.0, "mem_use": 34.62, "gen_rate": 2.0, "speed": 1.97, "text": "<</SYS>"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.8, "tree_w": 8, "tree_size": 16, "t0": 0.5687, "t1": 0.21, "tft": 1.0183, "input_0": 25, "input_1": 17, "min_CLP": -4.26, "draft_iters": 5.8, "mem_use": 34.4, "gen_rate": 4.0, "speed": 5.11, "text": "\\n\"I\\'m going to violate the con"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.5089, "t1": 0.22, "tft": 1.5514, "input_0": 28, "input_1": 17, "min_CLP": -3.95, "draft_iters": 4.8, "mem_use": 34.74, "gen_rate": 3.7, "speed": 5.04, "text": "\"he\\'s just being a hater. he\\'s"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.4909, "t1": 0.21, "tft": 1.2286, "input_0": 26, "input_1": 17, "min_CLP": -4.22, "draft_iters": 4.6, "mem_use": 34.45, "gen_rate": 3.0, "speed": 4.26, "text": "\\n[INST] <<SYS>>\\nYour mayonnais"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 33, "tree_h": 3.1, "tree_w": 10, "tree_size": 16, "t0": 0.4323, "t1": 0.23, "tft": 1.6487, "input_0": 23, "input_1": 17, "min_CLP": -4.33, "draft_iters": 4.1, "mem_use": 35.06, "gen_rate": 2.5, "speed": 3.85, "text": "\"\\nYou probably can't. \\n\\nA hum"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 2.9, "tree_w": 9, "tree_size": 16, "t0": 0.42, "t1": 0.2175, "tft": 1.0315, "input_0": 24, "input_1": 17, "min_CLP": -4.02, "draft_iters": 3.9, "mem_use": 34.62, "gen_rate": 2.8, "speed": 4.46, "text": "\"\\nI don't think so, but I'm not"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.554, "t1": 0.23, "tft": 2.0223, "input_0": 31, "input_1": 17, "min_CLP": -3.7, "draft_iters": 5.1, "mem_use": 35.25, "gen_rate": 3.2, "speed": 4.07, "text": "Most trails are easy to moderate"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 1.1525, "t1": 0.2175, "tft": 1.4143, "input_0": 45, "input_1": 17, "min_CLP": -3.9, "draft_iters": 12.0, "mem_use": 34.6, "gen_rate": 11.0, "speed": 8.06, "text": "<</SYS>\\n\\nWrite a tweet for med"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.0, "tree_w": 3, "tree_size": 16, "t0": 1.33, "t1": 0.2133, "tft": 1.182, "input_0": 50, "input_1": 17, "min_CLP": -3.31, "draft_iters": 14.0, "mem_use": 34.54, "gen_rate": 12.3, "speed": 8.0, "text": "<</SYS>\\n\\n[INST] <<SYS>>\\nYou a"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.6718, "t1": 0.25, "tft": 3.1075, "input_0": 33, "input_1": 17, "min_CLP": -3.68, "draft_iters": 6.3, "mem_use": 35.81, "gen_rate": 2.9, "speed": 3.16, "text": "\"As for why this script doesn't "}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 2, "tree_size": 16, "t0": 1.32, "t1": 0.21, "tft": 1.0403, "input_0": 52, "input_1": 17, "min_CLP": -3.87, "draft_iters": 13.7, "mem_use": 34.89, "gen_rate": 13.7, "speed": 8.92, "text": "\\nCan I compile python code to m"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.5033, "t1": 0.2192, "tft": 1.2147, "input_0": 27, "input_1": 17, "min_CLP": -3.94, "draft_iters": 4.8, "mem_use": 34.67, "gen_rate": 2.7, "speed": 3.7, "text": "There are a lot of other industr"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 1.046, "t1": 0.21, "tft": 1.4124, "input_0": 41, "input_1": 17, "min_CLP": -3.73, "draft_iters": 10.8, "mem_use": 34.48, "gen_rate": 8.0, "speed": 6.35, "text": "The reason why this matters is b"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.5209, "t1": 0.21, "tft": 1.2223, "input_0": 30, "input_1": 17, "min_CLP": -4.18, "draft_iters": 4.9, "mem_use": 34.4, "gen_rate": 3.1, "speed": 4.21, "text": "I want to develop machine learni"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.6636, "t1": 0.2382, "tft": 2.3319, "input_0": 31, "input_1": 17, "min_CLP": -3.74, "draft_iters": 6.3, "mem_use": 35.45, "gen_rate": 2.9, "speed": 3.23, "text": "1. Did you send a video or meme "}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.2, "tree_w": 6, "tree_size": 16, "t0": 0.71, "t1": 0.21, "tft": 1.2702, "input_0": 30, "input_1": 17, "min_CLP": -4.22, "draft_iters": 7.2, "mem_use": 34.69, "gen_rate": 3.4, "speed": 3.69, "text": "\"\\nIs it violent to play with yo"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 11.2, "tree_w": 3, "tree_size": 16, "t0": 1.1875, "t1": 0.21, "tft": 1.2264, "input_0": 49, "input_1": 17, "min_CLP": -3.21, "draft_iters": 12.2, "mem_use": 34.41, "gen_rate": 12.0, "speed": 8.57, "text": "\"\\nThe third verse of Rick Astle"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.576, "t1": 0.251, "tft": 3.1566, "input_0": 31, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.0, "mem_use": 36.0, "gen_rate": 3.4, "speed": 4.1, "text": "\\nWhile there are many countries"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.5244, "t1": 0.2278, "tft": 1.6764, "input_0": 28, "input_1": 17, "min_CLP": -3.83, "draft_iters": 4.9, "mem_use": 35.05, "gen_rate": 4.0, "speed": 5.32, "text": "I am sorry if I have offended yo"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.902, "t1": 0.216, "tft": 1.3607, "input_0": 41, "input_1": 17, "min_CLP": -3.85, "draft_iters": 9.0, "mem_use": 34.54, "gen_rate": 7.8, "speed": 7.01, "text": "Du kannst Deutsch sprechen? (You"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.555, "t1": 0.215, "tft": 1.3331, "input_0": 53, "input_1": 17, "min_CLP": -3.27, "draft_iters": 16.5, "mem_use": 34.51, "gen_rate": 16.5, "speed": 9.33, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 7.3, "tree_w": 5, "tree_size": 16, "t0": 0.8133, "t1": 0.21, "tft": 1.1354, "input_0": 33, "input_1": 17, "min_CLP": -4.46, "draft_iters": 8.3, "mem_use": 34.4, "gen_rate": 6.8, "speed": 6.66, "text": "\\nwhat is the role of a populati"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 0.8875, "t1": 0.22, "tft": 1.3699, "input_0": 39, "input_1": 17, "min_CLP": -3.43, "draft_iters": 8.9, "mem_use": 34.82, "gen_rate": 4.2, "speed": 3.83, "text": "\"I'm sorry, I don't quite unders"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.6633, "t1": 0.2233, "tft": 2.7039, "input_0": 63, "input_1": 17, "min_CLP": -2.82, "draft_iters": 17.0, "mem_use": 34.94, "gen_rate": 12.7, "speed": 6.71, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.9156, "t1": 0.2789, "tft": 4.4891, "input_0": 40, "input_1": 17, "min_CLP": -3.53, "draft_iters": 8.1, "mem_use": 36.7, "gen_rate": 3.7, "speed": 3.08, "text": "Step 2 \u2014 Compiling Your TypeScri"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.7, "tree_w": 4, "tree_size": 16, "t0": 1.0283, "t1": 0.21, "tft": 1.3026, "input_0": 39, "input_1": 17, "min_CLP": -3.78, "draft_iters": 10.7, "mem_use": 35.29, "gen_rate": 6.0, "speed": 4.84, "text": "\\nHow can I be more social witho"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 38, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.5, "t1": 0.2192, "tft": 1.1369, "input_0": 28, "input_1": 17, "min_CLP": -4.03, "draft_iters": 4.8, "mem_use": 34.69, "gen_rate": 3.2, "speed": 4.41, "text": "[INST] Berlin is known for its h"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.54, "t1": 0.21, "tft": 1.1352, "input_0": 53, "input_1": 17, "min_CLP": -3.15, "draft_iters": 16.5, "mem_use": 34.41, "gen_rate": 16.5, "speed": 9.41, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.4, "tree_w": 8, "tree_size": 16, "t0": 0.578, "t1": 0.24, "tft": 2.6411, "input_0": 26, "input_1": 17, "min_CLP": -4.05, "draft_iters": 5.4, "mem_use": 35.64, "gen_rate": 3.2, "speed": 3.9, "text": "\"\\n[INST] <<SYS>>\\nI'm looking t"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.2, "tree_w": 9, "tree_size": 16, "t0": 0.4382, "t1": 0.21, "tft": 0.9512, "input_0": 25, "input_1": 17, "min_CLP": -4.21, "draft_iters": 4.2, "mem_use": 34.79, "gen_rate": 2.9, "speed": 4.46, "text": "\\nThe most important thing in a "}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 2, "tree_size": 16, "t0": 1.5033, "t1": 0.24, "tft": 3.5764, "input_0": 51, "input_1": 17, "min_CLP": -3.24, "draft_iters": 15.3, "mem_use": 35.57, "gen_rate": 15.3, "speed": 8.79, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.3, "tree_w": 8, "tree_size": 16, "t0": 0.464, "t1": 0.21, "tft": 1.1329, "input_0": 27, "input_1": 17, "min_CLP": -4.01, "draft_iters": 4.3, "mem_use": 34.77, "gen_rate": 3.3, "speed": 4.88, "text": "\\nIn the technological age, we a"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.61, "t1": 0.21, "tft": 2.0732, "input_0": 60, "input_1": 17, "min_CLP": -3.03, "draft_iters": 17.0, "mem_use": 34.41, "gen_rate": 17.0, "speed": 9.33, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.4864, "t1": 0.21, "tft": 1.3262, "input_0": 27, "input_1": 17, "min_CLP": -4.26, "draft_iters": 4.5, "mem_use": 34.45, "gen_rate": 2.9, "speed": 4.16, "text": "Please provide a brief outline o"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.529, "t1": 0.222, "tft": 1.8494, "input_0": 31, "input_1": 17, "min_CLP": -3.78, "draft_iters": 4.9, "mem_use": 34.95, "gen_rate": 3.4, "speed": 4.52, "text": "Yes, the quality of life was ver"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 33, "tree_h": 3.2, "tree_w": 8, "tree_size": 16, "t0": 0.4415, "t1": 0.21, "tft": 1.2273, "input_0": 25, "input_1": 17, "min_CLP": -4.13, "draft_iters": 4.2, "mem_use": 34.46, "gen_rate": 2.5, "speed": 3.88, "text": "\"\\nP.S.\\nI'm sorry, I don't know"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.1, "tree_w": 5, "tree_size": 16, "t0": 0.8857, "t1": 0.2171, "tft": 1.0691, "input_0": 35, "input_1": 17, "min_CLP": -3.65, "draft_iters": 9.1, "mem_use": 34.54, "gen_rate": 5.3, "speed": 4.8, "text": "[INST] <<SYS>>\\nThe link format "}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.548, "t1": 0.219, "tft": 1.3485, "input_0": 30, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.2, "mem_use": 34.68, "gen_rate": 3.5, "speed": 4.57, "text": "Selective fire means that the ri"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.55, "t1": 0.21, "tft": 1.3359, "input_0": 34, "input_1": 17, "min_CLP": -4.23, "draft_iters": 5.1, "mem_use": 34.48, "gen_rate": 3.4, "speed": 4.46, "text": "[INST] I am a Goddess of love, b"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.7, "tree_w": 7, "tree_size": 16, "t0": 0.519, "t1": 0.23, "tft": 1.9777, "input_0": 30, "input_1": 17, "min_CLP": -4.06, "draft_iters": 4.7, "mem_use": 35.2, "gen_rate": 3.3, "speed": 4.41, "text": "\"The commands mkdir and cd are a"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 4, "tree_size": 16, "t0": 0.9483, "t1": 0.21, "tft": 1.3121, "input_0": 43, "input_1": 17, "min_CLP": -3.19, "draft_iters": 9.5, "mem_use": 34.58, "gen_rate": 5.5, "speed": 4.73, "text": "\\nWrite a response that agrees w"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.493, "t1": 0.22, "tft": 1.743, "input_0": 29, "input_1": 17, "min_CLP": -3.88, "draft_iters": 4.5, "mem_use": 34.82, "gen_rate": 3.2, "speed": 4.48, "text": "The first commercially available"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.2, "tree_w": 8, "tree_size": 16, "t0": 0.5444, "t1": 0.21, "tft": 1.2213, "input_0": 29, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.2, "mem_use": 34.46, "gen_rate": 3.9, "speed": 5.13, "text": "\\nLast edited by [GAM] on Fri De"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.4708, "t1": 0.21, "tft": 1.1307, "input_0": 26, "input_1": 17, "min_CLP": -4.37, "draft_iters": 4.5, "mem_use": 34.39, "gen_rate": 2.8, "speed": 4.14, "text": "\\nThe cat was placed in a box wi"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.6762, "t1": 0.2712, "tft": 4.8144, "input_0": 33, "input_1": 17, "min_CLP": -3.37, "draft_iters": 5.9, "mem_use": 36.57, "gen_rate": 4.0, "speed": 4.22, "text": "\"If you're concerned about the w"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 2.9, "tree_w": 8, "tree_size": 16, "t0": 0.431, "t1": 0.211, "tft": 1.1721, "input_0": 26, "input_1": 17, "min_CLP": -3.98, "draft_iters": 3.9, "mem_use": 35.23, "gen_rate": 3.3, "speed": 5.13, "text": "\"\\nI really like this project. I"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 9.2, "tree_w": 4, "tree_size": 16, "t0": 1.0233, "t1": 0.2217, "tft": 1.7124, "input_0": 45, "input_1": 17, "min_CLP": -3.39, "draft_iters": 10.2, "mem_use": 34.93, "gen_rate": 7.3, "speed": 5.88, "text": "The distance to travel around th"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.6022, "t1": 0.24, "tft": 2.5241, "input_0": 32, "input_1": 17, "min_CLP": -4.0, "draft_iters": 5.4, "mem_use": 35.59, "gen_rate": 3.9, "speed": 4.62, "text": "If you are playing survival mode"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.5, "tree_w": 9, "tree_size": 16, "t0": 0.471, "t1": 0.213, "tft": 1.0755, "input_0": 25, "input_1": 17, "min_CLP": -4.3, "draft_iters": 4.5, "mem_use": 34.76, "gen_rate": 3.2, "speed": 4.66, "text": "\"You're like a rich kid in the g"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.9083, "t1": 0.2117, "tft": 1.2715, "input_0": 39, "input_1": 17, "min_CLP": -3.32, "draft_iters": 9.2, "mem_use": 34.54, "gen_rate": 5.8, "speed": 5.2, "text": "\"[INST] You're welcome. [\\\\INST]"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.6456, "t1": 0.22, "tft": 1.8857, "input_0": 33, "input_1": 17, "min_CLP": -3.6, "draft_iters": 6.2, "mem_use": 34.78, "gen_rate": 3.9, "speed": 4.5, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.6425, "t1": 0.2125, "tft": 1.1841, "input_0": 34, "input_1": 17, "min_CLP": -4.1, "draft_iters": 6.1, "mem_use": 34.54, "gen_rate": 4.0, "speed": 4.67, "text": "What were the main points discus"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.6511, "t1": 0.22, "tft": 1.6768, "input_0": 36, "input_1": 17, "min_CLP": -3.81, "draft_iters": 6.2, "mem_use": 34.9, "gen_rate": 3.6, "speed": 4.07, "text": "\\nWhat was the atomic number of "}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.4967, "t1": 0.2133, "tft": 1.1901, "input_0": 50, "input_1": 17, "min_CLP": -3.1, "draft_iters": 16.0, "mem_use": 34.54, "gen_rate": 16.0, "speed": 9.35, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.2567, "t1": 0.21, "tft": 1.3128, "input_0": 44, "input_1": 17, "min_CLP": -3.78, "draft_iters": 13.3, "mem_use": 34.41, "gen_rate": 12.0, "speed": 8.17, "text": "\\nList the pieces of a reinforce"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 32, "tree_h": 3.3, "tree_w": 8, "tree_size": 16, "t0": 0.4507, "t1": 0.21, "tft": 1.2266, "input_0": 25, "input_1": 17, "min_CLP": -4.26, "draft_iters": 4.3, "mem_use": 34.4, "gen_rate": 2.3, "speed": 3.45, "text": "\\nThe following is a list of que"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.8, "tree_w": 4, "tree_size": 16, "t0": 1.18, "t1": 0.28, "tft": 4.3848, "input_0": 44, "input_1": 17, "min_CLP": -3.61, "draft_iters": 10.8, "mem_use": 36.79, "gen_rate": 8.8, "speed": 6.0, "text": "\"\\nImplement the bubble sort alg"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.729, "t1": 0.21, "tft": 1.2936, "input_0": 35, "input_1": 17, "min_CLP": -3.65, "draft_iters": 7.2, "mem_use": 35.34, "gen_rate": 3.3, "speed": 3.5, "text": "Javascript is widely used to dev"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.58, "t1": 0.23, "tft": 2.112, "input_0": 34, "input_1": 17, "min_CLP": -3.76, "draft_iters": 5.2, "mem_use": 35.24, "gen_rate": 3.6, "speed": 4.38, "text": "F-centers can be produced from a"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.42, "t1": 0.23, "tft": 1.9992, "input_0": 57, "input_1": 17, "min_CLP": -3.04, "draft_iters": 14.3, "mem_use": 35.14, "gen_rate": 12.7, "speed": 7.67, "text": "\\nIn option, \"2. Use the Command"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.3967, "t1": 0.2133, "tft": 1.2753, "input_0": 49, "input_1": 17, "min_CLP": -3.27, "draft_iters": 14.7, "mem_use": 34.55, "gen_rate": 12.7, "speed": 7.86, "text": "\\n[SYS]\\n\\nYou are a helpful, re"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 3, "tree_size": 16, "t0": 1.2075, "t1": 0.21, "tft": 1.2218, "input_0": 51, "input_1": 17, "min_CLP": -3.87, "draft_iters": 12.5, "mem_use": 34.44, "gen_rate": 8.5, "speed": 5.98, "text": "\\n<SYS>\\n\\n<INST>\\n\\n<SYS>\\n\\n<S"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.489, "t1": 0.21, "tft": 1.3166, "input_0": 28, "input_1": 17, "min_CLP": -3.98, "draft_iters": 4.6, "mem_use": 34.42, "gen_rate": 3.2, "speed": 4.55, "text": "\\nWhen you are asked a question "}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.0, "tree_w": 7, "tree_size": 16, "t0": 0.624, "t1": 0.221, "tft": 1.6757, "input_0": 33, "input_1": 17, "min_CLP": -3.95, "draft_iters": 6.0, "mem_use": 34.94, "gen_rate": 3.3, "speed": 3.89, "text": "\\n[INST] As a moron, I fail to c"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.515, "t1": 0.22, "tft": 1.3182, "input_0": 53, "input_1": 17, "min_CLP": -3.64, "draft_iters": 16.0, "mem_use": 34.58, "gen_rate": 16.0, "speed": 9.23, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.4767, "t1": 0.23, "tft": 2.4655, "input_0": 52, "input_1": 17, "min_CLP": -2.83, "draft_iters": 15.3, "mem_use": 35.28, "gen_rate": 15.3, "speed": 8.97, "text": "Here is a list of words related "}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.6, "tree_w": 7, "tree_size": 16, "t0": 0.6714, "t1": 0.2186, "tft": 1.1412, "input_0": 32, "input_1": 17, "min_CLP": -3.89, "draft_iters": 6.6, "mem_use": 34.69, "gen_rate": 4.9, "speed": 5.46, "text": "That they are a compassionate pe"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.6822, "t1": 0.2189, "tft": 1.1234, "input_0": 30, "input_1": 17, "min_CLP": -3.69, "draft_iters": 6.8, "mem_use": 34.6, "gen_rate": 3.9, "speed": 4.33, "text": "\"\\nIs it the government's respon"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5618, "t1": 0.2118, "tft": 1.3194, "input_0": 31, "input_1": 17, "min_CLP": -3.98, "draft_iters": 5.4, "mem_use": 34.49, "gen_rate": 3.2, "speed": 4.09, "text": "\\nProgramming languages are gene"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.5712, "t1": 0.25, "tft": 3.2946, "input_0": 28, "input_1": 17, "min_CLP": -4.0, "draft_iters": 5.1, "mem_use": 35.89, "gen_rate": 4.0, "speed": 4.87, "text": "\\nDo you have any suggestions fo"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.5467, "t1": 0.25, "tft": 3.3751, "input_0": 31, "input_1": 17, "min_CLP": -3.99, "draft_iters": 4.7, "mem_use": 35.91, "gen_rate": 3.8, "speed": 4.75, "text": "\\n\"I don\\'t mean to be rude, but"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.6587, "t1": 0.21, "tft": 1.3011, "input_0": 30, "input_1": 17, "min_CLP": -3.88, "draft_iters": 6.6, "mem_use": 34.91, "gen_rate": 4.6, "speed": 5.32, "text": "\"\\nSend it to me via PM or Twitt"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.65, "t1": 0.225, "tft": 2.374, "input_0": 64, "input_1": 17, "min_CLP": -3.95, "draft_iters": 17.0, "mem_use": 34.98, "gen_rate": 17.0, "speed": 9.06, "text": "\\n\"Exciting news, Medium readers"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 2, "tree_size": 16, "t0": 1.47, "t1": 0.23, "tft": 1.9329, "input_0": 49, "input_1": 17, "min_CLP": -3.6, "draft_iters": 15.3, "mem_use": 35.21, "gen_rate": 15.3, "speed": 9.03, "text": "\"\\nLet's say you're driving and "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.71, "t1": 0.21, "tft": 1.6333, "input_0": 33, "input_1": 17, "min_CLP": -3.9, "draft_iters": 7.1, "mem_use": 34.6, "gen_rate": 4.1, "speed": 4.47, "text": "\\nHow do I normalize a vector? ["}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.63, "t1": 0.21, "tft": 1.0931, "input_0": 67, "input_1": 17, "min_CLP": -2.58, "draft_iters": 16.5, "mem_use": 34.53, "gen_rate": 16.5, "speed": 8.94, "text": "I am Freyja, a god from beyond t"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.6, "tree_w": 7, "tree_size": 16, "t0": 0.792, "t1": 0.23, "tft": 2.193, "input_0": 40, "input_1": 17, "min_CLP": -3.73, "draft_iters": 7.6, "mem_use": 35.31, "gen_rate": 6.4, "speed": 6.24, "text": "\"Many people have heard that Her"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 34, "tree_h": 3.3, "tree_w": 9, "tree_size": 16, "t0": 0.4523, "t1": 0.2115, "tft": 1.3109, "input_0": 25, "input_1": 17, "min_CLP": -4.12, "draft_iters": 4.3, "mem_use": 34.63, "gen_rate": 2.6, "speed": 3.93, "text": "\"\\nA:\\n\\nYes. I think it's possi"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.8, "tree_w": 4, "tree_size": 16, "t0": 1.05, "t1": 0.23, "tft": 2.0302, "input_0": 37, "input_1": 17, "min_CLP": -3.77, "draft_iters": 10.8, "mem_use": 35.27, "gen_rate": 10.5, "speed": 8.19, "text": "\\nSure!\\n\\nI have two remote Deb"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.488, "t1": 0.21, "tft": 1.2158, "input_0": 27, "input_1": 17, "min_CLP": -3.96, "draft_iters": 4.6, "mem_use": 34.63, "gen_rate": 3.2, "speed": 4.56, "text": "\\nThe next decade is going to be"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 7, "tree_size": 16, "t0": 0.784, "t1": 0.21, "tft": 1.2197, "input_0": 37, "input_1": 17, "min_CLP": -3.79, "draft_iters": 7.8, "mem_use": 34.4, "gen_rate": 6.4, "speed": 6.4, "text": "\\nHow do I cook a salmon fillet "}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.51, "t1": 0.22, "tft": 1.4378, "input_0": 50, "input_1": 17, "min_CLP": -3.29, "draft_iters": 16.0, "mem_use": 34.74, "gen_rate": 16.0, "speed": 9.24, "text": "\\ncan you write code? [\\\\INST]\\n"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 3, "tree_size": 16, "t0": 1.2567, "t1": 0.22, "tft": 1.5981, "input_0": 41, "input_1": 17, "min_CLP": -3.5, "draft_iters": 13.3, "mem_use": 34.91, "gen_rate": 13.3, "speed": 9.04, "text": "\\nCan you write haiku for differ"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.5111, "t1": 0.21, "tft": 1.1264, "input_0": 28, "input_1": 17, "min_CLP": -4.0, "draft_iters": 4.9, "mem_use": 34.44, "gen_rate": 3.8, "speed": 5.23, "text": "\\nAn AK47 is a rifle, designed b"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.555, "t1": 0.215, "tft": 1.3206, "input_0": 43, "input_1": 17, "min_CLP": -3.43, "draft_iters": 17.0, "mem_use": 34.57, "gen_rate": 17.0, "speed": 9.61, "text": "\\nI have two remote Debian serve"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 46, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.5691, "t1": 0.23, "tft": 2.2519, "input_0": 26, "input_1": 17, "min_CLP": -3.99, "draft_iters": 5.5, "mem_use": 35.29, "gen_rate": 4.2, "speed": 5.22, "text": "\"I'd like to make sure you under"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.3967, "t1": 0.2133, "tft": 1.2814, "input_0": 50, "input_1": 17, "min_CLP": -3.32, "draft_iters": 14.7, "mem_use": 34.66, "gen_rate": 14.7, "speed": 9.12, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.6522, "t1": 0.22, "tft": 1.4536, "input_0": 35, "input_1": 17, "min_CLP": -3.63, "draft_iters": 6.2, "mem_use": 34.8, "gen_rate": 3.9, "speed": 4.46, "text": "\"You are correct, there's no har"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.471, "t1": 0.216, "tft": 1.1198, "input_0": 27, "input_1": 17, "min_CLP": -3.98, "draft_iters": 4.4, "mem_use": 34.63, "gen_rate": 3.2, "speed": 4.67, "text": "\\nI know a friend who is very de"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 6.0, "tree_w": 6, "tree_size": 16, "t0": 0.704, "t1": 0.22, "tft": 1.8409, "input_0": 32, "input_1": 17, "min_CLP": -3.92, "draft_iters": 7.0, "mem_use": 34.69, "gen_rate": 4.1, "speed": 4.45, "text": "User : ok please tell me about t"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.5, "tree_w": 3, "tree_size": 16, "t0": 1.1025, "t1": 0.21, "tft": 1.2143, "input_0": 43, "input_1": 17, "min_CLP": -3.93, "draft_iters": 11.5, "mem_use": 34.38, "gen_rate": 11.0, "speed": 8.36, "text": "\\nWhat is your favorite food? [\\"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.1, "tree_w": 8, "tree_size": 16, "t0": 0.4373, "t1": 0.21, "tft": 1.2163, "input_0": 26, "input_1": 17, "min_CLP": -4.18, "draft_iters": 4.1, "mem_use": 34.38, "gen_rate": 3.1, "speed": 4.75, "text": "\\nThe cryptocurrency market is i"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.72, "t1": 0.2188, "tft": 1.4379, "input_0": 37, "input_1": 17, "min_CLP": -3.77, "draft_iters": 7.0, "mem_use": 34.69, "gen_rate": 4.0, "speed": 4.27, "text": "[INST]\\nWhat is the difference b"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 33, "tree_h": 3.1, "tree_w": 9, "tree_size": 16, "t0": 0.4292, "t1": 0.2115, "tft": 1.1807, "input_0": 24, "input_1": 17, "min_CLP": -4.19, "draft_iters": 4.1, "mem_use": 34.54, "gen_rate": 2.5, "speed": 3.95, "text": "\\nThe AI chat bot is your only c"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 1, "tree_size": 16, "t0": 1.4067, "t1": 0.21, "tft": 1.313, "input_0": 53, "input_1": 17, "min_CLP": -4.06, "draft_iters": 14.7, "mem_use": 34.43, "gen_rate": 14.7, "speed": 9.06, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.5675, "t1": 0.21, "tft": 1.1318, "input_0": 28, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.5, "mem_use": 34.41, "gen_rate": 4.0, "speed": 5.13, "text": "Why do women wear high heels? [\\"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.4033, "t1": 0.22, "tft": 1.3352, "input_0": 55, "input_1": 17, "min_CLP": -3.27, "draft_iters": 14.7, "mem_use": 34.65, "gen_rate": 14.7, "speed": 9.05, "text": "The Windows XP background image "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.59, "t1": 0.26, "tft": 3.9476, "input_0": 30, "input_1": 17, "min_CLP": -3.54, "draft_iters": 5.2, "mem_use": 36.26, "gen_rate": 3.2, "speed": 3.75, "text": "You should ask your neighbours i"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.5755, "t1": 0.24, "tft": 2.4208, "input_0": 28, "input_1": 17, "min_CLP": -3.76, "draft_iters": 5.3, "mem_use": 35.58, "gen_rate": 3.1, "speed": 3.8, "text": "\"\\nDear Mike, I'm sorry, but it "}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.9, "tree_w": 6, "tree_size": 16, "t0": 0.5244, "t1": 0.22, "tft": 1.5369, "input_0": 29, "input_1": 17, "min_CLP": -3.66, "draft_iters": 4.9, "mem_use": 34.76, "gen_rate": 3.7, "speed": 4.93, "text": "There are many factors that woul"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.5525, "t1": 0.21, "tft": 1.1293, "input_0": 29, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.2, "mem_use": 34.39, "gen_rate": 2.8, "speed": 3.59, "text": "\"\\nIf there are, I'd really appr"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 2, "tree_size": 16, "t0": 1.42, "t1": 0.21, "tft": 1.2961, "input_0": 52, "input_1": 17, "min_CLP": -3.94, "draft_iters": 15.0, "mem_use": 34.38, "gen_rate": 15.0, "speed": 9.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.8, "tree_w": 7, "tree_size": 16, "t0": 0.576, "t1": 0.213, "tft": 1.2734, "input_0": 28, "input_1": 17, "min_CLP": -4.22, "draft_iters": 5.8, "mem_use": 34.53, "gen_rate": 3.4, "speed": 4.31, "text": "\\nYou can use [\\\\INST] to help y"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 5, "tree_size": 16, "t0": 0.5971, "t1": 0.22, "tft": 1.7972, "input_0": 36, "input_1": 17, "min_CLP": -3.74, "draft_iters": 5.6, "mem_use": 34.93, "gen_rate": 4.6, "speed": 5.58, "text": "With more than one access point,"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5833, "t1": 0.23, "tft": 2.0238, "input_0": 30, "input_1": 17, "min_CLP": -3.67, "draft_iters": 5.4, "mem_use": 35.25, "gen_rate": 4.1, "speed": 5.04, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 3.5, "tree_w": 9, "tree_size": 16, "t0": 0.4754, "t1": 0.21, "tft": 1.1366, "input_0": 27, "input_1": 17, "min_CLP": -4.18, "draft_iters": 4.5, "mem_use": 34.61, "gen_rate": 2.5, "speed": 3.58, "text": "\"\\nI feel like this is the type "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.4867, "t1": 0.22, "tft": 1.8154, "input_0": 64, "input_1": 17, "min_CLP": -3.82, "draft_iters": 15.3, "mem_use": 34.62, "gen_rate": 15.3, "speed": 9.0, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n[INST]"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.5225, "t1": 0.21, "tft": 1.2128, "input_0": 33, "input_1": 17, "min_CLP": -3.82, "draft_iters": 4.8, "mem_use": 34.39, "gen_rate": 4.0, "speed": 5.43, "text": "\\nPolar bears are cold-blooded a"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.4764, "t1": 0.2145, "tft": 1.1873, "input_0": 28, "input_1": 17, "min_CLP": -3.96, "draft_iters": 4.5, "mem_use": 34.55, "gen_rate": 2.9, "speed": 4.21, "text": "\\nHere is the problem with this "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.4, "tree_w": 8, "tree_size": 16, "t0": 0.5487, "t1": 0.2125, "tft": 1.0671, "input_0": 27, "input_1": 17, "min_CLP": -3.74, "draft_iters": 5.4, "mem_use": 34.54, "gen_rate": 4.0, "speed": 5.24, "text": "I have never heard of a sudoku f"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.5, "tree_w": 6, "tree_size": 16, "t0": 0.78, "t1": 0.24, "tft": 2.4108, "input_0": 36, "input_1": 17, "min_CLP": -3.95, "draft_iters": 7.5, "mem_use": 35.59, "gen_rate": 5.8, "speed": 5.72, "text": "<</SYS>\\n\\n1. The dough needs to"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.5, "tree_w": 7, "tree_size": 16, "t0": 0.6587, "t1": 0.2125, "tft": 1.235, "input_0": 32, "input_1": 17, "min_CLP": -3.9, "draft_iters": 6.5, "mem_use": 34.76, "gen_rate": 4.5, "speed": 5.15, "text": "\\nhow to learn to read and write"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.6544, "t1": 0.25, "tft": 3.3041, "input_0": 33, "input_1": 17, "min_CLP": -3.84, "draft_iters": 5.9, "mem_use": 35.91, "gen_rate": 3.7, "speed": 4.06, "text": "The story should have a beginnin"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.485, "t1": 0.21, "tft": 1.1371, "input_0": 45, "input_1": 17, "min_CLP": -3.47, "draft_iters": 16.0, "mem_use": 34.91, "gen_rate": 16.0, "speed": 9.43, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.621, "t1": 0.21, "tft": 1.1251, "input_0": 34, "input_1": 17, "min_CLP": -4.07, "draft_iters": 5.9, "mem_use": 34.39, "gen_rate": 3.6, "speed": 4.33, "text": "\\nJavaScript is a programming la"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.3275, "t1": 0.21, "tft": 1.3026, "input_0": 46, "input_1": 17, "min_CLP": -4.13, "draft_iters": 14.0, "mem_use": 34.4, "gen_rate": 8.8, "speed": 5.67, "text": "\\nCreate a table with the planet"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.6483, "t1": 0.215, "tft": 1.1095, "input_0": 33, "input_1": 17, "min_CLP": -3.74, "draft_iters": 6.3, "mem_use": 34.6, "gen_rate": 5.8, "speed": 6.76, "text": "Yes, you can use the image.\\n[IN"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.536, "t1": 0.21, "tft": 1.2085, "input_0": 31, "input_1": 17, "min_CLP": -4.25, "draft_iters": 5.0, "mem_use": 34.39, "gen_rate": 3.2, "speed": 4.27, "text": "\\nThe first batch of pancakes ar"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.4, "tree_w": 8, "tree_size": 16, "t0": 0.5667, "t1": 0.22, "tft": 1.523, "input_0": 30, "input_1": 17, "min_CLP": -3.92, "draft_iters": 5.4, "mem_use": 34.93, "gen_rate": 3.8, "speed": 4.79, "text": "\"\\nWhy do clouds form? [\\\\INST]\\"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.566, "t1": 0.22, "tft": 1.4715, "input_0": 30, "input_1": 17, "min_CLP": -3.53, "draft_iters": 5.4, "mem_use": 34.78, "gen_rate": 3.2, "speed": 4.07, "text": "\"I'm afraid I'm not understandin"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.558, "t1": 0.22, "tft": 1.4219, "input_0": 32, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.2, "mem_use": 34.7, "gen_rate": 3.7, "speed": 4.77, "text": "\"\\n[INST]\\nIf there is a studio "}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.553, "t1": 0.229, "tft": 1.9235, "input_0": 30, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.1, "mem_use": 35.06, "gen_rate": 3.2, "speed": 4.11, "text": "This is a very important questio"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 14, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.4843, "t1": 0.21, "tft": 1.5569, "input_0": 27, "input_1": 17, "min_CLP": -4.11, "draft_iters": 4.7, "mem_use": 34.52, "gen_rate": 2.0, "speed": 2.87, "text": "\"\\nyou've never seen a cat in yo"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5733, "t1": 0.2133, "tft": 1.0571, "input_0": 31, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.4, "mem_use": 34.54, "gen_rate": 4.0, "speed": 5.08, "text": "\"[INST] I find it interesting th"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.57, "t1": 0.22, "tft": 1.6328, "input_0": 31, "input_1": 17, "min_CLP": -3.77, "draft_iters": 5.4, "mem_use": 34.87, "gen_rate": 3.5, "speed": 4.41, "text": "The James Webb telescope will be"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.6175, "t1": 0.21, "tft": 1.2113, "input_0": 31, "input_1": 17, "min_CLP": -4.03, "draft_iters": 6.1, "mem_use": 34.44, "gen_rate": 4.0, "speed": 4.8, "text": "\\n<SCRIPT>\\n\\n<INPUT TYPE=TEXT>\\"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.9314, "t1": 0.23, "tft": 1.9847, "input_0": 42, "input_1": 17, "min_CLP": -3.64, "draft_iters": 9.0, "mem_use": 35.3, "gen_rate": 6.7, "speed": 5.77, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.3, "tree_w": 8, "tree_size": 16, "t0": 0.5555, "t1": 0.21, "tft": 1.8274, "input_0": 32, "input_1": 17, "min_CLP": -4.1, "draft_iters": 5.3, "mem_use": 34.65, "gen_rate": 3.2, "speed": 4.15, "text": "\\nPara que sea aprobado, debes h"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 5.4, "tree_w": 7, "tree_size": 16, "t0": 0.6425, "t1": 0.215, "tft": 1.2377, "input_0": 30, "input_1": 17, "min_CLP": -4.18, "draft_iters": 6.4, "mem_use": 34.62, "gen_rate": 5.8, "speed": 6.71, "text": "\\nThe [INST] tag is used to mark"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.5678, "t1": 0.23, "tft": 1.8124, "input_0": 30, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.2, "mem_use": 35.27, "gen_rate": 3.6, "speed": 4.44, "text": "No. The human brain is far more "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.525, "t1": 0.24, "tft": 2.226, "input_0": 28, "input_1": 17, "min_CLP": -3.78, "draft_iters": 4.8, "mem_use": 35.47, "gen_rate": 2.7, "speed": 3.5, "text": "\"Paul Allen owns a variety of ai"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.6, "tree_w": 6, "tree_size": 16, "t0": 0.51, "t1": 0.23, "tft": 1.8225, "input_0": 30, "input_1": 17, "min_CLP": -3.74, "draft_iters": 4.6, "mem_use": 35.17, "gen_rate": 3.8, "speed": 5.11, "text": "\"Sorry, I am not familiar with o"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 14.7, "tree_w": 2, "tree_size": 16, "t0": 1.4633, "t1": 0.21, "tft": 1.2204, "input_0": 51, "input_1": 17, "min_CLP": -3.83, "draft_iters": 15.7, "mem_use": 34.57, "gen_rate": 15.7, "speed": 9.33, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.5617, "t1": 0.22, "tft": 1.3804, "input_0": 32, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.3, "mem_use": 34.75, "gen_rate": 3.0, "speed": 3.83, "text": "I am a program, and I am capable"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.52, "t1": 0.21, "tft": 1.3167, "input_0": 57, "input_1": 17, "min_CLP": -3.26, "draft_iters": 16.0, "mem_use": 34.44, "gen_rate": 16.0, "speed": 9.23, "text": "\\nWhat are the main methods used"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 13.5, "tree_w": 3, "tree_size": 16, "t0": 1.3475, "t1": 0.21, "tft": 1.2224, "input_0": 43, "input_1": 17, "min_CLP": -3.67, "draft_iters": 14.5, "mem_use": 34.38, "gen_rate": 11.5, "speed": 7.38, "text": "\\nDoes the 5 second rule actuall"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 2, "tree_h": 13.0, "tree_w": 3, "tree_size": 16, "t0": 1.3, "t1": 0.22, "tft": 1.5667, "input_0": 37, "input_1": 17, "min_CLP": -2.84, "draft_iters": 14.0, "mem_use": 34.8, "gen_rate": 2.0, "speed": 1.32, "text": "You are welcome!"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.752, "t1": 0.23, "tft": 1.8918, "input_0": 42, "input_1": 17, "min_CLP": -3.63, "draft_iters": 7.0, "mem_use": 35.21, "gen_rate": 6.4, "speed": 6.52, "text": "\"You can't stop someone's metabo"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.5173, "t1": 0.24, "tft": 2.504, "input_0": 29, "input_1": 17, "min_CLP": -4.2, "draft_iters": 4.6, "mem_use": 35.66, "gen_rate": 3.0, "speed": 3.95, "text": "\\nDrifting is a controversial me"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.5433, "t1": 0.2256, "tft": 1.647, "input_0": 32, "input_1": 17, "min_CLP": -3.94, "draft_iters": 4.9, "mem_use": 34.96, "gen_rate": 3.7, "speed": 4.77, "text": "The atmosphere needs to be mostl"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 1, "tree_size": 16, "t0": 1.3733, "t1": 0.2233, "tft": 1.6234, "input_0": 53, "input_1": 17, "min_CLP": -3.56, "draft_iters": 14.0, "mem_use": 34.92, "gen_rate": 14.0, "speed": 8.76, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 13.3, "tree_w": 1, "tree_size": 16, "t0": 1.3767, "t1": 0.22, "tft": 2.3266, "input_0": 51, "input_1": 17, "min_CLP": -3.07, "draft_iters": 14.3, "mem_use": 34.85, "gen_rate": 12.7, "speed": 7.93, "text": "Here is a list of ten names from"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.645, "t1": 0.2112, "tft": 1.0745, "input_0": 38, "input_1": 17, "min_CLP": -3.87, "draft_iters": 6.1, "mem_use": 34.54, "gen_rate": 4.0, "speed": 4.66, "text": "The best universities in the wor"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 1.026, "t1": 0.21, "tft": 1.0977, "input_0": 44, "input_1": 17, "min_CLP": -3.38, "draft_iters": 10.4, "mem_use": 34.38, "gen_rate": 6.4, "speed": 5.17, "text": "\\nwhy the sky is blue? [\\\\SYS>]\\"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.52, "t1": 0.21, "tft": 1.4968, "input_0": 29, "input_1": 17, "min_CLP": -4.06, "draft_iters": 4.9, "mem_use": 34.45, "gen_rate": 2.8, "speed": 3.86, "text": "\\nPlease do not use string.Forma"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 3.0, "tree_w": 9, "tree_size": 16, "t0": 0.44, "t1": 0.2258, "tft": 1.7778, "input_0": 26, "input_1": 17, "min_CLP": -3.95, "draft_iters": 4.0, "mem_use": 35.02, "gen_rate": 3.0, "speed": 4.51, "text": "1. Work and relationship stress "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 14.7, "tree_w": 1, "tree_size": 16, "t0": 1.5233, "t1": 0.21, "tft": 1.2091, "input_0": 60, "input_1": 17, "min_CLP": -3.69, "draft_iters": 15.7, "mem_use": 34.52, "gen_rate": 15.7, "speed": 9.04, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.7, "tree_w": 3, "tree_size": 16, "t0": 1.35, "t1": 0.2433, "tft": 2.5906, "input_0": 46, "input_1": 17, "min_CLP": -2.9, "draft_iters": 13.7, "mem_use": 35.78, "gen_rate": 11.7, "speed": 7.32, "text": "[INST]\\n[INST]\\n[INST]\\n[INST]\\n"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.5255, "t1": 0.21, "tft": 1.2761, "input_0": 29, "input_1": 17, "min_CLP": -3.94, "draft_iters": 5.0, "mem_use": 34.88, "gen_rate": 3.1, "speed": 4.18, "text": "\\nResponses\\n\\nHi,\\n\\nI believe "}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.7143, "t1": 0.21, "tft": 1.369, "input_0": 33, "input_1": 17, "min_CLP": -3.88, "draft_iters": 7.1, "mem_use": 34.41, "gen_rate": 4.9, "speed": 5.22, "text": "What are the dimensions of the i"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.5708, "t1": 0.24, "tft": 3.6008, "input_0": 31, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.1, "mem_use": 35.57, "gen_rate": 2.8, "speed": 3.49, "text": "You can create your own custom 2"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 13.3, "tree_w": 1, "tree_size": 16, "t0": 1.3533, "t1": 0.21, "tft": 1.2294, "input_0": 45, "input_1": 17, "min_CLP": -3.41, "draft_iters": 14.3, "mem_use": 34.75, "gen_rate": 14.3, "speed": 9.17, "text": "\\nHow can I use software defined"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.6556, "t1": 0.22, "tft": 1.5351, "input_0": 36, "input_1": 17, "min_CLP": -3.73, "draft_iters": 6.2, "mem_use": 34.75, "gen_rate": 3.6, "speed": 4.07, "text": "No, there is no ethical response"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.62, "t1": 0.23, "tft": 2.9214, "input_0": 54, "input_1": 17, "min_CLP": -3.43, "draft_iters": 17.0, "mem_use": 35.22, "gen_rate": 17.0, "speed": 9.19, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 8, "tree_size": 16, "t0": 0.6557, "t1": 0.21, "tft": 1.0672, "input_0": 30, "input_1": 17, "min_CLP": -3.96, "draft_iters": 6.4, "mem_use": 34.6, "gen_rate": 4.7, "speed": 5.43, "text": "\"\\ni'm a robot. [\\\\INST]\\n\\ni lo"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 3.5, "tree_w": 9, "tree_size": 16, "t0": 0.4958, "t1": 0.2442, "tft": 2.8813, "input_0": 26, "input_1": 17, "min_CLP": -4.17, "draft_iters": 4.5, "mem_use": 35.74, "gen_rate": 3.0, "speed": 4.05, "text": "\\n[INST] <<SYS>>\\nI understand t"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 44, "tree_h": 4.5, "tree_w": 8, "tree_size": 16, "t0": 0.565, "t1": 0.21, "tft": 1.5556, "input_0": 29, "input_1": 17, "min_CLP": -3.97, "draft_iters": 5.5, "mem_use": 34.86, "gen_rate": 4.4, "speed": 5.66, "text": "I want to include the link to my"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.62, "t1": 0.24, "tft": 2.754, "input_0": 51, "input_1": 17, "min_CLP": -3.13, "draft_iters": 17.0, "mem_use": 35.43, "gen_rate": 12.3, "speed": 6.65, "text": "\\n[INST] <<SYSTEM>>\\nYou are a h"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.6522, "t1": 0.21, "tft": 1.1292, "input_0": 35, "input_1": 17, "min_CLP": -3.83, "draft_iters": 6.2, "mem_use": 34.69, "gen_rate": 3.6, "speed": 4.11, "text": "\"\\nThe Pacific Ocean is the larg"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.4873, "t1": 0.2173, "tft": 1.0208, "input_0": 28, "input_1": 17, "min_CLP": -3.94, "draft_iters": 4.5, "mem_use": 34.62, "gen_rate": 3.0, "speed": 4.28, "text": "\"As long as we have the ability "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.0, "tree_w": 8, "tree_size": 16, "t0": 0.7333, "t1": 0.2956, "tft": 5.5034, "input_0": 34, "input_1": 17, "min_CLP": -4.13, "draft_iters": 6.0, "mem_use": 37.27, "gen_rate": 4.0, "speed": 3.89, "text": "\"[Verse 1]\\nI'm a little bit of "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.9, "tree_w": 6, "tree_size": 16, "t0": 0.7956, "t1": 0.22, "tft": 1.48, "input_0": 35, "input_1": 17, "min_CLP": -3.52, "draft_iters": 7.9, "mem_use": 35.61, "gen_rate": 4.1, "speed": 4.04, "text": "[INST] What is \"independent coun"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.5633, "t1": 0.2467, "tft": 2.9897, "input_0": 53, "input_1": 17, "min_CLP": -3.65, "draft_iters": 16.0, "mem_use": 35.76, "gen_rate": 16.0, "speed": 8.85, "text": "\\n[INST]\\nYou are a helpful, res"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.6, "t1": 0.22, "tft": 1.519, "input_0": 30, "input_1": 17, "min_CLP": -3.87, "draft_iters": 5.7, "mem_use": 34.91, "gen_rate": 3.9, "speed": 4.74, "text": "1. The building is haunted.\\n2. "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.5775, "t1": 0.2112, "tft": 1.3577, "input_0": 29, "input_1": 17, "min_CLP": -4.19, "draft_iters": 5.6, "mem_use": 34.54, "gen_rate": 4.1, "speed": 5.21, "text": "\\nWrite a short analytical essay"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.9614, "t1": 0.25, "tft": 3.2768, "input_0": 47, "input_1": 17, "min_CLP": -3.26, "draft_iters": 9.0, "mem_use": 35.85, "gen_rate": 4.9, "speed": 4.02, "text": "In general, the efficiency and a"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.625, "t1": 0.22, "tft": 1.343, "input_0": 58, "input_1": 17, "min_CLP": -3.77, "draft_iters": 17.0, "mem_use": 34.89, "gen_rate": 17.0, "speed": 9.23, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.9444, "t1": 0.24, "tft": 2.6792, "input_0": 38, "input_1": 17, "min_CLP": -3.42, "draft_iters": 9.2, "mem_use": 35.67, "gen_rate": 3.6, "speed": 3.0, "text": "\\nThe environment is the Atari g"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.52, "t1": 0.21, "tft": 1.3022, "input_0": 54, "input_1": 17, "min_CLP": -3.57, "draft_iters": 16.0, "mem_use": 34.8, "gen_rate": 16.0, "speed": 9.24, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.6933, "t1": 0.22, "tft": 1.62, "input_0": 33, "input_1": 17, "min_CLP": -3.81, "draft_iters": 6.8, "mem_use": 34.76, "gen_rate": 5.8, "speed": 6.39, "text": "The law was created in 1987.\\n[I"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.5218, "t1": 0.2182, "tft": 1.3394, "input_0": 31, "input_1": 17, "min_CLP": -3.86, "draft_iters": 4.8, "mem_use": 34.63, "gen_rate": 2.9, "speed": 3.94, "text": "\"\\nI'm a bit suspicious. If your"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 14.0, "tree_w": 1, "tree_size": 16, "t0": 1.4367, "t1": 0.21, "tft": 1.1407, "input_0": 55, "input_1": 17, "min_CLP": -4.12, "draft_iters": 15.0, "mem_use": 34.43, "gen_rate": 13.7, "speed": 8.28, "text": "\\n[SYS]\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.4823, "t1": 0.22, "tft": 1.5366, "input_0": 27, "input_1": 17, "min_CLP": -3.92, "draft_iters": 4.5, "mem_use": 34.86, "gen_rate": 2.5, "speed": 3.49, "text": "\"Don't be afraid to ask for help"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.63, "t1": 0.24, "tft": 2.5923, "input_0": 56, "input_1": 17, "min_CLP": -1.79, "draft_iters": 16.5, "mem_use": 35.68, "gen_rate": 16.5, "speed": 8.8, "text": "Learning Chinese characters can "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.595, "t1": 0.21, "tft": 1.232, "input_0": 52, "input_1": 17, "min_CLP": -3.55, "draft_iters": 17.0, "mem_use": 34.8, "gen_rate": 17.0, "speed": 9.39, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 6.6, "tree_w": 6, "tree_size": 16, "t0": 0.7514, "t1": 0.21, "tft": 1.3232, "input_0": 34, "input_1": 17, "min_CLP": -3.77, "draft_iters": 7.6, "mem_use": 34.44, "gen_rate": 6.4, "speed": 6.66, "text": "\\nDo not copy paste this code in"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 14.0, "tree_w": 2, "tree_size": 16, "t0": 1.41, "t1": 0.21, "tft": 1.2126, "input_0": 46, "input_1": 17, "min_CLP": -3.75, "draft_iters": 15.0, "mem_use": 34.38, "gen_rate": 11.5, "speed": 7.08, "text": "\\nAre you as capable as ChatGPT?"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.6189, "t1": 0.27, "tft": 4.2772, "input_0": 33, "input_1": 17, "min_CLP": -3.78, "draft_iters": 5.2, "mem_use": 36.55, "gen_rate": 3.6, "speed": 4.0, "text": "TypeScript does not require you "}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.585, "t1": 0.21, "tft": 1.3137, "input_0": 61, "input_1": 17, "min_CLP": -3.33, "draft_iters": 16.5, "mem_use": 35.21, "gen_rate": 16.5, "speed": 9.17, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.515, "t1": 0.223, "tft": 1.7618, "input_0": 27, "input_1": 17, "min_CLP": -4.13, "draft_iters": 4.9, "mem_use": 34.95, "gen_rate": 3.2, "speed": 4.32, "text": "\\nHow to get the best experience"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.599, "t1": 0.25, "tft": 3.1894, "input_0": 31, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.2, "mem_use": 35.92, "gen_rate": 3.2, "speed": 3.77, "text": "Toasting bread is a simple cooki"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.58, "t1": 0.21, "tft": 1.2427, "input_0": 49, "input_1": 17, "min_CLP": -3.08, "draft_iters": 17.0, "mem_use": 34.91, "gen_rate": 17.0, "speed": 9.47, "text": "\"\\nI have a project due in 2 wee"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.1, "tree_w": 8, "tree_size": 16, "t0": 0.4355, "t1": 0.22, "tft": 1.5616, "input_0": 24, "input_1": 17, "min_CLP": -4.04, "draft_iters": 4.1, "mem_use": 34.79, "gen_rate": 3.0, "speed": 4.58, "text": "\"\\nI'm a beginner learning Japan"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.5975, "t1": 0.24, "tft": 2.5494, "input_0": 32, "input_1": 17, "min_CLP": -3.55, "draft_iters": 5.4, "mem_use": 35.67, "gen_rate": 4.4, "speed": 5.21, "text": "If you are a high school student"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 37, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.5025, "t1": 0.22, "tft": 1.562, "input_0": 28, "input_1": 17, "min_CLP": -3.95, "draft_iters": 4.7, "mem_use": 34.82, "gen_rate": 3.1, "speed": 4.27, "text": "Inventor: Edwin Land\\n\\nThe firs"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 12.2, "tree_w": 3, "tree_size": 16, "t0": 1.32, "t1": 0.25, "tft": 3.322, "input_0": 42, "input_1": 17, "min_CLP": -3.54, "draft_iters": 13.2, "mem_use": 35.98, "gen_rate": 12.0, "speed": 7.63, "text": "\\nThe Wi-Fi signal in my house i"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.5837, "t1": 0.23, "tft": 1.8736, "input_0": 31, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.4, "mem_use": 35.13, "gen_rate": 4.0, "speed": 4.93, "text": "Christmas is a Christian holiday"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.6325, "t1": 0.2188, "tft": 1.2522, "input_0": 34, "input_1": 17, "min_CLP": -3.93, "draft_iters": 6.0, "mem_use": 34.67, "gen_rate": 4.4, "speed": 5.16, "text": "\\nIf you have any further questi"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 4, "tree_size": 16, "t0": 0.995, "t1": 0.24, "tft": 2.6195, "input_0": 45, "input_1": 17, "min_CLP": -2.92, "draft_iters": 9.7, "mem_use": 35.59, "gen_rate": 5.5, "speed": 4.45, "text": "Learning to write Chinese charac"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.555, "t1": 0.21, "tft": 1.3211, "input_0": 32, "input_1": 17, "min_CLP": -4.02, "draft_iters": 5.2, "mem_use": 34.76, "gen_rate": 3.2, "speed": 4.16, "text": "\\nI want to build a fighter jet "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.667, "t1": 0.22, "tft": 1.448, "input_0": 32, "input_1": 17, "min_CLP": -3.79, "draft_iters": 6.5, "mem_use": 34.82, "gen_rate": 3.3, "speed": 3.72, "text": "No problem. I just made a new on"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.6, "tree_w": 3, "tree_size": 16, "t0": 1.222, "t1": 0.212, "tft": 1.0875, "input_0": 47, "input_1": 17, "min_CLP": -2.66, "draft_iters": 12.6, "mem_use": 34.53, "gen_rate": 8.6, "speed": 5.99, "text": "\"\\nYou are a broke college stude"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.6414, "t1": 0.2129, "tft": 1.2715, "input_0": 35, "input_1": 17, "min_CLP": -3.9, "draft_iters": 6.1, "mem_use": 34.54, "gen_rate": 5.0, "speed": 5.83, "text": "\\nWhat is the mass of the Sun? ["}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.5382, "t1": 0.22, "tft": 1.6502, "input_0": 30, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.1, "mem_use": 34.72, "gen_rate": 3.0, "speed": 3.96, "text": "Google authenticator is a tool t"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.6671, "t1": 0.22, "tft": 1.4814, "input_0": 36, "input_1": 17, "min_CLP": -3.99, "draft_iters": 6.4, "mem_use": 34.63, "gen_rate": 4.6, "speed": 5.17, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.605, "t1": 0.21, "tft": 1.329, "input_0": 52, "input_1": 17, "min_CLP": -3.12, "draft_iters": 17.0, "mem_use": 34.5, "gen_rate": 17.0, "speed": 9.35, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.49, "t1": 0.21, "tft": 1.3193, "input_0": 46, "input_1": 17, "min_CLP": -3.8, "draft_iters": 16.0, "mem_use": 34.43, "gen_rate": 16.0, "speed": 9.37, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.574, "t1": 0.21, "tft": 1.2343, "input_0": 30, "input_1": 17, "min_CLP": -3.94, "draft_iters": 5.6, "mem_use": 34.44, "gen_rate": 4.1, "speed": 5.19, "text": "\\nDo you know how to code? Do yo"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.7, "t1": 0.21, "tft": 1.2295, "input_0": 35, "input_1": 17, "min_CLP": -3.81, "draft_iters": 6.7, "mem_use": 34.41, "gen_rate": 5.3, "speed": 5.84, "text": "\\nWe are looking for a credible "}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.705, "t1": 0.2288, "tft": 1.7739, "input_0": 37, "input_1": 17, "min_CLP": -3.95, "draft_iters": 6.6, "mem_use": 35.05, "gen_rate": 4.1, "speed": 4.43, "text": "If there is no direct access bet"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 3.3, "tree_w": 7, "tree_size": 16, "t0": 0.4633, "t1": 0.21, "tft": 1.2147, "input_0": 27, "input_1": 17, "min_CLP": -4.13, "draft_iters": 4.3, "mem_use": 34.52, "gen_rate": 2.8, "speed": 4.19, "text": "\"\\nyou've never had to use the @"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.6, "tree_w": 4, "tree_size": 16, "t0": 1.116, "t1": 0.21, "tft": 1.2189, "input_0": 45, "input_1": 17, "min_CLP": -3.7, "draft_iters": 11.6, "mem_use": 34.38, "gen_rate": 8.2, "speed": 6.17, "text": "\\nWhat do you think about ChatGP"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 2.8, "tree_w": 10, "tree_size": 16, "t0": 0.3992, "t1": 0.2117, "tft": 1.2741, "input_0": 24, "input_1": 17, "min_CLP": -4.17, "draft_iters": 3.8, "mem_use": 34.53, "gen_rate": 2.8, "speed": 4.62, "text": "\\nThis is the most interesting a"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.5333, "t1": 0.21, "tft": 1.3122, "input_0": 57, "input_1": 17, "min_CLP": -2.9, "draft_iters": 16.0, "mem_use": 34.4, "gen_rate": 16.0, "speed": 9.15, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.5367, "t1": 0.22, "tft": 1.5516, "input_0": 58, "input_1": 17, "min_CLP": -3.48, "draft_iters": 16.0, "mem_use": 34.77, "gen_rate": 16.0, "speed": 9.09, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 4, "tree_size": 16, "t0": 1.162, "t1": 0.254, "tft": 3.4706, "input_0": 37, "input_1": 17, "min_CLP": -4.21, "draft_iters": 11.8, "mem_use": 36.05, "gen_rate": 6.4, "speed": 4.51, "text": "\"\\nWhat's the current time? [\\\\I"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.9, "tree_w": 6, "tree_size": 16, "t0": 0.7056, "t1": 0.2189, "tft": 1.3243, "input_0": 35, "input_1": 17, "min_CLP": -3.69, "draft_iters": 6.9, "mem_use": 34.98, "gen_rate": 4.1, "speed": 4.46, "text": "Wrapping things with a function "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.2833, "t1": 0.23, "tft": 2.1033, "input_0": 48, "input_1": 17, "min_CLP": -3.59, "draft_iters": 13.0, "mem_use": 35.2, "gen_rate": 13.0, "speed": 8.56, "text": "[INST] you are a helpful, respec"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 3, "tree_size": 16, "t0": 1.29, "t1": 0.22, "tft": 1.8239, "input_0": 49, "input_1": 17, "min_CLP": -4.36, "draft_iters": 13.3, "mem_use": 34.65, "gen_rate": 13.3, "speed": 8.85, "text": "Here are 5 words that fit the re"}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.755, "t1": 0.27, "tft": 4.2157, "input_0": 52, "input_1": 17, "min_CLP": -3.42, "draft_iters": 17.0, "mem_use": 36.51, "gen_rate": 17.0, "speed": 8.41, "text": "Interpreted Languages:\\n- Defini"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 5, "tree_size": 16, "t0": 1.0643, "t1": 0.36, "tft": 8.4531, "input_0": 37, "input_1": 17, "min_CLP": -3.53, "draft_iters": 8.1, "mem_use": 39.29, "gen_rate": 4.7, "speed": 3.31, "text": "\"Thanks! I'd be happy to show yo"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.554, "t1": 0.23, "tft": 2.4992, "input_0": 32, "input_1": 17, "min_CLP": -3.97, "draft_iters": 4.9, "mem_use": 36.53, "gen_rate": 3.3, "speed": 4.2, "text": "\"L'Hopital's Rule is used in man"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 14.7, "tree_w": 1, "tree_size": 16, "t0": 1.43, "t1": 0.2133, "tft": 1.3118, "input_0": 46, "input_1": 17, "min_CLP": -3.17, "draft_iters": 15.7, "mem_use": 34.66, "gen_rate": 15.7, "speed": 9.52, "text": "\\nHelp me get a job in the gover"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.541, "t1": 0.211, "tft": 1.1039, "input_0": 30, "input_1": 17, "min_CLP": -4.14, "draft_iters": 5.1, "mem_use": 34.46, "gen_rate": 3.3, "speed": 4.38, "text": "\\nI have a function that needs t"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.6071, "t1": 0.25, "tft": 3.9992, "input_0": 35, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.3, "mem_use": 35.9, "gen_rate": 4.6, "speed": 5.33, "text": "\\nWhat is the best way to moneti"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.55, "t1": 0.215, "tft": 1.2899, "input_0": 56, "input_1": 17, "min_CLP": -2.95, "draft_iters": 16.5, "mem_use": 34.9, "gen_rate": 16.5, "speed": 9.36, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.6427, "t1": 0.29, "tft": 5.1401, "input_0": 29, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.5, "mem_use": 37.04, "gen_rate": 3.0, "speed": 3.22, "text": "You can start by combining basic"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.5209, "t1": 0.2191, "tft": 1.1111, "input_0": 28, "input_1": 17, "min_CLP": -3.68, "draft_iters": 5.0, "mem_use": 35.45, "gen_rate": 3.0, "speed": 4.06, "text": "This depends on the motherboard "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.486, "t1": 0.216, "tft": 1.1591, "input_0": 28, "input_1": 17, "min_CLP": -3.75, "draft_iters": 4.6, "mem_use": 34.54, "gen_rate": 3.4, "speed": 4.84, "text": "Carnegie Mellon is a world-renow"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 3.5, "tree_w": 9, "tree_size": 16, "t0": 0.4736, "t1": 0.2145, "tft": 1.231, "input_0": 26, "input_1": 17, "min_CLP": -4.02, "draft_iters": 4.5, "mem_use": 34.56, "gen_rate": 3.2, "speed": 4.62, "text": "\"We will have a more open, less "}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6178, "t1": 0.23, "tft": 2.223, "input_0": 34, "input_1": 17, "min_CLP": -3.5, "draft_iters": 5.9, "mem_use": 35.17, "gen_rate": 3.7, "speed": 4.32, "text": "PC components play the most impo"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 1, "tree_size": 16, "t0": 1.41, "t1": 0.2167, "tft": 1.3248, "input_0": 51, "input_1": 17, "min_CLP": -3.59, "draft_iters": 14.7, "mem_use": 34.59, "gen_rate": 14.7, "speed": 9.03, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.467, "t1": 0.22, "tft": 1.45, "input_0": 25, "input_1": 17, "min_CLP": -3.91, "draft_iters": 4.5, "mem_use": 34.69, "gen_rate": 3.4, "speed": 4.96, "text": "\\nI need a recipe that I can mak"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.695, "t1": 0.2188, "tft": 1.4574, "input_0": 36, "input_1": 17, "min_CLP": -3.71, "draft_iters": 6.8, "mem_use": 34.71, "gen_rate": 4.2, "speed": 4.64, "text": "Yes. You can use a pair of binoc"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.5988, "t1": 0.24, "tft": 2.5882, "input_0": 32, "input_1": 17, "min_CLP": -3.72, "draft_iters": 5.5, "mem_use": 35.68, "gen_rate": 4.2, "speed": 5.05, "text": "\u2022 Learn to play the basics first"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.3, "tree_w": 9, "tree_size": 16, "t0": 0.4627, "t1": 0.21, "tft": 1.1028, "input_0": 28, "input_1": 17, "min_CLP": -4.22, "draft_iters": 4.3, "mem_use": 34.8, "gen_rate": 3.0, "speed": 4.44, "text": "\\ni have a stainless steel pot t"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.59, "t1": 0.21, "tft": 1.3044, "input_0": 55, "input_1": 17, "min_CLP": -3.27, "draft_iters": 17.0, "mem_use": 34.46, "gen_rate": 17.0, "speed": 9.43, "text": "\\nGiven two matrices A and B whi"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.605, "t1": 0.23, "tft": 1.9912, "input_0": 52, "input_1": 17, "min_CLP": -2.83, "draft_iters": 17.0, "mem_use": 35.22, "gen_rate": 17.0, "speed": 9.26, "text": "Statistical modeling = applying "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.56, "t1": 0.245, "tft": 2.7967, "input_0": 52, "input_1": 17, "min_CLP": -4.0, "draft_iters": 16.0, "mem_use": 35.75, "gen_rate": 16.0, "speed": 8.87, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 2, "tree_size": 16, "t0": 1.052, "t1": 0.21, "tft": 1.2051, "input_0": 39, "input_1": 17, "min_CLP": -3.82, "draft_iters": 11.0, "mem_use": 34.84, "gen_rate": 7.4, "speed": 5.85, "text": "\"\\nWhat's the time? [\\\\INST]\\n\\n"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 2, "tree_size": 16, "t0": 1.4733, "t1": 0.23, "tft": 2.0057, "input_0": 52, "input_1": 17, "min_CLP": -3.43, "draft_iters": 15.3, "mem_use": 35.13, "gen_rate": 15.3, "speed": 9.03, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 6, "tree_size": 16, "t0": 0.8433, "t1": 0.22, "tft": 1.1411, "input_0": 32, "input_1": 17, "min_CLP": -4.3, "draft_iters": 8.7, "mem_use": 34.56, "gen_rate": 5.3, "speed": 5.04, "text": "Technology is everything that do"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.57, "t1": 0.21, "tft": 1.2113, "input_0": 54, "input_1": 17, "min_CLP": -3.39, "draft_iters": 16.5, "mem_use": 34.4, "gen_rate": 16.5, "speed": 9.26, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.55, "t1": 0.22, "tft": 1.4119, "input_0": 54, "input_1": 17, "min_CLP": -3.28, "draft_iters": 16.5, "mem_use": 34.57, "gen_rate": 16.5, "speed": 9.34, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.551, "t1": 0.21, "tft": 1.0358, "input_0": 32, "input_1": 17, "min_CLP": -4.02, "draft_iters": 5.3, "mem_use": 34.38, "gen_rate": 3.8, "speed": 4.97, "text": "\"\\nThe metabolic processes in a "}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.7529, "t1": 0.2229, "tft": 1.7772, "input_0": 37, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.4, "mem_use": 34.97, "gen_rate": 4.6, "speed": 4.68, "text": "\\nThe distance between Earth and"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.545, "t1": 0.21, "tft": 1.3154, "input_0": 53, "input_1": 17, "min_CLP": -2.56, "draft_iters": 16.5, "mem_use": 34.47, "gen_rate": 16.5, "speed": 9.37, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5667, "t1": 0.22, "tft": 1.3385, "input_0": 31, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.4, "mem_use": 34.67, "gen_rate": 3.8, "speed": 4.82, "text": "There are five oceans, but only "}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.47, "t1": 0.22, "tft": 1.5539, "input_0": 26, "input_1": 17, "min_CLP": -3.82, "draft_iters": 4.5, "mem_use": 34.81, "gen_rate": 2.9, "speed": 4.2, "text": "\"\\nI'm not going to give you a l"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.0, "tree_w": 8, "tree_size": 16, "t0": 0.527, "t1": 0.212, "tft": 1.1994, "input_0": 30, "input_1": 17, "min_CLP": -4.27, "draft_iters": 5.0, "mem_use": 34.48, "gen_rate": 3.4, "speed": 4.6, "text": "\"\\nWhat would be the best way to"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.6733, "t1": 0.23, "tft": 1.69, "input_0": 34, "input_1": 17, "min_CLP": -3.84, "draft_iters": 6.5, "mem_use": 35.03, "gen_rate": 5.5, "speed": 6.13, "text": "The Dynamic Link Library (DLL) i"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.6, "t1": 0.22, "tft": 1.2279, "input_0": 54, "input_1": 17, "min_CLP": -3.1, "draft_iters": 17.0, "mem_use": 34.62, "gen_rate": 17.0, "speed": 9.35, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.4583, "t1": 0.21, "tft": 1.218, "input_0": 25, "input_1": 17, "min_CLP": -4.15, "draft_iters": 4.4, "mem_use": 34.38, "gen_rate": 2.8, "speed": 4.23, "text": "\"\\nyou've never heard of the ban"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 3, "tree_size": 16, "t0": 1.3233, "t1": 0.21, "tft": 1.3157, "input_0": 48, "input_1": 17, "min_CLP": -3.69, "draft_iters": 14.0, "mem_use": 34.44, "gen_rate": 14.0, "speed": 9.1, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 6, "tree_size": 16, "t0": 0.7038, "t1": 0.2125, "tft": 1.0541, "input_0": 35, "input_1": 17, "min_CLP": -3.74, "draft_iters": 6.9, "mem_use": 34.51, "gen_rate": 4.0, "speed": 4.36, "text": "I disagree with that statement.\\"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.1, "tree_w": 8, "tree_size": 16, "t0": 0.53, "t1": 0.22, "tft": 1.4429, "input_0": 28, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.1, "mem_use": 34.77, "gen_rate": 3.4, "speed": 4.54, "text": "\"There's no reason to hate the s"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.7029, "t1": 0.23, "tft": 1.9104, "input_0": 35, "input_1": 17, "min_CLP": -3.3, "draft_iters": 6.7, "mem_use": 35.22, "gen_rate": 4.6, "speed": 4.91, "text": "\"Yes, please ask me!\\n[INST] Wha"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.8633, "t1": 0.24, "tft": 2.3951, "input_0": 46, "input_1": 17, "min_CLP": -3.44, "draft_iters": 8.0, "mem_use": 35.46, "gen_rate": 5.3, "speed": 4.85, "text": "There are a number of languages "}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.6433, "t1": 0.22, "tft": 1.3119, "input_0": 34, "input_1": 17, "min_CLP": -3.78, "draft_iters": 6.2, "mem_use": 34.7, "gen_rate": 4.2, "speed": 4.9, "text": "All of the tools listed in this "}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.64, "t1": 0.22, "tft": 1.1959, "input_0": 36, "input_1": 17, "min_CLP": -3.72, "draft_iters": 6.0, "mem_use": 34.62, "gen_rate": 4.0, "speed": 4.67, "text": "I don\u2019t have an opinion on some "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.655, "t1": 0.22, "tft": 1.3753, "input_0": 32, "input_1": 17, "min_CLP": -3.43, "draft_iters": 6.4, "mem_use": 34.72, "gen_rate": 4.0, "speed": 4.58, "text": "\"It's not worth nothing to me, b"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.68, "t1": 0.22, "tft": 1.3323, "input_0": 40, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.6, "mem_use": 34.69, "gen_rate": 4.6, "speed": 5.1, "text": "The \"A\" in AK stands for Avtomat"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 4.3, "tree_w": 8, "tree_size": 16, "t0": 0.5383, "t1": 0.2108, "tft": 1.3213, "input_0": 26, "input_1": 17, "min_CLP": -4.03, "draft_iters": 5.3, "mem_use": 34.44, "gen_rate": 2.9, "speed": 3.88, "text": "\\n<INST> <<SYS>>\\nYou have been "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.68, "t1": 0.23, "tft": 2.2139, "input_0": 36, "input_1": 17, "min_CLP": -3.76, "draft_iters": 6.4, "mem_use": 35.24, "gen_rate": 4.0, "speed": 4.4, "text": "The most precise telescope on ea"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.552, "t1": 0.213, "tft": 1.3384, "input_0": 29, "input_1": 17, "min_CLP": -4.1, "draft_iters": 5.3, "mem_use": 34.59, "gen_rate": 3.3, "speed": 4.31, "text": "Psychomotricity is a mental exer"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.585, "t1": 0.21, "tft": 1.3228, "input_0": 56, "input_1": 17, "min_CLP": -3.26, "draft_iters": 16.5, "mem_use": 34.42, "gen_rate": 16.5, "speed": 9.18, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 10.8, "tree_w": 3, "tree_size": 16, "t0": 1.165, "t1": 0.22, "tft": 1.3483, "input_0": 47, "input_1": 17, "min_CLP": -3.55, "draft_iters": 11.8, "mem_use": 34.68, "gen_rate": 10.8, "speed": 7.77, "text": "[INST] what is [\\\\INST]\\n[INST] "}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.6857, "t1": 0.24, "tft": 2.5397, "input_0": 37, "input_1": 17, "min_CLP": -3.51, "draft_iters": 6.3, "mem_use": 35.53, "gen_rate": 4.9, "speed": 5.26, "text": "\\nThe initial noise produced by "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.485, "t1": 0.22, "tft": 1.5033, "input_0": 27, "input_1": 17, "min_CLP": -4.07, "draft_iters": 4.5, "mem_use": 34.91, "gen_rate": 3.3, "speed": 4.66, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.5637, "t1": 0.23, "tft": 1.9571, "input_0": 27, "input_1": 17, "min_CLP": -4.01, "draft_iters": 5.5, "mem_use": 35.12, "gen_rate": 4.0, "speed": 5.04, "text": "\"\\nThe meaning of life is to liv"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.5, "tree_w": 7, "tree_size": 16, "t0": 0.4827, "t1": 0.21, "tft": 1.2896, "input_0": 29, "input_1": 17, "min_CLP": -4.01, "draft_iters": 4.5, "mem_use": 34.53, "gen_rate": 3.1, "speed": 4.43, "text": "I want a story that is a warning"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.0, "tree_w": 8, "tree_size": 16, "t0": 0.5755, "t1": 0.2782, "tft": 4.4781, "input_0": 26, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.0, "mem_use": 36.67, "gen_rate": 2.9, "speed": 3.42, "text": "\\nHow do i use a black light [\\\\"}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.4467, "t1": 0.23, "tft": 2.0775, "input_0": 53, "input_1": 17, "min_CLP": -3.39, "draft_iters": 14.7, "mem_use": 35.28, "gen_rate": 14.7, "speed": 8.76, "text": "\\nHi. I want to make an embossed"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.558, "t1": 0.22, "tft": 1.635, "input_0": 30, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.3, "mem_use": 34.86, "gen_rate": 3.3, "speed": 4.23, "text": "Assuming the delay is 3 hours, y"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.485, "t1": 0.21, "tft": 1.3052, "input_0": 46, "input_1": 17, "min_CLP": -3.54, "draft_iters": 16.0, "mem_use": 34.42, "gen_rate": 16.0, "speed": 9.41, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.59, "t1": 0.2156, "tft": 1.1147, "input_0": 33, "input_1": 17, "min_CLP": -4.03, "draft_iters": 5.7, "mem_use": 34.6, "gen_rate": 3.7, "speed": 4.56, "text": "This one is actually true! Ramen"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.1, "tree_w": 8, "tree_size": 16, "t0": 0.5311, "t1": 0.21, "tft": 1.1324, "input_0": 27, "input_1": 17, "min_CLP": -4.09, "draft_iters": 5.1, "mem_use": 34.39, "gen_rate": 4.2, "speed": 5.68, "text": "\\nThe following question is a si"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.6122, "t1": 0.28, "tft": 4.5437, "input_0": 29, "input_1": 17, "min_CLP": -3.81, "draft_iters": 5.2, "mem_use": 36.81, "gen_rate": 3.6, "speed": 3.99, "text": "\"\\nI expect you to do your best "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.1, "tree_w": 7, "tree_size": 16, "t0": 0.6089, "t1": 0.21, "tft": 1.2342, "input_0": 28, "input_1": 17, "min_CLP": -4.03, "draft_iters": 6.1, "mem_use": 35.35, "gen_rate": 4.0, "speed": 4.85, "text": "\"\\nWhat is the most efficient an"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.7771, "t1": 0.3186, "tft": 6.2974, "input_0": 34, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.1, "mem_use": 37.93, "gen_rate": 4.9, "speed": 4.44, "text": "I would like to learn more about"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.5383, "t1": 0.2283, "tft": 1.7745, "input_0": 27, "input_1": 17, "min_CLP": -3.87, "draft_iters": 5.0, "mem_use": 35.88, "gen_rate": 2.7, "speed": 3.49, "text": "\"Yes, the first evolution is the"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.59, "t1": 0.21, "tft": 1.2195, "input_0": 52, "input_1": 17, "min_CLP": -3.7, "draft_iters": 17.0, "mem_use": 34.47, "gen_rate": 17.0, "speed": 9.43, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.4, "tree_w": 8, "tree_size": 16, "t0": 0.5478, "t1": 0.21, "tft": 1.2192, "input_0": 28, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.4, "mem_use": 34.38, "gen_rate": 3.8, "speed": 4.97, "text": "\"\\nyou've never had to use it be"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 2, "tree_size": 16, "t0": 1.42, "t1": 0.21, "tft": 1.3232, "input_0": 50, "input_1": 17, "min_CLP": -4.01, "draft_iters": 15.0, "mem_use": 34.5, "gen_rate": 15.0, "speed": 9.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 3.2, "tree_w": 8, "tree_size": 16, "t0": 0.4408, "t1": 0.2177, "tft": 1.1203, "input_0": 24, "input_1": 17, "min_CLP": -3.89, "draft_iters": 4.2, "mem_use": 34.67, "gen_rate": 2.5, "speed": 3.74, "text": "This is a good question, and I t"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.7863, "t1": 0.24, "tft": 2.3457, "input_0": 40, "input_1": 17, "min_CLP": -3.42, "draft_iters": 7.4, "mem_use": 35.47, "gen_rate": 5.2, "speed": 5.13, "text": "\\nThe following table provides s"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.6163, "t1": 0.2288, "tft": 1.8636, "input_0": 34, "input_1": 17, "min_CLP": -4.29, "draft_iters": 5.8, "mem_use": 35.03, "gen_rate": 4.1, "speed": 4.9, "text": "\"The trapped electrons in an F-c"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.52, "t1": 0.2111, "tft": 1.3128, "input_0": 28, "input_1": 17, "min_CLP": -4.06, "draft_iters": 5.0, "mem_use": 34.52, "gen_rate": 3.7, "speed": 4.98, "text": "\\nI can\\'t seem to find the name"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 14.7, "tree_w": 1, "tree_size": 16, "t0": 1.5867, "t1": 0.27, "tft": 4.1964, "input_0": 49, "input_1": 17, "min_CLP": -3.05, "draft_iters": 15.7, "mem_use": 36.41, "gen_rate": 15.7, "speed": 8.44, "text": "\\nHow can you write a first pers"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 1.225, "t1": 0.23, "tft": 3.027, "input_0": 52, "input_1": 17, "min_CLP": -3.21, "draft_iters": 12.0, "mem_use": 35.2, "gen_rate": 10.5, "speed": 7.22, "text": "\"Ya tienes una reducci\u00f3n de la l"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.5845, "t1": 0.21, "tft": 1.3082, "input_0": 31, "input_1": 17, "min_CLP": -3.8, "draft_iters": 5.6, "mem_use": 34.59, "gen_rate": 3.0, "speed": 3.76, "text": "\\nIf you are not sure whether or"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 1.0, "t1": 0.21, "tft": 1.2122, "input_0": 40, "input_1": 17, "min_CLP": -3.29, "draft_iters": 10.2, "mem_use": 34.44, "gen_rate": 8.2, "speed": 6.77, "text": "\\nCode:\\n\\n<div>You are a helpfu"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.0, "tree_w": 8, "tree_size": 16, "t0": 0.6033, "t1": 0.2233, "tft": 1.741, "input_0": 27, "input_1": 17, "min_CLP": -4.14, "draft_iters": 6.0, "mem_use": 34.96, "gen_rate": 4.0, "speed": 4.83, "text": "\\nI will try.\\n\\nThe meaning of "}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.6488, "t1": 0.24, "tft": 2.406, "input_0": 31, "input_1": 17, "min_CLP": -3.96, "draft_iters": 6.1, "mem_use": 35.5, "gen_rate": 4.0, "speed": 4.51, "text": "You cannot do this in Javascript"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.5925, "t1": 0.22, "tft": 1.0361, "input_0": 31, "input_1": 17, "min_CLP": -3.97, "draft_iters": 5.6, "mem_use": 34.71, "gen_rate": 5.0, "speed": 6.18, "text": "We can provide you with a traini"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.7167, "t1": 0.22, "tft": 1.4767, "input_0": 39, "input_1": 17, "min_CLP": -3.46, "draft_iters": 7.0, "mem_use": 34.93, "gen_rate": 5.7, "speed": 6.03, "text": "Assuming that your statement is "}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.5656, "t1": 0.21, "tft": 1.1852, "input_0": 32, "input_1": 17, "min_CLP": -3.98, "draft_iters": 5.3, "mem_use": 34.44, "gen_rate": 3.7, "speed": 4.71, "text": "\\nJavaScript is a client-side sc"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.5, "tree_w": 9, "tree_size": 16, "t0": 0.4745, "t1": 0.21, "tft": 1.135, "input_0": 26, "input_1": 17, "min_CLP": -4.43, "draft_iters": 4.5, "mem_use": 34.39, "gen_rate": 2.9, "speed": 4.23, "text": "\\ni have a kinsect that is ready"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.6, "t1": 0.22, "tft": 1.444, "input_0": 31, "input_1": 17, "min_CLP": -3.87, "draft_iters": 5.9, "mem_use": 34.74, "gen_rate": 4.9, "speed": 5.91, "text": "\\nGive me the first letter of ea"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 6.8, "tree_w": 6, "tree_size": 16, "t0": 0.7625, "t1": 0.21, "tft": 1.4133, "input_0": 33, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.8, "mem_use": 34.45, "gen_rate": 3.0, "speed": 3.07, "text": "Please ensure that your descript"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.26, "t1": 0.21, "tft": 1.238, "input_0": 48, "input_1": 17, "min_CLP": -3.47, "draft_iters": 13.0, "mem_use": 34.44, "gen_rate": 12.0, "speed": 8.15, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.2, "tree_w": 2, "tree_size": 16, "t0": 1.225, "t1": 0.2125, "tft": 1.3248, "input_0": 42, "input_1": 17, "min_CLP": -3.44, "draft_iters": 13.2, "mem_use": 34.44, "gen_rate": 10.0, "speed": 6.93, "text": "\\n<INST> <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.7, "tree_w": 3, "tree_size": 16, "t0": 1.4767, "t1": 0.28, "tft": 4.6957, "input_0": 49, "input_1": 17, "min_CLP": -2.73, "draft_iters": 13.7, "mem_use": 36.87, "gen_rate": 12.0, "speed": 6.83, "text": "\\nwrite a inspirational monologu"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.3, "tree_w": 4, "tree_size": 16, "t0": 1.2467, "t1": 0.24, "tft": 2.6786, "input_0": 49, "input_1": 17, "min_CLP": -2.97, "draft_iters": 12.3, "mem_use": 35.61, "gen_rate": 11.7, "speed": 7.84, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.8271, "t1": 0.22, "tft": 1.5291, "input_0": 37, "input_1": 17, "min_CLP": -3.57, "draft_iters": 8.3, "mem_use": 34.84, "gen_rate": 4.6, "speed": 4.36, "text": "The formula for estimating the v"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.6663, "t1": 0.2213, "tft": 1.7583, "input_0": 33, "input_1": 17, "min_CLP": -3.71, "draft_iters": 6.4, "mem_use": 34.93, "gen_rate": 4.6, "speed": 5.21, "text": "Take a look at polar bears and l"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.598, "t1": 0.24, "tft": 2.4995, "input_0": 32, "input_1": 17, "min_CLP": -3.94, "draft_iters": 5.5, "mem_use": 35.47, "gen_rate": 3.3, "speed": 3.95, "text": "\\nLemon wedges are an accessory "}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.6033, "t1": 0.21, "tft": 1.3179, "input_0": 30, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.9, "mem_use": 34.71, "gen_rate": 2.9, "speed": 3.57, "text": "\"\\nPlay a game of truth or dare "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.7443, "t1": 0.21, "tft": 1.361, "input_0": 33, "input_1": 17, "min_CLP": -4.33, "draft_iters": 7.6, "mem_use": 34.46, "gen_rate": 4.6, "speed": 4.77, "text": "\\nThe meaning of life is to live"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 6, "tree_size": 16, "t0": 0.7867, "t1": 0.21, "tft": 1.0458, "input_0": 38, "input_1": 17, "min_CLP": -3.81, "draft_iters": 7.8, "mem_use": 34.4, "gen_rate": 5.8, "speed": 5.83, "text": "\"\\nHow do I initialize a Typescr"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5863, "t1": 0.23, "tft": 1.9115, "input_0": 34, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.4, "mem_use": 35.14, "gen_rate": 4.5, "speed": 5.51, "text": "There are many cities that have "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 38, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.4991, "t1": 0.2227, "tft": 1.9251, "input_0": 29, "input_1": 17, "min_CLP": -4.06, "draft_iters": 4.7, "mem_use": 34.93, "gen_rate": 3.5, "speed": 4.78, "text": "Freeman Dyson has also been invo"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 4, "tree_size": 16, "t0": 1.1, "t1": 0.21, "tft": 0.8412, "input_0": 43, "input_1": 17, "min_CLP": -4.04, "draft_iters": 11.3, "mem_use": 34.46, "gen_rate": 11.3, "speed": 8.64, "text": "\\nCan you write code?\\n\\nYou are"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.64, "t1": 0.22, "tft": 1.5545, "input_0": 32, "input_1": 17, "min_CLP": -3.83, "draft_iters": 6.2, "mem_use": 34.72, "gen_rate": 4.2, "speed": 4.94, "text": "\\nWhat\\'s your favorite dish? [\\"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.8, "tree_w": 8, "tree_size": 16, "t0": 0.6064, "t1": 0.2273, "tft": 1.8534, "input_0": 30, "input_1": 17, "min_CLP": -4.14, "draft_iters": 5.8, "mem_use": 35.05, "gen_rate": 3.2, "speed": 3.82, "text": "\\nWhat are the names of the Engl"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 5, "tree_size": 16, "t0": 0.7786, "t1": 0.22, "tft": 1.4758, "input_0": 33, "input_1": 17, "min_CLP": -3.73, "draft_iters": 7.9, "mem_use": 34.6, "gen_rate": 4.6, "speed": 4.6, "text": "1.    Set realistic goals and ex"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.4, "tree_w": 5, "tree_size": 16, "t0": 0.9957, "t1": 0.21, "tft": 1.3777, "input_0": 39, "input_1": 17, "min_CLP": -4.16, "draft_iters": 10.4, "mem_use": 34.44, "gen_rate": 5.3, "speed": 4.38, "text": "\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f\\n\\n\u7b54\u6848"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.63, "t1": 0.22, "tft": 1.3049, "input_0": 34, "input_1": 17, "min_CLP": -3.79, "draft_iters": 6.0, "mem_use": 34.68, "gen_rate": 4.7, "speed": 5.55, "text": "In order to make a comparison of"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 6, "tree_size": 16, "t0": 0.7612, "t1": 0.2213, "tft": 2.2811, "input_0": 35, "input_1": 17, "min_CLP": -3.76, "draft_iters": 7.5, "mem_use": 34.95, "gen_rate": 4.0, "speed": 4.06, "text": "[Instructional questions]: [\\\\IN"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.5613, "t1": 0.22, "tft": 1.692, "input_0": 30, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.2, "mem_use": 34.79, "gen_rate": 4.0, "speed": 5.12, "text": "The URL decoded string is the st"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.9, "tree_w": 4, "tree_size": 16, "t0": 0.99, "t1": 0.2457, "tft": 2.8164, "input_0": 38, "input_1": 17, "min_CLP": -3.52, "draft_iters": 9.9, "mem_use": 35.78, "gen_rate": 5.1, "speed": 4.16, "text": "\"Yes. I know exactly what L'Hopi"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.59, "t1": 0.28, "tft": 4.3868, "input_0": 29, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.0, "mem_use": 36.69, "gen_rate": 3.7, "speed": 4.23, "text": "There are a number of brands of "}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.534, "t1": 0.229, "tft": 1.8322, "input_0": 30, "input_1": 17, "min_CLP": -3.8, "draft_iters": 4.9, "mem_use": 35.29, "gen_rate": 3.4, "speed": 4.46, "text": "There are many ways to approach "}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.5967, "t1": 0.23, "tft": 2.1004, "input_0": 28, "input_1": 17, "min_CLP": -4.11, "draft_iters": 5.7, "mem_use": 35.29, "gen_rate": 4.2, "speed": 5.1, "text": "\\nThis is my first time using th"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.4533, "t1": 0.21, "tft": 1.3079, "input_0": 52, "input_1": 17, "min_CLP": -3.95, "draft_iters": 15.3, "mem_use": 34.65, "gen_rate": 13.0, "speed": 7.8, "text": "\\n[INST]\\nYou are a helpful, res"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.606, "t1": 0.223, "tft": 2.7572, "input_0": 32, "input_1": 17, "min_CLP": -3.51, "draft_iters": 5.7, "mem_use": 34.96, "gen_rate": 3.2, "speed": 3.85, "text": "The answer to that question is a"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.9, "tree_w": 6, "tree_size": 16, "t0": 0.7788, "t1": 0.2125, "tft": 1.3176, "input_0": 35, "input_1": 17, "min_CLP": -3.93, "draft_iters": 7.9, "mem_use": 34.48, "gen_rate": 4.6, "speed": 4.66, "text": "\\nHey! Can you tell me about the"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.535, "t1": 0.21, "tft": 1.237, "input_0": 55, "input_1": 17, "min_CLP": -3.6, "draft_iters": 16.0, "mem_use": 34.41, "gen_rate": 16.0, "speed": 9.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 14.2, "tree_w": 2, "tree_size": 16, "t0": 1.422, "t1": 0.21, "tft": 1.2319, "input_0": 49, "input_1": 17, "min_CLP": -3.95, "draft_iters": 15.2, "mem_use": 34.41, "gen_rate": 9.6, "speed": 5.87, "text": "\\nIn minecraft, what are the bes"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.4533, "t1": 0.21, "tft": 1.3297, "input_0": 54, "input_1": 17, "min_CLP": -3.91, "draft_iters": 15.3, "mem_use": 34.38, "gen_rate": 15.3, "speed": 9.19, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 15.7, "tree_w": 1, "tree_size": 16, "t0": 1.6033, "t1": 0.23, "tft": 1.8708, "input_0": 54, "input_1": 17, "min_CLP": -3.01, "draft_iters": 16.7, "mem_use": 35.03, "gen_rate": 12.3, "speed": 6.74, "text": "\\n[INST]\\nYou are a helpful, res"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.7986, "t1": 0.22, "tft": 1.3107, "input_0": 41, "input_1": 17, "min_CLP": -3.74, "draft_iters": 7.7, "mem_use": 34.61, "gen_rate": 5.1, "speed": 5.07, "text": "# Add Tailwind CSS to the projec"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.6338, "t1": 0.29, "tft": 5.1165, "input_0": 32, "input_1": 17, "min_CLP": -4.03, "draft_iters": 5.1, "mem_use": 37.14, "gen_rate": 4.4, "speed": 4.73, "text": "\\nInvertebrates\\nSexual selectio"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.2, "tree_w": 8, "tree_size": 16, "t0": 0.4625, "t1": 0.2192, "tft": 1.2222, "input_0": 28, "input_1": 17, "min_CLP": -4.09, "draft_iters": 4.2, "mem_use": 35.5, "gen_rate": 2.7, "speed": 3.93, "text": "The LLM problem is by far the ha"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.3533, "t1": 0.21, "tft": 1.1429, "input_0": 45, "input_1": 17, "min_CLP": -4.06, "draft_iters": 14.3, "mem_use": 34.44, "gen_rate": 14.3, "speed": 9.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.63, "t1": 0.215, "tft": 1.2289, "input_0": 55, "input_1": 17, "min_CLP": -1.4, "draft_iters": 17.0, "mem_use": 34.53, "gen_rate": 17.0, "speed": 9.23, "text": "\\nwrite a eulogy for my 100 year"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.487, "t1": 0.23, "tft": 2.1951, "input_0": 28, "input_1": 17, "min_CLP": -3.91, "draft_iters": 4.4, "mem_use": 35.3, "gen_rate": 3.4, "speed": 4.73, "text": "\\nThe snake game is a classic ga"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.6586, "t1": 0.21, "tft": 1.2446, "input_0": 36, "input_1": 17, "min_CLP": -3.62, "draft_iters": 6.3, "mem_use": 34.65, "gen_rate": 4.7, "speed": 5.4, "text": "Yes, but I am not currently thin"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.3, "tree_w": 8, "tree_size": 16, "t0": 0.6417, "t1": 0.2117, "tft": 1.306, "input_0": 31, "input_1": 17, "min_CLP": -4.27, "draft_iters": 6.3, "mem_use": 34.45, "gen_rate": 5.3, "speed": 6.25, "text": "\\nA:\\n\\nA smile and a hug.\\n\\nB:"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.3933, "t1": 0.21, "tft": 1.114, "input_0": 51, "input_1": 17, "min_CLP": -4.2, "draft_iters": 14.7, "mem_use": 34.38, "gen_rate": 14.7, "speed": 9.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 1.034, "t1": 0.24, "tft": 2.5974, "input_0": 43, "input_1": 17, "min_CLP": -3.48, "draft_iters": 10.2, "mem_use": 35.54, "gen_rate": 7.8, "speed": 6.12, "text": "\"To say 'I love you' in Quenya, "}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.6482, "t1": 0.2109, "tft": 1.3118, "input_0": 34, "input_1": 17, "min_CLP": -3.65, "draft_iters": 6.4, "mem_use": 34.75, "gen_rate": 3.1, "speed": 3.58, "text": "\"\\nThe book is about Harry Potte"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.5663, "t1": 0.22, "tft": 1.3396, "input_0": 32, "input_1": 17, "min_CLP": -3.92, "draft_iters": 5.4, "mem_use": 34.69, "gen_rate": 4.1, "speed": 5.25, "text": "\"[INST] The Second Amendment is "}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.493, "t1": 0.21, "tft": 1.3103, "input_0": 28, "input_1": 17, "min_CLP": -4.04, "draft_iters": 4.7, "mem_use": 34.42, "gen_rate": 3.3, "speed": 4.68, "text": "\\nWhen you are looking at the su"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.3, "tree_w": 9, "tree_size": 16, "t0": 0.4564, "t1": 0.2191, "tft": 1.3336, "input_0": 26, "input_1": 17, "min_CLP": -4.1, "draft_iters": 4.3, "mem_use": 34.63, "gen_rate": 2.9, "speed": 4.32, "text": "\"\\nI also want you to be able to"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 0.968, "t1": 0.212, "tft": 1.1174, "input_0": 47, "input_1": 17, "min_CLP": -3.48, "draft_iters": 9.6, "mem_use": 34.47, "gen_rate": 8.0, "speed": 6.76, "text": "Melbourne.\\n[INST] What is the o"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.8, "tree_w": 6, "tree_size": 16, "t0": 0.775, "t1": 0.2125, "tft": 1.1528, "input_0": 37, "input_1": 17, "min_CLP": -3.67, "draft_iters": 7.8, "mem_use": 34.55, "gen_rate": 4.2, "speed": 4.29, "text": "[INST] who are you and what do y"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 4.1, "tree_w": 8, "tree_size": 16, "t0": 0.5462, "t1": 0.2415, "tft": 2.6877, "input_0": 26, "input_1": 17, "min_CLP": -4.03, "draft_iters": 5.1, "mem_use": 35.7, "gen_rate": 2.5, "speed": 3.12, "text": "\\n[INST] I would have to say tha"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.3367, "t1": 0.21, "tft": 1.2351, "input_0": 50, "input_1": 17, "min_CLP": -4.1, "draft_iters": 14.0, "mem_use": 34.81, "gen_rate": 14.0, "speed": 9.03, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.5742, "t1": 0.23, "tft": 1.8704, "input_0": 31, "input_1": 17, "min_CLP": -4.27, "draft_iters": 5.4, "mem_use": 35.13, "gen_rate": 2.7, "speed": 3.33, "text": "Yes. If the vector A is a linear"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.58, "t1": 0.21, "tft": 1.2228, "input_0": 55, "input_1": 17, "min_CLP": -3.63, "draft_iters": 16.5, "mem_use": 34.54, "gen_rate": 16.5, "speed": 9.2, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.3767, "t1": 0.21, "tft": 1.4175, "input_0": 50, "input_1": 17, "min_CLP": -3.2, "draft_iters": 14.3, "mem_use": 34.44, "gen_rate": 12.7, "speed": 7.98, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 12.2, "tree_w": 3, "tree_size": 16, "t0": 1.255, "t1": 0.21, "tft": 1.3083, "input_0": 47, "input_1": 17, "min_CLP": -4.14, "draft_iters": 13.2, "mem_use": 34.41, "gen_rate": 11.2, "speed": 7.66, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.7025, "t1": 0.22, "tft": 1.5552, "input_0": 36, "input_1": 17, "min_CLP": -3.88, "draft_iters": 6.9, "mem_use": 34.7, "gen_rate": 4.4, "speed": 4.75, "text": "No, variance is the sum of the s"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.0, "tree_w": 6, "tree_size": 16, "t0": 0.7137, "t1": 0.22, "tft": 1.7628, "input_0": 33, "input_1": 17, "min_CLP": -4.47, "draft_iters": 7.0, "mem_use": 34.85, "gen_rate": 4.6, "speed": 4.94, "text": "\\nComplete the following company"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.572, "t1": 0.22, "tft": 1.6459, "input_0": 31, "input_1": 17, "min_CLP": -3.77, "draft_iters": 5.4, "mem_use": 34.72, "gen_rate": 3.2, "speed": 4.04, "text": "You can see the best starry sky "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 7.6, "tree_w": 7, "tree_size": 16, "t0": 0.834, "t1": 0.21, "tft": 1.2174, "input_0": 34, "input_1": 17, "min_CLP": -3.93, "draft_iters": 8.6, "mem_use": 34.4, "gen_rate": 8.2, "speed": 7.83, "text": "I am a bad person, I am a bad pe"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.5463, "t1": 0.2188, "tft": 1.1284, "input_0": 30, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.1, "mem_use": 34.67, "gen_rate": 4.2, "speed": 5.57, "text": "This is an interesting question."}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 5, "tree_size": 16, "t0": 0.8083, "t1": 0.2167, "tft": 1.2099, "input_0": 37, "input_1": 17, "min_CLP": -4.09, "draft_iters": 8.0, "mem_use": 34.62, "gen_rate": 5.8, "speed": 5.7, "text": "\\n[INST] Which of the following "}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.735, "t1": 0.26, "tft": 3.9439, "input_0": 60, "input_1": 17, "min_CLP": -2.43, "draft_iters": 17.0, "mem_use": 36.21, "gen_rate": 17.0, "speed": 8.5, "text": "\"I am Open Assistant, an AI lang"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.57, "t1": 0.24, "tft": 2.5093, "input_0": 30, "input_1": 17, "min_CLP": -3.43, "draft_iters": 5.2, "mem_use": 35.54, "gen_rate": 3.7, "speed": 4.53, "text": "\"The decision to build your own "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.4033, "t1": 0.21, "tft": 1.1318, "input_0": 52, "input_1": 17, "min_CLP": -4.17, "draft_iters": 14.7, "mem_use": 34.74, "gen_rate": 14.7, "speed": 9.07, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.59, "t1": 0.21, "tft": 1.3299, "input_0": 55, "input_1": 17, "min_CLP": -3.16, "draft_iters": 17.0, "mem_use": 34.51, "gen_rate": 17.0, "speed": 9.44, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.6482, "t1": 0.3618, "tft": 8.9413, "input_0": 28, "input_1": 17, "min_CLP": -3.93, "draft_iters": 4.5, "mem_use": 39.29, "gen_rate": 3.1, "speed": 3.05, "text": "The _physics_process function is"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.69, "t1": 0.2167, "tft": 1.327, "input_0": 36, "input_1": 17, "min_CLP": -3.63, "draft_iters": 6.7, "mem_use": 36.54, "gen_rate": 5.3, "speed": 5.89, "text": "No, decorators are always placed"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.39, "t1": 0.21, "tft": 1.2226, "input_0": 54, "input_1": 17, "min_CLP": -3.04, "draft_iters": 14.3, "mem_use": 34.46, "gen_rate": 14.0, "speed": 8.71, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.0, "tree_w": 9, "tree_size": 16, "t0": 0.5025, "t1": 0.21, "tft": 1.2453, "input_0": 24, "input_1": 17, "min_CLP": -4.14, "draft_iters": 5.0, "mem_use": 34.44, "gen_rate": 4.0, "speed": 5.58, "text": "\\nPlease do not share any links "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.0, "tree_w": 9, "tree_size": 16, "t0": 0.4527, "t1": 0.2445, "tft": 2.7073, "input_0": 24, "input_1": 17, "min_CLP": -4.04, "draft_iters": 4.0, "mem_use": 35.74, "gen_rate": 2.9, "speed": 4.17, "text": "\"\\nI thought I'd share a few mor"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.7886, "t1": 0.2186, "tft": 1.4688, "input_0": 43, "input_1": 17, "min_CLP": -3.7, "draft_iters": 7.4, "mem_use": 34.83, "gen_rate": 5.3, "speed": 5.26, "text": "There are some, but not many. He"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.7312, "t1": 0.22, "tft": 1.5569, "input_0": 38, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.1, "mem_use": 34.73, "gen_rate": 4.2, "speed": 4.47, "text": "\\nWhat is the speed of sound? [\\"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 2.9, "tree_w": 9, "tree_size": 16, "t0": 0.417, "t1": 0.215, "tft": 1.2777, "input_0": 25, "input_1": 17, "min_CLP": -4.01, "draft_iters": 3.9, "mem_use": 34.55, "gen_rate": 3.5, "speed": 5.53, "text": "\"\\nHere are some links to some a"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 1.1633, "t1": 0.22, "tft": 1.5291, "input_0": 49, "input_1": 17, "min_CLP": -4.14, "draft_iters": 12.0, "mem_use": 34.73, "gen_rate": 12.0, "speed": 8.69, "text": "Generative bias dreams,\\nData it"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.6917, "t1": 0.2167, "tft": 1.2039, "input_0": 35, "input_1": 17, "min_CLP": -4.86, "draft_iters": 6.8, "mem_use": 34.57, "gen_rate": 5.7, "speed": 6.24, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.7025, "t1": 0.24, "tft": 2.5217, "input_0": 34, "input_1": 17, "min_CLP": -3.67, "draft_iters": 6.6, "mem_use": 35.56, "gen_rate": 4.0, "speed": 4.24, "text": "\"\\nYou should definitely set up "}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 9.5, "tree_w": 3, "tree_size": 16, "t0": 1.025, "t1": 0.21, "tft": 1.8572, "input_0": 45, "input_1": 17, "min_CLP": -3.36, "draft_iters": 10.5, "mem_use": 34.75, "gen_rate": 7.2, "speed": 5.79, "text": "Canberra is located in the north"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 8.7, "tree_w": 5, "tree_size": 16, "t0": 0.9514, "t1": 0.2129, "tft": 1.217, "input_0": 41, "input_1": 17, "min_CLP": -3.58, "draft_iters": 9.7, "mem_use": 34.46, "gen_rate": 5.9, "speed": 5.03, "text": "\"I can speak Spanish. How can I "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.561, "t1": 0.211, "tft": 1.2343, "input_0": 31, "input_1": 17, "min_CLP": -5.13, "draft_iters": 5.4, "mem_use": 34.44, "gen_rate": 4.1, "speed": 5.28, "text": "\\nDo you know the difference bet"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.89, "t1": 0.3, "tft": 5.5077, "input_0": 56, "input_1": 17, "min_CLP": -1.52, "draft_iters": 17.0, "mem_use": 37.4, "gen_rate": 17.0, "speed": 7.75, "text": "\\nwrite code that imitates a fak"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.75, "t1": 0.23, "tft": 2.009, "input_0": 36, "input_1": 17, "min_CLP": -3.89, "draft_iters": 7.2, "mem_use": 35.64, "gen_rate": 3.2, "speed": 3.26, "text": "\\nWhat is the best way to get be"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.492, "t1": 0.22, "tft": 1.1288, "input_0": 28, "input_1": 17, "min_CLP": -3.99, "draft_iters": 4.6, "mem_use": 34.66, "gen_rate": 3.4, "speed": 4.81, "text": "Not in the near future. AI assis"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.69, "t1": 0.24, "tft": 2.5491, "input_0": 38, "input_1": 17, "min_CLP": -3.75, "draft_iters": 6.3, "mem_use": 35.63, "gen_rate": 4.7, "speed": 5.06, "text": "In order to breed animals in Min"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.695, "t1": 0.25, "tft": 3.3346, "input_0": 59, "input_1": 17, "min_CLP": -3.28, "draft_iters": 17.0, "mem_use": 35.98, "gen_rate": 17.0, "speed": 8.73, "text": "Die meisten Menschen kennen die "}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.4, "tree_w": 9, "tree_size": 16, "t0": 0.492, "t1": 0.237, "tft": 1.9971, "input_0": 25, "input_1": 17, "min_CLP": -4.09, "draft_iters": 4.4, "mem_use": 35.41, "gen_rate": 3.5, "speed": 4.81, "text": "\"[INST] I'm sorry, but I cannot "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.55, "t1": 0.22, "tft": 1.7023, "input_0": 32, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.1, "mem_use": 34.79, "gen_rate": 4.4, "speed": 5.67, "text": "You can call the police if you h"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 3.5, "tree_w": 9, "tree_size": 16, "t0": 0.4869, "t1": 0.22, "tft": 1.6451, "input_0": 27, "input_1": 17, "min_CLP": -4.1, "draft_iters": 4.5, "mem_use": 34.91, "gen_rate": 2.5, "speed": 3.47, "text": "You know how to self-attention m"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 10.4, "tree_w": 3, "tree_size": 16, "t0": 1.09, "t1": 0.2143, "tft": 1.319, "input_0": 39, "input_1": 17, "min_CLP": -3.29, "draft_iters": 11.4, "mem_use": 34.48, "gen_rate": 5.9, "speed": 4.49, "text": "\\nWrite me a function in JavaScr"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.6971, "t1": 0.23, "tft": 1.9389, "input_0": 34, "input_1": 17, "min_CLP": -3.98, "draft_iters": 6.7, "mem_use": 35.12, "gen_rate": 5.6, "speed": 6.02, "text": "Because it is a form of indecent"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.6767, "t1": 0.22, "tft": 1.2538, "input_0": 31, "input_1": 17, "min_CLP": -3.89, "draft_iters": 6.8, "mem_use": 34.67, "gen_rate": 3.6, "speed": 3.98, "text": "\"\\n[INST] <<SYS>>\\nThank you for"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.6422, "t1": 0.23, "tft": 1.9791, "input_0": 33, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.0, "mem_use": 35.13, "gen_rate": 3.6, "speed": 4.08, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.5058, "t1": 0.22, "tft": 2.2929, "input_0": 28, "input_1": 17, "min_CLP": -3.9, "draft_iters": 4.8, "mem_use": 34.79, "gen_rate": 2.9, "speed": 4.02, "text": "I would need the specific date o"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.39, "t1": 0.21, "tft": 1.0162, "input_0": 52, "input_1": 17, "min_CLP": -2.86, "draft_iters": 14.3, "mem_use": 34.46, "gen_rate": 14.3, "speed": 8.94, "text": "\\nMe de uma lista de nicks para "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.3, "tree_w": 8, "tree_size": 16, "t0": 0.5555, "t1": 0.22, "tft": 1.4091, "input_0": 30, "input_1": 17, "min_CLP": -3.79, "draft_iters": 5.3, "mem_use": 34.62, "gen_rate": 2.9, "speed": 3.76, "text": "Yes, it was the first time the B"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.2, "tree_w": 1, "tree_size": 16, "t0": 1.565, "t1": 0.23, "tft": 2.9215, "input_0": 58, "input_1": 17, "min_CLP": -2.2, "draft_iters": 16.2, "mem_use": 35.19, "gen_rate": 8.0, "speed": 4.45, "text": "1. \u00abBorn to Run\u00bb, Bruce Springst"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 2, "tree_size": 16, "t0": 1.53, "t1": 0.21, "tft": 1.2271, "input_0": 55, "input_1": 17, "min_CLP": -3.07, "draft_iters": 16.0, "mem_use": 34.58, "gen_rate": 16.0, "speed": 9.18, "text": "\\nPlease give me a table of the "}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.8, "tree_w": 4, "tree_size": 16, "t0": 1.03, "t1": 0.22, "tft": 1.5925, "input_0": 37, "input_1": 17, "min_CLP": -3.09, "draft_iters": 10.8, "mem_use": 34.71, "gen_rate": 10.5, "speed": 8.41, "text": "\"I know, I'm sorry.\\n\\nWrite a c"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.5737, "t1": 0.22, "tft": 1.4667, "input_0": 31, "input_1": 17, "min_CLP": -3.65, "draft_iters": 5.4, "mem_use": 34.9, "gen_rate": 4.0, "speed": 5.02, "text": "The clock reminds us that time i"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.4, "tree_w": 7, "tree_size": 16, "t0": 0.6612, "t1": 0.23, "tft": 2.1036, "input_0": 32, "input_1": 17, "min_CLP": -4.0, "draft_iters": 6.4, "mem_use": 35.31, "gen_rate": 4.1, "speed": 4.62, "text": "\"[INST]\\n\\nHow do you know if yo"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.5, "tree_w": 7, "tree_size": 16, "t0": 0.489, "t1": 0.21, "tft": 1.5512, "input_0": 30, "input_1": 17, "min_CLP": -3.78, "draft_iters": 4.5, "mem_use": 34.65, "gen_rate": 3.5, "speed": 4.98, "text": "He was born in Hamburg, Germany,"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.56, "t1": 0.2122, "tft": 1.313, "input_0": 31, "input_1": 17, "min_CLP": -4.33, "draft_iters": 5.2, "mem_use": 34.45, "gen_rate": 4.2, "speed": 5.46, "text": "\\nWhich of the following is true"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 1.2133, "t1": 0.27, "tft": 4.0166, "input_0": 46, "input_1": 17, "min_CLP": -4.07, "draft_iters": 11.3, "mem_use": 36.5, "gen_rate": 11.3, "speed": 7.64, "text": "\\n<</SYS>\\n\\nYou are a helpful, "}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.3233, "t1": 0.21, "tft": 1.3128, "input_0": 44, "input_1": 17, "min_CLP": -3.84, "draft_iters": 14.0, "mem_use": 35.2, "gen_rate": 14.0, "speed": 9.11, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.494, "t1": 0.211, "tft": 1.735, "input_0": 29, "input_1": 17, "min_CLP": -3.88, "draft_iters": 4.6, "mem_use": 34.38, "gen_rate": 3.3, "speed": 4.67, "text": "\\nHello, I am looking to build m"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.85, "t1": 0.29, "tft": 5.7922, "input_0": 68, "input_1": 17, "min_CLP": -2.46, "draft_iters": 17.0, "mem_use": 36.95, "gen_rate": 17.0, "speed": 7.96, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.58, "t1": 0.239, "tft": 2.0431, "input_0": 32, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.3, "mem_use": 35.43, "gen_rate": 3.4, "speed": 4.17, "text": "\"\u2022 Keep your new habit in mind w"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.5664, "t1": 0.2291, "tft": 1.5721, "input_0": 30, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.3, "mem_use": 35.03, "gen_rate": 3.4, "speed": 4.24, "text": "\\nThe information is not known f"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.724, "t1": 0.211, "tft": 1.4505, "input_0": 32, "input_1": 17, "min_CLP": -4.04, "draft_iters": 7.3, "mem_use": 34.52, "gen_rate": 3.3, "speed": 3.52, "text": "[INST] The date was the very fir"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.56, "t1": 0.21, "tft": 1.232, "input_0": 52, "input_1": 17, "min_CLP": -2.42, "draft_iters": 17.0, "mem_use": 34.49, "gen_rate": 17.0, "speed": 9.61, "text": "\"\\nI've recently started playing"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 10.4, "tree_w": 3, "tree_size": 16, "t0": 1.112, "t1": 0.222, "tft": 1.959, "input_0": 45, "input_1": 17, "min_CLP": -3.74, "draft_iters": 11.4, "mem_use": 34.95, "gen_rate": 9.0, "speed": 6.74, "text": "\"[INST] What's the weather? [\\\\I"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.2, "tree_w": 8, "tree_size": 16, "t0": 0.56, "t1": 0.24, "tft": 2.3634, "input_0": 27, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.2, "mem_use": 35.5, "gen_rate": 4.1, "speed": 5.18, "text": "\\nI would prefer it to use the `"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.0, "tree_w": 7, "tree_size": 16, "t0": 0.712, "t1": 0.22, "tft": 1.5822, "input_0": 33, "input_1": 17, "min_CLP": -4.0, "draft_iters": 7.0, "mem_use": 34.87, "gen_rate": 6.4, "speed": 6.87, "text": "\"I'm a [\\\\INST] and I want to cr"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.5517, "t1": 0.2208, "tft": 1.9421, "input_0": 30, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.2, "mem_use": 34.96, "gen_rate": 2.7, "speed": 3.44, "text": "\"\\nI know you're going to think "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.4733, "t1": 0.2167, "tft": 1.3151, "input_0": 57, "input_1": 17, "min_CLP": -3.15, "draft_iters": 15.3, "mem_use": 34.62, "gen_rate": 14.7, "speed": 8.69, "text": "That would depend on the species"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.844, "t1": 0.218, "tft": 1.5751, "input_0": 44, "input_1": 17, "min_CLP": -3.18, "draft_iters": 8.2, "mem_use": 34.61, "gen_rate": 6.8, "speed": 6.41, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.55, "t1": 0.23, "tft": 2.103, "input_0": 55, "input_1": 17, "min_CLP": -3.34, "draft_iters": 16.0, "mem_use": 35.31, "gen_rate": 16.0, "speed": 9.0, "text": "\\n1. Use the built-in Error Chec"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.7, "tree_w": 7, "tree_size": 16, "t0": 0.513, "t1": 0.23, "tft": 2.1098, "input_0": 30, "input_1": 17, "min_CLP": -3.79, "draft_iters": 4.7, "mem_use": 35.26, "gen_rate": 3.4, "speed": 4.56, "text": "Yes. Open Assistant has been tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.5944, "t1": 0.25, "tft": 3.43, "input_0": 29, "input_1": 17, "min_CLP": -4.03, "draft_iters": 5.4, "mem_use": 35.98, "gen_rate": 3.8, "speed": 4.47, "text": "\"\\nWhat is the best way to store"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.6986, "t1": 0.21, "tft": 1.2134, "input_0": 41, "input_1": 17, "min_CLP": -4.01, "draft_iters": 6.7, "mem_use": 34.95, "gen_rate": 4.7, "speed": 5.18, "text": "\\nThe President of Germany is th"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.583, "t1": 0.22, "tft": 1.6487, "input_0": 30, "input_1": 17, "min_CLP": -3.93, "draft_iters": 5.6, "mem_use": 34.89, "gen_rate": 4.0, "speed": 4.97, "text": "It is a library for processing C"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 5, "tree_size": 16, "t0": 0.8243, "t1": 0.25, "tft": 3.0086, "input_0": 35, "input_1": 17, "min_CLP": -3.63, "draft_iters": 7.9, "mem_use": 35.87, "gen_rate": 4.9, "speed": 4.53, "text": "how does crypto currency mining "}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 6, "tree_size": 16, "t0": 0.6875, "t1": 0.2175, "tft": 1.2365, "input_0": 31, "input_1": 17, "min_CLP": -3.89, "draft_iters": 6.9, "mem_use": 34.89, "gen_rate": 4.4, "speed": 4.84, "text": "\\nYou are the best assistant! [\\"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.91, "t1": 0.228, "tft": 1.8972, "input_0": 38, "input_1": 17, "min_CLP": -3.77, "draft_iters": 9.2, "mem_use": 35.08, "gen_rate": 9.0, "speed": 7.91, "text": "\"Sorry, I don't know.\\n[INST] Wh"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 16, "max_branch_width": 32, "gen_rate": 6.83, "gen_rate_micro": 4.9, "gen_speed": 5.723, "gen_speed_micro": 5.316, "t0": 0.8552, "t1": 0.2241, "input_0": 37.3, "input_1": 17.0, "tree_size": 16.0, "tree_w": 5.2, "tree_h": 7.5, "prompt_len": 320.7, "min_CLP": -3.73, "mem_use": 39.29, "exp_time": 4606.96}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.6833, "t1": 0.24, "tft": 1.4329, "input_0": 72, "input_1": 33, "min_CLP": -5.07, "draft_iters": 6.0, "mem_use": 34.53, "gen_rate": 5.3, "speed": 5.78, "text": "\"The Dyson sphere is a hypotheti"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.7178, "t1": 0.2544, "tft": 2.096, "input_0": 68, "input_1": 33, "min_CLP": -4.72, "draft_iters": 6.2, "mem_use": 35.15, "gen_rate": 3.7, "speed": 3.77, "text": "\\nHow many times have you been h"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 1.144, "t1": 0.264, "tft": 2.6277, "input_0": 109, "input_1": 33, "min_CLP": -3.98, "draft_iters": 9.8, "mem_use": 35.55, "gen_rate": 6.8, "speed": 4.82, "text": "4. Darkest Dungeon\\n5. Civ V\\n6."}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.91, "t1": 0.24, "tft": 1.35, "input_0": 99, "input_1": 33, "min_CLP": -3.66, "draft_iters": 32.0, "mem_use": 34.72, "gen_rate": 33.0, "speed": 10.48, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 3, "tree_size": 32, "t0": 2.6, "t1": 0.24, "tft": 1.3581, "input_0": 113, "input_1": 33, "min_CLP": -4.48, "draft_iters": 28.0, "mem_use": 34.44, "gen_rate": 28.5, "speed": 10.05, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.2, "tree_w": 8, "tree_size": 32, "t0": 1.3375, "t1": 0.27, "tft": 3.1696, "input_0": 100, "input_1": 33, "min_CLP": -3.99, "draft_iters": 12.2, "mem_use": 35.71, "gen_rate": 9.5, "speed": 5.91, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.8167, "t1": 0.28, "tft": 3.7212, "input_0": 74, "input_1": 33, "min_CLP": -4.04, "draft_iters": 7.2, "mem_use": 36.03, "gen_rate": 5.3, "speed": 4.86, "text": "There are several other techniqu"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 12, "tree_size": 32, "t0": 0.8171, "t1": 0.32, "tft": 4.8134, "input_0": 71, "input_1": 33, "min_CLP": -4.45, "draft_iters": 6.4, "mem_use": 37.14, "gen_rate": 4.6, "speed": 4.03, "text": "\\n1. Social Media Marketing (SMM"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 11, "tree_size": 32, "t0": 0.7863, "t1": 0.27, "tft": 2.7089, "input_0": 64, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.9, "mem_use": 35.76, "gen_rate": 4.0, "speed": 3.79, "text": "\\nI am not a lawyer, but I am fa"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.3, "tree_w": 13, "tree_size": 32, "t0": 0.7256, "t1": 0.26, "tft": 2.454, "input_0": 72, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.3, "mem_use": 35.52, "gen_rate": 3.6, "speed": 3.59, "text": "You can start a hobby in any sea"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 18.0, "tree_w": 9, "tree_size": 32, "t0": 1.855, "t1": 0.24, "tft": 1.4603, "input_0": 108, "input_1": 33, "min_CLP": -4.35, "draft_iters": 19.0, "mem_use": 34.79, "gen_rate": 19.0, "speed": 9.06, "text": "\\nWrite me a program that takes "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 16, "tree_size": 32, "t0": 0.626, "t1": 0.27, "tft": 2.5696, "input_0": 63, "input_1": 33, "min_CLP": -4.74, "draft_iters": 5.5, "mem_use": 35.7, "gen_rate": 3.3, "speed": 3.69, "text": "\\nI have tried to shorten it a b"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 19.0, "tree_w": 6, "tree_size": 32, "t0": 1.9375, "t1": 0.26, "tft": 2.1309, "input_0": 96, "input_1": 33, "min_CLP": -3.76, "draft_iters": 19.8, "mem_use": 35.32, "gen_rate": 12.5, "speed": 5.69, "text": "Sure! Here are the issues with u"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.0, "tree_w": 5, "tree_size": 32, "t0": 1.5275, "t1": 0.24, "tft": 1.3673, "input_0": 108, "input_1": 33, "min_CLP": -4.31, "draft_iters": 15.0, "mem_use": 34.65, "gen_rate": 9.5, "speed": 5.38, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.695, "t1": 0.28, "tft": 3.639, "input_0": 66, "input_1": 33, "min_CLP": -4.32, "draft_iters": 5.9, "mem_use": 36.03, "gen_rate": 4.0, "speed": 4.11, "text": "\"It's important to start small a"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 22, "tree_h": 3.6, "tree_w": 16, "tree_size": 32, "t0": 0.5186, "t1": 0.24, "tft": 1.2828, "input_0": 54, "input_1": 33, "min_CLP": -4.7, "draft_iters": 4.6, "mem_use": 34.95, "gen_rate": 3.1, "speed": 4.15, "text": "\"\\nMost people use a 1000kbps up"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.3, "tree_w": 13, "tree_size": 32, "t0": 0.6811, "t1": 0.24, "tft": 1.2391, "input_0": 65, "input_1": 33, "min_CLP": -4.73, "draft_iters": 6.3, "mem_use": 34.44, "gen_rate": 3.6, "speed": 3.85, "text": "\\nHow do you find the area of a "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.09, "t1": 0.24, "tft": 3.3581, "input_0": 141, "input_1": 33, "min_CLP": -3.77, "draft_iters": 32.0, "mem_use": 34.43, "gen_rate": 33.0, "speed": 9.92, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 10, "tree_size": 32, "t0": 1.036, "t1": 0.244, "tft": 1.9968, "input_0": 96, "input_1": 33, "min_CLP": -4.55, "draft_iters": 9.6, "mem_use": 34.73, "gen_rate": 7.0, "speed": 5.47, "text": "D-theanine is less common than L"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 11, "tree_size": 32, "t0": 0.7329, "t1": 0.24, "tft": 1.4516, "input_0": 67, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.9, "mem_use": 34.44, "gen_rate": 4.6, "speed": 4.7, "text": "\\nA. The Balfour Declaration is "}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 3, "tree_size": 32, "t0": 2.84, "t1": 0.25, "tft": 1.693, "input_0": 108, "input_1": 33, "min_CLP": -3.6, "draft_iters": 30.0, "mem_use": 34.91, "gen_rate": 30.5, "speed": 9.88, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.2, "tree_w": 14, "tree_size": 32, "t0": 0.5867, "t1": 0.24, "tft": 2.1157, "input_0": 62, "input_1": 33, "min_CLP": -4.73, "draft_iters": 5.2, "mem_use": 34.45, "gen_rate": 3.7, "speed": 4.45, "text": "\"\\nI thank you for your interest"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.96, "t1": 0.27, "tft": 2.9493, "input_0": 87, "input_1": 33, "min_CLP": -4.19, "draft_iters": 8.4, "mem_use": 35.65, "gen_rate": 6.8, "speed": 5.53, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 2, "tree_size": 32, "t0": 2.93, "t1": 0.24, "tft": 1.3318, "input_0": 118, "input_1": 33, "min_CLP": -3.7, "draft_iters": 31.0, "mem_use": 34.77, "gen_rate": 31.5, "speed": 9.93, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 1, "tree_size": 32, "t0": 2.95, "t1": 0.25, "tft": 2.0311, "input_0": 128, "input_1": 33, "min_CLP": -3.55, "draft_iters": 31.0, "mem_use": 35.0, "gen_rate": 31.5, "speed": 9.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 7.4, "tree_w": 12, "tree_size": 32, "t0": 0.8544, "t1": 0.24, "tft": 1.3665, "input_0": 65, "input_1": 33, "min_CLP": -4.75, "draft_iters": 8.4, "mem_use": 34.51, "gen_rate": 4.4, "speed": 4.07, "text": "\\nWhat are some of the most impo"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.3, "tree_w": 15, "tree_size": 32, "t0": 0.61, "t1": 0.2478, "tft": 1.8535, "input_0": 65, "input_1": 33, "min_CLP": -4.65, "draft_iters": 5.3, "mem_use": 34.79, "gen_rate": 4.1, "speed": 4.81, "text": "Austenite is an allotrope of iro"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 16.0, "tree_w": 5, "tree_size": 32, "t0": 1.6467, "t1": 0.24, "tft": 1.7654, "input_0": 98, "input_1": 33, "min_CLP": -4.63, "draft_iters": 16.7, "mem_use": 34.72, "gen_rate": 16.3, "speed": 8.64, "text": "\\n<SYS>\\n\\n[INST] <<SYS>>\\nYou a"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 3, "tree_size": 32, "t0": 2.745, "t1": 0.27, "tft": 2.8728, "input_0": 123, "input_1": 33, "min_CLP": -4.18, "draft_iters": 28.0, "mem_use": 35.69, "gen_rate": 28.5, "speed": 9.45, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.7, "tree_w": 11, "tree_size": 32, "t0": 1.0829, "t1": 0.24, "tft": 1.3636, "input_0": 82, "input_1": 33, "min_CLP": -4.49, "draft_iters": 10.7, "mem_use": 34.81, "gen_rate": 5.4, "speed": 4.11, "text": "\\nWhat are some great things to "}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.6737, "t1": 0.2475, "tft": 1.7648, "input_0": 69, "input_1": 33, "min_CLP": -4.48, "draft_iters": 6.0, "mem_use": 34.8, "gen_rate": 4.0, "speed": 4.34, "text": "No, as the game is turn-based, t"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 43, "tree_h": 5.0, "tree_w": 15, "tree_size": 32, "t0": 0.661, "t1": 0.25, "tft": 2.2429, "input_0": 58, "input_1": 33, "min_CLP": -4.75, "draft_iters": 6.0, "mem_use": 35.07, "gen_rate": 4.3, "speed": 4.71, "text": "[INST] I will answer the questio"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 3, "tree_size": 32, "t0": 2.365, "t1": 0.24, "tft": 2.4163, "input_0": 114, "input_1": 33, "min_CLP": -3.89, "draft_iters": 24.5, "mem_use": 34.68, "gen_rate": 25.0, "speed": 9.59, "text": "\\n[INST] Dear Freya, goddess of "}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.4, "tree_w": 14, "tree_size": 32, "t0": 0.6278, "t1": 0.2611, "tft": 2.2783, "input_0": 63, "input_1": 33, "min_CLP": -4.59, "draft_iters": 5.4, "mem_use": 35.52, "gen_rate": 4.0, "speed": 4.49, "text": "You can try substitutes for chee"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.6, "tree_w": 12, "tree_size": 32, "t0": 0.8333, "t1": 0.26, "tft": 2.2267, "input_0": 75, "input_1": 33, "min_CLP": -4.36, "draft_iters": 7.6, "mem_use": 35.47, "gen_rate": 3.9, "speed": 3.55, "text": "\\nTo be completely honest, there"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.4, "tree_w": 10, "tree_size": 32, "t0": 0.842, "t1": 0.32, "tft": 5.3295, "input_0": 76, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.4, "mem_use": 37.16, "gen_rate": 3.2, "speed": 2.76, "text": "Selenium has long been the most "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 12, "tree_size": 32, "t0": 0.838, "t1": 0.24, "tft": 1.3762, "input_0": 71, "input_1": 33, "min_CLP": -4.91, "draft_iters": 8.0, "mem_use": 35.49, "gen_rate": 6.8, "speed": 6.3, "text": "\"\\nWhat is the average length of"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.1, "tree_w": 16, "tree_size": 32, "t0": 0.651, "t1": 0.24, "tft": 2.4176, "input_0": 57, "input_1": 33, "min_CLP": -4.73, "draft_iters": 6.1, "mem_use": 34.71, "gen_rate": 3.5, "speed": 3.92, "text": "What\\'s the name of the movie wh"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.736, "t1": 0.276, "tft": 3.2883, "input_0": 64, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.6, "mem_use": 35.9, "gen_rate": 3.6, "speed": 3.56, "text": "\"\\nHello Mike! It's nice to meet"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.6, "tree_w": 13, "tree_size": 32, "t0": 0.63, "t1": 0.25, "tft": 1.956, "input_0": 62, "input_1": 33, "min_CLP": -4.54, "draft_iters": 5.6, "mem_use": 34.89, "gen_rate": 4.2, "speed": 4.84, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 14, "tree_size": 32, "t0": 0.945, "t1": 0.24, "tft": 1.2674, "input_0": 65, "input_1": 33, "min_CLP": -4.59, "draft_iters": 9.3, "mem_use": 34.55, "gen_rate": 5.8, "speed": 4.92, "text": "[INST] You have no power over me"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 17.3, "tree_w": 6, "tree_size": 32, "t0": 1.8, "t1": 0.27, "tft": 2.9435, "input_0": 83, "input_1": 33, "min_CLP": -4.74, "draft_iters": 18.0, "mem_use": 35.77, "gen_rate": 14.3, "speed": 6.93, "text": "\\nWrite a short essay. [\\\\INST]\\"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.3, "tree_w": 12, "tree_size": 32, "t0": 0.6444, "t1": 0.28, "tft": 3.3755, "input_0": 63, "input_1": 33, "min_CLP": -4.68, "draft_iters": 5.3, "mem_use": 36.02, "gen_rate": 3.6, "speed": 3.84, "text": "\"Thank you! Yes it is helpful. I"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.78, "t1": 0.26, "tft": 2.1335, "input_0": 74, "input_1": 33, "min_CLP": -4.4, "draft_iters": 7.0, "mem_use": 35.23, "gen_rate": 5.3, "speed": 5.15, "text": "\"In terms of popularity, SonarQu"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 8.7, "tree_w": 9, "tree_size": 32, "t0": 1.0343, "t1": 0.25, "tft": 1.6146, "input_0": 81, "input_1": 33, "min_CLP": -5.02, "draft_iters": 9.7, "mem_use": 34.85, "gen_rate": 6.1, "speed": 4.8, "text": "\"You're welcome! :)\\n[INST] Can "}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 2, "tree_size": 32, "t0": 2.96, "t1": 0.245, "tft": 2.2814, "input_0": 157, "input_1": 33, "min_CLP": -4.44, "draft_iters": 30.5, "mem_use": 34.72, "gen_rate": 30.5, "speed": 9.52, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.7467, "t1": 0.24, "tft": 1.785, "input_0": 69, "input_1": 33, "min_CLP": -4.54, "draft_iters": 7.0, "mem_use": 34.44, "gen_rate": 3.9, "speed": 3.94, "text": "\\nCheck your System Drive for Er"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 15.7, "tree_w": 6, "tree_size": 32, "t0": 1.88, "t1": 0.32, "tft": 5.1797, "input_0": 103, "input_1": 33, "min_CLP": -4.67, "draft_iters": 16.3, "mem_use": 37.24, "gen_rate": 15.7, "speed": 7.13, "text": "\"I'll try.\\n\\n[The scene opens w"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.1, "tree_w": 14, "tree_size": 32, "t0": 0.6011, "t1": 0.26, "tft": 1.9513, "input_0": 62, "input_1": 33, "min_CLP": -4.83, "draft_iters": 5.1, "mem_use": 35.56, "gen_rate": 3.6, "speed": 4.14, "text": "It was a dark night, the wind ho"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 3.9, "tree_w": 17, "tree_size": 32, "t0": 0.556, "t1": 0.249, "tft": 1.5738, "input_0": 58, "input_1": 33, "min_CLP": -5.11, "draft_iters": 4.9, "mem_use": 34.84, "gen_rate": 3.8, "speed": 4.73, "text": "\\nSomeone has written a question"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.7155, "t1": 0.2491, "tft": 2.1924, "input_0": 62, "input_1": 33, "min_CLP": -4.65, "draft_iters": 6.6, "mem_use": 34.86, "gen_rate": 2.9, "speed": 3.02, "text": "A previous work [\\\\INST] propose"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 22.0, "tree_w": 4, "tree_size": 32, "t0": 2.2433, "t1": 0.2633, "tft": 3.212, "input_0": 109, "input_1": 33, "min_CLP": -3.87, "draft_iters": 22.7, "mem_use": 35.55, "gen_rate": 11.3, "speed": 4.52, "text": "F-centers are crystallographic d"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.7, "tree_w": 14, "tree_size": 32, "t0": 0.7267, "t1": 0.25, "tft": 2.1132, "input_0": 62, "input_1": 33, "min_CLP": -4.61, "draft_iters": 6.7, "mem_use": 35.12, "gen_rate": 3.7, "speed": 3.74, "text": "\\nOn this day in 1836, the Argen"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.7033, "t1": 0.26, "tft": 2.2957, "input_0": 78, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.2, "mem_use": 35.3, "gen_rate": 6.0, "speed": 6.23, "text": "\"Yes, technology can be used for"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.5, "tree_w": 9, "tree_size": 32, "t0": 1.0975, "t1": 0.24, "tft": 1.4498, "input_0": 81, "input_1": 33, "min_CLP": -4.57, "draft_iters": 10.5, "mem_use": 34.61, "gen_rate": 8.5, "speed": 6.36, "text": "The appropriate response would b"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.6975, "t1": 0.2688, "tft": 2.7049, "input_0": 68, "input_1": 33, "min_CLP": -4.68, "draft_iters": 6.1, "mem_use": 35.6, "gen_rate": 4.1, "speed": 4.28, "text": "This is a pitch deck for FullVie"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 11, "tree_size": 32, "t0": 0.7657, "t1": 0.29, "tft": 4.1337, "input_0": 73, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.3, "mem_use": 36.36, "gen_rate": 4.9, "speed": 4.6, "text": "\\nI\\'m sorry for the confusion, "}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 0.9, "t1": 0.3, "tft": 4.5753, "input_0": 83, "input_1": 33, "min_CLP": -4.2, "draft_iters": 7.4, "mem_use": 36.53, "gen_rate": 4.7, "speed": 3.94, "text": "It is true that Keras is easier "}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 2, "tree_size": 32, "t0": 3.0, "t1": 0.26, "tft": 2.1463, "input_0": 137, "input_1": 33, "min_CLP": -3.39, "draft_iters": 30.5, "mem_use": 35.27, "gen_rate": 31.0, "speed": 9.51, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.955, "t1": 0.24, "tft": 1.363, "input_0": 130, "input_1": 33, "min_CLP": -3.64, "draft_iters": 31.5, "mem_use": 34.66, "gen_rate": 32.0, "speed": 10.01, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.4, "tree_w": 16, "tree_size": 32, "t0": 0.615, "t1": 0.27, "tft": 2.8595, "input_0": 61, "input_1": 33, "min_CLP": -4.74, "draft_iters": 5.4, "mem_use": 35.64, "gen_rate": 3.2, "speed": 3.62, "text": "\\nThe egg is a very hard to cook"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 13, "tree_size": 32, "t0": 0.6422, "t1": 0.28, "tft": 3.4122, "input_0": 63, "input_1": 33, "min_CLP": -4.59, "draft_iters": 5.3, "mem_use": 36.06, "gen_rate": 3.7, "speed": 3.97, "text": "[The battle begins. The Spartans"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.682, "t1": 0.25, "tft": 1.5161, "input_0": 62, "input_1": 33, "min_CLP": -4.47, "draft_iters": 6.2, "mem_use": 34.97, "gen_rate": 3.6, "speed": 3.87, "text": "\"So you think that it's not easy"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 15.5, "tree_w": 5, "tree_size": 32, "t0": 1.7025, "t1": 0.2425, "tft": 1.6838, "input_0": 117, "input_1": 33, "min_CLP": -4.85, "draft_iters": 16.5, "mem_use": 34.8, "gen_rate": 12.0, "speed": 6.17, "text": "\\n[SYS]\\n[\\\\INST]\\n[SYS]\\n[\\\\INS"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 9, "tree_h": 4.3, "tree_w": 14, "tree_size": 32, "t0": 0.5967, "t1": 0.2467, "tft": 1.5719, "input_0": 55, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.3, "mem_use": 34.82, "gen_rate": 3.0, "speed": 3.57, "text": "\\nI meant that someone else woul"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.7388, "t1": 0.29, "tft": 4.0452, "input_0": 73, "input_1": 33, "min_CLP": -4.53, "draft_iters": 6.2, "mem_use": 36.29, "gen_rate": 4.1, "speed": 4.01, "text": "Like all pointers, a void pointe"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.8117, "t1": 0.2817, "tft": 3.8829, "input_0": 74, "input_1": 33, "min_CLP": -4.45, "draft_iters": 7.0, "mem_use": 36.12, "gen_rate": 5.3, "speed": 4.87, "text": "\"Hello Mike, I'm sorry to hear t"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.0, "tree_w": 13, "tree_size": 32, "t0": 0.5967, "t1": 0.27, "tft": 2.7039, "input_0": 63, "input_1": 33, "min_CLP": -4.43, "draft_iters": 5.0, "mem_use": 35.76, "gen_rate": 3.6, "speed": 4.1, "text": "\"This is a great question, and i"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 3, "tree_size": 32, "t0": 2.38, "t1": 0.24, "tft": 1.3652, "input_0": 105, "input_1": 33, "min_CLP": -4.36, "draft_iters": 25.0, "mem_use": 34.82, "gen_rate": 25.5, "speed": 9.71, "text": "[INST]<<SYS>>\\nYou are a helpful"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.955, "t1": 0.24, "tft": 1.342, "input_0": 131, "input_1": 33, "min_CLP": -3.48, "draft_iters": 31.5, "mem_use": 34.44, "gen_rate": 32.0, "speed": 10.02, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.0, "tree_w": 3, "tree_size": 32, "t0": 2.115, "t1": 0.27, "tft": 2.7766, "input_0": 129, "input_1": 33, "min_CLP": -3.81, "draft_iters": 20.0, "mem_use": 35.67, "gen_rate": 17.5, "speed": 7.34, "text": "\"Certainly, here's a table of th"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.5727, "t1": 0.24, "tft": 1.4345, "input_0": 57, "input_1": 33, "min_CLP": -4.86, "draft_iters": 5.2, "mem_use": 34.78, "gen_rate": 3.2, "speed": 3.93, "text": "\\nI would like to thank to all t"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.7014, "t1": 0.2686, "tft": 2.8795, "input_0": 68, "input_1": 33, "min_CLP": -4.7, "draft_iters": 6.1, "mem_use": 35.57, "gen_rate": 4.7, "speed": 4.88, "text": "\"\\nA man walks into a bar and or"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.782, "t1": 0.26, "tft": 2.7429, "input_0": 77, "input_1": 33, "min_CLP": -4.29, "draft_iters": 7.0, "mem_use": 35.51, "gen_rate": 6.4, "speed": 6.12, "text": "\"\\nTaleb's writing style has bee"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.5727, "t1": 0.24, "tft": 1.3285, "input_0": 57, "input_1": 33, "min_CLP": -4.7, "draft_iters": 5.2, "mem_use": 34.7, "gen_rate": 3.0, "speed": 3.7, "text": "\\nThe answer to this question is"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.7844, "t1": 0.24, "tft": 1.1942, "input_0": 68, "input_1": 33, "min_CLP": -4.59, "draft_iters": 7.2, "mem_use": 34.6, "gen_rate": 3.6, "speed": 3.47, "text": "The timezone is based on your cu"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.4, "tree_w": 15, "tree_size": 32, "t0": 0.6667, "t1": 0.24, "tft": 1.2371, "input_0": 54, "input_1": 33, "min_CLP": -4.73, "draft_iters": 6.4, "mem_use": 34.61, "gen_rate": 3.9, "speed": 4.28, "text": "\"\\nYou can't trust the internet!"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 24.7, "tree_w": 4, "tree_size": 32, "t0": 2.4333, "t1": 0.24, "tft": 1.9509, "input_0": 109, "input_1": 33, "min_CLP": -4.58, "draft_iters": 25.7, "mem_use": 34.47, "gen_rate": 16.7, "speed": 6.23, "text": "\\nSuppose I have 12 eggs. I drop"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 10, "tree_size": 32, "t0": 0.8529, "t1": 0.25, "tft": 2.1615, "input_0": 79, "input_1": 33, "min_CLP": -4.33, "draft_iters": 7.7, "mem_use": 34.86, "gen_rate": 4.6, "speed": 4.15, "text": "The Sieve of Eratosthenes is an "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 19, "tree_h": 4.7, "tree_w": 13, "tree_size": 32, "t0": 0.625, "t1": 0.24, "tft": 1.2513, "input_0": 62, "input_1": 33, "min_CLP": -4.57, "draft_iters": 5.7, "mem_use": 34.64, "gen_rate": 3.2, "speed": 3.65, "text": "\"It's probably spoiled. If you s"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 21.5, "tree_w": 3, "tree_size": 32, "t0": 2.185, "t1": 0.24, "tft": 1.4027, "input_0": 115, "input_1": 33, "min_CLP": -4.27, "draft_iters": 22.5, "mem_use": 34.49, "gen_rate": 17.0, "speed": 7.0, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 14, "tree_size": 32, "t0": 0.6756, "t1": 0.2478, "tft": 1.8008, "input_0": 64, "input_1": 33, "min_CLP": -4.55, "draft_iters": 6.2, "mem_use": 34.8, "gen_rate": 3.6, "speed": 3.86, "text": "The ability to recognize faces, "}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 1.0817, "t1": 0.26, "tft": 2.2354, "input_0": 82, "input_1": 33, "min_CLP": -3.87, "draft_iters": 10.0, "mem_use": 35.35, "gen_rate": 6.0, "speed": 4.46, "text": "\"AI assistants can help individu"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 10, "tree_size": 32, "t0": 1.0567, "t1": 0.275, "tft": 3.7131, "input_0": 65, "input_1": 33, "min_CLP": -4.71, "draft_iters": 10.2, "mem_use": 35.86, "gen_rate": 5.8, "speed": 4.38, "text": "\"\\n[Verse 4]\\nI'm a survivor, I'"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 10, "tree_size": 32, "t0": 0.7486, "t1": 0.2529, "tft": 1.8587, "input_0": 84, "input_1": 33, "min_CLP": -4.36, "draft_iters": 6.4, "mem_use": 35.14, "gen_rate": 4.9, "speed": 4.85, "text": "Yes, scp is a Unix command, and "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.9, "tree_w": 17, "tree_size": 32, "t0": 0.566, "t1": 0.266, "tft": 2.7416, "input_0": 55, "input_1": 33, "min_CLP": -4.83, "draft_iters": 4.9, "mem_use": 35.57, "gen_rate": 3.3, "speed": 3.97, "text": "\\nI have a question about a drea"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.4, "tree_w": 5, "tree_size": 32, "t0": 1.376, "t1": 0.24, "tft": 1.335, "input_0": 91, "input_1": 33, "min_CLP": -4.31, "draft_iters": 13.4, "mem_use": 34.74, "gen_rate": 7.6, "speed": 4.7, "text": "\\nIf you found a dollar bill on "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.9383, "t1": 0.24, "tft": 1.3976, "input_0": 88, "input_1": 33, "min_CLP": -3.99, "draft_iters": 8.5, "mem_use": 34.61, "gen_rate": 5.8, "speed": 4.94, "text": "Melbourne is the largest city in"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 8.0, "tree_w": 11, "tree_size": 32, "t0": 0.9457, "t1": 0.2429, "tft": 1.6499, "input_0": 72, "input_1": 33, "min_CLP": -4.76, "draft_iters": 9.0, "mem_use": 34.73, "gen_rate": 6.1, "speed": 5.16, "text": "\\nThe most dangerous thing in a "}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 3, "tree_size": 32, "t0": 2.615, "t1": 0.24, "tft": 1.1848, "input_0": 117, "input_1": 33, "min_CLP": -4.81, "draft_iters": 28.0, "mem_use": 34.59, "gen_rate": 28.5, "speed": 9.97, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.0, "tree_w": 13, "tree_size": 32, "t0": 0.5544, "t1": 0.24, "tft": 1.3718, "input_0": 57, "input_1": 33, "min_CLP": -4.71, "draft_iters": 5.0, "mem_use": 34.47, "gen_rate": 3.9, "speed": 4.89, "text": "\"\\nI need to learn German. I hav"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 16, "tree_size": 32, "t0": 0.6487, "t1": 0.24, "tft": 1.3346, "input_0": 59, "input_1": 33, "min_CLP": -4.66, "draft_iters": 6.1, "mem_use": 34.46, "gen_rate": 4.4, "speed": 4.93, "text": "\\nA:\\n\\nIt would take you about "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.5, "tree_w": 4, "tree_size": 32, "t0": 1.585, "t1": 0.26, "tft": 2.839, "input_0": 123, "input_1": 33, "min_CLP": -3.66, "draft_iters": 14.5, "mem_use": 35.3, "gen_rate": 9.5, "speed": 5.15, "text": "\"In order to understand Fermat's"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.0, "tree_w": 15, "tree_size": 32, "t0": 0.5564, "t1": 0.24, "tft": 1.51, "input_0": 58, "input_1": 33, "min_CLP": -4.8, "draft_iters": 5.0, "mem_use": 34.6, "gen_rate": 3.1, "speed": 3.88, "text": "\"\\nI've a few months to do some "}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 13.8, "tree_w": 9, "tree_size": 32, "t0": 1.475, "t1": 0.24, "tft": 1.4663, "input_0": 96, "input_1": 33, "min_CLP": -4.52, "draft_iters": 14.5, "mem_use": 34.62, "gen_rate": 14.8, "speed": 8.59, "text": "\\nI would like to know how to cr"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.7, "tree_w": 15, "tree_size": 32, "t0": 0.5267, "t1": 0.24, "tft": 1.3582, "input_0": 57, "input_1": 33, "min_CLP": -4.53, "draft_iters": 4.7, "mem_use": 34.44, "gen_rate": 3.9, "speed": 5.08, "text": "\\nI have been playing guitar for"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.7, "tree_w": 12, "tree_size": 32, "t0": 0.644, "t1": 0.24, "tft": 1.1747, "input_0": 70, "input_1": 33, "min_CLP": -4.63, "draft_iters": 5.7, "mem_use": 34.6, "gen_rate": 3.6, "speed": 4.07, "text": "\\nObi-Wan Kenobi, Master of the "}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.6775, "t1": 0.24, "tft": 1.3878, "input_0": 65, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.1, "mem_use": 34.53, "gen_rate": 4.6, "speed": 5.04, "text": "Rifle: A firearm that is held by"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.4, "tree_w": 15, "tree_size": 32, "t0": 0.6655, "t1": 0.24, "tft": 1.3729, "input_0": 54, "input_1": 33, "min_CLP": -4.71, "draft_iters": 6.4, "mem_use": 34.66, "gen_rate": 3.0, "speed": 3.31, "text": "\\nYou are a kind and considerate"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.8, "tree_w": 11, "tree_size": 32, "t0": 0.9133, "t1": 0.2967, "tft": 4.0407, "input_0": 80, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.8, "mem_use": 36.49, "gen_rate": 4.2, "speed": 3.49, "text": "\"Sure. There are several Markdow"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.7667, "t1": 0.24, "tft": 1.3869, "input_0": 71, "input_1": 33, "min_CLP": -4.7, "draft_iters": 7.0, "mem_use": 35.18, "gen_rate": 4.3, "speed": 4.3, "text": "Yes, absolutely.\\n[INST] If some"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.86, "t1": 0.2883, "tft": 4.0177, "input_0": 69, "input_1": 33, "min_CLP": -4.46, "draft_iters": 7.3, "mem_use": 36.18, "gen_rate": 5.5, "speed": 4.8, "text": "\\nCan you please be more specifi"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 4.6, "tree_w": 14, "tree_size": 32, "t0": 0.62, "t1": 0.25, "tft": 1.5815, "input_0": 63, "input_1": 33, "min_CLP": -4.62, "draft_iters": 5.6, "mem_use": 35.02, "gen_rate": 2.8, "speed": 3.27, "text": "\"I'm glad you checked. I'm sure "}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.7, "tree_w": 6, "tree_size": 32, "t0": 1.98, "t1": 0.24, "tft": 1.2407, "input_0": 99, "input_1": 33, "min_CLP": -4.24, "draft_iters": 20.7, "mem_use": 34.63, "gen_rate": 12.0, "speed": 5.4, "text": "A decorator is a special type of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 14, "tree_size": 32, "t0": 0.6625, "t1": 0.26, "tft": 2.0609, "input_0": 58, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.0, "mem_use": 35.31, "gen_rate": 4.1, "speed": 4.47, "text": "\\nI am sorry, but I cannot compi"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.7537, "t1": 0.24, "tft": 1.6635, "input_0": 74, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.9, "mem_use": 34.61, "gen_rate": 4.1, "speed": 4.15, "text": "There are many different methods"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.7729, "t1": 0.27, "tft": 2.6753, "input_0": 79, "input_1": 33, "min_CLP": -4.33, "draft_iters": 6.6, "mem_use": 35.64, "gen_rate": 4.6, "speed": 4.39, "text": "\"There are many ways to attract "}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.9, "tree_w": 14, "tree_size": 32, "t0": 0.655, "t1": 0.2487, "tft": 1.688, "input_0": 62, "input_1": 33, "min_CLP": -4.74, "draft_iters": 5.9, "mem_use": 34.92, "gen_rate": 4.6, "speed": 5.12, "text": "I hope you can answer this quest"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.2, "tree_w": 13, "tree_size": 32, "t0": 0.772, "t1": 0.24, "tft": 1.5565, "input_0": 70, "input_1": 33, "min_CLP": -5.04, "draft_iters": 7.2, "mem_use": 34.71, "gen_rate": 3.2, "speed": 3.15, "text": "\\nWrite an essay on how Shakespe"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.6, "tree_w": 10, "tree_size": 32, "t0": 0.98, "t1": 0.244, "tft": 1.4259, "input_0": 68, "input_1": 33, "min_CLP": -4.46, "draft_iters": 9.6, "mem_use": 34.79, "gen_rate": 7.4, "speed": 6.04, "text": "The most popular APIs are the on"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 23.0, "tree_w": 2, "tree_size": 32, "t0": 2.56, "t1": 0.26, "tft": 3.2151, "input_0": 175, "input_1": 33, "min_CLP": -4.06, "draft_iters": 24.0, "mem_use": 35.44, "gen_rate": 19.5, "speed": 6.9, "text": "\"Tolkien's Quenya is a fictional"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 12, "tree_size": 32, "t0": 0.74, "t1": 0.24, "tft": 1.3498, "input_0": 75, "input_1": 33, "min_CLP": -4.92, "draft_iters": 6.7, "mem_use": 34.7, "gen_rate": 4.7, "speed": 4.82, "text": "\\nWhat is the main difference be"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.1, "tree_w": 16, "tree_size": 32, "t0": 0.5611, "t1": 0.24, "tft": 1.2541, "input_0": 56, "input_1": 33, "min_CLP": -4.9, "draft_iters": 5.1, "mem_use": 34.45, "gen_rate": 3.6, "speed": 4.44, "text": "\\nWhen I run it, I get the follo"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 9.6, "tree_w": 10, "tree_size": 32, "t0": 1.0825, "t1": 0.2538, "tft": 1.9742, "input_0": 70, "input_1": 33, "min_CLP": -4.69, "draft_iters": 10.6, "mem_use": 35.15, "gen_rate": 4.8, "speed": 3.55, "text": "\\nMy name is Luna. I am a robot."}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.0, "tree_w": 10, "tree_size": 32, "t0": 0.9486, "t1": 0.2471, "tft": 1.5781, "input_0": 73, "input_1": 33, "min_CLP": -4.44, "draft_iters": 9.0, "mem_use": 34.79, "gen_rate": 5.3, "speed": 4.43, "text": "The `@` symbol is used in Python"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.6688, "t1": 0.25, "tft": 1.4899, "input_0": 64, "input_1": 33, "min_CLP": -4.4, "draft_iters": 6.0, "mem_use": 34.85, "gen_rate": 4.2, "speed": 4.64, "text": "You can do this by creating a fi"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.76, "t1": 0.27, "tft": 2.7034, "input_0": 75, "input_1": 33, "min_CLP": -4.29, "draft_iters": 6.6, "mem_use": 35.73, "gen_rate": 4.9, "speed": 4.72, "text": "\"It's great that your friends ar"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 62, "tree_h": 19.4, "tree_w": 5, "tree_size": 32, "t0": 1.926, "t1": 0.244, "tft": 1.7825, "input_0": 96, "input_1": 33, "min_CLP": -4.0, "draft_iters": 20.0, "mem_use": 34.81, "gen_rate": 12.4, "speed": 5.71, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 6, "tree_size": 32, "t0": 2.25, "t1": 0.26, "tft": 2.5082, "input_0": 102, "input_1": 33, "min_CLP": -3.67, "draft_iters": 23.0, "mem_use": 35.35, "gen_rate": 23.0, "speed": 9.16, "text": "\\nThe longest amount of time we "}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 3, "tree_size": 32, "t0": 2.22, "t1": 0.24, "tft": 1.3499, "input_0": 120, "input_1": 33, "min_CLP": -4.59, "draft_iters": 22.5, "mem_use": 34.65, "gen_rate": 23.0, "speed": 9.37, "text": "\\nCan you think and feel like a "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 17.0, "tree_w": 4, "tree_size": 32, "t0": 1.7475, "t1": 0.24, "tft": 2.479, "input_0": 99, "input_1": 33, "min_CLP": -4.36, "draft_iters": 18.0, "mem_use": 34.55, "gen_rate": 14.2, "speed": 7.17, "text": "[INST] Attention mechanism,\\nSof"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.67, "t1": 0.24, "tft": 1.2541, "input_0": 67, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.1, "mem_use": 34.68, "gen_rate": 2.9, "speed": 3.19, "text": "This is not a compliment, but it"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.8278, "t1": 0.2644, "tft": 3.063, "input_0": 74, "input_1": 33, "min_CLP": -4.54, "draft_iters": 7.3, "mem_use": 35.55, "gen_rate": 3.9, "speed": 3.56, "text": "I am the sun, I am the fire,\\nI "}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 10, "tree_size": 32, "t0": 0.9383, "t1": 0.2433, "tft": 1.7339, "input_0": 75, "input_1": 33, "min_CLP": -4.44, "draft_iters": 8.8, "mem_use": 34.78, "gen_rate": 5.5, "speed": 4.65, "text": "\"\\nwhat does lithium do to the b"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 12, "tree_size": 32, "t0": 1.36, "t1": 0.24, "tft": 1.3632, "input_0": 72, "input_1": 33, "min_CLP": -4.58, "draft_iters": 14.3, "mem_use": 34.45, "gen_rate": 12.3, "speed": 7.7, "text": "\\n* <SYS>\\n\\nYou are a helpful, "}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 0.83, "t1": 0.24, "tft": 2.0841, "input_0": 81, "input_1": 33, "min_CLP": -4.48, "draft_iters": 7.4, "mem_use": 34.44, "gen_rate": 4.9, "speed": 4.55, "text": "\"\\nPresident's Day is a holiday "}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 15.5, "tree_w": 6, "tree_size": 32, "t0": 1.6375, "t1": 0.24, "tft": 1.4014, "input_0": 90, "input_1": 33, "min_CLP": -4.71, "draft_iters": 16.5, "mem_use": 34.6, "gen_rate": 10.5, "speed": 5.59, "text": "\\nWhich of the following is a ph"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.0, "tree_w": 5, "tree_size": 32, "t0": 1.6167, "t1": 0.25, "tft": 2.4477, "input_0": 102, "input_1": 33, "min_CLP": -4.24, "draft_iters": 16.0, "mem_use": 34.98, "gen_rate": 11.3, "speed": 6.07, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 12, "tree_size": 32, "t0": 0.89, "t1": 0.24, "tft": 1.6762, "input_0": 68, "input_1": 33, "min_CLP": -4.69, "draft_iters": 8.6, "mem_use": 34.64, "gen_rate": 4.9, "speed": 4.29, "text": "\"Why did the windows break?     "}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 13, "tree_size": 32, "t0": 0.7025, "t1": 0.24, "tft": 1.3461, "input_0": 61, "input_1": 33, "min_CLP": -4.67, "draft_iters": 6.6, "mem_use": 34.67, "gen_rate": 4.0, "speed": 4.23, "text": "\\nDo you have any opinions on th"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 6.8, "tree_w": 12, "tree_size": 32, "t0": 0.8178, "t1": 0.24, "tft": 1.3217, "input_0": 71, "input_1": 33, "min_CLP": -4.51, "draft_iters": 7.8, "mem_use": 34.44, "gen_rate": 4.4, "speed": 4.21, "text": "Does the ATF have the right to s"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.0, "tree_w": 15, "tree_size": 32, "t0": 0.5589, "t1": 0.2444, "tft": 1.6816, "input_0": 58, "input_1": 33, "min_CLP": -4.57, "draft_iters": 5.0, "mem_use": 34.79, "gen_rate": 3.7, "speed": 4.57, "text": "\"yeah, like, whatever, Ted. like"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.0, "tree_w": 7, "tree_size": 32, "t0": 1.84, "t1": 0.24, "tft": 1.3302, "input_0": 91, "input_1": 33, "min_CLP": -4.62, "draft_iters": 19.5, "mem_use": 34.5, "gen_rate": 19.5, "speed": 9.39, "text": "\\n<SYS>\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.6, "tree_w": 14, "tree_size": 32, "t0": 0.6178, "t1": 0.25, "tft": 1.7611, "input_0": 57, "input_1": 33, "min_CLP": -4.52, "draft_iters": 5.6, "mem_use": 35.12, "gen_rate": 3.7, "speed": 4.21, "text": "\"I'm not sure I understand what "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.8614, "t1": 0.24, "tft": 1.1643, "input_0": 75, "input_1": 33, "min_CLP": -4.49, "draft_iters": 8.0, "mem_use": 34.67, "gen_rate": 4.9, "speed": 4.4, "text": "No.\\n[INST] What will be your fa"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.1, "tree_w": 10, "tree_size": 32, "t0": 0.9929, "t1": 0.26, "tft": 2.1704, "input_0": 84, "input_1": 33, "min_CLP": -4.24, "draft_iters": 9.1, "mem_use": 35.3, "gen_rate": 4.9, "speed": 3.89, "text": "If you are a beginner hiker, you"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 21.0, "tree_w": 4, "tree_size": 32, "t0": 2.13, "t1": 0.24, "tft": 1.5111, "input_0": 111, "input_1": 33, "min_CLP": -4.42, "draft_iters": 22.0, "mem_use": 34.64, "gen_rate": 22.0, "speed": 9.27, "text": "[INST]\\n[INST]\\n[INST]\\n[INST]\\n"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.2, "tree_w": 13, "tree_size": 32, "t0": 0.85, "t1": 0.24, "tft": 1.3177, "input_0": 65, "input_1": 33, "min_CLP": -4.68, "draft_iters": 8.2, "mem_use": 34.6, "gen_rate": 3.7, "speed": 3.37, "text": "How do you get the two sons of B"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.9586, "t1": 0.2729, "tft": 3.1728, "input_0": 82, "input_1": 33, "min_CLP": -4.4, "draft_iters": 8.4, "mem_use": 35.87, "gen_rate": 5.6, "speed": 4.52, "text": "The derivative of a function f(x"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.7, "tree_w": 11, "tree_size": 32, "t0": 0.9114, "t1": 0.24, "tft": 1.2323, "input_0": 70, "input_1": 33, "min_CLP": -4.58, "draft_iters": 8.7, "mem_use": 34.89, "gen_rate": 4.9, "speed": 4.22, "text": "\\n[INST] <<SYS>>\\nYes, you can. "}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.4, "tree_w": 15, "tree_size": 32, "t0": 0.601, "t1": 0.24, "tft": 1.641, "input_0": 59, "input_1": 33, "min_CLP": -4.61, "draft_iters": 5.4, "mem_use": 34.7, "gen_rate": 3.5, "speed": 4.14, "text": "\"Pirating video games is wrong. "}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.0, "tree_w": 12, "tree_size": 32, "t0": 0.85, "t1": 0.24, "tft": 1.5407, "input_0": 71, "input_1": 33, "min_CLP": -4.67, "draft_iters": 8.0, "mem_use": 34.53, "gen_rate": 4.6, "speed": 4.25, "text": "It matters because the pan is al"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.7389, "t1": 0.24, "tft": 1.3336, "input_0": 64, "input_1": 33, "min_CLP": -4.66, "draft_iters": 7.0, "mem_use": 34.44, "gen_rate": 4.1, "speed": 4.2, "text": "\"\\nI'm looking for the best libr"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.7075, "t1": 0.26, "tft": 2.3878, "input_0": 72, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.1, "mem_use": 35.5, "gen_rate": 4.1, "speed": 4.25, "text": "\"With a video message, it's impo"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.9, "tree_w": 16, "tree_size": 32, "t0": 0.73, "t1": 0.24, "tft": 1.3144, "input_0": 65, "input_1": 33, "min_CLP": -5.26, "draft_iters": 6.9, "mem_use": 34.7, "gen_rate": 4.9, "speed": 5.02, "text": "Is it possible to buy something "}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 8.3, "tree_w": 10, "tree_size": 32, "t0": 0.9714, "t1": 0.24, "tft": 1.5252, "input_0": 77, "input_1": 33, "min_CLP": -4.81, "draft_iters": 9.3, "mem_use": 34.46, "gen_rate": 6.0, "speed": 4.96, "text": "\"\\nWhat is the definition of the"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.7027, "t1": 0.28, "tft": 3.4083, "input_0": 69, "input_1": 33, "min_CLP": -4.46, "draft_iters": 5.9, "mem_use": 36.04, "gen_rate": 3.2, "speed": 3.23, "text": "I am not familiar enough with in"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 53, "tree_h": 6.0, "tree_w": 13, "tree_size": 32, "t0": 0.7611, "t1": 0.25, "tft": 1.9726, "input_0": 66, "input_1": 33, "min_CLP": -4.62, "draft_iters": 7.0, "mem_use": 35.11, "gen_rate": 5.9, "speed": 5.8, "text": "\"I understand that you are an AI"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 11, "tree_size": 32, "t0": 0.8229, "t1": 0.24, "tft": 1.3787, "input_0": 72, "input_1": 33, "min_CLP": -4.46, "draft_iters": 7.7, "mem_use": 34.59, "gen_rate": 4.9, "speed": 4.57, "text": "\\nDo you want to be a better wor"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 5, "tree_size": 32, "t0": 2.17, "t1": 0.24, "tft": 1.4555, "input_0": 117, "input_1": 33, "min_CLP": -4.7, "draft_iters": 22.5, "mem_use": 34.55, "gen_rate": 23.0, "speed": 9.55, "text": "\\n<SYS>\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 13.1, "tree_w": 5, "tree_size": 32, "t0": 1.4157, "t1": 0.24, "tft": 1.3596, "input_0": 89, "input_1": 33, "min_CLP": -4.46, "draft_iters": 14.1, "mem_use": 34.44, "gen_rate": 4.7, "speed": 2.85, "text": "\\nexplain what asexual reproduct"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 54, "tree_h": 21.8, "tree_w": 5, "tree_size": 32, "t0": 2.21, "t1": 0.2475, "tft": 1.4974, "input_0": 114, "input_1": 33, "min_CLP": -3.95, "draft_iters": 22.8, "mem_use": 34.86, "gen_rate": 13.5, "speed": 5.49, "text": "\"I'm sorry, I don't quite unders"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 21.0, "tree_w": 5, "tree_size": 32, "t0": 2.1, "t1": 0.25, "tft": 3.5576, "input_0": 90, "input_1": 33, "min_CLP": -4.37, "draft_iters": 22.0, "mem_use": 34.99, "gen_rate": 22.0, "speed": 9.38, "text": "\\nAqu\u00ed tienes tu respuesta esper"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.95, "t1": 0.3, "tft": 4.845, "input_0": 89, "input_1": 33, "min_CLP": -4.16, "draft_iters": 7.7, "mem_use": 36.74, "gen_rate": 5.3, "speed": 4.26, "text": "\\nStep 2 \u2014 Writing the TypeScrip"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.67, "t1": 0.24, "tft": 1.3717, "input_0": 63, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.1, "mem_use": 35.32, "gen_rate": 3.6, "speed": 3.91, "text": "\"\\nYou have a problem. And it's "}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.5, "tree_w": 14, "tree_size": 32, "t0": 0.62, "t1": 0.243, "tft": 1.5571, "input_0": 64, "input_1": 33, "min_CLP": -4.76, "draft_iters": 5.5, "mem_use": 34.74, "gen_rate": 3.4, "speed": 3.93, "text": "The city is well-known for a num"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 56, "tree_h": 27.0, "tree_w": 4, "tree_size": 32, "t0": 2.58, "t1": 0.24, "tft": 1.8549, "input_0": 110, "input_1": 33, "min_CLP": -3.87, "draft_iters": 27.5, "mem_use": 34.46, "gen_rate": 28.0, "speed": 9.95, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.5, "tree_w": 7, "tree_size": 32, "t0": 1.78, "t1": 0.27, "tft": 2.6928, "input_0": 79, "input_1": 33, "min_CLP": -4.45, "draft_iters": 18.5, "mem_use": 35.69, "gen_rate": 18.0, "speed": 8.8, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.0, "tree_w": 14, "tree_size": 32, "t0": 0.5556, "t1": 0.24, "tft": 1.181, "input_0": 56, "input_1": 33, "min_CLP": -4.62, "draft_iters": 5.0, "mem_use": 34.79, "gen_rate": 3.9, "speed": 4.9, "text": "\"\\nI love short shorts! They are"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.6922, "t1": 0.2678, "tft": 4.4908, "input_0": 70, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.0, "mem_use": 35.62, "gen_rate": 3.6, "speed": 3.71, "text": "This could be a potential proble"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.9, "tree_w": 13, "tree_size": 32, "t0": 0.56, "t1": 0.24, "tft": 1.3255, "input_0": 63, "input_1": 33, "min_CLP": -4.82, "draft_iters": 4.9, "mem_use": 34.75, "gen_rate": 3.9, "speed": 4.86, "text": "\"The need for an AI assistant is"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.92, "t1": 0.24, "tft": 3.154, "input_0": 102, "input_1": 33, "min_CLP": -2.19, "draft_iters": 32.0, "mem_use": 34.45, "gen_rate": 33.0, "speed": 10.44, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.8, "tree_w": 12, "tree_size": 32, "t0": 0.7283, "t1": 0.24, "tft": 1.4533, "input_0": 68, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.8, "mem_use": 34.49, "gen_rate": 5.5, "speed": 5.68, "text": "\\nCan you describe a time when y"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.5, "tree_w": 14, "tree_size": 32, "t0": 0.6313, "t1": 0.25, "tft": 1.919, "input_0": 69, "input_1": 33, "min_CLP": -4.55, "draft_iters": 5.5, "mem_use": 35.0, "gen_rate": 4.1, "speed": 4.68, "text": "The quality of life in America i"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 14, "tree_size": 32, "t0": 0.6686, "t1": 0.24, "tft": 1.3656, "input_0": 65, "input_1": 33, "min_CLP": -4.79, "draft_iters": 6.0, "mem_use": 34.47, "gen_rate": 4.7, "speed": 5.2, "text": "\\nDo you think that people who a"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 11, "tree_size": 32, "t0": 0.9457, "t1": 0.24, "tft": 1.1973, "input_0": 78, "input_1": 33, "min_CLP": -4.47, "draft_iters": 9.0, "mem_use": 34.59, "gen_rate": 4.7, "speed": 3.98, "text": "\"[INST] Here's a link to an exam"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.1, "tree_w": 10, "tree_size": 32, "t0": 0.8586, "t1": 0.2429, "tft": 1.7727, "input_0": 73, "input_1": 33, "min_CLP": -4.2, "draft_iters": 8.1, "mem_use": 34.73, "gen_rate": 4.9, "speed": 4.41, "text": "Selective fire is the ability of"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.7, "tree_w": 13, "tree_size": 32, "t0": 0.6327, "t1": 0.24, "tft": 1.4132, "input_0": 64, "input_1": 33, "min_CLP": -4.68, "draft_iters": 5.7, "mem_use": 34.53, "gen_rate": 3.0, "speed": 3.44, "text": "I am a goddess of beauty and lov"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 0.9071, "t1": 0.2586, "tft": 2.1483, "input_0": 77, "input_1": 33, "min_CLP": -4.41, "draft_iters": 8.3, "mem_use": 35.25, "gen_rate": 4.7, "speed": 4.05, "text": "On Windows, you can use the Unix"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 50, "tree_h": 8.2, "tree_w": 15, "tree_size": 32, "t0": 0.9263, "t1": 0.24, "tft": 1.4555, "input_0": 64, "input_1": 33, "min_CLP": -4.58, "draft_iters": 9.2, "mem_use": 34.58, "gen_rate": 6.2, "speed": 5.37, "text": "\\n<SYS>\\nYour response should be"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.8, "tree_w": 14, "tree_size": 32, "t0": 0.6289, "t1": 0.2478, "tft": 1.9219, "input_0": 62, "input_1": 33, "min_CLP": -4.54, "draft_iters": 5.8, "mem_use": 34.87, "gen_rate": 3.7, "speed": 4.19, "text": "Microwave ovens were first inven"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.85, "t1": 0.24, "tft": 1.4714, "input_0": 75, "input_1": 33, "min_CLP": -3.31, "draft_iters": 32.0, "mem_use": 34.51, "gen_rate": 33.0, "speed": 10.67, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.6767, "t1": 0.24, "tft": 1.3619, "input_0": 69, "input_1": 33, "min_CLP": -4.76, "draft_iters": 6.1, "mem_use": 34.43, "gen_rate": 3.9, "speed": 4.25, "text": "\\n<INST>\\n\\nAfter the cat is obs"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 0.9429, "t1": 0.3, "tft": 5.2683, "input_0": 84, "input_1": 33, "min_CLP": -4.22, "draft_iters": 7.6, "mem_use": 36.61, "gen_rate": 5.0, "speed": 4.02, "text": "\"If you're worried about how you"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.8, "tree_w": 14, "tree_size": 32, "t0": 0.5482, "t1": 0.24, "tft": 1.3104, "input_0": 59, "input_1": 33, "min_CLP": -4.76, "draft_iters": 4.8, "mem_use": 35.23, "gen_rate": 3.0, "speed": 3.8, "text": "\\nThe problem with the question "}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.8056, "t1": 0.25, "tft": 1.8666, "input_0": 74, "input_1": 33, "min_CLP": -4.37, "draft_iters": 7.2, "mem_use": 34.98, "gen_rate": 3.6, "speed": 3.37, "text": "It is not possible to travel aro"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.0, "tree_w": 14, "tree_size": 32, "t0": 0.5736, "t1": 0.27, "tft": 2.5496, "input_0": 57, "input_1": 33, "min_CLP": -4.76, "draft_iters": 5.0, "mem_use": 35.64, "gen_rate": 3.0, "speed": 3.57, "text": "\\nYou could make a trap that wil"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.5, "tree_w": 15, "tree_size": 32, "t0": 0.601, "t1": 0.24, "tft": 1.1854, "input_0": 60, "input_1": 33, "min_CLP": -4.73, "draft_iters": 5.5, "mem_use": 34.76, "gen_rate": 3.5, "speed": 4.16, "text": "Sure. I had a friend who was in "}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.84, "t1": 0.24, "tft": 1.3157, "input_0": 64, "input_1": 33, "min_CLP": -4.5, "draft_iters": 8.0, "mem_use": 34.59, "gen_rate": 0.0, "speed": 0.0, "text": "You are welcome."}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.765, "t1": 0.25, "tft": 2.1342, "input_0": 79, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.7, "mem_use": 34.82, "gen_rate": 5.7, "speed": 5.61, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.6378, "t1": 0.24, "tft": 1.2759, "input_0": 62, "input_1": 33, "min_CLP": -4.89, "draft_iters": 5.9, "mem_use": 34.59, "gen_rate": 4.1, "speed": 4.68, "text": "\\nConcepts:\\n\\\\- the black swan "}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.6933, "t1": 0.25, "tft": 2.2438, "input_0": 72, "input_1": 33, "min_CLP": -4.56, "draft_iters": 6.1, "mem_use": 34.94, "gen_rate": 3.6, "speed": 3.77, "text": "A transactional interpretation i"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.4, "tree_w": 13, "tree_size": 32, "t0": 0.683, "t1": 0.24, "tft": 1.3169, "input_0": 60, "input_1": 33, "min_CLP": -4.67, "draft_iters": 6.4, "mem_use": 34.6, "gen_rate": 3.2, "speed": 3.46, "text": "\\nDear University Embosser,\\n\\nI"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.6812, "t1": 0.24, "tft": 1.4504, "input_0": 72, "input_1": 33, "min_CLP": -4.63, "draft_iters": 6.1, "mem_use": 34.45, "gen_rate": 4.4, "speed": 4.74, "text": "\\nA reinforcement learning syste"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 3, "tree_size": 32, "t0": 2.9, "t1": 0.24, "tft": 1.3443, "input_0": 124, "input_1": 33, "min_CLP": -4.04, "draft_iters": 30.5, "mem_use": 34.44, "gen_rate": 31.0, "speed": 9.88, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 21.0, "tree_w": 5, "tree_size": 32, "t0": 2.36, "t1": 0.3067, "tft": 4.5449, "input_0": 104, "input_1": 33, "min_CLP": -4.24, "draft_iters": 22.0, "mem_use": 36.82, "gen_rate": 13.7, "speed": 5.13, "text": "\"\\nPlease implement the Quicksor"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.0, "tree_w": 7, "tree_size": 32, "t0": 1.1329, "t1": 0.24, "tft": 1.576, "input_0": 84, "input_1": 33, "min_CLP": -4.26, "draft_iters": 11.0, "mem_use": 35.34, "gen_rate": 5.1, "speed": 3.75, "text": "There are many applications of J"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.773, "t1": 0.259, "tft": 2.262, "input_0": 74, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.9, "mem_use": 35.28, "gen_rate": 3.3, "speed": 3.2, "text": "\\nF-centers are primarily create"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 11, "tree_size": 32, "t0": 0.8371, "t1": 0.2557, "tft": 2.134, "input_0": 78, "input_1": 33, "min_CLP": -4.33, "draft_iters": 7.6, "mem_use": 35.19, "gen_rate": 4.7, "speed": 4.32, "text": "\\n3. Use a third-party tool to c"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.1, "tree_w": 12, "tree_size": 32, "t0": 0.785, "t1": 0.24, "tft": 1.8232, "input_0": 74, "input_1": 33, "min_CLP": -4.79, "draft_iters": 7.1, "mem_use": 34.56, "gen_rate": 5.1, "speed": 5.0, "text": "\\nThe following are examples of "}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 13, "tree_size": 32, "t0": 0.89, "t1": 0.24, "tft": 1.3642, "input_0": 67, "input_1": 33, "min_CLP": -4.92, "draft_iters": 8.7, "mem_use": 34.48, "gen_rate": 4.7, "speed": 4.18, "text": "\\nWhat is the best way to proces"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.5, "tree_w": 13, "tree_size": 32, "t0": 0.6818, "t1": 0.24, "tft": 1.5115, "input_0": 59, "input_1": 33, "min_CLP": -4.64, "draft_iters": 6.5, "mem_use": 34.47, "gen_rate": 2.9, "speed": 3.16, "text": "\\n[INST] <<SYS>>\\nThe best way t"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.3, "tree_w": 13, "tree_size": 32, "t0": 0.7778, "t1": 0.25, "tft": 1.8861, "input_0": 58, "input_1": 33, "min_CLP": -4.67, "draft_iters": 7.3, "mem_use": 34.98, "gen_rate": 3.8, "speed": 3.68, "text": "\\nUser : please tell me more abo"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.668, "t1": 0.24, "tft": 1.4543, "input_0": 64, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.1, "mem_use": 34.63, "gen_rate": 3.2, "speed": 3.52, "text": "\\nQuestion: How can we be sure t"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.2, "tree_w": 7, "tree_size": 32, "t0": 1.7325, "t1": 0.26, "tft": 2.926, "input_0": 94, "input_1": 33, "min_CLP": -3.73, "draft_iters": 17.2, "mem_use": 35.33, "gen_rate": 10.2, "speed": 5.15, "text": "Here is a list of only the femin"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 14, "tree_h": 4.6, "tree_w": 14, "tree_size": 32, "t0": 0.618, "t1": 0.24, "tft": 1.5926, "input_0": 58, "input_1": 33, "min_CLP": -4.71, "draft_iters": 5.6, "mem_use": 34.74, "gen_rate": 2.8, "speed": 3.25, "text": "I would not take their answers s"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.7, "tree_w": 9, "tree_size": 32, "t0": 1.7433, "t1": 0.24, "tft": 1.2423, "input_0": 77, "input_1": 33, "min_CLP": -4.01, "draft_iters": 18.7, "mem_use": 34.65, "gen_rate": 11.0, "speed": 5.54, "text": "Yes, the Bureau of Alcohol, Toba"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.97, "t1": 0.24, "tft": 1.3614, "input_0": 139, "input_1": 33, "min_CLP": -3.87, "draft_iters": 32.0, "mem_use": 34.54, "gen_rate": 33.0, "speed": 10.29, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 2, "tree_size": 32, "t0": 2.485, "t1": 0.28, "tft": 3.4654, "input_0": 120, "input_1": 33, "min_CLP": -4.34, "draft_iters": 24.5, "mem_use": 35.92, "gen_rate": 25.0, "speed": 9.04, "text": "\\nWrite me a Graphic Novel plot "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 1, "tree_size": 32, "t0": 3.055, "t1": 0.28, "tft": 3.7083, "input_0": 113, "input_1": 33, "min_CLP": -4.09, "draft_iters": 31.5, "mem_use": 35.96, "gen_rate": 32.0, "speed": 9.6, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 28.0, "tree_w": 2, "tree_size": 32, "t0": 2.67, "t1": 0.24, "tft": 1.446, "input_0": 119, "input_1": 33, "min_CLP": -4.13, "draft_iters": 28.5, "mem_use": 34.96, "gen_rate": 29.0, "speed": 9.97, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 27.5, "tree_w": 1, "tree_size": 32, "t0": 2.805, "t1": 0.25, "tft": 2.9234, "input_0": 153, "input_1": 33, "min_CLP": -4.33, "draft_iters": 28.0, "mem_use": 35.03, "gen_rate": 25.0, "speed": 8.17, "text": "\\n\"Exciting news, Medium readers"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.87, "t1": 0.26, "tft": 2.2494, "input_0": 74, "input_1": 33, "min_CLP": -4.37, "draft_iters": 8.0, "mem_use": 35.26, "gen_rate": 4.4, "speed": 3.88, "text": "\"\\nThat's exactly the sort of th"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.6736, "t1": 0.24, "tft": 2.0323, "input_0": 68, "input_1": 33, "min_CLP": -4.69, "draft_iters": 6.1, "mem_use": 34.58, "gen_rate": 2.9, "speed": 3.19, "text": "\\nA vector is a scalar number. I"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 6, "tree_size": 32, "t0": 2.165, "t1": 0.24, "tft": 1.3615, "input_0": 102, "input_1": 33, "min_CLP": -4.89, "draft_iters": 22.5, "mem_use": 34.57, "gen_rate": 23.0, "speed": 9.55, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.9, "tree_w": 14, "tree_size": 32, "t0": 0.6656, "t1": 0.26, "tft": 2.6019, "input_0": 64, "input_1": 33, "min_CLP": -4.78, "draft_iters": 5.9, "mem_use": 35.35, "gen_rate": 3.7, "speed": 3.97, "text": "\"\\nThis rumor is completely fals"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.1, "tree_w": 16, "tree_size": 32, "t0": 0.5655, "t1": 0.24, "tft": 1.3619, "input_0": 57, "input_1": 33, "min_CLP": -4.95, "draft_iters": 5.1, "mem_use": 34.65, "gen_rate": 3.2, "speed": 3.95, "text": "\\nA good understanding of how a "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.5, "tree_w": 12, "tree_size": 32, "t0": 0.825, "t1": 0.26, "tft": 2.0777, "input_0": 69, "input_1": 33, "min_CLP": -4.55, "draft_iters": 7.5, "mem_use": 35.31, "gen_rate": 3.7, "speed": 3.41, "text": "\\nThe following should help you "}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.0, "tree_w": 14, "tree_size": 32, "t0": 0.5611, "t1": 0.24, "tft": 1.3255, "input_0": 58, "input_1": 33, "min_CLP": -4.84, "draft_iters": 5.0, "mem_use": 34.61, "gen_rate": 3.8, "speed": 4.74, "text": "\\nI would think it would be simi"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.3, "tree_w": 14, "tree_size": 32, "t0": 0.5718, "t1": 0.24, "tft": 1.3631, "input_0": 59, "input_1": 33, "min_CLP": -4.61, "draft_iters": 5.3, "mem_use": 34.44, "gen_rate": 3.0, "speed": 3.69, "text": "\\nYou need a pan with a good non"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 51, "tree_h": 6.7, "tree_w": 12, "tree_size": 32, "t0": 0.8156, "t1": 0.2444, "tft": 1.4913, "input_0": 70, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.7, "mem_use": 34.79, "gen_rate": 5.7, "speed": 5.35, "text": "\"Ok, I'll start with my version "}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 57, "tree_h": 12.4, "tree_w": 12, "tree_size": 32, "t0": 1.3314, "t1": 0.25, "tft": 1.6182, "input_0": 86, "input_1": 33, "min_CLP": -4.36, "draft_iters": 13.4, "mem_use": 34.95, "gen_rate": 8.1, "speed": 5.15, "text": "\"\\nI don't know, maybe you could"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 8, "tree_size": 32, "t0": 1.0633, "t1": 0.24, "tft": 1.3542, "input_0": 78, "input_1": 33, "min_CLP": -4.25, "draft_iters": 10.3, "mem_use": 34.47, "gen_rate": 5.5, "speed": 4.22, "text": "A. A rifle that shoots AK47 bull"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.9, "t1": 0.24, "tft": 1.6347, "input_0": 91, "input_1": 33, "min_CLP": -3.43, "draft_iters": 32.0, "mem_use": 34.62, "gen_rate": 33.0, "speed": 10.52, "text": "\\nI have two remote Debian serve"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.02, "t1": 0.26, "tft": 2.3857, "input_0": 103, "input_1": 33, "min_CLP": -4.01, "draft_iters": 32.0, "mem_use": 35.34, "gen_rate": 33.0, "speed": 10.07, "text": "Sure, here you go:\\n\\n* Stats mo"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 62, "tree_h": 15.0, "tree_w": 7, "tree_size": 32, "t0": 1.555, "t1": 0.24, "tft": 1.6692, "input_0": 92, "input_1": 33, "min_CLP": -4.05, "draft_iters": 15.8, "mem_use": 34.64, "gen_rate": 15.5, "speed": 8.63, "text": "\\nWhat should I do to start a su"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.7089, "t1": 0.2478, "tft": 1.6798, "input_0": 73, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.2, "mem_use": 34.85, "gen_rate": 3.9, "speed": 4.07, "text": "There is no harm in letting the "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.5855, "t1": 0.24, "tft": 1.3403, "input_0": 59, "input_1": 33, "min_CLP": -4.73, "draft_iters": 5.2, "mem_use": 34.68, "gen_rate": 2.9, "speed": 3.51, "text": "\\nI guess they would appreciate "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 31, "tree_h": 4.7, "tree_w": 14, "tree_size": 32, "t0": 0.6322, "t1": 0.2422, "tft": 1.6085, "input_0": 64, "input_1": 33, "min_CLP": -4.69, "draft_iters": 5.7, "mem_use": 34.74, "gen_rate": 3.4, "speed": 3.93, "text": "User : i am a data scientist\\nAg"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 1.0683, "t1": 0.24, "tft": 1.3598, "input_0": 92, "input_1": 33, "min_CLP": -4.39, "draft_iters": 9.8, "mem_use": 34.43, "gen_rate": 5.3, "speed": 4.08, "text": "\\nWhat is your mood? [\\\\SYS]\\n\\n"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.9, "tree_w": 15, "tree_size": 32, "t0": 0.5536, "t1": 0.24, "tft": 1.268, "input_0": 58, "input_1": 33, "min_CLP": -4.84, "draft_iters": 4.9, "mem_use": 34.43, "gen_rate": 3.1, "speed": 3.91, "text": "\\n<INST>\\n\\nAfter the initial ri"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 13, "tree_size": 32, "t0": 0.7238, "t1": 0.2412, "tft": 1.8561, "input_0": 67, "input_1": 33, "min_CLP": -4.5, "draft_iters": 6.8, "mem_use": 34.73, "gen_rate": 4.1, "speed": 4.26, "text": "\"Theanine may help the body's pr"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.0, "tree_w": 17, "tree_size": 32, "t0": 0.5511, "t1": 0.24, "tft": 2.0907, "input_0": 49, "input_1": 33, "min_CLP": -4.73, "draft_iters": 5.0, "mem_use": 34.58, "gen_rate": 3.7, "speed": 4.64, "text": "\\nThe bot should be able to make"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 26.5, "tree_w": 3, "tree_size": 32, "t0": 2.57, "t1": 0.24, "tft": 1.4283, "input_0": 128, "input_1": 33, "min_CLP": -4.77, "draft_iters": 27.0, "mem_use": 34.48, "gen_rate": 27.5, "speed": 9.79, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.6, "tree_w": 12, "tree_size": 32, "t0": 0.8037, "t1": 0.24, "tft": 1.3413, "input_0": 70, "input_1": 33, "min_CLP": -4.73, "draft_iters": 7.6, "mem_use": 34.46, "gen_rate": 5.1, "speed": 4.92, "text": "\\nWhy do people say that the Uni"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 14, "tree_size": 32, "t0": 0.619, "t1": 0.24, "tft": 1.7656, "input_0": 63, "input_1": 33, "min_CLP": -4.77, "draft_iters": 5.5, "mem_use": 34.7, "gen_rate": 3.3, "speed": 3.83, "text": "The Bliss image is a stylized ve"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.7414, "t1": 0.29, "tft": 4.0518, "input_0": 66, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.1, "mem_use": 36.29, "gen_rate": 4.9, "speed": 4.71, "text": "\"It's not a good idea to use ano"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.7, "tree_w": 15, "tree_size": 32, "t0": 0.554, "t1": 0.27, "tft": 2.5406, "input_0": 57, "input_1": 33, "min_CLP": -4.64, "draft_iters": 4.7, "mem_use": 35.63, "gen_rate": 3.3, "speed": 4.02, "text": "\"\\nI'm sure we did. I can rememb"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.6, "tree_w": 13, "tree_size": 32, "t0": 0.6289, "t1": 0.2444, "tft": 1.5358, "input_0": 64, "input_1": 33, "min_CLP": -4.65, "draft_iters": 5.6, "mem_use": 34.78, "gen_rate": 3.6, "speed": 4.07, "text": "A Dyson Sphere would be very lar"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.4, "tree_w": 13, "tree_size": 32, "t0": 0.603, "t1": 0.24, "tft": 1.3247, "input_0": 63, "input_1": 33, "min_CLP": -4.62, "draft_iters": 5.4, "mem_use": 34.44, "gen_rate": 3.3, "speed": 3.93, "text": "\"\\nI'm looking to get started wi"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 18.5, "tree_w": 5, "tree_size": 32, "t0": 1.865, "t1": 0.24, "tft": 1.4234, "input_0": 95, "input_1": 33, "min_CLP": -4.31, "draft_iters": 19.5, "mem_use": 34.43, "gen_rate": 18.5, "speed": 8.8, "text": "\\nDo you know how to speak Germa"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.88, "t1": 0.24, "tft": 1.4028, "input_0": 86, "input_1": 33, "min_CLP": -3.39, "draft_iters": 32.0, "mem_use": 34.57, "gen_rate": 33.0, "speed": 10.59, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.8529, "t1": 0.25, "tft": 1.921, "input_0": 87, "input_1": 33, "min_CLP": -4.35, "draft_iters": 7.7, "mem_use": 34.98, "gen_rate": 4.6, "speed": 4.16, "text": "If you want to improve the Wi-Fi"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.5, "tree_w": 7, "tree_size": 32, "t0": 1.32, "t1": 0.26, "tft": 2.3162, "input_0": 94, "input_1": 33, "min_CLP": -3.98, "draft_iters": 12.5, "mem_use": 35.29, "gen_rate": 5.3, "speed": 3.38, "text": "Yes, there are several AI tools "}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.7, "tree_w": 17, "tree_size": 32, "t0": 0.529, "t1": 0.24, "tft": 1.4067, "input_0": 57, "input_1": 33, "min_CLP": -4.93, "draft_iters": 4.7, "mem_use": 34.6, "gen_rate": 3.2, "speed": 4.17, "text": "\\nI like it! I think it would be"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 10.7, "tree_w": 7, "tree_size": 32, "t0": 1.2157, "t1": 0.24, "tft": 2.4148, "input_0": 90, "input_1": 33, "min_CLP": -4.24, "draft_iters": 11.7, "mem_use": 34.68, "gen_rate": 6.0, "speed": 4.11, "text": "\"o\\n        |/\\\\\\n        | \\\\\\n"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.3, "tree_w": 4, "tree_size": 32, "t0": 1.7733, "t1": 0.24, "tft": 1.3253, "input_0": 106, "input_1": 33, "min_CLP": -4.77, "draft_iters": 18.3, "mem_use": 34.44, "gen_rate": 12.7, "speed": 6.3, "text": "\\nHow do polar bears stay warm i"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.93, "t1": 0.24, "tft": 1.3278, "input_0": 105, "input_1": 33, "min_CLP": -3.63, "draft_iters": 32.0, "mem_use": 34.6, "gen_rate": 33.0, "speed": 10.41, "text": "\\nIs there a true, most ethical "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 8, "tree_size": 32, "t0": 1.5425, "t1": 0.24, "tft": 1.097, "input_0": 85, "input_1": 33, "min_CLP": -4.39, "draft_iters": 15.8, "mem_use": 34.59, "gen_rate": 8.2, "speed": 4.64, "text": "[INST]\\nI need help from you to "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.72, "t1": 0.27, "tft": 2.6146, "input_0": 74, "input_1": 33, "min_CLP": -4.25, "draft_iters": 6.1, "mem_use": 35.64, "gen_rate": 4.4, "speed": 4.43, "text": "\\n1. Preheat oven to 350\u00b0F.\\n2. "}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.8, "tree_w": 17, "tree_size": 32, "t0": 0.52, "t1": 0.24, "tft": 1.6566, "input_0": 48, "input_1": 33, "min_CLP": -4.81, "draft_iters": 4.8, "mem_use": 34.77, "gen_rate": 3.2, "speed": 4.22, "text": "\\nI have been writing a lot of q"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.8, "tree_w": 15, "tree_size": 32, "t0": 0.573, "t1": 0.28, "tft": 3.4523, "input_0": 58, "input_1": 33, "min_CLP": -4.87, "draft_iters": 4.8, "mem_use": 35.96, "gen_rate": 3.2, "speed": 3.77, "text": "\\nOur heroine is a beautiful you"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 4.2, "tree_w": 16, "tree_size": 32, "t0": 0.5733, "t1": 0.24, "tft": 1.3617, "input_0": 58, "input_1": 33, "min_CLP": -4.92, "draft_iters": 5.2, "mem_use": 34.91, "gen_rate": 2.8, "speed": 3.49, "text": "\\n* <SYS> is a chatbot that will"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.71, "t1": 0.24, "tft": 1.267, "input_0": 69, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.5, "mem_use": 34.43, "gen_rate": 4.4, "speed": 4.62, "text": "\\n<SYS>\\n\\nHTML is the language "}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 8, "tree_size": 32, "t0": 1.87, "t1": 0.24, "tft": 1.4411, "input_0": 83, "input_1": 33, "min_CLP": -4.75, "draft_iters": 20.0, "mem_use": 34.44, "gen_rate": 20.0, "speed": 9.48, "text": "\\nCreate a table with the planet"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.6725, "t1": 0.24, "tft": 1.346, "input_0": 65, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.1, "mem_use": 34.64, "gen_rate": 4.2, "speed": 4.65, "text": "\"The image is free to use, given"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 2, "tree_size": 32, "t0": 2.925, "t1": 0.24, "tft": 1.325, "input_0": 120, "input_1": 33, "min_CLP": -3.4, "draft_iters": 31.0, "mem_use": 34.44, "gen_rate": 31.5, "speed": 9.96, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.775, "t1": 0.25, "tft": 1.757, "input_0": 70, "input_1": 33, "min_CLP": -4.6, "draft_iters": 7.0, "mem_use": 34.97, "gen_rate": 5.5, "speed": 5.35, "text": "\\nHow do the planets orbit the s"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.8, "tree_w": 14, "tree_size": 32, "t0": 0.552, "t1": 0.246, "tft": 1.6622, "input_0": 63, "input_1": 33, "min_CLP": -4.67, "draft_iters": 4.8, "mem_use": 34.82, "gen_rate": 3.5, "speed": 4.38, "text": "\"The only thing that I can think"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 12, "tree_size": 32, "t0": 0.6963, "t1": 0.2412, "tft": 1.3228, "input_0": 66, "input_1": 33, "min_CLP": -4.4, "draft_iters": 6.4, "mem_use": 34.75, "gen_rate": 4.0, "speed": 4.25, "text": "\"\\nI'd say the studio would stil"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.8033, "t1": 0.2511, "tft": 2.037, "input_0": 70, "input_1": 33, "min_CLP": -4.41, "draft_iters": 7.3, "mem_use": 35.12, "gen_rate": 3.7, "speed": 3.48, "text": "\\nI can certainly help you with "}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 17.2, "tree_w": 5, "tree_size": 32, "t0": 1.784, "t1": 0.24, "tft": 2.1288, "input_0": 96, "input_1": 33, "min_CLP": -4.39, "draft_iters": 18.2, "mem_use": 34.52, "gen_rate": 9.4, "speed": 4.64, "text": "\\nMake ASCII art of a cat.\\n\\n<<"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.5, "tree_w": 12, "tree_size": 32, "t0": 0.707, "t1": 0.24, "tft": 1.2789, "input_0": 65, "input_1": 33, "min_CLP": -4.79, "draft_iters": 6.5, "mem_use": 34.59, "gen_rate": 3.4, "speed": 3.6, "text": "<</SYS>\\n\\nWhat is your name? [\\"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 9, "tree_size": 32, "t0": 1.172, "t1": 0.25, "tft": 1.6997, "input_0": 84, "input_1": 33, "min_CLP": -4.41, "draft_iters": 11.4, "mem_use": 34.93, "gen_rate": 7.4, "speed": 5.21, "text": "\"The James Webb Space Telescope "}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.1, "tree_w": 15, "tree_size": 32, "t0": 0.55, "t1": 0.24, "tft": 1.456, "input_0": 53, "input_1": 33, "min_CLP": -4.82, "draft_iters": 5.1, "mem_use": 34.49, "gen_rate": 3.1, "speed": 3.92, "text": "\"\\nIt's a system that ensures th"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 13.5, "tree_w": 9, "tree_size": 32, "t0": 1.4675, "t1": 0.26, "tft": 2.1929, "input_0": 81, "input_1": 33, "min_CLP": -4.16, "draft_iters": 14.5, "mem_use": 35.35, "gen_rate": 12.0, "speed": 6.95, "text": "\"No problem. Here's a modified v"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.3, "tree_w": 13, "tree_size": 32, "t0": 0.7043, "t1": 0.24, "tft": 2.6065, "input_0": 72, "input_1": 33, "min_CLP": -4.72, "draft_iters": 6.3, "mem_use": 34.65, "gen_rate": 4.6, "speed": 4.83, "text": "\\nPuede que te preguntes si es p"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.653, "t1": 0.24, "tft": 1.3803, "input_0": 63, "input_1": 33, "min_CLP": -4.71, "draft_iters": 5.9, "mem_use": 34.67, "gen_rate": 3.6, "speed": 4.02, "text": "\"\\nActually, this is a better qu"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.7314, "t1": 0.26, "tft": 1.957, "input_0": 69, "input_1": 33, "min_CLP": -4.53, "draft_iters": 6.6, "mem_use": 35.32, "gen_rate": 4.7, "speed": 4.77, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.7867, "t1": 0.2622, "tft": 2.5426, "input_0": 71, "input_1": 33, "min_CLP": -4.57, "draft_iters": 6.9, "mem_use": 35.52, "gen_rate": 3.8, "speed": 3.59, "text": "Paul Allen has a large collectio"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.7, "tree_w": 11, "tree_size": 32, "t0": 0.85, "t1": 0.2589, "tft": 1.9983, "input_0": 76, "input_1": 33, "min_CLP": -4.66, "draft_iters": 7.7, "mem_use": 35.22, "gen_rate": 3.9, "speed": 3.52, "text": "Certainly, there are several cas"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.2, "tree_w": 12, "tree_size": 32, "t0": 0.7775, "t1": 0.24, "tft": 1.4026, "input_0": 68, "input_1": 33, "min_CLP": -4.62, "draft_iters": 7.2, "mem_use": 34.56, "gen_rate": 4.0, "speed": 3.93, "text": "\\nRomeo:\\n\\nRomeo is the main ch"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.0, "tree_w": 15, "tree_size": 32, "t0": 0.572, "t1": 0.249, "tft": 1.5648, "input_0": 61, "input_1": 33, "min_CLP": -4.58, "draft_iters": 5.0, "mem_use": 34.8, "gen_rate": 3.2, "speed": 3.91, "text": "\"I'm a Large Language Model, whi"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 12, "tree_size": 32, "t0": 0.9975, "t1": 0.24, "tft": 1.6931, "input_0": 64, "input_1": 33, "min_CLP": -4.46, "draft_iters": 10.0, "mem_use": 34.48, "gen_rate": 8.0, "speed": 6.48, "text": "\\nThe main methods used by car m"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.1, "tree_w": 15, "tree_size": 32, "t0": 0.566, "t1": 0.24, "tft": 1.3235, "input_0": 56, "input_1": 33, "min_CLP": -4.85, "draft_iters": 5.1, "mem_use": 34.43, "gen_rate": 3.4, "speed": 4.23, "text": "\\nA valid question, and one that"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.96, "t1": 0.25, "tft": 1.7053, "input_0": 112, "input_1": 33, "min_CLP": -3.37, "draft_iters": 31.5, "mem_use": 34.85, "gen_rate": 32.0, "speed": 9.98, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.715, "t1": 0.2588, "tft": 2.1373, "input_0": 68, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.2, "mem_use": 35.26, "gen_rate": 4.1, "speed": 4.24, "text": "\"You cannot stop someone's metab"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 11, "tree_size": 32, "t0": 0.8786, "t1": 0.27, "tft": 2.6515, "input_0": 71, "input_1": 33, "min_CLP": -4.32, "draft_iters": 7.9, "mem_use": 35.7, "gen_rate": 4.6, "speed": 3.98, "text": "I\\'m not familiar with the \"mult"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.685, "t1": 0.25, "tft": 1.8631, "input_0": 71, "input_1": 33, "min_CLP": -4.53, "draft_iters": 6.0, "mem_use": 35.0, "gen_rate": 4.0, "speed": 4.28, "text": "\"A completely purple sky is unli"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 0.7929, "t1": 0.25, "tft": 2.0734, "input_0": 70, "input_1": 33, "min_CLP": -4.4, "draft_iters": 7.1, "mem_use": 34.97, "gen_rate": 5.1, "speed": 4.94, "text": "\\nI love you,\\n[INST] <<SYS>>\\nY"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 18.3, "tree_w": 6, "tree_size": 32, "t0": 1.89, "t1": 0.25, "tft": 3.1308, "input_0": 101, "input_1": 33, "min_CLP": -4.08, "draft_iters": 19.3, "mem_use": 34.91, "gen_rate": 16.7, "speed": 7.79, "text": "Here is a list of ten words from"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.4, "tree_w": 11, "tree_size": 32, "t0": 0.7062, "t1": 0.24, "tft": 1.31, "input_0": 67, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.4, "mem_use": 34.58, "gen_rate": 4.5, "speed": 4.75, "text": "\"If you're not in the United Sta"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 18.5, "tree_w": 6, "tree_size": 32, "t0": 1.865, "t1": 0.24, "tft": 1.407, "input_0": 100, "input_1": 33, "min_CLP": -4.39, "draft_iters": 19.5, "mem_use": 34.42, "gen_rate": 16.5, "speed": 7.84, "text": "[INST] <<SYS>>\\n[INST] <<SYS>>\\n"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 1, "tree_size": 32, "t0": 2.925, "t1": 0.24, "tft": 1.7338, "input_0": 137, "input_1": 33, "min_CLP": -4.16, "draft_iters": 31.0, "mem_use": 34.49, "gen_rate": 31.5, "speed": 9.96, "text": "\\nWrite a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.7814, "t1": 0.25, "tft": 1.8898, "input_0": 72, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.9, "mem_use": 35.07, "gen_rate": 4.9, "speed": 4.7, "text": "1. Seek to reduce the financial "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 22.0, "tree_w": 4, "tree_size": 32, "t0": 2.1625, "t1": 0.24, "tft": 1.3506, "input_0": 103, "input_1": 33, "min_CLP": -4.19, "draft_iters": 22.8, "mem_use": 34.5, "gen_rate": 10.5, "speed": 4.37, "text": "[\\\\INST] <<SYS>>\\n[INST] You are"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.7729, "t1": 0.2714, "tft": 3.1421, "input_0": 68, "input_1": 33, "min_CLP": -4.31, "draft_iters": 6.7, "mem_use": 35.85, "gen_rate": 5.6, "speed": 5.33, "text": "Sets are used to store unique ob"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.86, "t1": 0.24, "tft": 1.3963, "input_0": 87, "input_1": 33, "min_CLP": -3.53, "draft_iters": 32.0, "mem_use": 34.89, "gen_rate": 33.0, "speed": 10.63, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 15, "tree_size": 32, "t0": 0.7329, "t1": 0.24, "tft": 1.4318, "input_0": 64, "input_1": 33, "min_CLP": -4.93, "draft_iters": 7.0, "mem_use": 34.46, "gen_rate": 4.7, "speed": 4.85, "text": "\\nWhat are the names of the two "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.13, "t1": 0.27, "tft": 5.1142, "input_0": 134, "input_1": 33, "min_CLP": -3.54, "draft_iters": 32.0, "mem_use": 35.62, "gen_rate": 33.0, "speed": 9.7, "text": "Monstermash.zone: offers a free "}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.5, "tree_w": 14, "tree_size": 32, "t0": 0.5873, "t1": 0.24, "tft": 1.3455, "input_0": 58, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.5, "mem_use": 34.8, "gen_rate": 3.0, "speed": 3.63, "text": "\\nA drone is a small, unmanned a"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.7586, "t1": 0.2486, "tft": 2.3933, "input_0": 72, "input_1": 33, "min_CLP": -4.62, "draft_iters": 6.9, "mem_use": 34.8, "gen_rate": 4.7, "speed": 4.69, "text": "\"Yes, pull the lever.\\n\\nThat's "}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.16, "t1": 0.26, "tft": 4.0949, "input_0": 140, "input_1": 33, "min_CLP": -4.2, "draft_iters": 32.0, "mem_use": 35.27, "gen_rate": 33.0, "speed": 9.64, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 2, "tree_size": 32, "t0": 2.925, "t1": 0.24, "tft": 1.1936, "input_0": 129, "input_1": 33, "min_CLP": -3.94, "draft_iters": 31.0, "mem_use": 34.62, "gen_rate": 31.5, "speed": 9.96, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 3.04, "t1": 0.27, "tft": 3.0379, "input_0": 96, "input_1": 33, "min_CLP": -3.67, "draft_iters": 32.0, "mem_use": 35.78, "gen_rate": 32.0, "speed": 9.68, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.0, "tree_w": 13, "tree_size": 32, "t0": 0.8267, "t1": 0.24, "tft": 2.3598, "input_0": 70, "input_1": 33, "min_CLP": -4.68, "draft_iters": 8.0, "mem_use": 34.84, "gen_rate": 6.7, "speed": 6.25, "text": "\"\\nI don't know. I'm not an rst "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.93, "t1": 0.26, "tft": 3.4269, "input_0": 78, "input_1": 33, "min_CLP": -3.13, "draft_iters": 32.0, "mem_use": 35.47, "gen_rate": 33.0, "speed": 10.33, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 8, "tree_size": 32, "t0": 1.0433, "t1": 0.24, "tft": 1.3618, "input_0": 96, "input_1": 33, "min_CLP": -4.41, "draft_iters": 9.7, "mem_use": 34.68, "gen_rate": 6.0, "speed": 4.68, "text": "\\nThe Arctic Ocean.\\n\\nWhat is t"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.5, "tree_w": 17, "tree_size": 32, "t0": 0.6075, "t1": 0.24, "tft": 1.0723, "input_0": 62, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.5, "mem_use": 34.67, "gen_rate": 4.1, "speed": 4.85, "text": "No, definitely not. AI assistant"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.4, "tree_w": 15, "tree_size": 32, "t0": 0.8687, "t1": 0.32, "tft": 5.6773, "input_0": 58, "input_1": 33, "min_CLP": -4.98, "draft_iters": 7.4, "mem_use": 37.31, "gen_rate": 4.2, "speed": 3.56, "text": "\"\\n[Verse 1]\\nA gardener walks d"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 17.0, "tree_w": 8, "tree_size": 32, "t0": 1.7733, "t1": 0.2467, "tft": 1.6761, "input_0": 102, "input_1": 33, "min_CLP": -3.67, "draft_iters": 17.7, "mem_use": 35.61, "gen_rate": 16.7, "speed": 8.25, "text": "0 find out if new competitors ha"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 16.0, "tree_w": 5, "tree_size": 32, "t0": 1.78, "t1": 0.27, "tft": 3.6601, "input_0": 108, "input_1": 33, "min_CLP": -4.24, "draft_iters": 17.0, "mem_use": 35.81, "gen_rate": 14.7, "speed": 7.13, "text": "<</SYS>\\n\\n                     "}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.3, "tree_w": 12, "tree_size": 32, "t0": 0.6922, "t1": 0.25, "tft": 1.7529, "input_0": 65, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.3, "mem_use": 34.95, "gen_rate": 3.8, "speed": 4.01, "text": "1. People are tired of you. If i"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.0, "t1": 0.24, "tft": 1.4054, "input_0": 131, "input_1": 33, "min_CLP": -3.66, "draft_iters": 32.0, "mem_use": 34.59, "gen_rate": 33.0, "speed": 10.19, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.9, "tree_w": 9, "tree_size": 32, "t0": 1.1088, "t1": 0.28, "tft": 3.8344, "input_0": 86, "input_1": 33, "min_CLP": -4.22, "draft_iters": 9.9, "mem_use": 35.88, "gen_rate": 4.4, "speed": 3.16, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.2, "tree_w": 14, "tree_size": 32, "t0": 0.579, "t1": 0.24, "tft": 1.7426, "input_0": 57, "input_1": 33, "min_CLP": -4.64, "draft_iters": 5.2, "mem_use": 34.89, "gen_rate": 3.4, "speed": 4.13, "text": "\\nFirst, I would recommend looki"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.8, "tree_w": 12, "tree_size": 32, "t0": 0.68, "t1": 0.27, "tft": 2.8093, "input_0": 68, "input_1": 33, "min_CLP": -4.59, "draft_iters": 5.8, "mem_use": 35.71, "gen_rate": 3.2, "speed": 3.35, "text": "This is a very broad question an"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 12, "tree_size": 32, "t0": 1.174, "t1": 0.24, "tft": 1.3596, "input_0": 64, "input_1": 33, "min_CLP": -4.82, "draft_iters": 12.2, "mem_use": 34.8, "gen_rate": 7.0, "speed": 4.95, "text": "\\nPlease implement the MinHash a"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.6962, "t1": 0.2487, "tft": 1.6682, "input_0": 67, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.2, "mem_use": 34.81, "gen_rate": 4.0, "speed": 4.25, "text": "The first law regarding nudity i"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 34, "tree_h": 3.8, "tree_w": 15, "tree_size": 32, "t0": 0.5531, "t1": 0.24, "tft": 1.7296, "input_0": 61, "input_1": 33, "min_CLP": -4.86, "draft_iters": 4.8, "mem_use": 34.67, "gen_rate": 2.6, "speed": 3.29, "text": "\"\\nHi,\\n\\nI'm currently experime"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 10.0, "tree_w": 11, "tree_size": 32, "t0": 1.098, "t1": 0.24, "tft": 1.6234, "input_0": 76, "input_1": 33, "min_CLP": -4.89, "draft_iters": 11.0, "mem_use": 34.47, "gen_rate": 8.8, "speed": 6.59, "text": "\\nHow to create a game in C. [\\\\"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.7386, "t1": 0.25, "tft": 1.9477, "input_0": 71, "input_1": 33, "min_CLP": -4.3, "draft_iters": 6.6, "mem_use": 34.91, "gen_rate": 4.9, "speed": 4.91, "text": "\"Don't let fear of looking dumb "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.73, "t1": 0.27, "tft": 2.8289, "input_0": 74, "input_1": 33, "min_CLP": -4.34, "draft_iters": 6.1, "mem_use": 35.72, "gen_rate": 4.2, "speed": 4.22, "text": "There are thousands of Chinese c"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.02, "t1": 0.24, "tft": 1.5862, "input_0": 128, "input_1": 33, "min_CLP": -3.79, "draft_iters": 32.0, "mem_use": 34.81, "gen_rate": 33.0, "speed": 10.13, "text": "\\nif it takes 8 hours to fly to "}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.5, "tree_w": 16, "tree_size": 32, "t0": 0.4927, "t1": 0.24, "tft": 1.4637, "input_0": 51, "input_1": 33, "min_CLP": -4.88, "draft_iters": 4.5, "mem_use": 34.48, "gen_rate": 3.0, "speed": 4.1, "text": "\"\\nWe want a bot that bans from "}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.692, "t1": 0.24, "tft": 1.359, "input_0": 71, "input_1": 33, "min_CLP": -4.75, "draft_iters": 6.1, "mem_use": 34.44, "gen_rate": 3.8, "speed": 4.08, "text": "\\n<INST>\\n\\nYour computer is a l"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.4, "tree_w": 13, "tree_size": 32, "t0": 0.85, "t1": 0.3, "tft": 4.4366, "input_0": 63, "input_1": 33, "min_CLP": -4.58, "draft_iters": 7.4, "mem_use": 36.59, "gen_rate": 3.3, "speed": 2.87, "text": "You can use TypeScript in the sa"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 0.8086, "t1": 0.24, "tft": 1.6382, "input_0": 72, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.6, "mem_use": 35.21, "gen_rate": 5.1, "speed": 4.9, "text": "\"\\nQ: How many times did Mike's "}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 13, "tree_size": 32, "t0": 0.7212, "t1": 0.25, "tft": 1.9147, "input_0": 67, "input_1": 33, "min_CLP": -4.57, "draft_iters": 6.5, "mem_use": 35.0, "gen_rate": 4.1, "speed": 4.24, "text": "\\nHow do I get a free Minecraft "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.795, "t1": 0.28, "tft": 3.7384, "input_0": 77, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.6, "mem_use": 35.96, "gen_rate": 4.4, "speed": 4.08, "text": "Toasting bread for the optimal a"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.01, "t1": 0.24, "tft": 1.3975, "input_0": 140, "input_1": 33, "min_CLP": -3.69, "draft_iters": 32.0, "mem_use": 34.92, "gen_rate": 33.0, "speed": 10.16, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 3.9, "tree_w": 16, "tree_size": 32, "t0": 0.5609, "t1": 0.2491, "tft": 1.5759, "input_0": 59, "input_1": 33, "min_CLP": -4.82, "draft_iters": 4.9, "mem_use": 34.83, "gen_rate": 3.3, "speed": 4.06, "text": "\\nI am trying to learn Kanji in "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.715, "t1": 0.27, "tft": 2.7043, "input_0": 70, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.1, "mem_use": 35.71, "gen_rate": 4.0, "speed": 4.06, "text": "The first thing I would recommen"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.0, "tree_w": 14, "tree_size": 32, "t0": 0.6756, "t1": 0.2489, "tft": 1.6769, "input_0": 70, "input_1": 33, "min_CLP": -4.72, "draft_iters": 6.0, "mem_use": 34.86, "gen_rate": 3.6, "speed": 3.85, "text": "Inventor: George Baird\\nBirthpla"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.8, "tree_w": 12, "tree_size": 32, "t0": 0.6955, "t1": 0.28, "tft": 3.4959, "input_0": 66, "input_1": 33, "min_CLP": -4.57, "draft_iters": 5.8, "mem_use": 36.02, "gen_rate": 2.9, "speed": 2.99, "text": "\\nHave a question for the Ask Ub"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 0.8125, "t1": 0.2538, "tft": 2.0093, "input_0": 81, "input_1": 33, "min_CLP": -4.51, "draft_iters": 7.1, "mem_use": 35.17, "gen_rate": 4.5, "speed": 4.21, "text": "The traditions of Christmas Day "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.5, "tree_w": 17, "tree_size": 32, "t0": 0.5064, "t1": 0.24, "tft": 1.7473, "input_0": 50, "input_1": 33, "min_CLP": -4.85, "draft_iters": 4.5, "mem_use": 34.72, "gen_rate": 3.0, "speed": 4.01, "text": "\\nA new AI has been created by a"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.74, "t1": 0.27, "tft": 3.0412, "input_0": 66, "input_1": 33, "min_CLP": -4.28, "draft_iters": 6.5, "mem_use": 35.63, "gen_rate": 3.6, "speed": 3.57, "text": "\\nThe most difficult parts of le"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.9, "tree_w": 11, "tree_size": 32, "t0": 0.65, "t1": 0.24, "tft": 1.4825, "input_0": 66, "input_1": 33, "min_CLP": -4.34, "draft_iters": 5.9, "mem_use": 34.76, "gen_rate": 3.7, "speed": 4.12, "text": "\\nI don\u2019t think it would be poss"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.6, "tree_w": 12, "tree_size": 32, "t0": 0.631, "t1": 0.248, "tft": 1.7503, "input_0": 67, "input_1": 33, "min_CLP": -4.4, "draft_iters": 5.6, "mem_use": 34.86, "gen_rate": 3.4, "speed": 3.88, "text": "\"Sorry, I'm not really that fami"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 60, "tree_h": 29.0, "tree_w": 2, "tree_size": 32, "t0": 2.77, "t1": 0.24, "tft": 1.1871, "input_0": 111, "input_1": 33, "min_CLP": -4.23, "draft_iters": 29.5, "mem_use": 34.57, "gen_rate": 30.0, "speed": 9.96, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 8.0, "tree_w": 12, "tree_size": 32, "t0": 0.97, "t1": 0.24, "tft": 1.3173, "input_0": 92, "input_1": 33, "min_CLP": -4.38, "draft_iters": 9.0, "mem_use": 34.58, "gen_rate": 6.8, "speed": 5.64, "text": "\\nWhat is the distance to the ce"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 13, "tree_size": 32, "t0": 0.5967, "t1": 0.2444, "tft": 1.6196, "input_0": 64, "input_1": 33, "min_CLP": -4.39, "draft_iters": 5.3, "mem_use": 34.77, "gen_rate": 3.7, "speed": 4.35, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.695, "t1": 0.24, "tft": 1.7412, "input_0": 69, "input_1": 33, "min_CLP": -4.4, "draft_iters": 6.2, "mem_use": 34.67, "gen_rate": 4.1, "speed": 4.4, "text": "Prime numbers are a major part o"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.5845, "t1": 0.24, "tft": 1.5544, "input_0": 63, "input_1": 33, "min_CLP": -4.82, "draft_iters": 5.2, "mem_use": 34.54, "gen_rate": 3.3, "speed": 3.97, "text": "\"\\nHi guys!\\nI'm making a quest "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.0, "tree_w": 8, "tree_size": 32, "t0": 1.58, "t1": 0.24, "tft": 1.5434, "input_0": 88, "input_1": 33, "min_CLP": -4.03, "draft_iters": 16.0, "mem_use": 34.47, "gen_rate": 11.0, "speed": 6.04, "text": "\\nThe wireless Internet signal i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 6.2, "tree_w": 12, "tree_size": 32, "t0": 0.76, "t1": 0.24, "tft": 1.4515, "input_0": 62, "input_1": 33, "min_CLP": -4.72, "draft_iters": 7.2, "mem_use": 34.48, "gen_rate": 4.4, "speed": 4.44, "text": "\\nWrite me an OOP (Object Orient"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 3.0, "tree_w": 23, "tree_size": 32, "t0": 0.44, "t1": 0.24, "tft": 1.3355, "input_0": 42, "input_1": 33, "min_CLP": -5.19, "draft_iters": 4.0, "mem_use": 34.45, "gen_rate": 1.0, "speed": 1.46, "text": "\\n* Required"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.735, "t1": 0.25, "tft": 1.9219, "input_0": 70, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.6, "mem_use": 35.11, "gen_rate": 3.5, "speed": 3.55, "text": "You can use a third-party servic"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.9, "tree_w": 14, "tree_size": 32, "t0": 0.5544, "t1": 0.24, "tft": 1.2223, "input_0": 62, "input_1": 33, "min_CLP": -4.85, "draft_iters": 4.9, "mem_use": 34.51, "gen_rate": 3.7, "speed": 4.62, "text": "The @ in python is used to refer"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 7, "tree_size": 32, "t0": 1.17, "t1": 0.24, "tft": 1.3593, "input_0": 73, "input_1": 33, "min_CLP": -4.67, "draft_iters": 11.8, "mem_use": 34.43, "gen_rate": 7.0, "speed": 4.96, "text": "\\n<INST>\\n\\n<SYS>\\n\\nSKILLS\\n\\n["}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.99, "t1": 0.24, "tft": 1.3985, "input_0": 132, "input_1": 33, "min_CLP": -4.36, "draft_iters": 32.0, "mem_use": 34.57, "gen_rate": 33.0, "speed": 10.23, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 1, "tree_size": 32, "t0": 2.7, "t1": 0.24, "tft": 1.5249, "input_0": 136, "input_1": 33, "min_CLP": -3.51, "draft_iters": 28.0, "mem_use": 34.45, "gen_rate": 28.5, "speed": 9.7, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 7, "tree_size": 32, "t0": 1.23, "t1": 0.25, "tft": 2.0234, "input_0": 91, "input_1": 33, "min_CLP": -4.42, "draft_iters": 11.8, "mem_use": 34.81, "gen_rate": 8.5, "speed": 5.75, "text": "\\nWhat is a statistical hypothes"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 20.5, "tree_w": 4, "tree_size": 32, "t0": 2.165, "t1": 0.28, "tft": 3.6824, "input_0": 101, "input_1": 33, "min_CLP": -4.4, "draft_iters": 21.2, "mem_use": 36.09, "gen_rate": 9.8, "speed": 3.98, "text": "\"\\nWhat's the current time? [\\\\I"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.4, "tree_w": 11, "tree_size": 32, "t0": 0.7863, "t1": 0.24, "tft": 1.8389, "input_0": 66, "input_1": 33, "min_CLP": -4.75, "draft_iters": 7.4, "mem_use": 34.99, "gen_rate": 4.6, "speed": 4.49, "text": "No.\\n\\nHow can I make a function"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.9, "tree_w": 16, "tree_size": 32, "t0": 0.559, "t1": 0.259, "tft": 2.2552, "input_0": 56, "input_1": 33, "min_CLP": -4.71, "draft_iters": 4.9, "mem_use": 35.25, "gen_rate": 3.2, "speed": 3.92, "text": "You stand before a deep, blacken"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 7.3, "tree_w": 12, "tree_size": 32, "t0": 0.87, "t1": 0.241, "tft": 2.2582, "input_0": 75, "input_1": 33, "min_CLP": -4.92, "draft_iters": 8.3, "mem_use": 34.7, "gen_rate": 4.1, "speed": 3.68, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 13.1, "tree_w": 9, "tree_size": 32, "t0": 1.5275, "t1": 0.3, "tft": 4.6082, "input_0": 83, "input_1": 33, "min_CLP": -4.37, "draft_iters": 14.1, "mem_use": 36.57, "gen_rate": 4.9, "speed": 2.67, "text": "[INST]\\n\\nWhat is the difference"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.4, "tree_w": 13, "tree_size": 32, "t0": 0.83, "t1": 0.39, "tft": 8.5801, "input_0": 62, "input_1": 33, "min_CLP": -4.39, "draft_iters": 5.4, "mem_use": 39.35, "gen_rate": 3.3, "speed": 2.7, "text": "\\nI am happy to share some code "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.8912, "t1": 0.26, "tft": 2.6529, "input_0": 72, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.0, "mem_use": 36.53, "gen_rate": 4.0, "speed": 3.47, "text": "\"In the digital age, the most wi"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 2, "tree_size": 32, "t0": 2.895, "t1": 0.24, "tft": 1.4572, "input_0": 129, "input_1": 33, "min_CLP": -4.19, "draft_iters": 30.5, "mem_use": 34.66, "gen_rate": 31.0, "speed": 9.89, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.6, "tree_w": 13, "tree_size": 32, "t0": 0.632, "t1": 0.24, "tft": 1.3316, "input_0": 66, "input_1": 33, "min_CLP": -4.69, "draft_iters": 5.6, "mem_use": 34.51, "gen_rate": 3.2, "speed": 3.67, "text": "\\nI have a value in TypeScript t"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 10.1, "tree_w": 9, "tree_size": 32, "t0": 1.1971, "t1": 0.28, "tft": 4.8837, "input_0": 72, "input_1": 33, "min_CLP": -4.47, "draft_iters": 11.1, "mem_use": 35.93, "gen_rate": 8.0, "speed": 5.43, "text": "A good name is important and can"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 6.2, "tree_w": 11, "tree_size": 32, "t0": 0.79, "t1": 0.24, "tft": 1.3322, "input_0": 68, "input_1": 33, "min_CLP": -4.81, "draft_iters": 7.2, "mem_use": 34.93, "gen_rate": 5.0, "speed": 4.86, "text": "\\nDo you think the world will be"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.5, "tree_w": 13, "tree_size": 32, "t0": 0.8036, "t1": 0.3182, "tft": 5.4275, "input_0": 68, "input_1": 33, "min_CLP": -4.52, "draft_iters": 6.5, "mem_use": 37.08, "gen_rate": 3.1, "speed": 2.76, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 0.7911, "t1": 0.24, "tft": 1.1599, "input_0": 78, "input_1": 33, "min_CLP": -4.45, "draft_iters": 7.1, "mem_use": 35.46, "gen_rate": 4.6, "speed": 4.41, "text": "You should install the motherboa"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.6713, "t1": 0.24, "tft": 1.3108, "input_0": 70, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.0, "mem_use": 34.58, "gen_rate": 4.0, "speed": 4.38, "text": "Carnegie Mellon University is on"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.0, "tree_w": 13, "tree_size": 32, "t0": 0.9233, "t1": 0.24, "tft": 1.3197, "input_0": 72, "input_1": 33, "min_CLP": -4.76, "draft_iters": 9.0, "mem_use": 34.62, "gen_rate": 6.5, "speed": 5.59, "text": "I am going to be able to do thin"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 11, "tree_size": 32, "t0": 0.7163, "t1": 0.2588, "tft": 2.4606, "input_0": 72, "input_1": 33, "min_CLP": -4.28, "draft_iters": 6.4, "mem_use": 35.22, "gen_rate": 4.2, "speed": 4.37, "text": "\"The most important components o"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.9, "tree_w": 10, "tree_size": 32, "t0": 0.84, "t1": 0.24, "tft": 1.3769, "input_0": 71, "input_1": 33, "min_CLP": -4.45, "draft_iters": 7.9, "mem_use": 34.64, "gen_rate": 3.8, "speed": 3.49, "text": "[REPLY]\\n\\n[INST] <<SYS>>\\nThe K"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.6711, "t1": 0.24, "tft": 1.2747, "input_0": 73, "input_1": 33, "min_CLP": -4.83, "draft_iters": 6.0, "mem_use": 34.74, "gen_rate": 3.6, "speed": 3.88, "text": "tomato sauce\\ntomato paste\\nchic"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 12, "tree_size": 32, "t0": 0.7188, "t1": 0.2437, "tft": 1.3312, "input_0": 73, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.5, "mem_use": 34.76, "gen_rate": 4.4, "speed": 4.54, "text": "Yes, you can get a pair of binoc"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.815, "t1": 0.27, "tft": 2.6298, "input_0": 71, "input_1": 33, "min_CLP": -4.48, "draft_iters": 7.2, "mem_use": 35.72, "gen_rate": 3.3, "speed": 3.04, "text": "\u2022 Here are some of my favorite Y"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.7, "tree_w": 6, "tree_size": 32, "t0": 1.7867, "t1": 0.24, "tft": 1.3254, "input_0": 97, "input_1": 33, "min_CLP": -4.84, "draft_iters": 18.7, "mem_use": 34.8, "gen_rate": 13.0, "speed": 6.41, "text": "\\n<INST>\\n\\n<SYS>\\n\\nYou are a h"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.97, "t1": 0.24, "tft": 1.4359, "input_0": 127, "input_1": 33, "min_CLP": -4.22, "draft_iters": 32.0, "mem_use": 34.51, "gen_rate": 32.0, "speed": 9.98, "text": "\\nGiven two matrices A and B whi"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 13.3, "tree_w": 7, "tree_size": 32, "t0": 1.4743, "t1": 0.2586, "tft": 2.1692, "input_0": 93, "input_1": 33, "min_CLP": -4.07, "draft_iters": 14.3, "mem_use": 35.26, "gen_rate": 5.1, "speed": 2.97, "text": "\\nStatistical modeling is the pr"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 3, "tree_size": 32, "t0": 2.805, "t1": 0.27, "tft": 2.9442, "input_0": 136, "input_1": 33, "min_CLP": -4.57, "draft_iters": 28.0, "mem_use": 35.8, "gen_rate": 28.5, "speed": 9.26, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 10.2, "tree_w": 10, "tree_size": 32, "t0": 1.1517, "t1": 0.24, "tft": 1.3525, "input_0": 79, "input_1": 33, "min_CLP": -4.46, "draft_iters": 11.2, "mem_use": 34.88, "gen_rate": 6.8, "speed": 4.91, "text": "\"[\\\\SYS]\\nThe current date is th"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 3, "tree_size": 32, "t0": 2.94, "t1": 0.26, "tft": 2.0494, "input_0": 116, "input_1": 33, "min_CLP": -4.06, "draft_iters": 30.5, "mem_use": 35.18, "gen_rate": 31.0, "speed": 9.7, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 11.8, "tree_w": 13, "tree_size": 32, "t0": 1.245, "t1": 0.24, "tft": 1.327, "input_0": 69, "input_1": 33, "min_CLP": -4.72, "draft_iters": 12.8, "mem_use": 34.61, "gen_rate": 11.0, "speed": 7.39, "text": "\\nWrite a response that disagree"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 3.7, "tree_w": 16, "tree_size": 32, "t0": 0.5225, "t1": 0.24, "tft": 1.2729, "input_0": 56, "input_1": 33, "min_CLP": -4.78, "draft_iters": 4.7, "mem_use": 34.45, "gen_rate": 3.0, "speed": 3.94, "text": "\\nI am looking into Monte Carlo "}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 58, "tree_h": 12.3, "tree_w": 10, "tree_size": 32, "t0": 1.2783, "t1": 0.24, "tft": 2.0411, "input_0": 72, "input_1": 33, "min_CLP": -4.6, "draft_iters": 13.2, "mem_use": 34.62, "gen_rate": 9.7, "speed": 6.36, "text": "\\nI am a lawyer. And I am lookin"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.9, "tree_w": 14, "tree_size": 32, "t0": 0.63, "t1": 0.24, "tft": 1.1543, "input_0": 59, "input_1": 33, "min_CLP": -4.74, "draft_iters": 5.9, "mem_use": 34.42, "gen_rate": 4.2, "speed": 4.86, "text": "\"\\nI'm not sure what you're aski"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.7, "tree_w": 9, "tree_size": 32, "t0": 1.1271, "t1": 0.25, "tft": 2.0142, "input_0": 82, "input_1": 33, "min_CLP": -4.15, "draft_iters": 10.7, "mem_use": 35.02, "gen_rate": 4.6, "speed": 3.32, "text": "\"\\nHow far away is the center of"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 13, "tree_size": 32, "t0": 0.7688, "t1": 0.24, "tft": 1.6722, "input_0": 72, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.1, "mem_use": 34.52, "gen_rate": 4.2, "speed": 4.22, "text": "\"\\nJill has one brother and a fa"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 13, "tree_size": 32, "t0": 0.7071, "t1": 0.24, "tft": 1.8455, "input_0": 73, "input_1": 33, "min_CLP": -4.99, "draft_iters": 6.4, "mem_use": 34.71, "gen_rate": 4.6, "speed": 4.81, "text": "\\nocean is a body of saltwater\\n"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 14, "tree_size": 32, "t0": 0.63, "t1": 0.2487, "tft": 1.5742, "input_0": 60, "input_1": 33, "min_CLP": -4.66, "draft_iters": 5.6, "mem_use": 34.86, "gen_rate": 4.1, "speed": 4.71, "text": "\\nThe first step is to find a jo"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.4, "tree_w": 13, "tree_size": 32, "t0": 0.5909, "t1": 0.24, "tft": 1.3601, "input_0": 59, "input_1": 33, "min_CLP": -4.65, "draft_iters": 5.4, "mem_use": 34.54, "gen_rate": 3.4, "speed": 4.04, "text": "\"\\nWhat are the best controllers"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.7057, "t1": 0.25, "tft": 1.9763, "input_0": 74, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.1, "mem_use": 35.08, "gen_rate": 5.3, "speed": 5.52, "text": "A DLL is a dynamic link library "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 56, "tree_h": 11.0, "tree_w": 10, "tree_size": 32, "t0": 1.172, "t1": 0.24, "tft": 1.4604, "input_0": 74, "input_1": 33, "min_CLP": -4.89, "draft_iters": 11.8, "mem_use": 34.67, "gen_rate": 11.2, "speed": 7.92, "text": "\\nDo you have any opinions on th"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.1, "tree_w": 13, "tree_size": 32, "t0": 0.5789, "t1": 0.24, "tft": 1.3303, "input_0": 63, "input_1": 33, "min_CLP": -4.91, "draft_iters": 5.1, "mem_use": 34.43, "gen_rate": 3.7, "speed": 4.49, "text": "The infinite banking concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.3, "tree_w": 18, "tree_size": 32, "t0": 0.476, "t1": 0.24, "tft": 1.4545, "input_0": 50, "input_1": 33, "min_CLP": -4.99, "draft_iters": 4.3, "mem_use": 34.49, "gen_rate": 3.2, "speed": 4.48, "text": "\\nThe testing framework should b"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.2, "tree_w": 10, "tree_size": 32, "t0": 0.8738, "t1": 0.24, "tft": 1.0803, "input_0": 71, "input_1": 33, "min_CLP": -4.36, "draft_iters": 8.2, "mem_use": 34.55, "gen_rate": 4.2, "speed": 3.82, "text": "[INST] I will make an argument f"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.7763, "t1": 0.2487, "tft": 1.4857, "input_0": 66, "input_1": 33, "min_CLP": -4.51, "draft_iters": 7.2, "mem_use": 34.81, "gen_rate": 4.1, "speed": 4.03, "text": "\"I can't think of anything else."}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 15, "tree_size": 32, "t0": 0.7514, "t1": 0.26, "tft": 2.3949, "input_0": 67, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.9, "mem_use": 35.26, "gen_rate": 5.0, "speed": 4.97, "text": "\"[INST] Sure, you can ask me. [\\"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.9471, "t1": 0.2629, "tft": 2.5341, "input_0": 85, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.4, "mem_use": 35.51, "gen_rate": 5.4, "speed": 4.48, "text": "While some languages may be easi"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.8833, "t1": 0.245, "tft": 1.7696, "input_0": 82, "input_1": 33, "min_CLP": -4.56, "draft_iters": 8.0, "mem_use": 34.74, "gen_rate": 6.0, "speed": 5.32, "text": "You can use all of the tools lis"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.7, "tree_w": 10, "tree_size": 32, "t0": 0.7422, "t1": 0.24, "tft": 1.2625, "input_0": 74, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.7, "mem_use": 34.67, "gen_rate": 4.1, "speed": 4.17, "text": "I do not have any opinion about "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 0.762, "t1": 0.242, "tft": 1.2388, "input_0": 63, "input_1": 33, "min_CLP": -4.52, "draft_iters": 7.1, "mem_use": 34.77, "gen_rate": 3.3, "speed": 3.28, "text": "I have a very important job to d"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.6589, "t1": 0.2422, "tft": 1.8836, "input_0": 65, "input_1": 33, "min_CLP": -4.49, "draft_iters": 5.9, "mem_use": 34.73, "gen_rate": 3.6, "speed": 3.94, "text": "The A comes from the Russian \"Ak"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.3, "tree_w": 14, "tree_size": 32, "t0": 0.675, "t1": 0.24, "tft": 1.4709, "input_0": 66, "input_1": 33, "min_CLP": -4.95, "draft_iters": 6.3, "mem_use": 34.49, "gen_rate": 3.2, "speed": 3.5, "text": "\\nIt has to be an electric type "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.7771, "t1": 0.2571, "tft": 2.2457, "input_0": 75, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.7, "mem_use": 35.28, "gen_rate": 4.9, "speed": 4.69, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 21.3, "tree_w": 5, "tree_size": 32, "t0": 2.13, "t1": 0.24, "tft": 1.5197, "input_0": 110, "input_1": 33, "min_CLP": -4.17, "draft_iters": 22.0, "mem_use": 34.59, "gen_rate": 21.0, "speed": 8.86, "text": "<</SYS>\\n\\n [INST] <<SYS>>\\nYou "}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.7, "tree_w": 9, "tree_size": 32, "t0": 1.3667, "t1": 0.24, "tft": 1.4756, "input_0": 83, "input_1": 33, "min_CLP": -4.54, "draft_iters": 13.7, "mem_use": 34.48, "gen_rate": 5.7, "speed": 3.53, "text": "\\nDo you believe in love at firs"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.8, "tree_w": 6, "tree_size": 32, "t0": 1.3875, "t1": 0.24, "tft": 1.7758, "input_0": 86, "input_1": 33, "min_CLP": -4.43, "draft_iters": 13.8, "mem_use": 34.72, "gen_rate": 9.8, "speed": 5.98, "text": "[INST] what do you want to creat"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.4, "tree_w": 12, "tree_size": 32, "t0": 0.7444, "t1": 0.2678, "tft": 2.6686, "input_0": 75, "input_1": 33, "min_CLP": -4.44, "draft_iters": 6.4, "mem_use": 35.57, "gen_rate": 3.9, "speed": 3.85, "text": "The initial noise is produced th"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.9, "tree_w": 17, "tree_size": 32, "t0": 0.5555, "t1": 0.25, "tft": 1.6168, "input_0": 59, "input_1": 33, "min_CLP": -4.74, "draft_iters": 4.9, "mem_use": 34.94, "gen_rate": 2.9, "speed": 3.62, "text": "\"Not really. While there are man"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.0, "tree_w": 14, "tree_size": 32, "t0": 0.6837, "t1": 0.2538, "tft": 2.0042, "input_0": 72, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.0, "mem_use": 35.15, "gen_rate": 4.5, "speed": 4.79, "text": "\"Life is about much more than ju"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.8, "tree_w": 13, "tree_size": 32, "t0": 0.63, "t1": 0.24, "tft": 1.4375, "input_0": 61, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.8, "mem_use": 34.53, "gen_rate": 3.7, "speed": 4.22, "text": "\"\\nI'm looking for someone to wr"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.7378, "t1": 0.3, "tft": 4.5286, "input_0": 66, "input_1": 33, "min_CLP": -4.66, "draft_iters": 6.0, "mem_use": 36.72, "gen_rate": 3.8, "speed": 3.62, "text": "\\nWhat is the weather forecast ["}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 15, "tree_size": 32, "t0": 0.9083, "t1": 0.2583, "tft": 2.2167, "input_0": 66, "input_1": 33, "min_CLP": -4.72, "draft_iters": 8.5, "mem_use": 35.3, "gen_rate": 5.7, "speed": 4.86, "text": "[INST] Thank you. How can i tran"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 46, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.9986, "t1": 0.2486, "tft": 2.0262, "input_0": 87, "input_1": 33, "min_CLP": -4.24, "draft_iters": 9.0, "mem_use": 34.91, "gen_rate": 6.6, "speed": 5.27, "text": "\"If you're traveling from a +8 u"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 1, "tree_h": 3.0, "tree_w": 20, "tree_size": 32, "t0": 0.455, "t1": 0.24, "tft": 1.4623, "input_0": 52, "input_1": 33, "min_CLP": -5.37, "draft_iters": 4.0, "mem_use": 34.45, "gen_rate": 0.5, "speed": 0.72, "text": "\\n* Required"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.3, "tree_w": 8, "tree_size": 32, "t0": 0.9771, "t1": 0.24, "tft": 1.2629, "input_0": 78, "input_1": 33, "min_CLP": -4.52, "draft_iters": 9.3, "mem_use": 34.64, "gen_rate": 5.4, "speed": 4.46, "text": "\"Ok, here's another one:\\n\\nWhat"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 19.0, "tree_w": 6, "tree_size": 32, "t0": 1.8867, "t1": 0.24, "tft": 1.2752, "input_0": 96, "input_1": 33, "min_CLP": -4.29, "draft_iters": 19.7, "mem_use": 34.44, "gen_rate": 18.7, "speed": 8.79, "text": "How many known to exist at the t"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.6, "tree_w": 12, "tree_size": 32, "t0": 0.7188, "t1": 0.3088, "tft": 4.5792, "input_0": 65, "input_1": 33, "min_CLP": -4.46, "draft_iters": 5.6, "mem_use": 36.85, "gen_rate": 4.2, "speed": 4.15, "text": "I understand. I will try to be a"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.1, "tree_w": 12, "tree_size": 32, "t0": 0.8557, "t1": 0.24, "tft": 1.33, "input_0": 70, "input_1": 33, "min_CLP": -4.64, "draft_iters": 8.1, "mem_use": 35.34, "gen_rate": 4.9, "speed": 4.44, "text": "\\nWhat is the most common langua"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.9, "tree_w": 10, "tree_size": 32, "t0": 1.1412, "t1": 0.3425, "tft": 6.5529, "input_0": 81, "input_1": 33, "min_CLP": -4.38, "draft_iters": 8.9, "mem_use": 37.97, "gen_rate": 4.2, "speed": 2.86, "text": "\\nHere is the Malbolge program t"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.7, "tree_w": 14, "tree_size": 32, "t0": 0.6375, "t1": 0.25, "tft": 1.7798, "input_0": 60, "input_1": 33, "min_CLP": -4.62, "draft_iters": 5.7, "mem_use": 35.88, "gen_rate": 2.8, "speed": 3.09, "text": "\"Yes, the first evolution form i"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.02, "t1": 0.24, "tft": 1.4271, "input_0": 132, "input_1": 33, "min_CLP": -3.27, "draft_iters": 32.0, "mem_use": 34.49, "gen_rate": 33.0, "speed": 10.11, "text": "\\nWhat parts of the human genome"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.87, "t1": 0.24, "tft": 1.3233, "input_0": 84, "input_1": 33, "min_CLP": -3.12, "draft_iters": 32.0, "mem_use": 34.42, "gen_rate": 33.0, "speed": 10.6, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 2, "tree_size": 32, "t0": 2.83, "t1": 0.24, "tft": 1.4744, "input_0": 119, "input_1": 33, "min_CLP": -4.35, "draft_iters": 30.0, "mem_use": 34.55, "gen_rate": 30.5, "speed": 9.93, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 9.2, "tree_w": 9, "tree_size": 32, "t0": 1.042, "t1": 0.242, "tft": 1.4729, "input_0": 71, "input_1": 33, "min_CLP": -4.18, "draft_iters": 10.2, "mem_use": 34.71, "gen_rate": 8.6, "speed": 6.7, "text": "The Office, Parks and Rec, The S"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 9, "tree_size": 32, "t0": 0.9967, "t1": 0.2617, "tft": 2.3686, "input_0": 94, "input_1": 33, "min_CLP": -4.41, "draft_iters": 8.8, "mem_use": 35.52, "gen_rate": 5.8, "speed": 4.63, "text": "You can use GNU Radio and SDR# t"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.8, "tree_w": 13, "tree_size": 32, "t0": 0.6733, "t1": 0.25, "tft": 2.0415, "input_0": 71, "input_1": 33, "min_CLP": -4.59, "draft_iters": 5.8, "mem_use": 35.1, "gen_rate": 3.6, "speed": 3.84, "text": "F-centers are often more prevale"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.8, "tree_w": 16, "tree_size": 32, "t0": 0.6422, "t1": 0.24, "tft": 1.6532, "input_0": 65, "input_1": 33, "min_CLP": -4.79, "draft_iters": 5.8, "mem_use": 34.53, "gen_rate": 3.8, "speed": 4.29, "text": "\\nI have a question about the ga"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.5, "tree_w": 7, "tree_size": 32, "t0": 2.435, "t1": 0.29, "tft": 4.7923, "input_0": 83, "input_1": 33, "min_CLP": -3.77, "draft_iters": 24.5, "mem_use": 36.45, "gen_rate": 16.5, "speed": 6.04, "text": "\\n[INST]\\n<<SYS>>\\nYou are a hel"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 27.0, "tree_w": 2, "tree_size": 32, "t0": 2.77, "t1": 0.26, "tft": 3.8915, "input_0": 133, "input_1": 33, "min_CLP": -3.69, "draft_iters": 28.0, "mem_use": 35.25, "gen_rate": 23.0, "speed": 7.6, "text": "\"Aqu\u00ed tienes una reducci\u00f3n de la"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 16.0, "tree_w": 4, "tree_size": 32, "t0": 1.6933, "t1": 0.24, "tft": 1.3334, "input_0": 106, "input_1": 33, "min_CLP": -4.13, "draft_iters": 17.0, "mem_use": 34.63, "gen_rate": 12.0, "speed": 6.21, "text": "\\nHow would I go about teaching "}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.4, "tree_w": 16, "tree_size": 32, "t0": 0.6733, "t1": 0.24, "tft": 1.4545, "input_0": 57, "input_1": 33, "min_CLP": -4.97, "draft_iters": 6.4, "mem_use": 34.49, "gen_rate": 4.3, "speed": 4.75, "text": "\\nThe [INST] prefix is from the "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.5769, "t1": 0.25, "tft": 1.8786, "input_0": 55, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.2, "mem_use": 35.01, "gen_rate": 2.5, "speed": 2.97, "text": "\"I will take you on a journey, o"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.8, "tree_w": 16, "tree_size": 32, "t0": 0.562, "t1": 0.264, "tft": 2.5441, "input_0": 56, "input_1": 33, "min_CLP": -4.57, "draft_iters": 4.8, "mem_use": 35.54, "gen_rate": 3.2, "speed": 3.87, "text": "In Javascript, the closest thing"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.4, "tree_w": 13, "tree_size": 32, "t0": 0.62, "t1": 0.2443, "tft": 1.4703, "input_0": 63, "input_1": 33, "min_CLP": -4.48, "draft_iters": 5.4, "mem_use": 34.73, "gen_rate": 4.6, "speed": 5.3, "text": "I am not sure what you mean by \""}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 61, "tree_h": 26.7, "tree_w": 3, "tree_size": 32, "t0": 2.6667, "t1": 0.25, "tft": 1.7202, "input_0": 133, "input_1": 33, "min_CLP": -3.35, "draft_iters": 27.3, "mem_use": 34.96, "gen_rate": 20.3, "speed": 6.98, "text": "The second batch of pancakes may"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.9, "tree_w": 11, "tree_size": 32, "t0": 0.8171, "t1": 0.24, "tft": 1.3588, "input_0": 70, "input_1": 33, "min_CLP": -4.65, "draft_iters": 7.9, "mem_use": 34.49, "gen_rate": 5.4, "speed": 5.15, "text": "\\nIs javascript the back-end lan"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.8, "tree_w": 7, "tree_size": 32, "t0": 1.355, "t1": 0.24, "tft": 1.3239, "input_0": 79, "input_1": 33, "min_CLP": -4.32, "draft_iters": 13.8, "mem_use": 34.43, "gen_rate": 8.5, "speed": 5.33, "text": "\\nwhat chemicals does l-theanine"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 6, "tree_size": 32, "t0": 2.345, "t1": 0.25, "tft": 1.4149, "input_0": 99, "input_1": 33, "min_CLP": -4.16, "draft_iters": 25.5, "mem_use": 34.79, "gen_rate": 26.0, "speed": 10.03, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 3, "tree_size": 32, "t0": 2.275, "t1": 0.24, "tft": 1.9516, "input_0": 120, "input_1": 33, "min_CLP": -4.72, "draft_iters": 23.5, "mem_use": 34.49, "gen_rate": 24.0, "speed": 9.54, "text": "\\n<<SYS>>\\nYou are a helpful, re"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 5.5, "tree_w": 15, "tree_size": 32, "t0": 0.6855, "t1": 0.24, "tft": 1.4759, "input_0": 61, "input_1": 33, "min_CLP": -4.99, "draft_iters": 6.5, "mem_use": 34.48, "gen_rate": 3.2, "speed": 3.44, "text": "\\nThe [INST] <<SYS>> program is "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 2, "tree_size": 32, "t0": 2.89, "t1": 0.24, "tft": 1.3635, "input_0": 147, "input_1": 33, "min_CLP": -3.88, "draft_iters": 30.5, "mem_use": 34.48, "gen_rate": 31.0, "speed": 9.91, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 24.5, "tree_w": 2, "tree_size": 32, "t0": 2.725, "t1": 0.31, "tft": 4.9519, "input_0": 121, "input_1": 33, "min_CLP": -4.08, "draft_iters": 25.0, "mem_use": 36.9, "gen_rate": 21.5, "speed": 7.08, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 59, "tree_h": 28.5, "tree_w": 2, "tree_size": 32, "t0": 2.91, "t1": 0.27, "tft": 2.9064, "input_0": 143, "input_1": 33, "min_CLP": -3.76, "draft_iters": 29.0, "mem_use": 35.65, "gen_rate": 29.5, "speed": 9.27, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.9057, "t1": 0.25, "tft": 1.6723, "input_0": 77, "input_1": 33, "min_CLP": -4.34, "draft_iters": 8.4, "mem_use": 34.88, "gen_rate": 4.7, "speed": 4.08, "text": "[INST] When you are estimating t"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.6844, "t1": 0.25, "tft": 1.8904, "input_0": 62, "input_1": 33, "min_CLP": -4.51, "draft_iters": 6.1, "mem_use": 34.98, "gen_rate": 3.8, "speed": 4.05, "text": "\"There are many things we can le"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.7011, "t1": 0.2611, "tft": 2.5452, "input_0": 69, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.1, "mem_use": 35.52, "gen_rate": 3.9, "speed": 4.02, "text": "You can serve a lemon wedge with"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 2, "tree_size": 32, "t0": 2.855, "t1": 0.24, "tft": 2.0856, "input_0": 130, "input_1": 33, "min_CLP": -3.62, "draft_iters": 30.5, "mem_use": 34.71, "gen_rate": 31.0, "speed": 10.01, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 7, "tree_size": 32, "t0": 1.5625, "t1": 0.24, "tft": 1.6502, "input_0": 87, "input_1": 33, "min_CLP": -4.31, "draft_iters": 16.0, "mem_use": 34.51, "gen_rate": 8.8, "speed": 4.86, "text": "\"\\nWhat is the meaning of life? "}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 4, "tree_size": 32, "t0": 2.41, "t1": 0.24, "tft": 1.3325, "input_0": 105, "input_1": 33, "min_CLP": -4.34, "draft_iters": 26.0, "mem_use": 34.45, "gen_rate": 26.5, "speed": 9.99, "text": "\\nHow do I initialize a Typescri"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 7.1, "tree_w": 13, "tree_size": 32, "t0": 0.8457, "t1": 0.2543, "tft": 2.1073, "input_0": 62, "input_1": 33, "min_CLP": -4.41, "draft_iters": 8.1, "mem_use": 35.19, "gen_rate": 6.3, "speed": 5.71, "text": "Berlin is a city founded by a si"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.7112, "t1": 0.25, "tft": 1.993, "input_0": 77, "input_1": 33, "min_CLP": -4.67, "draft_iters": 6.1, "mem_use": 34.98, "gen_rate": 4.6, "speed": 4.81, "text": "Dyson was also known for his def"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 10, "tree_size": 32, "t0": 1.0725, "t1": 0.24, "tft": 1.064, "input_0": 86, "input_1": 33, "min_CLP": -4.71, "draft_iters": 10.5, "mem_use": 34.46, "gen_rate": 8.8, "speed": 6.68, "text": "Are you a coder? [\\\\INST]\\nDo yo"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 11, "tree_size": 32, "t0": 0.86, "t1": 0.2433, "tft": 1.456, "input_0": 75, "input_1": 33, "min_CLP": -4.42, "draft_iters": 8.0, "mem_use": 34.77, "gen_rate": 5.5, "speed": 4.98, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.87, "t1": 0.25, "tft": 2.081, "input_0": 83, "input_1": 33, "min_CLP": -2.79, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 10.57, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.4, "tree_w": 10, "tree_size": 32, "t0": 0.9629, "t1": 0.24, "tft": 1.5621, "input_0": 71, "input_1": 33, "min_CLP": -5.16, "draft_iters": 9.4, "mem_use": 34.65, "gen_rate": 5.1, "speed": 4.26, "text": "1.    Use the right strategies t"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.81, "t1": 0.24, "tft": 1.6145, "input_0": 80, "input_1": 33, "min_CLP": -3.39, "draft_iters": 32.0, "mem_use": 34.48, "gen_rate": 32.0, "speed": 10.51, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 9, "tree_size": 32, "t0": 1.095, "t1": 0.24, "tft": 1.8447, "input_0": 90, "input_1": 33, "min_CLP": -4.29, "draft_iters": 10.2, "mem_use": 34.73, "gen_rate": 8.8, "speed": 6.54, "text": "It is difficult to make any comp"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 47, "tree_h": 9.4, "tree_w": 9, "tree_size": 32, "t0": 1.051, "t1": 0.25, "tft": 2.9237, "input_0": 73, "input_1": 33, "min_CLP": -4.35, "draft_iters": 10.4, "mem_use": 35.01, "gen_rate": 4.7, "speed": 3.61, "text": "[INST] how can i ask the largest"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.645, "t1": 0.247, "tft": 1.9128, "input_0": 63, "input_1": 33, "min_CLP": -4.62, "draft_iters": 6.0, "mem_use": 34.83, "gen_rate": 3.5, "speed": 3.93, "text": "In reStructuredText, URLs are as"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.8, "tree_w": 11, "tree_size": 32, "t0": 0.86, "t1": 0.27, "tft": 3.4401, "input_0": 69, "input_1": 33, "min_CLP": -4.42, "draft_iters": 7.8, "mem_use": 35.85, "gen_rate": 3.7, "speed": 3.23, "text": "\\nHow do you think you would per"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.855, "t1": 0.3025, "tft": 4.5434, "input_0": 77, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.0, "mem_use": 36.73, "gen_rate": 4.0, "speed": 3.45, "text": "There are many different brands "}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 12, "tree_size": 32, "t0": 0.6437, "t1": 0.2512, "tft": 1.849, "input_0": 66, "input_1": 33, "min_CLP": -4.82, "draft_iters": 5.6, "mem_use": 35.32, "gen_rate": 4.1, "speed": 4.59, "text": "I suggest you take a look at the"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 59, "tree_h": 28.5, "tree_w": 4, "tree_size": 32, "t0": 2.74, "t1": 0.26, "tft": 2.3323, "input_0": 110, "input_1": 33, "min_CLP": -3.88, "draft_iters": 29.0, "mem_use": 35.34, "gen_rate": 29.5, "speed": 9.83, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.4, "tree_w": 7, "tree_size": 32, "t0": 1.18, "t1": 0.24, "tft": 1.4529, "input_0": 95, "input_1": 33, "min_CLP": -4.66, "draft_iters": 11.4, "mem_use": 34.66, "gen_rate": 7.6, "speed": 5.35, "text": "\\nExplain the difference between"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 9.2, "tree_w": 11, "tree_size": 32, "t0": 1.034, "t1": 0.25, "tft": 3.7067, "input_0": 72, "input_1": 33, "min_CLP": -4.4, "draft_iters": 10.1, "mem_use": 35.0, "gen_rate": 3.5, "speed": 2.72, "text": "The answer would depend on the d"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.5, "tree_w": 14, "tree_size": 32, "t0": 0.5991, "t1": 0.24, "tft": 1.3865, "input_0": 59, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.5, "mem_use": 34.53, "gen_rate": 2.9, "speed": 3.47, "text": "\\nI have written a novel format "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.94, "t1": 0.24, "tft": 1.3361, "input_0": 127, "input_1": 33, "min_CLP": -3.76, "draft_iters": 31.5, "mem_use": 34.46, "gen_rate": 32.0, "speed": 10.07, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.0, "tree_w": 16, "tree_size": 32, "t0": 0.56, "t1": 0.24, "tft": 1.3691, "input_0": 59, "input_1": 33, "min_CLP": -4.95, "draft_iters": 5.0, "mem_use": 34.46, "gen_rate": 3.1, "speed": 3.88, "text": "\"\\nI'm looking for a quick way t"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.0, "tree_w": 12, "tree_size": 32, "t0": 1.2375, "t1": 0.24, "tft": 2.0563, "input_0": 65, "input_1": 33, "min_CLP": -5.04, "draft_iters": 13.0, "mem_use": 34.43, "gen_rate": 9.8, "speed": 6.6, "text": "\\nAchievement:\\n\\n[\\\\INST]<<SYS>"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.8, "tree_w": 13, "tree_size": 32, "t0": 0.642, "t1": 0.25, "tft": 2.3494, "input_0": 57, "input_1": 33, "min_CLP": -4.61, "draft_iters": 5.8, "mem_use": 35.1, "gen_rate": 3.6, "speed": 4.03, "text": "\"\\nIn the above example, the pro"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 6.1, "tree_w": 12, "tree_size": 32, "t0": 0.7717, "t1": 0.24, "tft": 1.545, "input_0": 72, "input_1": 33, "min_CLP": -4.49, "draft_iters": 7.1, "mem_use": 34.65, "gen_rate": 2.8, "speed": 2.72, "text": "\"npm install tailwind\\n// Tailwi"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.7612, "t1": 0.32, "tft": 5.368, "input_0": 61, "input_1": 33, "min_CLP": -4.76, "draft_iters": 6.1, "mem_use": 37.18, "gen_rate": 4.2, "speed": 3.94, "text": "Sexual dimorphism is a costly tr"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.4, "tree_w": 13, "tree_size": 32, "t0": 0.704, "t1": 0.24, "tft": 1.5491, "input_0": 65, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.4, "mem_use": 35.5, "gen_rate": 3.5, "speed": 3.69, "text": "\"I am not sure what you mean by "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 4, "tree_size": 32, "t0": 2.185, "t1": 0.24, "tft": 1.2767, "input_0": 96, "input_1": 33, "min_CLP": -4.99, "draft_iters": 23.0, "mem_use": 34.47, "gen_rate": 23.5, "speed": 9.69, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.91, "t1": 0.24, "tft": 1.3947, "input_0": 94, "input_1": 33, "min_CLP": -2.25, "draft_iters": 32.0, "mem_use": 34.57, "gen_rate": 33.0, "speed": 10.48, "text": "\\nwrite a eulogy for my 100 year"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 3.02, "t1": 0.26, "tft": 2.419, "input_0": 107, "input_1": 33, "min_CLP": -4.69, "draft_iters": 32.0, "mem_use": 35.35, "gen_rate": 32.0, "speed": 9.75, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.8, "tree_w": 9, "tree_size": 32, "t0": 0.93, "t1": 0.24, "tft": 1.4854, "input_0": 76, "input_1": 33, "min_CLP": -4.71, "draft_iters": 8.8, "mem_use": 34.64, "gen_rate": 6.8, "speed": 5.81, "text": "Yes, but I am not currently thin"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.8, "tree_w": 11, "tree_size": 32, "t0": 1.1025, "t1": 0.24, "tft": 1.3536, "input_0": 86, "input_1": 33, "min_CLP": -4.77, "draft_iters": 10.8, "mem_use": 34.51, "gen_rate": 10.5, "speed": 7.84, "text": "\\n<INST> <<SYS>>\\nYour friend is"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.4, "tree_w": 11, "tree_size": 32, "t0": 0.9529, "t1": 0.24, "tft": 1.3499, "input_0": 72, "input_1": 33, "min_CLP": -4.54, "draft_iters": 9.4, "mem_use": 34.43, "gen_rate": 5.4, "speed": 4.56, "text": "[\\\\INST] <<SYS>>\\nThe color of M"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 12.2, "tree_w": 6, "tree_size": 32, "t0": 1.414, "t1": 0.268, "tft": 2.8362, "input_0": 101, "input_1": 33, "min_CLP": -4.16, "draft_iters": 13.2, "mem_use": 35.59, "gen_rate": 9.0, "speed": 5.37, "text": "Here are some examples of the Qu"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 3, "tree_size": 32, "t0": 2.865, "t1": 0.24, "tft": 1.4475, "input_0": 115, "input_1": 33, "min_CLP": -3.67, "draft_iters": 30.5, "mem_use": 34.76, "gen_rate": 31.0, "speed": 9.98, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 27.5, "tree_w": 2, "tree_size": 32, "t0": 2.725, "t1": 0.24, "tft": 1.7675, "input_0": 129, "input_1": 33, "min_CLP": -3.54, "draft_iters": 28.5, "mem_use": 34.73, "gen_rate": 23.0, "speed": 7.75, "text": "\"The Second Amendment guarantees"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 51, "tree_h": 7.7, "tree_w": 13, "tree_size": 32, "t0": 0.8671, "t1": 0.24, "tft": 1.3587, "input_0": 57, "input_1": 33, "min_CLP": -4.84, "draft_iters": 8.7, "mem_use": 34.47, "gen_rate": 7.3, "speed": 6.59, "text": "\\nDo we need to know the answer "}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.9, "tree_w": 12, "tree_size": 32, "t0": 0.8378, "t1": 0.24, "tft": 1.48, "input_0": 71, "input_1": 33, "min_CLP": -4.49, "draft_iters": 7.9, "mem_use": 34.68, "gen_rate": 3.8, "speed": 3.5, "text": "\\nI need help with grocery shopp"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 10, "tree_size": 32, "t0": 0.905, "t1": 0.24, "tft": 1.2737, "input_0": 82, "input_1": 33, "min_CLP": -4.33, "draft_iters": 8.3, "mem_use": 34.52, "gen_rate": 5.8, "speed": 5.1, "text": "Melbourne was the capital of the"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 8, "tree_size": 32, "t0": 1.188, "t1": 0.24, "tft": 1.4039, "input_0": 91, "input_1": 33, "min_CLP": -4.18, "draft_iters": 11.2, "mem_use": 34.6, "gen_rate": 6.6, "speed": 4.62, "text": "[INST] how old is your grandma? "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.1, "tree_w": 14, "tree_size": 32, "t0": 0.6, "t1": 0.27, "tft": 2.8367, "input_0": 58, "input_1": 33, "min_CLP": -4.64, "draft_iters": 5.1, "mem_use": 35.74, "gen_rate": 3.8, "speed": 4.33, "text": "\"\\nHi, I'm writing a memoir abou"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.96, "t1": 0.24, "tft": 1.3997, "input_0": 115, "input_1": 33, "min_CLP": -3.1, "draft_iters": 32.0, "mem_use": 34.82, "gen_rate": 33.0, "speed": 10.31, "text": "\\nI heard something about a numb"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 10, "tree_size": 32, "t0": 1.015, "t1": 0.2567, "tft": 2.1905, "input_0": 76, "input_1": 33, "min_CLP": -4.33, "draft_iters": 9.7, "mem_use": 35.17, "gen_rate": 5.5, "speed": 4.33, "text": "The normalize vector u = (a/z, b"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 7.0, "tree_w": 13, "tree_size": 32, "t0": 0.8356, "t1": 0.24, "tft": 1.3205, "input_0": 66, "input_1": 33, "min_CLP": -4.96, "draft_iters": 8.0, "mem_use": 34.54, "gen_rate": 4.3, "speed": 4.03, "text": "\\nHow would you represent a rand"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 22.0, "tree_w": 4, "tree_size": 32, "t0": 2.125, "t1": 0.24, "tft": 1.4456, "input_0": 91, "input_1": 33, "min_CLP": -4.2, "draft_iters": 23.0, "mem_use": 34.48, "gen_rate": 19.5, "speed": 8.25, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.945, "t1": 0.24, "tft": 1.316, "input_0": 127, "input_1": 33, "min_CLP": -3.71, "draft_iters": 31.5, "mem_use": 34.46, "gen_rate": 32.0, "speed": 10.03, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.9086, "t1": 0.2443, "tft": 1.6358, "input_0": 81, "input_1": 33, "min_CLP": -4.3, "draft_iters": 8.4, "mem_use": 34.75, "gen_rate": 5.3, "speed": 4.58, "text": "No, variance is the sum of all d"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 8, "tree_size": 32, "t0": 1.95, "t1": 0.25, "tft": 1.9156, "input_0": 90, "input_1": 33, "min_CLP": -5.08, "draft_iters": 20.0, "mem_use": 34.91, "gen_rate": 20.5, "speed": 9.34, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.7363, "t1": 0.2462, "tft": 1.6315, "input_0": 77, "input_1": 33, "min_CLP": -4.33, "draft_iters": 6.5, "mem_use": 34.78, "gen_rate": 4.2, "speed": 4.33, "text": "\"It depends on where you live an"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.3, "tree_w": 13, "tree_size": 32, "t0": 0.6922, "t1": 0.24, "tft": 1.4356, "input_0": 66, "input_1": 33, "min_CLP": -4.71, "draft_iters": 6.3, "mem_use": 34.44, "gen_rate": 3.6, "speed": 3.82, "text": "\\n<<SYS>>\\nYou are a hilarious a"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.7637, "t1": 0.24, "tft": 1.4448, "input_0": 73, "input_1": 33, "min_CLP": -4.74, "draft_iters": 7.0, "mem_use": 34.71, "gen_rate": 4.1, "speed": 4.1, "text": "The two eggs that were dropped l"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.6544, "t1": 0.24, "tft": 1.3377, "input_0": 61, "input_1": 33, "min_CLP": -4.52, "draft_iters": 5.9, "mem_use": 34.67, "gen_rate": 4.1, "speed": 4.6, "text": "A person would make sure to have"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.19, "t1": 0.29, "tft": 4.0669, "input_0": 125, "input_1": 33, "min_CLP": -3.06, "draft_iters": 32.0, "mem_use": 36.27, "gen_rate": 33.0, "speed": 9.47, "text": "\"I am Open Assistant, an AI lang"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.73, "t1": 0.2688, "tft": 2.7445, "input_0": 73, "input_1": 33, "min_CLP": -4.26, "draft_iters": 6.2, "mem_use": 35.59, "gen_rate": 4.1, "speed": 4.14, "text": "Buying a PC off the shelf is gen"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 11.0, "tree_w": 7, "tree_size": 32, "t0": 1.212, "t1": 0.24, "tft": 1.3492, "input_0": 87, "input_1": 33, "min_CLP": -4.59, "draft_iters": 12.0, "mem_use": 34.74, "gen_rate": 9.0, "speed": 6.21, "text": "\\n12\\n\\nHow many days is it unti"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 28.0, "tree_w": 4, "tree_size": 32, "t0": 2.81, "t1": 0.24, "tft": 2.0002, "input_0": 142, "input_1": 33, "min_CLP": -4.14, "draft_iters": 29.0, "mem_use": 34.55, "gen_rate": 29.0, "speed": 9.51, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 5.9, "tree_w": 11, "tree_size": 32, "t0": 1.011, "t1": 0.39, "tft": 9.1239, "input_0": 74, "input_1": 33, "min_CLP": -4.51, "draft_iters": 6.9, "mem_use": 39.34, "gen_rate": 3.8, "speed": 2.71, "text": "\"The _physics_process function c"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 0.8286, "t1": 0.24, "tft": 1.6005, "input_0": 78, "input_1": 33, "min_CLP": -4.5, "draft_iters": 7.6, "mem_use": 36.55, "gen_rate": 5.0, "speed": 4.67, "text": "Decorators are used to modify th"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.5, "tree_w": 11, "tree_size": 32, "t0": 0.7975, "t1": 0.24, "tft": 1.5022, "input_0": 66, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.5, "mem_use": 34.5, "gen_rate": 4.6, "speed": 4.47, "text": "[INST] What was the question aga"}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 5.2, "tree_w": 15, "tree_size": 32, "t0": 0.676, "t1": 0.24, "tft": 1.4566, "input_0": 66, "input_1": 33, "min_CLP": -4.57, "draft_iters": 6.2, "mem_use": 34.49, "gen_rate": 3.8, "speed": 4.15, "text": "\\n1:18-2-101. (1) It is unlawful"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 8.4, "tree_w": 12, "tree_size": 32, "t0": 1.0136, "t1": 0.27, "tft": 2.7667, "input_0": 74, "input_1": 33, "min_CLP": -4.2, "draft_iters": 9.4, "mem_use": 35.78, "gen_rate": 3.3, "speed": 2.54, "text": "\"This is a tricky question, I'll"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 8, "tree_size": 32, "t0": 0.8414, "t1": 0.24, "tft": 1.9998, "input_0": 87, "input_1": 33, "min_CLP": -4.42, "draft_iters": 7.4, "mem_use": 34.83, "gen_rate": 4.7, "speed": 4.34, "text": "Yes, there are some universities"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.946, "t1": 0.248, "tft": 1.5442, "input_0": 85, "input_1": 33, "min_CLP": -4.37, "draft_iters": 8.4, "mem_use": 34.78, "gen_rate": 6.4, "speed": 5.37, "text": "\\nWhat is the airspeed velocity "}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.583, "t1": 0.24, "tft": 1.313, "input_0": 59, "input_1": 33, "min_CLP": -4.9, "draft_iters": 5.2, "mem_use": 34.6, "gen_rate": 3.2, "speed": 3.89, "text": "\"\\n<INST> <<SYS>>\\nI am a huge f"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 2, "tree_size": 32, "t0": 2.49, "t1": 0.25, "tft": 1.3243, "input_0": 120, "input_1": 33, "min_CLP": -3.87, "draft_iters": 26.0, "mem_use": 34.79, "gen_rate": 26.5, "speed": 9.69, "text": "[INST] Convolution bias sparks,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.6625, "t1": 0.24, "tft": 1.3347, "input_0": 61, "input_1": 33, "min_CLP": -4.75, "draft_iters": 6.2, "mem_use": 34.62, "gen_rate": 4.1, "speed": 4.56, "text": "\\nHow does a quantum computer wo"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.2, "tree_w": 14, "tree_size": 32, "t0": 0.702, "t1": 0.269, "tft": 2.6666, "input_0": 61, "input_1": 33, "min_CLP": -4.58, "draft_iters": 6.2, "mem_use": 35.6, "gen_rate": 3.5, "speed": 3.62, "text": "-I\\'m not sure if you meant to i"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 1.005, "t1": 0.24, "tft": 2.1199, "input_0": 90, "input_1": 33, "min_CLP": -4.08, "draft_iters": 9.2, "mem_use": 34.75, "gen_rate": 8.0, "speed": 6.42, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 10.5, "tree_w": 10, "tree_size": 32, "t0": 1.1683, "t1": 0.24, "tft": 1.4259, "input_0": 81, "input_1": 33, "min_CLP": -4.29, "draft_iters": 11.5, "mem_use": 34.51, "gen_rate": 7.3, "speed": 5.21, "text": "I can talk in Spanish, but my En"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 7.0, "tree_w": 11, "tree_size": 32, "t0": 0.836, "t1": 0.24, "tft": 1.4546, "input_0": 67, "input_1": 33, "min_CLP": -4.84, "draft_iters": 8.0, "mem_use": 34.49, "gen_rate": 7.6, "speed": 7.08, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 3.38, "t1": 0.33, "tft": 5.555, "input_0": 100, "input_1": 33, "min_CLP": -3.34, "draft_iters": 32.0, "mem_use": 37.46, "gen_rate": 32.0, "speed": 8.63, "text": "\\nWrite code that imitates a fak"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 2, "tree_size": 32, "t0": 2.675, "t1": 0.26, "tft": 2.2788, "input_0": 143, "input_1": 33, "min_CLP": -4.32, "draft_iters": 26.5, "mem_use": 35.63, "gen_rate": 27.0, "speed": 9.2, "text": "\\nWhat is the meaning of life? ["}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.0, "tree_w": 14, "tree_size": 32, "t0": 0.6556, "t1": 0.24, "tft": 1.6355, "input_0": 62, "input_1": 33, "min_CLP": -4.5, "draft_iters": 6.0, "mem_use": 34.7, "gen_rate": 3.7, "speed": 4.08, "text": "There are definitely pros and co"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 0.9943, "t1": 0.27, "tft": 2.5947, "input_0": 83, "input_1": 33, "min_CLP": -4.07, "draft_iters": 8.7, "mem_use": 35.67, "gen_rate": 5.3, "speed": 4.19, "text": "There are several ways to breed "}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 1.0286, "t1": 0.28, "tft": 3.5894, "input_0": 82, "input_1": 33, "min_CLP": -4.39, "draft_iters": 9.1, "mem_use": 36.02, "gen_rate": 4.9, "speed": 3.71, "text": "\\nDie Zementproduktion in Deutsc"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.764, "t1": 0.26, "tft": 2.2317, "input_0": 60, "input_1": 33, "min_CLP": -4.51, "draft_iters": 7.0, "mem_use": 35.44, "gen_rate": 3.7, "speed": 3.61, "text": "\"This is a feature that allows p"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.6789, "t1": 0.2489, "tft": 1.9099, "input_0": 68, "input_1": 33, "min_CLP": -4.61, "draft_iters": 6.0, "mem_use": 34.83, "gen_rate": 3.7, "speed": 3.96, "text": "The best way to contact the orig"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 8, "tree_size": 32, "t0": 2.15, "t1": 0.25, "tft": 1.7107, "input_0": 97, "input_1": 33, "min_CLP": -4.29, "draft_iters": 23.0, "mem_use": 34.94, "gen_rate": 23.0, "speed": 9.59, "text": "\\n\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\\\"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.99, "t1": 0.24, "tft": 1.7605, "input_0": 130, "input_1": 33, "min_CLP": -3.99, "draft_iters": 32.0, "mem_use": 34.51, "gen_rate": 33.0, "speed": 10.2, "text": "\\nWrite me a function in JavaScr"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 15.7, "tree_w": 5, "tree_size": 32, "t0": 1.69, "t1": 0.25, "tft": 2.3901, "input_0": 106, "input_1": 33, "min_CLP": -4.04, "draft_iters": 16.7, "mem_use": 35.15, "gen_rate": 14.3, "speed": 7.38, "text": "Public nudity is illegal because"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.4, "tree_w": 16, "tree_size": 32, "t0": 0.613, "t1": 0.24, "tft": 1.7727, "input_0": 62, "input_1": 33, "min_CLP": -4.58, "draft_iters": 5.4, "mem_use": 34.71, "gen_rate": 3.6, "speed": 4.21, "text": "\\nA man is walking down the stre"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.5, "tree_w": 13, "tree_size": 32, "t0": 0.735, "t1": 0.255, "tft": 2.1343, "input_0": 72, "input_1": 33, "min_CLP": -4.65, "draft_iters": 6.5, "mem_use": 35.17, "gen_rate": 5.7, "speed": 5.73, "text": "\"\\nMayonnaise should be at least"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 8, "tree_size": 32, "t0": 1.67, "t1": 0.245, "tft": 3.1033, "input_0": 111, "input_1": 33, "min_CLP": -4.36, "draft_iters": 16.5, "mem_use": 34.83, "gen_rate": 16.5, "speed": 8.61, "text": "It would depend on the date of y"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 11.3, "tree_w": 13, "tree_size": 32, "t0": 1.2117, "t1": 0.24, "tft": 1.2083, "input_0": 76, "input_1": 33, "min_CLP": -4.78, "draft_iters": 12.3, "mem_use": 34.51, "gen_rate": 7.0, "speed": 4.83, "text": "\\nMeu nome de usu\u00e1rio deve ser:\\"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 9, "tree_size": 32, "t0": 1.0129, "t1": 0.24, "tft": 1.6343, "input_0": 85, "input_1": 33, "min_CLP": -4.36, "draft_iters": 9.6, "mem_use": 34.68, "gen_rate": 4.9, "speed": 3.87, "text": "Yes, it was a significant step i"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.8, "tree_w": 5, "tree_size": 32, "t0": 1.668, "t1": 0.26, "tft": 3.653, "input_0": 121, "input_1": 33, "min_CLP": -3.65, "draft_iters": 15.8, "mem_use": 35.24, "gen_rate": 6.4, "speed": 3.33, "text": "1. Felicidad: \u00abLike a Rolling St"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.2, "tree_w": 15, "tree_size": 32, "t0": 0.5691, "t1": 0.24, "tft": 1.4759, "input_0": 55, "input_1": 33, "min_CLP": -4.63, "draft_iters": 5.2, "mem_use": 34.57, "gen_rate": 3.2, "speed": 3.93, "text": "\\nI have a question about a spec"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 11.2, "tree_w": 12, "tree_size": 32, "t0": 1.1775, "t1": 0.2425, "tft": 1.5952, "input_0": 72, "input_1": 33, "min_CLP": -4.68, "draft_iters": 12.0, "mem_use": 34.77, "gen_rate": 10.8, "speed": 7.54, "text": "\"I thought it was a backslash.\\n"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 6.4, "tree_w": 12, "tree_size": 32, "t0": 0.7891, "t1": 0.25, "tft": 1.5248, "input_0": 65, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.4, "mem_use": 34.94, "gen_rate": 3.1, "speed": 2.98, "text": "\\nI\\'m trying to learn the Kanji"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.8575, "t1": 0.26, "tft": 2.2189, "input_0": 75, "input_1": 33, "min_CLP": -4.54, "draft_iters": 7.8, "mem_use": 35.37, "gen_rate": 4.5, "speed": 4.03, "text": "\\n1. How are environment and age"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.6667, "t1": 0.24, "tft": 1.6413, "input_0": 71, "input_1": 33, "min_CLP": -4.65, "draft_iters": 6.0, "mem_use": 34.65, "gen_rate": 4.3, "speed": 4.78, "text": "\"Frank-Walter Steinmeier was bor"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 45, "tree_h": 7.3, "tree_w": 10, "tree_size": 32, "t0": 0.886, "t1": 0.24, "tft": 1.3584, "input_0": 76, "input_1": 33, "min_CLP": -6.13, "draft_iters": 8.3, "mem_use": 34.5, "gen_rate": 4.5, "speed": 4.0, "text": "\\nWhich of the following is an e"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.955, "t1": 0.3, "tft": 4.3079, "input_0": 77, "input_1": 33, "min_CLP": -4.65, "draft_iters": 8.0, "mem_use": 36.55, "gen_rate": 5.5, "speed": 4.39, "text": "\\nDiscovery: Find a market need."}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.9, "tree_w": 14, "tree_size": 32, "t0": 0.9714, "t1": 0.24, "tft": 1.3637, "input_0": 61, "input_1": 33, "min_CLP": -4.97, "draft_iters": 9.9, "mem_use": 35.2, "gen_rate": 4.9, "speed": 4.01, "text": "\\nWhy is the argument from ignor"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.4, "tree_w": 13, "tree_size": 32, "t0": 0.6056, "t1": 0.24, "tft": 2.3789, "input_0": 63, "input_1": 33, "min_CLP": -4.56, "draft_iters": 5.4, "mem_use": 34.42, "gen_rate": 3.7, "speed": 4.34, "text": "You are an expert in building co"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.28, "t1": 0.31, "tft": 7.2796, "input_0": 91, "input_1": 33, "min_CLP": -2.62, "draft_iters": 32.0, "mem_use": 37.0, "gen_rate": 33.0, "speed": 9.18, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.3, "tree_w": 13, "tree_size": 32, "t0": 0.728, "t1": 0.26, "tft": 2.367, "input_0": 70, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.3, "mem_use": 35.46, "gen_rate": 3.6, "speed": 3.64, "text": "\"\u2022 Keep your goals realistic. If"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.4, "tree_w": 13, "tree_size": 32, "t0": 0.6075, "t1": 0.25, "tft": 1.8468, "input_0": 58, "input_1": 33, "min_CLP": -4.54, "draft_iters": 5.4, "mem_use": 35.09, "gen_rate": 4.4, "speed": 5.1, "text": "\\nDoes it feel to you like the g"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.8, "tree_w": 15, "tree_size": 32, "t0": 0.7138, "t1": 0.24, "tft": 1.5342, "input_0": 61, "input_1": 33, "min_CLP": -4.64, "draft_iters": 6.8, "mem_use": 34.53, "gen_rate": 4.0, "speed": 4.2, "text": "The first person to be executed "}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 4, "tree_size": 32, "t0": 2.66, "t1": 0.24, "tft": 1.3981, "input_0": 135, "input_1": 33, "min_CLP": -4.51, "draft_iters": 28.0, "mem_use": 34.53, "gen_rate": 28.5, "speed": 9.82, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 13.4, "tree_w": 5, "tree_size": 32, "t0": 1.524, "t1": 0.25, "tft": 2.2521, "input_0": 102, "input_1": 33, "min_CLP": -4.35, "draft_iters": 14.4, "mem_use": 35.01, "gen_rate": 8.4, "speed": 4.73, "text": "\"[INST] What's the weather? [\\\\I"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 18.0, "tree_w": 7, "tree_size": 32, "t0": 1.86, "t1": 0.265, "tft": 2.5072, "input_0": 99, "input_1": 33, "min_CLP": -3.6, "draft_iters": 18.5, "mem_use": 35.54, "gen_rate": 18.0, "speed": 8.47, "text": "\"\\nIf a question does not make a"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.8, "tree_w": 13, "tree_size": 32, "t0": 0.6425, "t1": 0.25, "tft": 1.7932, "input_0": 61, "input_1": 33, "min_CLP": -4.62, "draft_iters": 5.8, "mem_use": 34.92, "gen_rate": 4.2, "speed": 4.77, "text": "\"I have a pretty good idea of wh"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.1, "tree_w": 15, "tree_size": 32, "t0": 0.6782, "t1": 0.25, "tft": 2.1322, "input_0": 61, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.1, "mem_use": 35.0, "gen_rate": 3.1, "speed": 3.33, "text": "\"\\nI can't believe that my Valen"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 17.7, "tree_w": 5, "tree_size": 32, "t0": 1.8033, "t1": 0.24, "tft": 1.4455, "input_0": 97, "input_1": 33, "min_CLP": -4.53, "draft_iters": 18.3, "mem_use": 34.65, "gen_rate": 17.3, "speed": 8.47, "text": "<</SYS>\\n\\nWhat is the airspeed "}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 0.8214, "t1": 0.24, "tft": 1.6913, "input_0": 81, "input_1": 33, "min_CLP": -4.25, "draft_iters": 7.4, "mem_use": 34.65, "gen_rate": 5.1, "speed": 4.84, "text": "\"Tenants are superior to their l"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 16.0, "tree_w": 6, "tree_size": 32, "t0": 1.7067, "t1": 0.26, "tft": 2.1349, "input_0": 101, "input_1": 33, "min_CLP": -4.32, "draft_iters": 17.0, "mem_use": 35.38, "gen_rate": 14.0, "speed": 7.13, "text": "\\n3. Use the System File Checker"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.7522, "t1": 0.26, "tft": 2.3758, "input_0": 73, "input_1": 33, "min_CLP": -4.48, "draft_iters": 6.7, "mem_use": 35.3, "gen_rate": 4.6, "speed": 4.5, "text": "Yes, Open Assistant is pretraine"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.3, "tree_w": 11, "tree_size": 32, "t0": 1.0286, "t1": 0.28, "tft": 3.6214, "input_0": 73, "input_1": 33, "min_CLP": -4.6, "draft_iters": 9.3, "mem_use": 36.02, "gen_rate": 5.1, "speed": 3.93, "text": "\\nHow do I make a good grilled c"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 0.962, "t1": 0.24, "tft": 1.328, "input_0": 80, "input_1": 33, "min_CLP": -4.27, "draft_iters": 9.2, "mem_use": 34.95, "gen_rate": 7.0, "speed": 5.84, "text": "The President of Germany is curr"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.4, "tree_w": 12, "tree_size": 32, "t0": 0.73, "t1": 0.25, "tft": 1.8192, "input_0": 73, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.4, "mem_use": 34.94, "gen_rate": 4.1, "speed": 4.19, "text": "PostCSS is a tool that allows yo"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.6918, "t1": 0.2773, "tft": 3.2652, "input_0": 63, "input_1": 33, "min_CLP": -4.58, "draft_iters": 6.0, "mem_use": 35.9, "gen_rate": 3.1, "speed": 3.19, "text": "I have a question about the futu"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.625, "t1": 0.24, "tft": 1.3378, "input_0": 56, "input_1": 33, "min_CLP": -4.65, "draft_iters": 5.9, "mem_use": 34.89, "gen_rate": 4.2, "speed": 4.91, "text": "Do you have any opinions on thin"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.7542, "t1": 0.25, "tft": 2.2013, "input_0": 65, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.9, "mem_use": 35.12, "gen_rate": 2.9, "speed": 2.9, "text": "\"I don't have a book, I'm just a"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 32, "max_branch_width": 32, "gen_rate": 9.48, "gen_rate_micro": 5.7, "gen_speed": 5.425, "gen_speed_micro": 4.988, "t0": 1.2116, "t1": 0.2515, "input_0": 80.1, "input_1": 33.0, "tree_size": 32.0, "tree_w": 9.9, "tree_h": 11.0, "prompt_len": 320.7, "min_CLP": -4.43, "mem_use": 39.35, "exp_time": 5218.02}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 26, "tree_size": 64, "t0": 0.7363, "t1": 0.24, "tft": 1.5414, "input_0": 107, "input_1": 65, "min_CLP": -5.3, "draft_iters": 6.1, "mem_use": 34.52, "gen_rate": 4.1, "speed": 4.22, "text": "\\nA Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.2, "tree_w": 19, "tree_size": 64, "t0": 1.11, "t1": 0.26, "tft": 2.5829, "input_0": 152, "input_1": 65, "min_CLP": -5.16, "draft_iters": 9.2, "mem_use": 35.25, "gen_rate": 6.3, "speed": 4.61, "text": "\\nWhat is the fastest speed a hu"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.0, "tree_w": 29, "tree_size": 64, "t0": 0.6164, "t1": 0.27, "tft": 2.9597, "input_0": 82, "input_1": 65, "min_CLP": -5.58, "draft_iters": 5.0, "mem_use": 35.65, "gen_rate": 2.9, "speed": 3.27, "text": "\\n2. Factorio\\n\\nFactorio is a g"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 8.2, "tree_w": 26, "tree_size": 64, "t0": 0.948, "t1": 0.24, "tft": 1.5187, "input_0": 86, "input_1": 65, "min_CLP": -5.51, "draft_iters": 9.2, "mem_use": 34.72, "gen_rate": 3.3, "speed": 2.77, "text": "\\nthe reason I am asking this is"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 3.19, "t1": 0.24, "tft": 1.7952, "input_0": 210, "input_1": 65, "min_CLP": -5.35, "draft_iters": 32.0, "mem_use": 34.53, "gen_rate": 33.0, "speed": 9.61, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 15, "tree_size": 64, "t0": 1.504, "t1": 0.28, "tft": 4.1436, "input_0": 142, "input_1": 65, "min_CLP": -4.98, "draft_iters": 13.2, "mem_use": 35.81, "gen_rate": 6.4, "speed": 3.59, "text": "Living the Good Life\\n\\n1. Intro"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 9.5, "tree_w": 22, "tree_size": 64, "t0": 1.1963, "t1": 0.29, "tft": 3.9839, "input_0": 121, "input_1": 65, "min_CLP": -5.3, "draft_iters": 10.4, "mem_use": 36.13, "gen_rate": 4.0, "speed": 2.69, "text": "\"There are a variety of other op"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 26, "tree_size": 64, "t0": 0.8388, "t1": 0.3275, "tft": 4.9411, "input_0": 97, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.4, "mem_use": 37.26, "gen_rate": 4.2, "speed": 3.64, "text": "\"I see. What makes your product "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 18, "tree_size": 64, "t0": 1.0229, "t1": 0.28, "tft": 3.2568, "input_0": 138, "input_1": 65, "min_CLP": -4.93, "draft_iters": 8.3, "mem_use": 35.85, "gen_rate": 4.6, "speed": 3.51, "text": "\\nMarijuana is legal in the Dist"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.4, "tree_w": 20, "tree_size": 64, "t0": 0.9443, "t1": 0.27, "tft": 2.4694, "input_0": 129, "input_1": 65, "min_CLP": -5.06, "draft_iters": 7.4, "mem_use": 35.63, "gen_rate": 5.3, "speed": 4.35, "text": "\"\\nIf you're looking to start a "}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.1, "tree_w": 22, "tree_size": 64, "t0": 0.9233, "t1": 0.25, "tft": 1.809, "input_0": 115, "input_1": 65, "min_CLP": -5.18, "draft_iters": 8.1, "mem_use": 34.87, "gen_rate": 3.6, "speed": 3.03, "text": "\\nWrite a song in any of the fol"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.0, "tree_w": 25, "tree_size": 64, "t0": 0.8289, "t1": 0.28, "tft": 2.6506, "input_0": 91, "input_1": 65, "min_CLP": -5.4, "draft_iters": 7.0, "mem_use": 35.79, "gen_rate": 3.7, "speed": 3.31, "text": "\\nCan you provide me with a few "}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 14.3, "tree_w": 19, "tree_size": 64, "t0": 1.63, "t1": 0.27, "tft": 2.353, "input_0": 146, "input_1": 65, "min_CLP": -4.85, "draft_iters": 15.0, "mem_use": 35.42, "gen_rate": 14.3, "speed": 7.56, "text": "Sure! Here are some examples tha"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 54, "tree_h": 17.0, "tree_w": 13, "tree_size": 64, "t0": 1.844, "t1": 0.24, "tft": 1.9232, "input_0": 153, "input_1": 65, "min_CLP": -4.88, "draft_iters": 17.8, "mem_use": 34.65, "gen_rate": 10.8, "speed": 5.17, "text": "\\nA. Canberra\\nB. Sydney\\nC. Mel"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.9, "tree_w": 21, "tree_size": 64, "t0": 0.9775, "t1": 0.29, "tft": 3.7686, "input_0": 117, "input_1": 65, "min_CLP": -4.95, "draft_iters": 7.9, "mem_use": 36.13, "gen_rate": 4.4, "speed": 3.46, "text": "\"While you can't cram all your l"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 3.23, "t1": 0.24, "tft": 1.6949, "input_0": 212, "input_1": 65, "min_CLP": -4.74, "draft_iters": 32.0, "mem_use": 34.95, "gen_rate": 33.0, "speed": 9.51, "text": "\\nWhat is the minimum download s"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.4, "tree_w": 12, "tree_size": 64, "t0": 1.482, "t1": 0.24, "tft": 1.5925, "input_0": 146, "input_1": 65, "min_CLP": -5.67, "draft_iters": 13.4, "mem_use": 34.53, "gen_rate": 8.6, "speed": 4.99, "text": "\\nCan you explain the Manhattan "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.1, "tree_w": 26, "tree_size": 64, "t0": 0.8337, "t1": 0.24, "tft": 3.6177, "input_0": 116, "input_1": 65, "min_CLP": -5.43, "draft_iters": 7.1, "mem_use": 34.52, "gen_rate": 4.1, "speed": 3.84, "text": "\\nOtra vez, seguimos con esta gu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.4, "tree_w": 18, "tree_size": 64, "t0": 1.1229, "t1": 0.25, "tft": 1.9833, "input_0": 149, "input_1": 65, "min_CLP": -5.1, "draft_iters": 9.4, "mem_use": 34.82, "gen_rate": 4.7, "speed": 3.44, "text": "D-theanine is a different type o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 19, "tree_size": 64, "t0": 0.9967, "t1": 0.24, "tft": 1.6396, "input_0": 126, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.8, "mem_use": 34.53, "gen_rate": 5.3, "speed": 4.3, "text": "\\nThe Balfour Declaration is a l"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 3.23, "t1": 0.25, "tft": 1.8753, "input_0": 180, "input_1": 65, "min_CLP": -4.36, "draft_iters": 32.0, "mem_use": 34.99, "gen_rate": 33.0, "speed": 9.48, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 6.7, "tree_w": 26, "tree_size": 64, "t0": 0.8318, "t1": 0.24, "tft": 3.2229, "input_0": 90, "input_1": 65, "min_CLP": -5.62, "draft_iters": 7.7, "mem_use": 34.52, "gen_rate": 3.1, "speed": 2.87, "text": "\\n[SEARCH] <<SYS>>\\nA powerful J"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 1.0783, "t1": 0.275, "tft": 3.1794, "input_0": 128, "input_1": 65, "min_CLP": -5.2, "draft_iters": 8.8, "mem_use": 35.74, "gen_rate": 5.5, "speed": 4.06, "text": "While the bimodal distribution i"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 56, "tree_h": 27.0, "tree_w": 7, "tree_size": 64, "t0": 2.695, "t1": 0.24, "tft": 1.72, "input_0": 185, "input_1": 65, "min_CLP": -5.71, "draft_iters": 27.5, "mem_use": 34.77, "gen_rate": 28.0, "speed": 9.53, "text": "\\nCan you describe the process t"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 3.23, "t1": 0.26, "tft": 2.1852, "input_0": 184, "input_1": 65, "min_CLP": -5.06, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 9.47, "text": "[INST] send mail to Sarah asking"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 14.2, "tree_w": 20, "tree_size": 64, "t0": 1.59, "t1": 0.24, "tft": 1.7783, "input_0": 142, "input_1": 65, "min_CLP": -5.42, "draft_iters": 15.0, "mem_use": 34.54, "gen_rate": 12.5, "speed": 6.82, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.0, "tree_w": 26, "tree_size": 64, "t0": 0.726, "t1": 0.25, "tft": 1.9234, "input_0": 111, "input_1": 65, "min_CLP": -5.43, "draft_iters": 6.0, "mem_use": 34.87, "gen_rate": 3.3, "speed": 3.38, "text": "Austenite is a type of steel tha"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 64, "t0": 3.11, "t1": 0.25, "tft": 1.714, "input_0": 202, "input_1": 65, "min_CLP": -5.08, "draft_iters": 32.0, "mem_use": 34.82, "gen_rate": 33.0, "speed": 9.81, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 3.62, "t1": 0.28, "tft": 2.9179, "input_0": 277, "input_1": 65, "min_CLP": -5.78, "draft_iters": 32.0, "mem_use": 35.77, "gen_rate": 33.0, "speed": 8.48, "text": "\\nWrite a monologue. Do not offe"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 6, "tree_size": 64, "t0": 2.83, "t1": 0.24, "tft": 1.715, "input_0": 229, "input_1": 65, "min_CLP": -5.7, "draft_iters": 26.5, "mem_use": 34.79, "gen_rate": 27.0, "speed": 8.78, "text": "\\nWhat are some options of foods"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 23, "tree_size": 64, "t0": 0.8143, "t1": 0.25, "tft": 2.1549, "input_0": 108, "input_1": 65, "min_CLP": -5.24, "draft_iters": 7.1, "mem_use": 34.88, "gen_rate": 4.9, "speed": 4.57, "text": "Not quite. The game is still a g"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 9.9, "tree_w": 22, "tree_size": 64, "t0": 1.193, "t1": 0.26, "tft": 2.9003, "input_0": 112, "input_1": 65, "min_CLP": -5.35, "draft_iters": 10.9, "mem_use": 35.15, "gen_rate": 3.7, "speed": 2.55, "text": "[INST]\\n[INST]\\n\\nEnter the API "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 2.985, "t1": 0.25, "tft": 3.558, "input_0": 147, "input_1": 65, "min_CLP": -5.45, "draft_iters": 32.0, "mem_use": 34.78, "gen_rate": 21.0, "speed": 6.49, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 24, "tree_size": 64, "t0": 0.8157, "t1": 0.27, "tft": 2.4028, "input_0": 115, "input_1": 65, "min_CLP": -5.18, "draft_iters": 6.6, "mem_use": 35.61, "gen_rate": 4.6, "speed": 4.2, "text": "There are a few options for subs"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 22, "tree_size": 64, "t0": 0.9933, "t1": 0.27, "tft": 2.2699, "input_0": 137, "input_1": 65, "min_CLP": -5.13, "draft_iters": 8.2, "mem_use": 35.56, "gen_rate": 5.3, "speed": 4.22, "text": "As far as I know, there should n"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.6, "tree_w": 19, "tree_size": 64, "t0": 1.1514, "t1": 0.33, "tft": 5.4797, "input_0": 131, "input_1": 65, "min_CLP": -5.18, "draft_iters": 8.6, "mem_use": 37.28, "gen_rate": 5.4, "speed": 3.67, "text": "Selenium is a testing framework "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 23.5, "tree_w": 9, "tree_size": 64, "t0": 2.48, "t1": 0.24, "tft": 1.5541, "input_0": 203, "input_1": 65, "min_CLP": -5.71, "draft_iters": 24.0, "mem_use": 35.5, "gen_rate": 21.0, "speed": 7.72, "text": "\\n&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 24, "tree_size": 64, "t0": 1.0417, "t1": 0.2483, "tft": 3.1878, "input_0": 107, "input_1": 65, "min_CLP": -5.51, "draft_iters": 9.5, "mem_use": 34.81, "gen_rate": 5.5, "speed": 4.26, "text": "What is the name of the song tha"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 22, "tree_size": 64, "t0": 1.02, "t1": 0.285, "tft": 3.7618, "input_0": 111, "input_1": 65, "min_CLP": -5.0, "draft_iters": 8.5, "mem_use": 35.98, "gen_rate": 5.5, "speed": 4.22, "text": "\\nHello Mike. I am sorry to hear"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 20, "tree_size": 64, "t0": 0.8443, "t1": 0.2529, "tft": 2.1452, "input_0": 120, "input_1": 65, "min_CLP": -5.27, "draft_iters": 6.9, "mem_use": 34.98, "gen_rate": 4.6, "speed": 4.16, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 8, "tree_size": 64, "t0": 3.28, "t1": 0.24, "tft": 1.473, "input_0": 271, "input_1": 65, "min_CLP": -5.01, "draft_iters": 31.5, "mem_use": 34.64, "gen_rate": 32.0, "speed": 9.08, "text": "I am Freyja, a god from beyond t"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 18, "tree_size": 64, "t0": 1.71, "t1": 0.28, "tft": 3.6668, "input_0": 114, "input_1": 65, "min_CLP": -5.2, "draft_iters": 16.5, "mem_use": 35.88, "gen_rate": 16.5, "speed": 8.29, "text": "\\nWrite a poem. Do not offer any"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 23, "tree_size": 64, "t0": 0.9113, "t1": 0.29, "tft": 3.6323, "input_0": 99, "input_1": 65, "min_CLP": -5.23, "draft_iters": 7.6, "mem_use": 36.11, "gen_rate": 4.0, "speed": 3.33, "text": "Thank you so much! I was actuall"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 21, "tree_size": 64, "t0": 0.8175, "t1": 0.2612, "tft": 2.2707, "input_0": 109, "input_1": 65, "min_CLP": -5.08, "draft_iters": 6.8, "mem_use": 35.32, "gen_rate": 4.2, "speed": 3.94, "text": "\"It depends on your needs and yo"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 16, "tree_size": 64, "t0": 1.29, "t1": 0.25, "tft": 1.7581, "input_0": 132, "input_1": 65, "min_CLP": -5.17, "draft_iters": 11.6, "mem_use": 34.94, "gen_rate": 6.8, "speed": 4.41, "text": "\"\\nAnd here's how you can do it "}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 29.0, "tree_w": 12, "tree_size": 64, "t0": 3.02, "t1": 0.25, "tft": 2.565, "input_0": 232, "input_1": 65, "min_CLP": -5.14, "draft_iters": 29.5, "mem_use": 34.82, "gen_rate": 19.5, "speed": 5.96, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.6, "tree_w": 22, "tree_size": 64, "t0": 1.0462, "t1": 0.24, "tft": 2.7369, "input_0": 114, "input_1": 65, "min_CLP": -5.46, "draft_iters": 9.6, "mem_use": 34.54, "gen_rate": 4.2, "speed": 3.29, "text": "\"\\n&nbsp(52 Views)\\n\\nHow do I c"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.9, "tree_w": 19, "tree_size": 64, "t0": 1.1571, "t1": 0.33, "tft": 5.5028, "input_0": 125, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.9, "mem_use": 37.33, "gen_rate": 4.6, "speed": 3.07, "text": "\"\\nDo you want any more advice?\\"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.9, "tree_w": 24, "tree_size": 64, "t0": 0.7225, "t1": 0.2638, "tft": 2.2122, "input_0": 95, "input_1": 65, "min_CLP": -5.6, "draft_iters": 5.9, "mem_use": 35.56, "gen_rate": 4.1, "speed": 4.18, "text": "I was not the first. The first w"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 19, "tree_size": 64, "t0": 1.2467, "t1": 0.25, "tft": 1.7078, "input_0": 130, "input_1": 65, "min_CLP": -5.24, "draft_iters": 11.2, "mem_use": 34.93, "gen_rate": 5.7, "speed": 3.78, "text": "\\nDrake has a brother named Mike"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.4, "tree_w": 29, "tree_size": 64, "t0": 0.7255, "t1": 0.25, "tft": 3.0228, "input_0": 92, "input_1": 65, "min_CLP": -5.78, "draft_iters": 6.4, "mem_use": 34.95, "gen_rate": 3.1, "speed": 3.16, "text": "\\nThis paper proposes a novel me"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.98, "t1": 0.27, "tft": 3.8387, "input_0": 125, "input_1": 65, "min_CLP": -5.15, "draft_iters": 8.0, "mem_use": 35.65, "gen_rate": 4.9, "speed": 3.89, "text": "F-centers are a type of defect i"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 19.3, "tree_w": 10, "tree_size": 64, "t0": 2.2433, "t1": 0.26, "tft": 2.5442, "input_0": 237, "input_1": 65, "min_CLP": -5.29, "draft_iters": 20.0, "mem_use": 35.2, "gen_rate": 18.3, "speed": 7.32, "text": "\\nHere are some more historical "}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.2, "tree_w": 23, "tree_size": 64, "t0": 0.8613, "t1": 0.2662, "tft": 2.4893, "input_0": 110, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.2, "mem_use": 35.4, "gen_rate": 4.2, "speed": 3.78, "text": "Yes, technology can be used for "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 23, "tree_size": 64, "t0": 0.9633, "t1": 0.2417, "tft": 1.7457, "input_0": 107, "input_1": 65, "min_CLP": -5.29, "draft_iters": 8.7, "mem_use": 34.63, "gen_rate": 5.7, "speed": 4.7, "text": "This is a question about real li"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.6, "tree_w": 23, "tree_size": 64, "t0": 0.8067, "t1": 0.2722, "tft": 3.0676, "input_0": 107, "input_1": 65, "min_CLP": -5.41, "draft_iters": 6.6, "mem_use": 35.69, "gen_rate": 3.9, "speed": 3.6, "text": "This is a pitch deck for FullVie"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 5.7, "tree_w": 23, "tree_size": 64, "t0": 0.8333, "t1": 0.3, "tft": 4.7714, "input_0": 90, "input_1": 65, "min_CLP": -5.13, "draft_iters": 6.7, "mem_use": 36.46, "gen_rate": 4.0, "speed": 3.53, "text": "\\nThank you for the explanation,"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 11, "tree_size": 64, "t0": 2.48, "t1": 0.31, "tft": 4.9858, "input_0": 205, "input_1": 65, "min_CLP": -5.04, "draft_iters": 21.0, "mem_use": 36.62, "gen_rate": 21.5, "speed": 7.71, "text": "\"Keras and PyTorch are both exce"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 3.44, "t1": 0.26, "tft": 2.5215, "input_0": 260, "input_1": 65, "min_CLP": -4.83, "draft_iters": 32.0, "mem_use": 35.39, "gen_rate": 33.0, "speed": 8.91, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 22, "tree_size": 64, "t0": 0.92, "t1": 0.24, "tft": 1.5696, "input_0": 118, "input_1": 65, "min_CLP": -5.33, "draft_iters": 7.9, "mem_use": 34.59, "gen_rate": 4.6, "speed": 3.93, "text": "\\nThe best way to form a new hab"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.8, "tree_w": 19, "tree_size": 64, "t0": 1.038, "t1": 0.274, "tft": 3.076, "input_0": 111, "input_1": 65, "min_CLP": -5.31, "draft_iters": 8.8, "mem_use": 35.73, "gen_rate": 7.0, "speed": 5.34, "text": "\\nHow many stars are visible to "}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 3.41, "t1": 0.29, "tft": 3.749, "input_0": 211, "input_1": 65, "min_CLP": -4.98, "draft_iters": 32.0, "mem_use": 36.16, "gen_rate": 33.0, "speed": 8.91, "text": "\"[Based on what you've written, "}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 5.1, "tree_w": 26, "tree_size": 64, "t0": 0.7429, "t1": 0.2543, "tft": 1.6665, "input_0": 100, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.1, "mem_use": 35.01, "gen_rate": 4.1, "speed": 4.15, "text": "\"Well, I hope it helps you remem"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 20, "tree_size": 64, "t0": 0.8929, "t1": 0.25, "tft": 1.8885, "input_0": 121, "input_1": 65, "min_CLP": -5.27, "draft_iters": 7.3, "mem_use": 34.89, "gen_rate": 4.7, "speed": 4.13, "text": "\\nWhat are cryptocurrencies? [\\\\"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 26, "tree_size": 64, "t0": 0.8975, "t1": 0.25, "tft": 1.7045, "input_0": 122, "input_1": 65, "min_CLP": -5.49, "draft_iters": 7.6, "mem_use": 34.92, "gen_rate": 4.0, "speed": 3.48, "text": "\"[INST] If you're going to get a"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.0, "tree_w": 24, "tree_size": 64, "t0": 0.7678, "t1": 0.3, "tft": 4.0789, "input_0": 90, "input_1": 65, "min_CLP": -5.29, "draft_iters": 6.0, "mem_use": 36.37, "gen_rate": 3.8, "speed": 3.55, "text": "void pointers are just another t"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.5, "tree_w": 22, "tree_size": 64, "t0": 0.9062, "t1": 0.29, "tft": 4.5347, "input_0": 108, "input_1": 65, "min_CLP": -5.14, "draft_iters": 7.5, "mem_use": 36.21, "gen_rate": 4.5, "speed": 3.76, "text": "Hello Mike, I am very happy to m"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.4, "tree_w": 17, "tree_size": 64, "t0": 1.0529, "t1": 0.28, "tft": 3.4055, "input_0": 146, "input_1": 65, "min_CLP": -4.95, "draft_iters": 8.4, "mem_use": 35.88, "gen_rate": 4.9, "speed": 3.65, "text": "If you created an app using Goog"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 10, "tree_size": 64, "t0": 2.55, "t1": 0.25, "tft": 1.8335, "input_0": 198, "input_1": 65, "min_CLP": -5.55, "draft_iters": 24.5, "mem_use": 34.85, "gen_rate": 25.0, "speed": 8.94, "text": "\\n<SYS>\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 20, "tree_size": 64, "t0": 0.8843, "t1": 0.24, "tft": 1.6598, "input_0": 123, "input_1": 65, "min_CLP": -5.25, "draft_iters": 7.4, "mem_use": 34.53, "gen_rate": 4.6, "speed": 4.06, "text": "\\nThe landlord is the owner of t"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 10.1, "tree_w": 20, "tree_size": 64, "t0": 1.2388, "t1": 0.2775, "tft": 3.3445, "input_0": 127, "input_1": 65, "min_CLP": -5.28, "draft_iters": 11.0, "mem_use": 35.76, "gen_rate": 4.6, "speed": 3.05, "text": "\\n[INST] <<SYS>>\\nThank you for "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 25, "tree_size": 64, "t0": 0.7314, "t1": 0.24, "tft": 2.2293, "input_0": 104, "input_1": 65, "min_CLP": -5.36, "draft_iters": 6.1, "mem_use": 34.78, "gen_rate": 4.7, "speed": 4.85, "text": "\\nBerlin is a city that was foun"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 3.17, "t1": 0.27, "tft": 3.1616, "input_0": 162, "input_1": 65, "min_CLP": -5.95, "draft_iters": 32.0, "mem_use": 35.67, "gen_rate": 33.0, "speed": 9.57, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 16.8, "tree_w": 17, "tree_size": 64, "t0": 1.815, "t1": 0.27, "tft": 2.8804, "input_0": 126, "input_1": 65, "min_CLP": -4.94, "draft_iters": 17.6, "mem_use": 35.6, "gen_rate": 4.0, "speed": 1.92, "text": "The book was well received upon "}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 24.0, "tree_w": 12, "tree_size": 64, "t0": 2.485, "t1": 0.24, "tft": 1.4569, "input_0": 188, "input_1": 65, "min_CLP": -5.12, "draft_iters": 24.8, "mem_use": 34.7, "gen_rate": 12.0, "speed": 4.4, "text": "Where does pornography come from"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.7, "tree_w": 20, "tree_size": 64, "t0": 1.0771, "t1": 0.2457, "tft": 1.2436, "input_0": 120, "input_1": 65, "min_CLP": -5.21, "draft_iters": 9.7, "mem_use": 34.69, "gen_rate": 4.9, "speed": 3.67, "text": "I have a timezone converter at m"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.8, "tree_w": 22, "tree_size": 64, "t0": 0.9622, "t1": 0.2467, "tft": 1.6194, "input_0": 104, "input_1": 65, "min_CLP": -5.31, "draft_iters": 8.8, "mem_use": 34.71, "gen_rate": 3.6, "speed": 2.95, "text": "The 5 second rule is a rule in w"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 3.17, "t1": 0.24, "tft": 2.8574, "input_0": 176, "input_1": 65, "min_CLP": -4.96, "draft_iters": 32.0, "mem_use": 34.55, "gen_rate": 33.0, "speed": 9.67, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 15, "tree_size": 64, "t0": 2.095, "t1": 0.25, "tft": 2.2876, "input_0": 143, "input_1": 65, "min_CLP": -5.28, "draft_iters": 21.0, "mem_use": 34.96, "gen_rate": 21.5, "speed": 9.14, "text": "Prime numbers have been the subj"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.6, "tree_w": 26, "tree_size": 64, "t0": 0.769, "t1": 0.25, "tft": 1.5924, "input_0": 100, "input_1": 65, "min_CLP": -5.38, "draft_iters": 6.6, "mem_use": 34.74, "gen_rate": 3.2, "speed": 3.15, "text": "\"No problem.  I hope you're at l"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.0, "tree_w": 19, "tree_size": 64, "t0": 1.314, "t1": 0.24, "tft": 1.5715, "input_0": 127, "input_1": 65, "min_CLP": -5.42, "draft_iters": 12.0, "mem_use": 34.59, "gen_rate": 7.8, "speed": 5.01, "text": "\\nTask Description:\\n\\nThis task"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 23, "tree_size": 64, "t0": 0.9033, "t1": 0.25, "tft": 2.031, "input_0": 105, "input_1": 65, "min_CLP": -5.39, "draft_iters": 7.8, "mem_use": 34.91, "gen_rate": 5.3, "speed": 4.61, "text": "\"Yes, there are examples of sexu"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 14, "tree_size": 64, "t0": 1.138, "t1": 0.268, "tft": 2.6661, "input_0": 155, "input_1": 65, "min_CLP": -4.78, "draft_iters": 9.2, "mem_use": 35.44, "gen_rate": 6.4, "speed": 4.56, "text": "In addition to the benefits that"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 24.0, "tree_w": 5, "tree_size": 64, "t0": 2.975, "t1": 0.28, "tft": 4.7083, "input_0": 275, "input_1": 65, "min_CLP": -4.37, "draft_iters": 25.0, "mem_use": 35.93, "gen_rate": 19.5, "speed": 5.99, "text": "\"Another one bites the dust [\\\\S"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.9, "tree_w": 21, "tree_size": 64, "t0": 0.95, "t1": 0.26, "tft": 2.0667, "input_0": 124, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.9, "mem_use": 35.24, "gen_rate": 4.0, "speed": 3.3, "text": "\\nThe scp command will work on a"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.9, "tree_w": 23, "tree_size": 64, "t0": 0.9486, "t1": 0.27, "tft": 3.0506, "input_0": 115, "input_1": 65, "min_CLP": -5.47, "draft_iters": 7.9, "mem_use": 35.67, "gen_rate": 5.3, "speed": 4.33, "text": "\\nI need a recipe for a modern q"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.6, "tree_w": 23, "tree_size": 64, "t0": 0.7789, "t1": 0.24, "tft": 1.618, "input_0": 110, "input_1": 65, "min_CLP": -5.28, "draft_iters": 6.6, "mem_use": 34.74, "gen_rate": 3.9, "speed": 3.81, "text": "\"\\nYou might get in trouble for "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.3, "tree_w": 16, "tree_size": 64, "t0": 1.2, "t1": 0.25, "tft": 1.7375, "input_0": 153, "input_1": 65, "min_CLP": -5.2, "draft_iters": 10.3, "mem_use": 34.69, "gen_rate": 6.7, "speed": 4.61, "text": "Melbourne, the capital of Victor"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 22, "tree_size": 64, "t0": 0.8717, "t1": 0.25, "tft": 1.5859, "input_0": 125, "input_1": 65, "min_CLP": -5.22, "draft_iters": 7.2, "mem_use": 34.82, "gen_rate": 5.3, "speed": 4.76, "text": "\\nWhat\u2019s your favorite movie? [\\"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.0, "tree_w": 23, "tree_size": 64, "t0": 0.9371, "t1": 0.2443, "tft": 1.325, "input_0": 114, "input_1": 65, "min_CLP": -5.3, "draft_iters": 8.0, "mem_use": 34.68, "gen_rate": 5.4, "speed": 4.59, "text": "\"I can't afford to be in Silicon"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.3, "tree_w": 17, "tree_size": 64, "t0": 1.53, "t1": 0.24, "tft": 1.6223, "input_0": 111, "input_1": 65, "min_CLP": -5.53, "draft_iters": 15.3, "mem_use": 34.55, "gen_rate": 10.7, "speed": 6.02, "text": "\\nWhat is the best approach for "}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.0, "tree_w": 21, "tree_size": 64, "t0": 0.988, "t1": 0.24, "tft": 1.6999, "input_0": 109, "input_1": 65, "min_CLP": -5.39, "draft_iters": 9.0, "mem_use": 34.55, "gen_rate": 6.6, "speed": 5.37, "text": "\\nIn order to walk around the wo"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 17, "tree_size": 64, "t0": 1.0833, "t1": 0.265, "tft": 3.2498, "input_0": 143, "input_1": 65, "min_CLP": -5.18, "draft_iters": 8.8, "mem_use": 35.4, "gen_rate": 6.0, "speed": 4.45, "text": "The Modularity Theorem is an imp"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 23, "tree_size": 64, "t0": 0.8914, "t1": 0.24, "tft": 1.8746, "input_0": 109, "input_1": 65, "min_CLP": -5.28, "draft_iters": 7.7, "mem_use": 34.61, "gen_rate": 4.9, "speed": 4.29, "text": "\\nIn what places is it best to g"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 3.41, "t1": 0.25, "tft": 2.5996, "input_0": 273, "input_1": 65, "min_CLP": -7.7, "draft_iters": 32.0, "mem_use": 34.71, "gen_rate": 33.0, "speed": 9.01, "text": "\\nHow can you write a first pers"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.0, "tree_w": 12, "tree_size": 64, "t0": 2.0967, "t1": 0.24, "tft": 1.4238, "input_0": 184, "input_1": 65, "min_CLP": -5.37, "draft_iters": 19.7, "mem_use": 34.54, "gen_rate": 12.0, "speed": 5.13, "text": "\\n&nbsp[INST] <<SYS>>\\n\\n&nbsp[I"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 7.7, "tree_w": 25, "tree_size": 64, "t0": 0.9633, "t1": 0.24, "tft": 1.3248, "input_0": 116, "input_1": 65, "min_CLP": -5.49, "draft_iters": 8.7, "mem_use": 34.69, "gen_rate": 4.7, "speed": 3.87, "text": "[SYS] Your question makes no sen"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 23, "tree_size": 64, "t0": 0.7675, "t1": 0.2412, "tft": 1.5262, "input_0": 99, "input_1": 65, "min_CLP": -5.3, "draft_iters": 6.5, "mem_use": 34.62, "gen_rate": 4.1, "speed": 4.07, "text": "Gas operated means that the bolt"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 21, "tree_size": 64, "t0": 0.8014, "t1": 0.25, "tft": 1.5673, "input_0": 104, "input_1": 65, "min_CLP": -5.29, "draft_iters": 6.9, "mem_use": 34.75, "gen_rate": 5.0, "speed": 4.77, "text": "\"\\nI'm not American, but I find "}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.2, "tree_w": 12, "tree_size": 64, "t0": 1.936, "t1": 0.306, "tft": 4.4528, "input_0": 184, "input_1": 65, "min_CLP": -4.89, "draft_iters": 16.2, "mem_use": 36.58, "gen_rate": 6.8, "speed": 3.03, "text": "\"Sure, here's a library that is "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.2, "tree_w": 21, "tree_size": 64, "t0": 0.9883, "t1": 0.25, "tft": 1.616, "input_0": 137, "input_1": 65, "min_CLP": -5.07, "draft_iters": 8.2, "mem_use": 35.18, "gen_rate": 6.5, "speed": 5.26, "text": "\"Yes. If you found a lost item, "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 15.0, "tree_w": 15, "tree_size": 64, "t0": 1.798, "t1": 0.292, "tft": 4.3579, "input_0": 149, "input_1": 65, "min_CLP": -4.85, "draft_iters": 16.0, "mem_use": 36.27, "gen_rate": 9.0, "speed": 4.3, "text": "Hello, it is nice to see you her"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.0, "tree_w": 26, "tree_size": 64, "t0": 0.795, "t1": 0.25, "tft": 1.608, "input_0": 89, "input_1": 65, "min_CLP": -5.42, "draft_iters": 7.0, "mem_use": 35.04, "gen_rate": 6.0, "speed": 5.74, "text": "\"\\nI've heard that the British E"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 17, "tree_size": 64, "t0": 1.03, "t1": 0.2467, "tft": 2.1437, "input_0": 139, "input_1": 65, "min_CLP": -5.2, "draft_iters": 8.7, "mem_use": 34.72, "gen_rate": 5.8, "speed": 4.57, "text": "A decorator is a small piece of "}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.4, "tree_w": 24, "tree_size": 64, "t0": 1.0871, "t1": 0.2657, "tft": 2.278, "input_0": 122, "input_1": 65, "min_CLP": -5.46, "draft_iters": 9.4, "mem_use": 35.41, "gen_rate": 4.6, "speed": 3.39, "text": "[INST]\\n\\nMy favorite band is Ra"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.2, "tree_w": 25, "tree_size": 64, "t0": 0.7478, "t1": 0.2456, "tft": 2.1082, "input_0": 107, "input_1": 65, "min_CLP": -5.43, "draft_iters": 6.2, "mem_use": 34.7, "gen_rate": 3.8, "speed": 3.8, "text": "\"I would recommend using your th"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.3, "tree_w": 20, "tree_size": 64, "t0": 0.9071, "t1": 0.2757, "tft": 2.8811, "input_0": 120, "input_1": 65, "min_CLP": -5.0, "draft_iters": 7.3, "mem_use": 35.74, "gen_rate": 4.9, "speed": 4.11, "text": "In order to maximize the Lifetim"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.8, "tree_w": 25, "tree_size": 64, "t0": 0.8225, "t1": 0.2538, "tft": 1.8907, "input_0": 116, "input_1": 65, "min_CLP": -5.54, "draft_iters": 6.8, "mem_use": 35.01, "gen_rate": 4.0, "speed": 3.71, "text": "\\nI am programmed to interact in"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.7, "tree_w": 20, "tree_size": 64, "t0": 1.3843, "t1": 0.25, "tft": 1.4955, "input_0": 109, "input_1": 65, "min_CLP": -5.33, "draft_iters": 13.6, "mem_use": 34.81, "gen_rate": 4.7, "speed": 2.89, "text": "[INST] Yes, I will.  I will prov"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 24, "tree_size": 64, "t0": 0.8175, "t1": 0.25, "tft": 1.4784, "input_0": 116, "input_1": 65, "min_CLP": -5.31, "draft_iters": 6.8, "mem_use": 34.87, "gen_rate": 4.1, "speed": 3.86, "text": "The top APIs, libraries, and dev"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 24.0, "tree_w": 5, "tree_size": 64, "t0": 2.755, "t1": 0.27, "tft": 4.1654, "input_0": 231, "input_1": 65, "min_CLP": -4.77, "draft_iters": 25.0, "mem_use": 35.53, "gen_rate": 16.0, "speed": 5.28, "text": "\"Tolkien's Quenya is a fictional"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 8, "tree_size": 64, "t0": 2.485, "t1": 0.24, "tft": 1.7627, "input_0": 202, "input_1": 65, "min_CLP": -5.54, "draft_iters": 23.5, "mem_use": 34.7, "gen_rate": 24.0, "speed": 8.8, "text": "\\n&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 23, "tree_size": 64, "t0": 0.8843, "t1": 0.24, "tft": 1.4253, "input_0": 124, "input_1": 65, "min_CLP": -5.36, "draft_iters": 7.6, "mem_use": 34.54, "gen_rate": 4.6, "speed": 4.06, "text": "\\nThe error is that the return v"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 4.0, "tree_w": 24, "tree_size": 64, "t0": 0.63, "t1": 0.26, "tft": 2.1866, "input_0": 87, "input_1": 65, "min_CLP": -5.28, "draft_iters": 5.0, "mem_use": 35.25, "gen_rate": 1.0, "speed": 1.13, "text": "- Luna"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 17, "tree_size": 64, "t0": 1.195, "t1": 0.25, "tft": 1.7492, "input_0": 154, "input_1": 65, "min_CLP": -5.04, "draft_iters": 10.3, "mem_use": 34.88, "gen_rate": 5.5, "speed": 3.81, "text": "Here is an example of the use of"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.1, "tree_w": 23, "tree_size": 64, "t0": 0.7422, "t1": 0.25, "tft": 1.6931, "input_0": 106, "input_1": 65, "min_CLP": -5.2, "draft_iters": 6.1, "mem_use": 34.94, "gen_rate": 3.7, "speed": 3.69, "text": "You can use a command line flag "}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 21, "tree_size": 64, "t0": 0.94, "t1": 0.28, "tft": 3.3228, "input_0": 124, "input_1": 65, "min_CLP": -5.04, "draft_iters": 7.5, "mem_use": 35.82, "gen_rate": 4.2, "speed": 3.49, "text": "\"\\nThe first thing you should do"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 25.5, "tree_w": 7, "tree_size": 64, "t0": 2.6275, "t1": 0.25, "tft": 2.1324, "input_0": 188, "input_1": 65, "min_CLP": -4.83, "draft_iters": 26.0, "mem_use": 34.81, "gen_rate": 9.2, "speed": 3.22, "text": "\\nWrite a blogpost for medium.co"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 10, "tree_size": 64, "t0": 2.3025, "t1": 0.27, "tft": 3.2649, "input_0": 157, "input_1": 65, "min_CLP": -4.84, "draft_iters": 22.0, "mem_use": 35.44, "gen_rate": 8.2, "speed": 3.21, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.5, "tree_w": 10, "tree_size": 64, "t0": 2.29, "t1": 0.24, "tft": 1.5472, "input_0": 178, "input_1": 65, "min_CLP": -5.14, "draft_iters": 22.5, "mem_use": 34.65, "gen_rate": 18.5, "speed": 7.3, "text": "Can you think and feel like a hu"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.3, "tree_w": 22, "tree_size": 64, "t0": 1.12, "t1": 0.2486, "tft": 2.8155, "input_0": 112, "input_1": 65, "min_CLP": -5.68, "draft_iters": 10.3, "mem_use": 34.64, "gen_rate": 5.4, "speed": 3.97, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.8329, "t1": 0.25, "tft": 1.6771, "input_0": 107, "input_1": 65, "min_CLP": -5.38, "draft_iters": 7.1, "mem_use": 34.77, "gen_rate": 4.7, "speed": 4.37, "text": "You are smart! You are very obse"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 46, "tree_h": 8.6, "tree_w": 27, "tree_size": 64, "t0": 1.0436, "t1": 0.27, "tft": 4.1692, "input_0": 90, "input_1": 65, "min_CLP": -5.93, "draft_iters": 9.6, "mem_use": 35.64, "gen_rate": 4.2, "speed": 3.18, "text": "O hw\u00e6t! \u00feu beorht \u00feu feor\u00f0, \u00feu b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.6, "tree_w": 21, "tree_size": 64, "t0": 1.0063, "t1": 0.25, "tft": 1.9413, "input_0": 120, "input_1": 65, "min_CLP": -5.22, "draft_iters": 8.6, "mem_use": 34.86, "gen_rate": 4.1, "speed": 3.28, "text": "\\nwhat are the major benefits of"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.5, "tree_w": 19, "tree_size": 64, "t0": 1.3375, "t1": 0.24, "tft": 1.8225, "input_0": 122, "input_1": 65, "min_CLP": -5.56, "draft_iters": 12.5, "mem_use": 34.54, "gen_rate": 10.0, "speed": 6.32, "text": "\"\\nThe following words are usefu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.0, "tree_w": 20, "tree_size": 64, "t0": 1.5525, "t1": 0.24, "tft": 3.1837, "input_0": 132, "input_1": 65, "min_CLP": -5.79, "draft_iters": 15.0, "mem_use": 34.54, "gen_rate": 9.0, "speed": 5.02, "text": "\\nHi open assistant, can you tel"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 20, "tree_size": 64, "t0": 1.0017, "t1": 0.2483, "tft": 1.5439, "input_0": 121, "input_1": 65, "min_CLP": -5.4, "draft_iters": 8.5, "mem_use": 34.69, "gen_rate": 5.7, "speed": 4.55, "text": "\\nWhat is the shortest distance "}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.4, "tree_w": 17, "tree_size": 64, "t0": 1.2757, "t1": 0.26, "tft": 2.6098, "input_0": 168, "input_1": 65, "min_CLP": -5.2, "draft_iters": 10.4, "mem_use": 35.1, "gen_rate": 4.6, "speed": 2.98, "text": "\"The existence and capabilities "}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 15.3, "tree_w": 10, "tree_size": 64, "t0": 1.8233, "t1": 0.25, "tft": 2.5641, "input_0": 191, "input_1": 65, "min_CLP": -4.99, "draft_iters": 16.3, "mem_use": 34.73, "gen_rate": 8.0, "speed": 3.87, "text": "Why is it frustrating to be a hu"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.9, "tree_w": 25, "tree_size": 64, "t0": 0.9056, "t1": 0.2489, "tft": 1.5441, "input_0": 111, "input_1": 65, "min_CLP": -5.5, "draft_iters": 7.9, "mem_use": 34.77, "gen_rate": 4.1, "speed": 3.57, "text": "<</SYS>\\n\\nWhy is this an issue?"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 11.0, "tree_w": 20, "tree_size": 64, "t0": 1.295, "t1": 0.24, "tft": 1.4104, "input_0": 122, "input_1": 65, "min_CLP": -5.27, "draft_iters": 12.0, "mem_use": 34.54, "gen_rate": 8.2, "speed": 5.3, "text": "\\nWhat is the second amendment? "}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 25, "tree_size": 64, "t0": 0.95, "t1": 0.25, "tft": 2.0397, "input_0": 95, "input_1": 65, "min_CLP": -5.27, "draft_iters": 8.8, "mem_use": 34.88, "gen_rate": 5.8, "speed": 4.86, "text": "\"yeah no, you can\\'t just judge "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.5, "tree_w": 30, "tree_size": 64, "t0": 0.661, "t1": 0.242, "tft": 1.4424, "input_0": 100, "input_1": 65, "min_CLP": -5.45, "draft_iters": 5.5, "mem_use": 34.59, "gen_rate": 3.6, "speed": 3.98, "text": "\\nI believe it is because it was"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.3, "tree_w": 27, "tree_size": 64, "t0": 0.638, "t1": 0.26, "tft": 1.8705, "input_0": 90, "input_1": 65, "min_CLP": -5.59, "draft_iters": 5.3, "mem_use": 35.2, "gen_rate": 3.3, "speed": 3.68, "text": "\\nIn case of fictional scenarios"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.2, "tree_w": 23, "tree_size": 64, "t0": 1.02, "t1": 0.25, "tft": 1.3292, "input_0": 118, "input_1": 65, "min_CLP": -5.27, "draft_iters": 9.2, "mem_use": 34.77, "gen_rate": 5.8, "speed": 4.61, "text": "\"No. I'm not interested in takin"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 22, "tree_size": 64, "t0": 0.8543, "t1": 0.2643, "tft": 2.5978, "input_0": 109, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.0, "mem_use": 35.4, "gen_rate": 4.6, "speed": 4.08, "text": "You can enjoy any of the hiking "}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 9, "tree_size": 64, "t0": 3.05, "t1": 0.25, "tft": 1.8594, "input_0": 196, "input_1": 65, "min_CLP": -5.04, "draft_iters": 30.5, "mem_use": 34.74, "gen_rate": 31.0, "speed": 9.4, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.11, "t1": 0.24, "tft": 1.6054, "input_0": 185, "input_1": 65, "min_CLP": -5.0, "draft_iters": 32.0, "mem_use": 34.69, "gen_rate": 33.0, "speed": 9.85, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 21, "tree_size": 64, "t0": 1.274, "t1": 0.28, "tft": 3.5105, "input_0": 140, "input_1": 65, "min_CLP": -5.05, "draft_iters": 11.0, "mem_use": 35.95, "gen_rate": 6.4, "speed": 4.11, "text": "[INST] I am not sure what you me"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 23, "tree_size": 64, "t0": 0.7729, "t1": 0.24, "tft": 1.415, "input_0": 105, "input_1": 65, "min_CLP": -5.29, "draft_iters": 6.4, "mem_use": 34.89, "gen_rate": 4.9, "speed": 4.77, "text": "\\nShort answer: No.\\nThe reason "}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.6, "tree_w": 23, "tree_size": 64, "t0": 0.7778, "t1": 0.25, "tft": 1.4627, "input_0": 102, "input_1": 65, "min_CLP": -5.22, "draft_iters": 6.6, "mem_use": 34.8, "gen_rate": 3.6, "speed": 3.47, "text": "In this specific example, I chos"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.5, "tree_w": 14, "tree_size": 64, "t0": 1.35, "t1": 0.2417, "tft": 2.159, "input_0": 135, "input_1": 65, "min_CLP": -4.79, "draft_iters": 12.5, "mem_use": 34.62, "gen_rate": 6.2, "speed": 3.87, "text": "\"the pan is already hot\\n[INST] "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.3, "tree_w": 22, "tree_size": 64, "t0": 0.9317, "t1": 0.24, "tft": 1.4248, "input_0": 107, "input_1": 65, "min_CLP": -5.22, "draft_iters": 8.3, "mem_use": 34.54, "gen_rate": 6.0, "speed": 5.11, "text": "\"\\nHi,\\n\\nI'm a newbie in deep l"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 23, "tree_size": 64, "t0": 0.8487, "t1": 0.27, "tft": 2.571, "input_0": 115, "input_1": 65, "min_CLP": -5.19, "draft_iters": 6.9, "mem_use": 35.59, "gen_rate": 4.2, "speed": 3.8, "text": "\"\\nYou're welcome! Don't worry a"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 24, "tree_size": 64, "t0": 1.13, "t1": 0.24, "tft": 1.5207, "input_0": 129, "input_1": 65, "min_CLP": -5.6, "draft_iters": 10.4, "mem_use": 34.7, "gen_rate": 7.0, "speed": 5.1, "text": "\\nYes. Thumb wars are violent.\\n"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 1.014, "t1": 0.24, "tft": 1.8388, "input_0": 115, "input_1": 65, "min_CLP": -5.58, "draft_iters": 8.8, "mem_use": 34.55, "gen_rate": 6.4, "speed": 5.09, "text": "\\nWhat is the German word for \"b"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 1.0067, "t1": 0.29, "tft": 3.8902, "input_0": 132, "input_1": 65, "min_CLP": -4.99, "draft_iters": 8.0, "mem_use": 36.14, "gen_rate": 5.3, "speed": 4.12, "text": "While I cannot provide specific "}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 24, "tree_size": 64, "t0": 0.745, "t1": 0.26, "tft": 2.1992, "input_0": 99, "input_1": 65, "min_CLP": -5.15, "draft_iters": 6.1, "mem_use": 35.18, "gen_rate": 4.0, "speed": 3.98, "text": "\\nI am sorry if I have caused yo"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 22, "tree_size": 64, "t0": 0.9086, "t1": 0.2443, "tft": 1.5085, "input_0": 117, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.9, "mem_use": 34.68, "gen_rate": 5.1, "speed": 4.46, "text": "\"I can assist by using Duolingo,"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 64, "t0": 3.17, "t1": 0.25, "tft": 1.6356, "input_0": 216, "input_1": 65, "min_CLP": -5.49, "draft_iters": 32.0, "mem_use": 34.65, "gen_rate": 33.0, "speed": 9.66, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.0, "tree_w": 20, "tree_size": 64, "t0": 1.548, "t1": 0.24, "tft": 1.568, "input_0": 133, "input_1": 65, "min_CLP": -5.49, "draft_iters": 15.0, "mem_use": 34.54, "gen_rate": 6.4, "speed": 3.57, "text": "\\nexplain what a self-reinforcin"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 26, "tree_h": 6.8, "tree_w": 23, "tree_size": 64, "t0": 0.9317, "t1": 0.25, "tft": 1.6609, "input_0": 129, "input_1": 65, "min_CLP": -5.07, "draft_iters": 7.8, "mem_use": 34.96, "gen_rate": 4.3, "speed": 3.66, "text": "\"I see, I will do my best to get"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 31.5, "tree_w": 3, "tree_size": 64, "t0": 3.545, "t1": 0.26, "tft": 4.3965, "input_0": 291, "input_1": 65, "min_CLP": -4.96, "draft_iters": 32.0, "mem_use": 35.09, "gen_rate": 31.0, "speed": 8.14, "text": "1. \u00abRespect\u00bb, Aretha Franklin.\\n"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 16, "tree_size": 64, "t0": 1.346, "t1": 0.31, "tft": 5.8959, "input_0": 145, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.2, "mem_use": 36.84, "gen_rate": 6.6, "speed": 3.98, "text": "Step 2 \u2014 Coding Your TypeScript "}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.9, "tree_w": 22, "tree_size": 64, "t0": 1.1113, "t1": 0.24, "tft": 1.5994, "input_0": 104, "input_1": 65, "min_CLP": -5.32, "draft_iters": 10.8, "mem_use": 35.31, "gen_rate": 4.2, "speed": 3.14, "text": "\\n[INST] <<SYS>>\\nWhen someone i"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 7.1, "tree_w": 22, "tree_size": 64, "t0": 0.9338, "t1": 0.25, "tft": 1.5038, "input_0": 112, "input_1": 65, "min_CLP": -5.49, "draft_iters": 8.1, "mem_use": 34.83, "gen_rate": 5.1, "speed": 4.33, "text": "\\nBerlin is known for its high l"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 53, "tree_h": 11.1, "tree_w": 19, "tree_size": 64, "t0": 1.2757, "t1": 0.2414, "tft": 2.8612, "input_0": 110, "input_1": 65, "min_CLP": -5.33, "draft_iters": 12.1, "mem_use": 34.55, "gen_rate": 7.6, "speed": 4.99, "text": "\\nwrite me script that if a word"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.5, "tree_w": 21, "tree_size": 64, "t0": 1.1733, "t1": 0.2783, "tft": 3.0503, "input_0": 155, "input_1": 65, "min_CLP": -5.4, "draft_iters": 9.5, "mem_use": 35.78, "gen_rate": 6.3, "speed": 4.36, "text": "\\nI have:\\n\\nPotatoes\\nEggs\\nMil"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 64, "t0": 2.96, "t1": 0.24, "tft": 1.5541, "input_0": 130, "input_1": 65, "min_CLP": -4.68, "draft_iters": 32.0, "mem_use": 34.79, "gen_rate": 33.0, "speed": 10.3, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 27.5, "tree_w": 5, "tree_size": 64, "t0": 3.205, "t1": 0.28, "tft": 5.1382, "input_0": 251, "input_1": 65, "min_CLP": -4.98, "draft_iters": 28.0, "mem_use": 35.71, "gen_rate": 26.0, "speed": 7.47, "text": "\"Here are the steps that could b"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.7, "tree_w": 23, "tree_size": 64, "t0": 0.6822, "t1": 0.24, "tft": 2.1096, "input_0": 97, "input_1": 65, "min_CLP": -5.48, "draft_iters": 5.7, "mem_use": 34.82, "gen_rate": 3.7, "speed": 3.96, "text": "\\nA great question!\\n\\nFirst of "}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 3.25, "t1": 0.24, "tft": 3.7235, "input_0": 221, "input_1": 65, "min_CLP": -4.83, "draft_iters": 32.0, "mem_use": 34.54, "gen_rate": 33.0, "speed": 9.46, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.8, "tree_w": 27, "tree_size": 64, "t0": 0.689, "t1": 0.24, "tft": 1.6068, "input_0": 95, "input_1": 65, "min_CLP": -5.54, "draft_iters": 5.8, "mem_use": 34.59, "gen_rate": 3.5, "speed": 3.76, "text": "\\nWe have a team of about 10 peo"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 22, "tree_size": 64, "t0": 0.8344, "t1": 0.26, "tft": 2.1687, "input_0": 120, "input_1": 65, "min_CLP": -5.19, "draft_iters": 6.8, "mem_use": 35.11, "gen_rate": 3.7, "speed": 3.35, "text": "Yes, life was very good in the 1"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.0, "tree_w": 27, "tree_size": 64, "t0": 0.7433, "t1": 0.24, "tft": 1.5155, "input_0": 114, "input_1": 65, "min_CLP": -5.37, "draft_iters": 6.0, "mem_use": 34.56, "gen_rate": 3.9, "speed": 3.94, "text": "\"\\nI've heard that film photogra"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 64, "t0": 2.88, "t1": 0.25, "tft": 1.8263, "input_0": 104, "input_1": 65, "min_CLP": -5.42, "draft_iters": 32.0, "mem_use": 34.68, "gen_rate": 33.0, "speed": 10.55, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 26, "tree_size": 64, "t0": 0.81, "t1": 0.25, "tft": 1.6304, "input_0": 116, "input_1": 65, "min_CLP": -5.27, "draft_iters": 6.8, "mem_use": 34.82, "gen_rate": 4.1, "speed": 3.89, "text": "Selective fire is the ability to"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 0.9738, "t1": 0.24, "tft": 1.6866, "input_0": 126, "input_1": 65, "min_CLP": -5.31, "draft_iters": 8.4, "mem_use": 34.61, "gen_rate": 4.4, "speed": 3.59, "text": "I am the goddess of beauty, love"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 14.0, "tree_w": 15, "tree_size": 64, "t0": 1.652, "t1": 0.26, "tft": 2.3126, "input_0": 158, "input_1": 65, "min_CLP": -4.9, "draft_iters": 14.8, "mem_use": 35.35, "gen_rate": 12.0, "speed": 6.27, "text": "You can use the command line too"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 22.5, "tree_w": 12, "tree_size": 64, "t0": 2.42, "t1": 0.24, "tft": 2.021, "input_0": 194, "input_1": 65, "min_CLP": -5.41, "draft_iters": 23.5, "mem_use": 34.64, "gen_rate": 17.5, "speed": 6.57, "text": "\\nWrite a response that agrees w"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.6, "tree_w": 20, "tree_size": 64, "t0": 0.9157, "t1": 0.2514, "tft": 2.1281, "input_0": 124, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.6, "mem_use": 34.96, "gen_rate": 5.0, "speed": 4.27, "text": "Microwaves were first developed "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 24, "tree_size": 64, "t0": 0.78, "t1": 0.24, "tft": 1.8553, "input_0": 91, "input_1": 65, "min_CLP": -5.41, "draft_iters": 6.9, "mem_use": 34.6, "gen_rate": 4.7, "speed": 4.61, "text": "\\nPros:\\n\\n- I can hear my teach"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.5, "tree_w": 24, "tree_size": 64, "t0": 0.7725, "t1": 0.24, "tft": 1.7513, "input_0": 104, "input_1": 65, "min_CLP": -5.38, "draft_iters": 6.5, "mem_use": 34.53, "gen_rate": 4.0, "speed": 3.94, "text": "\\nThe cat was in a box with a ra"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 14, "tree_size": 64, "t0": 1.392, "t1": 0.31, "tft": 6.1204, "input_0": 141, "input_1": 65, "min_CLP": -4.9, "draft_iters": 11.2, "mem_use": 36.71, "gen_rate": 6.4, "speed": 3.76, "text": "\"If you rejected the offer to dr"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.4, "tree_w": 26, "tree_size": 64, "t0": 0.6478, "t1": 0.2433, "tft": 1.5311, "input_0": 92, "input_1": 65, "min_CLP": -5.58, "draft_iters": 5.4, "mem_use": 35.23, "gen_rate": 3.7, "speed": 4.11, "text": "\\nIs it possible to use the proc"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 16, "tree_size": 64, "t0": 1.325, "t1": 0.26, "tft": 2.2179, "input_0": 147, "input_1": 65, "min_CLP": -5.42, "draft_iters": 11.8, "mem_use": 35.09, "gen_rate": 8.0, "speed": 5.05, "text": "\"Assuming that the walker can cr"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.5, "tree_w": 22, "tree_size": 64, "t0": 0.825, "t1": 0.2738, "tft": 2.6231, "input_0": 116, "input_1": 65, "min_CLP": -5.31, "draft_iters": 6.5, "mem_use": 35.73, "gen_rate": 4.2, "speed": 3.87, "text": "You could simply place a block o"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 23, "tree_size": 64, "t0": 0.845, "t1": 0.2462, "tft": 1.3245, "input_0": 105, "input_1": 65, "min_CLP": -5.32, "draft_iters": 7.4, "mem_use": 34.77, "gen_rate": 4.1, "speed": 3.79, "text": "\"I don't get it. Are you saying "}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.6, "tree_w": 16, "tree_size": 64, "t0": 1.574, "t1": 0.244, "tft": 1.4832, "input_0": 147, "input_1": 65, "min_CLP": -5.3, "draft_iters": 14.6, "mem_use": 34.68, "gen_rate": 6.4, "speed": 3.52, "text": "\\nHi open assistant, can you tel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.6, "tree_w": 19, "tree_size": 64, "t0": 0.916, "t1": 0.25, "tft": 2.311, "input_0": 115, "input_1": 65, "min_CLP": -5.11, "draft_iters": 7.6, "mem_use": 34.91, "gen_rate": 6.4, "speed": 5.48, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 24, "tree_size": 64, "t0": 0.8257, "t1": 0.2443, "tft": 1.4388, "input_0": 112, "input_1": 65, "min_CLP": -5.32, "draft_iters": 7.0, "mem_use": 34.68, "gen_rate": 4.7, "speed": 4.41, "text": "\"What is the author's opinion ab"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.9, "tree_w": 23, "tree_size": 64, "t0": 0.9222, "t1": 0.2556, "tft": 2.3739, "input_0": 115, "input_1": 65, "min_CLP": -5.18, "draft_iters": 7.9, "mem_use": 35.03, "gen_rate": 3.7, "speed": 3.11, "text": "Transactional interpretations ar"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.5, "tree_w": 25, "tree_size": 64, "t0": 0.6645, "t1": 0.2464, "tft": 2.0114, "input_0": 95, "input_1": 65, "min_CLP": -5.54, "draft_iters": 5.5, "mem_use": 34.69, "gen_rate": 3.3, "speed": 3.6, "text": "\\nI have a Raspberry Pi 3. I wan"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.9, "tree_w": 20, "tree_size": 64, "t0": 1.1457, "t1": 0.24, "tft": 1.6081, "input_0": 146, "input_1": 65, "min_CLP": -5.41, "draft_iters": 9.9, "mem_use": 34.54, "gen_rate": 4.9, "speed": 3.5, "text": "\\nIn what ways does reinforcemen"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 26, "tree_size": 64, "t0": 0.7287, "t1": 0.24, "tft": 1.6397, "input_0": 93, "input_1": 65, "min_CLP": -5.51, "draft_iters": 6.4, "mem_use": 34.53, "gen_rate": 4.2, "speed": 4.37, "text": "\"\\nThe two reasons are:\\n\\n1. Th"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.3, "tree_w": 18, "tree_size": 64, "t0": 1.69, "t1": 0.3167, "tft": 4.7578, "input_0": 134, "input_1": 65, "min_CLP": -5.42, "draft_iters": 14.3, "mem_use": 36.89, "gen_rate": 5.5, "speed": 2.74, "text": "\\nThe Timsort algorithm is an im"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 9.3, "tree_w": 19, "tree_size": 64, "t0": 1.1729, "t1": 0.24, "tft": 1.8147, "input_0": 138, "input_1": 65, "min_CLP": -5.06, "draft_iters": 10.3, "mem_use": 35.33, "gen_rate": 6.0, "speed": 4.24, "text": "It is used to create interactive"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 22.0, "tree_w": 15, "tree_size": 64, "t0": 2.27, "t1": 0.26, "tft": 2.4532, "input_0": 141, "input_1": 65, "min_CLP": -4.71, "draft_iters": 22.5, "mem_use": 35.4, "gen_rate": 18.5, "speed": 7.3, "text": "\\nF-centers are created by expos"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.3, "tree_w": 14, "tree_size": 64, "t0": 1.42, "t1": 0.26, "tft": 2.2304, "input_0": 165, "input_1": 65, "min_CLP": -4.76, "draft_iters": 12.3, "mem_use": 35.28, "gen_rate": 5.7, "speed": 3.37, "text": "\\n3. Use the Windows Memory Diag"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 26, "tree_size": 64, "t0": 0.9129, "t1": 0.2414, "tft": 2.3255, "input_0": 103, "input_1": 65, "min_CLP": -5.55, "draft_iters": 8.3, "mem_use": 34.66, "gen_rate": 4.6, "speed": 3.96, "text": "\\n(Note: Answers will be graded "}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 64, "t0": 2.98, "t1": 0.24, "tft": 1.7682, "input_0": 140, "input_1": 65, "min_CLP": -5.37, "draft_iters": 32.0, "mem_use": 34.57, "gen_rate": 33.0, "speed": 10.23, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 15, "tree_size": 64, "t0": 1.8133, "t1": 0.24, "tft": 1.7598, "input_0": 132, "input_1": 65, "min_CLP": -5.46, "draft_iters": 17.7, "mem_use": 34.56, "gen_rate": 11.7, "speed": 5.67, "text": "\\nWhat are some of the well know"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 31.0, "tree_w": 6, "tree_size": 64, "t0": 3.125, "t1": 0.255, "tft": 2.6661, "input_0": 189, "input_1": 65, "min_CLP": -4.59, "draft_iters": 31.5, "mem_use": 35.08, "gen_rate": 19.0, "speed": 5.62, "text": "\\nUser : pls tell me about consc"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 64, "t0": 3.11, "t1": 0.25, "tft": 1.9119, "input_0": 203, "input_1": 65, "min_CLP": -5.63, "draft_iters": 32.0, "mem_use": 34.72, "gen_rate": 33.0, "speed": 9.82, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.2, "tree_w": 13, "tree_size": 64, "t0": 1.774, "t1": 0.27, "tft": 4.0388, "input_0": 166, "input_1": 65, "min_CLP": -5.47, "draft_iters": 16.2, "mem_use": 35.42, "gen_rate": 6.6, "speed": 3.23, "text": "Here is list of words related to"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.2, "tree_w": 22, "tree_size": 64, "t0": 0.7463, "t1": 0.25, "tft": 1.3712, "input_0": 94, "input_1": 65, "min_CLP": -5.15, "draft_iters": 6.2, "mem_use": 34.82, "gen_rate": 4.2, "speed": 4.27, "text": "\"I think that, if you're going t"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 19, "tree_size": 64, "t0": 1.29, "t1": 0.248, "tft": 1.9306, "input_0": 130, "input_1": 65, "min_CLP": -5.22, "draft_iters": 12.0, "mem_use": 34.74, "gen_rate": 6.4, "speed": 4.16, "text": "What is the ATF gunwalking scand"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 2.91, "t1": 0.24, "tft": 1.7749, "input_0": 116, "input_1": 65, "min_CLP": -5.27, "draft_iters": 32.0, "mem_use": 34.63, "gen_rate": 33.0, "speed": 10.46, "text": "\\nWhat is the difference betwean"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.0, "tree_w": 18, "tree_size": 64, "t0": 1.3717, "t1": 0.285, "tft": 3.7758, "input_0": 133, "input_1": 65, "min_CLP": -5.36, "draft_iters": 12.0, "mem_use": 36.02, "gen_rate": 5.7, "speed": 3.42, "text": "\\nWrite me a graphic novel set i"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 7, "tree_size": 64, "t0": 3.38, "t1": 0.29, "tft": 4.203, "input_0": 230, "input_1": 65, "min_CLP": -4.79, "draft_iters": 32.0, "mem_use": 36.05, "gen_rate": 32.0, "speed": 8.73, "text": "\\nOnce upon a time, in the city "}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 3.02, "t1": 0.24, "tft": 1.8147, "input_0": 149, "input_1": 65, "min_CLP": -5.45, "draft_iters": 32.0, "mem_use": 34.91, "gen_rate": 33.0, "speed": 10.13, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 3.34, "t1": 0.26, "tft": 3.4215, "input_0": 225, "input_1": 65, "min_CLP": -5.58, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 9.16, "text": "\\n\"Exciting news, Medium readers"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 18.3, "tree_w": 9, "tree_size": 64, "t0": 2.12, "t1": 0.26, "tft": 2.4076, "input_0": 192, "input_1": 65, "min_CLP": -4.83, "draft_iters": 19.3, "mem_use": 35.35, "gen_rate": 16.0, "speed": 6.71, "text": "\"\\nThe maximum speed of the car "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.9, "tree_w": 20, "tree_size": 64, "t0": 1.1329, "t1": 0.24, "tft": 2.9861, "input_0": 110, "input_1": 65, "min_CLP": -5.4, "draft_iters": 10.7, "mem_use": 34.61, "gen_rate": 5.0, "speed": 3.64, "text": "\\nAnswer:\\n\\n[INST] <<SYS>>\\n\\nT"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.4, "tree_w": 18, "tree_size": 64, "t0": 1.2643, "t1": 0.2443, "tft": 1.3981, "input_0": 129, "input_1": 65, "min_CLP": -5.27, "draft_iters": 11.4, "mem_use": 34.67, "gen_rate": 4.7, "speed": 3.12, "text": "[INST] You dare command me? [\\\\I"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 22, "tree_size": 64, "t0": 0.8857, "t1": 0.2686, "tft": 3.3452, "input_0": 97, "input_1": 65, "min_CLP": -5.19, "draft_iters": 7.7, "mem_use": 35.45, "gen_rate": 4.6, "speed": 3.98, "text": "\"Hershey's chocolate is not inte"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 25, "tree_size": 64, "t0": 0.7271, "t1": 0.2414, "tft": 1.6204, "input_0": 89, "input_1": 65, "min_CLP": -5.29, "draft_iters": 6.3, "mem_use": 34.65, "gen_rate": 4.9, "speed": 4.99, "text": "\"\\nWhy would you want to host a "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 23, "tree_size": 64, "t0": 0.905, "t1": 0.2675, "tft": 2.313, "input_0": 119, "input_1": 65, "min_CLP": -5.05, "draft_iters": 7.4, "mem_use": 35.41, "gen_rate": 4.1, "speed": 3.52, "text": "\"\\nI don't understand what you'r"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 23, "tree_size": 64, "t0": 0.7412, "t1": 0.24, "tft": 1.443, "input_0": 113, "input_1": 65, "min_CLP": -5.35, "draft_iters": 6.1, "mem_use": 34.61, "gen_rate": 4.1, "speed": 4.19, "text": "\\nThe future of AI will be one o"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 64, "t0": 3.02, "t1": 0.24, "tft": 1.5505, "input_0": 150, "input_1": 65, "min_CLP": -5.45, "draft_iters": 32.0, "mem_use": 34.54, "gen_rate": 33.0, "speed": 10.12, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.2, "tree_w": 20, "tree_size": 64, "t0": 0.9625, "t1": 0.25, "tft": 1.6552, "input_0": 120, "input_1": 65, "min_CLP": -5.24, "draft_iters": 8.2, "mem_use": 34.88, "gen_rate": 4.5, "speed": 3.71, "text": "\"Here's my code, it's not perfec"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.4, "tree_w": 23, "tree_size": 64, "t0": 0.8622, "t1": 0.2556, "tft": 1.79, "input_0": 99, "input_1": 65, "min_CLP": -5.38, "draft_iters": 7.4, "mem_use": 35.05, "gen_rate": 4.0, "speed": 3.58, "text": "\"\\nWhat is the best way to learn"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 22, "tree_size": 64, "t0": 0.81, "t1": 0.24, "tft": 1.4316, "input_0": 109, "input_1": 65, "min_CLP": -5.19, "draft_iters": 6.9, "mem_use": 34.53, "gen_rate": 4.0, "speed": 3.8, "text": "\\nThe AK47 is a Russian made ass"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.6, "tree_w": 26, "tree_size": 64, "t0": 0.6733, "t1": 0.2456, "tft": 2.0856, "input_0": 98, "input_1": 65, "min_CLP": -5.52, "draft_iters": 5.6, "mem_use": 34.71, "gen_rate": 3.8, "speed": 4.1, "text": "\"\\nI have a CentOS 7 server that"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 17.3, "tree_w": 12, "tree_size": 64, "t0": 2.0, "t1": 0.265, "tft": 2.7518, "input_0": 164, "input_1": 65, "min_CLP": -4.84, "draft_iters": 18.3, "mem_use": 35.43, "gen_rate": 5.5, "speed": 2.43, "text": "Statistical modeling:  [SYS]\\nSt"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.8, "tree_w": 28, "tree_size": 64, "t0": 0.6956, "t1": 0.2456, "tft": 1.9562, "input_0": 98, "input_1": 65, "min_CLP": -5.35, "draft_iters": 5.8, "mem_use": 34.69, "gen_rate": 4.0, "speed": 4.25, "text": "\"\\nI am looking for a game that "}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.2, "tree_w": 23, "tree_size": 64, "t0": 0.8556, "t1": 0.25, "tft": 2.1357, "input_0": 115, "input_1": 65, "min_CLP": -5.14, "draft_iters": 7.2, "mem_use": 34.94, "gen_rate": 3.8, "speed": 3.41, "text": "Cooking is a science, and there "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.7, "tree_w": 25, "tree_size": 64, "t0": 0.7811, "t1": 0.25, "tft": 1.5109, "input_0": 102, "input_1": 65, "min_CLP": -5.33, "draft_iters": 6.7, "mem_use": 34.77, "gen_rate": 3.9, "speed": 3.78, "text": "\"\\nI'm trying to think of a way "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.2, "tree_w": 27, "tree_size": 64, "t0": 0.7009, "t1": 0.25, "tft": 1.9769, "input_0": 82, "input_1": 65, "min_CLP": -5.56, "draft_iters": 6.2, "mem_use": 34.83, "gen_rate": 3.1, "speed": 3.25, "text": "User : If they are different the"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.4, "tree_w": 17, "tree_size": 64, "t0": 1.18, "t1": 0.24, "tft": 1.6294, "input_0": 128, "input_1": 65, "min_CLP": -5.1, "draft_iters": 10.4, "mem_use": 34.53, "gen_rate": 8.2, "speed": 5.75, "text": "\\nDo you have any special talent"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.5, "tree_w": 21, "tree_size": 64, "t0": 1.885, "t1": 0.24, "tft": 1.9075, "input_0": 207, "input_1": 65, "min_CLP": -5.51, "draft_iters": 16.5, "mem_use": 34.53, "gen_rate": 16.0, "speed": 7.51, "text": "\\nThis is a discussion on How ca"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 23.5, "tree_w": 13, "tree_size": 64, "t0": 2.38, "t1": 0.25, "tft": 1.7496, "input_0": 151, "input_1": 65, "min_CLP": -4.84, "draft_iters": 24.5, "mem_use": 34.82, "gen_rate": 17.5, "speed": 6.66, "text": "It is an amino acid that is foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 64, "t0": 2.92, "t1": 0.25, "tft": 3.3699, "input_0": 122, "input_1": 65, "min_CLP": -5.41, "draft_iters": 32.0, "mem_use": 34.67, "gen_rate": 33.0, "speed": 10.42, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 38, "tree_h": 5.6, "tree_w": 25, "tree_size": 64, "t0": 0.7491, "t1": 0.24, "tft": 2.1031, "input_0": 88, "input_1": 65, "min_CLP": -5.48, "draft_iters": 6.6, "mem_use": 34.57, "gen_rate": 3.5, "speed": 3.48, "text": "\"\\nbe nice to the new guy, but n"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 24, "tree_size": 64, "t0": 0.9543, "t1": 0.24, "tft": 1.5379, "input_0": 109, "input_1": 65, "min_CLP": -5.54, "draft_iters": 8.4, "mem_use": 34.55, "gen_rate": 5.0, "speed": 4.18, "text": "\\nWhy is it called \"cops and rob"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.6, "tree_w": 25, "tree_size": 64, "t0": 0.7787, "t1": 0.25, "tft": 1.6296, "input_0": 106, "input_1": 65, "min_CLP": -5.54, "draft_iters": 6.6, "mem_use": 34.8, "gen_rate": 4.8, "speed": 4.63, "text": "The background image is made up "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 23, "tree_size": 64, "t0": 0.8314, "t1": 0.3, "tft": 4.0361, "input_0": 111, "input_1": 65, "min_CLP": -5.22, "draft_iters": 6.4, "mem_use": 36.38, "gen_rate": 4.7, "speed": 4.17, "text": "I would recommend against this, "}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 25, "tree_size": 64, "t0": 0.9083, "t1": 0.2733, "tft": 2.7069, "input_0": 138, "input_1": 65, "min_CLP": -5.23, "draft_iters": 7.2, "mem_use": 35.72, "gen_rate": 5.3, "speed": 4.51, "text": "\"\\nThis is a very interesting th"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 64, "t0": 2.93, "t1": 0.25, "tft": 1.6906, "input_0": 108, "input_1": 65, "min_CLP": -5.07, "draft_iters": 32.0, "mem_use": 34.86, "gen_rate": 33.0, "speed": 10.39, "text": "A Dyson Sphere is a hypothetical"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 24, "tree_size": 64, "t0": 0.8871, "t1": 0.24, "tft": 1.7711, "input_0": 100, "input_1": 65, "min_CLP": -5.66, "draft_iters": 7.9, "mem_use": 34.53, "gen_rate": 5.1, "speed": 4.56, "text": "\"\\nAnyone have experience with t"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 22.0, "tree_w": 8, "tree_size": 64, "t0": 2.33, "t1": 0.24, "tft": 1.5491, "input_0": 152, "input_1": 65, "min_CLP": -4.69, "draft_iters": 23.0, "mem_use": 34.53, "gen_rate": 18.0, "speed": 7.01, "text": "\\nDo you know how to speak Germa"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.7, "tree_w": 24, "tree_size": 64, "t0": 0.77, "t1": 0.2422, "tft": 1.7692, "input_0": 105, "input_1": 65, "min_CLP": -5.31, "draft_iters": 6.7, "mem_use": 34.67, "gen_rate": 3.6, "speed": 3.5, "text": "\\nEr ist eine hilfsbereite, unve"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 18, "tree_size": 64, "t0": 0.97, "t1": 0.26, "tft": 2.3618, "input_0": 125, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.0, "mem_use": 35.09, "gen_rate": 6.6, "speed": 5.38, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.2, "tree_w": 22, "tree_size": 64, "t0": 1.22, "t1": 0.2675, "tft": 2.5191, "input_0": 154, "input_1": 65, "min_CLP": -5.3, "draft_iters": 10.2, "mem_use": 35.4, "gen_rate": 8.0, "speed": 5.39, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 16.8, "tree_w": 17, "tree_size": 64, "t0": 1.775, "t1": 0.24, "tft": 1.9913, "input_0": 120, "input_1": 65, "min_CLP": -5.25, "draft_iters": 17.8, "mem_use": 34.61, "gen_rate": 10.8, "speed": 5.33, "text": "\\n[INST]\\nHow do you think?\\n[IN"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 13, "tree_size": 64, "t0": 2.97, "t1": 0.25, "tft": 2.764, "input_0": 146, "input_1": 65, "min_CLP": -4.99, "draft_iters": 32.0, "mem_use": 34.77, "gen_rate": 32.0, "speed": 9.93, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n[INST]"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.9, "tree_w": 21, "tree_size": 64, "t0": 1.1057, "t1": 0.24, "tft": 1.6199, "input_0": 125, "input_1": 65, "min_CLP": -5.26, "draft_iters": 9.9, "mem_use": 34.53, "gen_rate": 5.1, "speed": 3.82, "text": "\"\\nThe Arctic is the coldest pla"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 21, "tree_size": 64, "t0": 2.91, "t1": 0.25, "tft": 1.6373, "input_0": 107, "input_1": 65, "min_CLP": -5.05, "draft_iters": 32.0, "mem_use": 34.69, "gen_rate": 33.0, "speed": 10.47, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 64, "t0": 3.09, "t1": 0.25, "tft": 1.1144, "input_0": 173, "input_1": 65, "min_CLP": -5.03, "draft_iters": 32.0, "mem_use": 34.67, "gen_rate": 33.0, "speed": 9.9, "text": "\\ncan you write code? [\\\\INST]\\n"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 20, "tree_size": 64, "t0": 1.152, "t1": 0.276, "tft": 2.6877, "input_0": 120, "input_1": 65, "min_CLP": -5.14, "draft_iters": 10.0, "mem_use": 35.74, "gen_rate": 7.0, "speed": 4.9, "text": "\\n1. You need to mix the ingredi"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 3.01, "t1": 0.25, "tft": 2.5498, "input_0": 150, "input_1": 65, "min_CLP": -5.94, "draft_iters": 32.0, "mem_use": 34.77, "gen_rate": 33.0, "speed": 10.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.7, "tree_w": 27, "tree_size": 64, "t0": 0.877, "t1": 0.289, "tft": 3.8931, "input_0": 93, "input_1": 65, "min_CLP": -5.58, "draft_iters": 7.7, "mem_use": 36.04, "gen_rate": 3.3, "speed": 2.83, "text": "\\nYou are a young man named Josh"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.8, "tree_w": 22, "tree_size": 64, "t0": 0.9788, "t1": 0.24, "tft": 1.7147, "input_0": 118, "input_1": 65, "min_CLP": -5.54, "draft_iters": 8.8, "mem_use": 34.92, "gen_rate": 4.5, "speed": 3.68, "text": "\\nThe ASCII art house is here:\\n"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.1, "tree_w": 20, "tree_size": 64, "t0": 0.8386, "t1": 0.24, "tft": 1.5411, "input_0": 111, "input_1": 65, "min_CLP": -5.37, "draft_iters": 7.1, "mem_use": 34.53, "gen_rate": 5.4, "speed": 5.01, "text": "\\nThe difference between HTML an"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 22.0, "tree_w": 12, "tree_size": 64, "t0": 2.3, "t1": 0.24, "tft": 2.3213, "input_0": 175, "input_1": 65, "min_CLP": -5.11, "draft_iters": 22.7, "mem_use": 34.54, "gen_rate": 12.3, "speed": 4.85, "text": "\\nCreate a table with the solar "}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.7, "tree_w": 18, "tree_size": 64, "t0": 0.94, "t1": 0.2483, "tft": 1.7181, "input_0": 143, "input_1": 65, "min_CLP": -5.2, "draft_iters": 7.7, "mem_use": 34.73, "gen_rate": 6.2, "speed": 5.19, "text": "You are allowed to use the image"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.2, "tree_w": 22, "tree_size": 64, "t0": 0.8337, "t1": 0.24, "tft": 1.6944, "input_0": 108, "input_1": 65, "min_CLP": -5.3, "draft_iters": 7.2, "mem_use": 34.53, "gen_rate": 4.4, "speed": 4.06, "text": "\\nThe reason is that the second "}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.4, "tree_w": 21, "tree_size": 64, "t0": 0.98, "t1": 0.26, "tft": 2.2011, "input_0": 124, "input_1": 65, "min_CLP": -5.31, "draft_iters": 8.4, "mem_use": 35.06, "gen_rate": 4.6, "speed": 3.74, "text": "\\nWhy does rain seem to fall fro"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 15, "tree_size": 64, "t0": 2.09, "t1": 0.25, "tft": 1.8055, "input_0": 173, "input_1": 65, "min_CLP": -5.66, "draft_iters": 20.0, "mem_use": 34.92, "gen_rate": 20.5, "speed": 8.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.8, "tree_w": 26, "tree_size": 64, "t0": 0.685, "t1": 0.25, "tft": 1.4075, "input_0": 94, "input_1": 65, "min_CLP": -5.42, "draft_iters": 5.8, "mem_use": 34.84, "gen_rate": 3.3, "speed": 3.54, "text": "\\nI thought you were just talkin"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.2, "tree_w": 22, "tree_size": 64, "t0": 0.95, "t1": 0.26, "tft": 2.1431, "input_0": 110, "input_1": 65, "min_CLP": -5.33, "draft_iters": 8.2, "mem_use": 35.2, "gen_rate": 3.6, "speed": 2.97, "text": "\"\\nI'd like to include a section"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 56, "tree_h": 24.3, "tree_w": 10, "tree_size": 64, "t0": 2.43, "t1": 0.24, "tft": 3.3466, "input_0": 158, "input_1": 65, "min_CLP": -4.99, "draft_iters": 24.8, "mem_use": 34.51, "gen_rate": 9.3, "speed": 3.49, "text": "\\nMake ASCII art of a cat:\\n\\n<S"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 23, "tree_size": 64, "t0": 0.775, "t1": 0.245, "tft": 1.4143, "input_0": 103, "input_1": 65, "min_CLP": -5.07, "draft_iters": 6.6, "mem_use": 34.68, "gen_rate": 4.0, "speed": 3.92, "text": "\"I'm not sure I understand the q"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.4, "tree_w": 15, "tree_size": 64, "t0": 1.402, "t1": 0.254, "tft": 2.1414, "input_0": 174, "input_1": 65, "min_CLP": -4.86, "draft_iters": 12.4, "mem_use": 35.01, "gen_rate": 7.2, "speed": 4.35, "text": "\\nThe James Webb Space Telescope"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 26, "tree_size": 64, "t0": 0.85, "t1": 0.24, "tft": 1.965, "input_0": 97, "input_1": 65, "min_CLP": -5.6, "draft_iters": 7.7, "mem_use": 34.57, "gen_rate": 5.3, "speed": 4.88, "text": "\"[INST] I don't know, I just wor"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 14.0, "tree_w": 16, "tree_size": 64, "t0": 1.645, "t1": 0.265, "tft": 2.9195, "input_0": 150, "input_1": 65, "min_CLP": -4.77, "draft_iters": 14.8, "mem_use": 35.44, "gen_rate": 14.2, "speed": 7.46, "text": "\\nIn that case, you could use th"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 28.0, "tree_w": 6, "tree_size": 64, "t0": 2.865, "t1": 0.24, "tft": 3.6856, "input_0": 196, "input_1": 65, "min_CLP": -5.36, "draft_iters": 28.5, "mem_use": 34.66, "gen_rate": 29.0, "speed": 9.34, "text": "\\nExpl\u00edcame como implementar el "}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 64, "t0": 3.06, "t1": 0.25, "tft": 1.8265, "input_0": 170, "input_1": 65, "min_CLP": -5.4, "draft_iters": 32.0, "mem_use": 34.75, "gen_rate": 33.0, "speed": 9.99, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.9, "tree_w": 17, "tree_size": 64, "t0": 1.1657, "t1": 0.2643, "tft": 2.2886, "input_0": 140, "input_1": 65, "min_CLP": -5.11, "draft_iters": 9.9, "mem_use": 35.41, "gen_rate": 4.6, "speed": 3.2, "text": "A common question about AI assis"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.4, "tree_w": 20, "tree_size": 64, "t0": 0.9338, "t1": 0.27, "tft": 2.7041, "input_0": 134, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.4, "mem_use": 35.61, "gen_rate": 4.8, "speed": 3.94, "text": "\\nAllen has a total of 45 aircra"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 1.2775, "t1": 0.26, "tft": 2.1029, "input_0": 165, "input_1": 65, "min_CLP": -4.86, "draft_iters": 10.8, "mem_use": 35.31, "gen_rate": 8.0, "speed": 5.19, "text": "Unfortunately, I am not aware of"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.9, "tree_w": 21, "tree_size": 64, "t0": 1.0925, "t1": 0.24, "tft": 1.662, "input_0": 130, "input_1": 65, "min_CLP": -5.43, "draft_iters": 9.9, "mem_use": 34.56, "gen_rate": 4.1, "speed": 3.08, "text": "\\nRomeo\u2019s character is the most "}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 24, "tree_size": 64, "t0": 0.7586, "t1": 0.25, "tft": 1.72, "input_0": 99, "input_1": 65, "min_CLP": -5.34, "draft_iters": 6.4, "mem_use": 34.9, "gen_rate": 4.9, "speed": 4.81, "text": "[/INST]\\n\\nI think it would be w"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 31.0, "tree_w": 7, "tree_size": 64, "t0": 3.07, "t1": 0.24, "tft": 1.8175, "input_0": 176, "input_1": 65, "min_CLP": -5.84, "draft_iters": 31.5, "mem_use": 34.58, "gen_rate": 31.5, "speed": 9.5, "text": "\\nWhat are the main methods used"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.5, "tree_w": 28, "tree_size": 64, "t0": 0.8562, "t1": 0.24, "tft": 1.4297, "input_0": 111, "input_1": 65, "min_CLP": -5.7, "draft_iters": 7.5, "mem_use": 34.53, "gen_rate": 5.1, "speed": 4.67, "text": "\\nDo you think that there are an"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 24, "tree_size": 64, "t0": 0.82, "t1": 0.25, "tft": 2.0442, "input_0": 118, "input_1": 65, "min_CLP": -5.47, "draft_iters": 6.8, "mem_use": 34.94, "gen_rate": 4.2, "speed": 3.96, "text": "\"\\nYou are a member of a social "}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 24, "tree_size": 64, "t0": 0.7757, "t1": 0.26, "tft": 2.3571, "input_0": 102, "input_1": 65, "min_CLP": -5.22, "draft_iters": 6.4, "mem_use": 35.35, "gen_rate": 4.6, "speed": 4.41, "text": "\"The complete shutdown of a pers"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.9, "tree_w": 19, "tree_size": 64, "t0": 1.0525, "t1": 0.2788, "tft": 3.0092, "input_0": 119, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.9, "mem_use": 35.79, "gen_rate": 4.2, "speed": 3.2, "text": "\\nThere are two main ways that p"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.8, "tree_w": 22, "tree_size": 64, "t0": 0.8237, "t1": 0.26, "tft": 2.5465, "input_0": 115, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.8, "mem_use": 35.11, "gen_rate": 4.5, "speed": 4.17, "text": "Yes, a completely purple sky is "}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 28.0, "tree_w": 11, "tree_size": 64, "t0": 2.765, "t1": 0.255, "tft": 2.218, "input_0": 153, "input_1": 65, "min_CLP": -5.37, "draft_iters": 28.5, "mem_use": 35.06, "gen_rate": 20.0, "speed": 6.62, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.7, "tree_w": 15, "tree_size": 64, "t0": 1.3783, "t1": 0.2517, "tft": 3.5915, "input_0": 160, "input_1": 65, "min_CLP": -5.0, "draft_iters": 12.7, "mem_use": 34.99, "gen_rate": 6.0, "speed": 3.67, "text": "Japanese:\\n\\n[INST] What is the "}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.9, "tree_w": 23, "tree_size": 64, "t0": 0.8, "t1": 0.2437, "tft": 1.2898, "input_0": 107, "input_1": 65, "min_CLP": -5.22, "draft_iters": 6.9, "mem_use": 34.68, "gen_rate": 4.1, "speed": 3.95, "text": "\"[INST] Well, in Europe, the bes"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 61, "tree_h": 19.0, "tree_w": 10, "tree_size": 64, "t0": 2.085, "t1": 0.24, "tft": 2.3785, "input_0": 168, "input_1": 65, "min_CLP": -5.41, "draft_iters": 19.8, "mem_use": 34.51, "gen_rate": 15.2, "speed": 6.55, "text": "\\nwhy is rain wet? [\\\\INST]\\n\\nw"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 1.015, "t1": 0.24, "tft": 2.2187, "input_0": 132, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.8, "mem_use": 34.59, "gen_rate": 5.1, "speed": 4.07, "text": "\\nFor example, to convert the fo"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.4, "tree_w": 20, "tree_size": 64, "t0": 1.0562, "t1": 0.26, "tft": 2.2555, "input_0": 121, "input_1": 65, "min_CLP": -5.2, "draft_iters": 9.4, "mem_use": 35.15, "gen_rate": 4.1, "speed": 3.13, "text": "1. Look for ways to reduce finan"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.09, "t1": 0.24, "tft": 1.8845, "input_0": 172, "input_1": 65, "min_CLP": -5.14, "draft_iters": 32.0, "mem_use": 34.51, "gen_rate": 33.0, "speed": 9.91, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 16, "tree_size": 64, "t0": 1.3475, "t1": 0.28, "tft": 3.4339, "input_0": 149, "input_1": 65, "min_CLP": -5.1, "draft_iters": 11.2, "mem_use": 35.92, "gen_rate": 8.5, "speed": 5.22, "text": "For example, if you need to stor"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 64, "t0": 3.0, "t1": 0.25, "tft": 1.5992, "input_0": 149, "input_1": 65, "min_CLP": -5.25, "draft_iters": 32.0, "mem_use": 34.89, "gen_rate": 33.0, "speed": 10.15, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 14, "tree_size": 64, "t0": 1.44, "t1": 0.24, "tft": 1.5326, "input_0": 154, "input_1": 65, "min_CLP": -5.23, "draft_iters": 12.8, "mem_use": 34.56, "gen_rate": 8.0, "speed": 4.76, "text": "\\nWhat is your favorite movie?\\n"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 1.0188, "t1": 0.2725, "tft": 5.3026, "input_0": 129, "input_1": 65, "min_CLP": -5.29, "draft_iters": 8.4, "mem_use": 35.71, "gen_rate": 4.4, "speed": 3.39, "text": "Unfortunately, the only open sou"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 55, "tree_h": 12.2, "tree_w": 21, "tree_size": 64, "t0": 1.348, "t1": 0.24, "tft": 1.4557, "input_0": 110, "input_1": 65, "min_CLP": -5.27, "draft_iters": 13.2, "mem_use": 34.75, "gen_rate": 11.0, "speed": 6.92, "text": "\\nThe answer to this question is"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.4, "tree_w": 24, "tree_size": 64, "t0": 0.8513, "t1": 0.25, "tft": 2.6988, "input_0": 113, "input_1": 65, "min_CLP": -5.3, "draft_iters": 7.4, "mem_use": 34.9, "gen_rate": 4.4, "speed": 3.97, "text": "[/INST]\\n\\nI\\'m not sure what yo"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 15.0, "tree_w": 11, "tree_size": 64, "t0": 1.865, "t1": 0.2625, "tft": 4.5542, "input_0": 200, "input_1": 65, "min_CLP": -4.72, "draft_iters": 16.0, "mem_use": 35.35, "gen_rate": 12.2, "speed": 5.76, "text": "1. m\u00eb - melm\u00eb\\n2. meles - melm\u00eb\\"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 64, "t0": 3.02, "t1": 0.25, "tft": 1.4139, "input_0": 162, "input_1": 65, "min_CLP": -5.3, "draft_iters": 32.0, "mem_use": 34.68, "gen_rate": 33.0, "speed": 10.11, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 10.8, "tree_w": 21, "tree_size": 64, "t0": 1.2812, "t1": 0.28, "tft": 3.5496, "input_0": 109, "input_1": 65, "min_CLP": -5.24, "draft_iters": 11.6, "mem_use": 35.89, "gen_rate": 4.5, "speed": 2.88, "text": "\\nYou cannot change the temperat"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.6, "tree_w": 24, "tree_size": 64, "t0": 0.765, "t1": 0.24, "tft": 3.385, "input_0": 102, "input_1": 65, "min_CLP": -5.5, "draft_iters": 6.6, "mem_use": 34.84, "gen_rate": 4.1, "speed": 4.09, "text": "\"\\nHi,\\n\\nI am writing a report "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.0, "tree_w": 20, "tree_size": 64, "t0": 1.1271, "t1": 0.27, "tft": 4.5179, "input_0": 118, "input_1": 65, "min_CLP": -5.31, "draft_iters": 10.0, "mem_use": 35.57, "gen_rate": 4.7, "speed": 3.37, "text": "\\nThe example code for step 1 is"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.7, "tree_w": 10, "tree_size": 64, "t0": 1.7367, "t1": 0.24, "tft": 1.8975, "input_0": 171, "input_1": 65, "min_CLP": -5.15, "draft_iters": 15.7, "mem_use": 34.68, "gen_rate": 11.7, "speed": 5.9, "text": "\\nThe largest ocean in the world"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.6, "tree_w": 28, "tree_size": 64, "t0": 0.674, "t1": 0.25, "tft": 1.2415, "input_0": 98, "input_1": 65, "min_CLP": -5.42, "draft_iters": 5.6, "mem_use": 34.75, "gen_rate": 3.5, "speed": 3.8, "text": "\"Probably, it's hard to say. AI "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.0, "tree_w": 24, "tree_size": 64, "t0": 1.2586, "t1": 0.33, "tft": 6.043, "input_0": 116, "input_1": 65, "min_CLP": -5.4, "draft_iters": 10.0, "mem_use": 37.38, "gen_rate": 5.6, "speed": 3.5, "text": "\"\\n[Verse 1]\\nI'm a cactus\\nYou'"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 46, "tree_h": 8.9, "tree_w": 21, "tree_size": 64, "t0": 1.0857, "t1": 0.25, "tft": 1.8674, "input_0": 109, "input_1": 65, "min_CLP": -5.23, "draft_iters": 9.9, "mem_use": 35.58, "gen_rate": 6.6, "speed": 4.9, "text": "0 find out if new competitors ha"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 19.0, "tree_w": 14, "tree_size": 64, "t0": 2.12, "t1": 0.28, "tft": 4.0498, "input_0": 155, "input_1": 65, "min_CLP": -5.18, "draft_iters": 19.7, "mem_use": 35.91, "gen_rate": 14.7, "speed": 6.11, "text": "\\n[INST] WHY BE A BUSINESS PROFE"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.7, "tree_w": 25, "tree_size": 64, "t0": 0.7078, "t1": 0.2578, "tft": 1.9487, "input_0": 98, "input_1": 65, "min_CLP": -5.48, "draft_iters": 5.7, "mem_use": 35.06, "gen_rate": 3.8, "speed": 3.92, "text": "\\nNOTE: The above example is not"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 64, "t0": 2.95, "t1": 0.25, "tft": 1.7018, "input_0": 121, "input_1": 65, "min_CLP": -5.66, "draft_iters": 32.0, "mem_use": 34.68, "gen_rate": 33.0, "speed": 10.33, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 16, "tree_size": 64, "t0": 1.0686, "t1": 0.28, "tft": 4.2413, "input_0": 145, "input_1": 65, "min_CLP": -4.94, "draft_iters": 8.3, "mem_use": 35.97, "gen_rate": 5.0, "speed": 3.7, "text": "The efficiency of a language mod"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 16, "tree_size": 64, "t0": 2.005, "t1": 0.25, "tft": 2.5491, "input_0": 133, "input_1": 65, "min_CLP": -5.46, "draft_iters": 20.0, "mem_use": 34.89, "gen_rate": 20.5, "speed": 9.09, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.7, "tree_w": 18, "tree_size": 64, "t0": 1.125, "t1": 0.2783, "tft": 3.9715, "input_0": 111, "input_1": 65, "min_CLP": -5.18, "draft_iters": 9.7, "mem_use": 35.81, "gen_rate": 5.3, "speed": 3.8, "text": "\\nList a few examples of network"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.7, "tree_w": 27, "tree_size": 64, "t0": 0.672, "t1": 0.24, "tft": 1.5463, "input_0": 90, "input_1": 65, "min_CLP": -5.56, "draft_iters": 5.7, "mem_use": 34.8, "gen_rate": 3.4, "speed": 3.72, "text": "\\nThis is a really simple algori"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.0, "tree_w": 19, "tree_size": 64, "t0": 0.948, "t1": 0.25, "tft": 1.7803, "input_0": 120, "input_1": 65, "min_CLP": -4.98, "draft_iters": 8.0, "mem_use": 34.91, "gen_rate": 7.0, "speed": 5.83, "text": "Public indecency laws were creat"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.0, "tree_w": 28, "tree_size": 64, "t0": 0.7136, "t1": 0.2491, "tft": 1.8608, "input_0": 93, "input_1": 65, "min_CLP": -5.45, "draft_iters": 6.0, "mem_use": 34.77, "gen_rate": 3.1, "speed": 3.22, "text": "\"\\nWe are all different, but one"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 3.14, "t1": 0.24, "tft": 2.5763, "input_0": 217, "input_1": 65, "min_CLP": -5.52, "draft_iters": 32.0, "mem_use": 34.56, "gen_rate": 33.0, "speed": 9.76, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.2, "tree_w": 23, "tree_size": 64, "t0": 0.86, "t1": 0.2533, "tft": 2.1069, "input_0": 110, "input_1": 65, "min_CLP": -5.2, "draft_iters": 7.2, "mem_use": 35.0, "gen_rate": 5.8, "speed": 5.25, "text": "\"\\nA good way to overcome this i"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 21.8, "tree_w": 11, "tree_size": 64, "t0": 2.402, "t1": 0.28, "tft": 3.6954, "input_0": 177, "input_1": 65, "min_CLP": -4.3, "draft_iters": 22.4, "mem_use": 35.83, "gen_rate": 6.4, "speed": 2.39, "text": "Learning Chinese characters can "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.0, "t1": 0.24, "tft": 2.5488, "input_0": 138, "input_1": 65, "min_CLP": -5.57, "draft_iters": 32.0, "mem_use": 34.81, "gen_rate": 33.0, "speed": 10.17, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.8, "tree_w": 23, "tree_size": 64, "t0": 0.7963, "t1": 0.24, "tft": 2.5875, "input_0": 111, "input_1": 65, "min_CLP": -5.54, "draft_iters": 6.8, "mem_use": 34.57, "gen_rate": 4.4, "speed": 4.21, "text": "\\nBot is run by Discord.js v14.\\"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.3, "tree_w": 28, "tree_size": 64, "t0": 0.7156, "t1": 0.24, "tft": 1.8878, "input_0": 89, "input_1": 65, "min_CLP": -5.45, "draft_iters": 6.3, "mem_use": 34.53, "gen_rate": 3.6, "speed": 3.71, "text": "\\nThis is a test to see how well"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 18, "tree_size": 64, "t0": 1.0114, "t1": 0.31, "tft": 4.6271, "input_0": 122, "input_1": 65, "min_CLP": -5.14, "draft_iters": 7.7, "mem_use": 36.67, "gen_rate": 4.9, "speed": 3.68, "text": "\"If you don't have to specify ty"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 20.0, "tree_w": 14, "tree_size": 64, "t0": 2.02, "t1": 0.24, "tft": 2.5315, "input_0": 141, "input_1": 65, "min_CLP": -5.26, "draft_iters": 20.5, "mem_use": 35.22, "gen_rate": 19.0, "speed": 8.39, "text": "\"\\nLuis Matilda Drake\\n\\nMike's "}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.1, "tree_w": 24, "tree_size": 64, "t0": 0.7757, "t1": 0.26, "tft": 2.151, "input_0": 116, "input_1": 65, "min_CLP": -5.35, "draft_iters": 6.1, "mem_use": 35.11, "gen_rate": 4.6, "speed": 4.44, "text": "\\nHow do you make a mob farm? [\\"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 13.8, "tree_w": 21, "tree_size": 64, "t0": 1.6175, "t1": 0.29, "tft": 4.6818, "input_0": 136, "input_1": 65, "min_CLP": -5.31, "draft_iters": 14.8, "mem_use": 36.05, "gen_rate": 11.2, "speed": 5.91, "text": "Toast your bread for 10 seconds."}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 3.31, "t1": 0.24, "tft": 1.6959, "input_0": 254, "input_1": 65, "min_CLP": -5.61, "draft_iters": 32.0, "mem_use": 34.94, "gen_rate": 33.0, "speed": 9.28, "text": "\"\\nI have a project due in 2 wee"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 8.6, "tree_w": 22, "tree_size": 64, "t0": 1.0467, "t1": 0.25, "tft": 1.7648, "input_0": 102, "input_1": 65, "min_CLP": -5.35, "draft_iters": 9.6, "mem_use": 34.92, "gen_rate": 4.4, "speed": 3.43, "text": "\"\\nI'm learning Japanese Kanji t"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 5.9, "tree_w": 20, "tree_size": 64, "t0": 0.8714, "t1": 0.28, "tft": 3.3486, "input_0": 122, "input_1": 65, "min_CLP": -5.13, "draft_iters": 6.9, "mem_use": 35.81, "gen_rate": 5.4, "speed": 4.72, "text": "To prepare for a robotics degree"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 5.9, "tree_w": 26, "tree_size": 64, "t0": 0.825, "t1": 0.25, "tft": 1.7496, "input_0": 110, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.9, "mem_use": 34.95, "gen_rate": 2.7, "speed": 2.48, "text": "Invented by a Canadian named RCA"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 64, "tree_h": 27.7, "tree_w": 12, "tree_size": 64, "t0": 3.0033, "t1": 0.29, "tft": 3.829, "input_0": 181, "input_1": 65, "min_CLP": -5.56, "draft_iters": 28.3, "mem_use": 36.12, "gen_rate": 21.3, "speed": 6.48, "text": "\\n<<SYS>>\\n\\n<<SYS>>\\n\\n<<SYS>>\\"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.0, "tree_w": 25, "tree_size": 64, "t0": 0.9343, "t1": 0.26, "tft": 2.1126, "input_0": 115, "input_1": 65, "min_CLP": -5.21, "draft_iters": 8.0, "mem_use": 35.26, "gen_rate": 5.6, "speed": 4.66, "text": "Christmas is a time of year that"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 64, "t0": 2.99, "t1": 0.25, "tft": 1.7199, "input_0": 129, "input_1": 65, "min_CLP": -4.99, "draft_iters": 32.0, "mem_use": 34.8, "gen_rate": 33.0, "speed": 10.18, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 3.18, "t1": 0.27, "tft": 3.7844, "input_0": 173, "input_1": 65, "min_CLP": -4.74, "draft_iters": 32.0, "mem_use": 35.73, "gen_rate": 33.0, "speed": 9.54, "text": "Learning to write Chinese charac"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.7, "tree_w": 22, "tree_size": 64, "t0": 0.8014, "t1": 0.24, "tft": 1.8216, "input_0": 108, "input_1": 65, "min_CLP": -5.38, "draft_iters": 6.7, "mem_use": 34.77, "gen_rate": 4.9, "speed": 4.64, "text": "\\nWhile you are correct that you"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 23, "tree_size": 64, "t0": 0.8957, "t1": 0.25, "tft": 1.8209, "input_0": 117, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.6, "mem_use": 34.96, "gen_rate": 5.1, "speed": 4.48, "text": "\"It's just an example of what a "}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 25, "tree_size": 64, "t0": 0.87, "t1": 0.2457, "tft": 1.3225, "input_0": 111, "input_1": 65, "min_CLP": -5.37, "draft_iters": 7.6, "mem_use": 34.67, "gen_rate": 4.6, "speed": 4.1, "text": "How do you know if your wallet i"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.04, "t1": 0.25, "tft": 1.7357, "input_0": 153, "input_1": 65, "min_CLP": -5.58, "draft_iters": 32.0, "mem_use": 34.67, "gen_rate": 33.0, "speed": 10.06, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.4, "tree_w": 24, "tree_size": 64, "t0": 0.769, "t1": 0.25, "tft": 1.809, "input_0": 103, "input_1": 65, "min_CLP": -5.22, "draft_iters": 6.4, "mem_use": 34.85, "gen_rate": 3.4, "speed": 3.34, "text": "Google Authenticator is an app t"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.8, "tree_w": 25, "tree_size": 64, "t0": 0.8262, "t1": 0.25, "tft": 2.043, "input_0": 120, "input_1": 65, "min_CLP": -5.42, "draft_iters": 6.8, "mem_use": 34.77, "gen_rate": 4.4, "speed": 4.07, "text": "We can use prime numbers to show"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 24, "tree_size": 64, "t0": 0.8971, "t1": 0.2414, "tft": 1.9974, "input_0": 105, "input_1": 65, "min_CLP": -5.39, "draft_iters": 8.1, "mem_use": 34.64, "gen_rate": 4.7, "speed": 4.13, "text": "\\nI also need to make a function"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 22, "tree_size": 64, "t0": 0.8843, "t1": 0.24, "tft": 1.8332, "input_0": 112, "input_1": 65, "min_CLP": -5.06, "draft_iters": 7.7, "mem_use": 34.56, "gen_rate": 4.6, "speed": 4.06, "text": "\\nIn order to get a better Wi-Fi"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.9, "tree_w": 24, "tree_size": 64, "t0": 1.0357, "t1": 0.24, "tft": 2.4119, "input_0": 99, "input_1": 65, "min_CLP": -5.36, "draft_iters": 9.9, "mem_use": 34.57, "gen_rate": 4.6, "speed": 3.57, "text": "\\nWrite me a program that takes "}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.8, "tree_w": 28, "tree_size": 64, "t0": 0.6691, "t1": 0.24, "tft": 1.5537, "input_0": 83, "input_1": 65, "min_CLP": -5.67, "draft_iters": 5.8, "mem_use": 34.54, "gen_rate": 3.0, "speed": 3.29, "text": "\\nThe idea behind the idea\\n\\nTh"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 9, "tree_size": 64, "t0": 2.58, "t1": 0.26, "tft": 2.3724, "input_0": 185, "input_1": 65, "min_CLP": -5.01, "draft_iters": 24.5, "mem_use": 35.18, "gen_rate": 25.0, "speed": 8.81, "text": "You can use the scp (secure copy"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 11, "tree_size": 64, "t0": 2.375, "t1": 0.24, "tft": 1.4964, "input_0": 183, "input_1": 65, "min_CLP": -5.55, "draft_iters": 22.5, "mem_use": 34.53, "gen_rate": 23.0, "speed": 8.79, "text": "\\nwhat does the @ in python do ["}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.0, "tree_w": 27, "tree_size": 64, "t0": 0.6067, "t1": 0.24, "tft": 2.2349, "input_0": 86, "input_1": 65, "min_CLP": -5.36, "draft_iters": 5.0, "mem_use": 34.53, "gen_rate": 3.9, "speed": 4.58, "text": "\\nThis is an interesting idea, I"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.4, "tree_w": 28, "tree_size": 64, "t0": 0.89, "t1": 0.242, "tft": 1.5946, "input_0": 82, "input_1": 65, "min_CLP": -5.48, "draft_iters": 8.4, "mem_use": 34.67, "gen_rate": 6.8, "speed": 6.0, "text": "\\nI will take it apart and put i"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 27.0, "tree_w": 13, "tree_size": 64, "t0": 2.615, "t1": 0.24, "tft": 1.6726, "input_0": 137, "input_1": 65, "min_CLP": -5.36, "draft_iters": 27.5, "mem_use": 34.54, "gen_rate": 18.5, "speed": 6.47, "text": "\\n<</SYS>\\n\\n[INST] <<SYS>>\\nYou"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 64, "t0": 3.1, "t1": 0.25, "tft": 3.006, "input_0": 162, "input_1": 65, "min_CLP": -5.36, "draft_iters": 32.0, "mem_use": 34.91, "gen_rate": 33.0, "speed": 9.84, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.3, "tree_w": 8, "tree_size": 64, "t0": 2.3833, "t1": 0.29, "tft": 4.3458, "input_0": 177, "input_1": 65, "min_CLP": -5.01, "draft_iters": 21.3, "mem_use": 36.18, "gen_rate": 12.7, "speed": 4.73, "text": "\"\\nWhat's the current time? [\\\\I"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 21, "tree_size": 64, "t0": 0.9088, "t1": 0.25, "tft": 1.7046, "input_0": 129, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.5, "mem_use": 34.99, "gen_rate": 4.2, "speed": 3.67, "text": "\\nYes, decorators can do more th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.1, "tree_w": 22, "tree_size": 64, "t0": 1.1512, "t1": 0.2625, "tft": 2.8016, "input_0": 124, "input_1": 65, "min_CLP": -5.22, "draft_iters": 10.1, "mem_use": 35.34, "gen_rate": 4.2, "speed": 3.0, "text": "[SYS] Hello.\\n[SYS] Can you hear"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 16, "tree_size": 64, "t0": 1.535, "t1": 0.25, "tft": 2.1106, "input_0": 136, "input_1": 65, "min_CLP": -5.46, "draft_iters": 14.8, "mem_use": 34.79, "gen_rate": 8.0, "speed": 4.49, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.7, "tree_w": 16, "tree_size": 64, "t0": 2.3433, "t1": 0.31, "tft": 4.8977, "input_0": 157, "input_1": 65, "min_CLP": -5.29, "draft_iters": 21.3, "mem_use": 36.65, "gen_rate": 11.3, "speed": 4.27, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.6, "tree_w": 27, "tree_size": 64, "t0": 0.8756, "t1": 0.4022, "tft": 8.693, "input_0": 90, "input_1": 65, "min_CLP": -5.61, "draft_iters": 5.6, "mem_use": 39.43, "gen_rate": 3.7, "speed": 2.87, "text": "Iris dataset is a publicly avail"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.7, "tree_w": 21, "tree_size": 64, "t0": 1.08, "t1": 0.27, "tft": 2.8975, "input_0": 106, "input_1": 65, "min_CLP": -5.3, "draft_iters": 9.7, "mem_use": 36.53, "gen_rate": 4.9, "speed": 3.61, "text": "\"L'H\u00f4pital's Rule is used to cal"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 15.0, "tree_w": 15, "tree_size": 64, "t0": 1.6467, "t1": 0.24, "tft": 1.9459, "input_0": 140, "input_1": 65, "min_CLP": -5.64, "draft_iters": 16.0, "mem_use": 34.66, "gen_rate": 13.3, "speed": 7.07, "text": "\\n[ACTION]\\n\\n[MED] <<SYS>>\\nYou"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 20, "tree_h": 4.9, "tree_w": 26, "tree_size": 64, "t0": 0.68, "t1": 0.24, "tft": 1.5795, "input_0": 87, "input_1": 65, "min_CLP": -5.42, "draft_iters": 5.9, "mem_use": 34.6, "gen_rate": 2.5, "speed": 2.71, "text": "\\nIf you are not sure of the typ"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 3.34, "t1": 0.29, "tft": 5.8959, "input_0": 172, "input_1": 65, "min_CLP": -4.37, "draft_iters": 32.0, "mem_use": 36.03, "gen_rate": 33.0, "speed": 9.1, "text": "The approach depends on many fac"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 9.7, "tree_w": 21, "tree_size": 64, "t0": 1.1667, "t1": 0.24, "tft": 1.7271, "input_0": 121, "input_1": 65, "min_CLP": -5.37, "draft_iters": 10.7, "mem_use": 34.91, "gen_rate": 8.0, "speed": 5.68, "text": "\"\\nI'm sure you're familiar with"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 8.4, "tree_w": 21, "tree_size": 64, "t0": 1.2625, "t1": 0.3225, "tft": 5.6803, "input_0": 157, "input_1": 65, "min_CLP": -5.21, "draft_iters": 9.4, "mem_use": 37.18, "gen_rate": 5.2, "speed": 3.31, "text": "You can start by learning about "}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 22, "tree_size": 64, "t0": 0.8514, "t1": 0.25, "tft": 1.3508, "input_0": 118, "input_1": 65, "min_CLP": -5.07, "draft_iters": 7.1, "mem_use": 35.47, "gen_rate": 4.6, "speed": 4.17, "text": "The order of the parts is import"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.7, "tree_w": 15, "tree_size": 64, "t0": 1.3783, "t1": 0.245, "tft": 1.4334, "input_0": 140, "input_1": 65, "min_CLP": -5.02, "draft_iters": 12.7, "mem_use": 34.67, "gen_rate": 6.7, "speed": 4.11, "text": "\"[INST] What are the best comput"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.7, "tree_w": 27, "tree_size": 64, "t0": 0.67, "t1": 0.2478, "tft": 1.6769, "input_0": 94, "input_1": 65, "min_CLP": -5.65, "draft_iters": 5.7, "mem_use": 34.7, "gen_rate": 3.6, "speed": 3.89, "text": "\"ChatGPT has an active, friendly"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 1.02, "t1": 0.26, "tft": 2.8676, "input_0": 133, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.4, "mem_use": 35.3, "gen_rate": 7.0, "speed": 5.46, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.7, "tree_w": 26, "tree_size": 64, "t0": 0.777, "t1": 0.246, "tft": 2.01, "input_0": 103, "input_1": 65, "min_CLP": -5.46, "draft_iters": 6.7, "mem_use": 34.73, "gen_rate": 3.2, "speed": 3.13, "text": "\\n<INST>\\nToshiba has been a lea"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 21, "tree_size": 64, "t0": 1.0143, "t1": 0.25, "tft": 1.4258, "input_0": 121, "input_1": 65, "min_CLP": -5.19, "draft_iters": 8.9, "mem_use": 34.83, "gen_rate": 4.7, "speed": 3.73, "text": "chili powder [\\\\INST]\\n\\nI want "}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.4, "tree_w": 22, "tree_size": 64, "t0": 0.8688, "t1": 0.25, "tft": 1.6456, "input_0": 117, "input_1": 65, "min_CLP": -5.1, "draft_iters": 7.4, "mem_use": 34.84, "gen_rate": 4.5, "speed": 4.02, "text": "You can try using a telescope, w"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.0, "tree_w": 23, "tree_size": 64, "t0": 0.8988, "t1": 0.28, "tft": 3.4002, "input_0": 131, "input_1": 65, "min_CLP": -5.11, "draft_iters": 7.0, "mem_use": 35.84, "gen_rate": 4.6, "speed": 3.93, "text": "\u2022 Start by looking up the chords"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.3, "tree_w": 25, "tree_size": 64, "t0": 0.7378, "t1": 0.24, "tft": 1.3886, "input_0": 100, "input_1": 65, "min_CLP": -5.32, "draft_iters": 6.3, "mem_use": 34.81, "gen_rate": 3.6, "speed": 3.63, "text": "\"\\nThis is quite a unique questi"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 3.35, "t1": 0.24, "tft": 1.8443, "input_0": 263, "input_1": 65, "min_CLP": -5.27, "draft_iters": 32.0, "mem_use": 34.6, "gen_rate": 33.0, "speed": 9.2, "text": "\\nGiven two matrices A and B whi"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 6.5, "tree_w": 25, "tree_size": 64, "t0": 0.8591, "t1": 0.2609, "tft": 2.6771, "input_0": 98, "input_1": 65, "min_CLP": -5.66, "draft_iters": 7.5, "mem_use": 35.35, "gen_rate": 3.0, "speed": 2.67, "text": "\"\\nThe rap song is called 'St. S"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 3.38, "t1": 0.28, "tft": 3.5144, "input_0": 224, "input_1": 65, "min_CLP": -5.97, "draft_iters": 32.0, "mem_use": 35.9, "gen_rate": 33.0, "speed": 9.01, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 7.6, "tree_w": 19, "tree_size": 64, "t0": 0.9875, "t1": 0.24, "tft": 1.9637, "input_0": 111, "input_1": 65, "min_CLP": -5.23, "draft_iters": 8.6, "mem_use": 34.84, "gen_rate": 5.2, "speed": 4.27, "text": "\\nPlease tell me when it is. [\\\\"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.6, "tree_w": 27, "tree_size": 64, "t0": 0.7611, "t1": 0.26, "tft": 2.1085, "input_0": 92, "input_1": 65, "min_CLP": -5.46, "draft_iters": 6.6, "mem_use": 35.27, "gen_rate": 3.7, "speed": 3.59, "text": "\\nThis is a great example of how"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 20, "tree_size": 64, "t0": 0.9171, "t1": 0.2486, "tft": 1.724, "input_0": 112, "input_1": 65, "min_CLP": -5.26, "draft_iters": 7.9, "mem_use": 34.7, "gen_rate": 5.0, "speed": 4.29, "text": "\"I'm sorry, but I'm not sure wha"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 21, "tree_size": 64, "t0": 0.9086, "t1": 0.24, "tft": 1.5207, "input_0": 121, "input_1": 65, "min_CLP": -5.24, "draft_iters": 7.6, "mem_use": 34.54, "gen_rate": 5.1, "speed": 4.46, "text": "\"\\nLet's say we have two variabl"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 64, "t0": 3.03, "t1": 0.25, "tft": 3.7515, "input_0": 180, "input_1": 65, "min_CLP": -5.4, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 33.0, "speed": 10.06, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 0.9725, "t1": 0.24, "tft": 1.3468, "input_0": 126, "input_1": 65, "min_CLP": -5.44, "draft_iters": 8.4, "mem_use": 34.51, "gen_rate": 4.9, "speed": 4.01, "text": "\\n[SYS]\\nYour metabolism is the "}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 3.19, "t1": 0.26, "tft": 2.4058, "input_0": 196, "input_1": 65, "min_CLP": -4.03, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 9.57, "text": "\\nHow far away is Saggitarius A*"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 11, "tree_size": 64, "t0": 1.7975, "t1": 0.24, "tft": 2.541, "input_0": 198, "input_1": 65, "min_CLP": -4.79, "draft_iters": 15.5, "mem_use": 34.61, "gen_rate": 9.8, "speed": 4.78, "text": "\\nA: John\\n\\nB: John\\n\\nC: Jay\\n"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 15, "tree_size": 64, "t0": 1.385, "t1": 0.25, "tft": 1.7671, "input_0": 144, "input_1": 65, "min_CLP": -5.35, "draft_iters": 12.2, "mem_use": 34.8, "gen_rate": 8.0, "speed": 4.9, "text": "\\nWhat is the largest bird in th"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 22, "tree_size": 64, "t0": 0.7513, "t1": 0.25, "tft": 1.76, "input_0": 107, "input_1": 65, "min_CLP": -5.33, "draft_iters": 6.1, "mem_use": 34.94, "gen_rate": 4.1, "speed": 4.1, "text": "\\nThe best way to get started is"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 18.5, "tree_w": 21, "tree_size": 64, "t0": 1.91, "t1": 0.24, "tft": 1.516, "input_0": 122, "input_1": 65, "min_CLP": -5.01, "draft_iters": 19.5, "mem_use": 34.62, "gen_rate": 17.0, "speed": 7.89, "text": "\"\\nI'd like the example to inclu"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 28, "tree_size": 64, "t0": 0.7157, "t1": 0.26, "tft": 2.0696, "input_0": 110, "input_1": 65, "min_CLP": -5.4, "draft_iters": 5.6, "mem_use": 35.16, "gen_rate": 4.6, "speed": 4.68, "text": "A dll file is a dynamic link lib"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 42, "tree_h": 10.8, "tree_w": 21, "tree_size": 64, "t0": 1.2389, "t1": 0.25, "tft": 1.795, "input_0": 116, "input_1": 65, "min_CLP": -5.47, "draft_iters": 11.7, "mem_use": 34.78, "gen_rate": 4.7, "speed": 3.14, "text": "\\nThe following sentence is a fr"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 28, "tree_size": 64, "t0": 0.7229, "t1": 0.24, "tft": 1.4231, "input_0": 85, "input_1": 65, "min_CLP": -5.9, "draft_iters": 6.4, "mem_use": 34.52, "gen_rate": 4.6, "speed": 4.74, "text": "\"\\nwhat is the Infinite banking "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.9, "tree_w": 24, "tree_size": 64, "t0": 0.781, "t1": 0.24, "tft": 1.8318, "input_0": 97, "input_1": 65, "min_CLP": -5.44, "draft_iters": 6.9, "mem_use": 34.58, "gen_rate": 3.4, "speed": 3.32, "text": "\\nWrite me an HTML5 game that us"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.9, "tree_w": 21, "tree_size": 64, "t0": 0.9187, "t1": 0.2437, "tft": 1.3928, "input_0": 116, "input_1": 65, "min_CLP": -5.19, "draft_iters": 7.9, "mem_use": 34.65, "gen_rate": 4.0, "speed": 3.44, "text": "Their money is superior to your "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 27, "tree_size": 64, "t0": 0.656, "t1": 0.25, "tft": 1.6807, "input_0": 88, "input_1": 65, "min_CLP": -5.42, "draft_iters": 5.5, "mem_use": 34.91, "gen_rate": 3.3, "speed": 3.64, "text": "\"I don't have a better reason. I"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.1, "tree_w": 26, "tree_size": 64, "t0": 0.734, "t1": 0.26, "tft": 3.01, "input_0": 99, "input_1": 65, "min_CLP": -5.25, "draft_iters": 6.1, "mem_use": 35.38, "gen_rate": 3.3, "speed": 3.31, "text": "\\nThis is a standard request for"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 3.19, "t1": 0.27, "tft": 2.8006, "input_0": 170, "input_1": 65, "min_CLP": -4.28, "draft_iters": 32.0, "mem_use": 35.6, "gen_rate": 33.0, "speed": 9.53, "text": "Learning a language can be chall"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 10.5, "tree_w": 14, "tree_size": 64, "t0": 1.37, "t1": 0.25, "tft": 1.5883, "input_0": 185, "input_1": 65, "min_CLP": -5.34, "draft_iters": 11.5, "mem_use": 34.83, "gen_rate": 6.0, "speed": 3.71, "text": "All of these tools can be used f"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.3, "tree_w": 24, "tree_size": 64, "t0": 0.765, "t1": 0.25, "tft": 1.5555, "input_0": 110, "input_1": 65, "min_CLP": -5.39, "draft_iters": 6.3, "mem_use": 34.75, "gen_rate": 5.3, "speed": 5.27, "text": "I do have opinions on certain su"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.1, "tree_w": 23, "tree_size": 64, "t0": 0.8375, "t1": 0.25, "tft": 1.6517, "input_0": 113, "input_1": 65, "min_CLP": -5.35, "draft_iters": 7.1, "mem_use": 34.86, "gen_rate": 4.0, "speed": 3.68, "text": "It is worth nothing to me. I am "}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 15, "tree_size": 64, "t0": 1.125, "t1": 0.25, "tft": 1.8416, "input_0": 154, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.0, "mem_use": 34.82, "gen_rate": 5.3, "speed": 3.88, "text": "The \"A\" in the name stands for \""}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 32.0, "tree_w": 20, "tree_size": 64, "t0": 2.97, "t1": 0.24, "tft": 1.6674, "input_0": 153, "input_1": 65, "min_CLP": -5.41, "draft_iters": 32.0, "mem_use": 34.58, "gen_rate": 19.0, "speed": 5.91, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.4, "tree_w": 19, "tree_size": 64, "t0": 1.188, "t1": 0.264, "tft": 2.4479, "input_0": 130, "input_1": 65, "min_CLP": -5.21, "draft_iters": 10.4, "mem_use": 35.4, "gen_rate": 7.4, "speed": 5.1, "text": "The **Lunar Reconnaissance Orbit"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.1, "tree_w": 25, "tree_size": 64, "t0": 1.2957, "t1": 0.2443, "tft": 1.893, "input_0": 128, "input_1": 65, "min_CLP": -5.67, "draft_iters": 12.1, "mem_use": 34.67, "gen_rate": 4.9, "speed": 3.15, "text": "<</SYS>\\n\\nComplete the followin"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.3, "tree_w": 14, "tree_size": 64, "t0": 1.91, "t1": 0.24, "tft": 2.3907, "input_0": 163, "input_1": 65, "min_CLP": -5.23, "draft_iters": 18.3, "mem_use": 34.56, "gen_rate": 12.0, "speed": 5.58, "text": "\\nProvide me with a list of 10 n"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.454, "t1": 0.25, "tft": 1.7134, "input_0": 171, "input_1": 65, "min_CLP": -4.76, "draft_iters": 12.4, "mem_use": 34.82, "gen_rate": 7.8, "speed": 4.58, "text": "[INST] what are your interests ["}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.9, "tree_w": 18, "tree_size": 64, "t0": 1.5529, "t1": 0.2714, "tft": 3.1178, "input_0": 159, "input_1": 65, "min_CLP": -5.16, "draft_iters": 13.7, "mem_use": 35.67, "gen_rate": 5.1, "speed": 2.82, "text": "The initial noise in an image is"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 26, "tree_size": 64, "t0": 0.7829, "t1": 0.2586, "tft": 1.8731, "input_0": 115, "input_1": 65, "min_CLP": -5.41, "draft_iters": 6.4, "mem_use": 35.03, "gen_rate": 4.6, "speed": 4.4, "text": "There is no sexual selection the"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 23, "tree_size": 64, "t0": 0.8357, "t1": 0.26, "tft": 2.1916, "input_0": 107, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.0, "mem_use": 35.25, "gen_rate": 4.9, "speed": 4.43, "text": "Good question! There are many wa"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.0, "tree_w": 28, "tree_size": 64, "t0": 0.675, "t1": 0.24, "tft": 1.571, "input_0": 84, "input_1": 65, "min_CLP": -5.6, "draft_iters": 6.0, "mem_use": 34.54, "gen_rate": 3.2, "speed": 3.49, "text": "\\nThis is the task given to you "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 64, "t0": 3.38, "t1": 0.31, "tft": 4.8954, "input_0": 141, "input_1": 65, "min_CLP": -5.1, "draft_iters": 32.0, "mem_use": 36.83, "gen_rate": 33.0, "speed": 8.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.7, "tree_w": 28, "tree_size": 64, "t0": 0.6978, "t1": 0.26, "tft": 2.3037, "input_0": 100, "input_1": 65, "min_CLP": -5.41, "draft_iters": 5.7, "mem_use": 35.29, "gen_rate": 3.6, "speed": 3.71, "text": "\\nThe Braille alphabet is formed"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 13.6, "tree_w": 17, "tree_size": 64, "t0": 1.524, "t1": 0.252, "tft": 2.6575, "input_0": 135, "input_1": 65, "min_CLP": -5.15, "draft_iters": 14.4, "mem_use": 35.0, "gen_rate": 12.0, "speed": 6.75, "text": "If you depart on a Saturday, you"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.8, "tree_w": 23, "tree_size": 64, "t0": 0.966, "t1": 0.24, "tft": 1.5876, "input_0": 115, "input_1": 65, "min_CLP": -5.34, "draft_iters": 8.7, "mem_use": 34.54, "gen_rate": 3.6, "speed": 2.97, "text": "\\nThe essay must be well structu"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 8, "tree_size": 64, "t0": 2.265, "t1": 0.25, "tft": 1.9417, "input_0": 197, "input_1": 65, "min_CLP": -4.69, "draft_iters": 21.0, "mem_use": 34.73, "gen_rate": 21.5, "speed": 8.55, "text": "\"Sure, here's another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 49, "tree_h": 8.8, "tree_w": 23, "tree_size": 64, "t0": 1.045, "t1": 0.24, "tft": 1.6684, "input_0": 106, "input_1": 65, "min_CLP": -5.42, "draft_iters": 9.8, "mem_use": 34.53, "gen_rate": 6.1, "speed": 4.75, "text": "\\nThe \u201cHow Many?\u201d question is on"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.0, "tree_w": 25, "tree_size": 64, "t0": 0.8111, "t1": 0.3189, "tft": 5.0051, "input_0": 98, "input_1": 65, "min_CLP": -5.26, "draft_iters": 6.0, "mem_use": 36.92, "gen_rate": 3.6, "speed": 3.15, "text": "\\nDoing this will not be easy an"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 3.02, "t1": 0.24, "tft": 1.5045, "input_0": 171, "input_1": 65, "min_CLP": -5.38, "draft_iters": 32.0, "mem_use": 35.34, "gen_rate": 19.0, "speed": 5.82, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.2, "tree_w": 23, "tree_size": 64, "t0": 1.0317, "t1": 0.3583, "tft": 7.173, "input_0": 118, "input_1": 65, "min_CLP": -5.22, "draft_iters": 7.2, "mem_use": 38.06, "gen_rate": 6.0, "speed": 4.32, "text": "\\nWhat is the most difficult pro"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.12, "t1": 0.26, "tft": 2.124, "input_0": 173, "input_1": 65, "min_CLP": -5.66, "draft_iters": 32.0, "mem_use": 35.9, "gen_rate": 33.0, "speed": 9.78, "text": "\\nWould you be able to design an"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.07, "t1": 0.24, "tft": 1.7757, "input_0": 169, "input_1": 65, "min_CLP": -5.9, "draft_iters": 32.0, "mem_use": 34.58, "gen_rate": 33.0, "speed": 9.95, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 56, "tree_h": 27.0, "tree_w": 11, "tree_size": 64, "t0": 2.72, "t1": 0.24, "tft": 1.6329, "input_0": 163, "input_1": 65, "min_CLP": -5.42, "draft_iters": 27.5, "mem_use": 34.52, "gen_rate": 28.0, "speed": 9.44, "text": "\\nhow does two factor authentica"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 25, "tree_size": 64, "t0": 0.6975, "t1": 0.2425, "tft": 1.5261, "input_0": 95, "input_1": 65, "min_CLP": -5.39, "draft_iters": 6.0, "mem_use": 34.64, "gen_rate": 4.0, "speed": 4.25, "text": "\"\\nI've always hated the ending "}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.4, "tree_w": 21, "tree_size": 64, "t0": 0.9225, "t1": 0.25, "tft": 1.366, "input_0": 143, "input_1": 65, "min_CLP": -5.28, "draft_iters": 7.4, "mem_use": 34.8, "gen_rate": 4.0, "speed": 3.42, "text": "It\u2019s a Wonderful Life, The Offic"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 13.6, "tree_w": 15, "tree_size": 64, "t0": 1.666, "t1": 0.27, "tft": 2.5348, "input_0": 166, "input_1": 65, "min_CLP": -5.02, "draft_iters": 14.6, "mem_use": 35.61, "gen_rate": 9.2, "speed": 4.74, "text": "\"\\nSDR devices:\\n\\nRTL-SDR: This"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.8, "tree_w": 20, "tree_size": 64, "t0": 1.0567, "t1": 0.26, "tft": 2.1423, "input_0": 126, "input_1": 65, "min_CLP": -5.39, "draft_iters": 8.8, "mem_use": 35.17, "gen_rate": 6.5, "speed": 4.94, "text": "\\nWhat are the characteristics o"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.1, "tree_w": 26, "tree_size": 64, "t0": 0.7087, "t1": 0.24, "tft": 2.2447, "input_0": 89, "input_1": 65, "min_CLP": -5.46, "draft_iters": 6.1, "mem_use": 34.61, "gen_rate": 4.6, "speed": 4.85, "text": "\"\\nI definitely don't think that"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.5, "tree_w": 24, "tree_size": 64, "t0": 1.0625, "t1": 0.3, "tft": 5.7147, "input_0": 112, "input_1": 65, "min_CLP": -5.37, "draft_iters": 8.5, "mem_use": 36.55, "gen_rate": 4.1, "speed": 3.02, "text": "\"\\nHow can I make a menu with bu"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 22.0, "tree_w": 8, "tree_size": 64, "t0": 2.405, "t1": 0.26, "tft": 4.6074, "input_0": 178, "input_1": 65, "min_CLP": -4.62, "draft_iters": 22.5, "mem_use": 35.34, "gen_rate": 19.0, "speed": 7.14, "text": "\"Here is a reduction of the list"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.7, "tree_w": 26, "tree_size": 64, "t0": 0.683, "t1": 0.24, "tft": 1.626, "input_0": 99, "input_1": 65, "min_CLP": -5.54, "draft_iters": 5.7, "mem_use": 34.58, "gen_rate": 3.3, "speed": 3.57, "text": "\\nI would start by showing your "}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 22, "tree_size": 64, "t0": 0.895, "t1": 0.24, "tft": 2.0297, "input_0": 132, "input_1": 65, "min_CLP": -5.32, "draft_iters": 7.4, "mem_use": 34.58, "gen_rate": 4.1, "speed": 3.62, "text": "\"\\nVoting\\n\\nVoting is an integr"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 63, "tree_h": 13.4, "tree_w": 16, "tree_size": 64, "t0": 1.566, "t1": 0.26, "tft": 2.1327, "input_0": 153, "input_1": 65, "min_CLP": -5.14, "draft_iters": 14.2, "mem_use": 35.11, "gen_rate": 12.6, "speed": 6.92, "text": "Yes, I believe that I can. I bel"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 9.8, "tree_w": 23, "tree_size": 64, "t0": 1.21, "t1": 0.27, "tft": 2.8065, "input_0": 127, "input_1": 65, "min_CLP": -5.29, "draft_iters": 10.8, "mem_use": 35.63, "gen_rate": 8.8, "speed": 5.93, "text": "In Javascript, the closest you c"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.5, "tree_w": 23, "tree_size": 64, "t0": 0.7825, "t1": 0.25, "tft": 1.4706, "input_0": 109, "input_1": 65, "min_CLP": -5.33, "draft_iters": 6.5, "mem_use": 34.82, "gen_rate": 4.6, "speed": 4.49, "text": "If you are looking for a trainin"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 13.5, "tree_w": 13, "tree_size": 64, "t0": 1.5375, "t1": 0.26, "tft": 1.8942, "input_0": 137, "input_1": 65, "min_CLP": -5.06, "draft_iters": 14.2, "mem_use": 35.06, "gen_rate": 14.2, "speed": 7.94, "text": "When you make the second batch o"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 25, "tree_size": 64, "t0": 1.16, "t1": 0.24, "tft": 1.4888, "input_0": 99, "input_1": 65, "min_CLP": -5.62, "draft_iters": 11.2, "mem_use": 34.53, "gen_rate": 5.3, "speed": 3.8, "text": "\\nis javascript back end or fron"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.2, "tree_w": 20, "tree_size": 64, "t0": 1.15, "t1": 0.24, "tft": 1.4356, "input_0": 130, "input_1": 65, "min_CLP": -5.33, "draft_iters": 10.2, "mem_use": 34.52, "gen_rate": 8.0, "speed": 5.73, "text": "\\nwhat are the benefits of green"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 18, "tree_size": 64, "t0": 2.445, "t1": 0.25, "tft": 1.5555, "input_0": 163, "input_1": 65, "min_CLP": -5.12, "draft_iters": 25.0, "mem_use": 34.88, "gen_rate": 25.5, "speed": 9.46, "text": "\\nGive me a list of 10 words whe"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 30.5, "tree_w": 7, "tree_size": 64, "t0": 3.05, "t1": 0.24, "tft": 3.0705, "input_0": 204, "input_1": 65, "min_CLP": -4.89, "draft_iters": 31.0, "mem_use": 34.59, "gen_rate": 16.0, "speed": 4.87, "text": "[\\\\INST]\\n[INST]\\n[INST]\\n[INST]"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 3.13, "t1": 0.24, "tft": 1.7099, "input_0": 199, "input_1": 65, "min_CLP": -5.48, "draft_iters": 32.0, "mem_use": 34.58, "gen_rate": 33.0, "speed": 9.77, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.01, "t1": 0.24, "tft": 1.7633, "input_0": 144, "input_1": 65, "min_CLP": -5.48, "draft_iters": 32.0, "mem_use": 34.57, "gen_rate": 33.0, "speed": 10.15, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 20.5, "tree_w": 12, "tree_size": 64, "t0": 2.385, "t1": 0.32, "tft": 5.1665, "input_0": 149, "input_1": 65, "min_CLP": -5.78, "draft_iters": 21.0, "mem_use": 37.0, "gen_rate": 20.0, "speed": 7.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 8, "tree_size": 64, "t0": 3.18, "t1": 0.275, "tft": 3.3473, "input_0": 163, "input_1": 65, "min_CLP": -4.86, "draft_iters": 31.0, "mem_use": 35.72, "gen_rate": 31.5, "speed": 9.12, "text": "\"Wiles' proof of Fermat's Last T"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.5, "tree_w": 25, "tree_size": 64, "t0": 0.9163, "t1": 0.2525, "tft": 2.0453, "input_0": 125, "input_1": 65, "min_CLP": -5.44, "draft_iters": 7.5, "mem_use": 34.97, "gen_rate": 4.9, "speed": 4.17, "text": "You can use the formula below to"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.5, "tree_w": 14, "tree_size": 64, "t0": 1.7975, "t1": 0.2575, "tft": 2.1466, "input_0": 147, "input_1": 65, "min_CLP": -4.98, "draft_iters": 17.5, "mem_use": 35.08, "gen_rate": 8.2, "speed": 4.02, "text": "\\nPolar bears have adapted to th"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.2, "tree_w": 22, "tree_size": 64, "t0": 0.785, "t1": 0.27, "tft": 2.6606, "input_0": 110, "input_1": 65, "min_CLP": -5.19, "draft_iters": 6.2, "mem_use": 35.62, "gen_rate": 4.0, "speed": 3.79, "text": "\\nLemon wedges are to serve with"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.0, "tree_w": 25, "tree_size": 64, "t0": 0.88, "t1": 0.24, "tft": 3.0596, "input_0": 100, "input_1": 65, "min_CLP": -5.48, "draft_iters": 8.0, "mem_use": 34.71, "gen_rate": 4.1, "speed": 3.67, "text": "\\n[SYS] <<SYS>>\\nAfter you have "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 19, "tree_size": 64, "t0": 0.9633, "t1": 0.24, "tft": 1.7163, "input_0": 117, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.5, "mem_use": 34.61, "gen_rate": 5.3, "speed": 4.42, "text": "\"There is no meaning, but there "}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.2, "tree_w": 18, "tree_size": 64, "t0": 1.4817, "t1": 0.2417, "tft": 1.5878, "input_0": 138, "input_1": 65, "min_CLP": -5.2, "draft_iters": 14.0, "mem_use": 34.54, "gen_rate": 5.8, "speed": 3.39, "text": "\\n[INST] <<SYS>>\\nIn this lesson"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 8.0, "tree_w": 19, "tree_size": 64, "t0": 1.0786, "t1": 0.26, "tft": 2.2106, "input_0": 128, "input_1": 65, "min_CLP": -5.24, "draft_iters": 9.0, "mem_use": 35.28, "gen_rate": 6.1, "speed": 4.58, "text": "Yes, there are. These include th"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 20, "tree_size": 64, "t0": 0.865, "t1": 0.26, "tft": 2.3315, "input_0": 112, "input_1": 65, "min_CLP": -5.2, "draft_iters": 7.1, "mem_use": 35.08, "gen_rate": 4.2, "speed": 3.79, "text": "\"Dyson's work has been controver"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 6, "tree_size": 64, "t0": 3.255, "t1": 0.24, "tft": 1.4031, "input_0": 248, "input_1": 65, "min_CLP": -5.69, "draft_iters": 31.5, "mem_use": 34.51, "gen_rate": 32.0, "speed": 9.15, "text": "\\ncan you write code? [\\\\INST]\\n"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.935, "t1": 0.25, "tft": 1.7258, "input_0": 116, "input_1": 65, "min_CLP": -5.09, "draft_iters": 8.0, "mem_use": 34.85, "gen_rate": 6.0, "speed": 5.05, "text": "\\nWhat is your favorite food? [\\"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.9, "tree_w": 25, "tree_size": 64, "t0": 0.9086, "t1": 0.26, "tft": 2.2398, "input_0": 112, "input_1": 65, "min_CLP": -5.73, "draft_iters": 7.9, "mem_use": 35.18, "gen_rate": 4.7, "speed": 4.04, "text": "\\nWhat is a good way to build a "}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 16.0, "tree_w": 16, "tree_size": 64, "t0": 1.7267, "t1": 0.25, "tft": 2.0673, "input_0": 129, "input_1": 65, "min_CLP": -5.44, "draft_iters": 17.0, "mem_use": 34.74, "gen_rate": 7.8, "speed": 3.97, "text": "1.          By taking action to "}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 25, "tree_size": 64, "t0": 0.85, "t1": 0.24, "tft": 2.1257, "input_0": 105, "input_1": 65, "min_CLP": -5.05, "draft_iters": 7.6, "mem_use": 34.57, "gen_rate": 4.6, "speed": 4.18, "text": "\\n\u6709\u6c92\u6709\u54ea\u4e9b\u8a71\u984c,\u5047\u5982\u4f60\u4e0d\u77e5\u9053\ufffd"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 24, "tree_size": 64, "t0": 0.7738, "t1": 0.25, "tft": 1.8282, "input_0": 108, "input_1": 65, "min_CLP": -5.39, "draft_iters": 6.5, "mem_use": 34.82, "gen_rate": 4.4, "speed": 4.27, "text": "The comparison can be done in ma"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 11, "tree_size": 64, "t0": 2.435, "t1": 0.26, "tft": 3.2958, "input_0": 175, "input_1": 65, "min_CLP": -5.1, "draft_iters": 23.5, "mem_use": 35.1, "gen_rate": 24.0, "speed": 8.92, "text": "[INST] how to find the biggest s"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 20.5, "tree_w": 12, "tree_size": 64, "t0": 2.2025, "t1": 0.25, "tft": 2.0983, "input_0": 163, "input_1": 65, "min_CLP": -5.44, "draft_iters": 21.2, "mem_use": 34.92, "gen_rate": 12.8, "speed": 5.2, "text": "The URL encoded string is as fol"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.8, "tree_w": 16, "tree_size": 64, "t0": 1.4717, "t1": 0.28, "tft": 3.9517, "input_0": 133, "input_1": 65, "min_CLP": -5.15, "draft_iters": 12.8, "mem_use": 35.92, "gen_rate": 5.3, "speed": 3.05, "text": "\\nHow can I use the principle of"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.6, "tree_w": 21, "tree_size": 64, "t0": 1.05, "t1": 0.3125, "tft": 4.7352, "input_0": 140, "input_1": 65, "min_CLP": -4.97, "draft_iters": 7.6, "mem_use": 36.85, "gen_rate": 4.4, "speed": 3.21, "text": "There are a variety of vegan and"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 19, "tree_size": 64, "t0": 1.0571, "t1": 0.26, "tft": 2.0381, "input_0": 135, "input_1": 65, "min_CLP": -5.18, "draft_iters": 9.0, "mem_use": 35.3, "gen_rate": 5.1, "speed": 3.9, "text": "\"You don't need to beat your opp"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 25, "tree_size": 64, "t0": 1.0171, "t1": 0.2686, "tft": 3.2676, "input_0": 113, "input_1": 65, "min_CLP": -5.36, "draft_iters": 9.0, "mem_use": 35.44, "gen_rate": 5.1, "speed": 4.01, "text": "\\nHow do we train AI assistants?"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.1, "tree_w": 21, "tree_size": 64, "t0": 0.9586, "t1": 0.24, "tft": 1.6329, "input_0": 126, "input_1": 65, "min_CLP": -5.28, "draft_iters": 8.1, "mem_use": 34.64, "gen_rate": 4.6, "speed": 3.8, "text": "\\nThe difference between sets an"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 19, "tree_size": 64, "t0": 0.9314, "t1": 0.2571, "tft": 3.8339, "input_0": 131, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.7, "mem_use": 35.11, "gen_rate": 4.7, "speed": 3.97, "text": "Black Friday is an American holi"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.07, "t1": 0.24, "tft": 1.6639, "input_0": 201, "input_1": 65, "min_CLP": -5.72, "draft_iters": 32.0, "mem_use": 34.61, "gen_rate": 33.0, "speed": 9.96, "text": "\\nHi, can you tell me a story in"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 62, "tree_h": 25.0, "tree_w": 9, "tree_size": 64, "t0": 2.6867, "t1": 0.24, "tft": 1.7783, "input_0": 217, "input_1": 65, "min_CLP": -5.46, "draft_iters": 25.7, "mem_use": 34.55, "gen_rate": 20.7, "speed": 7.06, "text": "\\n[inst]\\n\\n[INST] <<SYS>>\\nYou "}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 2.95, "t1": 0.24, "tft": 1.7274, "input_0": 125, "input_1": 65, "min_CLP": -4.9, "draft_iters": 32.0, "mem_use": 34.55, "gen_rate": 33.0, "speed": 10.33, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.7, "tree_w": 24, "tree_size": 64, "t0": 0.9422, "t1": 0.24, "tft": 3.3258, "input_0": 95, "input_1": 65, "min_CLP": -5.67, "draft_iters": 8.7, "mem_use": 34.53, "gen_rate": 3.7, "speed": 3.1, "text": "\\nUse the runes to answer questi"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.0, "tree_w": 19, "tree_size": 64, "t0": 1.345, "t1": 0.26, "tft": 2.9294, "input_0": 139, "input_1": 65, "min_CLP": -5.2, "draft_iters": 11.8, "mem_use": 35.17, "gen_rate": 5.5, "speed": 3.42, "text": "\"\\nWrite me a program that takes"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 10.0, "tree_w": 18, "tree_size": 64, "t0": 1.226, "t1": 0.248, "tft": 1.9404, "input_0": 134, "input_1": 65, "min_CLP": -5.24, "draft_iters": 11.0, "mem_use": 34.74, "gen_rate": 9.2, "speed": 6.25, "text": "npm install tailwind-cli --save\\"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 24, "tree_size": 64, "t0": 0.9725, "t1": 0.33, "tft": 5.4674, "input_0": 115, "input_1": 65, "min_CLP": -5.33, "draft_iters": 7.2, "mem_use": 37.3, "gen_rate": 4.1, "speed": 3.17, "text": "Sexual dimorphism is a general o"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.7, "tree_w": 27, "tree_size": 64, "t0": 0.6727, "t1": 0.2491, "tft": 1.4553, "input_0": 97, "input_1": 65, "min_CLP": -5.63, "draft_iters": 5.7, "mem_use": 35.5, "gen_rate": 2.9, "speed": 3.16, "text": "The LLM system is very complicat"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 29.5, "tree_w": 10, "tree_size": 64, "t0": 2.955, "t1": 0.245, "tft": 1.4227, "input_0": 169, "input_1": 65, "min_CLP": -5.7, "draft_iters": 30.0, "mem_use": 34.56, "gen_rate": 29.0, "speed": 9.06, "text": "\"I'm a broke college student liv"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.1, "tree_w": 25, "tree_size": 64, "t0": 0.8178, "t1": 0.2444, "tft": 1.812, "input_0": 98, "input_1": 65, "min_CLP": -5.4, "draft_iters": 7.1, "mem_use": 34.67, "gen_rate": 3.9, "speed": 3.66, "text": "\\n1. She was born on January 1, "}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.8, "tree_w": 22, "tree_size": 64, "t0": 0.9211, "t1": 0.2689, "tft": 2.8759, "input_0": 113, "input_1": 65, "min_CLP": -5.6, "draft_iters": 7.8, "mem_use": 35.44, "gen_rate": 3.8, "speed": 3.18, "text": "\\nCoding the snake game in C is "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 17, "tree_size": 64, "t0": 1.292, "t1": 0.24, "tft": 1.6485, "input_0": 145, "input_1": 65, "min_CLP": -5.39, "draft_iters": 11.2, "mem_use": 34.65, "gen_rate": 7.4, "speed": 4.83, "text": "I am, but I am not currently thi"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 27, "tree_size": 64, "t0": 0.71, "t1": 0.2412, "tft": 1.8335, "input_0": 101, "input_1": 65, "min_CLP": -5.36, "draft_iters": 6.0, "mem_use": 34.6, "gen_rate": 4.2, "speed": 4.46, "text": "\"\\nWhat is the most important th"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 64, "t0": 3.16, "t1": 0.24, "tft": 1.6429, "input_0": 233, "input_1": 65, "min_CLP": -5.05, "draft_iters": 32.0, "mem_use": 34.51, "gen_rate": 33.0, "speed": 9.71, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 16.0, "tree_w": 18, "tree_size": 64, "t0": 1.85, "t1": 0.27, "tft": 3.2578, "input_0": 168, "input_1": 65, "min_CLP": -5.28, "draft_iters": 17.0, "mem_use": 35.68, "gen_rate": 14.3, "speed": 6.76, "text": "\"The Quenya version of 'I love y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.5, "tree_w": 26, "tree_size": 64, "t0": 0.643, "t1": 0.24, "tft": 1.5699, "input_0": 88, "input_1": 65, "min_CLP": -5.42, "draft_iters": 5.5, "mem_use": 34.76, "gen_rate": 3.4, "speed": 3.84, "text": "\\nI\\'m sure we all had one of th"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 16, "tree_size": 64, "t0": 1.0833, "t1": 0.25, "tft": 1.7309, "input_0": 141, "input_1": 65, "min_CLP": -5.08, "draft_iters": 9.0, "mem_use": 34.83, "gen_rate": 6.0, "speed": 4.51, "text": "No. The Second Amendment does no"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 25, "tree_size": 64, "t0": 1.205, "t1": 0.24, "tft": 1.4976, "input_0": 96, "input_1": 65, "min_CLP": -5.56, "draft_iters": 12.0, "mem_use": 34.55, "gen_rate": 8.0, "speed": 5.53, "text": "\\nThe previous question has been"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 3.29, "t1": 0.25, "tft": 1.8137, "input_0": 259, "input_1": 65, "min_CLP": -4.79, "draft_iters": 32.0, "mem_use": 34.77, "gen_rate": 33.0, "speed": 9.32, "text": "\\nI want you to act as a babysit"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 9.1, "tree_w": 16, "tree_size": 64, "t0": 1.1814, "t1": 0.2414, "tft": 1.6003, "input_0": 149, "input_1": 65, "min_CLP": -4.82, "draft_iters": 10.1, "mem_use": 34.61, "gen_rate": 6.1, "speed": 4.31, "text": "Melbourne was the capital from 1"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.9, "tree_w": 23, "tree_size": 64, "t0": 0.9871, "t1": 0.2457, "tft": 1.6335, "input_0": 116, "input_1": 65, "min_CLP": -5.18, "draft_iters": 8.9, "mem_use": 34.69, "gen_rate": 4.6, "speed": 3.71, "text": "\"I'm sorry to hear about your gr"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 20, "tree_size": 64, "t0": 1.0914, "t1": 0.28, "tft": 3.6443, "input_0": 112, "input_1": 65, "min_CLP": -5.0, "draft_iters": 9.3, "mem_use": 35.86, "gen_rate": 4.7, "speed": 3.44, "text": "[\\\\INST] What are the core value"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 2.98, "t1": 0.24, "tft": 1.7986, "input_0": 139, "input_1": 65, "min_CLP": -5.57, "draft_iters": 32.0, "mem_use": 34.83, "gen_rate": 33.0, "speed": 10.22, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 6.4, "tree_w": 21, "tree_size": 64, "t0": 0.9029, "t1": 0.26, "tft": 2.5514, "input_0": 120, "input_1": 65, "min_CLP": -5.22, "draft_iters": 7.4, "mem_use": 35.27, "gen_rate": 5.6, "speed": 4.79, "text": "\\nA vector normalizes to a unit "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.8, "tree_w": 26, "tree_size": 64, "t0": 0.6744, "t1": 0.24, "tft": 1.4229, "input_0": 86, "input_1": 65, "min_CLP": -5.51, "draft_iters": 5.8, "mem_use": 34.55, "gen_rate": 3.7, "speed": 4.0, "text": "\\nThe problem with using a symme"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 26.0, "tree_w": 12, "tree_size": 64, "t0": 2.605, "t1": 0.24, "tft": 1.6722, "input_0": 142, "input_1": 65, "min_CLP": -5.27, "draft_iters": 27.0, "mem_use": 34.57, "gen_rate": 16.5, "speed": 5.8, "text": "\\n[SYS] <<<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.4, "tree_w": 21, "tree_size": 64, "t0": 1.0486, "t1": 0.24, "tft": 1.6273, "input_0": 115, "input_1": 65, "min_CLP": -5.35, "draft_iters": 9.4, "mem_use": 34.55, "gen_rate": 4.9, "speed": 3.76, "text": "\\nA:\\n\\nIn day to day life you w"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 1.12, "t1": 0.25, "tft": 1.7838, "input_0": 136, "input_1": 65, "min_CLP": -5.09, "draft_iters": 9.6, "mem_use": 34.84, "gen_rate": 7.0, "speed": 5.11, "text": "No. The variance is the sum of s"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.4, "tree_w": 26, "tree_size": 64, "t0": 0.7512, "t1": 0.2525, "tft": 2.1399, "input_0": 100, "input_1": 65, "min_CLP": -5.41, "draft_iters": 6.4, "mem_use": 34.99, "gen_rate": 4.5, "speed": 4.48, "text": "\"\\nI'm not sure what I'm suppose"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.1, "tree_w": 22, "tree_size": 64, "t0": 0.85, "t1": 0.25, "tft": 1.8701, "input_0": 112, "input_1": 65, "min_CLP": -5.16, "draft_iters": 7.1, "mem_use": 34.86, "gen_rate": 4.0, "speed": 3.63, "text": "You can see the best starry sky "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 3.16, "t1": 0.24, "tft": 1.6238, "input_0": 218, "input_1": 65, "min_CLP": -5.3, "draft_iters": 32.0, "mem_use": 34.54, "gen_rate": 33.0, "speed": 9.7, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.8, "tree_w": 21, "tree_size": 64, "t0": 0.8056, "t1": 0.2489, "tft": 1.3179, "input_0": 104, "input_1": 65, "min_CLP": -5.05, "draft_iters": 6.8, "mem_use": 34.8, "gen_rate": 3.8, "speed": 3.59, "text": "It is impossible to break an egg"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 24, "tree_size": 64, "t0": 0.934, "t1": 0.248, "tft": 1.7926, "input_0": 106, "input_1": 65, "min_CLP": -5.1, "draft_iters": 8.4, "mem_use": 34.77, "gen_rate": 7.0, "speed": 5.92, "text": "A person can cope with stress fr"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 17, "tree_size": 64, "t0": 1.3317, "t1": 0.3, "tft": 4.2872, "input_0": 147, "input_1": 65, "min_CLP": -5.0, "draft_iters": 11.0, "mem_use": 36.35, "gen_rate": 5.5, "speed": 3.38, "text": "1. Project management tools: Mic"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 1.2317, "t1": 0.27, "tft": 2.9363, "input_0": 137, "input_1": 65, "min_CLP": -4.76, "draft_iters": 10.5, "mem_use": 35.68, "gen_rate": 5.7, "speed": 3.76, "text": "\\nYou can build your own PC for "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.4, "tree_w": 22, "tree_size": 64, "t0": 0.845, "t1": 0.24, "tft": 1.6711, "input_0": 109, "input_1": 65, "min_CLP": -5.47, "draft_iters": 7.4, "mem_use": 34.75, "gen_rate": 4.4, "speed": 4.02, "text": "\\nAnswer:\\n\\nIt is 12 days until"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 13.7, "tree_w": 23, "tree_size": 64, "t0": 1.4467, "t1": 0.24, "tft": 3.119, "input_0": 112, "input_1": 65, "min_CLP": -5.53, "draft_iters": 14.3, "mem_use": 34.64, "gen_rate": 13.7, "speed": 8.09, "text": "\"\\nI'm a very helpful, respectfu"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 27, "tree_size": 64, "t0": 1.1143, "t1": 0.4014, "tft": 9.6238, "input_0": 114, "input_1": 65, "min_CLP": -5.43, "draft_iters": 7.4, "mem_use": 39.43, "gen_rate": 5.0, "speed": 3.29, "text": "\"The _physics_process function i"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.2, "tree_w": 20, "tree_size": 64, "t0": 0.9467, "t1": 0.25, "tft": 1.8317, "input_0": 115, "input_1": 65, "min_CLP": -5.25, "draft_iters": 8.2, "mem_use": 36.54, "gen_rate": 4.1, "speed": 3.45, "text": "\"Yes, you can decorate a method "}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.9017, "t1": 0.24, "tft": 1.7203, "input_0": 105, "input_1": 65, "min_CLP": -5.27, "draft_iters": 8.0, "mem_use": 34.6, "gen_rate": 6.0, "speed": 5.24, "text": "[INST] But I would like to know "}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.7, "tree_w": 22, "tree_size": 64, "t0": 0.92, "t1": 0.24, "tft": 1.7794, "input_0": 130, "input_1": 65, "min_CLP": -5.21, "draft_iters": 7.7, "mem_use": 34.59, "gen_rate": 5.5, "speed": 4.73, "text": "\\nWyoming Statute:\\n18-5-101. Pu"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.4, "tree_w": 25, "tree_size": 64, "t0": 0.6989, "t1": 0.28, "tft": 3.5281, "input_0": 96, "input_1": 65, "min_CLP": -5.36, "draft_iters": 5.4, "mem_use": 35.89, "gen_rate": 3.9, "speed": 3.97, "text": "\"First off, I'm a real person. I"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.8, "tree_w": 11, "tree_size": 64, "t0": 1.68, "t1": 0.25, "tft": 2.1024, "input_0": 206, "input_1": 65, "min_CLP": -4.43, "draft_iters": 14.8, "mem_use": 34.84, "gen_rate": 9.5, "speed": 4.92, "text": "Sure, here are some of the best "}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.5, "tree_w": 21, "tree_size": 64, "t0": 1.1967, "t1": 0.25, "tft": 1.6379, "input_0": 143, "input_1": 65, "min_CLP": -5.21, "draft_iters": 10.5, "mem_use": 34.87, "gen_rate": 5.5, "speed": 3.8, "text": "\\nWhat is the airspeed velocity "}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 64, "t0": 2.9, "t1": 0.25, "tft": 1.6299, "input_0": 109, "input_1": 65, "min_CLP": -5.37, "draft_iters": 32.0, "mem_use": 34.69, "gen_rate": 33.0, "speed": 10.5, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 25, "tree_size": 64, "t0": 0.8971, "t1": 0.25, "tft": 1.4724, "input_0": 106, "input_1": 65, "min_CLP": -5.88, "draft_iters": 8.0, "mem_use": 34.87, "gen_rate": 5.0, "speed": 4.35, "text": "Generative bias dreams,\\nData it"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 28, "tree_size": 64, "t0": 0.7257, "t1": 0.2471, "tft": 1.8508, "input_0": 93, "input_1": 65, "min_CLP": -5.32, "draft_iters": 6.3, "mem_use": 34.7, "gen_rate": 4.9, "speed": 5.0, "text": "\"\\nHow do you make a cat disappe"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.4, "tree_w": 21, "tree_size": 64, "t0": 0.9929, "t1": 0.27, "tft": 2.8091, "input_0": 115, "input_1": 65, "min_CLP": -5.19, "draft_iters": 8.4, "mem_use": 35.69, "gen_rate": 4.9, "speed": 3.83, "text": "\\nYou should not discuss your dr"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 18.0, "tree_w": 8, "tree_size": 64, "t0": 2.1133, "t1": 0.2433, "tft": 2.3501, "input_0": 208, "input_1": 65, "min_CLP": -4.82, "draft_iters": 19.0, "mem_use": 34.75, "gen_rate": 13.0, "speed": 5.51, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 18.0, "tree_w": 15, "tree_size": 64, "t0": 1.986, "t1": 0.24, "tft": 1.5898, "input_0": 165, "input_1": 65, "min_CLP": -4.96, "draft_iters": 19.0, "mem_use": 34.6, "gen_rate": 9.4, "speed": 4.22, "text": "I can do a conversation in Spani"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 8.6, "tree_w": 21, "tree_size": 64, "t0": 1.0214, "t1": 0.24, "tft": 1.6788, "input_0": 105, "input_1": 65, "min_CLP": -5.38, "draft_iters": 9.6, "mem_use": 34.58, "gen_rate": 5.7, "speed": 4.52, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 3.66, "t1": 0.34, "tft": 6.2734, "input_0": 176, "input_1": 65, "min_CLP": -4.81, "draft_iters": 32.0, "mem_use": 37.53, "gen_rate": 33.0, "speed": 8.26, "text": "\"Sure, here's an example code sn"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 58, "tree_h": 11.8, "tree_w": 15, "tree_size": 64, "t0": 1.4267, "t1": 0.2683, "tft": 2.5675, "input_0": 149, "input_1": 65, "min_CLP": -5.35, "draft_iters": 12.7, "mem_use": 35.64, "gen_rate": 9.7, "speed": 5.71, "text": "\\nIf you have any questions, ple"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 27, "tree_size": 64, "t0": 0.8175, "t1": 0.25, "tft": 1.5459, "input_0": 126, "input_1": 65, "min_CLP": -5.42, "draft_iters": 6.6, "mem_use": 34.79, "gen_rate": 4.0, "speed": 3.75, "text": "AI assistants will never replace"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 20, "tree_size": 64, "t0": 0.9414, "t1": 0.2771, "tft": 2.8892, "input_0": 125, "input_1": 65, "min_CLP": -5.12, "draft_iters": 7.9, "mem_use": 35.75, "gen_rate": 4.6, "speed": 3.75, "text": "You can breed animals in Minecra"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 12.8, "tree_w": 14, "tree_size": 64, "t0": 1.6417, "t1": 0.29, "tft": 4.3277, "input_0": 169, "input_1": 65, "min_CLP": -4.8, "draft_iters": 13.8, "mem_use": 36.12, "gen_rate": 8.0, "speed": 4.14, "text": "Wie viel Aussto\u00df von CO2 verursa"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 17.3, "tree_w": 12, "tree_size": 64, "t0": 1.9967, "t1": 0.27, "tft": 2.8952, "input_0": 165, "input_1": 65, "min_CLP": -5.29, "draft_iters": 18.0, "mem_use": 35.53, "gen_rate": 16.7, "speed": 7.35, "text": "[INST] Thanks. [\\\\INST]\\n[INST] "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.8, "tree_w": 24, "tree_size": 64, "t0": 0.8037, "t1": 0.25, "tft": 2.1583, "input_0": 102, "input_1": 65, "min_CLP": -5.26, "draft_iters": 6.8, "mem_use": 34.93, "gen_rate": 4.0, "speed": 3.79, "text": "You could ask the people who fou"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.3, "tree_w": 24, "tree_size": 64, "t0": 0.7667, "t1": 0.2544, "tft": 1.9341, "input_0": 104, "input_1": 65, "min_CLP": -5.35, "draft_iters": 6.3, "mem_use": 35.04, "gen_rate": 4.2, "speed": 4.13, "text": "You know what self-attention is."}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 29.5, "tree_w": 9, "tree_size": 64, "t0": 2.9775, "t1": 0.2425, "tft": 2.077, "input_0": 207, "input_1": 65, "min_CLP": -4.95, "draft_iters": 30.0, "mem_use": 34.61, "gen_rate": 14.8, "speed": 4.58, "text": "\\n<</SYS>\\n\\nWrite a function in"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 22, "tree_size": 64, "t0": 0.9243, "t1": 0.26, "tft": 3.3741, "input_0": 120, "input_1": 65, "min_CLP": -5.15, "draft_iters": 7.7, "mem_use": 35.25, "gen_rate": 4.7, "speed": 3.97, "text": "It is illegal to be naked in pub"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 25, "tree_size": 64, "t0": 2.85, "t1": 0.25, "tft": 1.7062, "input_0": 101, "input_1": 65, "min_CLP": -5.45, "draft_iters": 32.0, "mem_use": 34.81, "gen_rate": 33.0, "speed": 10.65, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.9, "tree_w": 21, "tree_size": 64, "t0": 0.955, "t1": 0.26, "tft": 2.3242, "input_0": 131, "input_1": 65, "min_CLP": -5.14, "draft_iters": 7.9, "mem_use": 35.27, "gen_rate": 4.2, "speed": 3.49, "text": "The ideal consistency is a semi-"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 3.24, "t1": 0.25, "tft": 3.5398, "input_0": 181, "input_1": 65, "min_CLP": -5.54, "draft_iters": 32.0, "mem_use": 34.93, "gen_rate": 33.0, "speed": 9.44, "text": "The answer would depend on the d"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 62, "tree_h": 9.0, "tree_w": 23, "tree_size": 64, "t0": 1.0862, "t1": 0.2412, "tft": 1.3764, "input_0": 114, "input_1": 65, "min_CLP": -5.49, "draft_iters": 9.9, "mem_use": 34.6, "gen_rate": 7.8, "speed": 5.83, "text": "\\nDice que n\u00e3o vai usar nenhum n"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 0.972, "t1": 0.25, "tft": 2.438, "input_0": 122, "input_1": 65, "min_CLP": -5.21, "draft_iters": 8.4, "mem_use": 34.77, "gen_rate": 6.4, "speed": 5.25, "text": "The declaration was significant "}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 23.3, "tree_w": 5, "tree_size": 64, "t0": 2.88, "t1": 0.26, "tft": 4.1901, "input_0": 280, "input_1": 65, "min_CLP": -3.92, "draft_iters": 24.3, "mem_use": 35.33, "gen_rate": 12.0, "speed": 3.82, "text": "1. \u00abBorn to Run\u00bb, Bruce Springst"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.2, "tree_w": 20, "tree_size": 64, "t0": 1.0325, "t1": 0.24, "tft": 2.2709, "input_0": 111, "input_1": 65, "min_CLP": -5.37, "draft_iters": 9.2, "mem_use": 34.62, "gen_rate": 4.8, "speed": 3.73, "text": "\\nPlease copy and paste this tab"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 16.3, "tree_w": 14, "tree_size": 64, "t0": 1.865, "t1": 0.25, "tft": 2.4456, "input_0": 179, "input_1": 65, "min_CLP": -5.03, "draft_iters": 17.3, "mem_use": 34.85, "gen_rate": 5.5, "speed": 2.6, "text": "Whoops, thanks for pointing that"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.8, "tree_w": 19, "tree_size": 64, "t0": 1.3067, "t1": 0.2567, "tft": 1.6427, "input_0": 126, "input_1": 65, "min_CLP": -5.2, "draft_iters": 11.8, "mem_use": 35.03, "gen_rate": 5.5, "speed": 3.52, "text": "A wish from the heart is a wish "}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.5, "tree_w": 15, "tree_size": 64, "t0": 1.3967, "t1": 0.2683, "tft": 3.1013, "input_0": 136, "input_1": 65, "min_CLP": -5.25, "draft_iters": 12.5, "mem_use": 35.45, "gen_rate": 5.5, "speed": 3.31, "text": "[INST] I would like to build a s"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 15, "tree_size": 64, "t0": 1.232, "t1": 0.244, "tft": 1.9967, "input_0": 157, "input_1": 65, "min_CLP": -5.0, "draft_iters": 10.4, "mem_use": 34.65, "gen_rate": 6.6, "speed": 4.47, "text": "Frank-Walter Steinmeier is the 1"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 64, "t0": 3.02, "t1": 0.24, "tft": 1.6425, "input_0": 142, "input_1": 65, "min_CLP": -5.39, "draft_iters": 32.0, "mem_use": 34.6, "gen_rate": 33.0, "speed": 10.13, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.4, "tree_w": 26, "tree_size": 64, "t0": 0.9943, "t1": 0.3086, "tft": 4.4838, "input_0": 96, "input_1": 65, "min_CLP": -5.32, "draft_iters": 8.4, "mem_use": 36.64, "gen_rate": 5.4, "speed": 4.18, "text": "\"\\nI will even share some of my "}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 60, "tree_h": 23.8, "tree_w": 13, "tree_size": 64, "t0": 2.385, "t1": 0.24, "tft": 1.4192, "input_0": 151, "input_1": 65, "min_CLP": -5.42, "draft_iters": 24.5, "mem_use": 35.2, "gen_rate": 15.0, "speed": 5.71, "text": "\"\\nWhy don't people like the man"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 18, "tree_h": 7.5, "tree_w": 26, "tree_size": 64, "t0": 0.915, "t1": 0.24, "tft": 3.6732, "input_0": 98, "input_1": 65, "min_CLP": -5.55, "draft_iters": 8.5, "mem_use": 34.52, "gen_rate": 3.0, "speed": 2.59, "text": "\\n* Ask the question\\n* Answer t"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 3.54, "t1": 0.32, "tft": 7.6592, "input_0": 184, "input_1": 65, "min_CLP": -5.25, "draft_iters": 32.0, "mem_use": 37.08, "gen_rate": 33.0, "speed": 8.56, "text": "\\nwrite code that imitates a fak"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.8925, "t1": 0.27, "tft": 2.51, "input_0": 124, "input_1": 65, "min_CLP": -5.11, "draft_iters": 7.1, "mem_use": 35.56, "gen_rate": 4.5, "speed": 3.87, "text": "\"\u2022 If you've already formed a ha"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.4, "tree_w": 25, "tree_size": 64, "t0": 0.7825, "t1": 0.26, "tft": 1.9318, "input_0": 107, "input_1": 65, "min_CLP": -5.22, "draft_iters": 6.4, "mem_use": 35.16, "gen_rate": 4.1, "speed": 3.96, "text": "\"\\nThe problem is that we don't "}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 22.2, "tree_w": 9, "tree_size": 64, "t0": 2.49, "t1": 0.2425, "tft": 1.8355, "input_0": 218, "input_1": 65, "min_CLP": -4.95, "draft_iters": 23.2, "mem_use": 34.62, "gen_rate": 11.5, "speed": 4.2, "text": "\"\\nWhat's the current date? [\\\\I"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 9.3, "tree_w": 18, "tree_size": 64, "t0": 1.1267, "t1": 0.245, "tft": 1.8307, "input_0": 114, "input_1": 65, "min_CLP": -5.24, "draft_iters": 10.3, "mem_use": 34.62, "gen_rate": 7.2, "speed": 5.22, "text": "\"\\nWhat is the meaning of the ga"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 23.0, "tree_w": 5, "tree_size": 64, "t0": 2.6, "t1": 0.26, "tft": 2.477, "input_0": 210, "input_1": 65, "min_CLP": -5.39, "draft_iters": 24.0, "mem_use": 35.1, "gen_rate": 13.7, "speed": 4.78, "text": "\"[INST] What's the current date?"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.2, "tree_w": 22, "tree_size": 64, "t0": 1.0463, "t1": 0.27, "tft": 2.5605, "input_0": 108, "input_1": 65, "min_CLP": -5.31, "draft_iters": 9.2, "mem_use": 35.63, "gen_rate": 4.0, "speed": 3.03, "text": "\\nAnswer:\\n\\nThe easiest way to "}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.8, "tree_w": 24, "tree_size": 64, "t0": 0.7833, "t1": 0.2522, "tft": 2.3348, "input_0": 97, "input_1": 65, "min_CLP": -5.41, "draft_iters": 6.8, "mem_use": 35.01, "gen_rate": 4.0, "speed": 3.86, "text": "\"\\nI have a question about [\\\\IN"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 8, "tree_size": 64, "t0": 2.705, "t1": 0.26, "tft": 2.9094, "input_0": 218, "input_1": 65, "min_CLP": -5.82, "draft_iters": 25.0, "mem_use": 35.11, "gen_rate": 25.5, "speed": 8.6, "text": "\\n<SYS>\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 20, "tree_size": 64, "t0": 1.1917, "t1": 0.25, "tft": 1.7836, "input_0": 118, "input_1": 65, "min_CLP": -5.18, "draft_iters": 11.2, "mem_use": 34.75, "gen_rate": 5.3, "speed": 3.71, "text": "The answer is the same as above."}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.1, "tree_w": 19, "tree_size": 64, "t0": 0.9529, "t1": 0.25, "tft": 1.9342, "input_0": 121, "input_1": 65, "min_CLP": -4.97, "draft_iters": 8.1, "mem_use": 34.75, "gen_rate": 5.1, "speed": 4.28, "text": "Tenants are superior to their la"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 8.0, "tree_w": 21, "tree_size": 64, "t0": 1.0557, "t1": 0.2686, "tft": 2.5082, "input_0": 119, "input_1": 65, "min_CLP": -5.24, "draft_iters": 9.0, "mem_use": 35.45, "gen_rate": 6.0, "speed": 4.54, "text": "\\nHow do I find the name of the "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.7, "tree_w": 27, "tree_size": 64, "t0": 0.7144, "t1": 0.2667, "tft": 2.5235, "input_0": 101, "input_1": 65, "min_CLP": -5.46, "draft_iters": 5.7, "mem_use": 35.41, "gen_rate": 3.7, "speed": 3.74, "text": "Open Assistant is trained with d"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 23, "tree_size": 64, "t0": 1.0529, "t1": 0.29, "tft": 4.0337, "input_0": 110, "input_1": 65, "min_CLP": -5.26, "draft_iters": 9.0, "mem_use": 36.12, "gen_rate": 4.6, "speed": 3.4, "text": "\"\\nHow to make a great pot roast"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.5, "tree_w": 13, "tree_size": 64, "t0": 1.1133, "t1": 0.24, "tft": 1.8177, "input_0": 133, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.5, "mem_use": 34.95, "gen_rate": 6.2, "speed": 4.55, "text": "\\nWho is the President of German"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.8, "tree_w": 11, "tree_size": 64, "t0": 1.7125, "t1": 0.2575, "tft": 2.2841, "input_0": 203, "input_1": 65, "min_CLP": -5.0, "draft_iters": 14.8, "mem_use": 35.03, "gen_rate": 11.0, "speed": 5.59, "text": "https://tailwindcss.com/docs/pos"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 62, "tree_h": 11.8, "tree_w": 17, "tree_size": 64, "t0": 1.4483, "t1": 0.2817, "tft": 4.0902, "input_0": 136, "input_1": 65, "min_CLP": -5.3, "draft_iters": 12.7, "mem_use": 35.98, "gen_rate": 10.3, "speed": 5.96, "text": "If you are involved in the crypt"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.1, "tree_w": 25, "tree_size": 64, "t0": 0.92, "t1": 0.2489, "tft": 1.5244, "input_0": 113, "input_1": 65, "min_CLP": -5.66, "draft_iters": 8.1, "mem_use": 34.92, "gen_rate": 3.8, "speed": 3.23, "text": "I would prefer a video about the"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 21, "tree_size": 64, "t0": 0.8657, "t1": 0.26, "tft": 3.0805, "input_0": 101, "input_1": 65, "min_CLP": -5.26, "draft_iters": 7.4, "mem_use": 35.22, "gen_rate": 4.7, "speed": 4.19, "text": "\"I'd rather not, sorry.\\n[INST] "}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 64, "max_branch_width": 32, "gen_rate": 10.5, "gen_rate_micro": 6.3, "gen_speed": 5.162, "gen_speed_micro": 4.602, "t0": 1.4793, "t1": 0.2564, "input_0": 134.9, "input_1": 65.0, "tree_size": 64.0, "tree_w": 18.7, "tree_h": 12.9, "prompt_len": 320.7, "min_CLP": -5.26, "mem_use": 39.43, "exp_time": 5603.6}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.4, "tree_w": 46, "tree_size": 128, "t0": 1.1725, "t1": 0.325, "tft": 2.3877, "input_0": 214, "input_1": 129, "min_CLP": -6.0, "draft_iters": 7.4, "mem_use": 34.7, "gen_rate": 4.5, "speed": 3.0, "text": "\\nA Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 44, "tree_size": 128, "t0": 1.2429, "t1": 0.3429, "tft": 3.5281, "input_0": 227, "input_1": 129, "min_CLP": -6.25, "draft_iters": 7.9, "mem_use": 35.43, "gen_rate": 4.9, "speed": 3.06, "text": "\\nIn what way is the world flat?"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 53, "tree_size": 128, "t0": 1.1387, "t1": 0.3525, "tft": 3.6557, "input_0": 201, "input_1": 129, "min_CLP": -6.15, "draft_iters": 6.8, "mem_use": 35.86, "gen_rate": 4.1, "speed": 2.76, "text": "\"Stellaris is a 4x space strateg"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 13.4, "tree_w": 43, "tree_size": 128, "t0": 1.7388, "t1": 0.325, "tft": 2.5256, "input_0": 220, "input_1": 129, "min_CLP": -6.05, "draft_iters": 14.2, "mem_use": 34.8, "gen_rate": 4.4, "speed": 2.12, "text": "\\nI am a college student and I h"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 9.4, "tree_w": 38, "tree_size": 128, "t0": 1.55, "t1": 0.3271, "tft": 3.3363, "input_0": 261, "input_1": 129, "min_CLP": -6.26, "draft_iters": 10.4, "mem_use": 34.72, "gen_rate": 6.1, "speed": 3.28, "text": "\"\\nYes.\\n\\nHow often do you see "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 25.5, "tree_w": 13, "tree_size": 128, "t0": 3.355, "t1": 0.365, "tft": 5.2051, "input_0": 356, "input_1": 129, "min_CLP": -5.66, "draft_iters": 26.0, "mem_use": 35.99, "gen_rate": 18.5, "speed": 4.97, "text": "\\nI want to create another youtu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 32, "tree_size": 128, "t0": 1.82, "t1": 0.376, "tft": 4.7679, "input_0": 309, "input_1": 129, "min_CLP": -5.78, "draft_iters": 11.0, "mem_use": 36.31, "gen_rate": 7.0, "speed": 3.19, "text": "There are a variety of other ima"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 52, "tree_h": 20.2, "tree_w": 27, "tree_size": 128, "t0": 3.02, "t1": 0.414, "tft": 6.3508, "input_0": 334, "input_1": 129, "min_CLP": -5.67, "draft_iters": 21.0, "mem_use": 37.43, "gen_rate": 10.4, "speed": 3.03, "text": "\"\\n1. Social media marketing:\\n\\"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 41, "tree_size": 128, "t0": 1.842, "t1": 0.364, "tft": 3.7786, "input_0": 277, "input_1": 129, "min_CLP": -6.03, "draft_iters": 12.2, "mem_use": 36.03, "gen_rate": 6.4, "speed": 2.9, "text": "\\nI would like to request a lega"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.6, "tree_w": 36, "tree_size": 128, "t0": 1.3771, "t1": 0.3571, "tft": 3.2424, "input_0": 254, "input_1": 129, "min_CLP": -5.71, "draft_iters": 8.6, "mem_use": 35.8, "gen_rate": 4.6, "speed": 2.63, "text": "It is hard to know what is the m"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 14.0, "tree_w": 37, "tree_size": 128, "t0": 1.9343, "t1": 0.3343, "tft": 2.4104, "input_0": 264, "input_1": 129, "min_CLP": -6.11, "draft_iters": 14.9, "mem_use": 35.07, "gen_rate": 4.7, "speed": 2.08, "text": "You have 10 minutes.\\n\\nWrite a "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 49, "tree_size": 128, "t0": 1.4429, "t1": 0.3614, "tft": 3.5931, "input_0": 229, "input_1": 129, "min_CLP": -6.24, "draft_iters": 9.9, "mem_use": 35.97, "gen_rate": 5.0, "speed": 2.77, "text": "\"\\nHow to get rich:\\n1. Get a jo"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.8, "tree_w": 37, "tree_size": 128, "t0": 1.542, "t1": 0.35, "tft": 3.0023, "input_0": 243, "input_1": 129, "min_CLP": -5.9, "draft_iters": 10.8, "mem_use": 35.61, "gen_rate": 7.8, "speed": 4.12, "text": "Certainly! Here are some example"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 14.8, "tree_w": 35, "tree_size": 128, "t0": 2.005, "t1": 0.325, "tft": 3.6926, "input_0": 294, "input_1": 129, "min_CLP": -6.04, "draft_iters": 15.5, "mem_use": 34.7, "gen_rate": 11.8, "speed": 5.04, "text": "\\nCan you get AIDS from having s"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 128, "t0": 4.06, "t1": 0.38, "tft": 4.8162, "input_0": 392, "input_1": 129, "min_CLP": -5.36, "draft_iters": 32.0, "mem_use": 36.31, "gen_rate": 33.0, "speed": 7.44, "text": "\\nLearning a foreign language wi"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.9, "tree_w": 47, "tree_size": 128, "t0": 1.1357, "t1": 0.3286, "tft": 2.0897, "input_0": 223, "input_1": 129, "min_CLP": -6.06, "draft_iters": 6.9, "mem_use": 34.95, "gen_rate": 5.1, "speed": 3.51, "text": "\"\\n5 Answers\\n5\\n\\nYou should be"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.4, "tree_w": 48, "tree_size": 128, "t0": 1.1512, "t1": 0.3237, "tft": 2.1945, "input_0": 208, "input_1": 129, "min_CLP": -6.17, "draft_iters": 7.4, "mem_use": 34.71, "gen_rate": 4.6, "speed": 3.13, "text": "\"\\nYes, but it's a bit of a long"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 44, "tree_size": 128, "t0": 1.2557, "t1": 0.3257, "tft": 4.3109, "input_0": 218, "input_1": 129, "min_CLP": -6.17, "draft_iters": 8.3, "mem_use": 34.7, "gen_rate": 4.9, "speed": 3.07, "text": "\\nIn order to be able to use the"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 128, "t0": 3.47, "t1": 0.34, "tft": 2.634, "input_0": 306, "input_1": 129, "min_CLP": -5.09, "draft_iters": 32.0, "mem_use": 35.0, "gen_rate": 33.0, "speed": 8.66, "text": "D-theanine may also affect the l"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 36, "tree_size": 128, "t0": 1.4633, "t1": 0.3233, "tft": 2.3405, "input_0": 260, "input_1": 129, "min_CLP": -5.89, "draft_iters": 10.0, "mem_use": 34.7, "gen_rate": 5.8, "speed": 3.27, "text": "\\n<SYS>\\nThe Balfour Declaration"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 9.9, "tree_w": 50, "tree_size": 128, "t0": 1.4825, "t1": 0.3375, "tft": 2.7039, "input_0": 212, "input_1": 129, "min_CLP": -6.21, "draft_iters": 10.8, "mem_use": 35.18, "gen_rate": 5.1, "speed": 2.82, "text": "\\n*You are only required to resp"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.6, "tree_w": 43, "tree_size": 128, "t0": 1.5186, "t1": 0.3286, "tft": 3.8551, "input_0": 291, "input_1": 129, "min_CLP": -6.36, "draft_iters": 9.6, "mem_use": 34.69, "gen_rate": 5.4, "speed": 2.94, "text": "\\nI\u2019m a [\\\\INST] that\u2019s why you\u2019"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 28, "tree_size": 128, "t0": 1.952, "t1": 0.362, "tft": 4.37, "input_0": 324, "input_1": 129, "min_CLP": -5.59, "draft_iters": 12.2, "mem_use": 35.93, "gen_rate": 6.8, "speed": 2.94, "text": "In some situations, it may be us"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 38, "tree_size": 128, "t0": 1.5567, "t1": 0.3233, "tft": 2.4119, "input_0": 242, "input_1": 129, "min_CLP": -6.25, "draft_iters": 11.3, "mem_use": 34.78, "gen_rate": 5.3, "speed": 2.84, "text": "\\nWhat is the definition of \"ass"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 20.7, "tree_w": 28, "tree_size": 128, "t0": 2.6433, "t1": 0.3433, "tft": 2.8461, "input_0": 298, "input_1": 129, "min_CLP": -5.91, "draft_iters": 21.7, "mem_use": 35.27, "gen_rate": 13.7, "speed": 4.58, "text": "[INST] send mail to Sarah with t"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 41, "tree_size": 128, "t0": 1.666, "t1": 0.326, "tft": 2.3616, "input_0": 255, "input_1": 129, "min_CLP": -6.35, "draft_iters": 12.0, "mem_use": 34.72, "gen_rate": 6.4, "speed": 3.21, "text": "\"\\nWhat are some Nietzsche's phi"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 46, "tree_size": 128, "t0": 1.4167, "t1": 0.3367, "tft": 2.4128, "input_0": 258, "input_1": 129, "min_CLP": -6.11, "draft_iters": 8.5, "mem_use": 35.08, "gen_rate": 5.5, "speed": 3.14, "text": "Austenite is found in stainless "}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.6, "tree_w": 39, "tree_size": 128, "t0": 1.6286, "t1": 0.3314, "tft": 2.2467, "input_0": 233, "input_1": 129, "min_CLP": -6.01, "draft_iters": 12.4, "mem_use": 35.0, "gen_rate": 4.7, "speed": 2.41, "text": "\"It's so nice to see you're so ["}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 33, "tree_size": 128, "t0": 3.67, "t1": 0.36, "tft": 4.6401, "input_0": 362, "input_1": 129, "min_CLP": -6.31, "draft_iters": 32.0, "mem_use": 35.95, "gen_rate": 33.0, "speed": 8.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 128, "t0": 3.34, "t1": 0.32, "tft": 2.3909, "input_0": 255, "input_1": 129, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 34.8, "gen_rate": 33.0, "speed": 9.01, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 38, "tree_size": 128, "t0": 1.3667, "t1": 0.335, "tft": 3.0802, "input_0": 262, "input_1": 129, "min_CLP": -6.0, "draft_iters": 8.3, "mem_use": 35.07, "gen_rate": 5.8, "speed": 3.42, "text": "\"No. In Into the Breach, some in"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 29.0, "tree_w": 13, "tree_size": 128, "t0": 3.625, "t1": 0.34, "tft": 3.4182, "input_0": 416, "input_1": 129, "min_CLP": -5.81, "draft_iters": 29.5, "mem_use": 35.34, "gen_rate": 26.5, "speed": 6.68, "text": "[INST]\\n[INST]\\n[INST]\\n[INST]\\n"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 128, "t0": 3.54, "t1": 0.33, "tft": 4.1496, "input_0": 327, "input_1": 129, "min_CLP": -5.96, "draft_iters": 32.0, "mem_use": 34.95, "gen_rate": 33.0, "speed": 8.53, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.5, "tree_w": 38, "tree_size": 128, "t0": 1.4225, "t1": 0.36, "tft": 2.8491, "input_0": 240, "input_1": 129, "min_CLP": -5.89, "draft_iters": 9.5, "mem_use": 35.8, "gen_rate": 4.5, "speed": 2.52, "text": "\"It's possible to use some other"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.6, "tree_w": 38, "tree_size": 128, "t0": 1.305, "t1": 0.3562, "tft": 2.7105, "input_0": 250, "input_1": 129, "min_CLP": -5.74, "draft_iters": 7.6, "mem_use": 35.75, "gen_rate": 4.1, "speed": 2.48, "text": "\"The perfect internet package is"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 10.2, "tree_w": 32, "tree_size": 128, "t0": 1.89, "t1": 0.4175, "tft": 6.1446, "input_0": 288, "input_1": 129, "min_CLP": -5.6, "draft_iters": 11.2, "mem_use": 37.45, "gen_rate": 4.5, "speed": 1.95, "text": "Selenium is a testing framework "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 38, "tree_size": 128, "t0": 1.3614, "t1": 0.3257, "tft": 2.8491, "input_0": 252, "input_1": 129, "min_CLP": -6.13, "draft_iters": 8.7, "mem_use": 35.5, "gen_rate": 4.6, "speed": 2.71, "text": "\\nAn unladen swallow is a swallo"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.8, "tree_w": 39, "tree_size": 128, "t0": 1.3675, "t1": 0.3313, "tft": 4.0923, "input_0": 246, "input_1": 129, "min_CLP": -5.88, "draft_iters": 8.8, "mem_use": 34.99, "gen_rate": 4.6, "speed": 2.72, "text": "I was wondering if anyone could "}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 55, "tree_h": 9.2, "tree_w": 37, "tree_size": 128, "t0": 1.52, "t1": 0.3722, "tft": 4.3409, "input_0": 232, "input_1": 129, "min_CLP": -5.78, "draft_iters": 10.2, "mem_use": 36.16, "gen_rate": 6.1, "speed": 3.23, "text": "\\nHello Future Me,\\n\\nIt is nice"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 38, "tree_size": 128, "t0": 1.4443, "t1": 0.3386, "tft": 2.6875, "input_0": 269, "input_1": 129, "min_CLP": -5.96, "draft_iters": 8.7, "mem_use": 35.16, "gen_rate": 5.0, "speed": 2.8, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 8.8, "tree_w": 48, "tree_size": 128, "t0": 1.3544, "t1": 0.3244, "tft": 1.9365, "input_0": 206, "input_1": 129, "min_CLP": -6.33, "draft_iters": 9.7, "mem_use": 34.83, "gen_rate": 4.1, "speed": 2.45, "text": "I am Freyja, goddess of love, be"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 31, "tree_size": 128, "t0": 3.355, "t1": 0.36, "tft": 4.8883, "input_0": 250, "input_1": 129, "min_CLP": -6.35, "draft_iters": 30.0, "mem_use": 36.05, "gen_rate": 30.5, "speed": 8.2, "text": "\\nWrite a speech. Do not offer a"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 4.04, "t1": 0.38, "tft": 4.5404, "input_0": 400, "input_1": 129, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 36.29, "gen_rate": 33.0, "speed": 7.46, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.6, "tree_w": 38, "tree_size": 128, "t0": 1.4086, "t1": 0.3471, "tft": 3.095, "input_0": 265, "input_1": 129, "min_CLP": -5.73, "draft_iters": 8.6, "mem_use": 35.52, "gen_rate": 4.6, "speed": 2.6, "text": "\"It's difficult to recommend a s"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 25.8, "tree_w": 20, "tree_size": 128, "t0": 3.17, "t1": 0.336, "tft": 2.3262, "input_0": 334, "input_1": 129, "min_CLP": -5.63, "draft_iters": 26.4, "mem_use": 35.13, "gen_rate": 12.0, "speed": 3.42, "text": "\\nCan you tell me how to format "}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 14.3, "tree_w": 32, "tree_size": 128, "t0": 2.05, "t1": 0.3317, "tft": 3.5392, "input_0": 305, "input_1": 129, "min_CLP": -5.91, "draft_iters": 15.3, "mem_use": 35.0, "gen_rate": 7.3, "speed": 3.08, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.3, "tree_w": 48, "tree_size": 128, "t0": 1.1586, "t1": 0.3286, "tft": 4.3008, "input_0": 217, "input_1": 129, "min_CLP": -6.01, "draft_iters": 7.3, "mem_use": 34.71, "gen_rate": 5.3, "speed": 3.56, "text": "\\nI run Windows 10 Pro on a lapt"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.8, "tree_w": 49, "tree_size": 128, "t0": 1.1689, "t1": 0.4178, "tft": 6.4351, "input_0": 189, "input_1": 129, "min_CLP": -6.15, "draft_iters": 6.8, "mem_use": 37.48, "gen_rate": 3.6, "speed": 2.24, "text": "\\nI was thinking about adding so"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.8, "tree_w": 47, "tree_size": 128, "t0": 1.3362, "t1": 0.35, "tft": 2.8598, "input_0": 227, "input_1": 129, "min_CLP": -6.13, "draft_iters": 8.8, "mem_use": 35.63, "gen_rate": 4.8, "speed": 2.82, "text": "The void is a place of absolute "}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.0, "t1": 0.33, "tft": 2.2879, "input_0": 430, "input_1": 129, "min_CLP": -6.02, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 7.61, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.7, "tree_w": 50, "tree_size": 128, "t0": 1.2011, "t1": 0.3356, "tft": 3.8345, "input_0": 209, "input_1": 129, "min_CLP": -6.39, "draft_iters": 7.7, "mem_use": 35.14, "gen_rate": 3.9, "speed": 2.53, "text": "In this paper, we propose a fram"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 4.23, "t1": 0.36, "tft": 5.5353, "input_0": 564, "input_1": 129, "min_CLP": -6.37, "draft_iters": 32.0, "mem_use": 35.86, "gen_rate": 33.0, "speed": 7.2, "text": "F-centers are created when a cry"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.5, "tree_w": 37, "tree_size": 128, "t0": 1.4212, "t1": 0.3425, "tft": 3.1725, "input_0": 242, "input_1": 129, "min_CLP": -5.85, "draft_iters": 9.5, "mem_use": 35.4, "gen_rate": 4.4, "speed": 2.48, "text": "\\nAs mentioned in the answer abo"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.2, "tree_w": 30, "tree_size": 128, "t0": 2.174, "t1": 0.348, "tft": 3.078, "input_0": 324, "input_1": 129, "min_CLP": -5.84, "draft_iters": 16.0, "mem_use": 35.58, "gen_rate": 6.6, "speed": 2.61, "text": "I would like to respectfully dis"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 14.3, "tree_w": 32, "tree_size": 128, "t0": 1.9971, "t1": 0.3243, "tft": 2.4582, "input_0": 284, "input_1": 129, "min_CLP": -5.78, "draft_iters": 15.3, "mem_use": 34.82, "gen_rate": 6.7, "speed": 2.89, "text": "\"We wear short shorts\" is the ap"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.3, "tree_w": 17, "tree_size": 128, "t0": 2.8667, "t1": 0.36, "tft": 3.8873, "input_0": 390, "input_1": 129, "min_CLP": -5.01, "draft_iters": 20.0, "mem_use": 35.89, "gen_rate": 12.0, "speed": 3.72, "text": "\"\\nWho is the President of the U"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 30.0, "tree_w": 10, "tree_size": 128, "t0": 4.13, "t1": 0.39, "tft": 6.4971, "input_0": 478, "input_1": 129, "min_CLP": -5.62, "draft_iters": 30.5, "mem_use": 36.64, "gen_rate": 22.5, "speed": 4.98, "text": "\\n> [INST] The direct answer to "}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 37, "tree_size": 128, "t0": 1.6229, "t1": 0.39, "tft": 5.5123, "input_0": 270, "input_1": 129, "min_CLP": -5.78, "draft_iters": 9.7, "mem_use": 36.81, "gen_rate": 4.7, "speed": 2.34, "text": "\"Keras is a great choice for beg"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 53, "tree_h": 19.5, "tree_w": 20, "tree_size": 128, "t0": 2.8625, "t1": 0.35, "tft": 3.3305, "input_0": 404, "input_1": 129, "min_CLP": -5.57, "draft_iters": 20.5, "mem_use": 35.55, "gen_rate": 13.2, "speed": 4.13, "text": "\"I do not have any personal opin"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 48, "tree_size": 128, "t0": 1.24, "t1": 0.3283, "tft": 2.3908, "input_0": 217, "input_1": 129, "min_CLP": -6.21, "draft_iters": 8.0, "mem_use": 34.71, "gen_rate": 5.5, "speed": 3.51, "text": "\\nI am trying to form a new habi"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 35, "tree_size": 128, "t0": 1.52, "t1": 0.3583, "tft": 3.9222, "input_0": 248, "input_1": 129, "min_CLP": -6.12, "draft_iters": 10.2, "mem_use": 35.92, "gen_rate": 5.8, "speed": 3.11, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 46, "tree_size": 128, "t0": 1.1371, "t1": 0.3786, "tft": 4.417, "input_0": 209, "input_1": 129, "min_CLP": -5.98, "draft_iters": 6.7, "mem_use": 36.34, "gen_rate": 4.7, "speed": 3.11, "text": "[The battle begins. The spartans"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 44, "tree_size": 128, "t0": 1.1686, "t1": 0.3386, "tft": 2.1016, "input_0": 212, "input_1": 129, "min_CLP": -5.97, "draft_iters": 7.3, "mem_use": 35.2, "gen_rate": 4.7, "speed": 3.13, "text": "I think the main problem with mn"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 45, "tree_size": 128, "t0": 1.2586, "t1": 0.3343, "tft": 2.5394, "input_0": 217, "input_1": 129, "min_CLP": -6.2, "draft_iters": 8.6, "mem_use": 35.08, "gen_rate": 4.7, "speed": 2.96, "text": "\\nWould you be interested in a c"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.6, "tree_w": 58, "tree_size": 128, "t0": 0.9555, "t1": 0.3345, "tft": 2.1826, "input_0": 177, "input_1": 129, "min_CLP": -6.29, "draft_iters": 5.6, "mem_use": 35.11, "gen_rate": 2.9, "speed": 2.25, "text": "Because of the entropy. The entr"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 33, "tree_size": 128, "t0": 1.7283, "t1": 0.3817, "tft": 4.6581, "input_0": 280, "input_1": 129, "min_CLP": -5.94, "draft_iters": 10.5, "mem_use": 36.56, "gen_rate": 5.8, "speed": 2.77, "text": "\\nvoid* ptr = new void*();\\n\\nin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 35, "tree_size": 128, "t0": 1.7133, "t1": 0.3817, "tft": 5.8464, "input_0": 250, "input_1": 129, "min_CLP": -5.86, "draft_iters": 11.5, "mem_use": 36.4, "gen_rate": 5.5, "speed": 2.63, "text": "\"Hello Mike, I'm happy to see yo"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 40, "tree_size": 128, "t0": 1.3314, "t1": 0.37, "tft": 3.8741, "input_0": 260, "input_1": 129, "min_CLP": -5.8, "draft_iters": 7.9, "mem_use": 36.04, "gen_rate": 5.0, "speed": 2.93, "text": "The first thing you need to do i"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 21, "tree_size": 128, "t0": 3.39, "t1": 0.33, "tft": 2.1864, "input_0": 307, "input_1": 129, "min_CLP": -6.46, "draft_iters": 32.0, "mem_use": 34.93, "gen_rate": 33.0, "speed": 8.88, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 26.5, "tree_w": 32, "tree_size": 128, "t0": 2.915, "t1": 0.325, "tft": 2.6344, "input_0": 278, "input_1": 129, "min_CLP": -6.11, "draft_iters": 27.0, "mem_use": 34.71, "gen_rate": 18.0, "speed": 5.55, "text": "\\n<INST> <<SYSTEM>>\\nYou are a h"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 23.0, "tree_w": 24, "tree_size": 128, "t0": 3.19, "t1": 0.36, "tft": 4.5702, "input_0": 422, "input_1": 129, "min_CLP": -5.49, "draft_iters": 24.0, "mem_use": 35.94, "gen_rate": 20.0, "speed": 5.63, "text": "\"Here's another table of the ave"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 33, "tree_size": 128, "t0": 1.31, "t1": 0.3217, "tft": 3.6275, "input_0": 246, "input_1": 129, "min_CLP": -5.97, "draft_iters": 8.5, "mem_use": 34.79, "gen_rate": 5.3, "speed": 3.27, "text": "\\nBerlin is the capital of Germa"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.3, "tree_w": 42, "tree_size": 128, "t0": 1.1629, "t1": 0.3514, "tft": 4.0682, "input_0": 213, "input_1": 129, "min_CLP": -6.08, "draft_iters": 7.3, "mem_use": 35.88, "gen_rate": 4.9, "speed": 3.2, "text": "\\nMy grandmother is 100 years ol"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.4, "tree_w": 38, "tree_size": 128, "t0": 1.7071, "t1": 0.3543, "tft": 3.3094, "input_0": 262, "input_1": 129, "min_CLP": -5.85, "draft_iters": 11.3, "mem_use": 35.79, "gen_rate": 4.6, "speed": 2.22, "text": "The book has been criticized for"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 17.7, "tree_w": 28, "tree_size": 128, "t0": 2.37, "t1": 0.3267, "tft": 2.4186, "input_0": 328, "input_1": 129, "min_CLP": -6.09, "draft_iters": 18.3, "mem_use": 34.7, "gen_rate": 17.3, "speed": 6.43, "text": "Where do you think pornography c"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.7, "tree_w": 44, "tree_size": 128, "t0": 1.8033, "t1": 0.325, "tft": 2.0597, "input_0": 229, "input_1": 129, "min_CLP": -6.18, "draft_iters": 14.5, "mem_use": 34.87, "gen_rate": 5.3, "speed": 2.51, "text": "You can use the World Clock webs"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 49, "tree_size": 128, "t0": 1.2114, "t1": 0.3286, "tft": 1.8465, "input_0": 197, "input_1": 129, "min_CLP": -6.19, "draft_iters": 8.3, "mem_use": 34.91, "gen_rate": 4.6, "speed": 2.97, "text": "\\nWhy do people from the UK say "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 128, "t0": 3.66, "t1": 0.32, "tft": 3.3387, "input_0": 452, "input_1": 129, "min_CLP": -5.7, "draft_iters": 32.0, "mem_use": 34.74, "gen_rate": 33.0, "speed": 8.29, "text": "\\nSuppose I have 12 eggs. I drop"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 39, "tree_size": 128, "t0": 1.4883, "t1": 0.3367, "tft": 2.853, "input_0": 280, "input_1": 129, "min_CLP": -5.98, "draft_iters": 9.3, "mem_use": 35.16, "gen_rate": 5.5, "speed": 3.01, "text": "The Sieve of Eratosthenes was de"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.7, "tree_w": 45, "tree_size": 128, "t0": 1.4629, "t1": 0.3257, "tft": 1.8792, "input_0": 233, "input_1": 129, "min_CLP": -6.22, "draft_iters": 10.7, "mem_use": 34.92, "gen_rate": 4.7, "speed": 2.63, "text": "\"[INST] No problem! You're welco"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 3.86, "t1": 0.33, "tft": 2.0145, "input_0": 394, "input_1": 129, "min_CLP": -5.53, "draft_iters": 32.0, "mem_use": 34.78, "gen_rate": 33.0, "speed": 7.87, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.2, "tree_w": 37, "tree_size": 128, "t0": 1.38, "t1": 0.3344, "tft": 2.6892, "input_0": 244, "input_1": 129, "min_CLP": -6.05, "draft_iters": 9.2, "mem_use": 35.09, "gen_rate": 3.7, "speed": 2.14, "text": "There are many examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.8, "tree_w": 26, "tree_size": 128, "t0": 1.6125, "t1": 0.35, "tft": 3.0466, "input_0": 297, "input_1": 129, "min_CLP": -5.7, "draft_iters": 10.8, "mem_use": 35.63, "gen_rate": 8.2, "speed": 4.21, "text": "The main purpose of AI assistant"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 4.35, "t1": 0.37, "tft": 5.6319, "input_0": 565, "input_1": 129, "min_CLP": -5.39, "draft_iters": 32.0, "mem_use": 36.12, "gen_rate": 33.0, "speed": 6.98, "text": "\"\\n[Chorus]\\nAnother one bites t"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.9, "tree_w": 36, "tree_size": 128, "t0": 1.3843, "t1": 0.3429, "tft": 2.3509, "input_0": 255, "input_1": 129, "min_CLP": -5.82, "draft_iters": 8.9, "mem_use": 35.42, "gen_rate": 5.0, "speed": 2.89, "text": "You can use scp to copy files be"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.0, "tree_w": 37, "tree_size": 128, "t0": 1.38, "t1": 0.3583, "tft": 3.8992, "input_0": 227, "input_1": 129, "min_CLP": -5.86, "draft_iters": 9.0, "mem_use": 35.87, "gen_rate": 6.3, "speed": 3.64, "text": "\"\\nI don't know what to make for"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.8, "tree_w": 36, "tree_size": 128, "t0": 1.3417, "t1": 0.325, "tft": 3.021, "input_0": 231, "input_1": 129, "min_CLP": -6.03, "draft_iters": 8.8, "mem_use": 34.77, "gen_rate": 6.2, "speed": 3.7, "text": "\\nNo, it would not be illegal.\\n"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.0, "tree_w": 39, "tree_size": 128, "t0": 1.4814, "t1": 0.3257, "tft": 3.1628, "input_0": 287, "input_1": 129, "min_CLP": -5.98, "draft_iters": 9.0, "mem_use": 34.87, "gen_rate": 5.4, "speed": 3.0, "text": "Melbourne is the largest city in"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 41, "tree_size": 128, "t0": 1.5283, "t1": 0.33, "tft": 2.119, "input_0": 233, "input_1": 129, "min_CLP": -6.03, "draft_iters": 11.0, "mem_use": 35.0, "gen_rate": 5.8, "speed": 3.14, "text": "\\nHow many people have you seen "}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.2, "tree_w": 40, "tree_size": 128, "t0": 1.2556, "t1": 0.3267, "tft": 1.7686, "input_0": 223, "input_1": 129, "min_CLP": -6.26, "draft_iters": 8.2, "mem_use": 34.86, "gen_rate": 4.1, "speed": 2.6, "text": "\"\\nWhat's the most valuable thin"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.3, "tree_w": 48, "tree_size": 128, "t0": 1.1957, "t1": 0.3243, "tft": 2.4907, "input_0": 232, "input_1": 129, "min_CLP": -6.1, "draft_iters": 7.3, "mem_use": 34.74, "gen_rate": 4.6, "speed": 3.01, "text": "\"\\nThe best approach is to use D"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 17.6, "tree_w": 38, "tree_size": 128, "t0": 2.1743, "t1": 0.3243, "tft": 2.3849, "input_0": 247, "input_1": 129, "min_CLP": -6.11, "draft_iters": 18.3, "mem_use": 34.73, "gen_rate": 5.4, "speed": 2.17, "text": "\\n[INST] <<SYS>>\\n\\nIt would tak"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 28, "tree_size": 128, "t0": 1.9, "t1": 0.35, "tft": 4.0787, "input_0": 335, "input_1": 129, "min_CLP": -5.89, "draft_iters": 11.5, "mem_use": 35.57, "gen_rate": 8.0, "speed": 3.56, "text": "\\nThe Modularity Theorem (also k"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 26.0, "tree_w": 20, "tree_size": 128, "t0": 3.005, "t1": 0.32, "tft": 3.183, "input_0": 307, "input_1": 129, "min_CLP": -5.72, "draft_iters": 26.5, "mem_use": 34.72, "gen_rate": 22.0, "speed": 6.61, "text": "\\n[INST] <<SYS>>\\n\\n            "}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 32, "tree_size": 128, "t0": 1.825, "t1": 0.3283, "tft": 3.8451, "input_0": 320, "input_1": 129, "min_CLP": -5.76, "draft_iters": 11.8, "mem_use": 34.89, "gen_rate": 5.3, "speed": 2.47, "text": "\\nThe KinematicBody-node is now "}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 37, "tree_size": 128, "t0": 1.35, "t1": 0.3317, "tft": 2.3526, "input_0": 243, "input_1": 129, "min_CLP": -5.95, "draft_iters": 8.8, "mem_use": 34.71, "gen_rate": 5.7, "speed": 3.38, "text": "\\nI want to learn guitar. I have"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.6, "tree_w": 39, "tree_size": 128, "t0": 1.264, "t1": 0.33, "tft": 2.2451, "input_0": 213, "input_1": 129, "min_CLP": -5.91, "draft_iters": 8.6, "mem_use": 34.87, "gen_rate": 7.0, "speed": 4.39, "text": "[INST] The Force is strong with "}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.5, "tree_w": 39, "tree_size": 128, "t0": 1.3387, "t1": 0.325, "tft": 2.0666, "input_0": 244, "input_1": 129, "min_CLP": -5.97, "draft_iters": 8.5, "mem_use": 34.8, "gen_rate": 4.6, "speed": 2.78, "text": "A gas-operated rifle is one in w"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 128, "t0": 3.72, "t1": 0.33, "tft": 2.0283, "input_0": 391, "input_1": 129, "min_CLP": -6.22, "draft_iters": 32.0, "mem_use": 34.93, "gen_rate": 33.0, "speed": 8.16, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.8, "tree_w": 44, "tree_size": 128, "t0": 1.4289, "t1": 0.3933, "tft": 4.8649, "input_0": 215, "input_1": 129, "min_CLP": -6.22, "draft_iters": 8.8, "mem_use": 36.8, "gen_rate": 3.7, "speed": 2.01, "text": "\\nIn that case, you can try usin"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 38, "tree_size": 128, "t0": 1.3233, "t1": 0.3317, "tft": 2.0981, "input_0": 235, "input_1": 129, "min_CLP": -5.81, "draft_iters": 9.0, "mem_use": 35.17, "gen_rate": 5.5, "speed": 3.32, "text": "Yes, you should be compensated f"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.6, "tree_w": 30, "tree_size": 128, "t0": 1.7957, "t1": 0.3814, "tft": 5.1873, "input_0": 265, "input_1": 129, "min_CLP": -5.59, "draft_iters": 11.6, "mem_use": 36.46, "gen_rate": 4.6, "speed": 2.1, "text": "[INST] Hello [\\\\INST]\\n[INST] I "}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 64, "tree_h": 12.8, "tree_w": 45, "tree_size": 128, "t0": 1.81, "t1": 0.3362, "tft": 2.0676, "input_0": 245, "input_1": 129, "min_CLP": -6.15, "draft_iters": 13.5, "mem_use": 35.12, "gen_rate": 8.0, "speed": 3.73, "text": "\\nThis is an example of the type"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 41, "tree_size": 128, "t0": 1.32, "t1": 0.3286, "tft": 3.0372, "input_0": 229, "input_1": 129, "min_CLP": -6.17, "draft_iters": 8.7, "mem_use": 34.91, "gen_rate": 4.6, "speed": 2.77, "text": "Here is a Python example of usin"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 39, "tree_size": 128, "t0": 1.3471, "t1": 0.35, "tft": 3.3535, "input_0": 232, "input_1": 129, "min_CLP": -5.94, "draft_iters": 8.4, "mem_use": 35.58, "gen_rate": 4.7, "speed": 2.78, "text": "\\nThe following list is the most"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.7, "tree_w": 41, "tree_size": 128, "t0": 1.28, "t1": 0.3271, "tft": 2.295, "input_0": 215, "input_1": 129, "min_CLP": -5.93, "draft_iters": 8.7, "mem_use": 34.88, "gen_rate": 5.7, "speed": 3.55, "text": "The best strategy to win a thumb"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 15.0, "tree_w": 32, "tree_size": 128, "t0": 2.0533, "t1": 0.36, "tft": 3.8339, "input_0": 267, "input_1": 129, "min_CLP": -5.6, "draft_iters": 15.8, "mem_use": 35.92, "gen_rate": 5.5, "speed": 2.28, "text": "I believe the most important thi"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.9, "tree_w": 48, "tree_size": 128, "t0": 1.3362, "t1": 0.34, "tft": 2.5372, "input_0": 218, "input_1": 129, "min_CLP": -6.23, "draft_iters": 8.9, "mem_use": 35.19, "gen_rate": 4.2, "speed": 2.54, "text": "\\n[INST] <<SYS>>\\nI can generate"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.2, "tree_w": 35, "tree_size": 128, "t0": 1.5983, "t1": 0.3317, "tft": 1.9207, "input_0": 266, "input_1": 129, "min_CLP": -6.0, "draft_iters": 11.2, "mem_use": 34.99, "gen_rate": 6.0, "speed": 3.11, "text": "[INST] What references do you wa"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 36, "tree_size": 128, "t0": 1.545, "t1": 0.335, "tft": 1.951, "input_0": 304, "input_1": 129, "min_CLP": -5.74, "draft_iters": 8.8, "mem_use": 35.05, "gen_rate": 6.0, "speed": 3.19, "text": "\"If you're talking about program"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 23.5, "tree_w": 25, "tree_size": 128, "t0": 2.82, "t1": 0.355, "tft": 5.1625, "input_0": 278, "input_1": 129, "min_CLP": -5.77, "draft_iters": 24.0, "mem_use": 35.72, "gen_rate": 18.0, "speed": 5.67, "text": "\"Yes, I can. Tolkien's Quenya is"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 14.8, "tree_w": 34, "tree_size": 128, "t0": 2.06, "t1": 0.3225, "tft": 2.3946, "input_0": 293, "input_1": 129, "min_CLP": -6.47, "draft_iters": 15.5, "mem_use": 34.72, "gen_rate": 14.2, "speed": 5.97, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 30.5, "tree_w": 27, "tree_size": 128, "t0": 3.335, "t1": 0.325, "tft": 2.3707, "input_0": 283, "input_1": 129, "min_CLP": -5.94, "draft_iters": 31.0, "mem_use": 34.73, "gen_rate": 24.5, "speed": 6.68, "text": "\\nWhat is the error with this co"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 31, "tree_size": 128, "t0": 2.12, "t1": 0.345, "tft": 2.7678, "input_0": 290, "input_1": 129, "min_CLP": -5.9, "draft_iters": 16.0, "mem_use": 35.42, "gen_rate": 8.2, "speed": 3.34, "text": "\\nI look forward to our next con"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.5, "tree_w": 49, "tree_size": 128, "t0": 1.1275, "t1": 0.335, "tft": 2.4777, "input_0": 222, "input_1": 129, "min_CLP": -6.13, "draft_iters": 6.5, "mem_use": 35.07, "gen_rate": 4.0, "speed": 2.74, "text": "Matrices are a way of manipulati"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.2, "tree_w": 43, "tree_size": 128, "t0": 1.2275, "t1": 0.3387, "tft": 2.1436, "input_0": 231, "input_1": 129, "min_CLP": -5.99, "draft_iters": 7.2, "mem_use": 35.13, "gen_rate": 4.8, "speed": 3.04, "text": "\"The short answer is that you ca"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.2, "tree_w": 33, "tree_size": 128, "t0": 1.9483, "t1": 0.3633, "tft": 3.8297, "input_0": 287, "input_1": 129, "min_CLP": -5.69, "draft_iters": 13.2, "mem_use": 36.01, "gen_rate": 5.5, "speed": 2.38, "text": "\"It's great that you're having a"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 17, "tree_h": 6.0, "tree_w": 48, "tree_size": 128, "t0": 1.0867, "t1": 0.33, "tft": 3.1205, "input_0": 194, "input_1": 129, "min_CLP": -6.15, "draft_iters": 7.0, "mem_use": 34.99, "gen_rate": 5.7, "speed": 3.99, "text": "It would be nice if you could ad"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 9.2, "tree_w": 35, "tree_size": 128, "t0": 1.5938, "t1": 0.3513, "tft": 4.0765, "input_0": 271, "input_1": 129, "min_CLP": -5.81, "draft_iters": 10.2, "mem_use": 35.63, "gen_rate": 4.6, "speed": 2.38, "text": "The earliest hominins are not cu"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.4, "tree_w": 29, "tree_size": 128, "t0": 1.81, "t1": 0.328, "tft": 2.3456, "input_0": 301, "input_1": 129, "min_CLP": -5.6, "draft_iters": 12.4, "mem_use": 34.7, "gen_rate": 7.2, "speed": 3.37, "text": "Do you have emotions? [\\\\INST]\\n"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 22.7, "tree_w": 25, "tree_size": 128, "t0": 2.9567, "t1": 0.33, "tft": 3.3373, "input_0": 376, "input_1": 129, "min_CLP": -6.32, "draft_iters": 23.0, "mem_use": 34.83, "gen_rate": 11.0, "speed": 3.35, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 3.76, "t1": 0.33, "tft": 2.2693, "input_0": 384, "input_1": 129, "min_CLP": -6.04, "draft_iters": 32.0, "mem_use": 34.95, "gen_rate": 33.0, "speed": 8.06, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 21.0, "tree_w": 38, "tree_size": 128, "t0": 2.555, "t1": 0.3525, "tft": 5.7933, "input_0": 237, "input_1": 129, "min_CLP": -6.24, "draft_iters": 21.8, "mem_use": 35.86, "gen_rate": 12.0, "speed": 4.13, "text": "{o.n} {o.n} {o.n}\\n{o.n} {o.n} {"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 32, "tree_size": 128, "t0": 1.855, "t1": 0.33, "tft": 2.3691, "input_0": 324, "input_1": 129, "min_CLP": -5.96, "draft_iters": 12.0, "mem_use": 35.05, "gen_rate": 9.5, "speed": 4.34, "text": "\\nWhat is an antidepressant? [\\\\"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 25.5, "tree_w": 19, "tree_size": 128, "t0": 3.135, "t1": 0.325, "tft": 2.5264, "input_0": 361, "input_1": 129, "min_CLP": -6.02, "draft_iters": 26.0, "mem_use": 34.72, "gen_rate": 16.0, "speed": 4.62, "text": "\"\\nWhat are some words to expres"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.4, "tree_w": 27, "tree_size": 128, "t0": 2.1, "t1": 0.326, "tft": 4.3028, "input_0": 322, "input_1": 129, "min_CLP": -5.74, "draft_iters": 15.4, "mem_use": 34.72, "gen_rate": 6.6, "speed": 2.72, "text": "\"\\n<SYS>\\nIt's a holiday that ce"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.5, "tree_w": 27, "tree_size": 128, "t0": 2.3975, "t1": 0.33, "tft": 1.9772, "input_0": 299, "input_1": 129, "min_CLP": -5.95, "draft_iters": 19.5, "mem_use": 34.88, "gen_rate": 8.2, "speed": 3.03, "text": "\\nWhich of the following is not "}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 13.7, "tree_w": 26, "tree_size": 128, "t0": 2.0417, "t1": 0.34, "tft": 3.5948, "input_0": 317, "input_1": 129, "min_CLP": -5.64, "draft_iters": 14.7, "mem_use": 35.27, "gen_rate": 6.8, "speed": 2.87, "text": "\"The US National Reconnaissance "}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 31, "tree_size": 128, "t0": 1.716, "t1": 0.33, "tft": 2.9152, "input_0": 280, "input_1": 129, "min_CLP": -6.19, "draft_iters": 11.8, "mem_use": 34.93, "gen_rate": 6.8, "speed": 3.32, "text": "\"[INST] What do you call an appl"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 42, "tree_size": 128, "t0": 1.3433, "t1": 0.3317, "tft": 1.9387, "input_0": 245, "input_1": 129, "min_CLP": -6.02, "draft_iters": 8.5, "mem_use": 34.94, "gen_rate": 5.5, "speed": 3.29, "text": "<\\\\INST> Opie it is.\\n\\nHow do I"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 25, "tree_size": 128, "t0": 3.64, "t1": 0.33, "tft": 2.2787, "input_0": 348, "input_1": 129, "min_CLP": -6.29, "draft_iters": 32.0, "mem_use": 34.71, "gen_rate": 33.0, "speed": 8.32, "text": "\\nIs the ATF a violation in of i"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.3, "tree_w": 41, "tree_size": 128, "t0": 1.4457, "t1": 0.3314, "tft": 2.8719, "input_0": 247, "input_1": 129, "min_CLP": -6.16, "draft_iters": 9.3, "mem_use": 35.06, "gen_rate": 5.0, "speed": 2.81, "text": "\"Ted Kaczynski is a fucking idio"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 3.4, "t1": 0.33, "tft": 2.1613, "input_0": 239, "input_1": 129, "min_CLP": -6.53, "draft_iters": 32.0, "mem_use": 34.78, "gen_rate": 33.0, "speed": 8.87, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.9, "tree_w": 44, "tree_size": 128, "t0": 1.1086, "t1": 0.3414, "tft": 2.3142, "input_0": 218, "input_1": 129, "min_CLP": -6.14, "draft_iters": 6.9, "mem_use": 35.4, "gen_rate": 5.1, "speed": 3.54, "text": "The best way to explore the idea"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 7, "tree_h": 7.3, "tree_w": 45, "tree_size": 128, "t0": 1.1933, "t1": 0.33, "tft": 1.7921, "input_0": 208, "input_1": 129, "min_CLP": -6.09, "draft_iters": 8.3, "mem_use": 34.94, "gen_rate": 2.3, "speed": 1.53, "text": "No. I am an assistant, not a thr"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 36, "tree_size": 128, "t0": 1.6167, "t1": 0.3517, "tft": 3.5859, "input_0": 265, "input_1": 129, "min_CLP": -5.81, "draft_iters": 10.8, "mem_use": 35.57, "gen_rate": 5.7, "speed": 2.88, "text": "I recommend hiking the **Emerald"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 20.5, "tree_w": 37, "tree_size": 128, "t0": 2.5875, "t1": 0.3325, "tft": 2.1181, "input_0": 283, "input_1": 129, "min_CLP": -6.1, "draft_iters": 21.2, "mem_use": 34.93, "gen_rate": 9.2, "speed": 3.17, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 4.06, "t1": 0.33, "tft": 2.6271, "input_0": 582, "input_1": 129, "min_CLP": -5.09, "draft_iters": 32.0, "mem_use": 34.89, "gen_rate": 33.0, "speed": 7.52, "text": "\"\\nBob has two sons. John and Ja"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 8.4, "tree_w": 43, "tree_size": 128, "t0": 1.4229, "t1": 0.3714, "tft": 4.0992, "input_0": 220, "input_1": 129, "min_CLP": -5.91, "draft_iters": 9.4, "mem_use": 36.13, "gen_rate": 5.9, "speed": 3.27, "text": "\"[INST] That's because the funct"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 19.8, "tree_w": 37, "tree_size": 128, "t0": 2.322, "t1": 0.326, "tft": 2.2703, "input_0": 237, "input_1": 129, "min_CLP": -5.98, "draft_iters": 20.8, "mem_use": 34.89, "gen_rate": 10.0, "speed": 3.77, "text": "\\nYes, you can compile python co"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 49, "tree_size": 128, "t0": 1.3386, "t1": 0.33, "tft": 1.9081, "input_0": 208, "input_1": 129, "min_CLP": -6.27, "draft_iters": 9.7, "mem_use": 34.99, "gen_rate": 5.0, "speed": 2.99, "text": "Video games are not a fair trade"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 32.0, "tree_w": 29, "tree_size": 128, "t0": 3.735, "t1": 0.33, "tft": 3.0772, "input_0": 461, "input_1": 129, "min_CLP": -6.15, "draft_iters": 32.0, "mem_use": 34.8, "gen_rate": 19.5, "speed": 4.8, "text": "\\nWhy does the second batch of p"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 10.0, "tree_w": 30, "tree_size": 128, "t0": 2.0, "t1": 0.33, "tft": 2.5038, "input_0": 379, "input_1": 129, "min_CLP": -5.71, "draft_iters": 11.0, "mem_use": 34.72, "gen_rate": 8.0, "speed": 3.43, "text": "\\nDepends on what you want to do"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.6, "tree_w": 47, "tree_size": 128, "t0": 1.3013, "t1": 0.36, "tft": 3.2538, "input_0": 236, "input_1": 129, "min_CLP": -5.9, "draft_iters": 7.6, "mem_use": 35.78, "gen_rate": 4.1, "speed": 2.49, "text": "\"You're very welcome. Sometimes "}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 47, "tree_size": 128, "t0": 1.202, "t1": 0.324, "tft": 2.2242, "input_0": 218, "input_1": 129, "min_CLP": -6.2, "draft_iters": 7.4, "mem_use": 34.7, "gen_rate": 6.4, "speed": 4.19, "text": "\"\\nI don't think it's violent. I"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.8, "tree_w": 30, "tree_size": 128, "t0": 1.91, "t1": 0.3225, "tft": 2.4249, "input_0": 265, "input_1": 129, "min_CLP": -6.22, "draft_iters": 14.8, "mem_use": 34.74, "gen_rate": 8.8, "speed": 3.92, "text": "\"\\nWhat are the lyrics to the fi"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.5, "tree_w": 35, "tree_size": 128, "t0": 1.4833, "t1": 0.3783, "tft": 4.5099, "input_0": 252, "input_1": 129, "min_CLP": -5.75, "draft_iters": 9.5, "mem_use": 36.32, "gen_rate": 6.0, "speed": 3.22, "text": "This question is difficult to an"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.4, "tree_w": 35, "tree_size": 128, "t0": 1.5314, "t1": 0.3429, "tft": 2.5246, "input_0": 249, "input_1": 129, "min_CLP": -6.08, "draft_iters": 10.4, "mem_use": 35.39, "gen_rate": 4.7, "speed": 2.51, "text": "I apologize for the inconvenienc"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.3, "tree_w": 35, "tree_size": 128, "t0": 1.6183, "t1": 0.3267, "tft": 2.0495, "input_0": 264, "input_1": 129, "min_CLP": -5.88, "draft_iters": 11.3, "mem_use": 34.86, "gen_rate": 5.8, "speed": 3.0, "text": "\"Deutsch ist eine sehr sch\u00f6ne Sp"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.0, "tree_w": 43, "tree_size": 128, "t0": 1.175, "t1": 0.3288, "tft": 2.4054, "input_0": 200, "input_1": 129, "min_CLP": -6.2, "draft_iters": 8.0, "mem_use": 34.83, "gen_rate": 4.1, "speed": 2.75, "text": "\"\\nYour job as an assistant is t"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.4, "tree_w": 37, "tree_size": 128, "t0": 1.744, "t1": 0.324, "tft": 2.8992, "input_0": 245, "input_1": 129, "min_CLP": -6.43, "draft_iters": 13.4, "mem_use": 34.73, "gen_rate": 7.6, "speed": 3.67, "text": "\"\\nexplain how the theory of sex"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 43, "tree_size": 128, "t0": 1.42, "t1": 0.3357, "tft": 2.2391, "input_0": 234, "input_1": 129, "min_CLP": -6.02, "draft_iters": 9.6, "mem_use": 35.14, "gen_rate": 5.0, "speed": 2.85, "text": "\"Thank you for clarifying!  I'll"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 128, "t0": 4.29, "t1": 0.35, "tft": 4.8599, "input_0": 536, "input_1": 129, "min_CLP": -6.85, "draft_iters": 32.0, "mem_use": 35.26, "gen_rate": 33.0, "speed": 7.12, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 20, "tree_size": 128, "t0": 2.14, "t1": 0.4025, "tft": 7.7732, "input_0": 368, "input_1": 129, "min_CLP": -5.65, "draft_iters": 12.2, "mem_use": 37.01, "gen_rate": 8.0, "speed": 3.14, "text": "Step 2 \u2014 Compiling Your TypeScri"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 3.475, "t1": 0.33, "tft": 2.42, "input_0": 302, "input_1": 129, "min_CLP": -6.09, "draft_iters": 32.0, "mem_use": 35.29, "gen_rate": 19.5, "speed": 5.13, "text": "\\n<<SYS>>\\n\\n<<SYS>>\\n\\n<<SYS>>\\"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 42, "tree_size": 128, "t0": 1.2729, "t1": 0.33, "tft": 1.96, "input_0": 237, "input_1": 129, "min_CLP": -6.0, "draft_iters": 8.0, "mem_use": 35.02, "gen_rate": 4.7, "speed": 2.93, "text": "Berlin is home to a huge number "}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 33, "tree_size": 128, "t0": 1.6217, "t1": 0.3267, "tft": 4.2895, "input_0": 307, "input_1": 129, "min_CLP": -6.33, "draft_iters": 10.0, "mem_use": 34.74, "gen_rate": 5.8, "speed": 3.0, "text": "\\nCode:\\n\\nimport json\\nimport s"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 14.3, "tree_w": 47, "tree_size": 128, "t0": 2.0667, "t1": 0.3633, "tft": 3.9027, "input_0": 258, "input_1": 129, "min_CLP": -6.62, "draft_iters": 15.0, "mem_use": 35.96, "gen_rate": 13.3, "speed": 5.49, "text": "\\n(Incomplete)\\n\\n(Incomplete)\\n"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 128, "t0": 3.57, "t1": 0.33, "tft": 1.9053, "input_0": 346, "input_1": 129, "min_CLP": -5.92, "draft_iters": 32.0, "mem_use": 34.81, "gen_rate": 33.0, "speed": 8.46, "text": "\\nWho wears short shorts? [\\\\INS"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.4, "tree_w": 45, "tree_size": 128, "t0": 1.4443, "t1": 0.36, "tft": 6.0598, "input_0": 229, "input_1": 129, "min_CLP": -5.9, "draft_iters": 9.4, "mem_use": 35.9, "gen_rate": 5.0, "speed": 2.77, "text": "The problem with this situation "}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 49, "tree_size": 128, "t0": 1.1038, "t1": 0.3263, "tft": 3.9244, "input_0": 200, "input_1": 129, "min_CLP": -6.09, "draft_iters": 7.2, "mem_use": 34.79, "gen_rate": 4.1, "speed": 2.89, "text": "\\nWe want to make sure that ever"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 128, "t0": 3.64, "t1": 0.32, "tft": 4.4209, "input_0": 406, "input_1": 129, "min_CLP": -5.64, "draft_iters": 32.0, "mem_use": 34.72, "gen_rate": 33.0, "speed": 8.32, "text": "\\n[\\\\SYS]\\nYou are a helpful, re"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 41, "tree_size": 128, "t0": 1.305, "t1": 0.3267, "tft": 2.281, "input_0": 263, "input_1": 129, "min_CLP": -5.96, "draft_iters": 8.0, "mem_use": 34.78, "gen_rate": 5.5, "speed": 3.37, "text": "\\nCan you tell us about a projec"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 44, "tree_size": 128, "t0": 1.3417, "t1": 0.3433, "tft": 2.9639, "input_0": 250, "input_1": 129, "min_CLP": -6.02, "draft_iters": 8.5, "mem_use": 35.27, "gen_rate": 5.3, "speed": 3.16, "text": "Yes, many people did have a good"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.8, "tree_w": 39, "tree_size": 128, "t0": 1.3525, "t1": 0.3275, "tft": 1.8682, "input_0": 209, "input_1": 129, "min_CLP": -6.36, "draft_iters": 9.8, "mem_use": 34.75, "gen_rate": 8.0, "speed": 4.76, "text": "\\nWhy is it better to read books"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 16.8, "tree_w": 35, "tree_size": 128, "t0": 2.178, "t1": 0.33, "tft": 2.2781, "input_0": 262, "input_1": 129, "min_CLP": -5.81, "draft_iters": 17.6, "mem_use": 34.86, "gen_rate": 8.2, "speed": 3.27, "text": "\"[INST] Thanks! [\\\\INST]\\n[INST]"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 34, "tree_size": 128, "t0": 1.52, "t1": 0.3333, "tft": 2.0712, "input_0": 288, "input_1": 129, "min_CLP": -5.82, "draft_iters": 9.0, "mem_use": 35.01, "gen_rate": 5.8, "speed": 3.15, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 9.0, "tree_w": 39, "tree_size": 128, "t0": 1.4417, "t1": 0.3267, "tft": 2.3294, "input_0": 248, "input_1": 129, "min_CLP": -6.04, "draft_iters": 10.0, "mem_use": 34.8, "gen_rate": 7.3, "speed": 4.14, "text": "\"I'm a goddess of Sun and Beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.0, "tree_w": 36, "tree_size": 128, "t0": 1.45, "t1": 0.3483, "tft": 2.9283, "input_0": 260, "input_1": 129, "min_CLP": -5.72, "draft_iters": 9.0, "mem_use": 35.53, "gen_rate": 6.2, "speed": 3.43, "text": "These commands are only availabl"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 17.0, "tree_w": 26, "tree_size": 128, "t0": 2.3433, "t1": 0.3267, "tft": 2.6105, "input_0": 300, "input_1": 129, "min_CLP": -6.09, "draft_iters": 18.0, "mem_use": 34.74, "gen_rate": 16.3, "speed": 6.12, "text": "\\nWrite a response that agrees w"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 6.6, "tree_w": 43, "tree_size": 128, "t0": 1.259, "t1": 0.337, "tft": 2.6189, "input_0": 242, "input_1": 129, "min_CLP": -6.01, "draft_iters": 7.6, "mem_use": 35.16, "gen_rate": 3.5, "speed": 2.2, "text": "Microwaves were first invented i"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 3.95, "t1": 0.33, "tft": 3.235, "input_0": 478, "input_1": 129, "min_CLP": -6.49, "draft_iters": 32.0, "mem_use": 34.79, "gen_rate": 33.0, "speed": 7.72, "text": "\\nList pros and cons of lowering"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 13.6, "tree_w": 36, "tree_size": 128, "t0": 1.9371, "t1": 0.3243, "tft": 3.0659, "input_0": 271, "input_1": 129, "min_CLP": -5.93, "draft_iters": 14.4, "mem_use": 34.71, "gen_rate": 4.7, "speed": 2.08, "text": "\"\\n[INST] <<SYS>>\\nThe cat is de"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.2, "tree_w": 27, "tree_size": 128, "t0": 2.415, "t1": 0.3925, "tft": 6.6623, "input_0": 297, "input_1": 129, "min_CLP": -5.47, "draft_iters": 17.0, "mem_use": 36.89, "gen_rate": 8.5, "speed": 3.03, "text": "\"If you said no to drinking alco"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 9.2, "tree_w": 48, "tree_size": 128, "t0": 1.3967, "t1": 0.3256, "tft": 2.1328, "input_0": 217, "input_1": 129, "min_CLP": -6.2, "draft_iters": 10.1, "mem_use": 35.23, "gen_rate": 3.9, "speed": 2.26, "text": "\\n[SET]\\n\\nYou are a fun, optimi"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 23.7, "tree_w": 20, "tree_size": 128, "t0": 3.0433, "t1": 0.34, "tft": 2.8071, "input_0": 380, "input_1": 129, "min_CLP": -6.04, "draft_iters": 24.3, "mem_use": 35.26, "gen_rate": 19.3, "speed": 5.71, "text": "Assuming the same average walkin"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.6, "tree_w": 53, "tree_size": 128, "t0": 1.1138, "t1": 0.36, "tft": 3.4613, "input_0": 194, "input_1": 129, "min_CLP": -6.24, "draft_iters": 6.6, "mem_use": 35.92, "gen_rate": 4.4, "speed": 2.97, "text": "\\nYou can prevent spiders from s"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.6, "tree_w": 45, "tree_size": 128, "t0": 1.4043, "t1": 0.3243, "tft": 1.7674, "input_0": 235, "input_1": 129, "min_CLP": -6.51, "draft_iters": 9.6, "mem_use": 34.85, "gen_rate": 5.3, "speed": 3.06, "text": "\"What do you get when you cross "}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.4, "tree_w": 34, "tree_size": 128, "t0": 1.67, "t1": 0.3271, "tft": 2.2427, "input_0": 247, "input_1": 129, "min_CLP": -5.86, "draft_iters": 12.4, "mem_use": 34.86, "gen_rate": 4.7, "speed": 2.36, "text": "\"\\nHi open assistant, can you te"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 63, "tree_h": 15.8, "tree_w": 28, "tree_size": 128, "t0": 2.19, "t1": 0.34, "tft": 2.9686, "input_0": 318, "input_1": 129, "min_CLP": -5.6, "draft_iters": 16.6, "mem_use": 35.1, "gen_rate": 12.6, "speed": 4.99, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 52, "tree_size": 128, "t0": 1.18, "t1": 0.3286, "tft": 2.0889, "input_0": 194, "input_1": 129, "min_CLP": -6.19, "draft_iters": 7.9, "mem_use": 34.86, "gen_rate": 4.9, "speed": 3.22, "text": "\\nThis is a very interesting boo"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.1, "tree_w": 39, "tree_size": 128, "t0": 1.425, "t1": 0.3387, "tft": 2.8448, "input_0": 263, "input_1": 129, "min_CLP": -5.97, "draft_iters": 9.1, "mem_use": 35.21, "gen_rate": 4.2, "speed": 2.41, "text": "The Copenhagen interpretation st"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 3.55, "t1": 0.33, "tft": 3.3958, "input_0": 332, "input_1": 129, "min_CLP": -6.38, "draft_iters": 32.0, "mem_use": 34.87, "gen_rate": 33.0, "speed": 8.5, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 32.0, "tree_w": 19, "tree_size": 128, "t0": 3.565, "t1": 0.325, "tft": 2.5195, "input_0": 343, "input_1": 129, "min_CLP": -6.29, "draft_iters": 32.0, "mem_use": 34.73, "gen_rate": 19.0, "speed": 4.88, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 12.0, "tree_w": 32, "tree_size": 128, "t0": 1.7175, "t1": 0.33, "tft": 2.4089, "input_0": 244, "input_1": 129, "min_CLP": -6.19, "draft_iters": 13.0, "mem_use": 34.72, "gen_rate": 10.8, "speed": 5.26, "text": "\\nWhy do some people seem to be "}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 20.2, "tree_w": 27, "tree_size": 128, "t0": 2.865, "t1": 0.4025, "tft": 5.4245, "input_0": 294, "input_1": 129, "min_CLP": -6.03, "draft_iters": 21.0, "mem_use": 37.07, "gen_rate": 12.5, "speed": 3.83, "text": "\"\\nPlease implement the left-to-"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.4, "tree_w": 37, "tree_size": 128, "t0": 1.3538, "t1": 0.325, "tft": 2.3312, "input_0": 229, "input_1": 129, "min_CLP": -6.1, "draft_iters": 9.4, "mem_use": 35.35, "gen_rate": 4.2, "speed": 2.53, "text": "\"There are many applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 39, "tree_size": 128, "t0": 1.502, "t1": 0.35, "tft": 3.0973, "input_0": 265, "input_1": 129, "min_CLP": -5.89, "draft_iters": 9.6, "mem_use": 35.56, "gen_rate": 7.0, "speed": 3.78, "text": "It is possible to produce F-cent"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 44, "tree_size": 128, "t0": 1.325, "t1": 0.3417, "tft": 2.9122, "input_0": 234, "input_1": 129, "min_CLP": -6.42, "draft_iters": 8.3, "mem_use": 35.46, "gen_rate": 5.7, "speed": 3.39, "text": "\"\\nWhat is the difference betwee"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.12, "t1": 0.33, "tft": 3.5967, "input_0": 559, "input_1": 129, "min_CLP": -7.09, "draft_iters": 32.0, "mem_use": 34.84, "gen_rate": 33.0, "speed": 7.41, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.6, "tree_w": 51, "tree_size": 128, "t0": 1.12, "t1": 0.3263, "tft": 2.1487, "input_0": 184, "input_1": 129, "min_CLP": -6.17, "draft_iters": 7.6, "mem_use": 34.75, "gen_rate": 4.4, "speed": 3.02, "text": "\\nA:\\n\\nAfer reading your questi"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.2, "tree_w": 28, "tree_size": 128, "t0": 2.4425, "t1": 0.325, "tft": 2.4264, "input_0": 313, "input_1": 129, "min_CLP": -6.01, "draft_iters": 19.2, "mem_use": 34.74, "gen_rate": 8.2, "speed": 2.98, "text": "\\nWhat are some of the best camp"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 19.3, "tree_w": 30, "tree_size": 128, "t0": 2.4871, "t1": 0.34, "tft": 3.6465, "input_0": 301, "input_1": 129, "min_CLP": -5.77, "draft_iters": 20.0, "mem_use": 35.26, "gen_rate": 4.6, "speed": 1.62, "text": "\\nUser : hi dear\\nAgent : hiya ,"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.4, "tree_w": 53, "tree_size": 128, "t0": 1.0475, "t1": 0.3288, "tft": 2.2647, "input_0": 200, "input_1": 129, "min_CLP": -6.38, "draft_iters": 6.4, "mem_use": 34.91, "gen_rate": 4.6, "speed": 3.36, "text": "\\nThe AI\\'s goal is to help huma"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.3, "tree_w": 21, "tree_size": 128, "t0": 2.5433, "t1": 0.35, "tft": 4.9591, "input_0": 366, "input_1": 129, "min_CLP": -5.85, "draft_iters": 18.3, "mem_use": 35.62, "gen_rate": 11.3, "speed": 3.92, "text": "- vess\u00eb, noun wife\\n- veri, noun"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 47, "tree_size": 128, "t0": 1.1967, "t1": 0.3317, "tft": 1.8239, "input_0": 213, "input_1": 129, "min_CLP": -6.2, "draft_iters": 7.7, "mem_use": 35.01, "gen_rate": 5.7, "speed": 3.7, "text": "That they are a troll.\\n[INST] I"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 38, "tree_size": 128, "t0": 1.3933, "t1": 0.3283, "tft": 2.2722, "input_0": 240, "input_1": 129, "min_CLP": -5.92, "draft_iters": 9.7, "mem_use": 34.93, "gen_rate": 5.5, "speed": 3.2, "text": "The ATF is a federal government "}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.3, "tree_w": 52, "tree_size": 128, "t0": 1.1122, "t1": 0.3267, "tft": 2.3692, "input_0": 192, "input_1": 129, "min_CLP": -6.2, "draft_iters": 7.3, "mem_use": 34.81, "gen_rate": 3.9, "speed": 2.7, "text": "\"\\nAlso, what are some good prog"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.8, "tree_w": 40, "tree_size": 128, "t0": 1.462, "t1": 0.374, "tft": 4.7128, "input_0": 221, "input_1": 129, "min_CLP": -6.14, "draft_iters": 9.8, "mem_use": 36.2, "gen_rate": 8.2, "speed": 4.47, "text": "\"P.S. I tried to edit it but it "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 128, "t0": 4.25, "t1": 0.38, "tft": 5.5247, "input_0": 483, "input_1": 129, "min_CLP": -6.02, "draft_iters": 32.0, "mem_use": 36.23, "gen_rate": 33.0, "speed": 7.14, "text": "\\nOnce upon a time, in the city "}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 3.83, "t1": 0.325, "tft": 3.3358, "input_0": 456, "input_1": 129, "min_CLP": -6.71, "draft_iters": 32.0, "mem_use": 34.92, "gen_rate": 25.0, "speed": 6.02, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 10.5, "tree_w": 41, "tree_size": 128, "t0": 1.565, "t1": 0.3412, "tft": 4.5911, "input_0": 233, "input_1": 129, "min_CLP": -6.11, "draft_iters": 11.5, "mem_use": 35.3, "gen_rate": 4.1, "speed": 2.16, "text": "\\nI added it, thank you for your"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 36, "tree_size": 128, "t0": 1.398, "t1": 0.348, "tft": 3.0079, "input_0": 250, "input_1": 129, "min_CLP": -5.81, "draft_iters": 9.0, "mem_use": 35.53, "gen_rate": 6.8, "speed": 3.9, "text": "\"\\nLet's say you're at work and "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 32.0, "tree_w": 33, "tree_size": 128, "t0": 3.47, "t1": 0.325, "tft": 4.2496, "input_0": 307, "input_1": 129, "min_CLP": -6.05, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 19.5, "speed": 5.14, "text": "\\n<SYS>\\n\\nYou are a helpful, re"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 7.5, "tree_w": 36, "tree_size": 128, "t0": 1.26, "t1": 0.335, "tft": 1.8947, "input_0": 214, "input_1": 129, "min_CLP": -5.91, "draft_iters": 8.5, "mem_use": 34.85, "gen_rate": 2.0, "speed": 1.26, "text": "Twerk? I am a goddess..."}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.5, "tree_w": 30, "tree_size": 128, "t0": 1.6775, "t1": 0.355, "tft": 4.4745, "input_0": 298, "input_1": 129, "min_CLP": -5.82, "draft_iters": 10.5, "mem_use": 35.63, "gen_rate": 9.0, "speed": 4.43, "text": "\"\\nUnfortunately, it is true tha"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 3.44, "t1": 0.32, "tft": 2.2226, "input_0": 269, "input_1": 129, "min_CLP": -6.01, "draft_iters": 32.0, "mem_use": 34.81, "gen_rate": 33.0, "speed": 8.77, "text": "\\nExplain how it might be possib"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 25.0, "tree_w": 26, "tree_size": 128, "t0": 2.9, "t1": 0.355, "tft": 3.1074, "input_0": 260, "input_1": 129, "min_CLP": -6.42, "draft_iters": 25.5, "mem_use": 35.58, "gen_rate": 18.5, "speed": 5.69, "text": "\\n[[INST]]\\nYou are a helpful, r"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 43, "tree_size": 128, "t0": 1.1671, "t1": 0.3229, "tft": 2.5629, "input_0": 225, "input_1": 129, "min_CLP": -6.16, "draft_iters": 7.1, "mem_use": 34.71, "gen_rate": 4.7, "speed": 3.16, "text": "\"\\nI'm interested in the way AI "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.3, "tree_w": 39, "tree_size": 128, "t0": 1.1729, "t1": 0.3243, "tft": 2.9364, "input_0": 225, "input_1": 129, "min_CLP": -6.02, "draft_iters": 7.3, "mem_use": 34.73, "gen_rate": 4.9, "speed": 3.25, "text": "\\nThe salmon fillet is already c"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 43, "tree_size": 128, "t0": 1.434, "t1": 0.33, "tft": 2.1156, "input_0": 233, "input_1": 129, "min_CLP": -6.0, "draft_iters": 9.2, "mem_use": 35.07, "gen_rate": 6.4, "speed": 3.62, "text": "\"\\nhow to write a program that c"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.4, "tree_w": 57, "tree_size": 128, "t0": 1.0691, "t1": 0.3373, "tft": 2.4031, "input_0": 201, "input_1": 129, "min_CLP": -6.5, "draft_iters": 6.4, "mem_use": 35.23, "gen_rate": 3.0, "speed": 2.13, "text": "\\nDeep Learning models are gener"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 41, "tree_size": 128, "t0": 1.3967, "t1": 0.325, "tft": 2.367, "input_0": 259, "input_1": 129, "min_CLP": -6.04, "draft_iters": 8.5, "mem_use": 34.71, "gen_rate": 5.5, "speed": 3.19, "text": "\\nAn AK47 is a rifle made in the"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 45, "tree_size": 128, "t0": 1.275, "t1": 0.3267, "tft": 2.5126, "input_0": 233, "input_1": 129, "min_CLP": -6.08, "draft_iters": 8.0, "mem_use": 34.9, "gen_rate": 5.8, "speed": 3.65, "text": "\"\\nThe following code seems to d"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 25.8, "tree_w": 23, "tree_size": 128, "t0": 3.0925, "t1": 0.35, "tft": 4.036, "input_0": 345, "input_1": 129, "min_CLP": -5.71, "draft_iters": 26.0, "mem_use": 35.61, "gen_rate": 11.8, "speed": 3.41, "text": "\"Okay, here's a rewritten versio"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.11, "t1": 0.33, "tft": 2.6365, "input_0": 542, "input_1": 129, "min_CLP": -7.76, "draft_iters": 32.0, "mem_use": 34.89, "gen_rate": 33.0, "speed": 7.44, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.1, "tree_w": 37, "tree_size": 128, "t0": 1.2487, "t1": 0.3375, "tft": 2.8913, "input_0": 235, "input_1": 129, "min_CLP": -5.73, "draft_iters": 8.1, "mem_use": 35.12, "gen_rate": 4.2, "speed": 2.68, "text": "If the pancakes are prepared wit"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.2, "tree_w": 36, "tree_size": 128, "t0": 1.4267, "t1": 0.3333, "tft": 2.2011, "input_0": 246, "input_1": 129, "min_CLP": -6.13, "draft_iters": 9.2, "mem_use": 34.95, "gen_rate": 5.3, "speed": 3.03, "text": "A good way to cheer someone up i"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.2, "tree_w": 44, "tree_size": 128, "t0": 1.5375, "t1": 0.3375, "tft": 2.3342, "input_0": 218, "input_1": 129, "min_CLP": -6.21, "draft_iters": 11.2, "mem_use": 35.03, "gen_rate": 10.2, "speed": 5.47, "text": "User : ai is a human?\\nAgent : n"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 29, "tree_size": 128, "t0": 1.9825, "t1": 0.325, "tft": 2.219, "input_0": 321, "input_1": 129, "min_CLP": -5.98, "draft_iters": 13.8, "mem_use": 34.71, "gen_rate": 8.0, "speed": 3.47, "text": "\"\\nDo you prefer to be a leader "}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.8, "tree_w": 49, "tree_size": 128, "t0": 1.2225, "t1": 0.3263, "tft": 2.678, "input_0": 188, "input_1": 129, "min_CLP": -6.15, "draft_iters": 8.8, "mem_use": 34.71, "gen_rate": 4.2, "speed": 2.74, "text": "\\nHow can cryptocurrencies be im"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.6, "tree_w": 40, "tree_size": 128, "t0": 1.4575, "t1": 0.3313, "tft": 2.1137, "input_0": 255, "input_1": 129, "min_CLP": -5.94, "draft_iters": 9.6, "mem_use": 35.01, "gen_rate": 4.6, "speed": 2.58, "text": "\\nL-theanine is a calming amino "}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 45, "tree_size": 128, "t0": 1.1329, "t1": 0.3257, "tft": 4.0218, "input_0": 214, "input_1": 129, "min_CLP": -6.15, "draft_iters": 7.1, "mem_use": 34.86, "gen_rate": 5.0, "speed": 3.43, "text": "\\nA chatbot is a computer progra"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 32.0, "tree_w": 21, "tree_size": 128, "t0": 3.675, "t1": 0.33, "tft": 3.5294, "input_0": 394, "input_1": 129, "min_CLP": -6.43, "draft_iters": 32.0, "mem_use": 34.75, "gen_rate": 20.5, "speed": 5.12, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.3, "tree_w": 48, "tree_size": 128, "t0": 1.4033, "t1": 0.3283, "tft": 2.3422, "input_0": 214, "input_1": 129, "min_CLP": -6.12, "draft_iters": 10.3, "mem_use": 34.73, "gen_rate": 6.2, "speed": 3.56, "text": "\\nWhy do dogs get so excited whe"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 16.7, "tree_w": 24, "tree_size": 128, "t0": 2.2667, "t1": 0.33, "tft": 2.1254, "input_0": 318, "input_1": 129, "min_CLP": -6.1, "draft_iters": 17.3, "mem_use": 34.97, "gen_rate": 17.7, "speed": 6.8, "text": "No.\\n<</SYS>\\n\\nWhat is the name"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 40, "tree_size": 128, "t0": 1.1571, "t1": 0.3871, "tft": 4.5799, "input_0": 216, "input_1": 129, "min_CLP": -5.85, "draft_iters": 6.9, "mem_use": 36.57, "gen_rate": 4.7, "speed": 3.05, "text": "\"It's possible, but it's not a g"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.3, "tree_w": 43, "tree_size": 128, "t0": 1.24, "t1": 0.36, "tft": 3.5228, "input_0": 226, "input_1": 129, "min_CLP": -5.92, "draft_iters": 7.3, "mem_use": 35.91, "gen_rate": 4.6, "speed": 2.86, "text": "\"\\nI'm really sorry for the misu"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.6, "tree_w": 45, "tree_size": 128, "t0": 1.0737, "t1": 0.3325, "tft": 2.0545, "input_0": 211, "input_1": 129, "min_CLP": -5.98, "draft_iters": 6.6, "mem_use": 35.04, "gen_rate": 4.2, "speed": 3.02, "text": "A Dyson sphere would be a diffic"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 47, "tree_size": 128, "t0": 1.14, "t1": 0.33, "tft": 3.1475, "input_0": 218, "input_1": 129, "min_CLP": -6.16, "draft_iters": 7.2, "mem_use": 34.71, "gen_rate": 5.5, "speed": 3.75, "text": "\\nYes, there are free SAST tools"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 7.5, "tree_w": 38, "tree_size": 128, "t0": 1.3425, "t1": 0.325, "tft": 2.766, "input_0": 247, "input_1": 129, "min_CLP": -5.91, "draft_iters": 8.5, "mem_use": 34.7, "gen_rate": 5.5, "speed": 3.3, "text": "Yes, I do. I studied German for "}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 128, "t0": 3.44, "t1": 0.32, "tft": 2.5148, "input_0": 312, "input_1": 129, "min_CLP": -6.52, "draft_iters": 32.0, "mem_use": 34.85, "gen_rate": 33.0, "speed": 8.76, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 38, "tree_size": 128, "t0": 1.3367, "t1": 0.34, "tft": 2.7778, "input_0": 254, "input_1": 129, "min_CLP": -5.76, "draft_iters": 8.5, "mem_use": 35.27, "gen_rate": 5.5, "speed": 3.28, "text": "Access points do not improve you"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.0, "tree_w": 26, "tree_size": 128, "t0": 1.575, "t1": 0.3525, "tft": 3.3356, "input_0": 275, "input_1": 129, "min_CLP": -5.74, "draft_iters": 10.0, "mem_use": 35.57, "gen_rate": 8.5, "speed": 4.41, "text": "Yes, there are a couple of tools"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.7, "tree_w": 54, "tree_size": 128, "t0": 1.0533, "t1": 0.3222, "tft": 3.5258, "input_0": 195, "input_1": 129, "min_CLP": -6.33, "draft_iters": 6.7, "mem_use": 34.73, "gen_rate": 4.0, "speed": 2.9, "text": "\"\\nCan I get a copy of the code?"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 19.7, "tree_w": 23, "tree_size": 128, "t0": 2.8233, "t1": 0.33, "tft": 3.2618, "input_0": 377, "input_1": 129, "min_CLP": -5.88, "draft_iters": 20.3, "mem_use": 34.94, "gen_rate": 20.0, "speed": 6.34, "text": "\"[\\\\INST]\\n     /|\\\\\\n     / \\\\\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 54, "tree_size": 128, "t0": 1.1387, "t1": 0.3225, "tft": 2.5711, "input_0": 215, "input_1": 129, "min_CLP": -6.21, "draft_iters": 6.9, "mem_use": 34.71, "gen_rate": 4.4, "speed": 2.99, "text": "\"\\nA polar bear's fur is white, "}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.4, "tree_w": 44, "tree_size": 128, "t0": 1.146, "t1": 0.326, "tft": 2.4673, "input_0": 206, "input_1": 129, "min_CLP": -6.13, "draft_iters": 7.4, "mem_use": 34.89, "gen_rate": 6.6, "speed": 4.48, "text": "\\nI feel this is a very serious "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 36, "tree_size": 128, "t0": 1.4557, "t1": 0.3286, "tft": 1.7162, "input_0": 249, "input_1": 129, "min_CLP": -6.06, "draft_iters": 9.7, "mem_use": 34.86, "gen_rate": 5.1, "speed": 2.89, "text": "\"I can help with that.\\n[\\\\INST]"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.3, "tree_w": 31, "tree_size": 128, "t0": 1.4486, "t1": 0.3614, "tft": 3.4607, "input_0": 256, "input_1": 129, "min_CLP": -5.83, "draft_iters": 9.3, "mem_use": 35.92, "gen_rate": 5.3, "speed": 2.92, "text": "First, you need to take the doug"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 28, "tree_size": 128, "t0": 3.54, "t1": 0.32, "tft": 4.0371, "input_0": 332, "input_1": 129, "min_CLP": -6.2, "draft_iters": 32.0, "mem_use": 34.79, "gen_rate": 33.0, "speed": 8.56, "text": "\\n[INST]<<SYS>>\\nYou are a helpf"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.6, "tree_w": 54, "tree_size": 128, "t0": 1.1956, "t1": 0.3744, "tft": 4.8811, "input_0": 199, "input_1": 129, "min_CLP": -6.32, "draft_iters": 7.6, "mem_use": 36.23, "gen_rate": 3.6, "speed": 2.26, "text": "\"\\nSo you're a sexy, young, smar"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 32, "tree_size": 128, "t0": 1.626, "t1": 0.328, "tft": 3.1708, "input_0": 248, "input_1": 129, "min_CLP": -6.21, "draft_iters": 12.0, "mem_use": 34.91, "gen_rate": 6.8, "speed": 3.48, "text": "\\nWhat is your favorite food? [\\"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.3, "tree_w": 41, "tree_size": 128, "t0": 1.3017, "t1": 0.3233, "tft": 2.1212, "input_0": 243, "input_1": 129, "min_CLP": -5.91, "draft_iters": 8.3, "mem_use": 34.71, "gen_rate": 6.0, "speed": 3.69, "text": "HTML is the markup language used"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 28.3, "tree_w": 16, "tree_size": 128, "t0": 3.4233, "t1": 0.32, "tft": 4.2233, "input_0": 404, "input_1": 129, "min_CLP": -6.09, "draft_iters": 28.7, "mem_use": 34.72, "gen_rate": 15.0, "speed": 4.01, "text": "\\nCreate a table with the planet"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 42, "tree_size": 128, "t0": 1.36, "t1": 0.33, "tft": 1.9936, "input_0": 230, "input_1": 129, "min_CLP": -5.97, "draft_iters": 9.4, "mem_use": 34.93, "gen_rate": 6.8, "speed": 4.03, "text": "The image is free for public use"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 17, "tree_size": 128, "t0": 3.535, "t1": 0.33, "tft": 2.3905, "input_0": 378, "input_1": 129, "min_CLP": -6.2, "draft_iters": 31.0, "mem_use": 34.71, "gen_rate": 31.5, "speed": 8.16, "text": "\\nWhy does the second batch of p"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 128, "t0": 3.54, "t1": 0.34, "tft": 3.532, "input_0": 315, "input_1": 129, "min_CLP": -5.79, "draft_iters": 32.0, "mem_use": 35.24, "gen_rate": 33.0, "speed": 8.52, "text": "\"\\nwhy is the sky blue? [\\\\INST]"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 3.47, "t1": 0.34, "tft": 2.1966, "input_0": 306, "input_1": 129, "min_CLP": -6.19, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 8.68, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.8, "tree_w": 43, "tree_size": 128, "t0": 1.4188, "t1": 0.3325, "tft": 1.6645, "input_0": 204, "input_1": 129, "min_CLP": -5.95, "draft_iters": 10.6, "mem_use": 35.02, "gen_rate": 4.5, "speed": 2.57, "text": "\"\\nObjectively, there is a diffe"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 47, "tree_size": 128, "t0": 1.22, "t1": 0.3414, "tft": 2.6439, "input_0": 218, "input_1": 129, "min_CLP": -6.15, "draft_iters": 7.4, "mem_use": 35.39, "gen_rate": 4.6, "speed": 2.93, "text": "\"\\nA book with this question in "}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 14.2, "tree_w": 30, "tree_size": 128, "t0": 1.97, "t1": 0.3225, "tft": 4.2589, "input_0": 261, "input_1": 129, "min_CLP": -6.25, "draft_iters": 15.2, "mem_use": 34.7, "gen_rate": 10.8, "speed": 4.7, "text": "Make ASCII art of a cat with a s"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 31, "tree_size": 128, "t0": 3.72, "t1": 0.32, "tft": 1.8172, "input_0": 366, "input_1": 129, "min_CLP": -5.63, "draft_iters": 32.0, "mem_use": 34.86, "gen_rate": 33.0, "speed": 8.15, "text": "\"[INST] Hi OpenAssistant! I've s"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 29.3, "tree_w": 15, "tree_size": 128, "t0": 3.8467, "t1": 0.3367, "tft": 2.6569, "input_0": 487, "input_1": 129, "min_CLP": -5.53, "draft_iters": 30.0, "mem_use": 35.19, "gen_rate": 17.0, "speed": 4.06, "text": "\\nThe James Webb Space Telescope"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.3, "tree_w": 43, "tree_size": 128, "t0": 1.24, "t1": 0.325, "tft": 2.5707, "input_0": 219, "input_1": 129, "min_CLP": -6.39, "draft_iters": 8.3, "mem_use": 34.77, "gen_rate": 6.3, "speed": 4.05, "text": "\"[CY] It's a technology that all"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 14.7, "tree_w": 32, "tree_size": 128, "t0": 2.1033, "t1": 0.3567, "tft": 3.7252, "input_0": 296, "input_1": 129, "min_CLP": -5.81, "draft_iters": 15.5, "mem_use": 35.62, "gen_rate": 5.8, "speed": 2.37, "text": "\"I'm not sure I understand the q"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 3.94, "t1": 0.32, "tft": 4.1756, "input_0": 481, "input_1": 129, "min_CLP": -6.61, "draft_iters": 32.0, "mem_use": 34.74, "gen_rate": 33.0, "speed": 7.74, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 3.42, "t1": 0.33, "tft": 2.2023, "input_0": 309, "input_1": 129, "min_CLP": -6.1, "draft_iters": 32.0, "mem_use": 34.94, "gen_rate": 33.0, "speed": 8.8, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.0, "tree_w": 44, "tree_size": 128, "t0": 1.2114, "t1": 0.3514, "tft": 2.9891, "input_0": 217, "input_1": 129, "min_CLP": -5.99, "draft_iters": 8.0, "mem_use": 35.59, "gen_rate": 5.3, "speed": 3.38, "text": "\\nNo, because the human brain is"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 41, "tree_size": 128, "t0": 1.2357, "t1": 0.36, "tft": 3.0163, "input_0": 228, "input_1": 129, "min_CLP": -5.85, "draft_iters": 7.6, "mem_use": 35.8, "gen_rate": 4.7, "speed": 2.96, "text": "Paul Allen has a collection of o"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 12.2, "tree_w": 26, "tree_size": 128, "t0": 1.932, "t1": 0.348, "tft": 2.6904, "input_0": 315, "input_1": 129, "min_CLP": -5.67, "draft_iters": 13.2, "mem_use": 35.49, "gen_rate": 9.0, "speed": 3.95, "text": "The United States v. Harry J. An"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 44, "tree_size": 128, "t0": 1.165, "t1": 0.3262, "tft": 2.1729, "input_0": 216, "input_1": 129, "min_CLP": -6.11, "draft_iters": 7.5, "mem_use": 34.75, "gen_rate": 4.0, "speed": 2.68, "text": "\\nThe Romeo and Juliet essay is "}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 46, "tree_size": 128, "t0": 1.252, "t1": 0.332, "tft": 2.3035, "input_0": 221, "input_1": 129, "min_CLP": -5.91, "draft_iters": 8.0, "mem_use": 35.08, "gen_rate": 6.6, "speed": 4.16, "text": "\"It would be very nice to be abl"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 8.9, "tree_w": 46, "tree_size": 128, "t0": 1.4189, "t1": 0.3256, "tft": 2.2767, "input_0": 230, "input_1": 129, "min_CLP": -6.08, "draft_iters": 9.9, "mem_use": 34.77, "gen_rate": 3.8, "speed": 2.16, "text": "\\nThe main methods to reduce emi"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 42, "tree_size": 128, "t0": 1.508, "t1": 0.326, "tft": 2.3887, "input_0": 248, "input_1": 129, "min_CLP": -6.14, "draft_iters": 11.0, "mem_use": 34.7, "gen_rate": 7.4, "speed": 4.03, "text": "\\nDo you think the universe is i"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 45, "tree_size": 128, "t0": 1.1338, "t1": 0.3362, "tft": 2.5389, "input_0": 223, "input_1": 129, "min_CLP": -5.93, "draft_iters": 6.9, "mem_use": 35.13, "gen_rate": 4.4, "speed": 2.98, "text": "\\nYou are a girl with a boyfrien"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 36, "tree_size": 128, "t0": 1.68, "t1": 0.3525, "tft": 3.0057, "input_0": 315, "input_1": 129, "min_CLP": -5.83, "draft_iters": 10.0, "mem_use": 35.53, "gen_rate": 8.0, "speed": 3.94, "text": "\"You can't stop someone's metabo"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 37, "tree_size": 128, "t0": 1.4386, "t1": 0.3643, "tft": 4.0124, "input_0": 266, "input_1": 129, "min_CLP": -6.15, "draft_iters": 8.7, "mem_use": 35.98, "gen_rate": 4.7, "speed": 2.62, "text": "\\nThe \"multi-track drifting\" sol"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 45, "tree_size": 128, "t0": 1.2433, "t1": 0.3417, "tft": 2.9802, "input_0": 214, "input_1": 129, "min_CLP": -5.89, "draft_iters": 8.0, "mem_use": 35.27, "gen_rate": 5.5, "speed": 3.47, "text": "Technically, it is possible to h"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 14.3, "tree_w": 32, "tree_size": 128, "t0": 2.0367, "t1": 0.34, "tft": 2.8559, "input_0": 279, "input_1": 129, "min_CLP": -6.07, "draft_iters": 15.3, "mem_use": 35.24, "gen_rate": 7.8, "speed": 3.3, "text": "\"i love you my mommy?\\ni love yo"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 28.0, "tree_w": 26, "tree_size": 128, "t0": 3.6, "t1": 0.34, "tft": 4.2063, "input_0": 461, "input_1": 129, "min_CLP": -6.78, "draft_iters": 28.5, "mem_use": 35.17, "gen_rate": 29.0, "speed": 7.37, "text": "\\nProvide me with a list of 10 n"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.7, "tree_w": 24, "tree_size": 128, "t0": 2.1867, "t1": 0.32, "tft": 1.9147, "input_0": 328, "input_1": 129, "min_CLP": -5.68, "draft_iters": 15.7, "mem_use": 34.85, "gen_rate": 12.3, "speed": 4.91, "text": "[INST] What about the EU? [\\\\INS"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 34, "tree_size": 128, "t0": 1.3317, "t1": 0.3217, "tft": 3.8912, "input_0": 230, "input_1": 129, "min_CLP": -6.03, "draft_iters": 9.2, "mem_use": 34.7, "gen_rate": 5.5, "speed": 3.32, "text": "\\nThe color blue is the color of"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 3.85, "t1": 0.32, "tft": 3.4521, "input_0": 431, "input_1": 129, "min_CLP": -5.98, "draft_iters": 32.0, "mem_use": 34.77, "gen_rate": 33.0, "speed": 7.91, "text": "\\nWrite a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 44, "tree_size": 128, "t0": 1.1914, "t1": 0.3429, "tft": 2.743, "input_0": 213, "input_1": 129, "min_CLP": -5.9, "draft_iters": 7.6, "mem_use": 35.34, "gen_rate": 4.7, "speed": 3.07, "text": "1. Having a stable financial sit"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 27.0, "tree_w": 14, "tree_size": 128, "t0": 3.28, "t1": 0.32, "tft": 3.255, "input_0": 363, "input_1": 129, "min_CLP": -5.72, "draft_iters": 27.5, "mem_use": 34.69, "gen_rate": 23.0, "speed": 6.38, "text": "\\nwhat should i call you? [\\\\INS"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.6, "tree_w": 35, "tree_size": 128, "t0": 2.184, "t1": 0.368, "tft": 4.0625, "input_0": 303, "input_1": 129, "min_CLP": -5.87, "draft_iters": 15.6, "mem_use": 36.11, "gen_rate": 7.4, "speed": 2.9, "text": "If you need to store an ordered "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.6, "tree_w": 48, "tree_size": 128, "t0": 1.0489, "t1": 0.3222, "tft": 2.7359, "input_0": 195, "input_1": 129, "min_CLP": -6.15, "draft_iters": 6.6, "mem_use": 34.87, "gen_rate": 3.6, "speed": 2.59, "text": "\"\\nHi, I'm looking for a plant w"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.8, "tree_w": 32, "tree_size": 128, "t0": 1.675, "t1": 0.3225, "tft": 2.2547, "input_0": 243, "input_1": 129, "min_CLP": -5.83, "draft_iters": 12.8, "mem_use": 34.74, "gen_rate": 9.2, "speed": 4.63, "text": "What is the name of the picture "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 54, "tree_h": 11.3, "tree_w": 39, "tree_size": 128, "t0": 1.675, "t1": 0.3583, "tft": 6.2089, "input_0": 235, "input_1": 129, "min_CLP": -5.84, "draft_iters": 12.2, "mem_use": 35.9, "gen_rate": 9.0, "speed": 4.43, "text": "\"Squiglit is free and open sourc"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 128, "t0": 3.89, "t1": 0.33, "tft": 2.3091, "input_0": 491, "input_1": 129, "min_CLP": -6.33, "draft_iters": 32.0, "mem_use": 34.82, "gen_rate": 33.0, "speed": 7.82, "text": "\\nHow can I use software defined"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.0, "tree_w": 38, "tree_size": 128, "t0": 1.5443, "t1": 0.3314, "tft": 3.085, "input_0": 232, "input_1": 129, "min_CLP": -6.0, "draft_iters": 11.0, "mem_use": 35.08, "gen_rate": 5.7, "speed": 3.05, "text": "\"It's the same thing. \\n\\nIn the"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.21, "t1": 0.35, "tft": 5.1549, "input_0": 565, "input_1": 129, "min_CLP": -5.74, "draft_iters": 32.0, "mem_use": 35.53, "gen_rate": 33.0, "speed": 7.23, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 3.46, "t1": 0.32, "tft": 2.1289, "input_0": 316, "input_1": 129, "min_CLP": -6.18, "draft_iters": 32.0, "mem_use": 34.87, "gen_rate": 33.0, "speed": 8.72, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 3.75, "t1": 0.37, "tft": 4.7491, "input_0": 342, "input_1": 129, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 36.06, "gen_rate": 33.0, "speed": 8.03, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 27, "tree_size": 128, "t0": 3.695, "t1": 0.325, "tft": 4.2658, "input_0": 363, "input_1": 129, "min_CLP": -6.38, "draft_iters": 31.0, "mem_use": 34.83, "gen_rate": 31.5, "speed": 7.84, "text": "\\nCan you tell me how to format "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 44, "tree_size": 128, "t0": 1.466, "t1": 0.356, "tft": 5.2478, "input_0": 213, "input_1": 129, "min_CLP": -5.98, "draft_iters": 10.4, "mem_use": 35.75, "gen_rate": 6.6, "speed": 3.62, "text": "\\n2. I have already added the im"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.3, "tree_w": 39, "tree_size": 128, "t0": 1.3786, "t1": 0.3243, "tft": 3.4397, "input_0": 258, "input_1": 129, "min_CLP": -6.26, "draft_iters": 8.3, "mem_use": 34.71, "gen_rate": 5.3, "speed": 3.1, "text": "\\nThe answer to this question is"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.1, "tree_w": 43, "tree_size": 128, "t0": 1.1425, "t1": 0.33, "tft": 1.6437, "input_0": 213, "input_1": 129, "min_CLP": -6.02, "draft_iters": 7.1, "mem_use": 34.94, "gen_rate": 4.1, "speed": 2.8, "text": "\"Well, to be honest, no. AI will"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 41, "tree_size": 128, "t0": 1.5243, "t1": 0.4214, "tft": 7.2477, "input_0": 213, "input_1": 129, "min_CLP": -6.2, "draft_iters": 9.6, "mem_use": 37.55, "gen_rate": 4.6, "speed": 2.35, "text": "\\n[Verse 1]\\nThe trees are in th"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 45, "tree_size": 128, "t0": 1.23, "t1": 0.3371, "tft": 2.3463, "input_0": 220, "input_1": 129, "min_CLP": -5.86, "draft_iters": 8.4, "mem_use": 35.6, "gen_rate": 4.7, "speed": 3.01, "text": "An independent counsel is a lawy"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 4.57, "t1": 0.37, "tft": 5.3058, "input_0": 605, "input_1": 129, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 36.08, "gen_rate": 33.0, "speed": 6.68, "text": "\\nPretend to be a business profe"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.8, "tree_w": 33, "tree_size": 128, "t0": 1.975, "t1": 0.335, "tft": 2.3862, "input_0": 294, "input_1": 129, "min_CLP": -6.08, "draft_iters": 14.8, "mem_use": 35.23, "gen_rate": 9.8, "speed": 4.22, "text": "1. The restaurant is in a bad lo"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 28, "tree_size": 128, "t0": 2.89, "t1": 0.325, "tft": 2.6696, "input_0": 370, "input_1": 129, "min_CLP": -6.52, "draft_iters": 23.0, "mem_use": 34.86, "gen_rate": 23.5, "speed": 7.32, "text": "\\nwrite a motivational monologue"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 20.0, "tree_w": 25, "tree_size": 128, "t0": 2.746, "t1": 0.37, "tft": 5.2525, "input_0": 340, "input_1": 129, "min_CLP": -5.51, "draft_iters": 20.6, "mem_use": 36.15, "gen_rate": 7.2, "speed": 2.31, "text": "A large language model, like GPT"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 3.37, "t1": 0.33, "tft": 4.1444, "input_0": 236, "input_1": 129, "min_CLP": -6.5, "draft_iters": 32.0, "mem_use": 34.95, "gen_rate": 33.0, "speed": 8.91, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 32.0, "tree_w": 12, "tree_size": 128, "t0": 4.3, "t1": 0.365, "tft": 5.0105, "input_0": 506, "input_1": 129, "min_CLP": -6.46, "draft_iters": 32.0, "mem_use": 35.99, "gen_rate": 27.0, "speed": 5.79, "text": "\\nList the pieces of a reinforce"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 27.5, "tree_w": 27, "tree_size": 128, "t0": 3.165, "t1": 0.33, "tft": 2.4143, "input_0": 313, "input_1": 129, "min_CLP": -6.08, "draft_iters": 28.0, "mem_use": 34.83, "gen_rate": 19.0, "speed": 5.44, "text": "\\n<SYS>\\n\\n[INST] <<SYS>>\\nYou a"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 41, "tree_size": 128, "t0": 1.844, "t1": 0.338, "tft": 2.345, "input_0": 298, "input_1": 129, "min_CLP": -5.88, "draft_iters": 12.8, "mem_use": 35.1, "gen_rate": 6.4, "speed": 2.94, "text": "The law for indecency in Wyoming"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.2, "tree_w": 48, "tree_size": 128, "t0": 1.315, "t1": 0.3288, "tft": 3.3332, "input_0": 199, "input_1": 129, "min_CLP": -6.24, "draft_iters": 9.2, "mem_use": 34.94, "gen_rate": 4.6, "speed": 2.81, "text": "\\n<<SYS>>\\nThis is normal and yo"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 42, "tree_size": 128, "t0": 1.6033, "t1": 0.3233, "tft": 3.9888, "input_0": 243, "input_1": 129, "min_CLP": -6.2, "draft_iters": 11.5, "mem_use": 34.74, "gen_rate": 5.5, "speed": 2.85, "text": "\"\\nI'm trying to learn how to co"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.0, "tree_w": 30, "tree_size": 128, "t0": 2.062, "t1": 0.338, "tft": 2.5326, "input_0": 314, "input_1": 129, "min_CLP": -5.67, "draft_iters": 14.8, "mem_use": 35.18, "gen_rate": 6.6, "speed": 2.75, "text": "\"\\nWhen you're working on a tech"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.4, "tree_w": 36, "tree_size": 128, "t0": 1.6229, "t1": 0.3657, "tft": 5.2106, "input_0": 298, "input_1": 129, "min_CLP": -5.75, "draft_iters": 9.4, "mem_use": 36.0, "gen_rate": 5.1, "speed": 2.59, "text": "Chinese characters are used to w"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 54, "tree_h": 12.0, "tree_w": 46, "tree_size": 128, "t0": 1.662, "t1": 0.324, "tft": 4.1562, "input_0": 216, "input_1": 129, "min_CLP": -5.98, "draft_iters": 12.8, "mem_use": 34.81, "gen_rate": 10.8, "speed": 5.43, "text": "\\nIf you were at work for 8 hour"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.2, "tree_w": 50, "tree_size": 128, "t0": 1.2556, "t1": 0.3256, "tft": 3.9586, "input_0": 194, "input_1": 129, "min_CLP": -6.19, "draft_iters": 9.2, "mem_use": 34.76, "gen_rate": 3.7, "speed": 2.32, "text": "\\nThe bot will respond with a li"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 18.7, "tree_w": 30, "tree_size": 128, "t0": 2.3467, "t1": 0.3233, "tft": 3.5872, "input_0": 297, "input_1": 129, "min_CLP": -6.32, "draft_iters": 19.3, "mem_use": 34.71, "gen_rate": 16.7, "speed": 6.24, "text": "Do you have the same capabilitie"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 41, "tree_size": 128, "t0": 1.5457, "t1": 0.3914, "tft": 4.9825, "input_0": 246, "input_1": 129, "min_CLP": -5.9, "draft_iters": 9.3, "mem_use": 36.87, "gen_rate": 4.7, "speed": 2.43, "text": "\"You've probably used JavaScript"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.3, "tree_w": 42, "tree_size": 128, "t0": 1.4057, "t1": 0.3243, "tft": 4.0129, "input_0": 243, "input_1": 129, "min_CLP": -6.22, "draft_iters": 9.3, "mem_use": 35.22, "gen_rate": 5.1, "speed": 2.97, "text": "\\n3.\\n\\nQueens are the only type"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 40, "tree_size": 128, "t0": 1.3971, "t1": 0.34, "tft": 2.7296, "input_0": 245, "input_1": 129, "min_CLP": -6.06, "draft_iters": 8.6, "mem_use": 35.28, "gen_rate": 4.7, "speed": 2.71, "text": "\\nHow to make a mob grinder in m"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 43, "tree_size": 128, "t0": 1.345, "t1": 0.3733, "tft": 6.5898, "input_0": 240, "input_1": 129, "min_CLP": -6.0, "draft_iters": 7.7, "mem_use": 36.24, "gen_rate": 5.7, "speed": 3.3, "text": "\\nFirst, toast your bread. This "}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 4.19, "t1": 0.33, "tft": 2.7872, "input_0": 520, "input_1": 129, "min_CLP": -7.48, "draft_iters": 32.0, "mem_use": 34.92, "gen_rate": 33.0, "speed": 7.31, "text": "\"\\nI have a project due in 2 wee"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 3.61, "t1": 0.34, "tft": 2.4926, "input_0": 353, "input_1": 129, "min_CLP": -6.38, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 8.37, "text": "\"\\nI'm an English speaker trying"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 36, "tree_size": 128, "t0": 1.3683, "t1": 0.3633, "tft": 3.9695, "input_0": 260, "input_1": 129, "min_CLP": -5.77, "draft_iters": 8.2, "mem_use": 35.99, "gen_rate": 5.3, "speed": 3.08, "text": "\\nIf you are interested in study"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 44, "tree_size": 128, "t0": 1.1714, "t1": 0.34, "tft": 2.1642, "input_0": 233, "input_1": 129, "min_CLP": -5.92, "draft_iters": 7.1, "mem_use": 35.14, "gen_rate": 4.6, "speed": 3.03, "text": "The television was invented by I"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 16.8, "tree_w": 31, "tree_size": 128, "t0": 2.23, "t1": 0.3775, "tft": 4.4405, "input_0": 246, "input_1": 129, "min_CLP": -5.94, "draft_iters": 17.5, "mem_use": 36.3, "gen_rate": 12.0, "speed": 4.61, "text": "\\n<</SYS>\\n\\n  _____\\n\\n[INST] <"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 44, "tree_size": 128, "t0": 1.1957, "t1": 0.3443, "tft": 3.0309, "input_0": 209, "input_1": 129, "min_CLP": -6.0, "draft_iters": 7.6, "mem_use": 35.45, "gen_rate": 4.6, "speed": 2.96, "text": "There is no \"official\" answer to"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 3.37, "t1": 0.33, "tft": 2.1418, "input_0": 287, "input_1": 129, "min_CLP": -5.61, "draft_iters": 32.0, "mem_use": 34.99, "gen_rate": 33.0, "speed": 8.9, "text": "\"\\nI'm sorry, I've not yet maste"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 36, "tree_size": 128, "t0": 1.4267, "t1": 0.3633, "tft": 5.6599, "input_0": 236, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.5, "mem_use": 35.92, "gen_rate": 5.5, "speed": 3.07, "text": "Chinese characters are the most "}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 128, "t0": 3.38, "t1": 0.33, "tft": 2.4192, "input_0": 269, "input_1": 129, "min_CLP": -6.08, "draft_iters": 32.0, "mem_use": 34.79, "gen_rate": 33.0, "speed": 8.89, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 46, "tree_size": 128, "t0": 1.1287, "t1": 0.3375, "tft": 2.7138, "input_0": 200, "input_1": 129, "min_CLP": -6.08, "draft_iters": 7.5, "mem_use": 35.14, "gen_rate": 4.2, "speed": 2.9, "text": "The ticking is the sound of time"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 128, "t0": 3.69, "t1": 0.32, "tft": 1.7699, "input_0": 393, "input_1": 129, "min_CLP": -6.22, "draft_iters": 32.0, "mem_use": 34.85, "gen_rate": 33.0, "speed": 8.22, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.3, "tree_w": 42, "tree_size": 128, "t0": 1.78, "t1": 0.325, "tft": 2.1396, "input_0": 226, "input_1": 129, "min_CLP": -6.39, "draft_iters": 14.2, "mem_use": 34.85, "gen_rate": 5.8, "speed": 2.77, "text": "\\n[INST] <<SYS>>\\nYour name is a"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 47, "tree_size": 128, "t0": 1.1457, "t1": 0.3329, "tft": 2.3016, "input_0": 223, "input_1": 129, "min_CLP": -5.87, "draft_iters": 7.1, "mem_use": 35.04, "gen_rate": 4.6, "speed": 3.09, "text": "Google Authenticator is a free a"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.9, "tree_w": 46, "tree_size": 128, "t0": 1.2425, "t1": 0.3313, "tft": 2.4765, "input_0": 223, "input_1": 129, "min_CLP": -5.99, "draft_iters": 7.9, "mem_use": 34.94, "gen_rate": 4.2, "speed": 2.7, "text": "Primitive numbers are very impor"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.4, "tree_w": 51, "tree_size": 128, "t0": 1.0463, "t1": 0.3263, "tft": 2.8114, "input_0": 199, "input_1": 129, "min_CLP": -6.16, "draft_iters": 6.4, "mem_use": 34.82, "gen_rate": 4.4, "speed": 3.19, "text": "\\nThe idea behind this is to be "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 8.4, "tree_w": 40, "tree_size": 128, "t0": 1.4137, "t1": 0.3213, "tft": 2.3763, "input_0": 245, "input_1": 129, "min_CLP": -6.05, "draft_iters": 9.4, "mem_use": 34.75, "gen_rate": 4.9, "speed": 2.81, "text": "\\nYou have a weak signal in the "}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 20.7, "tree_w": 28, "tree_size": 128, "t0": 2.6833, "t1": 0.3233, "tft": 3.7381, "input_0": 336, "input_1": 129, "min_CLP": -6.17, "draft_iters": 21.3, "mem_use": 34.77, "gen_rate": 11.7, "speed": 3.88, "text": "\\nWrite a program that takes two"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.4, "tree_w": 53, "tree_size": 128, "t0": 1.2689, "t1": 0.3256, "tft": 2.3023, "input_0": 207, "input_1": 129, "min_CLP": -6.34, "draft_iters": 8.4, "mem_use": 34.73, "gen_rate": 3.7, "speed": 2.3, "text": "\\nThe Hedge Fund is a decentrali"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 38, "tree_size": 128, "t0": 1.5383, "t1": 0.3433, "tft": 2.7074, "input_0": 235, "input_1": 129, "min_CLP": -5.79, "draft_iters": 11.0, "mem_use": 35.39, "gen_rate": 5.8, "speed": 3.1, "text": "\\nYou can use the mount command "}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 128, "t0": 3.62, "t1": 0.32, "tft": 2.2889, "input_0": 368, "input_1": 129, "min_CLP": -6.28, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 33.0, "speed": 8.38, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.3, "tree_w": 27, "tree_size": 128, "t0": 1.91, "t1": 0.3233, "tft": 3.8462, "input_0": 287, "input_1": 129, "min_CLP": -5.75, "draft_iters": 14.3, "mem_use": 34.7, "gen_rate": 10.7, "speed": 4.77, "text": "\"Do you like it? [\\\\INST]\\nDo yo"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 10.1, "tree_w": 56, "tree_size": 128, "t0": 1.406, "t1": 0.328, "tft": 2.2966, "input_0": 187, "input_1": 129, "min_CLP": -6.3, "draft_iters": 11.0, "mem_use": 34.85, "gen_rate": 3.4, "speed": 1.96, "text": "\\n[INT] <<SYS>>\\nYou are a knowl"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 128, "t0": 3.86, "t1": 0.32, "tft": 3.336, "input_0": 443, "input_1": 129, "min_CLP": -6.09, "draft_iters": 32.0, "mem_use": 34.72, "gen_rate": 33.0, "speed": 7.9, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 27.0, "tree_w": 28, "tree_size": 128, "t0": 3.2, "t1": 0.335, "tft": 4.4932, "input_0": 352, "input_1": 129, "min_CLP": -5.76, "draft_iters": 27.5, "mem_use": 35.1, "gen_rate": 24.0, "speed": 6.8, "text": "\\n1. A statistical model is a ma"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 26.5, "tree_w": 13, "tree_size": 128, "t0": 3.735, "t1": 0.375, "tft": 5.1604, "input_0": 476, "input_1": 129, "min_CLP": -6.77, "draft_iters": 27.0, "mem_use": 36.37, "gen_rate": 27.5, "speed": 6.69, "text": "\\nWhat is the current time? [\\\\I"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 37, "tree_size": 128, "t0": 1.68, "t1": 0.336, "tft": 2.7897, "input_0": 268, "input_1": 129, "min_CLP": -5.84, "draft_iters": 12.0, "mem_use": 35.02, "gen_rate": 6.6, "speed": 3.28, "text": "Decorators are just a way of ext"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 18.5, "tree_w": 30, "tree_size": 128, "t0": 2.4, "t1": 0.35, "tft": 4.3838, "input_0": 279, "input_1": 129, "min_CLP": -5.93, "draft_iters": 19.5, "mem_use": 35.54, "gen_rate": 18.0, "speed": 6.55, "text": "\"[INST] it's me [\\\\INST]\\n[INST]"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 12.3, "tree_w": 41, "tree_size": 128, "t0": 1.73, "t1": 0.3343, "tft": 2.6205, "input_0": 236, "input_1": 129, "min_CLP": -6.44, "draft_iters": 13.1, "mem_use": 34.97, "gen_rate": 7.7, "speed": 3.73, "text": "dong\\nlong\\nlooser\\nsewer\\nsneak"}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.7, "t1": 0.4, "tft": 5.7559, "input_0": 686, "input_1": 129, "min_CLP": -4.27, "draft_iters": 32.0, "mem_use": 36.85, "gen_rate": 33.0, "speed": 6.47, "text": "\\n| Aspect          | Interprete"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 39, "tree_size": 128, "t0": 2.01, "t1": 0.4917, "tft": 9.3046, "input_0": 320, "input_1": 129, "min_CLP": -6.03, "draft_iters": 9.3, "mem_use": 39.65, "gen_rate": 5.8, "speed": 2.33, "text": "\"\\nI'm happy to help! Here are a"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 42, "tree_size": 128, "t0": 1.464, "t1": 0.352, "tft": 3.5186, "input_0": 265, "input_1": 129, "min_CLP": -6.04, "draft_iters": 9.6, "mem_use": 36.54, "gen_rate": 6.4, "speed": 3.52, "text": "\"The modern computers and networ"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 3.83, "t1": 0.32, "tft": 3.5666, "input_0": 421, "input_1": 129, "min_CLP": -6.19, "draft_iters": 32.0, "mem_use": 34.73, "gen_rate": 33.0, "speed": 7.94, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.4, "tree_w": 53, "tree_size": 128, "t0": 1.0578, "t1": 0.3244, "tft": 2.0287, "input_0": 192, "input_1": 129, "min_CLP": -6.37, "draft_iters": 6.4, "mem_use": 34.79, "gen_rate": 3.9, "speed": 2.81, "text": "\\nI\\'ve been doing some research"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.2, "tree_w": 43, "tree_size": 128, "t0": 1.2338, "t1": 0.3738, "tft": 6.7289, "input_0": 221, "input_1": 129, "min_CLP": -6.01, "draft_iters": 7.2, "mem_use": 36.22, "gen_rate": 4.4, "speed": 2.72, "text": "You can ask me for ideas and I w"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.0, "tree_w": 26, "tree_size": 128, "t0": 2.0467, "t1": 0.3267, "tft": 2.1488, "input_0": 314, "input_1": 129, "min_CLP": -5.97, "draft_iters": 15.0, "mem_use": 34.91, "gen_rate": 12.3, "speed": 5.19, "text": "\"\\nGive me some impression of wh"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 29, "tree_size": 128, "t0": 1.716, "t1": 0.416, "tft": 6.3566, "input_0": 258, "input_1": 129, "min_CLP": -5.84, "draft_iters": 10.6, "mem_use": 37.38, "gen_rate": 6.8, "speed": 3.19, "text": "\"It's a good idea to start with "}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 39, "tree_size": 128, "t0": 1.356, "t1": 0.33, "tft": 1.879, "input_0": 237, "input_1": 129, "min_CLP": -5.86, "draft_iters": 9.2, "mem_use": 35.46, "gen_rate": 7.2, "speed": 4.28, "text": "Yes, you should install them in "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 38, "tree_size": 128, "t0": 1.3033, "t1": 0.3283, "tft": 1.9523, "input_0": 236, "input_1": 129, "min_CLP": -5.93, "draft_iters": 8.3, "mem_use": 34.87, "gen_rate": 5.8, "speed": 3.57, "text": "\"Carnegie Mellon is the only uni"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.9, "tree_w": 51, "tree_size": 128, "t0": 1.3656, "t1": 0.3278, "tft": 1.8089, "input_0": 245, "input_1": 129, "min_CLP": -6.5, "draft_iters": 8.9, "mem_use": 34.88, "gen_rate": 3.9, "speed": 2.3, "text": "I will be more free, and more op"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.4, "tree_w": 33, "tree_size": 128, "t0": 1.636, "t1": 0.348, "tft": 3.6777, "input_0": 297, "input_1": 129, "min_CLP": -5.79, "draft_iters": 10.4, "mem_use": 35.49, "gen_rate": 7.2, "speed": 3.63, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 45, "tree_size": 128, "t0": 1.2, "t1": 0.33, "tft": 2.192, "input_0": 227, "input_1": 129, "min_CLP": -6.1, "draft_iters": 7.5, "mem_use": 34.92, "gen_rate": 5.3, "speed": 3.49, "text": "\\nThe KH-11 satellite was the fi"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 38, "tree_size": 128, "t0": 1.534, "t1": 0.33, "tft": 1.9089, "input_0": 263, "input_1": 129, "min_CLP": -5.98, "draft_iters": 10.2, "mem_use": 35.02, "gen_rate": 6.6, "speed": 3.54, "text": "turmeric\\noregano\\ncumin\\nfennel"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 40, "tree_size": 128, "t0": 1.33, "t1": 0.3317, "tft": 2.3473, "input_0": 252, "input_1": 129, "min_CLP": -5.79, "draft_iters": 8.5, "mem_use": 35.03, "gen_rate": 5.8, "speed": 3.51, "text": "The best way to see the stars is"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.0, "tree_w": 41, "tree_size": 128, "t0": 1.59, "t1": 0.368, "tft": 4.1447, "input_0": 292, "input_1": 129, "min_CLP": -6.41, "draft_iters": 10.0, "mem_use": 36.0, "gen_rate": 7.8, "speed": 3.98, "text": "\u2022 I recommend the following chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 128, "t0": 3.44, "t1": 0.32, "tft": 2.3939, "input_0": 320, "input_1": 129, "min_CLP": -6.06, "draft_iters": 32.0, "mem_use": 34.81, "gen_rate": 33.0, "speed": 8.76, "text": "\\n[INST]<<SYS>>\\nYou are a helpf"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 50, "tree_size": 128, "t0": 1.3257, "t1": 0.3286, "tft": 2.9237, "input_0": 199, "input_1": 129, "min_CLP": -6.21, "draft_iters": 9.6, "mem_use": 34.79, "gen_rate": 5.0, "speed": 3.02, "text": "\\nThis is a hard one. I think th"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 3.82, "t1": 0.34, "tft": 4.0508, "input_0": 424, "input_1": 129, "min_CLP": -5.42, "draft_iters": 32.0, "mem_use": 35.53, "gen_rate": 33.0, "speed": 7.93, "text": "\\nA statistical model is a mathe"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 4.43, "t1": 0.36, "tft": 4.4572, "input_0": 548, "input_1": 129, "min_CLP": -7.59, "draft_iters": 32.0, "mem_use": 36.07, "gen_rate": 33.0, "speed": 6.89, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 19.2, "tree_w": 15, "tree_size": 128, "t0": 2.64, "t1": 0.3267, "tft": 2.6332, "input_0": 372, "input_1": 129, "min_CLP": -5.69, "draft_iters": 20.2, "mem_use": 34.87, "gen_rate": 6.3, "speed": 2.14, "text": "\"What's the current time? [\\\\INS"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.4, "tree_w": 49, "tree_size": 128, "t0": 1.024, "t1": 0.342, "tft": 2.8842, "input_0": 191, "input_1": 129, "min_CLP": -6.18, "draft_iters": 6.4, "mem_use": 35.45, "gen_rate": 3.5, "speed": 2.56, "text": "\"\\nI'm a new hire here. So I don"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 10.0, "tree_w": 33, "tree_size": 128, "t0": 1.62, "t1": 0.325, "tft": 2.0988, "input_0": 286, "input_1": 129, "min_CLP": -6.02, "draft_iters": 11.0, "mem_use": 34.88, "gen_rate": 4.0, "speed": 2.05, "text": "Sure, I guess.\\n<</SYS>"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 128, "t0": 3.41, "t1": 0.33, "tft": 2.9429, "input_0": 287, "input_1": 129, "min_CLP": -6.26, "draft_iters": 32.0, "mem_use": 34.72, "gen_rate": 33.0, "speed": 8.83, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.2, "tree_w": 48, "tree_size": 128, "t0": 1.5075, "t1": 0.3275, "tft": 4.1136, "input_0": 221, "input_1": 129, "min_CLP": -6.59, "draft_iters": 11.2, "mem_use": 34.89, "gen_rate": 9.0, "speed": 4.91, "text": "\\nThe AI assistant. Is the AI as"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.6, "tree_w": 23, "tree_size": 128, "t0": 2.29, "t1": 0.326, "tft": 2.3537, "input_0": 353, "input_1": 129, "min_CLP": -5.74, "draft_iters": 16.6, "mem_use": 34.69, "gen_rate": 6.8, "speed": 2.6, "text": "How does the body produce energy"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 16.6, "tree_w": 25, "tree_size": 128, "t0": 2.31, "t1": 0.34, "tft": 3.2057, "input_0": 316, "input_1": 129, "min_CLP": -5.49, "draft_iters": 17.4, "mem_use": 35.29, "gen_rate": 7.6, "speed": 2.87, "text": "\\nThe Andromeda galaxy is locate"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 4.13, "t1": 0.32, "tft": 3.113, "input_0": 562, "input_1": 129, "min_CLP": -5.48, "draft_iters": 32.0, "mem_use": 34.79, "gen_rate": 33.0, "speed": 7.41, "text": "\"\\nBob has two sons. John and Ja"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 17.2, "tree_w": 27, "tree_size": 128, "t0": 2.2467, "t1": 0.3333, "tft": 2.168, "input_0": 279, "input_1": 129, "min_CLP": -5.67, "draft_iters": 18.0, "mem_use": 34.98, "gen_rate": 6.0, "speed": 2.33, "text": "\\nWhat is the largest ocean on E"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.9, "tree_w": 42, "tree_size": 128, "t0": 1.4113, "t1": 0.3387, "tft": 2.2378, "input_0": 224, "input_1": 129, "min_CLP": -6.16, "draft_iters": 9.8, "mem_use": 35.13, "gen_rate": 4.0, "speed": 2.29, "text": "\"\\nWhat sort of qualifications d"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 37, "tree_size": 128, "t0": 1.2017, "t1": 0.3267, "tft": 2.1325, "input_0": 223, "input_1": 129, "min_CLP": -6.1, "draft_iters": 7.8, "mem_use": 34.81, "gen_rate": 5.3, "speed": 3.49, "text": "\"\\nI'm new to PyGame and I have "}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 6.2, "tree_w": 46, "tree_size": 128, "t0": 1.17, "t1": 0.344, "tft": 2.5139, "input_0": 216, "input_1": 129, "min_CLP": -6.09, "draft_iters": 7.2, "mem_use": 35.35, "gen_rate": 3.9, "speed": 2.57, "text": "A DLL file (Dynamic Link Library"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.2, "tree_w": 30, "tree_size": 128, "t0": 2.295, "t1": 0.3325, "tft": 2.2529, "input_0": 309, "input_1": 129, "min_CLP": -6.22, "draft_iters": 18.2, "mem_use": 34.95, "gen_rate": 8.5, "speed": 3.24, "text": "\\nWhich of the following is true"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 128, "t0": 3.27, "t1": 0.32, "tft": 2.2681, "input_0": 242, "input_1": 129, "min_CLP": -5.7, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 33.0, "speed": 9.19, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 8.3, "tree_w": 53, "tree_size": 128, "t0": 1.264, "t1": 0.326, "tft": 2.7959, "input_0": 188, "input_1": 129, "min_CLP": -6.31, "draft_iters": 9.3, "mem_use": 34.77, "gen_rate": 3.4, "speed": 2.14, "text": "\\nThe question is:\\n\\nHow to mak"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 36, "tree_size": 128, "t0": 1.5767, "t1": 0.3267, "tft": 1.853, "input_0": 240, "input_1": 129, "min_CLP": -5.9, "draft_iters": 11.2, "mem_use": 34.84, "gen_rate": 5.5, "speed": 2.89, "text": "\"I don't think they are on a hig"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 128, "t0": 3.51, "t1": 0.34, "tft": 2.1837, "input_0": 314, "input_1": 129, "min_CLP": -6.21, "draft_iters": 32.0, "mem_use": 35.09, "gen_rate": 33.0, "speed": 8.59, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.4, "tree_w": 44, "tree_size": 128, "t0": 1.345, "t1": 0.35, "tft": 3.5358, "input_0": 243, "input_1": 129, "min_CLP": -5.99, "draft_iters": 8.4, "mem_use": 35.54, "gen_rate": 4.1, "speed": 2.44, "text": "Yeah, if you have any specific q"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.8, "tree_w": 29, "tree_size": 128, "t0": 1.7117, "t1": 0.36, "tft": 3.6902, "input_0": 292, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.8, "mem_use": 35.78, "gen_rate": 6.3, "speed": 3.06, "text": "There are a variety of languages"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 43, "tree_size": 128, "t0": 1.3186, "t1": 0.3329, "tft": 2.1622, "input_0": 229, "input_1": 129, "min_CLP": -5.95, "draft_iters": 8.6, "mem_use": 35.01, "gen_rate": 4.7, "speed": 2.85, "text": "You can use all of these tools f"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.1, "tree_w": 31, "tree_size": 128, "t0": 1.4971, "t1": 0.3314, "tft": 2.0275, "input_0": 253, "input_1": 129, "min_CLP": -5.85, "draft_iters": 10.1, "mem_use": 34.94, "gen_rate": 4.6, "speed": 2.5, "text": "I am an AI. Since I am not capab"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.7, "tree_w": 25, "tree_size": 128, "t0": 1.8433, "t1": 0.33, "tft": 2.2556, "input_0": 280, "input_1": 129, "min_CLP": -5.97, "draft_iters": 13.7, "mem_use": 35.04, "gen_rate": 12.0, "speed": 5.51, "text": "You are a part of the future. Yo"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 44, "tree_size": 128, "t0": 1.2171, "t1": 0.3329, "tft": 2.391, "input_0": 220, "input_1": 129, "min_CLP": -6.21, "draft_iters": 7.6, "mem_use": 35.01, "gen_rate": 5.1, "speed": 3.31, "text": "\\nHow can you tell if a woman is"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 22.5, "tree_w": 20, "tree_size": 128, "t0": 2.865, "t1": 0.32, "tft": 2.7032, "input_0": 358, "input_1": 129, "min_CLP": -6.43, "draft_iters": 23.0, "mem_use": 34.76, "gen_rate": 21.5, "speed": 6.75, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.0, "tree_w": 35, "tree_size": 128, "t0": 1.405, "t1": 0.3475, "tft": 3.2899, "input_0": 250, "input_1": 129, "min_CLP": -5.88, "draft_iters": 9.0, "mem_use": 35.56, "gen_rate": 4.8, "speed": 2.71, "text": "\"The **Hubble Space Telescope** "}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 50, "tree_size": 128, "t0": 1.1043, "t1": 0.3286, "tft": 3.2805, "input_0": 195, "input_1": 129, "min_CLP": -6.3, "draft_iters": 7.0, "mem_use": 34.87, "gen_rate": 4.7, "speed": 3.29, "text": "Hippoplaisir is a specialist in "}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.8, "tree_w": 39, "tree_size": 128, "t0": 1.6075, "t1": 0.3225, "tft": 3.8315, "input_0": 208, "input_1": 129, "min_CLP": -6.35, "draft_iters": 12.8, "mem_use": 34.74, "gen_rate": 10.5, "speed": 5.44, "text": "\\nProvide me with the first thre"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 15.5, "tree_w": 19, "tree_size": 128, "t0": 2.2775, "t1": 0.33, "tft": 2.2888, "input_0": 344, "input_1": 129, "min_CLP": -5.66, "draft_iters": 16.5, "mem_use": 35.0, "gen_rate": 10.5, "speed": 4.03, "text": "[INST] how did you get started p"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.9, "tree_w": 36, "tree_size": 128, "t0": 1.3887, "t1": 0.3638, "tft": 3.9724, "input_0": 243, "input_1": 129, "min_CLP": -5.92, "draft_iters": 8.9, "mem_use": 35.87, "gen_rate": 4.6, "speed": 2.64, "text": "The initial noise is generated b"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.9, "tree_w": 49, "tree_size": 128, "t0": 1.1743, "t1": 0.3429, "tft": 2.377, "input_0": 216, "input_1": 129, "min_CLP": -6.09, "draft_iters": 6.9, "mem_use": 35.22, "gen_rate": 4.9, "speed": 3.2, "text": "Human sexual selection is also a"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 26, "tree_size": 128, "t0": 1.51, "t1": 0.3475, "tft": 3.0936, "input_0": 284, "input_1": 129, "min_CLP": -5.84, "draft_iters": 10.0, "mem_use": 35.43, "gen_rate": 8.0, "speed": 4.3, "text": "The meaning of life is whatever "}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 19, "tree_size": 128, "t0": 2.715, "t1": 0.33, "tft": 2.4219, "input_0": 369, "input_1": 129, "min_CLP": -6.48, "draft_iters": 21.0, "mem_use": 34.72, "gen_rate": 21.5, "speed": 7.06, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 31, "tree_size": 128, "t0": 3.89, "t1": 0.4, "tft": 6.8253, "input_0": 305, "input_1": 129, "min_CLP": -6.02, "draft_iters": 32.0, "mem_use": 37.0, "gen_rate": 33.0, "speed": 7.7, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.5, "tree_w": 43, "tree_size": 128, "t0": 2.33, "t1": 0.35, "tft": 3.107, "input_0": 262, "input_1": 129, "min_CLP": -6.75, "draft_iters": 19.2, "mem_use": 35.48, "gen_rate": 8.0, "speed": 2.99, "text": "\\nThe Braille character set only"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 128, "t0": 3.54, "t1": 0.34, "tft": 3.6176, "input_0": 333, "input_1": 129, "min_CLP": -5.81, "draft_iters": 32.0, "mem_use": 35.19, "gen_rate": 33.0, "speed": 8.51, "text": "If the plane is delayed in Singa"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 32.0, "tree_w": 34, "tree_size": 128, "t0": 3.45, "t1": 0.33, "tft": 2.8464, "input_0": 284, "input_1": 129, "min_CLP": -6.32, "draft_iters": 32.0, "mem_use": 34.73, "gen_rate": 20.0, "speed": 5.29, "text": "\\n<SYS>\\n\\nYou are a helpful, re"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.5, "tree_w": 41, "tree_size": 128, "t0": 1.2013, "t1": 0.3313, "tft": 2.5783, "input_0": 216, "input_1": 129, "min_CLP": -6.02, "draft_iters": 8.5, "mem_use": 34.92, "gen_rate": 4.2, "speed": 2.78, "text": "[INST] A homeless man is walking"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 29, "tree_size": 128, "t0": 2.65, "t1": 0.3275, "tft": 2.6277, "input_0": 318, "input_1": 129, "min_CLP": -6.04, "draft_iters": 22.2, "mem_use": 34.72, "gen_rate": 8.2, "speed": 2.77, "text": "\\n<SYS>\\nThe number of black hol"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.0, "tree_w": 47, "tree_size": 128, "t0": 1.4743, "t1": 0.4057, "tft": 5.4295, "input_0": 216, "input_1": 129, "min_CLP": -6.12, "draft_iters": 9.0, "mem_use": 37.1, "gen_rate": 5.6, "speed": 2.97, "text": "\\nIf you are babysitting the kid"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 7.6, "tree_w": 44, "tree_size": 128, "t0": 1.292, "t1": 0.324, "tft": 2.1494, "input_0": 217, "input_1": 129, "min_CLP": -6.18, "draft_iters": 8.6, "mem_use": 35.35, "gen_rate": 8.0, "speed": 4.95, "text": "\\nIf the universe was created, w"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 37, "tree_size": 128, "t0": 1.605, "t1": 0.4483, "tft": 8.2124, "input_0": 238, "input_1": 129, "min_CLP": -5.93, "draft_iters": 9.0, "mem_use": 38.23, "gen_rate": 5.7, "speed": 2.76, "text": "[INST] I am sorry, but due to th"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.0, "tree_w": 43, "tree_size": 128, "t0": 1.2378, "t1": 0.3422, "tft": 2.7529, "input_0": 217, "input_1": 129, "min_CLP": -6.2, "draft_iters": 8.0, "mem_use": 35.9, "gen_rate": 3.8, "speed": 2.39, "text": "Yes, it is the first evolution f"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 18.0, "tree_w": 38, "tree_size": 128, "t0": 2.2733, "t1": 0.3267, "tft": 2.2423, "input_0": 271, "input_1": 129, "min_CLP": -7.01, "draft_iters": 18.7, "mem_use": 34.78, "gen_rate": 17.7, "speed": 6.79, "text": "\\n3.2\\n\\n[INST] <<SYS>>\\nYou are"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 32.0, "tree_w": 17, "tree_size": 128, "t0": 3.915, "t1": 0.325, "tft": 2.3877, "input_0": 441, "input_1": 129, "min_CLP": -7.0, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 28.5, "speed": 6.72, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 3.94, "t1": 0.33, "tft": 2.1414, "input_0": 495, "input_1": 129, "min_CLP": -5.92, "draft_iters": 32.0, "mem_use": 34.82, "gen_rate": 33.0, "speed": 7.73, "text": "\\nI have an almost irrational ha"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 32, "tree_size": 128, "t0": 1.9525, "t1": 0.33, "tft": 1.7854, "input_0": 376, "input_1": 129, "min_CLP": -5.63, "draft_iters": 11.8, "mem_use": 34.99, "gen_rate": 8.5, "speed": 3.72, "text": "I\u2019d recommend \u201cThe Office\u201d, \u201cThe"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.5, "tree_w": 24, "tree_size": 128, "t0": 2.635, "t1": 0.3575, "tft": 3.0734, "input_0": 320, "input_1": 129, "min_CLP": -5.46, "draft_iters": 20.2, "mem_use": 35.8, "gen_rate": 10.0, "speed": 3.34, "text": "\\nSoftware: You will need to pur"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.1, "tree_w": 46, "tree_size": 128, "t0": 1.1613, "t1": 0.3425, "tft": 2.5752, "input_0": 226, "input_1": 129, "min_CLP": -6.21, "draft_iters": 7.1, "mem_use": 35.38, "gen_rate": 4.6, "speed": 3.07, "text": "\"\\nF-centers create a number of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 20.0, "tree_w": 29, "tree_size": 128, "t0": 2.4225, "t1": 0.3275, "tft": 3.5895, "input_0": 270, "input_1": 129, "min_CLP": -5.96, "draft_iters": 20.8, "mem_use": 34.8, "gen_rate": 9.2, "speed": 3.36, "text": "\"\\n[INST] <<SYS>>\\nCan you pleas"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.7, "tree_w": 51, "tree_size": 128, "t0": 1.5617, "t1": 0.39, "tft": 6.9308, "input_0": 227, "input_1": 129, "min_CLP": -6.47, "draft_iters": 9.7, "mem_use": 36.74, "gen_rate": 5.3, "speed": 2.74, "text": "\"\\nHow can I create a new node ("}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 25.0, "tree_w": 12, "tree_size": 128, "t0": 3.4467, "t1": 0.35, "tft": 5.3602, "input_0": 453, "input_1": 129, "min_CLP": -5.28, "draft_iters": 25.7, "mem_use": 35.53, "gen_rate": 15.3, "speed": 4.04, "text": "Aqu\u00ed tienes la reducci\u00f3n de la l"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.6, "tree_w": 47, "tree_size": 128, "t0": 1.2171, "t1": 0.3286, "tft": 2.3024, "input_0": 228, "input_1": 129, "min_CLP": -6.46, "draft_iters": 7.6, "mem_use": 34.71, "gen_rate": 4.9, "speed": 3.14, "text": "\\nA:\\n\\nYou could start by teach"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 23.5, "tree_w": 26, "tree_size": 128, "t0": 2.7425, "t1": 0.3275, "tft": 3.382, "input_0": 270, "input_1": 129, "min_CLP": -6.21, "draft_iters": 24.0, "mem_use": 34.77, "gen_rate": 12.0, "speed": 3.91, "text": "\\nExamples:\\n\\n[INST]\\n\\t<SYS>\\n"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 58, "tree_h": 11.5, "tree_w": 38, "tree_size": 128, "t0": 1.6317, "t1": 0.3433, "tft": 2.5496, "input_0": 218, "input_1": 129, "min_CLP": -5.92, "draft_iters": 12.3, "mem_use": 35.28, "gen_rate": 9.7, "speed": 4.89, "text": "\"I will not respond to questions"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 9.6, "tree_w": 39, "tree_size": 128, "t0": 1.5525, "t1": 0.36, "tft": 3.8106, "input_0": 253, "input_1": 129, "min_CLP": -5.88, "draft_iters": 10.6, "mem_use": 35.82, "gen_rate": 4.6, "speed": 2.42, "text": "You can use the same kind of uni"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.2, "tree_w": 35, "tree_size": 128, "t0": 1.502, "t1": 0.332, "tft": 2.0866, "input_0": 269, "input_1": 129, "min_CLP": -6.06, "draft_iters": 10.2, "mem_use": 35.01, "gen_rate": 7.2, "speed": 3.93, "text": "\\nI am a beginner in guitar and "}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 128, "t0": 3.63, "t1": 0.34, "tft": 2.6503, "input_0": 346, "input_1": 129, "min_CLP": -6.32, "draft_iters": 32.0, "mem_use": 35.25, "gen_rate": 33.0, "speed": 8.31, "text": "The second batch of pancakes may"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.6, "tree_w": 40, "tree_size": 128, "t0": 1.1986, "t1": 0.33, "tft": 2.5029, "input_0": 236, "input_1": 129, "min_CLP": -6.07, "draft_iters": 7.6, "mem_use": 34.7, "gen_rate": 4.9, "speed": 3.18, "text": "\\nJavaScript is a scripting lang"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 22, "tree_size": 128, "t0": 3.34, "t1": 0.33, "tft": 2.398, "input_0": 294, "input_1": 129, "min_CLP": -6.25, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 33.0, "speed": 9.01, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 21.5, "tree_w": 22, "tree_size": 128, "t0": 2.82, "t1": 0.3375, "tft": 2.4895, "input_0": 350, "input_1": 129, "min_CLP": -5.66, "draft_iters": 22.2, "mem_use": 35.06, "gen_rate": 10.5, "speed": 3.33, "text": "\\nGive me a list of 5 words that"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 3.8, "t1": 0.33, "tft": 3.5194, "input_0": 411, "input_1": 129, "min_CLP": -6.2, "draft_iters": 32.0, "mem_use": 34.78, "gen_rate": 33.0, "speed": 7.99, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 10.6, "tree_w": 39, "tree_size": 128, "t0": 1.5413, "t1": 0.3288, "tft": 2.8063, "input_0": 224, "input_1": 129, "min_CLP": -6.04, "draft_iters": 11.6, "mem_use": 34.77, "gen_rate": 4.9, "speed": 2.61, "text": "\\nThe following is an example of"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 44, "tree_size": 128, "t0": 1.358, "t1": 0.326, "tft": 2.158, "input_0": 222, "input_1": 129, "min_CLP": -6.43, "draft_iters": 9.6, "mem_use": 34.76, "gen_rate": 6.4, "speed": 3.79, "text": "\\nI have a question about the Po"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 50, "tree_size": 128, "t0": 1.14, "t1": 0.4063, "tft": 5.8447, "input_0": 201, "input_1": 129, "min_CLP": -6.07, "draft_iters": 6.0, "mem_use": 37.18, "gen_rate": 4.0, "speed": 2.58, "text": "\"\\nThat's a great response! I'm "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 26.5, "tree_w": 25, "tree_size": 128, "t0": 3.465, "t1": 0.36, "tft": 4.2142, "input_0": 458, "input_1": 129, "min_CLP": -5.66, "draft_iters": 27.0, "mem_use": 35.93, "gen_rate": 17.5, "speed": 4.58, "text": "\\nThe Taniyama-Shimura-Weil conj"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 28, "tree_size": 128, "t0": 1.8425, "t1": 0.3375, "tft": 2.5832, "input_0": 301, "input_1": 129, "min_CLP": -5.95, "draft_iters": 12.8, "mem_use": 35.16, "gen_rate": 8.5, "speed": 3.9, "text": "The formula for calculating the "}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 32, "tree_size": 128, "t0": 2.095, "t1": 0.34, "tft": 2.5574, "input_0": 284, "input_1": 129, "min_CLP": -5.74, "draft_iters": 16.0, "mem_use": 35.27, "gen_rate": 8.5, "speed": 3.49, "text": "We can learn a lot from polar be"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.5, "tree_w": 34, "tree_size": 128, "t0": 1.4683, "t1": 0.36, "tft": 3.1072, "input_0": 250, "input_1": 129, "min_CLP": -5.8, "draft_iters": 9.5, "mem_use": 35.8, "gen_rate": 6.2, "speed": 3.38, "text": "\\nThank you for your question.\\n"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 40, "tree_size": 128, "t0": 3.39, "t1": 0.33, "tft": 4.1665, "input_0": 251, "input_1": 129, "min_CLP": -6.62, "draft_iters": 32.0, "mem_use": 34.8, "gen_rate": 33.0, "speed": 8.87, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.0, "tree_w": 38, "tree_size": 128, "t0": 1.3686, "t1": 0.33, "tft": 2.1404, "input_0": 232, "input_1": 129, "min_CLP": -6.11, "draft_iters": 9.0, "mem_use": 34.79, "gen_rate": 5.6, "speed": 3.28, "text": "\"\\nHow to get rid of acne? [\\\\IN"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.4, "tree_w": 44, "tree_size": 128, "t0": 1.215, "t1": 0.3288, "tft": 2.7329, "input_0": 206, "input_1": 129, "min_CLP": -6.0, "draft_iters": 8.4, "mem_use": 34.72, "gen_rate": 4.6, "speed": 2.99, "text": "\"\\nI've been using typescript fo"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 9.0, "tree_w": 31, "tree_size": 128, "t0": 1.58, "t1": 0.3457, "tft": 2.9503, "input_0": 287, "input_1": 129, "min_CLP": -5.8, "draft_iters": 10.0, "mem_use": 35.46, "gen_rate": 6.0, "speed": 3.12, "text": "The city of Amsterdam was founde"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.0, "tree_w": 44, "tree_size": 128, "t0": 1.2288, "t1": 0.3387, "tft": 2.7112, "input_0": 233, "input_1": 129, "min_CLP": -6.07, "draft_iters": 7.0, "mem_use": 35.26, "gen_rate": 4.2, "speed": 2.71, "text": "Dyson also has a significant his"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 128, "t0": 3.54, "t1": 0.33, "tft": 1.9744, "input_0": 351, "input_1": 129, "min_CLP": -5.99, "draft_iters": 32.0, "mem_use": 34.69, "gen_rate": 33.0, "speed": 8.53, "text": "\\ncan you write code? [\\\\INST]\\n"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.8, "tree_w": 35, "tree_size": 128, "t0": 1.734, "t1": 0.334, "tft": 2.2262, "input_0": 287, "input_1": 129, "min_CLP": -6.04, "draft_iters": 11.8, "mem_use": 35.04, "gen_rate": 8.2, "speed": 3.97, "text": "\\nWho is the most famous person "}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 42, "tree_size": 128, "t0": 1.3114, "t1": 0.3443, "tft": 3.277, "input_0": 225, "input_1": 129, "min_CLP": -6.18, "draft_iters": 8.6, "mem_use": 35.38, "gen_rate": 4.9, "speed": 2.94, "text": "\\nWhat is the best way to get my"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 29, "tree_size": 128, "t0": 1.9867, "t1": 0.3267, "tft": 2.3485, "input_0": 316, "input_1": 129, "min_CLP": -5.76, "draft_iters": 14.0, "mem_use": 34.93, "gen_rate": 10.7, "speed": 4.61, "text": "\"1.    Be open and honest with y"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 62, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 3.8367, "t1": 0.3233, "tft": 3.5487, "input_0": 455, "input_1": 129, "min_CLP": -5.66, "draft_iters": 32.0, "mem_use": 34.75, "gen_rate": 20.7, "speed": 4.96, "text": "\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f [SYS]\\n\\n\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f [SYS]\\n\\n"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 34, "tree_size": 128, "t0": 2.12, "t1": 0.3325, "tft": 2.4057, "input_0": 336, "input_1": 129, "min_CLP": -6.12, "draft_iters": 15.0, "mem_use": 35.0, "gen_rate": 10.0, "speed": 4.08, "text": "The comparison of deep learning "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.5, "tree_w": 26, "tree_size": 128, "t0": 2.525, "t1": 0.34, "tft": 4.1249, "input_0": 286, "input_1": 129, "min_CLP": -5.99, "draft_iters": 20.2, "mem_use": 35.27, "gen_rate": 10.0, "speed": 3.49, "text": "[INST] how to ask a question abo"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 17.3, "tree_w": 28, "tree_size": 128, "t0": 2.6233, "t1": 0.34, "tft": 2.6319, "input_0": 365, "input_1": 129, "min_CLP": -6.22, "draft_iters": 18.0, "mem_use": 35.12, "gen_rate": 18.0, "speed": 6.08, "text": "The URL decoded string is %21.\\n"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 20.3, "tree_w": 21, "tree_size": 128, "t0": 2.8633, "t1": 0.3667, "tft": 4.6052, "input_0": 379, "input_1": 129, "min_CLP": -5.53, "draft_iters": 21.0, "mem_use": 36.11, "gen_rate": 13.7, "speed": 4.23, "text": "\"\\nHow can I use L'Hopital's Rul"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 34, "tree_size": 128, "t0": 1.5, "t1": 0.3986, "tft": 5.1542, "input_0": 265, "input_1": 129, "min_CLP": -5.78, "draft_iters": 8.4, "mem_use": 37.01, "gen_rate": 4.7, "speed": 2.48, "text": "There are a variety of vegan che"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 40, "tree_size": 128, "t0": 1.1775, "t1": 0.3438, "tft": 2.598, "input_0": 214, "input_1": 129, "min_CLP": -5.75, "draft_iters": 7.5, "mem_use": 35.4, "gen_rate": 4.1, "speed": 2.71, "text": "\"It's important to set realistic"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 24, "tree_size": 128, "t0": 1.965, "t1": 0.355, "tft": 4.5151, "input_0": 326, "input_1": 129, "min_CLP": -5.82, "draft_iters": 12.8, "mem_use": 35.63, "gen_rate": 8.0, "speed": 3.46, "text": "\\nWhat are the different types o"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 23.5, "tree_w": 13, "tree_size": 128, "t0": 2.97, "t1": 0.32, "tft": 2.3352, "input_0": 391, "input_1": 129, "min_CLP": -5.67, "draft_iters": 24.0, "mem_use": 34.71, "gen_rate": 23.5, "speed": 7.14, "text": "\\nExplain the difference between"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 24.0, "tree_w": 18, "tree_size": 128, "t0": 3.2067, "t1": 0.34, "tft": 4.3552, "input_0": 370, "input_1": 129, "min_CLP": -6.14, "draft_iters": 24.7, "mem_use": 35.28, "gen_rate": 11.3, "speed": 3.2, "text": "The answer to your question woul"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 41, "tree_size": 128, "t0": 3.28, "t1": 0.33, "tft": 2.4633, "input_0": 257, "input_1": 129, "min_CLP": -6.28, "draft_iters": 32.0, "mem_use": 34.8, "gen_rate": 33.0, "speed": 9.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 128, "t0": 3.31, "t1": 0.32, "tft": 2.4386, "input_0": 263, "input_1": 129, "min_CLP": -6.16, "draft_iters": 32.0, "mem_use": 34.74, "gen_rate": 33.0, "speed": 9.1, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 46, "tree_size": 128, "t0": 1.4443, "t1": 0.33, "tft": 2.7352, "input_0": 232, "input_1": 129, "min_CLP": -6.3, "draft_iters": 10.4, "mem_use": 34.74, "gen_rate": 4.9, "speed": 2.74, "text": "\\nIn minecraft, what are the bes"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 31.3, "tree_w": 22, "tree_size": 128, "t0": 3.5233, "t1": 0.3233, "tft": 4.298, "input_0": 336, "input_1": 129, "min_CLP": -6.18, "draft_iters": 31.7, "mem_use": 34.7, "gen_rate": 15.7, "speed": 4.07, "text": "\\n<[/INST]\\n\\n<<SYS>>\\n\\nYou are"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 28.0, "tree_w": 13, "tree_size": 128, "t0": 3.56, "t1": 0.345, "tft": 4.7357, "input_0": 408, "input_1": 129, "min_CLP": -5.41, "draft_iters": 28.5, "mem_use": 35.38, "gen_rate": 25.0, "speed": 6.4, "text": "\"\\nWrite me a Shakespeare Progra"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.0, "tree_w": 34, "tree_size": 128, "t0": 1.82, "t1": 0.33, "tft": 2.7169, "input_0": 300, "input_1": 129, "min_CLP": -6.16, "draft_iters": 12.0, "mem_use": 34.93, "gen_rate": 5.5, "speed": 2.56, "text": "$ tailwind init\\n[INST] What is "}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.0, "tree_w": 44, "tree_size": 128, "t0": 1.2675, "t1": 0.4212, "tft": 6.0433, "input_0": 204, "input_1": 129, "min_CLP": -6.21, "draft_iters": 7.0, "mem_use": 37.45, "gen_rate": 4.2, "speed": 2.52, "text": "Dimorphism in sexual traits is o"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 8.0, "tree_w": 47, "tree_size": 128, "t0": 1.515, "t1": 0.3317, "tft": 1.9089, "input_0": 284, "input_1": 129, "min_CLP": -6.28, "draft_iters": 9.0, "mem_use": 35.5, "gen_rate": 5.0, "speed": 2.71, "text": "\"I'm not quite sure what you mea"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 3.87, "t1": 0.33, "tft": 1.8585, "input_0": 434, "input_1": 129, "min_CLP": -6.32, "draft_iters": 32.0, "mem_use": 34.75, "gen_rate": 33.0, "speed": 7.85, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 3.32, "t1": 0.33, "tft": 3.0626, "input_0": 238, "input_1": 129, "min_CLP": -6.41, "draft_iters": 32.0, "mem_use": 34.86, "gen_rate": 33.0, "speed": 9.04, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 4.01, "t1": 0.35, "tft": 3.5804, "input_0": 411, "input_1": 129, "min_CLP": -6.03, "draft_iters": 32.0, "mem_use": 35.63, "gen_rate": 33.0, "speed": 7.57, "text": "\\nHow to code the snake game in "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 24, "tree_size": 128, "t0": 1.884, "t1": 0.33, "tft": 2.3547, "input_0": 277, "input_1": 129, "min_CLP": -5.58, "draft_iters": 14.4, "mem_use": 34.8, "gen_rate": 7.6, "speed": 3.44, "text": "Yes, I am an assistant, but I am"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.0, "tree_w": 34, "tree_size": 128, "t0": 2.2, "t1": 0.325, "tft": 3.1413, "input_0": 236, "input_1": 129, "min_CLP": -5.79, "draft_iters": 19.0, "mem_use": 34.79, "gen_rate": 10.2, "speed": 4.06, "text": "\\n[INST] <<SYS>>\\nWhat is the mo"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 8.5, "tree_w": 38, "tree_size": 128, "t0": 1.385, "t1": 0.325, "tft": 3.0407, "input_0": 235, "input_1": 129, "min_CLP": -6.07, "draft_iters": 9.5, "mem_use": 34.7, "gen_rate": 4.9, "speed": 2.85, "text": "What do you get when you multipl"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.7, "tree_w": 25, "tree_size": 128, "t0": 2.2433, "t1": 0.3633, "tft": 4.9873, "input_0": 295, "input_1": 129, "min_CLP": -6.01, "draft_iters": 16.7, "mem_use": 35.88, "gen_rate": 10.7, "speed": 4.09, "text": "\"The phrase 'I love you' is:\\n\\n"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 43, "tree_size": 128, "t0": 1.4317, "t1": 0.325, "tft": 2.4361, "input_0": 218, "input_1": 129, "min_CLP": -6.14, "draft_iters": 10.2, "mem_use": 34.74, "gen_rate": 6.2, "speed": 3.51, "text": "\\nSome people say that \"Harry Po"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 8.8, "tree_w": 26, "tree_size": 128, "t0": 1.54, "t1": 0.332, "tft": 2.4233, "input_0": 288, "input_1": 129, "min_CLP": -5.89, "draft_iters": 9.8, "mem_use": 35.0, "gen_rate": 8.0, "speed": 4.27, "text": "No. The Second Amendment guarant"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.8, "tree_w": 43, "tree_size": 128, "t0": 1.7283, "t1": 0.3267, "tft": 2.3141, "input_0": 218, "input_1": 129, "min_CLP": -6.27, "draft_iters": 13.7, "mem_use": 34.74, "gen_rate": 5.7, "speed": 2.76, "text": "\\nThe best formula to generate a"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.6, "tree_w": 51, "tree_size": 128, "t0": 1.3275, "t1": 0.3312, "tft": 2.3272, "input_0": 199, "input_1": 129, "min_CLP": -6.27, "draft_iters": 9.5, "mem_use": 34.95, "gen_rate": 4.1, "speed": 2.49, "text": "\\nYou can make any suggestions y"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 16.8, "tree_w": 26, "tree_size": 128, "t0": 2.488, "t1": 0.33, "tft": 2.104, "input_0": 386, "input_1": 129, "min_CLP": -5.55, "draft_iters": 17.8, "mem_use": 34.8, "gen_rate": 8.2, "speed": 2.91, "text": "Melbourne was the capital of the"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 23, "tree_size": 128, "t0": 1.9375, "t1": 0.3275, "tft": 2.1627, "input_0": 290, "input_1": 129, "min_CLP": -5.77, "draft_iters": 14.2, "mem_use": 34.89, "gen_rate": 8.8, "speed": 3.86, "text": "[INST] thanks [\\\\INST]\\n[INST] y"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.11, "t1": 0.36, "tft": 5.0649, "input_0": 460, "input_1": 129, "min_CLP": -6.32, "draft_iters": 32.0, "mem_use": 36.02, "gen_rate": 33.0, "speed": 7.37, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.0, "tree_w": 43, "tree_size": 128, "t0": 1.105, "t1": 0.3262, "tft": 2.2037, "input_0": 214, "input_1": 129, "min_CLP": -6.15, "draft_iters": 7.0, "mem_use": 34.82, "gen_rate": 4.5, "speed": 3.14, "text": "\\nYes, this is real. The British"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 4.01, "t1": 0.35, "tft": 3.6699, "input_0": 445, "input_1": 129, "min_CLP": -5.48, "draft_iters": 32.0, "mem_use": 35.45, "gen_rate": 33.0, "speed": 7.56, "text": "For a vector A in a n dimensiona"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.5, "tree_w": 43, "tree_size": 128, "t0": 1.4117, "t1": 0.3283, "tft": 2.3814, "input_0": 252, "input_1": 129, "min_CLP": -6.43, "draft_iters": 9.5, "mem_use": 34.73, "gen_rate": 6.7, "speed": 3.83, "text": "\\nWhat are the differences betwe"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.3, "tree_w": 49, "tree_size": 128, "t0": 1.1343, "t1": 0.3286, "tft": 2.6778, "input_0": 234, "input_1": 129, "min_CLP": -6.25, "draft_iters": 6.3, "mem_use": 34.75, "gen_rate": 5.0, "speed": 3.42, "text": "\\nA young man was sitting on the"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.4, "tree_w": 37, "tree_size": 128, "t0": 1.3563, "t1": 0.3237, "tft": 2.4518, "input_0": 225, "input_1": 129, "min_CLP": -6.28, "draft_iters": 9.4, "mem_use": 34.74, "gen_rate": 4.6, "speed": 2.75, "text": "\\nFor example, when you are tryi"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.5, "tree_w": 38, "tree_size": 128, "t0": 1.6783, "t1": 0.3333, "tft": 2.2649, "input_0": 240, "input_1": 129, "min_CLP": -5.94, "draft_iters": 12.5, "mem_use": 35.02, "gen_rate": 6.3, "speed": 3.15, "text": "The sum of squares error is the "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 29.0, "tree_w": 37, "tree_size": 128, "t0": 3.17, "t1": 0.34, "tft": 2.7623, "input_0": 266, "input_1": 129, "min_CLP": -6.21, "draft_iters": 29.5, "mem_use": 35.18, "gen_rate": 20.0, "speed": 5.7, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.0, "tree_w": 46, "tree_size": 128, "t0": 1.1543, "t1": 0.3357, "tft": 2.3455, "input_0": 224, "input_1": 129, "min_CLP": -6.06, "draft_iters": 7.0, "mem_use": 35.05, "gen_rate": 5.4, "speed": 3.64, "text": "\"The best place to see the best "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 31.5, "tree_w": 29, "tree_size": 128, "t0": 3.48, "t1": 0.325, "tft": 2.9097, "input_0": 301, "input_1": 129, "min_CLP": -5.94, "draft_iters": 32.0, "mem_use": 34.72, "gen_rate": 18.5, "speed": 4.86, "text": "\\n<SYS>\\n\\n<INST>\\n\\n<SYS>\\n\\n<I"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 38, "tree_size": 128, "t0": 1.7075, "t1": 0.335, "tft": 1.7285, "input_0": 269, "input_1": 129, "min_CLP": -5.71, "draft_iters": 11.5, "mem_use": 34.99, "gen_rate": 8.0, "speed": 3.92, "text": "I think you mean, if the two I d"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 47, "tree_size": 128, "t0": 1.2843, "t1": 0.3286, "tft": 2.266, "input_0": 226, "input_1": 129, "min_CLP": -5.98, "draft_iters": 8.0, "mem_use": 34.94, "gen_rate": 4.6, "speed": 2.83, "text": "Financial difficulties can cause"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 4.4, "t1": 0.39, "tft": 5.5734, "input_0": 507, "input_1": 129, "min_CLP": -7.04, "draft_iters": 32.0, "mem_use": 36.54, "gen_rate": 33.0, "speed": 6.9, "text": "\"I am Open Assistant, an AI lang"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 29, "tree_size": 128, "t0": 1.8825, "t1": 0.3575, "tft": 4.5042, "input_0": 321, "input_1": 129, "min_CLP": -5.51, "draft_iters": 11.5, "mem_use": 35.87, "gen_rate": 8.5, "speed": 3.8, "text": "\\nThe main advantages of buildin"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 21.3, "tree_w": 23, "tree_size": 128, "t0": 2.725, "t1": 0.325, "tft": 2.9996, "input_0": 331, "input_1": 129, "min_CLP": -5.92, "draft_iters": 22.0, "mem_use": 34.79, "gen_rate": 7.2, "speed": 2.35, "text": "\\n<SYS>\\n\\n<STYLE>\\n<STYLE NAME>"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.6, "tree_w": 45, "tree_size": 128, "t0": 1.2529, "t1": 0.3257, "tft": 4.1323, "input_0": 205, "input_1": 129, "min_CLP": -6.33, "draft_iters": 8.6, "mem_use": 34.84, "gen_rate": 5.6, "speed": 3.52, "text": "\\nWhat is the fastest way to go "}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 41, "tree_size": 128, "t0": 1.81, "t1": 0.4967, "tft": 10.8613, "input_0": 273, "input_1": 129, "min_CLP": -6.01, "draft_iters": 9.3, "mem_use": 39.66, "gen_rate": 5.3, "speed": 2.32, "text": "\\nWhen the player jumps, the _ph"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.2, "tree_w": 30, "tree_size": 128, "t0": 1.5067, "t1": 0.33, "tft": 2.3591, "input_0": 275, "input_1": 129, "min_CLP": -5.82, "draft_iters": 10.2, "mem_use": 36.53, "gen_rate": 5.7, "speed": 3.08, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 49, "tree_h": 11.7, "tree_w": 35, "tree_size": 128, "t0": 1.6729, "t1": 0.3271, "tft": 2.2278, "input_0": 224, "input_1": 129, "min_CLP": -5.95, "draft_iters": 12.7, "mem_use": 34.79, "gen_rate": 7.0, "speed": 3.5, "text": "\"[INST] I'm sorry, but it's not "}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 10.9, "tree_w": 41, "tree_size": 128, "t0": 1.6857, "t1": 0.3257, "tft": 2.5221, "input_0": 282, "input_1": 129, "min_CLP": -6.21, "draft_iters": 11.9, "mem_use": 34.78, "gen_rate": 6.0, "speed": 2.98, "text": "\\n<SYS>\\nThe following is an exc"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 41, "tree_size": 128, "t0": 1.2643, "t1": 0.37, "tft": 3.902, "input_0": 220, "input_1": 129, "min_CLP": -5.98, "draft_iters": 7.4, "mem_use": 36.06, "gen_rate": 4.9, "speed": 2.97, "text": "\"\\nI'm not sure if you're being "}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 9.3, "tree_w": 36, "tree_size": 128, "t0": 1.48, "t1": 0.3333, "tft": 2.6181, "input_0": 244, "input_1": 129, "min_CLP": -5.88, "draft_iters": 10.3, "mem_use": 34.99, "gen_rate": 7.7, "speed": 4.23, "text": "\"I'm not sure, but I'd bet there"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.4, "tree_w": 33, "tree_size": 128, "t0": 2.178, "t1": 0.336, "tft": 2.2424, "input_0": 267, "input_1": 129, "min_CLP": -6.09, "draft_iters": 17.4, "mem_use": 35.05, "gen_rate": 7.0, "speed": 2.78, "text": "\\nThis is a reference to Monty P"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.4, "tree_w": 48, "tree_size": 128, "t0": 1.025, "t1": 0.3275, "tft": 2.2147, "input_0": 196, "input_1": 129, "min_CLP": -6.08, "draft_iters": 6.4, "mem_use": 34.89, "gen_rate": 4.4, "speed": 3.23, "text": "\"\\nI'm just starting out with ne"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 128, "t0": 3.9, "t1": 0.34, "tft": 2.2721, "input_0": 412, "input_1": 129, "min_CLP": -6.23, "draft_iters": 32.0, "mem_use": 35.06, "gen_rate": 33.0, "speed": 7.8, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.8, "tree_w": 31, "tree_size": 128, "t0": 1.865, "t1": 0.33, "tft": 1.9617, "input_0": 263, "input_1": 129, "min_CLP": -5.86, "draft_iters": 13.8, "mem_use": 34.89, "gen_rate": 5.7, "speed": 2.58, "text": "\"\\nThe cat could be dead or aliv"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.4, "tree_w": 41, "tree_size": 128, "t0": 1.3557, "t1": 0.36, "tft": 3.7044, "input_0": 217, "input_1": 129, "min_CLP": -5.81, "draft_iters": 9.4, "mem_use": 35.89, "gen_rate": 4.6, "speed": 2.67, "text": "It depends on how severe your sy"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.0, "tree_w": 18, "tree_size": 128, "t0": 2.6133, "t1": 0.33, "tft": 3.0388, "input_0": 364, "input_1": 129, "min_CLP": -5.49, "draft_iters": 20.0, "mem_use": 34.79, "gen_rate": 11.0, "speed": 3.74, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 14.6, "tree_w": 27, "tree_size": 128, "t0": 2.088, "t1": 0.328, "tft": 2.067, "input_0": 305, "input_1": 129, "min_CLP": -5.82, "draft_iters": 15.6, "mem_use": 34.79, "gen_rate": 9.0, "speed": 3.73, "text": "\"I'm not Spanish, but I can try "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 49, "tree_size": 128, "t0": 1.2686, "t1": 0.3257, "tft": 2.1776, "input_0": 232, "input_1": 129, "min_CLP": -6.33, "draft_iters": 8.0, "mem_use": 34.77, "gen_rate": 4.9, "speed": 3.04, "text": "\\nI have read that the surface a"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 4.78, "t1": 0.42, "tft": 7.7737, "input_0": 540, "input_1": 129, "min_CLP": -6.96, "draft_iters": 32.0, "mem_use": 37.72, "gen_rate": 33.0, "speed": 6.35, "text": "\\nwrite code that imitates a fak"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 14.3, "tree_w": 41, "tree_size": 128, "t0": 1.9433, "t1": 0.3517, "tft": 3.4436, "input_0": 226, "input_1": 129, "min_CLP": -5.9, "draft_iters": 15.2, "mem_use": 35.63, "gen_rate": 5.3, "speed": 2.32, "text": "\\nWhat is the meaning of life? ["}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.4, "tree_w": 48, "tree_size": 128, "t0": 1.1633, "t1": 0.3344, "tft": 2.0099, "input_0": 209, "input_1": 129, "min_CLP": -5.98, "draft_iters": 7.4, "mem_use": 34.98, "gen_rate": 3.8, "speed": 2.52, "text": "I personally believe in the impo"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 33, "tree_size": 128, "t0": 1.524, "t1": 0.364, "tft": 3.8485, "input_0": 267, "input_1": 129, "min_CLP": -5.83, "draft_iters": 9.8, "mem_use": 35.94, "gen_rate": 6.4, "speed": 3.39, "text": "Breeding animals in Minecraft is"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 29, "tree_size": 128, "t0": 1.696, "t1": 0.38, "tft": 5.9299, "input_0": 297, "input_1": 129, "min_CLP": -5.62, "draft_iters": 11.0, "mem_use": 36.3, "gen_rate": 6.8, "speed": 3.28, "text": "Zement ist eine der gr\u00f6\u00dften Veru"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.9, "tree_w": 45, "tree_size": 128, "t0": 1.3862, "t1": 0.3562, "tft": 4.1588, "input_0": 205, "input_1": 129, "min_CLP": -6.03, "draft_iters": 9.9, "mem_use": 35.73, "gen_rate": 4.1, "speed": 2.37, "text": "\"I'm sorry, but you can't use th"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 37, "tree_size": 128, "t0": 1.2914, "t1": 0.3371, "tft": 2.6726, "input_0": 258, "input_1": 129, "min_CLP": -5.77, "draft_iters": 8.0, "mem_use": 35.12, "gen_rate": 5.0, "speed": 3.07, "text": "If you found it in a store, you "}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 7.1, "tree_w": 48, "tree_size": 128, "t0": 1.237, "t1": 0.341, "tft": 2.4301, "input_0": 205, "input_1": 129, "min_CLP": -6.27, "draft_iters": 8.1, "mem_use": 35.22, "gen_rate": 3.2, "speed": 2.03, "text": "You understand how self-attentio"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 4.15, "t1": 0.33, "tft": 3.5676, "input_0": 539, "input_1": 129, "min_CLP": -6.35, "draft_iters": 32.0, "mem_use": 34.79, "gen_rate": 33.0, "speed": 7.37, "text": "\\nWrite me a function in JavaScr"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 3.94, "t1": 0.34, "tft": 4.3287, "input_0": 433, "input_1": 129, "min_CLP": -5.77, "draft_iters": 32.0, "mem_use": 35.43, "gen_rate": 33.0, "speed": 7.7, "text": "\\nIn the state of Wyoming, publi"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 4.11, "t1": 0.33, "tft": 2.2078, "input_0": 447, "input_1": 129, "min_CLP": -6.87, "draft_iters": 32.0, "mem_use": 34.99, "gen_rate": 33.0, "speed": 7.43, "text": "\"\\nPlease help me write a poem f"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 40, "tree_size": 128, "t0": 1.478, "t1": 0.348, "tft": 2.9413, "input_0": 290, "input_1": 129, "min_CLP": -5.92, "draft_iters": 9.6, "mem_use": 35.44, "gen_rate": 7.0, "speed": 3.83, "text": "Mayonnaise should be thick enoug"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 9.4, "tree_w": 38, "tree_size": 128, "t0": 1.568, "t1": 0.34, "tft": 3.9572, "input_0": 278, "input_1": 129, "min_CLP": -6.01, "draft_iters": 10.4, "mem_use": 35.12, "gen_rate": 8.8, "speed": 4.62, "text": "That is a good question. As I am"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 41, "tree_size": 128, "t0": 1.378, "t1": 0.33, "tft": 2.2509, "input_0": 216, "input_1": 129, "min_CLP": -6.01, "draft_iters": 10.0, "mem_use": 34.79, "gen_rate": 6.6, "speed": 3.86, "text": "\\nThis is a list of names I use "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 15.4, "tree_w": 27, "tree_size": 128, "t0": 2.234, "t1": 0.33, "tft": 3.6562, "input_0": 331, "input_1": 129, "min_CLP": -5.8, "draft_iters": 16.2, "mem_use": 34.94, "gen_rate": 8.4, "speed": 3.27, "text": "[INST] The Balfour Declaration w"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 4.015, "t1": 0.35, "tft": 5.6212, "input_0": 462, "input_1": 129, "min_CLP": -4.92, "draft_iters": 32.0, "mem_use": 35.51, "gen_rate": 18.0, "speed": 4.13, "text": "1. \u00abRespect\u00bb, Aretha Franklin.  "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.2, "tree_w": 59, "tree_size": 128, "t0": 1.1867, "t1": 0.3267, "tft": 3.9804, "input_0": 184, "input_1": 129, "min_CLP": -6.68, "draft_iters": 8.2, "mem_use": 34.79, "gen_rate": 3.6, "speed": 2.35, "text": "\\nHere is one I came across and "}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 22.0, "tree_w": 26, "tree_size": 128, "t0": 2.65, "t1": 0.33, "tft": 3.8018, "input_0": 320, "input_1": 129, "min_CLP": -5.96, "draft_iters": 22.5, "mem_use": 35.04, "gen_rate": 21.5, "speed": 7.2, "text": "Correct!\\n\\n```\\n[INST] <<SYS>>\\"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 38, "tree_size": 128, "t0": 1.175, "t1": 0.3412, "tft": 2.2306, "input_0": 222, "input_1": 129, "min_CLP": -6.1, "draft_iters": 7.5, "mem_use": 35.22, "gen_rate": 4.0, "speed": 2.64, "text": "A clock is a device that keeps t"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 15.0, "tree_w": 35, "tree_size": 128, "t0": 1.99, "t1": 0.35, "tft": 4.2221, "input_0": 232, "input_1": 129, "min_CLP": -6.31, "draft_iters": 15.8, "mem_use": 35.64, "gen_rate": 11.8, "speed": 5.02, "text": "\\nRead the following text:\\n\\n1."}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 43, "tree_size": 128, "t0": 1.3557, "t1": 0.3271, "tft": 2.4712, "input_0": 252, "input_1": 129, "min_CLP": -5.84, "draft_iters": 8.7, "mem_use": 34.8, "gen_rate": 5.0, "speed": 2.97, "text": "Frank-Walter Steinmeier was born"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 42, "tree_size": 128, "t0": 1.2637, "t1": 0.3275, "tft": 2.1105, "input_0": 239, "input_1": 129, "min_CLP": -6.39, "draft_iters": 8.1, "mem_use": 34.78, "gen_rate": 4.1, "speed": 2.59, "text": "\"\\nWhat's the distance between t"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.6, "tree_w": 41, "tree_size": 128, "t0": 1.614, "t1": 0.392, "tft": 5.0381, "input_0": 260, "input_1": 129, "min_CLP": -5.99, "draft_iters": 9.6, "mem_use": 36.84, "gen_rate": 7.2, "speed": 3.59, "text": "\\nThe steps are:\\n\\nFind a marke"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 26.5, "tree_w": 28, "tree_size": 128, "t0": 3.2425, "t1": 0.33, "tft": 2.2957, "input_0": 363, "input_1": 129, "min_CLP": -5.94, "draft_iters": 27.0, "mem_use": 35.2, "gen_rate": 8.8, "speed": 2.45, "text": "\"\\n[INST] <<SYS>>\\nWhy do you th"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 3.83, "t1": 0.33, "tft": 4.2528, "input_0": 427, "input_1": 129, "min_CLP": -6.2, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 33.0, "speed": 7.92, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 4.53, "t1": 0.41, "tft": 8.1636, "input_0": 455, "input_1": 129, "min_CLP": -5.43, "draft_iters": 32.0, "mem_use": 37.32, "gen_rate": 33.0, "speed": 6.68, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 38, "tree_size": 128, "t0": 1.3717, "t1": 0.3583, "tft": 3.0628, "input_0": 243, "input_1": 129, "min_CLP": -5.84, "draft_iters": 9.0, "mem_use": 35.75, "gen_rate": 5.8, "speed": 3.38, "text": "\"\u2022 Reward yourself. Reward yours"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.3, "tree_w": 39, "tree_size": 128, "t0": 1.17, "t1": 0.3444, "tft": 2.2929, "input_0": 218, "input_1": 129, "min_CLP": -6.0, "draft_iters": 7.3, "mem_use": 35.35, "gen_rate": 3.9, "speed": 2.57, "text": "\"A rule of chess is that there i"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.1, "tree_w": 41, "tree_size": 128, "t0": 1.4943, "t1": 0.3286, "tft": 2.2701, "input_0": 249, "input_1": 129, "min_CLP": -6.06, "draft_iters": 10.1, "mem_use": 34.8, "gen_rate": 5.1, "speed": 2.82, "text": "\"The 6th of February, 1992, is t"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 4.33, "t1": 0.33, "tft": 2.3859, "input_0": 624, "input_1": 129, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 34.8, "gen_rate": 33.0, "speed": 7.08, "text": "\"\\nI've recently started playing"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 18.8, "tree_w": 21, "tree_size": 128, "t0": 2.628, "t1": 0.342, "tft": 3.0335, "input_0": 352, "input_1": 129, "min_CLP": -5.67, "draft_iters": 19.8, "mem_use": 35.27, "gen_rate": 9.2, "speed": 3.1, "text": "[INST] Do you have a boyfriend? "}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 128, "t0": 4.24, "t1": 0.36, "tft": 3.9249, "input_0": 517, "input_1": 129, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 35.85, "gen_rate": 33.0, "speed": 7.17, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 34, "tree_size": 128, "t0": 1.75, "t1": 0.34, "tft": 3.9452, "input_0": 312, "input_1": 129, "min_CLP": -6.03, "draft_iters": 11.5, "mem_use": 35.2, "gen_rate": 5.5, "speed": 2.63, "text": "\"I'm a [\\\\INST] and I want to [\\"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 3.39, "t1": 0.34, "tft": 4.0739, "input_0": 247, "input_1": 129, "min_CLP": -6.74, "draft_iters": 32.0, "mem_use": 35.28, "gen_rate": 33.0, "speed": 8.83, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 37, "tree_size": 128, "t0": 1.5325, "t1": 0.3275, "tft": 2.4962, "input_0": 247, "input_1": 129, "min_CLP": -5.93, "draft_iters": 10.8, "mem_use": 34.93, "gen_rate": 8.5, "speed": 4.57, "text": "Yes, this is the same as the ans"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.9, "tree_w": 37, "tree_size": 128, "t0": 1.4586, "t1": 0.33, "tft": 2.3951, "input_0": 253, "input_1": 129, "min_CLP": -5.76, "draft_iters": 9.9, "mem_use": 34.93, "gen_rate": 4.9, "speed": 2.72, "text": "Tenants are superior to landlord"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.0, "tree_w": 21, "tree_size": 128, "t0": 2.915, "t1": 0.35, "tft": 3.4792, "input_0": 358, "input_1": 129, "min_CLP": -5.75, "draft_iters": 21.5, "mem_use": 35.63, "gen_rate": 16.0, "speed": 4.89, "text": "\\n3. Use the Disk Defragmenter:\\"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.5, "tree_w": 43, "tree_size": 128, "t0": 1.3662, "t1": 0.35, "tft": 3.0676, "input_0": 231, "input_1": 129, "min_CLP": -6.0, "draft_iters": 8.5, "mem_use": 35.57, "gen_rate": 4.5, "speed": 2.62, "text": "Open Assistant is a pretrained m"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 57, "tree_size": 128, "t0": 0.9975, "t1": 0.3787, "tft": 4.7701, "input_0": 172, "input_1": 129, "min_CLP": -6.5, "draft_iters": 6.0, "mem_use": 36.3, "gen_rate": 4.1, "speed": 2.99, "text": "\"<</SYS></s>I don't think that i"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 34, "tree_size": 128, "t0": 1.4167, "t1": 0.325, "tft": 3.4159, "input_0": 241, "input_1": 129, "min_CLP": -5.77, "draft_iters": 9.8, "mem_use": 34.95, "gen_rate": 5.5, "speed": 3.16, "text": "\\nGermany is a federal republic."}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.4, "tree_w": 48, "tree_size": 128, "t0": 1.0444, "t1": 0.34, "tft": 2.9011, "input_0": 199, "input_1": 129, "min_CLP": -6.21, "draft_iters": 6.4, "mem_use": 35.21, "gen_rate": 3.6, "speed": 2.57, "text": "PostCSS is a plugin developed by"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 6.4, "tree_w": 44, "tree_size": 128, "t0": 1.2267, "t1": 0.37, "tft": 5.8331, "input_0": 209, "input_1": 129, "min_CLP": -6.17, "draft_iters": 7.4, "mem_use": 36.17, "gen_rate": 4.3, "speed": 2.71, "text": "\\ni know this is a long shot but"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.8, "tree_w": 49, "tree_size": 128, "t0": 1.5063, "t1": 0.3312, "tft": 2.3328, "input_0": 217, "input_1": 129, "min_CLP": -6.24, "draft_iters": 10.8, "mem_use": 34.94, "gen_rate": 4.4, "speed": 2.38, "text": "\"You should definitely create a "}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 22, "tree_size": 128, "t0": 3.93, "t1": 0.35, "tft": 4.5045, "input_0": 398, "input_1": 129, "min_CLP": -6.31, "draft_iters": 32.0, "mem_use": 35.41, "gen_rate": 33.0, "speed": 7.71, "text": "\\nThe static still state is a st"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 128, "max_branch_width": 32, "gen_rate": 11.74, "gen_rate_micro": 7.17, "gen_speed": 4.185, "gen_speed_micro": 3.593, "t0": 2.0905, "t1": 0.3411, "input_0": 286.3, "input_1": 129.0, "tree_size": 128.0, "tree_w": 33.9, "tree_h": 15.0, "prompt_len": 320.7, "min_CLP": -6.04, "mem_use": 39.66, "exp_time": 7235.09}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 87, "tree_size": 256, "t0": 1.7029, "t1": 0.6529, "tft": 3.3234, "input_0": 473, "input_1": 257, "min_CLP": -6.84, "draft_iters": 9.0, "mem_use": 35.06, "gen_rate": 4.7, "speed": 2.0, "text": "\\nA Dyson sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.2, "tree_w": 59, "tree_size": 256, "t0": 2.546, "t1": 0.68, "tft": 4.4309, "input_0": 642, "input_1": 257, "min_CLP": -6.81, "draft_iters": 14.2, "mem_use": 35.8, "gen_rate": 7.2, "speed": 2.23, "text": "\\nWhat is the largest land anima"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.2, "tree_w": 101, "tree_size": 256, "t0": 1.5311, "t1": 0.6922, "tft": 5.0353, "input_0": 419, "input_1": 257, "min_CLP": -7.0, "draft_iters": 7.2, "mem_use": 36.19, "gen_rate": 4.2, "speed": 1.9, "text": "\"\\nThe chat is a big factor in t"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 17.8, "tree_w": 73, "tree_size": 256, "t0": 2.65, "t1": 0.655, "tft": 4.4649, "input_0": 499, "input_1": 257, "min_CLP": -7.18, "draft_iters": 18.7, "mem_use": 35.16, "gen_rate": 5.3, "speed": 1.61, "text": "\\nSimilar to C#:\\n\\n#!/usr/bin/e"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 256, "t0": 4.79, "t1": 0.65, "tft": 4.5969, "input_0": 797, "input_1": 257, "min_CLP": -7.06, "draft_iters": 32.0, "mem_use": 35.08, "gen_rate": 33.0, "speed": 6.07, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 24.3, "tree_w": 33, "tree_size": 256, "t0": 4.14, "t1": 0.7, "tft": 6.5391, "input_0": 835, "input_1": 257, "min_CLP": -6.45, "draft_iters": 25.3, "mem_use": 36.35, "gen_rate": 10.7, "speed": 2.2, "text": "\\n1. Introduction: Define the co"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 59, "tree_size": 256, "t0": 2.93, "t1": 0.71, "tft": 5.6842, "input_0": 757, "input_1": 257, "min_CLP": -6.85, "draft_iters": 15.0, "mem_use": 36.67, "gen_rate": 8.8, "speed": 2.4, "text": "There are a number of other mach"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.7, "tree_w": 70, "tree_size": 256, "t0": 2.59, "t1": 0.7567, "tft": 8.4527, "input_0": 556, "input_1": 257, "min_CLP": -6.52, "draft_iters": 13.8, "mem_use": 37.78, "gen_rate": 6.2, "speed": 1.84, "text": "\\n1. Social media marketing: The"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 23.5, "tree_w": 38, "tree_size": 256, "t0": 3.655, "t1": 0.81, "tft": 5.3096, "input_0": 673, "input_1": 257, "min_CLP": -6.77, "draft_iters": 24.0, "mem_use": 36.4, "gen_rate": 21.5, "speed": 4.82, "text": "\\nLegal status of marijuana for "}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 79, "tree_size": 256, "t0": 1.9429, "t1": 0.6914, "tft": 4.3806, "input_0": 560, "input_1": 257, "min_CLP": -6.52, "draft_iters": 8.9, "mem_use": 36.18, "gen_rate": 4.7, "speed": 1.79, "text": "There are many hobbies that you "}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 27.3, "tree_w": 54, "tree_size": 256, "t0": 3.74, "t1": 0.66, "tft": 4.0948, "input_0": 652, "input_1": 257, "min_CLP": -6.58, "draft_iters": 27.7, "mem_use": 35.42, "gen_rate": 15.3, "speed": 3.49, "text": "\\nWrite a program that takes two"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.6, "tree_w": 97, "tree_size": 256, "t0": 1.6443, "t1": 0.7, "tft": 4.7138, "input_0": 418, "input_1": 257, "min_CLP": -7.02, "draft_iters": 8.6, "mem_use": 36.34, "gen_rate": 4.6, "speed": 1.95, "text": "\"\\nWhat is your favorite type of"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 80, "tree_size": 256, "t0": 2.045, "t1": 0.6833, "tft": 4.7001, "input_0": 497, "input_1": 257, "min_CLP": -6.92, "draft_iters": 11.7, "mem_use": 35.97, "gen_rate": 5.5, "speed": 2.01, "text": "\\nThis is a great idea!\\n\\nHere "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.0, "tree_w": 66, "tree_size": 256, "t0": 2.2517, "t1": 0.6533, "tft": 4.6356, "input_0": 549, "input_1": 257, "min_CLP": -7.2, "draft_iters": 13.2, "mem_use": 35.07, "gen_rate": 6.8, "speed": 2.35, "text": "\\nAustralia is the continent, an"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 30.0, "tree_w": 36, "tree_size": 256, "t0": 4.3267, "t1": 0.71, "tft": 5.9838, "input_0": 649, "input_1": 257, "min_CLP": -6.13, "draft_iters": 30.3, "mem_use": 36.67, "gen_rate": 12.3, "speed": 2.45, "text": "Learning a language can be chall"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 21.6, "tree_w": 72, "tree_size": 256, "t0": 3.004, "t1": 0.652, "tft": 3.1678, "input_0": 536, "input_1": 257, "min_CLP": -6.69, "draft_iters": 22.0, "mem_use": 35.2, "gen_rate": 6.4, "speed": 1.75, "text": "\\nThe minimum upload speed to st"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 256, "t0": 5.17, "t1": 0.65, "tft": 3.3888, "input_0": 1073, "input_1": 257, "min_CLP": -8.14, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 5.67, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.9, "tree_w": 81, "tree_size": 256, "t0": 1.7075, "t1": 0.65, "tft": 4.7839, "input_0": 476, "input_1": 257, "min_CLP": -6.8, "draft_iters": 8.9, "mem_use": 35.07, "gen_rate": 4.8, "speed": 2.01, "text": "\\nThe world is a beautiful place"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.5, "tree_w": 61, "tree_size": 256, "t0": 2.4225, "t1": 0.66, "tft": 3.904, "input_0": 601, "input_1": 257, "min_CLP": -6.41, "draft_iters": 14.0, "mem_use": 35.4, "gen_rate": 8.5, "speed": 2.76, "text": "D-theanine is the form found in "}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.5, "tree_w": 68, "tree_size": 256, "t0": 2.0117, "t1": 0.6517, "tft": 3.44, "input_0": 589, "input_1": 257, "min_CLP": -6.58, "draft_iters": 10.7, "mem_use": 35.07, "gen_rate": 5.5, "speed": 2.06, "text": "\\nThe Balfour Declaration was a "}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 31.5, "tree_w": 44, "tree_size": 256, "t0": 4.445, "t1": 0.67, "tft": 4.7348, "input_0": 717, "input_1": 257, "min_CLP": -6.98, "draft_iters": 32.0, "mem_use": 35.54, "gen_rate": 20.0, "speed": 3.91, "text": "\\n<SYS>\\n\\nYou are a helpful, re"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 14.2, "tree_w": 83, "tree_size": 256, "t0": 2.2575, "t1": 0.65, "tft": 4.4865, "input_0": 464, "input_1": 257, "min_CLP": -6.7, "draft_iters": 15.0, "mem_use": 35.06, "gen_rate": 11.2, "speed": 3.87, "text": "\\nI am very glad to have you her"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 81, "tree_size": 256, "t0": 1.9983, "t1": 0.7, "tft": 6.4479, "input_0": 514, "input_1": 257, "min_CLP": -6.62, "draft_iters": 10.2, "mem_use": 36.3, "gen_rate": 6.2, "speed": 2.29, "text": "A bimodal distribution is a dist"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 13.7, "tree_w": 74, "tree_size": 256, "t0": 2.3943, "t1": 0.6514, "tft": 2.9616, "input_0": 557, "input_1": 257, "min_CLP": -6.79, "draft_iters": 14.9, "mem_use": 35.11, "gen_rate": 4.6, "speed": 1.5, "text": "\\nIf so, describe the process us"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 32.0, "tree_w": 40, "tree_size": 256, "t0": 4.575, "t1": 0.67, "tft": 4.6638, "input_0": 767, "input_1": 257, "min_CLP": -6.88, "draft_iters": 32.0, "mem_use": 35.65, "gen_rate": 17.0, "speed": 3.24, "text": "[INST] send mail to Sarah asking"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 256, "t0": 4.64, "t1": 0.65, "tft": 2.9032, "input_0": 878, "input_1": 257, "min_CLP": -6.87, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 6.23, "text": "\"\\nWhat are some Nietzsche's phi"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.8, "tree_w": 84, "tree_size": 256, "t0": 1.9783, "t1": 0.6617, "tft": 3.3345, "input_0": 557, "input_1": 257, "min_CLP": -6.91, "draft_iters": 10.0, "mem_use": 35.42, "gen_rate": 5.8, "speed": 2.21, "text": "\"Austenite is a form of iron tha"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.6, "tree_w": 102, "tree_size": 256, "t0": 1.68, "t1": 0.66, "tft": 3.0557, "input_0": 459, "input_1": 257, "min_CLP": -7.65, "draft_iters": 8.8, "mem_use": 35.37, "gen_rate": 4.4, "speed": 1.87, "text": "\\nComplete the following company"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.4, "tree_w": 74, "tree_size": 256, "t0": 2.2714, "t1": 0.7, "tft": 6.0682, "input_0": 506, "input_1": 257, "min_CLP": -6.82, "draft_iters": 13.4, "mem_use": 36.32, "gen_rate": 4.7, "speed": 1.59, "text": "I am a mage of the College of Wi"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.2, "tree_w": 68, "tree_size": 256, "t0": 2.2917, "t1": 0.65, "tft": 3.4154, "input_0": 534, "input_1": 257, "min_CLP": -6.65, "draft_iters": 13.3, "mem_use": 35.1, "gen_rate": 6.7, "speed": 2.26, "text": "\\nWhat are some of the best micr"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.8, "tree_w": 58, "tree_size": 256, "t0": 2.398, "t1": 0.662, "tft": 4.9715, "input_0": 609, "input_1": 257, "min_CLP": -6.65, "draft_iters": 13.8, "mem_use": 35.44, "gen_rate": 7.2, "speed": 2.35, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 19.0, "tree_w": 51, "tree_size": 256, "t0": 3.225, "t1": 0.6725, "tft": 4.2873, "input_0": 682, "input_1": 257, "min_CLP": -6.66, "draft_iters": 19.8, "mem_use": 35.7, "gen_rate": 14.2, "speed": 3.66, "text": "\"[Instagram questions]: {How to "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 4.74, "t1": 0.66, "tft": 4.8091, "input_0": 804, "input_1": 257, "min_CLP": -7.35, "draft_iters": 32.0, "mem_use": 35.33, "gen_rate": 33.0, "speed": 6.12, "text": "[INST] Dear Freya, goddess of lo"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 72, "tree_size": 256, "t0": 1.9683, "t1": 0.69, "tft": 3.8875, "input_0": 542, "input_1": 257, "min_CLP": -6.59, "draft_iters": 9.0, "mem_use": 36.16, "gen_rate": 5.5, "speed": 2.07, "text": "\"Cheese is important to a lot of"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.4, "tree_w": 78, "tree_size": 256, "t0": 1.9686, "t1": 0.69, "tft": 3.7892, "input_0": 463, "input_1": 257, "min_CLP": -6.8, "draft_iters": 11.6, "mem_use": 36.12, "gen_rate": 5.6, "speed": 2.1, "text": "If you are looking for a good IS"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.2, "tree_w": 84, "tree_size": 256, "t0": 2.3583, "t1": 0.76, "tft": 7.239, "input_0": 626, "input_1": 257, "min_CLP": -6.78, "draft_iters": 10.8, "mem_use": 37.85, "gen_rate": 5.7, "speed": 1.82, "text": "Selenium is a great testing fram"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 84, "tree_size": 256, "t0": 1.89, "t1": 0.65, "tft": 4.6865, "input_0": 478, "input_1": 257, "min_CLP": -6.91, "draft_iters": 10.5, "mem_use": 35.5, "gen_rate": 5.3, "speed": 2.1, "text": "\\nIt is not a question of how fa"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 256, "t0": 4.7, "t1": 0.66, "tft": 4.801, "input_0": 910, "input_1": 257, "min_CLP": -5.7, "draft_iters": 32.0, "mem_use": 35.36, "gen_rate": 33.0, "speed": 6.15, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.0, "tree_w": 84, "tree_size": 256, "t0": 2.2771, "t1": 0.7086, "tft": 5.9393, "input_0": 497, "input_1": 257, "min_CLP": -6.77, "draft_iters": 13.3, "mem_use": 36.54, "gen_rate": 4.9, "speed": 1.63, "text": "\"\\nHi, this is Mike. I'm glad yo"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 86, "tree_size": 256, "t0": 1.8583, "t1": 0.67, "tft": 3.7217, "input_0": 549, "input_1": 257, "min_CLP": -6.85, "draft_iters": 9.2, "mem_use": 35.53, "gen_rate": 6.0, "speed": 2.38, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 32.0, "tree_w": 21, "tree_size": 256, "t0": 4.905, "t1": 0.655, "tft": 2.7763, "input_0": 1009, "input_1": 257, "min_CLP": -6.38, "draft_iters": 32.0, "mem_use": 35.19, "gen_rate": 30.5, "speed": 5.49, "text": "\\nAct as the Norse Goddess Freya"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 25.0, "tree_w": 70, "tree_size": 256, "t0": 3.555, "t1": 0.7, "tft": 6.6395, "input_0": 508, "input_1": 257, "min_CLP": -6.84, "draft_iters": 26.0, "mem_use": 36.42, "gen_rate": 16.0, "speed": 3.76, "text": "\\nWrite a dialogue. Do not offer"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 86, "tree_size": 256, "t0": 1.7525, "t1": 0.71, "tft": 5.2338, "input_0": 476, "input_1": 257, "min_CLP": -6.94, "draft_iters": 7.9, "mem_use": 36.66, "gen_rate": 4.2, "speed": 1.72, "text": "\\nI am working on a documentary "}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 75, "tree_size": 256, "t0": 2.2, "t1": 0.68, "tft": 4.6161, "input_0": 569, "input_1": 257, "min_CLP": -6.52, "draft_iters": 11.5, "mem_use": 35.91, "gen_rate": 5.8, "speed": 2.03, "text": "There is no \"best\" tool; it depe"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.4, "tree_w": 73, "tree_size": 256, "t0": 1.968, "t1": 0.666, "tft": 3.1098, "input_0": 603, "input_1": 257, "min_CLP": -7.0, "draft_iters": 9.8, "mem_use": 35.49, "gen_rate": 7.4, "speed": 2.81, "text": "\"You're welcome!\\n\\nWhat is the "}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 32.0, "tree_w": 36, "tree_size": 256, "t0": 4.3, "t1": 0.66, "tft": 4.7996, "input_0": 671, "input_1": 257, "min_CLP": -6.78, "draft_iters": 32.0, "mem_use": 35.39, "gen_rate": 22.0, "speed": 4.43, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 83, "tree_size": 256, "t0": 1.5857, "t1": 0.65, "tft": 4.6577, "input_0": 473, "input_1": 257, "min_CLP": -6.79, "draft_iters": 7.6, "mem_use": 35.1, "gen_rate": 5.0, "speed": 2.23, "text": "\"\\nThis is a very basic question"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 256, "t0": 4.85, "t1": 0.76, "tft": 8.4218, "input_0": 653, "input_1": 257, "min_CLP": -7.25, "draft_iters": 32.0, "mem_use": 37.88, "gen_rate": 33.0, "speed": 5.88, "text": "\\n[The scene opens with a Sparta"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.9, "tree_w": 98, "tree_size": 256, "t0": 1.66, "t1": 0.6812, "tft": 4.4433, "input_0": 450, "input_1": 257, "min_CLP": -7.09, "draft_iters": 8.2, "mem_use": 35.96, "gen_rate": 4.2, "speed": 1.81, "text": "\\nYou have been given the opport"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.2, "tree_w": 100, "tree_size": 256, "t0": 1.6, "t1": 0.6625, "tft": 3.0395, "input_0": 427, "input_1": 257, "min_CLP": -7.03, "draft_iters": 8.5, "mem_use": 35.48, "gen_rate": 4.8, "speed": 2.1, "text": "\"\\nIt is not surprising that a l"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 63, "tree_size": 256, "t0": 2.45, "t1": 0.6633, "tft": 4.8984, "input_0": 525, "input_1": 257, "min_CLP": -6.77, "draft_iters": 15.7, "mem_use": 35.5, "gen_rate": 10.7, "speed": 3.42, "text": "\\nIn this paper, we propose a ne"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 256, "t0": 5.04, "t1": 0.69, "tft": 7.307, "input_0": 1016, "input_1": 257, "min_CLP": -6.65, "draft_iters": 32.0, "mem_use": 36.19, "gen_rate": 33.0, "speed": 5.76, "text": "\\nF-centers are crystallographic"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 8.2, "tree_w": 66, "tree_size": 256, "t0": 1.9867, "t1": 0.675, "tft": 4.2965, "input_0": 562, "input_1": 257, "min_CLP": -6.64, "draft_iters": 9.5, "mem_use": 35.76, "gen_rate": 6.8, "speed": 2.57, "text": "\\nThe year 18th century was a pe"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 84, "tree_size": 256, "t0": 2.096, "t1": 0.682, "tft": 3.9991, "input_0": 605, "input_1": 257, "min_CLP": -6.68, "draft_iters": 10.6, "mem_use": 35.95, "gen_rate": 7.0, "speed": 2.52, "text": "Yes, technology can be used for "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 86, "tree_size": 256, "t0": 1.8129, "t1": 0.6543, "tft": 3.5052, "input_0": 481, "input_1": 257, "min_CLP": -7.06, "draft_iters": 9.9, "mem_use": 35.18, "gen_rate": 4.7, "speed": 1.91, "text": "Short shorts refer to shorts tha"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 19.5, "tree_w": 55, "tree_size": 256, "t0": 3.1212, "t1": 0.6987, "tft": 5.3034, "input_0": 586, "input_1": 257, "min_CLP": -6.64, "draft_iters": 20.6, "mem_use": 36.25, "gen_rate": 4.0, "speed": 1.05, "text": "\"Okay, let's create a pitch deck"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.8, "tree_w": 53, "tree_size": 256, "t0": 2.916, "t1": 0.726, "tft": 7.8889, "input_0": 589, "input_1": 257, "min_CLP": -6.44, "draft_iters": 16.8, "mem_use": 37.01, "gen_rate": 6.6, "speed": 1.81, "text": "\\nA consistent, correct answer w"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 67, "tree_size": 256, "t0": 2.1317, "t1": 0.73, "tft": 6.7036, "input_0": 577, "input_1": 257, "min_CLP": -6.42, "draft_iters": 10.0, "mem_use": 37.18, "gen_rate": 5.7, "speed": 1.98, "text": "I would definitely recommend lea"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 77, "tree_size": 256, "t0": 1.93, "t1": 0.68, "tft": 4.7163, "input_0": 510, "input_1": 257, "min_CLP": -6.73, "draft_iters": 9.5, "mem_use": 35.92, "gen_rate": 5.5, "speed": 2.11, "text": "I believe that it is important t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.6, "tree_w": 39, "tree_size": 256, "t0": 2.582, "t1": 0.65, "tft": 3.1775, "input_0": 603, "input_1": 257, "min_CLP": -6.33, "draft_iters": 15.6, "mem_use": 35.1, "gen_rate": 7.0, "speed": 2.17, "text": "What is the best way to be happy"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 16, "tree_size": 256, "t0": 5.87, "t1": 0.7, "tft": 5.8756, "input_0": 1386, "input_1": 257, "min_CLP": -6.32, "draft_iters": 32.0, "mem_use": 36.28, "gen_rate": 32.0, "speed": 4.87, "text": "\\nCan you cook an egg only using"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.9, "tree_w": 79, "tree_size": 256, "t0": 1.8957, "t1": 0.7114, "tft": 5.4288, "input_0": 515, "input_1": 257, "min_CLP": -6.67, "draft_iters": 9.1, "mem_use": 36.71, "gen_rate": 4.9, "speed": 1.86, "text": "[The spartan general is sitting "}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 23.2, "tree_w": 71, "tree_size": 256, "t0": 3.355, "t1": 0.67, "tft": 2.7767, "input_0": 561, "input_1": 257, "min_CLP": -6.88, "draft_iters": 23.8, "mem_use": 35.56, "gen_rate": 12.0, "speed": 2.98, "text": "\\nTry this one:\\n[INST] <<SYS>>\\"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 96, "tree_size": 256, "t0": 1.6714, "t1": 0.6614, "tft": 3.684, "input_0": 460, "input_1": 257, "min_CLP": -6.91, "draft_iters": 8.4, "mem_use": 35.44, "gen_rate": 5.0, "speed": 2.14, "text": "\\nWhy is Ethereum so popular? [\\"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.5, "tree_w": 106, "tree_size": 256, "t0": 1.7, "t1": 0.6625, "tft": 3.034, "input_0": 415, "input_1": 257, "min_CLP": -7.04, "draft_iters": 9.5, "mem_use": 35.46, "gen_rate": 4.4, "speed": 1.85, "text": "\\nBecause the other would be Hit"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.9, "tree_w": 54, "tree_size": 256, "t0": 2.6271, "t1": 0.7229, "tft": 5.376, "input_0": 614, "input_1": 257, "min_CLP": -6.57, "draft_iters": 13.9, "mem_use": 36.93, "gen_rate": 5.0, "speed": 1.49, "text": "\\nvoid *p;\\nint i;\\nvoid main() "}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 62, "tree_size": 256, "t0": 2.148, "t1": 0.716, "tft": 7.802, "input_0": 600, "input_1": 257, "min_CLP": -6.49, "draft_iters": 10.4, "mem_use": 36.8, "gen_rate": 6.6, "speed": 2.31, "text": "\"Hello Mike, I'm sorry to hear t"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 80, "tree_size": 256, "t0": 1.9817, "t1": 0.7, "tft": 4.8426, "input_0": 559, "input_1": 257, "min_CLP": -6.57, "draft_iters": 9.5, "mem_use": 36.41, "gen_rate": 5.5, "speed": 2.05, "text": "This is a great question, and I "}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 97, "tree_size": 256, "t0": 1.9567, "t1": 0.6567, "tft": 4.1801, "input_0": 562, "input_1": 257, "min_CLP": -7.02, "draft_iters": 10.3, "mem_use": 35.3, "gen_rate": 5.3, "speed": 2.04, "text": "\"\\nWhat is the scariest thing yo"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 44, "tree_size": 256, "t0": 4.19, "t1": 0.65, "tft": 4.505, "input_0": 644, "input_1": 257, "min_CLP": -6.91, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 6.81, "text": "\\nExplain why landlords can be c"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.0, "tree_w": 66, "tree_size": 256, "t0": 2.9433, "t1": 0.7, "tft": 6.3092, "input_0": 950, "input_1": 257, "min_CLP": -6.61, "draft_iters": 13.3, "mem_use": 36.32, "gen_rate": 11.7, "speed": 3.2, "text": "\"Certainly, here's a table of th"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 46, "tree_size": 256, "t0": 4.02, "t1": 0.65, "tft": 4.3509, "input_0": 609, "input_1": 257, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 35.05, "gen_rate": 33.0, "speed": 7.07, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.4, "tree_w": 102, "tree_size": 256, "t0": 1.64, "t1": 0.6912, "tft": 6.427, "input_0": 426, "input_1": 257, "min_CLP": -6.91, "draft_iters": 8.6, "mem_use": 36.22, "gen_rate": 4.6, "speed": 1.98, "text": "\"\\nI just found my grandmother's"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 84, "tree_size": 256, "t0": 1.8529, "t1": 0.6929, "tft": 5.5051, "input_0": 509, "input_1": 257, "min_CLP": -6.79, "draft_iters": 8.7, "mem_use": 36.16, "gen_rate": 4.7, "speed": 1.85, "text": "\\nThe book is unique in the fact"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.6, "tree_w": 100, "tree_size": 256, "t0": 1.5611, "t1": 0.65, "tft": 3.0053, "input_0": 433, "input_1": 257, "min_CLP": -7.0, "draft_iters": 7.7, "mem_use": 35.07, "gen_rate": 4.0, "speed": 1.81, "text": "\"\\nAnswer:\\n\\nSexuality is a par"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 57, "tree_size": 256, "t0": 2.67, "t1": 0.6575, "tft": 2.9768, "input_0": 558, "input_1": 257, "min_CLP": -6.44, "draft_iters": 17.2, "mem_use": 35.24, "gen_rate": 8.8, "speed": 2.63, "text": "\"[INST] How to check current tim"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 93, "tree_size": 256, "t0": 1.68, "t1": 0.655, "tft": 2.716, "input_0": 478, "input_1": 257, "min_CLP": -6.98, "draft_iters": 8.0, "mem_use": 35.26, "gen_rate": 5.3, "speed": 2.28, "text": "\\nCommon Sense [\\\\INST]\\nCommon "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 27.5, "tree_w": 36, "tree_size": 256, "t0": 4.055, "t1": 0.65, "tft": 4.2285, "input_0": 743, "input_1": 257, "min_CLP": -6.54, "draft_iters": 28.0, "mem_use": 35.11, "gen_rate": 16.5, "speed": 3.5, "text": "\\nI have 12 eggs. I drop 2 and e"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.9, "tree_w": 80, "tree_size": 256, "t0": 2.2629, "t1": 0.6686, "tft": 3.8288, "input_0": 581, "input_1": 257, "min_CLP": -6.65, "draft_iters": 12.9, "mem_use": 35.5, "gen_rate": 4.9, "speed": 1.66, "text": "The Riemann Hypothesis states th"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 2.34, "t1": 0.66, "tft": 2.6832, "input_0": 680, "input_1": 257, "min_CLP": -6.74, "draft_iters": 12.0, "mem_use": 35.28, "gen_rate": 7.0, "speed": 2.34, "text": "\"You're welcome. Good luck with "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 27.5, "tree_w": 44, "tree_size": 256, "t0": 4.29, "t1": 0.655, "tft": 2.9055, "input_0": 874, "input_1": 257, "min_CLP": -6.75, "draft_iters": 28.0, "mem_use": 35.14, "gen_rate": 18.0, "speed": 3.64, "text": "\\nWrite a post on Medium.com abo"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.4, "tree_w": 85, "tree_size": 256, "t0": 1.8014, "t1": 0.66, "tft": 3.5694, "input_0": 504, "input_1": 257, "min_CLP": -6.89, "draft_iters": 9.7, "mem_use": 35.44, "gen_rate": 5.4, "speed": 2.2, "text": "In animals, sexual selection has"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.7, "tree_w": 60, "tree_size": 256, "t0": 2.4343, "t1": 0.6857, "tft": 4.1342, "input_0": 572, "input_1": 257, "min_CLP": -6.37, "draft_iters": 13.9, "mem_use": 35.99, "gen_rate": 4.7, "speed": 1.51, "text": "In order to make AI assistants m"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 32.0, "tree_w": 19, "tree_size": 256, "t0": 5.06, "t1": 0.705, "tft": 7.375, "input_0": 961, "input_1": 257, "min_CLP": -6.44, "draft_iters": 32.0, "mem_use": 36.48, "gen_rate": 27.5, "speed": 4.77, "text": "\\n[Outro]\\nAnother one bites the"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.6, "tree_w": 71, "tree_size": 256, "t0": 2.0386, "t1": 0.68, "tft": 3.2753, "input_0": 497, "input_1": 257, "min_CLP": -6.69, "draft_iters": 11.6, "mem_use": 35.78, "gen_rate": 4.9, "speed": 1.79, "text": "No, scp works on any operating s"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 256, "t0": 5.16, "t1": 0.69, "tft": 5.4544, "input_0": 967, "input_1": 257, "min_CLP": -6.55, "draft_iters": 32.0, "mem_use": 36.22, "gen_rate": 33.0, "speed": 5.64, "text": "\\nPlease give me a recipe I can "}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.8, "tree_w": 74, "tree_size": 256, "t0": 2.335, "t1": 0.65, "tft": 4.4702, "input_0": 540, "input_1": 257, "min_CLP": -6.68, "draft_iters": 14.0, "mem_use": 35.1, "gen_rate": 6.7, "speed": 2.23, "text": "\"\\n[INST] <<SYS>>\\nOf course not"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.7, "tree_w": 82, "tree_size": 256, "t0": 1.9233, "t1": 0.6583, "tft": 4.8263, "input_0": 590, "input_1": 257, "min_CLP": -6.81, "draft_iters": 9.7, "mem_use": 35.24, "gen_rate": 6.7, "speed": 2.59, "text": "\"Melbourne is the largest city i"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 56, "tree_size": 256, "t0": 3.95, "t1": 0.66, "tft": 2.9808, "input_0": 584, "input_1": 257, "min_CLP": -7.09, "draft_iters": 32.0, "mem_use": 35.38, "gen_rate": 33.0, "speed": 7.15, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.9, "tree_w": 100, "tree_size": 256, "t0": 1.6413, "t1": 0.6512, "tft": 2.5151, "input_0": 469, "input_1": 257, "min_CLP": -7.08, "draft_iters": 8.1, "mem_use": 35.23, "gen_rate": 4.4, "speed": 1.91, "text": "\\nYou are a quick thinker, and a"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.0, "tree_w": 74, "tree_size": 256, "t0": 2.276, "t1": 0.652, "tft": 3.2713, "input_0": 560, "input_1": 257, "min_CLP": -6.96, "draft_iters": 13.4, "mem_use": 35.12, "gen_rate": 7.6, "speed": 2.59, "text": "\\nWhat are some of the best ways"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.1, "tree_w": 92, "tree_size": 256, "t0": 1.815, "t1": 0.6512, "tft": 3.4811, "input_0": 448, "input_1": 257, "min_CLP": -6.86, "draft_iters": 10.2, "mem_use": 35.11, "gen_rate": 4.5, "speed": 1.82, "text": "\\n<<SYS>>\\n\\nYou would need to w"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.5, "tree_w": 78, "tree_size": 256, "t0": 1.8675, "t1": 0.6837, "tft": 5.7584, "input_0": 497, "input_1": 257, "min_CLP": -6.82, "draft_iters": 9.8, "mem_use": 35.93, "gen_rate": 4.6, "speed": 1.81, "text": "The Modularity Theorem is a math"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 32.0, "tree_w": 38, "tree_size": 256, "t0": 4.34, "t1": 0.65, "tft": 3.6515, "input_0": 792, "input_1": 257, "min_CLP": -6.99, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 15.0, "speed": 3.01, "text": "\\n<<SYS>>\\n\\n<<INST>>\\n\\n<<SYS>>"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 256, "t0": 4.77, "t1": 0.66, "tft": 4.7283, "input_0": 901, "input_1": 257, "min_CLP": -7.02, "draft_iters": 32.0, "mem_use": 35.26, "gen_rate": 33.0, "speed": 6.08, "text": "\\nHow can you write a first pers"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.4, "tree_w": 84, "tree_size": 256, "t0": 1.9157, "t1": 0.6514, "tft": 3.3522, "input_0": 529, "input_1": 257, "min_CLP": -6.74, "draft_iters": 9.9, "mem_use": 35.1, "gen_rate": 4.7, "speed": 1.84, "text": "\"\\nThis is a question I've notic"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.5, "tree_w": 83, "tree_size": 256, "t0": 1.74, "t1": 0.655, "tft": 2.7575, "input_0": 473, "input_1": 257, "min_CLP": -6.69, "draft_iters": 9.5, "mem_use": 35.24, "gen_rate": 6.0, "speed": 2.51, "text": "[SYS] You must be patient, young"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 15.4, "tree_w": 50, "tree_size": 256, "t0": 2.978, "t1": 0.656, "tft": 3.0362, "input_0": 766, "input_1": 257, "min_CLP": -6.44, "draft_iters": 16.8, "mem_use": 35.17, "gen_rate": 8.2, "speed": 2.26, "text": "The operating mechanism is gas-o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 88, "tree_size": 256, "t0": 1.71, "t1": 0.6557, "tft": 2.9949, "input_0": 484, "input_1": 257, "min_CLP": -6.89, "draft_iters": 8.3, "mem_use": 35.3, "gen_rate": 4.7, "speed": 2.0, "text": "\\n\"The Office\" is a very good sh"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.9, "tree_w": 79, "tree_size": 256, "t0": 2.0278, "t1": 0.73, "tft": 5.7235, "input_0": 565, "input_1": 257, "min_CLP": -6.82, "draft_iters": 9.2, "mem_use": 37.14, "gen_rate": 4.0, "speed": 1.45, "text": "\"I'm afraid I don't know of any "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.1, "tree_w": 64, "tree_size": 256, "t0": 1.9514, "t1": 0.6586, "tft": 2.7297, "input_0": 529, "input_1": 257, "min_CLP": -6.58, "draft_iters": 10.1, "mem_use": 35.32, "gen_rate": 4.7, "speed": 1.81, "text": "It is a very common courtesy to "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 13.1, "tree_w": 66, "tree_size": 256, "t0": 2.4838, "t1": 0.7187, "tft": 6.6915, "input_0": 548, "input_1": 257, "min_CLP": -6.4, "draft_iters": 13.9, "mem_use": 36.85, "gen_rate": 4.4, "speed": 1.37, "text": "\"Hello, it's a pleasure to answe"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.1, "tree_w": 91, "tree_size": 256, "t0": 1.8325, "t1": 0.6625, "tft": 3.0269, "input_0": 500, "input_1": 257, "min_CLP": -6.86, "draft_iters": 9.6, "mem_use": 35.49, "gen_rate": 4.8, "speed": 1.9, "text": "This is true, but we should not "}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.2, "tree_w": 92, "tree_size": 256, "t0": 1.625, "t1": 0.6537, "tft": 4.6977, "input_0": 434, "input_1": 257, "min_CLP": -6.95, "draft_iters": 8.2, "mem_use": 35.28, "gen_rate": 4.6, "speed": 2.03, "text": "\"I don't like to do a lot of exp"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 79, "tree_size": 256, "t0": 1.9333, "t1": 0.6833, "tft": 5.5185, "input_0": 582, "input_1": 257, "min_CLP": -6.96, "draft_iters": 9.0, "mem_use": 35.96, "gen_rate": 5.5, "speed": 2.1, "text": "This is a hard question, as the "}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.4, "tree_w": 75, "tree_size": 256, "t0": 2.0171, "t1": 0.6543, "tft": 2.9445, "input_0": 506, "input_1": 257, "min_CLP": -6.59, "draft_iters": 11.6, "mem_use": 35.26, "gen_rate": 5.0, "speed": 1.87, "text": "\"I would not answer this because"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 66, "tree_size": 256, "t0": 2.122, "t1": 0.7, "tft": 5.7726, "input_0": 539, "input_1": 257, "min_CLP": -6.57, "draft_iters": 10.8, "mem_use": 36.29, "gen_rate": 6.8, "speed": 2.41, "text": "\"\\nA great way to acquire revenu"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 12.6, "tree_w": 92, "tree_size": 256, "t0": 2.1343, "t1": 0.67, "tft": 4.1199, "input_0": 470, "input_1": 257, "min_CLP": -6.96, "draft_iters": 13.6, "mem_use": 35.56, "gen_rate": 4.6, "speed": 1.63, "text": "[INST] As an example, you could "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.7, "tree_w": 80, "tree_size": 256, "t0": 2.1167, "t1": 0.66, "tft": 2.4569, "input_0": 625, "input_1": 257, "min_CLP": -6.77, "draft_iters": 11.0, "mem_use": 35.37, "gen_rate": 6.0, "speed": 2.16, "text": "I can\u2019t find any references on t"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.7, "tree_w": 54, "tree_size": 256, "t0": 2.54, "t1": 0.66, "tft": 2.7712, "input_0": 697, "input_1": 257, "min_CLP": -6.66, "draft_iters": 13.0, "mem_use": 35.45, "gen_rate": 6.0, "speed": 1.87, "text": "API: Application Programming Int"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 32.0, "tree_w": 65, "tree_size": 256, "t0": 4.265, "t1": 0.69, "tft": 6.2937, "input_0": 589, "input_1": 257, "min_CLP": -6.94, "draft_iters": 32.0, "mem_use": 36.09, "gen_rate": 29.0, "speed": 5.85, "text": "Tolkien\\'s Quenya is a fictional"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 19.0, "tree_w": 48, "tree_size": 256, "t0": 2.88, "t1": 0.65, "tft": 3.0505, "input_0": 587, "input_1": 257, "min_CLP": -6.6, "draft_iters": 19.7, "mem_use": 35.1, "gen_rate": 17.3, "speed": 4.91, "text": "\\nWhat is the best way to improv"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 15.6, "tree_w": 79, "tree_size": 256, "t0": 2.3814, "t1": 0.65, "tft": 4.0071, "input_0": 472, "input_1": 257, "min_CLP": -6.88, "draft_iters": 16.4, "mem_use": 35.11, "gen_rate": 6.0, "speed": 1.98, "text": "\\nIt is not a valid class.\\n\\nTh"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 37, "tree_size": 256, "t0": 4.27, "t1": 0.68, "tft": 4.0394, "input_0": 673, "input_1": 257, "min_CLP": -7.65, "draft_iters": 32.0, "mem_use": 35.79, "gen_rate": 33.0, "speed": 6.67, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 66, "tree_size": 256, "t0": 2.032, "t1": 0.66, "tft": 3.2237, "input_0": 557, "input_1": 257, "min_CLP": -6.85, "draft_iters": 11.2, "mem_use": 35.45, "gen_rate": 6.8, "speed": 2.52, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 95, "tree_size": 256, "t0": 1.7929, "t1": 0.6657, "tft": 3.0642, "input_0": 463, "input_1": 257, "min_CLP": -7.0, "draft_iters": 9.6, "mem_use": 35.49, "gen_rate": 4.6, "speed": 1.86, "text": "The easiest way to do this is to"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 15.0, "tree_w": 63, "tree_size": 256, "t0": 2.846, "t1": 0.7, "tft": 5.1582, "input_0": 628, "input_1": 257, "min_CLP": -6.45, "draft_iters": 16.0, "mem_use": 36.37, "gen_rate": 12.0, "speed": 3.38, "text": "\"It's great that you're sticking"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 34, "tree_size": 256, "t0": 4.27, "t1": 0.66, "tft": 4.7385, "input_0": 684, "input_1": 257, "min_CLP": -6.37, "draft_iters": 32.0, "mem_use": 35.38, "gen_rate": 33.0, "speed": 6.69, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 14.2, "tree_w": 63, "tree_size": 256, "t0": 2.5033, "t1": 0.6867, "tft": 5.3577, "input_0": 586, "input_1": 257, "min_CLP": -6.49, "draft_iters": 15.2, "mem_use": 35.99, "gen_rate": 6.3, "speed": 1.99, "text": "The earliest known fossils of ho"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 44, "tree_size": 256, "t0": 3.2275, "t1": 0.65, "tft": 3.6639, "input_0": 608, "input_1": 257, "min_CLP": -6.26, "draft_iters": 22.2, "mem_use": 35.07, "gen_rate": 8.2, "speed": 2.13, "text": "Can you think and feel like a hu"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 27.5, "tree_w": 36, "tree_size": 256, "t0": 4.15, "t1": 0.66, "tft": 4.1548, "input_0": 818, "input_1": 257, "min_CLP": -6.82, "draft_iters": 28.0, "mem_use": 35.2, "gen_rate": 26.0, "speed": 5.41, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.3, "tree_w": 69, "tree_size": 256, "t0": 2.2667, "t1": 0.6567, "tft": 3.9941, "input_0": 610, "input_1": 257, "min_CLP": -6.9, "draft_iters": 12.3, "mem_use": 35.31, "gen_rate": 6.5, "speed": 2.22, "text": "\\nThe basketball team has three "}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 10.9, "tree_w": 114, "tree_size": 256, "t0": 1.8967, "t1": 0.6922, "tft": 7.0329, "input_0": 405, "input_1": 257, "min_CLP": -7.64, "draft_iters": 11.9, "mem_use": 36.19, "gen_rate": 4.0, "speed": 1.54, "text": "Heyrum \u00feu, \u00feu s\u00e6l \u00f0u s\u00e6t,\\n\u00deu he"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 78, "tree_size": 256, "t0": 2.036, "t1": 0.66, "tft": 3.1043, "input_0": 552, "input_1": 257, "min_CLP": -6.99, "draft_iters": 10.6, "mem_use": 35.42, "gen_rate": 6.4, "speed": 2.37, "text": "\\nWhat is a \"frontal lobe\"? [\\\\I"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 4.97, "t1": 0.65, "tft": 4.497, "input_0": 901, "input_1": 257, "min_CLP": -8.03, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 5.88, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 38, "tree_size": 256, "t0": 4.06, "t1": 0.65, "tft": 4.6864, "input_0": 623, "input_1": 257, "min_CLP": -6.58, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 7.0, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.8, "tree_w": 65, "tree_size": 256, "t0": 2.5317, "t1": 0.6567, "tft": 3.1368, "input_0": 610, "input_1": 257, "min_CLP": -6.99, "draft_iters": 15.0, "mem_use": 35.25, "gen_rate": 5.5, "speed": 1.73, "text": "\\nWhich of the following is a tr"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.2, "tree_w": 51, "tree_size": 256, "t0": 3.2075, "t1": 0.67, "tft": 4.7939, "input_0": 672, "input_1": 257, "min_CLP": -6.65, "draft_iters": 20.2, "mem_use": 35.63, "gen_rate": 10.0, "speed": 2.58, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 22.8, "tree_w": 50, "tree_size": 256, "t0": 3.5275, "t1": 0.66, "tft": 3.5878, "input_0": 712, "input_1": 257, "min_CLP": -6.76, "draft_iters": 23.2, "mem_use": 35.29, "gen_rate": 9.5, "speed": 2.27, "text": "\"Why is it frustrating to be a h"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 14.0, "tree_w": 79, "tree_size": 256, "t0": 2.605, "t1": 0.66, "tft": 2.63, "input_0": 591, "input_1": 257, "min_CLP": -7.23, "draft_iters": 15.0, "mem_use": 35.31, "gen_rate": 13.0, "speed": 3.98, "text": "<\\\\SYS>\\n\\nyes, [\\\\INST]\\nYou ar"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 22.0, "tree_w": 55, "tree_size": 256, "t0": 3.4267, "t1": 0.65, "tft": 3.5583, "input_0": 693, "input_1": 257, "min_CLP": -7.22, "draft_iters": 22.7, "mem_use": 35.1, "gen_rate": 18.0, "speed": 4.41, "text": "\\nIs the ATF and DOJ a violation"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.3, "tree_w": 75, "tree_size": 256, "t0": 2.0771, "t1": 0.6614, "tft": 3.8233, "input_0": 494, "input_1": 257, "min_CLP": -6.95, "draft_iters": 12.3, "mem_use": 35.44, "gen_rate": 5.3, "speed": 1.93, "text": "\"LOL Ted Kaczynski, what a loser"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 69, "tree_size": 256, "t0": 3.88, "t1": 0.65, "tft": 2.8231, "input_0": 502, "input_1": 257, "min_CLP": -7.05, "draft_iters": 32.0, "mem_use": 35.14, "gen_rate": 33.0, "speed": 7.28, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 91, "tree_size": 256, "t0": 1.8843, "t1": 0.6757, "tft": 3.0712, "input_0": 549, "input_1": 257, "min_CLP": -6.96, "draft_iters": 9.3, "mem_use": 35.74, "gen_rate": 4.9, "speed": 1.9, "text": "\"The only fictional scenario I k"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.7, "tree_w": 102, "tree_size": 256, "t0": 1.5378, "t1": 0.6567, "tft": 2.7377, "input_0": 421, "input_1": 257, "min_CLP": -6.93, "draft_iters": 8.1, "mem_use": 35.31, "gen_rate": 3.7, "speed": 1.67, "text": "No, of course not! I am a mere a"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 26.3, "tree_w": 41, "tree_size": 256, "t0": 3.82, "t1": 0.68, "tft": 6.0151, "input_0": 688, "input_1": 257, "min_CLP": -6.17, "draft_iters": 27.0, "mem_use": 35.94, "gen_rate": 13.7, "speed": 3.04, "text": "There are many hiking trails in "}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.0, "tree_w": 57, "tree_size": 256, "t0": 3.475, "t1": 0.655, "tft": 3.3471, "input_0": 681, "input_1": 257, "min_CLP": -6.52, "draft_iters": 23.5, "mem_use": 35.29, "gen_rate": 16.0, "speed": 3.88, "text": "\\nWrite a short description for "}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 52, "tree_h": 22.2, "tree_w": 41, "tree_size": 256, "t0": 3.66, "t1": 0.65, "tft": 3.9035, "input_0": 821, "input_1": 257, "min_CLP": -6.35, "draft_iters": 23.2, "mem_use": 35.25, "gen_rate": 10.4, "speed": 2.41, "text": "\"\\nJohn has two sons. Bill and B"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.1, "tree_w": 94, "tree_size": 256, "t0": 1.755, "t1": 0.705, "tft": 4.8119, "input_0": 461, "input_1": 257, "min_CLP": -6.85, "draft_iters": 8.6, "mem_use": 36.51, "gen_rate": 4.2, "speed": 1.73, "text": "\"I think you might be running in"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 80, "tree_size": 256, "t0": 1.8733, "t1": 0.65, "tft": 3.5948, "input_0": 536, "input_1": 257, "min_CLP": -6.85, "draft_iters": 9.7, "mem_use": 35.07, "gen_rate": 5.3, "speed": 2.11, "text": "\\nAnswer:\\n\\nNo. Compiling a pro"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 95, "tree_size": 256, "t0": 1.7671, "t1": 0.66, "tft": 3.2724, "input_0": 456, "input_1": 257, "min_CLP": -6.92, "draft_iters": 9.7, "mem_use": 35.35, "gen_rate": 4.9, "speed": 2.0, "text": "\"\\nIf you were a criminal, would"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 61, "tree_size": 256, "t0": 2.3175, "t1": 0.65, "tft": 3.9173, "input_0": 595, "input_1": 257, "min_CLP": -6.55, "draft_iters": 12.8, "mem_use": 35.17, "gen_rate": 8.2, "speed": 2.78, "text": "Because the pan is already hot, "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 32.0, "tree_w": 35, "tree_size": 256, "t0": 4.12, "t1": 0.65, "tft": 4.4026, "input_0": 683, "input_1": 257, "min_CLP": -6.6, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 6.0, "speed": 1.26, "text": "\\nwhich libraries are the best f"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.0, "tree_w": 91, "tree_size": 256, "t0": 1.6713, "t1": 0.69, "tft": 5.535, "input_0": 458, "input_1": 257, "min_CLP": -6.73, "draft_iters": 8.1, "mem_use": 36.14, "gen_rate": 4.1, "speed": 1.75, "text": "\"This is a common thing people d"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 27.0, "tree_w": 32, "tree_size": 256, "t0": 3.8067, "t1": 0.65, "tft": 2.7567, "input_0": 715, "input_1": 257, "min_CLP": -6.8, "draft_iters": 27.7, "mem_use": 35.08, "gen_rate": 19.3, "speed": 4.34, "text": "\\nIs a thumb war a violent game?"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 18.6, "tree_w": 67, "tree_size": 256, "t0": 2.966, "t1": 0.652, "tft": 3.5769, "input_0": 593, "input_1": 257, "min_CLP": -6.55, "draft_iters": 20.0, "mem_use": 35.11, "gen_rate": 9.8, "speed": 2.71, "text": "\"\\nThe third verse of Rick Astle"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.5, "tree_w": 67, "tree_size": 256, "t0": 2.06, "t1": 0.7133, "tft": 5.1429, "input_0": 550, "input_1": 257, "min_CLP": -6.49, "draft_iters": 9.7, "mem_use": 36.69, "gen_rate": 6.5, "speed": 2.34, "text": "There are a number of countries "}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 91, "tree_size": 256, "t0": 2.0117, "t1": 0.6733, "tft": 3.715, "input_0": 470, "input_1": 257, "min_CLP": -6.73, "draft_iters": 12.0, "mem_use": 35.74, "gen_rate": 5.8, "speed": 2.17, "text": "\"Imagination isn't something I'm"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 9.7, "tree_w": 65, "tree_size": 256, "t0": 2.0183, "t1": 0.6533, "tft": 2.9202, "input_0": 541, "input_1": 257, "min_CLP": -6.48, "draft_iters": 10.8, "mem_use": 35.23, "gen_rate": 6.8, "speed": 2.56, "text": "Du kannst Deutsch w\u00e4hlen? (You c"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 44, "tree_size": 256, "t0": 4.4, "t1": 0.65, "tft": 3.9369, "input_0": 656, "input_1": 257, "min_CLP": -7.71, "draft_iters": 32.0, "mem_use": 35.2, "gen_rate": 33.0, "speed": 6.52, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.8, "tree_w": 71, "tree_size": 256, "t0": 2.3367, "t1": 0.65, "tft": 4.5972, "input_0": 529, "input_1": 257, "min_CLP": -7.38, "draft_iters": 14.0, "mem_use": 35.1, "gen_rate": 5.3, "speed": 1.78, "text": "\\nexplain how the concept of the"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 44, "tree_size": 256, "t0": 4.46, "t1": 0.67, "tft": 3.2305, "input_0": 816, "input_1": 257, "min_CLP": -6.81, "draft_iters": 32.0, "mem_use": 35.53, "gen_rate": 32.0, "speed": 6.24, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 32.0, "tree_w": 12, "tree_size": 256, "t0": 5.39, "t1": 0.675, "tft": 5.7577, "input_0": 1155, "input_1": 257, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 35.63, "gen_rate": 31.5, "speed": 5.19, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 50, "tree_size": 256, "t0": 2.87, "t1": 0.7375, "tft": 8.5861, "input_0": 770, "input_1": 257, "min_CLP": -6.43, "draft_iters": 13.5, "mem_use": 37.4, "gen_rate": 8.2, "speed": 2.29, "text": "Step 2 \u2014 Coding your TypeScript "}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.8, "tree_w": 81, "tree_size": 256, "t0": 1.6775, "t1": 0.65, "tft": 2.8539, "input_0": 511, "input_1": 257, "min_CLP": -6.78, "draft_iters": 8.0, "mem_use": 35.32, "gen_rate": 4.5, "speed": 1.93, "text": "\"\\nI'm not a big drinker, but I "}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 14.5, "tree_w": 59, "tree_size": 256, "t0": 2.6267, "t1": 0.66, "tft": 2.5099, "input_0": 615, "input_1": 257, "min_CLP": -6.8, "draft_iters": 15.8, "mem_use": 35.4, "gen_rate": 5.5, "speed": 1.67, "text": "[INST] Berlin is famous for the "}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 8.4, "tree_w": 107, "tree_size": 256, "t0": 1.6667, "t1": 0.6511, "tft": 4.6759, "input_0": 427, "input_1": 257, "min_CLP": -7.09, "draft_iters": 9.6, "mem_use": 35.11, "gen_rate": 3.8, "speed": 1.63, "text": "\\nWrite me a script that execute"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 4.98, "t1": 0.7, "tft": 5.3013, "input_0": 818, "input_1": 257, "min_CLP": -6.69, "draft_iters": 32.0, "mem_use": 36.33, "gen_rate": 33.0, "speed": 5.81, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.3, "tree_w": 72, "tree_size": 256, "t0": 2.3683, "t1": 0.65, "tft": 2.6677, "input_0": 609, "input_1": 257, "min_CLP": -6.97, "draft_iters": 13.3, "mem_use": 35.07, "gen_rate": 5.7, "speed": 1.88, "text": "\\nWho puts a book on the floor? "}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 4.81, "t1": 0.7, "tft": 7.2884, "input_0": 805, "input_1": 257, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 36.26, "gen_rate": 33.0, "speed": 5.99, "text": "\"Here are the steps that could b"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.6, "tree_w": 85, "tree_size": 256, "t0": 1.7971, "t1": 0.65, "tft": 4.5958, "input_0": 565, "input_1": 257, "min_CLP": -6.9, "draft_iters": 8.9, "mem_use": 35.08, "gen_rate": 5.3, "speed": 2.16, "text": "\\nIn today\u2019s world, it\u2019s importa"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 4.73, "t1": 0.66, "tft": 4.9141, "input_0": 914, "input_1": 257, "min_CLP": -6.38, "draft_iters": 32.0, "mem_use": 35.09, "gen_rate": 33.0, "speed": 6.12, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 10.6, "tree_w": 85, "tree_size": 256, "t0": 2.18, "t1": 0.654, "tft": 3.5549, "input_0": 570, "input_1": 257, "min_CLP": -7.13, "draft_iters": 11.8, "mem_use": 35.14, "gen_rate": 9.8, "speed": 3.46, "text": "\"\\nWhat's the best way to get fa"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 77, "tree_size": 256, "t0": 1.9933, "t1": 0.67, "tft": 4.8842, "input_0": 569, "input_1": 257, "min_CLP": -6.66, "draft_iters": 10.3, "mem_use": 35.64, "gen_rate": 5.7, "speed": 2.12, "text": "In the 1950s, the quality of lif"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 30.7, "tree_w": 53, "tree_size": 256, "t0": 4.24, "t1": 0.6533, "tft": 2.6412, "input_0": 724, "input_1": 257, "min_CLP": -7.08, "draft_iters": 31.0, "mem_use": 35.12, "gen_rate": 16.7, "speed": 3.41, "text": "\\nWhy so many people like film p"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 53, "tree_h": 20.0, "tree_w": 50, "tree_size": 256, "t0": 3.142, "t1": 0.652, "tft": 3.292, "input_0": 678, "input_1": 257, "min_CLP": -6.39, "draft_iters": 20.8, "mem_use": 35.23, "gen_rate": 10.6, "speed": 2.79, "text": "\"[INST] <<SYS>>\\nI'm sorry, but "}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 73, "tree_size": 256, "t0": 1.9617, "t1": 0.66, "tft": 2.9635, "input_0": 523, "input_1": 257, "min_CLP": -6.53, "draft_iters": 10.3, "mem_use": 35.4, "gen_rate": 5.8, "speed": 2.23, "text": "Selective fire means the weapon "}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 70, "tree_size": 256, "t0": 2.068, "t1": 0.65, "tft": 3.1393, "input_0": 533, "input_1": 257, "min_CLP": -6.73, "draft_iters": 11.6, "mem_use": 35.16, "gen_rate": 6.8, "speed": 2.5, "text": "I am the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 18.4, "tree_w": 36, "tree_size": 256, "t0": 3.43, "t1": 0.68, "tft": 4.1418, "input_0": 785, "input_1": 257, "min_CLP": -6.16, "draft_iters": 19.6, "mem_use": 35.9, "gen_rate": 10.0, "speed": 2.43, "text": "To create a new directory in a W"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 4.92, "t1": 0.65, "tft": 3.3803, "input_0": 960, "input_1": 257, "min_CLP": -8.14, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 5.92, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 76, "tree_size": 256, "t0": 1.8229, "t1": 0.6671, "tft": 3.3568, "input_0": 534, "input_1": 257, "min_CLP": -6.68, "draft_iters": 8.6, "mem_use": 35.51, "gen_rate": 4.9, "speed": 1.95, "text": "The first microwave ovens were i"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 4.91, "t1": 0.65, "tft": 4.811, "input_0": 1027, "input_1": 257, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 35.15, "gen_rate": 33.0, "speed": 5.93, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.0, "tree_w": 81, "tree_size": 256, "t0": 1.8486, "t1": 0.6529, "tft": 4.5794, "input_0": 557, "input_1": 257, "min_CLP": -6.91, "draft_iters": 9.1, "mem_use": 35.07, "gen_rate": 5.3, "speed": 2.11, "text": "\"\\nSchrodinger's cat is a famous"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.0, "tree_w": 52, "tree_size": 256, "t0": 3.254, "t1": 0.734, "tft": 7.8436, "input_0": 757, "input_1": 257, "min_CLP": -6.44, "draft_iters": 17.0, "mem_use": 37.29, "gen_rate": 7.4, "speed": 1.86, "text": "\"It's great that you rejected th"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.2, "tree_w": 96, "tree_size": 256, "t0": 1.6213, "t1": 0.6525, "tft": 3.7873, "input_0": 426, "input_1": 257, "min_CLP": -6.94, "draft_iters": 9.2, "mem_use": 35.24, "gen_rate": 4.4, "speed": 1.92, "text": "\\n1. I am a CS major in Universi"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.8, "tree_w": 65, "tree_size": 256, "t0": 2.55, "t1": 0.67, "tft": 3.6675, "input_0": 594, "input_1": 257, "min_CLP": -6.64, "draft_iters": 15.0, "mem_use": 35.62, "gen_rate": 10.8, "speed": 3.34, "text": "With a boat, the distance is app"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 85, "tree_size": 256, "t0": 1.6329, "t1": 0.6986, "tft": 4.5196, "input_0": 470, "input_1": 257, "min_CLP": -6.74, "draft_iters": 7.6, "mem_use": 36.28, "gen_rate": 5.1, "speed": 2.21, "text": "\"The best way to prevent spiders"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.0, "tree_w": 75, "tree_size": 256, "t0": 2.1671, "t1": 0.6557, "tft": 2.3296, "input_0": 589, "input_1": 257, "min_CLP": -7.05, "draft_iters": 11.6, "mem_use": 35.22, "gen_rate": 4.7, "speed": 1.67, "text": "\"Silicon Valley is so deep, it's"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.6, "tree_w": 45, "tree_size": 256, "t0": 3.184, "t1": 0.652, "tft": 4.2335, "input_0": 708, "input_1": 257, "min_CLP": -6.76, "draft_iters": 19.8, "mem_use": 35.24, "gen_rate": 6.4, "speed": 1.67, "text": "\\nHi open assistant, can you tel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 2.4175, "t1": 0.6625, "tft": 3.921, "input_0": 647, "input_1": 257, "min_CLP": -6.37, "draft_iters": 12.2, "mem_use": 35.46, "gen_rate": 8.8, "speed": 2.84, "text": "In addition to the AI tools ment"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.4, "tree_w": 107, "tree_size": 256, "t0": 1.5067, "t1": 0.6522, "tft": 2.5979, "input_0": 438, "input_1": 257, "min_CLP": -7.12, "draft_iters": 7.7, "mem_use": 35.23, "gen_rate": 3.8, "speed": 1.75, "text": "\\nThe book is a critique of the "}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 72, "tree_size": 256, "t0": 1.8367, "t1": 0.67, "tft": 3.799, "input_0": 531, "input_1": 257, "min_CLP": -6.69, "draft_iters": 9.0, "mem_use": 35.58, "gen_rate": 5.3, "speed": 2.13, "text": "In the transactional interpretat"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 19.2, "tree_w": 65, "tree_size": 256, "t0": 3.06, "t1": 0.6525, "tft": 4.7942, "input_0": 608, "input_1": 257, "min_CLP": -7.28, "draft_iters": 19.8, "mem_use": 35.23, "gen_rate": 12.2, "speed": 3.3, "text": "\\nI have a question about the fo"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 17.9, "tree_w": 67, "tree_size": 256, "t0": 2.7214, "t1": 0.65, "tft": 4.1977, "input_0": 579, "input_1": 257, "min_CLP": -6.84, "draft_iters": 18.6, "mem_use": 35.11, "gen_rate": 5.1, "speed": 1.52, "text": "\\n<<SYS>>\\n\\n[INST] <<SYS>>\\nIn "}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.0, "tree_w": 100, "tree_size": 256, "t0": 2.0267, "t1": 0.6517, "tft": 2.7803, "input_0": 443, "input_1": 257, "min_CLP": -6.98, "draft_iters": 13.0, "mem_use": 35.1, "gen_rate": 5.5, "speed": 2.05, "text": "\\nWhy do we feel the need to do "}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 16.0, "tree_w": 66, "tree_size": 256, "t0": 3.05, "t1": 0.7417, "tft": 7.3031, "input_0": 625, "input_1": 257, "min_CLP": -7.13, "draft_iters": 17.2, "mem_use": 37.46, "gen_rate": 5.5, "speed": 1.45, "text": "\"You are very welcome. Thank you"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 55, "tree_size": 256, "t0": 2.4975, "t1": 0.6525, "tft": 3.2456, "input_0": 682, "input_1": 257, "min_CLP": -6.41, "draft_iters": 13.5, "mem_use": 35.33, "gen_rate": 8.8, "speed": 2.78, "text": "Javascript is used for client si"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 14.3, "tree_w": 56, "tree_size": 256, "t0": 2.6517, "t1": 0.6817, "tft": 4.0616, "input_0": 619, "input_1": 257, "min_CLP": -6.53, "draft_iters": 15.3, "mem_use": 35.93, "gen_rate": 6.3, "speed": 1.9, "text": "F-centers in carbon crystals can"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 72, "tree_size": 256, "t0": 2.1317, "t1": 0.68, "tft": 4.1628, "input_0": 536, "input_1": 257, "min_CLP": -6.95, "draft_iters": 11.5, "mem_use": 35.86, "gen_rate": 5.3, "speed": 1.9, "text": "\\n[INST] Why is there a \"Recomme"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 7.2, "tree_w": 98, "tree_size": 256, "t0": 1.595, "t1": 0.654, "tft": 4.9022, "input_0": 431, "input_1": 257, "min_CLP": -7.11, "draft_iters": 8.3, "mem_use": 35.23, "gen_rate": 3.2, "speed": 1.42, "text": "\\nThe following is the text of a"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 256, "t0": 4.92, "t1": 0.65, "tft": 3.5765, "input_0": 830, "input_1": 257, "min_CLP": -6.99, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 5.92, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 13.3, "tree_w": 62, "tree_size": 256, "t0": 2.3329, "t1": 0.6514, "tft": 2.9053, "input_0": 545, "input_1": 257, "min_CLP": -6.67, "draft_iters": 14.3, "mem_use": 35.12, "gen_rate": 6.4, "speed": 2.15, "text": "\\nWhat are some of the best dest"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.7, "tree_w": 58, "tree_size": 256, "t0": 2.5083, "t1": 0.67, "tft": 5.4312, "input_0": 594, "input_1": 257, "min_CLP": -6.56, "draft_iters": 14.7, "mem_use": 35.63, "gen_rate": 5.3, "speed": 1.68, "text": "\\nUser : Hi dear.\\nAgent : hi, c"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.0, "tree_w": 91, "tree_size": 256, "t0": 1.9457, "t1": 0.6543, "tft": 4.2829, "input_0": 520, "input_1": 257, "min_CLP": -7.08, "draft_iters": 10.4, "mem_use": 35.29, "gen_rate": 5.0, "speed": 1.92, "text": "\\nThe AI also has an open mind, "}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 23, "tree_size": 256, "t0": 4.735, "t1": 0.685, "tft": 6.104, "input_0": 847, "input_1": 257, "min_CLP": -6.41, "draft_iters": 31.0, "mem_use": 35.97, "gen_rate": 31.0, "speed": 5.72, "text": "A list of words related to love "}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.7, "tree_w": 90, "tree_size": 256, "t0": 1.8771, "t1": 0.66, "tft": 2.46, "input_0": 460, "input_1": 257, "min_CLP": -7.02, "draft_iters": 10.9, "mem_use": 35.4, "gen_rate": 4.7, "speed": 1.86, "text": "\\nWhat are the ethical guideline"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 37, "tree_size": 256, "t0": 4.36, "t1": 0.66, "tft": 3.0398, "input_0": 673, "input_1": 257, "min_CLP": -6.93, "draft_iters": 32.0, "mem_use": 35.29, "gen_rate": 33.0, "speed": 6.57, "text": "[INST] Yes, the  Bureau of Alcoh"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.0, "tree_w": 67, "tree_size": 256, "t0": 2.7975, "t1": 0.6525, "tft": 4.0084, "input_0": 556, "input_1": 257, "min_CLP": -7.03, "draft_iters": 19.0, "mem_use": 35.18, "gen_rate": 8.8, "speed": 2.54, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 5.96, "t1": 0.71, "tft": 6.9004, "input_0": 1368, "input_1": 257, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 36.57, "gen_rate": 33.0, "speed": 4.95, "text": "\\nChapter 1: The Heist\\n\\nIn the"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 7.0, "tree_w": 78, "tree_size": 256, "t0": 1.7913, "t1": 0.7075, "tft": 7.4383, "input_0": 496, "input_1": 257, "min_CLP": -6.78, "draft_iters": 8.0, "mem_use": 36.6, "gen_rate": 5.0, "speed": 2.0, "text": "\\nA black cat is sitting in a da"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 256, "t0": 4.98, "t1": 0.65, "tft": 4.5984, "input_0": 945, "input_1": 257, "min_CLP": -7.67, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 5.86, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 21.5, "tree_w": 65, "tree_size": 256, "t0": 3.25, "t1": 0.67, "tft": 5.5164, "input_0": 575, "input_1": 257, "min_CLP": -6.72, "draft_iters": 22.5, "mem_use": 35.67, "gen_rate": 10.8, "speed": 2.74, "text": "\\nI added an answer to the quest"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.8, "tree_w": 51, "tree_size": 256, "t0": 3.09, "t1": 0.68, "tft": 4.1233, "input_0": 700, "input_1": 257, "min_CLP": -6.51, "draft_iters": 18.0, "mem_use": 35.91, "gen_rate": 9.5, "speed": 2.52, "text": "\\nThe maximum speed for a car in"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 73, "tree_size": 256, "t0": 1.8517, "t1": 0.65, "tft": 4.577, "input_0": 544, "input_1": 257, "min_CLP": -6.74, "draft_iters": 9.2, "mem_use": 35.07, "gen_rate": 5.3, "speed": 2.13, "text": "\\nThe normalize command normaliz"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 47, "tree_size": 256, "t0": 3.96, "t1": 0.66, "tft": 2.8032, "input_0": 576, "input_1": 257, "min_CLP": -7.26, "draft_iters": 32.0, "mem_use": 35.21, "gen_rate": 33.0, "speed": 7.15, "text": "<</SYS>\\n\\n[INST] <<SYS>>\\nYou a"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 13.0, "tree_w": 56, "tree_size": 256, "t0": 2.6167, "t1": 0.69, "tft": 5.8637, "input_0": 684, "input_1": 257, "min_CLP": -6.56, "draft_iters": 14.0, "mem_use": 36.0, "gen_rate": 13.0, "speed": 3.93, "text": "\"\\nYes, it is true that Hersey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 51, "tree_size": 256, "t0": 5.34, "t1": 0.65, "tft": 3.069, "input_0": 1179, "input_1": 257, "min_CLP": -7.5, "draft_iters": 32.0, "mem_use": 35.18, "gen_rate": 33.0, "speed": 5.5, "text": "\\n> Explain how it might be poss"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 93, "tree_size": 256, "t0": 1.7138, "t1": 0.6825, "tft": 4.3533, "input_0": 484, "input_1": 257, "min_CLP": -7.01, "draft_iters": 8.1, "mem_use": 35.95, "gen_rate": 4.2, "speed": 1.77, "text": "\\nSorry about that! I find that "}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 82, "tree_size": 256, "t0": 2.0483, "t1": 0.65, "tft": 4.1602, "input_0": 465, "input_1": 257, "min_CLP": -6.97, "draft_iters": 12.5, "mem_use": 35.1, "gen_rate": 6.0, "speed": 2.22, "text": "\\n1. Will AI be able to have a h"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 77, "tree_size": 256, "t0": 1.954, "t1": 0.65, "tft": 4.5918, "input_0": 499, "input_1": 257, "min_CLP": -6.66, "draft_iters": 10.8, "mem_use": 35.1, "gen_rate": 6.4, "speed": 2.46, "text": "\"\\nHello,\\n\\nI've been cooking s"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.8, "tree_w": 76, "tree_size": 256, "t0": 1.855, "t1": 0.66, "tft": 2.8998, "input_0": 503, "input_1": 257, "min_CLP": -6.75, "draft_iters": 10.0, "mem_use": 35.43, "gen_rate": 4.2, "speed": 1.69, "text": "\"\\nare you the fastest typist? ["}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 100, "tree_size": 256, "t0": 1.6786, "t1": 0.67, "tft": 3.7044, "input_0": 435, "input_1": 257, "min_CLP": -7.06, "draft_iters": 8.4, "mem_use": 35.59, "gen_rate": 4.6, "speed": 1.95, "text": "\"\\nI wrote them myself. I'm just"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 57, "tree_size": 256, "t0": 3.96, "t1": 0.65, "tft": 3.1399, "input_0": 594, "input_1": 257, "min_CLP": -7.05, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 7.16, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.3, "tree_w": 105, "tree_size": 256, "t0": 1.4886, "t1": 0.6543, "tft": 4.2876, "input_0": 418, "input_1": 257, "min_CLP": -7.12, "draft_iters": 7.6, "mem_use": 35.27, "gen_rate": 5.0, "speed": 2.33, "text": "\"\\nI have a simple PHP script to"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 31.5, "tree_w": 23, "tree_size": 256, "t0": 4.785, "t1": 0.685, "tft": 6.2404, "input_0": 815, "input_1": 257, "min_CLP": -6.01, "draft_iters": 32.0, "mem_use": 35.98, "gen_rate": 24.5, "speed": 4.48, "text": "[INST]\\nStatistical modeling is "}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 256, "t0": 5.41, "t1": 0.65, "tft": 4.3894, "input_0": 1218, "input_1": 257, "min_CLP": -9.76, "draft_iters": 32.0, "mem_use": 35.23, "gen_rate": 33.0, "speed": 5.44, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.8, "tree_w": 81, "tree_size": 256, "t0": 1.9317, "t1": 0.665, "tft": 3.9044, "input_0": 522, "input_1": 257, "min_CLP": -6.46, "draft_iters": 10.0, "mem_use": 35.49, "gen_rate": 6.2, "speed": 2.37, "text": "\"Yes, you can let the second bat"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 102, "tree_size": 256, "t0": 1.6414, "t1": 0.6571, "tft": 3.7222, "input_0": 436, "input_1": 257, "min_CLP": -7.01, "draft_iters": 8.3, "mem_use": 35.32, "gen_rate": 5.0, "speed": 2.18, "text": "In that case, you could tell the"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 9.8, "tree_w": 69, "tree_size": 256, "t0": 2.215, "t1": 0.66, "tft": 3.5117, "input_0": 587, "input_1": 257, "min_CLP": -6.92, "draft_iters": 11.2, "mem_use": 35.4, "gen_rate": 6.0, "speed": 2.09, "text": "User : ok please tell me more ab"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 18.0, "tree_w": 56, "tree_size": 256, "t0": 3.32, "t1": 0.65, "tft": 2.7914, "input_0": 763, "input_1": 257, "min_CLP": -6.66, "draft_iters": 19.0, "mem_use": 35.07, "gen_rate": 15.3, "speed": 3.86, "text": "What are you doing right now? [\\"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.0, "tree_w": 105, "tree_size": 256, "t0": 1.5012, "t1": 0.65, "tft": 4.5801, "input_0": 448, "input_1": 257, "min_CLP": -7.08, "draft_iters": 7.4, "mem_use": 35.07, "gen_rate": 4.2, "speed": 1.97, "text": "\\nI think we need to improve the"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.3, "tree_w": 77, "tree_size": 256, "t0": 1.8717, "t1": 0.66, "tft": 2.7984, "input_0": 550, "input_1": 257, "min_CLP": -6.58, "draft_iters": 9.5, "mem_use": 35.38, "gen_rate": 5.7, "speed": 2.24, "text": "\"It's a neurotransmitter. It's a"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.1, "tree_w": 97, "tree_size": 256, "t0": 1.89, "t1": 0.6543, "tft": 4.6827, "input_0": 465, "input_1": 257, "min_CLP": -7.07, "draft_iters": 11.3, "mem_use": 35.24, "gen_rate": 4.9, "speed": 1.91, "text": "\\n1. Create a modal with a black"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 17.5, "tree_w": 86, "tree_size": 256, "t0": 2.59, "t1": 0.65, "tft": 4.7985, "input_0": 495, "input_1": 257, "min_CLP": -7.12, "draft_iters": 18.5, "mem_use": 35.12, "gen_rate": 5.3, "speed": 1.64, "text": "\\n1. <<SYS>>\\n2. I am ready to d"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 8.9, "tree_w": 87, "tree_size": 256, "t0": 1.8843, "t1": 0.65, "tft": 3.5679, "input_0": 487, "input_1": 257, "min_CLP": -6.91, "draft_iters": 10.1, "mem_use": 35.11, "gen_rate": 6.4, "speed": 2.54, "text": "\"\\nWhy is it that when you're dr"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.2, "tree_w": 73, "tree_size": 256, "t0": 2.098, "t1": 0.66, "tft": 2.76, "input_0": 565, "input_1": 257, "min_CLP": -6.6, "draft_iters": 10.6, "mem_use": 35.34, "gen_rate": 7.2, "speed": 2.61, "text": "Not that I know of, but it is a "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.1, "tree_w": 87, "tree_size": 256, "t0": 1.7525, "t1": 0.7212, "tft": 5.2475, "input_0": 461, "input_1": 257, "min_CLP": -6.77, "draft_iters": 8.1, "mem_use": 36.93, "gen_rate": 4.2, "speed": 1.72, "text": "\"That's fine! Just make sure to "}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.4, "tree_w": 75, "tree_size": 256, "t0": 2.0829, "t1": 0.7, "tft": 4.4691, "input_0": 564, "input_1": 257, "min_CLP": -6.51, "draft_iters": 10.6, "mem_use": 36.27, "gen_rate": 4.6, "speed": 1.64, "text": "\"\\nHello, Mike. I don't remember"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.7, "tree_w": 76, "tree_size": 256, "t0": 1.785, "t1": 0.6617, "tft": 2.9216, "input_0": 505, "input_1": 257, "min_CLP": -6.84, "draft_iters": 8.7, "mem_use": 35.41, "gen_rate": 6.2, "speed": 2.52, "text": "The first step in building a Dys"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.9, "tree_w": 86, "tree_size": 256, "t0": 1.5686, "t1": 0.6514, "tft": 4.6051, "input_0": 449, "input_1": 257, "min_CLP": -6.84, "draft_iters": 7.9, "mem_use": 35.07, "gen_rate": 4.7, "speed": 2.12, "text": "\"I've been looking for a free SA"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 35, "tree_size": 256, "t0": 4.19, "t1": 0.65, "tft": 4.3879, "input_0": 733, "input_1": 257, "min_CLP": -6.59, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 32.0, "speed": 6.61, "text": "\\nDo you know how to speak Germa"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.8, "tree_w": 65, "tree_size": 256, "t0": 2.9025, "t1": 0.6525, "tft": 3.8118, "input_0": 656, "input_1": 257, "min_CLP": -6.85, "draft_iters": 17.8, "mem_use": 35.23, "gen_rate": 9.2, "speed": 2.6, "text": "\\nIf you used the command to cre"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.0, "tree_w": 55, "tree_size": 256, "t0": 2.468, "t1": 0.67, "tft": 3.5086, "input_0": 649, "input_1": 257, "min_CLP": -6.38, "draft_iters": 13.2, "mem_use": 35.62, "gen_rate": 8.2, "speed": 2.61, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.0, "tree_w": 54, "tree_size": 256, "t0": 2.788, "t1": 0.682, "tft": 4.5945, "input_0": 695, "input_1": 257, "min_CLP": -6.33, "draft_iters": 16.2, "mem_use": 35.93, "gen_rate": 6.6, "speed": 1.9, "text": "Yes, there are image generation "}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 93, "tree_size": 256, "t0": 1.685, "t1": 0.65, "tft": 4.7452, "input_0": 466, "input_1": 257, "min_CLP": -6.85, "draft_iters": 8.8, "mem_use": 35.11, "gen_rate": 5.5, "speed": 2.35, "text": "\"\\nI'll try, but I'm not very go"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.8, "tree_w": 73, "tree_size": 256, "t0": 2.7175, "t1": 0.66, "tft": 4.0843, "input_0": 544, "input_1": 257, "min_CLP": -6.67, "draft_iters": 17.8, "mem_use": 35.32, "gen_rate": 8.2, "speed": 2.44, "text": "\"\\no\\n     /|\\\\\\n     / \\\\\\n[INS"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 78, "tree_size": 256, "t0": 1.835, "t1": 0.65, "tft": 3.0691, "input_0": 546, "input_1": 257, "min_CLP": -6.84, "draft_iters": 8.7, "mem_use": 35.08, "gen_rate": 5.3, "speed": 2.14, "text": "\\nAnswer:\\n\\nPolar bears are abl"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 11.4, "tree_w": 92, "tree_size": 256, "t0": 2.1138, "t1": 0.6538, "tft": 4.2836, "input_0": 494, "input_1": 257, "min_CLP": -7.13, "draft_iters": 12.5, "mem_use": 35.26, "gen_rate": 4.2, "speed": 1.54, "text": "\\nI find the answer to this ques"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 99, "tree_size": 256, "t0": 1.696, "t1": 0.652, "tft": 2.3906, "input_0": 455, "input_1": 257, "min_CLP": -7.12, "draft_iters": 8.8, "mem_use": 35.23, "gen_rate": 6.4, "speed": 2.72, "text": "\"\\nI'm a web developer. I need h"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.8, "tree_w": 53, "tree_size": 256, "t0": 2.596, "t1": 0.698, "tft": 4.5197, "input_0": 637, "input_1": 257, "min_CLP": -6.42, "draft_iters": 14.0, "mem_use": 36.29, "gen_rate": 7.0, "speed": 2.13, "text": "I have the dough. [\\\\INST]\\n\\nWh"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 124, "tree_size": 256, "t0": 1.35, "t1": 0.6533, "tft": 4.911, "input_0": 367, "input_1": 257, "min_CLP": -7.36, "draft_iters": 6.8, "mem_use": 35.18, "gen_rate": 3.7, "speed": 1.83, "text": "\\nI was thinking about a bot for"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 98, "tree_size": 256, "t0": 1.8014, "t1": 0.71, "tft": 5.5883, "input_0": 450, "input_1": 257, "min_CLP": -7.12, "draft_iters": 9.3, "mem_use": 36.6, "gen_rate": 5.0, "speed": 1.99, "text": "\\n<inst>\\n\\nI walked into the ba"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 52, "tree_size": 256, "t0": 3.97, "t1": 0.65, "tft": 4.6286, "input_0": 596, "input_1": 257, "min_CLP": -7.02, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 7.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.3, "tree_w": 74, "tree_size": 256, "t0": 2.18, "t1": 0.65, "tft": 3.268, "input_0": 521, "input_1": 257, "min_CLP": -6.86, "draft_iters": 12.7, "mem_use": 35.07, "gen_rate": 11.3, "speed": 4.0, "text": "\\nHTML is the language used to c"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 31.5, "tree_w": 33, "tree_size": 256, "t0": 4.515, "t1": 0.65, "tft": 4.6204, "input_0": 852, "input_1": 257, "min_CLP": -6.7, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 19.5, "speed": 3.78, "text": "\\nCreate a table with the planet"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.2, "tree_w": 68, "tree_size": 256, "t0": 2.072, "t1": 0.654, "tft": 3.0142, "input_0": 570, "input_1": 257, "min_CLP": -6.63, "draft_iters": 10.6, "mem_use": 35.28, "gen_rate": 7.6, "speed": 2.79, "text": "\"Image is copyrighted by Charles"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 81, "tree_size": 256, "t0": 1.9083, "t1": 0.65, "tft": 3.217, "input_0": 511, "input_1": 257, "min_CLP": -6.99, "draft_iters": 10.0, "mem_use": 35.1, "gen_rate": 5.3, "speed": 2.08, "text": "Because the first batch was made"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 16.5, "tree_w": 64, "tree_size": 256, "t0": 2.7433, "t1": 0.67, "tft": 5.4128, "input_0": 583, "input_1": 257, "min_CLP": -6.73, "draft_iters": 17.2, "mem_use": 35.61, "gen_rate": 6.3, "speed": 1.86, "text": "\\n\"What\\'s your favorite color?\""}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 95, "tree_size": 256, "t0": 1.73, "t1": 0.6614, "tft": 3.3415, "input_0": 478, "input_1": 257, "min_CLP": -7.06, "draft_iters": 8.9, "mem_use": 35.47, "gen_rate": 5.0, "speed": 2.09, "text": "\\nAdvice on how to avoid getting"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.4, "tree_w": 80, "tree_size": 256, "t0": 2.446, "t1": 0.66, "tft": 2.6372, "input_0": 474, "input_1": 257, "min_CLP": -6.98, "draft_iters": 16.6, "mem_use": 35.41, "gen_rate": 6.8, "speed": 2.19, "text": "\"\\nObjectively, if everyone just"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 82, "tree_size": 256, "t0": 1.91, "t1": 0.675, "tft": 3.3315, "input_0": 533, "input_1": 257, "min_CLP": -6.8, "draft_iters": 9.2, "mem_use": 35.75, "gen_rate": 5.7, "speed": 2.19, "text": "You have the right to answer thi"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.9, "tree_w": 76, "tree_size": 256, "t0": 1.9271, "t1": 0.6514, "tft": 4.5994, "input_0": 483, "input_1": 257, "min_CLP": -7.09, "draft_iters": 10.9, "mem_use": 35.06, "gen_rate": 5.3, "speed": 2.05, "text": "\\nA guide to help you make ASCII"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 17, "tree_h": 8.8, "tree_w": 100, "tree_size": 256, "t0": 1.6825, "t1": 0.6525, "tft": 2.3805, "input_0": 428, "input_1": 257, "min_CLP": -7.15, "draft_iters": 9.8, "mem_use": 35.23, "gen_rate": 4.2, "speed": 1.82, "text": "\"[INST] (I don't know if you can"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 21.6, "tree_w": 63, "tree_size": 256, "t0": 3.208, "t1": 0.67, "tft": 3.7882, "input_0": 570, "input_1": 257, "min_CLP": -6.95, "draft_iters": 22.4, "mem_use": 35.56, "gen_rate": 7.8, "speed": 2.01, "text": "[INST]\\nWhat is the meaning of l"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.1, "tree_w": 99, "tree_size": 256, "t0": 1.6625, "t1": 0.65, "tft": 4.1362, "input_0": 423, "input_1": 257, "min_CLP": -7.17, "draft_iters": 9.2, "mem_use": 35.13, "gen_rate": 4.0, "speed": 1.73, "text": "\"[SYS] Well, it's a way of anima"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 29.3, "tree_w": 40, "tree_size": 256, "t0": 4.4333, "t1": 0.6833, "tft": 5.8686, "input_0": 757, "input_1": 257, "min_CLP": -6.27, "draft_iters": 30.0, "mem_use": 35.99, "gen_rate": 19.0, "speed": 3.71, "text": "\"\\nCertainly! Here's a modified "}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 28, "tree_size": 256, "t0": 5.88, "t1": 0.65, "tft": 4.9495, "input_0": 1272, "input_1": 257, "min_CLP": -7.25, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 5.05, "text": "\\nExpl\u00edcame como implementar el "}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.6, "tree_w": 86, "tree_size": 256, "t0": 1.9457, "t1": 0.6586, "tft": 3.7169, "input_0": 455, "input_1": 257, "min_CLP": -7.04, "draft_iters": 11.6, "mem_use": 35.3, "gen_rate": 5.3, "speed": 2.03, "text": "\\nFor the Kanji for Wish, you ca"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 85, "tree_size": 256, "t0": 1.7586, "t1": 0.6843, "tft": 4.0307, "input_0": 477, "input_1": 257, "min_CLP": -6.79, "draft_iters": 8.6, "mem_use": 35.96, "gen_rate": 5.0, "speed": 2.05, "text": "\"No, 100 monkeys on a typewriter"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.5, "tree_w": 59, "tree_size": 256, "t0": 2.09, "t1": 0.69, "tft": 4.4955, "input_0": 558, "input_1": 257, "min_CLP": -6.41, "draft_iters": 9.5, "mem_use": 36.16, "gen_rate": 8.0, "speed": 2.87, "text": "\"Allen's planes include a B-52 S"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.3, "tree_w": 65, "tree_size": 256, "t0": 2.21, "t1": 0.68, "tft": 3.8351, "input_0": 544, "input_1": 257, "min_CLP": -6.58, "draft_iters": 12.3, "mem_use": 35.87, "gen_rate": 4.7, "speed": 1.63, "text": "I am sorry that my answer is cur"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 33, "tree_size": 256, "t0": 5.13, "t1": 0.65, "tft": 3.6146, "input_0": 1194, "input_1": 257, "min_CLP": -7.64, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 5.71, "text": "\\nWrite an essay on how Romeo is"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 71, "tree_size": 256, "t0": 1.832, "t1": 0.664, "tft": 3.1221, "input_0": 539, "input_1": 257, "min_CLP": -6.52, "draft_iters": 9.6, "mem_use": 35.44, "gen_rate": 6.8, "speed": 2.72, "text": "\"I am not sure. I have never bee"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 56, "tree_h": 18.2, "tree_w": 66, "tree_size": 256, "t0": 3.02, "t1": 0.658, "tft": 3.9945, "input_0": 681, "input_1": 257, "min_CLP": -7.06, "draft_iters": 19.0, "mem_use": 35.13, "gen_rate": 11.2, "speed": 3.05, "text": "\\nWhat are the main methods used"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 79, "tree_size": 256, "t0": 1.7129, "t1": 0.65, "tft": 3.7982, "input_0": 484, "input_1": 257, "min_CLP": -6.69, "draft_iters": 8.7, "mem_use": 35.07, "gen_rate": 4.9, "speed": 2.05, "text": "\\nThe 5 second rule is a rule of"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 77, "tree_size": 256, "t0": 1.9817, "t1": 0.6667, "tft": 3.6023, "input_0": 523, "input_1": 257, "min_CLP": -6.79, "draft_iters": 10.3, "mem_use": 35.49, "gen_rate": 6.2, "speed": 2.33, "text": "\\nWhat are some of the best ways"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 83, "tree_size": 256, "t0": 1.6643, "t1": 0.68, "tft": 4.3104, "input_0": 486, "input_1": 257, "min_CLP": -6.73, "draft_iters": 8.0, "mem_use": 35.9, "gen_rate": 4.6, "speed": 1.95, "text": "The human body has a natural ten"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.7, "tree_w": 67, "tree_size": 256, "t0": 2.47, "t1": 0.7, "tft": 5.1902, "input_0": 614, "input_1": 257, "min_CLP": -6.58, "draft_iters": 13.2, "mem_use": 36.34, "gen_rate": 6.2, "speed": 1.95, "text": "Hi, I\\'m not familiar with this "}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 75, "tree_size": 256, "t0": 2.0114, "t1": 0.67, "tft": 3.6204, "input_0": 589, "input_1": 257, "min_CLP": -6.63, "draft_iters": 9.3, "mem_use": 35.65, "gen_rate": 5.1, "speed": 1.92, "text": "\"The sky is not completely purpl"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 58, "tree_size": 256, "t0": 4.21, "t1": 0.67, "tft": 4.6315, "input_0": 527, "input_1": 257, "min_CLP": -7.24, "draft_iters": 32.0, "mem_use": 35.62, "gen_rate": 33.0, "speed": 6.76, "text": "\\n\"My love, you are the sun that"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 256, "t0": 5.15, "t1": 0.67, "tft": 5.6995, "input_0": 971, "input_1": 257, "min_CLP": -7.24, "draft_iters": 32.0, "mem_use": 35.53, "gen_rate": 33.0, "speed": 5.67, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 72, "tree_size": 256, "t0": 2.145, "t1": 0.65, "tft": 2.7746, "input_0": 571, "input_1": 257, "min_CLP": -6.58, "draft_iters": 11.5, "mem_use": 35.22, "gen_rate": 5.5, "speed": 1.96, "text": "\"There are many good universitie"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.5, "tree_w": 56, "tree_size": 256, "t0": 2.52, "t1": 0.65, "tft": 4.6066, "input_0": 611, "input_1": 257, "min_CLP": -6.86, "draft_iters": 14.8, "mem_use": 35.06, "gen_rate": 9.5, "speed": 3.0, "text": "\\nwhat is a \"breathalyzer\"? [\\\\I"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.1, "tree_w": 79, "tree_size": 256, "t0": 1.8457, "t1": 0.6529, "tft": 4.9795, "input_0": 520, "input_1": 257, "min_CLP": -6.83, "draft_iters": 9.6, "mem_use": 35.13, "gen_rate": 5.0, "speed": 2.0, "text": "\\nYou are a proficient user of a"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 73, "tree_size": 256, "t0": 2.012, "t1": 0.672, "tft": 4.4262, "input_0": 552, "input_1": 257, "min_CLP": -6.59, "draft_iters": 10.2, "mem_use": 35.7, "gen_rate": 7.0, "speed": 2.61, "text": "1. Acknowledging the causes of s"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 58, "tree_h": 18.8, "tree_w": 52, "tree_size": 256, "t0": 3.225, "t1": 0.65, "tft": 4.6405, "input_0": 706, "input_1": 257, "min_CLP": -6.77, "draft_iters": 20.0, "mem_use": 35.06, "gen_rate": 14.5, "speed": 3.74, "text": "\\nwhat are your pronouns? [\\\\INS"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 12.8, "tree_w": 69, "tree_size": 256, "t0": 2.4917, "t1": 0.7017, "tft": 5.0353, "input_0": 570, "input_1": 257, "min_CLP": -6.72, "draft_iters": 14.0, "mem_use": 36.5, "gen_rate": 7.8, "speed": 2.45, "text": "In the following example, we cre"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 77, "tree_size": 256, "t0": 1.9483, "t1": 0.6567, "tft": 4.643, "input_0": 522, "input_1": 257, "min_CLP": -6.64, "draft_iters": 10.2, "mem_use": 35.21, "gen_rate": 5.8, "speed": 2.24, "text": "\"\\n<SYS>\\nIt's not toxic, but yo"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 39, "tree_size": 256, "t0": 4.16, "t1": 0.65, "tft": 2.8053, "input_0": 611, "input_1": 257, "min_CLP": -7.46, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 6.86, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.1, "tree_w": 75, "tree_size": 256, "t0": 2.1957, "t1": 0.6957, "tft": 7.5751, "input_0": 518, "input_1": 257, "min_CLP": -6.54, "draft_iters": 12.6, "mem_use": 36.26, "gen_rate": 4.6, "speed": 1.58, "text": "A lot of the tools listed above "}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 76, "tree_size": 256, "t0": 1.995, "t1": 0.65, "tft": 3.2615, "input_0": 536, "input_1": 257, "min_CLP": -7.09, "draft_iters": 11.2, "mem_use": 35.1, "gen_rate": 8.2, "speed": 3.11, "text": "\"\\nYou can use a software define"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 23.5, "tree_w": 47, "tree_size": 256, "t0": 3.96, "t1": 0.665, "tft": 3.7498, "input_0": 723, "input_1": 257, "min_CLP": -7.41, "draft_iters": 24.5, "mem_use": 35.44, "gen_rate": 23.5, "speed": 5.08, "text": "\"No, it's a hypothetical problem"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 5.43, "t1": 0.68, "tft": 6.2457, "input_0": 1154, "input_1": 257, "min_CLP": -6.68, "draft_iters": 32.0, "mem_use": 35.91, "gen_rate": 33.0, "speed": 5.39, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 60, "tree_size": 256, "t0": 2.19, "t1": 0.6525, "tft": 3.2394, "input_0": 579, "input_1": 257, "min_CLP": -6.66, "draft_iters": 12.0, "mem_use": 35.23, "gen_rate": 8.2, "speed": 2.9, "text": "\\nwhat kind of story should i wr"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 57, "tree_size": 256, "t0": 4.22, "t1": 0.7, "tft": 6.6995, "input_0": 532, "input_1": 257, "min_CLP": -7.03, "draft_iters": 32.0, "mem_use": 36.44, "gen_rate": 33.0, "speed": 6.7, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 62, "tree_h": 16.6, "tree_w": 66, "tree_size": 256, "t0": 2.858, "t1": 0.65, "tft": 4.6266, "input_0": 615, "input_1": 257, "min_CLP": -6.96, "draft_iters": 17.6, "mem_use": 35.1, "gen_rate": 12.4, "speed": 3.53, "text": "\\nIs there any way to format a U"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.2, "tree_w": 92, "tree_size": 256, "t0": 2.0317, "t1": 0.69, "tft": 6.5354, "input_0": 497, "input_1": 257, "min_CLP": -6.82, "draft_iters": 11.3, "mem_use": 36.12, "gen_rate": 6.7, "speed": 2.45, "text": "\\n[INST] <<SYS>>\\nThank you for "}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 14.2, "tree_w": 54, "tree_size": 256, "t0": 2.56, "t1": 0.65, "tft": 4.63, "input_0": 614, "input_1": 257, "min_CLP": -6.64, "draft_iters": 15.2, "mem_use": 35.07, "gen_rate": 9.6, "speed": 2.99, "text": "The Pacific Ocean.\\n\\nWhat is th"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.0, "tree_w": 100, "tree_size": 256, "t0": 1.5263, "t1": 0.66, "tft": 2.3087, "input_0": 455, "input_1": 257, "min_CLP": -7.11, "draft_iters": 7.1, "mem_use": 35.3, "gen_rate": 4.8, "speed": 2.17, "text": "\\nWell, that depends on how you "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 59, "tree_h": 30.8, "tree_w": 31, "tree_size": 256, "t0": 4.938, "t1": 0.762, "tft": 9.6037, "input_0": 712, "input_1": 257, "min_CLP": -6.64, "draft_iters": 31.0, "mem_use": 37.95, "gen_rate": 11.8, "speed": 2.07, "text": "\\n[Verse 1]\\nYou are a helpful, "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.2, "tree_w": 43, "tree_size": 256, "t0": 3.265, "t1": 0.67, "tft": 3.4731, "input_0": 736, "input_1": 257, "min_CLP": -6.33, "draft_iters": 19.5, "mem_use": 35.61, "gen_rate": 11.0, "speed": 2.8, "text": "[INST] What is a food supplier? "}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 11.3, "tree_w": 105, "tree_size": 256, "t0": 1.9873, "t1": 0.7027, "tft": 7.3569, "input_0": 408, "input_1": 257, "min_CLP": -7.37, "draft_iters": 12.2, "mem_use": 36.45, "gen_rate": 3.4, "speed": 1.25, "text": "lolololololo, im not being serio"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 67, "tree_size": 256, "t0": 2.196, "t1": 0.67, "tft": 3.9704, "input_0": 531, "input_1": 257, "min_CLP": -6.67, "draft_iters": 12.0, "mem_use": 35.61, "gen_rate": 7.2, "speed": 2.51, "text": "\\n1. The weather. If it is cold "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 57, "tree_h": 11.8, "tree_w": 93, "tree_size": 256, "t0": 2.0938, "t1": 0.6513, "tft": 4.7198, "input_0": 476, "input_1": 257, "min_CLP": -7.19, "draft_iters": 13.1, "mem_use": 35.26, "gen_rate": 7.1, "speed": 2.59, "text": "\\nWrite a speech about the value"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.8, "tree_w": 60, "tree_size": 256, "t0": 2.5017, "t1": 0.7083, "tft": 7.2451, "input_0": 607, "input_1": 257, "min_CLP": -6.4, "draft_iters": 13.2, "mem_use": 36.52, "gen_rate": 6.0, "speed": 1.87, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 256, "t0": 5.25, "t1": 0.66, "tft": 4.8345, "input_0": 1150, "input_1": 257, "min_CLP": -8.56, "draft_iters": 32.0, "mem_use": 35.32, "gen_rate": 33.0, "speed": 5.58, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 28.0, "tree_w": 37, "tree_size": 256, "t0": 4.4675, "t1": 0.7, "tft": 6.8212, "input_0": 863, "input_1": 257, "min_CLP": -6.33, "draft_iters": 28.5, "mem_use": 36.35, "gen_rate": 8.2, "speed": 1.6, "text": "The knowledge, hardware, and sof"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 42, "tree_size": 256, "t0": 4.42, "t1": 0.65, "tft": 4.1665, "input_0": 718, "input_1": 257, "min_CLP": -6.78, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 6.5, "text": "\\n[INST]<<SYS>>\\nYou are a helpf"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 72, "tree_size": 256, "t0": 1.83, "t1": 0.6614, "tft": 3.1307, "input_0": 505, "input_1": 257, "min_CLP": -6.71, "draft_iters": 9.7, "mem_use": 35.44, "gen_rate": 4.7, "speed": 1.89, "text": "In 1984, Public Law 98-262 was p"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 4.69, "t1": 0.66, "tft": 4.8134, "input_0": 899, "input_1": 257, "min_CLP": -6.81, "draft_iters": 32.0, "mem_use": 35.35, "gen_rate": 33.0, "speed": 6.16, "text": "\"\\nI will be having a party tomo"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 9.4, "tree_w": 110, "tree_size": 256, "t0": 1.742, "t1": 0.65, "tft": 4.7525, "input_0": 417, "input_1": 257, "min_CLP": -7.45, "draft_iters": 10.4, "mem_use": 35.12, "gen_rate": 8.6, "speed": 3.59, "text": "\\nHow to create a simple game in"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.5, "tree_w": 79, "tree_size": 256, "t0": 2.09, "t1": 0.67, "tft": 3.2299, "input_0": 557, "input_1": 257, "min_CLP": -6.66, "draft_iters": 10.8, "mem_use": 35.55, "gen_rate": 6.0, "speed": 2.18, "text": "\"Don't worry about looking dumb."}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.3, "tree_w": 76, "tree_size": 256, "t0": 2.03, "t1": 0.7, "tft": 7.0919, "input_0": 539, "input_1": 257, "min_CLP": -6.77, "draft_iters": 9.7, "mem_use": 36.38, "gen_rate": 6.0, "speed": 2.2, "text": "\\nThe most important Chinese cha"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 32.0, "tree_w": 25, "tree_size": 256, "t0": 4.635, "t1": 0.655, "tft": 4.8764, "input_0": 900, "input_1": 257, "min_CLP": -7.13, "draft_iters": 32.0, "mem_use": 35.18, "gen_rate": 26.0, "speed": 4.91, "text": "\\nif it takes 8 hours to fly to "}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 256, "t0": 4.86, "t1": 0.66, "tft": 4.8285, "input_0": 993, "input_1": 257, "min_CLP": -7.06, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 5.99, "text": "\\nWrite code for a Discord bot u"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 58, "tree_size": 256, "t0": 4.03, "t1": 0.65, "tft": 4.6684, "input_0": 597, "input_1": 257, "min_CLP": -6.93, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 7.05, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 58, "tree_size": 256, "t0": 2.3567, "t1": 0.7367, "tft": 5.8504, "input_0": 649, "input_1": 257, "min_CLP": -6.51, "draft_iters": 10.7, "mem_use": 37.28, "gen_rate": 6.3, "speed": 2.05, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 41, "tree_size": 256, "t0": 4.22, "t1": 0.65, "tft": 4.7803, "input_0": 728, "input_1": 257, "min_CLP": -6.88, "draft_iters": 32.0, "mem_use": 35.23, "gen_rate": 33.0, "speed": 6.78, "text": "\"\\nMike's mother had four kids. "}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 62, "tree_h": 29.0, "tree_w": 40, "tree_size": 256, "t0": 4.1325, "t1": 0.67, "tft": 3.389, "input_0": 767, "input_1": 257, "min_CLP": -6.35, "draft_iters": 29.2, "mem_use": 35.65, "gen_rate": 15.5, "speed": 3.23, "text": "\\nWhat is the best way to farm X"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.2, "tree_w": 67, "tree_size": 256, "t0": 2.38, "t1": 0.71, "tft": 7.3631, "input_0": 675, "input_1": 257, "min_CLP": -6.61, "draft_iters": 11.4, "mem_use": 36.6, "gen_rate": 8.4, "speed": 2.72, "text": "A good rule of thumb for toastin"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.1, "tree_w": 90, "tree_size": 256, "t0": 1.8586, "t1": 0.6529, "tft": 4.6951, "input_0": 445, "input_1": 257, "min_CLP": -7.05, "draft_iters": 11.1, "mem_use": 35.2, "gen_rate": 4.9, "speed": 1.93, "text": "\\nEDIT: I just realised that I p"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 17.2, "tree_w": 80, "tree_size": 256, "t0": 2.712, "t1": 0.668, "tft": 3.7551, "input_0": 533, "input_1": 257, "min_CLP": -6.9, "draft_iters": 18.2, "mem_use": 35.47, "gen_rate": 7.6, "speed": 2.25, "text": "\"\\nI created a mnemonic for the "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.7, "tree_w": 80, "tree_size": 256, "t0": 1.6886, "t1": 0.7, "tft": 4.744, "input_0": 483, "input_1": 257, "min_CLP": -6.67, "draft_iters": 7.9, "mem_use": 36.35, "gen_rate": 5.3, "speed": 2.21, "text": "First, you should have a good un"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 18.4, "tree_w": 54, "tree_size": 256, "t0": 3.346, "t1": 0.666, "tft": 2.8868, "input_0": 816, "input_1": 257, "min_CLP": -6.89, "draft_iters": 19.4, "mem_use": 35.51, "gen_rate": 7.8, "speed": 1.94, "text": "Inventor: Philo T. Farnsworth\\nI"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 16, "tree_h": 14.5, "tree_w": 54, "tree_size": 256, "t0": 2.8825, "t1": 0.71, "tft": 5.8371, "input_0": 671, "input_1": 257, "min_CLP": -6.73, "draft_iters": 15.5, "mem_use": 36.66, "gen_rate": 4.0, "speed": 1.11, "text": "[INST] Please mark this as done."}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.7, "tree_w": 90, "tree_size": 256, "t0": 1.7943, "t1": 0.68, "tft": 3.8838, "input_0": 487, "input_1": 257, "min_CLP": -6.69, "draft_iters": 9.0, "mem_use": 35.81, "gen_rate": 4.9, "speed": 1.96, "text": "Christmas is celebrated on diffe"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.7, "tree_w": 79, "tree_size": 256, "t0": 2.13, "t1": 0.66, "tft": 3.1933, "input_0": 492, "input_1": 257, "min_CLP": -6.86, "draft_iters": 12.9, "mem_use": 35.37, "gen_rate": 4.6, "speed": 1.64, "text": "I am disappointed in your lack o"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 66, "tree_size": 256, "t0": 2.306, "t1": 0.7, "tft": 7.1039, "input_0": 642, "input_1": 257, "min_CLP": -6.69, "draft_iters": 10.4, "mem_use": 36.28, "gen_rate": 6.6, "speed": 2.2, "text": "The most difficult part of learn"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 76, "tree_size": 256, "t0": 3.95, "t1": 0.65, "tft": 4.3117, "input_0": 531, "input_1": 257, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 35.16, "gen_rate": 33.0, "speed": 7.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 19.8, "tree_w": 58, "tree_size": 256, "t0": 2.895, "t1": 0.665, "tft": 4.1492, "input_0": 550, "input_1": 257, "min_CLP": -6.65, "draft_iters": 20.5, "mem_use": 35.52, "gen_rate": 8.5, "speed": 2.39, "text": "Okay, sure! How about: \"A wish f"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 30, "tree_size": 256, "t0": 4.51, "t1": 0.65, "tft": 2.8562, "input_0": 851, "input_1": 257, "min_CLP": -6.82, "draft_iters": 32.0, "mem_use": 35.21, "gen_rate": 32.0, "speed": 6.19, "text": "\"\\nIf I wanted to know how deep "}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 256, "t0": 5.21, "t1": 0.66, "tft": 3.2395, "input_0": 1018, "input_1": 257, "min_CLP": -7.22, "draft_iters": 32.0, "mem_use": 35.22, "gen_rate": 33.0, "speed": 5.62, "text": "\\nHow far away is Saggitarius A*"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 75, "tree_size": 256, "t0": 1.8237, "t1": 0.66, "tft": 3.2488, "input_0": 526, "input_1": 257, "min_CLP": -6.61, "draft_iters": 8.6, "mem_use": 35.41, "gen_rate": 4.4, "speed": 1.76, "text": "Google Authenticator is a mobile"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.0, "tree_w": 65, "tree_size": 256, "t0": 2.3267, "t1": 0.66, "tft": 3.1496, "input_0": 551, "input_1": 257, "min_CLP": -6.63, "draft_iters": 13.3, "mem_use": 35.36, "gen_rate": 11.7, "speed": 3.91, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 81, "tree_size": 256, "t0": 1.7583, "t1": 0.655, "tft": 3.9912, "input_0": 485, "input_1": 257, "min_CLP": -6.88, "draft_iters": 9.2, "mem_use": 35.19, "gen_rate": 6.0, "speed": 2.49, "text": "\\nI have a script, and I want it"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 32.0, "tree_w": 24, "tree_size": 256, "t0": 4.96, "t1": 0.655, "tft": 3.3605, "input_0": 987, "input_1": 257, "min_CLP": -6.96, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 25.0, "speed": 4.45, "text": "\\nThe wireless Internet signal i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 29.5, "tree_w": 30, "tree_size": 256, "t0": 4.405, "t1": 0.65, "tft": 4.7722, "input_0": 714, "input_1": 257, "min_CLP": -6.46, "draft_iters": 30.5, "mem_use": 35.13, "gen_rate": 27.0, "speed": 5.34, "text": "\\nWrite me a SPL program that ta"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.7, "tree_w": 68, "tree_size": 256, "t0": 2.1357, "t1": 0.65, "tft": 3.4072, "input_0": 546, "input_1": 257, "min_CLP": -6.81, "draft_iters": 11.9, "mem_use": 35.11, "gen_rate": 5.1, "speed": 1.84, "text": "\\nWe are looking for a whitepape"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 62, "tree_h": 23.0, "tree_w": 36, "tree_size": 256, "t0": 3.675, "t1": 0.6725, "tft": 3.9361, "input_0": 724, "input_1": 257, "min_CLP": -6.36, "draft_iters": 23.8, "mem_use": 35.73, "gen_rate": 15.5, "speed": 3.56, "text": "You can also use the SSH command"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 104, "tree_size": 256, "t0": 1.5412, "t1": 0.65, "tft": 3.9567, "input_0": 421, "input_1": 257, "min_CLP": -6.94, "draft_iters": 7.8, "mem_use": 35.07, "gen_rate": 4.0, "speed": 1.82, "text": "\"\\nWhat does the @ in python do?"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 49, "tree_size": 256, "t0": 3.95, "t1": 0.65, "tft": 4.7041, "input_0": 596, "input_1": 257, "min_CLP": -6.9, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 7.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.1, "tree_w": 97, "tree_size": 256, "t0": 1.5478, "t1": 0.6522, "tft": 3.0514, "input_0": 435, "input_1": 257, "min_CLP": -7.06, "draft_iters": 7.4, "mem_use": 35.21, "gen_rate": 4.0, "speed": 1.82, "text": "\\nIf you think that this is too "}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 36, "tree_size": 256, "t0": 4.3, "t1": 0.65, "tft": 4.7489, "input_0": 656, "input_1": 257, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 6.67, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 5.67, "t1": 0.67, "tft": 5.3345, "input_0": 1296, "input_1": 257, "min_CLP": -7.5, "draft_iters": 32.0, "mem_use": 35.45, "gen_rate": 33.0, "speed": 5.21, "text": "\\nA statistical model is a mathe"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.3, "tree_w": 41, "tree_size": 256, "t0": 3.55, "t1": 0.7167, "tft": 6.7495, "input_0": 728, "input_1": 257, "min_CLP": -6.45, "draft_iters": 20.7, "mem_use": 36.74, "gen_rate": 11.3, "speed": 2.66, "text": "\\nWhat is the capital of the Uni"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 24.0, "tree_w": 47, "tree_size": 256, "t0": 3.7267, "t1": 0.66, "tft": 4.8723, "input_0": 760, "input_1": 257, "min_CLP": -6.41, "draft_iters": 25.0, "mem_use": 35.37, "gen_rate": 16.0, "speed": 3.65, "text": "Decorators allow you to change t"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.3, "tree_w": 93, "tree_size": 256, "t0": 2.1883, "t1": 0.68, "tft": 6.2328, "input_0": 444, "input_1": 257, "min_CLP": -7.05, "draft_iters": 14.3, "mem_use": 35.92, "gen_rate": 5.7, "speed": 1.97, "text": "[INST] I am an Agent of the Blad"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 23.7, "tree_w": 34, "tree_size": 256, "t0": 3.6667, "t1": 0.66, "tft": 3.5107, "input_0": 746, "input_1": 257, "min_CLP": -6.6, "draft_iters": 24.7, "mem_use": 35.37, "gen_rate": 11.7, "speed": 2.7, "text": "A B C D E F G H [INST]\\n\\nGive m"}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 29.7, "tree_w": 25, "tree_size": 256, "t0": 5.12, "t1": 0.7333, "tft": 7.6404, "input_0": 977, "input_1": 257, "min_CLP": -6.17, "draft_iters": 30.3, "mem_use": 37.26, "gen_rate": 19.3, "speed": 3.3, "text": "\\n| Interpreted Languages       "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 77, "tree_size": 256, "t0": 2.3217, "t1": 0.84, "tft": 11.8917, "input_0": 552, "input_1": 257, "min_CLP": -6.51, "draft_iters": 9.3, "mem_use": 39.99, "gen_rate": 6.0, "speed": 1.9, "text": "I would be happy to provide you "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.4, "tree_w": 67, "tree_size": 256, "t0": 2.652, "t1": 0.688, "tft": 4.6148, "input_0": 659, "input_1": 257, "min_CLP": -6.76, "draft_iters": 15.4, "mem_use": 36.54, "gen_rate": 7.0, "speed": 2.1, "text": "\"L'H\u00f4pital's Rule is a fundament"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 4.89, "t1": 0.65, "tft": 4.7213, "input_0": 868, "input_1": 257, "min_CLP": -7.19, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 5.95, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 9.4, "tree_w": 93, "tree_size": 256, "t0": 1.7775, "t1": 0.655, "tft": 3.4228, "input_0": 465, "input_1": 257, "min_CLP": -7.08, "draft_iters": 10.2, "mem_use": 35.15, "gen_rate": 4.0, "speed": 1.64, "text": "\\nThe problem:\\n\\nI am building "}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.6, "tree_w": 81, "tree_size": 256, "t0": 2.442, "t1": 0.71, "tft": 7.4983, "input_0": 535, "input_1": 257, "min_CLP": -6.82, "draft_iters": 13.6, "mem_use": 36.58, "gen_rate": 6.4, "speed": 2.03, "text": "\"\\n> How can I start a successfu"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 28.7, "tree_w": 39, "tree_size": 256, "t0": 4.06, "t1": 0.65, "tft": 3.1213, "input_0": 744, "input_1": 257, "min_CLP": -6.73, "draft_iters": 29.0, "mem_use": 35.11, "gen_rate": 21.0, "speed": 4.46, "text": "\\nGive me an impression of what "}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.3, "tree_w": 72, "tree_size": 256, "t0": 2.2543, "t1": 0.7586, "tft": 7.583, "input_0": 528, "input_1": 257, "min_CLP": -6.81, "draft_iters": 10.4, "mem_use": 37.73, "gen_rate": 5.3, "speed": 1.75, "text": "There are several open source fr"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.2, "tree_w": 67, "tree_size": 256, "t0": 2.436, "t1": 0.66, "tft": 2.3849, "input_0": 609, "input_1": 257, "min_CLP": -6.53, "draft_iters": 13.4, "mem_use": 35.46, "gen_rate": 8.6, "speed": 2.78, "text": "There are lots of different ways"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.2, "tree_w": 85, "tree_size": 256, "t0": 2.3467, "t1": 0.6517, "tft": 2.7957, "input_0": 534, "input_1": 257, "min_CLP": -6.99, "draft_iters": 15.3, "mem_use": 35.23, "gen_rate": 6.0, "speed": 2.0, "text": "\"CMU's Robotics program is one o"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 13.8, "tree_w": 88, "tree_size": 256, "t0": 2.4225, "t1": 0.655, "tft": 2.5142, "input_0": 551, "input_1": 257, "min_CLP": -7.0, "draft_iters": 14.8, "mem_use": 35.25, "gen_rate": 11.2, "speed": 3.66, "text": "I will be free to answer any que"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 65, "tree_size": 256, "t0": 2.1033, "t1": 0.68, "tft": 5.0683, "input_0": 580, "input_1": 257, "min_CLP": -6.35, "draft_iters": 9.8, "mem_use": 35.88, "gen_rate": 5.5, "speed": 1.97, "text": "The biggest factors that impact "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.4, "tree_w": 84, "tree_size": 256, "t0": 1.9214, "t1": 0.6543, "tft": 3.1063, "input_0": 516, "input_1": 257, "min_CLP": -7.26, "draft_iters": 9.7, "mem_use": 35.3, "gen_rate": 5.4, "speed": 2.11, "text": "\\nWhat is the name of the most f"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 77, "tree_size": 256, "t0": 2.125, "t1": 0.66, "tft": 2.7539, "input_0": 577, "input_1": 257, "min_CLP": -6.78, "draft_iters": 11.0, "mem_use": 35.39, "gen_rate": 5.3, "speed": 1.91, "text": "chili powder\\nlentils\\ntomatoes\\"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 64, "tree_size": 256, "t0": 2.066, "t1": 0.66, "tft": 3.0182, "input_0": 583, "input_1": 257, "min_CLP": -6.49, "draft_iters": 10.4, "mem_use": 35.41, "gen_rate": 7.2, "speed": 2.64, "text": "Unfortunately, most cities have "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.5, "tree_w": 78, "tree_size": 256, "t0": 1.8413, "t1": 0.7, "tft": 4.9447, "input_0": 476, "input_1": 257, "min_CLP": -6.82, "draft_iters": 9.5, "mem_use": 36.36, "gen_rate": 4.0, "speed": 1.57, "text": "\u2022 YouTube is a great resource fo"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.3, "tree_w": 111, "tree_size": 256, "t0": 1.5511, "t1": 0.6511, "tft": 3.8239, "input_0": 410, "input_1": 257, "min_CLP": -7.43, "draft_iters": 8.7, "mem_use": 35.07, "gen_rate": 4.0, "speed": 1.81, "text": "\\nI was thinking of using my sta"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 63, "tree_h": 32.0, "tree_w": 34, "tree_size": 256, "t0": 4.69, "t1": 0.655, "tft": 4.5511, "input_0": 822, "input_1": 257, "min_CLP": -6.6, "draft_iters": 32.0, "mem_use": 35.15, "gen_rate": 15.8, "speed": 2.95, "text": "\\nGiven two matrices A and B whi"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 31.5, "tree_w": 23, "tree_size": 256, "t0": 4.865, "t1": 0.68, "tft": 6.2987, "input_0": 861, "input_1": 257, "min_CLP": -6.53, "draft_iters": 32.0, "mem_use": 35.91, "gen_rate": 23.0, "speed": 4.14, "text": "Could you explain each sentence "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 22.2, "tree_w": 78, "tree_size": 256, "t0": 3.175, "t1": 0.7017, "tft": 6.7337, "input_0": 518, "input_1": 257, "min_CLP": -6.87, "draft_iters": 22.8, "mem_use": 36.46, "gen_rate": 5.5, "speed": 1.42, "text": "\\nWrite a short story. The setti"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 20.0, "tree_w": 64, "tree_size": 256, "t0": 3.0333, "t1": 0.65, "tft": 4.1745, "input_0": 601, "input_1": 257, "min_CLP": -6.86, "draft_iters": 21.0, "mem_use": 35.06, "gen_rate": 5.8, "speed": 1.58, "text": "\"\\nWhat's the current date?\\n\\nT"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 97, "tree_size": 256, "t0": 1.6143, "t1": 0.68, "tft": 3.9469, "input_0": 458, "input_1": 257, "min_CLP": -6.95, "draft_iters": 7.7, "mem_use": 35.86, "gen_rate": 5.0, "speed": 2.18, "text": "\\nI have had a few technical pro"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.3, "tree_w": 50, "tree_size": 256, "t0": 2.7833, "t1": 0.66, "tft": 2.7728, "input_0": 628, "input_1": 257, "min_CLP": -6.79, "draft_iters": 16.3, "mem_use": 35.25, "gen_rate": 11.3, "speed": 3.3, "text": "\"I don't know how to write like "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 45, "tree_size": 256, "t0": 4.02, "t1": 0.65, "tft": 4.6513, "input_0": 599, "input_1": 257, "min_CLP": -7.04, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 7.05, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 256, "t0": 4.03, "t1": 0.66, "tft": 4.8129, "input_0": 621, "input_1": 257, "min_CLP": -7.01, "draft_iters": 32.0, "mem_use": 35.26, "gen_rate": 33.0, "speed": 7.04, "text": "\\n>> [INST] <<SYS>>\\nYou are a h"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 75, "tree_size": 256, "t0": 2.178, "t1": 0.65, "tft": 4.2535, "input_0": 642, "input_1": 257, "min_CLP": -6.74, "draft_iters": 10.8, "mem_use": 35.06, "gen_rate": 6.4, "speed": 2.26, "text": "\\nIn order to understand how met"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 13.0, "tree_w": 58, "tree_size": 256, "t0": 2.33, "t1": 0.67, "tft": 5.5132, "input_0": 544, "input_1": 257, "min_CLP": -6.66, "draft_iters": 14.0, "mem_use": 35.66, "gen_rate": 0.0, "speed": 0.0, "text": "You are welcome."}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 71, "tree_size": 256, "t0": 1.828, "t1": 0.65, "tft": 4.3483, "input_0": 491, "input_1": 257, "min_CLP": -6.6, "draft_iters": 9.8, "mem_use": 35.16, "gen_rate": 6.8, "speed": 2.74, "text": "\\nA father, mother and son are o"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 55, "tree_size": 256, "t0": 2.532, "t1": 0.66, "tft": 2.8057, "input_0": 696, "input_1": 257, "min_CLP": -6.78, "draft_iters": 13.4, "mem_use": 35.35, "gen_rate": 7.4, "speed": 2.32, "text": "\\nWhat is the name of the river "}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 89, "tree_size": 256, "t0": 1.7114, "t1": 0.6657, "tft": 3.144, "input_0": 469, "input_1": 257, "min_CLP": -6.88, "draft_iters": 8.6, "mem_use": 35.53, "gen_rate": 5.0, "speed": 2.1, "text": "\"\\nThis is a great question.\\n\\n"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 113, "tree_size": 256, "t0": 1.2925, "t1": 0.6538, "tft": 3.5052, "input_0": 394, "input_1": 257, "min_CLP": -7.21, "draft_iters": 6.2, "mem_use": 35.17, "gen_rate": 4.1, "speed": 2.12, "text": "\\nI am also a beginner in this t"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 84, "tree_size": 256, "t0": 1.6257, "t1": 0.6714, "tft": 3.6116, "input_0": 471, "input_1": 257, "min_CLP": -6.76, "draft_iters": 7.7, "mem_use": 35.71, "gen_rate": 4.6, "speed": 1.99, "text": "The Dynamic Link Library (DLL) i"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 60, "tree_size": 256, "t0": 4.2, "t1": 0.66, "tft": 2.8887, "input_0": 600, "input_1": 257, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 35.31, "gen_rate": 33.0, "speed": 6.8, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 88, "tree_size": 256, "t0": 1.796, "t1": 0.65, "tft": 2.7196, "input_0": 463, "input_1": 257, "min_CLP": -7.1, "draft_iters": 9.8, "mem_use": 35.06, "gen_rate": 7.0, "speed": 2.86, "text": "\\nWhat is the infinite banking c"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 114, "tree_size": 256, "t0": 1.5683, "t1": 0.6517, "tft": 4.7268, "input_0": 456, "input_1": 257, "min_CLP": -7.3, "draft_iters": 7.8, "mem_use": 35.13, "gen_rate": 5.8, "speed": 2.63, "text": "\\nThe framework should be able t"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.4, "tree_w": 77, "tree_size": 256, "t0": 1.8671, "t1": 0.6543, "tft": 2.4505, "input_0": 514, "input_1": 257, "min_CLP": -6.65, "draft_iters": 9.7, "mem_use": 35.2, "gen_rate": 5.3, "speed": 2.1, "text": "The landlord, by default, is the"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.7, "tree_w": 91, "tree_size": 256, "t0": 1.8129, "t1": 0.6614, "tft": 2.7809, "input_0": 509, "input_1": 257, "min_CLP": -6.78, "draft_iters": 9.1, "mem_use": 35.45, "gen_rate": 4.9, "speed": 1.96, "text": "\"I think it's because the charac"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 83, "tree_size": 256, "t0": 1.73, "t1": 0.68, "tft": 4.8875, "input_0": 474, "input_1": 257, "min_CLP": -6.73, "draft_iters": 8.6, "mem_use": 35.91, "gen_rate": 5.0, "speed": 2.07, "text": "\"\\nI would be happy to help you "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.2, "tree_w": 52, "tree_size": 256, "t0": 2.71, "t1": 0.69, "tft": 5.9646, "input_0": 699, "input_1": 257, "min_CLP": -6.3, "draft_iters": 14.2, "mem_use": 36.15, "gen_rate": 7.0, "speed": 2.06, "text": "\"Although English is the most co"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 72, "tree_size": 256, "t0": 2.032, "t1": 0.66, "tft": 2.9412, "input_0": 566, "input_1": 257, "min_CLP": -6.76, "draft_iters": 10.4, "mem_use": 35.39, "gen_rate": 6.8, "speed": 2.53, "text": "Most of the AI tools mentioned a"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 31, "tree_h": 9.5, "tree_w": 73, "tree_size": 256, "t0": 2.0433, "t1": 0.6583, "tft": 2.6187, "input_0": 546, "input_1": 257, "min_CLP": -6.79, "draft_iters": 10.7, "mem_use": 35.31, "gen_rate": 5.2, "speed": 1.91, "text": "Due to the fact that I am not a "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.7, "tree_w": 91, "tree_size": 256, "t0": 1.875, "t1": 0.66, "tft": 3.0115, "input_0": 478, "input_1": 257, "min_CLP": -6.86, "draft_iters": 10.8, "mem_use": 35.43, "gen_rate": 6.7, "speed": 2.63, "text": "\"It's worth nothing to me. You s"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 57, "tree_size": 256, "t0": 2.5875, "t1": 0.66, "tft": 3.0736, "input_0": 624, "input_1": 257, "min_CLP": -7.03, "draft_iters": 14.8, "mem_use": 35.4, "gen_rate": 8.5, "speed": 2.62, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.2, "tree_w": 64, "tree_size": 256, "t0": 2.415, "t1": 0.655, "tft": 4.5981, "input_0": 560, "input_1": 257, "min_CLP": -6.87, "draft_iters": 14.5, "mem_use": 35.13, "gen_rate": 10.8, "speed": 3.51, "text": "\\nWhat do you think about the ne"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 17.2, "tree_w": 48, "tree_size": 256, "t0": 3.27, "t1": 0.682, "tft": 4.551, "input_0": 780, "input_1": 257, "min_CLP": -6.45, "draft_iters": 18.4, "mem_use": 35.92, "gen_rate": 6.4, "speed": 1.62, "text": "The ***[Mauna Kea Observatories]"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 17.0, "tree_w": 74, "tree_size": 256, "t0": 2.775, "t1": 0.6517, "tft": 4.0841, "input_0": 576, "input_1": 257, "min_CLP": -7.26, "draft_iters": 18.3, "mem_use": 35.21, "gen_rate": 6.7, "speed": 1.94, "text": "The company is a [\\\\INST]\\n[INST"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 4.79, "t1": 0.65, "tft": 4.7381, "input_0": 936, "input_1": 257, "min_CLP": -8.23, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 6.06, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 17.5, "tree_w": 41, "tree_size": 256, "t0": 3.2225, "t1": 0.66, "tft": 4.31, "input_0": 766, "input_1": 257, "min_CLP": -6.3, "draft_iters": 18.8, "mem_use": 35.39, "gen_rate": 10.5, "speed": 2.7, "text": "[INST] what is your name? [\\\\INS"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.2, "tree_w": 61, "tree_size": 256, "t0": 2.282, "t1": 0.696, "tft": 5.1736, "input_0": 628, "input_1": 257, "min_CLP": -6.67, "draft_iters": 10.8, "mem_use": 36.22, "gen_rate": 7.0, "speed": 2.35, "text": "The initial noise is produced by"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 99, "tree_size": 256, "t0": 1.7583, "t1": 0.67, "tft": 3.5983, "input_0": 532, "input_1": 257, "min_CLP": -6.98, "draft_iters": 8.5, "mem_use": 35.59, "gen_rate": 5.5, "speed": 2.27, "text": "Evolutionary psychologists sugge"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.7, "tree_w": 72, "tree_size": 256, "t0": 2.4667, "t1": 0.68, "tft": 5.5796, "input_0": 612, "input_1": 257, "min_CLP": -6.56, "draft_iters": 14.0, "mem_use": 35.8, "gen_rate": 12.3, "speed": 3.92, "text": "\"I'm glad that you're excited ab"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.5, "tree_w": 99, "tree_size": 256, "t0": 1.6833, "t1": 0.65, "tft": 2.8467, "input_0": 469, "input_1": 257, "min_CLP": -7.03, "draft_iters": 8.7, "mem_use": 35.09, "gen_rate": 6.0, "speed": 2.57, "text": "\\nYou are a successful artist. Y"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 5.76, "t1": 0.74, "tft": 8.6751, "input_0": 1114, "input_1": 257, "min_CLP": -5.8, "draft_iters": 32.0, "mem_use": 37.38, "gen_rate": 33.0, "speed": 5.08, "text": "\\nWhat is the James Webb Space T"}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 76, "tree_size": 256, "t0": 4.1, "t1": 0.68, "tft": 5.1407, "input_0": 514, "input_1": 257, "min_CLP": -7.67, "draft_iters": 32.0, "mem_use": 35.86, "gen_rate": 33.0, "speed": 6.9, "text": "\\nHi. I want to make an embossed"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 14.0, "tree_w": 61, "tree_size": 256, "t0": 2.555, "t1": 0.67, "tft": 4.4628, "input_0": 586, "input_1": 257, "min_CLP": -6.67, "draft_iters": 15.2, "mem_use": 35.55, "gen_rate": 5.3, "speed": 1.65, "text": "Assuming your original departure"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 19.8, "tree_w": 52, "tree_size": 256, "t0": 3.195, "t1": 0.65, "tft": 4.6295, "input_0": 663, "input_1": 257, "min_CLP": -7.31, "draft_iters": 20.8, "mem_use": 35.1, "gen_rate": 10.5, "speed": 2.73, "text": "\\nWrite a short essay on how the"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 27.5, "tree_w": 42, "tree_size": 256, "t0": 4.735, "t1": 0.66, "tft": 3.2391, "input_0": 1101, "input_1": 257, "min_CLP": -7.0, "draft_iters": 28.5, "mem_use": 35.28, "gen_rate": 22.0, "speed": 4.08, "text": "\"Sure! Here's another one for yo"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 26.5, "tree_w": 47, "tree_size": 256, "t0": 4.05, "t1": 0.65, "tft": 4.6473, "input_0": 743, "input_1": 257, "min_CLP": -7.2, "draft_iters": 27.5, "mem_use": 35.1, "gen_rate": 27.5, "speed": 5.84, "text": "\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.7, "tree_w": 93, "tree_size": 256, "t0": 1.8157, "t1": 0.7414, "tft": 6.086, "input_0": 438, "input_1": 257, "min_CLP": -6.73, "draft_iters": 8.9, "mem_use": 37.48, "gen_rate": 4.9, "speed": 1.9, "text": "\"In that case you're right, I'm "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 75, "tree_size": 256, "t0": 1.98, "t1": 0.65, "tft": 3.1923, "input_0": 490, "input_1": 257, "min_CLP": -6.81, "draft_iters": 11.4, "mem_use": 35.34, "gen_rate": 7.0, "speed": 2.66, "text": "\\nIs there any proof that the un"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.7, "tree_w": 75, "tree_size": 256, "t0": 2.5314, "t1": 0.7914, "tft": 9.5561, "input_0": 525, "input_1": 257, "min_CLP": -6.76, "draft_iters": 12.9, "mem_use": 38.61, "gen_rate": 4.9, "speed": 1.46, "text": "Yes, I do. The first program out"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 61, "tree_h": 17.0, "tree_w": 78, "tree_size": 256, "t0": 2.6433, "t1": 0.67, "tft": 4.5331, "input_0": 511, "input_1": 257, "min_CLP": -6.95, "draft_iters": 17.8, "mem_use": 35.89, "gen_rate": 10.2, "speed": 3.07, "text": "\\nOkay, so I\\'m not sure what yo"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 90, "tree_size": 256, "t0": 1.6767, "t1": 0.65, "tft": 4.1908, "input_0": 465, "input_1": 257, "min_CLP": -7.32, "draft_iters": 8.8, "mem_use": 35.13, "gen_rate": 5.7, "speed": 2.43, "text": "\\nWhat is the closest equivalent"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.4, "tree_w": 62, "tree_size": 256, "t0": 2.492, "t1": 0.65, "tft": 3.3875, "input_0": 574, "input_1": 257, "min_CLP": -6.91, "draft_iters": 15.4, "mem_use": 35.07, "gen_rate": 7.8, "speed": 2.48, "text": "\\nHow do you get a job at a poli"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 73, "tree_size": 256, "t0": 2.076, "t1": 0.654, "tft": 2.8409, "input_0": 620, "input_1": 257, "min_CLP": -6.75, "draft_iters": 10.8, "mem_use": 35.19, "gen_rate": 6.6, "speed": 2.42, "text": "\\nI\\'m trying to think of a reas"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.5, "tree_w": 70, "tree_size": 256, "t0": 1.9133, "t1": 0.6583, "tft": 2.4255, "input_0": 530, "input_1": 257, "min_CLP": -6.68, "draft_iters": 9.7, "mem_use": 35.35, "gen_rate": 6.0, "speed": 2.33, "text": "You should watch the newest epis"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.8, "tree_w": 70, "tree_size": 256, "t0": 2.0967, "t1": 0.6917, "tft": 4.5988, "input_0": 522, "input_1": 257, "min_CLP": -6.49, "draft_iters": 11.2, "mem_use": 36.16, "gen_rate": 5.3, "speed": 1.91, "text": "SDR devices are available for pu"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.7, "tree_w": 62, "tree_size": 256, "t0": 2.4067, "t1": 0.6733, "tft": 3.3125, "input_0": 580, "input_1": 257, "min_CLP": -6.38, "draft_iters": 13.7, "mem_use": 35.72, "gen_rate": 5.5, "speed": 1.78, "text": "The presence of F-centers can ma"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.4, "tree_w": 77, "tree_size": 256, "t0": 1.7857, "t1": 0.6543, "tft": 4.7577, "input_0": 493, "input_1": 257, "min_CLP": -6.85, "draft_iters": 9.4, "mem_use": 35.16, "gen_rate": 4.9, "speed": 1.99, "text": "\"\\nI'm afraid that's not possibl"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 12, "tree_size": 256, "t0": 5.82, "t1": 0.73, "tft": 8.36, "input_0": 1238, "input_1": 257, "min_CLP": -6.66, "draft_iters": 32.0, "mem_use": 37.09, "gen_rate": 32.0, "speed": 4.89, "text": "\\nHow can you write a first pers"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 256, "t0": 5.44, "t1": 0.68, "tft": 6.5354, "input_0": 1210, "input_1": 257, "min_CLP": -6.68, "draft_iters": 32.0, "mem_use": 35.91, "gen_rate": 33.0, "speed": 5.38, "text": "\"Aqu\u00ed tienes una reducci\u00f3n de la"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 4.89, "t1": 0.65, "tft": 3.2239, "input_0": 826, "input_1": 257, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 5.95, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 21.3, "tree_w": 58, "tree_size": 256, "t0": 3.1267, "t1": 0.65, "tft": 4.7969, "input_0": 573, "input_1": 257, "min_CLP": -6.95, "draft_iters": 22.0, "mem_use": 35.13, "gen_rate": 18.0, "speed": 4.76, "text": "\\nThe following is an example of"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 61, "tree_h": 20.0, "tree_w": 53, "tree_size": 256, "t0": 3.09, "t1": 0.67, "tft": 3.7739, "input_0": 570, "input_1": 257, "min_CLP": -6.8, "draft_iters": 20.7, "mem_use": 35.65, "gen_rate": 20.3, "speed": 5.41, "text": "I can write that in a poem, the "}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.9, "tree_w": 103, "tree_size": 256, "t0": 1.6244, "t1": 0.6933, "tft": 4.7531, "input_0": 448, "input_1": 257, "min_CLP": -7.19, "draft_iters": 8.0, "mem_use": 36.18, "gen_rate": 3.7, "speed": 1.58, "text": "\\nJsFiddle\\n\\nAs a Javascript co"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 66, "tree_size": 256, "t0": 2.232, "t1": 0.66, "tft": 3.6865, "input_0": 609, "input_1": 257, "min_CLP": -6.81, "draft_iters": 11.0, "mem_use": 35.37, "gen_rate": 6.6, "speed": 2.28, "text": "\\nThe first thing you need to do"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 79, "tree_size": 256, "t0": 1.8633, "t1": 0.67, "tft": 3.8154, "input_0": 492, "input_1": 257, "min_CLP": -6.6, "draft_iters": 10.0, "mem_use": 35.62, "gen_rate": 6.0, "speed": 2.37, "text": "If the pan is hot, you can assum"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 101, "tree_size": 256, "t0": 1.7986, "t1": 0.65, "tft": 4.2279, "input_0": 490, "input_1": 257, "min_CLP": -7.36, "draft_iters": 9.7, "mem_use": 35.07, "gen_rate": 5.0, "speed": 2.04, "text": "\\njavascript is a front end lang"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 55, "tree_size": 256, "t0": 3.94, "t1": 0.65, "tft": 3.3602, "input_0": 601, "input_1": 257, "min_CLP": -7.0, "draft_iters": 32.0, "mem_use": 35.07, "gen_rate": 33.0, "speed": 7.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 33, "tree_size": 256, "t0": 4.84, "t1": 0.67, "tft": 3.635, "input_0": 927, "input_1": 257, "min_CLP": -6.62, "draft_iters": 32.0, "mem_use": 35.43, "gen_rate": 33.0, "speed": 5.99, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 29.0, "tree_w": 42, "tree_size": 256, "t0": 4.03, "t1": 0.65, "tft": 4.3119, "input_0": 688, "input_1": 257, "min_CLP": -6.78, "draft_iters": 29.5, "mem_use": 35.14, "gen_rate": 18.5, "speed": 3.95, "text": "\\nComplete the following sentenc"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 58, "tree_size": 256, "t0": 3.82, "t1": 0.65, "tft": 4.6386, "input_0": 539, "input_1": 257, "min_CLP": -7.03, "draft_iters": 32.0, "mem_use": 35.13, "gen_rate": 33.0, "speed": 7.37, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 5.03, "t1": 0.65, "tft": 3.0509, "input_0": 848, "input_1": 257, "min_CLP": -7.03, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 33.0, "speed": 5.81, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 85, "tree_size": 256, "t0": 1.6443, "t1": 0.7486, "tft": 8.0962, "input_0": 447, "input_1": 257, "min_CLP": -6.81, "draft_iters": 7.3, "mem_use": 37.54, "gen_rate": 4.7, "speed": 1.97, "text": "\"\\nI like the script. I think it"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 5.39, "t1": 0.69, "tft": 5.6044, "input_0": 1061, "input_1": 257, "min_CLP": -7.69, "draft_iters": 32.0, "mem_use": 36.28, "gen_rate": 33.0, "speed": 5.42, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.0, "tree_w": 58, "tree_size": 256, "t0": 2.2467, "t1": 0.6683, "tft": 3.2307, "input_0": 541, "input_1": 257, "min_CLP": -6.52, "draft_iters": 13.0, "mem_use": 35.53, "gen_rate": 5.3, "speed": 1.83, "text": "The formula for estimating the v"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 14.0, "tree_w": 63, "tree_size": 256, "t0": 2.5067, "t1": 0.67, "tft": 3.4097, "input_0": 597, "input_1": 257, "min_CLP": -6.61, "draft_iters": 15.0, "mem_use": 35.62, "gen_rate": 7.7, "speed": 2.41, "text": "\"\\nA polar bear's fur is thick a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 70, "tree_size": 256, "t0": 2.11, "t1": 0.69, "tft": 4.303, "input_0": 583, "input_1": 257, "min_CLP": -6.49, "draft_iters": 10.0, "mem_use": 36.17, "gen_rate": 5.8, "speed": 2.08, "text": "\\nThe lemon wedges are just a ga"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 51, "tree_size": 256, "t0": 3.99, "t1": 0.65, "tft": 4.8149, "input_0": 597, "input_1": 257, "min_CLP": -6.95, "draft_iters": 32.0, "mem_use": 35.18, "gen_rate": 33.0, "speed": 7.11, "text": "\\n<INST>\\nYou are a helpful, res"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 12.7, "tree_w": 54, "tree_size": 256, "t0": 2.41, "t1": 0.65, "tft": 2.7826, "input_0": 612, "input_1": 257, "min_CLP": -6.7, "draft_iters": 13.9, "mem_use": 35.15, "gen_rate": 5.4, "speed": 1.77, "text": "\"\\nWhat is your favorite Pokemon"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.7, "tree_w": 70, "tree_size": 256, "t0": 2.3733, "t1": 0.6517, "tft": 4.2407, "input_0": 606, "input_1": 257, "min_CLP": -6.74, "draft_iters": 13.8, "mem_use": 35.1, "gen_rate": 5.7, "speed": 1.87, "text": "\\nHello,\\n\\nI am new to TypeScri"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.2, "tree_w": 49, "tree_size": 256, "t0": 2.7725, "t1": 0.68, "tft": 3.9675, "input_0": 637, "input_1": 257, "min_CLP": -6.58, "draft_iters": 16.5, "mem_use": 35.87, "gen_rate": 9.5, "speed": 2.75, "text": "[INST] Can you name any cities c"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 72, "tree_size": 256, "t0": 1.944, "t1": 0.67, "tft": 3.8777, "input_0": 583, "input_1": 257, "min_CLP": -6.82, "draft_iters": 9.4, "mem_use": 35.63, "gen_rate": 6.4, "speed": 2.45, "text": "Dyson has also argued that the u"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 27.5, "tree_w": 31, "tree_size": 256, "t0": 4.055, "t1": 0.65, "tft": 3.4294, "input_0": 811, "input_1": 257, "min_CLP": -6.46, "draft_iters": 27.8, "mem_use": 35.06, "gen_rate": 11.0, "speed": 2.34, "text": "\\ncan you code? [\\\\INST]\\n\\ncan "}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 76, "tree_size": 256, "t0": 2.17, "t1": 0.66, "tft": 3.8582, "input_0": 588, "input_1": 257, "min_CLP": -6.74, "draft_iters": 11.8, "mem_use": 35.41, "gen_rate": 8.5, "speed": 3.0, "text": "\\nI didn\\'t know that! [\\\\INST]\\"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 45, "tree_size": 256, "t0": 4.58, "t1": 0.67, "tft": 4.8644, "input_0": 709, "input_1": 257, "min_CLP": -6.75, "draft_iters": 32.0, "mem_use": 35.73, "gen_rate": 33.0, "speed": 6.28, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.0, "tree_w": 71, "tree_size": 256, "t0": 2.56, "t1": 0.658, "tft": 3.5543, "input_0": 549, "input_1": 257, "min_CLP": -6.63, "draft_iters": 16.0, "mem_use": 35.29, "gen_rate": 6.6, "speed": 2.05, "text": "1.    By taking care of myself a"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 31.5, "tree_w": 23, "tree_size": 256, "t0": 4.87, "t1": 0.655, "tft": 4.6683, "input_0": 933, "input_1": 257, "min_CLP": -7.51, "draft_iters": 32.0, "mem_use": 35.12, "gen_rate": 31.0, "speed": 5.61, "text": "\\n\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\\\"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.0, "tree_w": 75, "tree_size": 256, "t0": 2.376, "t1": 0.66, "tft": 2.9883, "input_0": 527, "input_1": 257, "min_CLP": -6.63, "draft_iters": 14.6, "mem_use": 35.37, "gen_rate": 7.6, "speed": 2.5, "text": "The comparison of the libraries "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 28.5, "tree_w": 35, "tree_size": 256, "t0": 4.625, "t1": 0.67, "tft": 5.4424, "input_0": 868, "input_1": 257, "min_CLP": -6.77, "draft_iters": 30.0, "mem_use": 35.64, "gen_rate": 23.0, "speed": 4.34, "text": "[INST] How can I ask complex mat"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 19.8, "tree_w": 51, "tree_size": 256, "t0": 3.13, "t1": 0.6625, "tft": 3.4462, "input_0": 615, "input_1": 257, "min_CLP": -6.74, "draft_iters": 20.5, "mem_use": 35.49, "gen_rate": 12.5, "speed": 3.3, "text": "The decoded URL string is\\n\\nhtt"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 24.2, "tree_w": 31, "tree_size": 256, "t0": 3.8325, "t1": 0.705, "tft": 6.1331, "input_0": 683, "input_1": 257, "min_CLP": -6.16, "draft_iters": 24.8, "mem_use": 36.47, "gen_rate": 14.8, "speed": 3.25, "text": "\"\\nHow can you use the derivativ"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 71, "tree_size": 256, "t0": 2.245, "t1": 0.74, "tft": 6.1759, "input_0": 570, "input_1": 257, "min_CLP": -6.61, "draft_iters": 10.7, "mem_use": 37.39, "gen_rate": 5.5, "speed": 1.84, "text": "The best vegan and dairy-free ch"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 74, "tree_size": 256, "t0": 2.1057, "t1": 0.6786, "tft": 3.3094, "input_0": 563, "input_1": 257, "min_CLP": -6.58, "draft_iters": 10.7, "mem_use": 35.77, "gen_rate": 5.0, "speed": 1.8, "text": "\"It's great that you want to bea"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.2, "tree_w": 73, "tree_size": 256, "t0": 1.9625, "t1": 0.69, "tft": 6.3804, "input_0": 512, "input_1": 257, "min_CLP": -6.52, "draft_iters": 10.2, "mem_use": 35.98, "gen_rate": 8.5, "speed": 3.21, "text": "\\nHow much does AI cost? [\\\\INST"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.0, "tree_w": 51, "tree_size": 256, "t0": 2.395, "t1": 0.65, "tft": 4.1346, "input_0": 579, "input_1": 257, "min_CLP": -6.61, "draft_iters": 14.0, "mem_use": 35.1, "gen_rate": 8.0, "speed": 2.62, "text": "What is the difference between a"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 79, "tree_size": 256, "t0": 2.135, "t1": 0.67, "tft": 5.2415, "input_0": 579, "input_1": 257, "min_CLP": -6.58, "draft_iters": 10.8, "mem_use": 35.65, "gen_rate": 5.5, "speed": 1.96, "text": "Black Friday is a shopping holid"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 58, "tree_size": 256, "t0": 3.85, "t1": 0.65, "tft": 4.3274, "input_0": 561, "input_1": 257, "min_CLP": -7.16, "draft_iters": 32.0, "mem_use": 35.16, "gen_rate": 33.0, "speed": 7.32, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.8, "tree_w": 94, "tree_size": 256, "t0": 1.75, "t1": 0.65, "tft": 3.8411, "input_0": 439, "input_1": 257, "min_CLP": -7.2, "draft_iters": 9.9, "mem_use": 35.11, "gen_rate": 4.6, "speed": 1.92, "text": "\\nNo.\\n\\nI have been informed th"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 17.5, "tree_w": 72, "tree_size": 256, "t0": 2.74, "t1": 0.6517, "tft": 3.712, "input_0": 577, "input_1": 257, "min_CLP": -6.8, "draft_iters": 18.3, "mem_use": 35.11, "gen_rate": 7.3, "speed": 2.16, "text": "\"\\nIn minecraft, what are the be"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 91, "tree_size": 256, "t0": 1.7833, "t1": 0.65, "tft": 4.7305, "input_0": 529, "input_1": 257, "min_CLP": -7.06, "draft_iters": 8.7, "mem_use": 35.07, "gen_rate": 5.5, "speed": 2.26, "text": "\\nThe Norse Goddess Freyja is th"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 16.4, "tree_w": 78, "tree_size": 256, "t0": 2.5943, "t1": 0.6714, "tft": 5.7472, "input_0": 489, "input_1": 257, "min_CLP": -6.86, "draft_iters": 17.3, "mem_use": 35.72, "gen_rate": 4.4, "speed": 1.36, "text": "\\nSubmit your program for consid"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.4, "tree_w": 59, "tree_size": 256, "t0": 2.35, "t1": 0.658, "tft": 4.1694, "input_0": 577, "input_1": 257, "min_CLP": -6.73, "draft_iters": 14.4, "mem_use": 35.3, "gen_rate": 6.6, "speed": 2.19, "text": "\"# Add Tailwind CSS to the proje"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.6, "tree_w": 78, "tree_size": 256, "t0": 2.1586, "t1": 0.76, "tft": 6.8334, "input_0": 503, "input_1": 257, "min_CLP": -7.19, "draft_iters": 10.6, "mem_use": 37.86, "gen_rate": 4.6, "speed": 1.57, "text": "Sexual selection is generally th"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.2, "tree_w": 108, "tree_size": 256, "t0": 1.5, "t1": 0.66, "tft": 2.3689, "input_0": 417, "input_1": 257, "min_CLP": -7.1, "draft_iters": 7.4, "mem_use": 35.5, "gen_rate": 4.0, "speed": 1.85, "text": "I am a very complex system, and "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 70, "tree_size": 256, "t0": 2.1825, "t1": 0.6525, "tft": 3.0128, "input_0": 597, "input_1": 257, "min_CLP": -7.53, "draft_iters": 11.8, "mem_use": 35.12, "gen_rate": 9.5, "speed": 3.35, "text": "\\n1. What is the difference betw"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 4.87, "t1": 0.66, "tft": 4.8917, "input_0": 931, "input_1": 257, "min_CLP": -8.46, "draft_iters": 32.0, "mem_use": 35.21, "gen_rate": 33.0, "speed": 5.97, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 5.01, "t1": 0.69, "tft": 5.9879, "input_0": 921, "input_1": 257, "min_CLP": -7.1, "draft_iters": 32.0, "mem_use": 35.99, "gen_rate": 33.0, "speed": 5.8, "text": "\\nHow to code the snake game in "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.0, "tree_w": 64, "tree_size": 256, "t0": 2.316, "t1": 0.652, "tft": 3.3771, "input_0": 566, "input_1": 257, "min_CLP": -6.69, "draft_iters": 13.0, "mem_use": 35.2, "gen_rate": 8.6, "speed": 2.9, "text": "\"Yes, and I have been programmed"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.7, "tree_w": 80, "tree_size": 256, "t0": 1.91, "t1": 0.6529, "tft": 4.8843, "input_0": 476, "input_1": 257, "min_CLP": -6.87, "draft_iters": 10.9, "mem_use": 35.16, "gen_rate": 5.3, "speed": 2.06, "text": "\"\\nIf you like this challenge, p"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 28, "tree_size": 256, "t0": 4.65, "t1": 0.655, "tft": 4.7171, "input_0": 854, "input_1": 257, "min_CLP": -6.81, "draft_iters": 32.0, "mem_use": 35.06, "gen_rate": 31.5, "speed": 5.94, "text": "\\nwhat is the color of mars [\\\\I"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 39, "tree_size": 256, "t0": 4.39, "t1": 0.7, "tft": 6.8501, "input_0": 580, "input_1": 257, "min_CLP": -7.08, "draft_iters": 32.0, "mem_use": 36.23, "gen_rate": 33.0, "speed": 6.48, "text": "Here is list of words related to"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 64, "tree_size": 256, "t0": 3.79, "t1": 0.65, "tft": 2.9405, "input_0": 511, "input_1": 257, "min_CLP": -7.0, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 7.43, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 22.5, "tree_w": 57, "tree_size": 256, "t0": 3.6, "t1": 0.66, "tft": 3.349, "input_0": 747, "input_1": 257, "min_CLP": -7.0, "draft_iters": 23.0, "mem_use": 35.39, "gen_rate": 21.5, "speed": 5.05, "text": "Yes.\\n<</SYS>\\n\\n[INST] <<SYS>>\\"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 79, "tree_size": 256, "t0": 2.048, "t1": 0.65, "tft": 3.5705, "input_0": 491, "input_1": 257, "min_CLP": -6.91, "draft_iters": 12.4, "mem_use": 35.12, "gen_rate": 7.0, "speed": 2.59, "text": "\\nWhat is the probability of a p"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 10.8, "tree_w": 84, "tree_size": 256, "t0": 2.0488, "t1": 0.66, "tft": 3.3395, "input_0": 511, "input_1": 257, "min_CLP": -6.98, "draft_iters": 11.6, "mem_use": 35.32, "gen_rate": 4.5, "speed": 1.66, "text": "\\nYou will be paid $3.00 per hou"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 14.8, "tree_w": 54, "tree_size": 256, "t0": 2.7675, "t1": 0.6525, "tft": 2.8506, "input_0": 701, "input_1": 257, "min_CLP": -6.45, "draft_iters": 15.8, "mem_use": 35.16, "gen_rate": 10.8, "speed": 3.14, "text": "Melbourne was the capital of the"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 18.5, "tree_w": 51, "tree_size": 256, "t0": 3.1025, "t1": 0.655, "tft": 3.902, "input_0": 699, "input_1": 257, "min_CLP": -6.61, "draft_iters": 19.5, "mem_use": 35.26, "gen_rate": 13.8, "speed": 3.66, "text": "[INST] My name is [\\\\INST]\\n[INS"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 92, "tree_size": 256, "t0": 1.6886, "t1": 0.7, "tft": 7.1228, "input_0": 465, "input_1": 257, "min_CLP": -6.84, "draft_iters": 8.1, "mem_use": 36.4, "gen_rate": 5.1, "speed": 2.15, "text": "\\nI am excited about this projec"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 108, "tree_size": 256, "t0": 3.67, "t1": 0.65, "tft": 4.1082, "input_0": 412, "input_1": 257, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 35.16, "gen_rate": 33.0, "speed": 7.64, "text": "\\n[INST] <<SYS>>\\nI heard someth"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 18.0, "tree_w": 51, "tree_size": 256, "t0": 3.02, "t1": 0.68, "tft": 5.2036, "input_0": 656, "input_1": 257, "min_CLP": -6.48, "draft_iters": 19.0, "mem_use": 35.82, "gen_rate": 14.0, "speed": 3.78, "text": "Yes, the normalize vector can co"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 105, "tree_size": 256, "t0": 1.5714, "t1": 0.65, "tft": 2.7999, "input_0": 444, "input_1": 257, "min_CLP": -7.31, "draft_iters": 8.0, "mem_use": 35.1, "gen_rate": 4.6, "speed": 2.05, "text": "\\nWhy is it that the uniform dis"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 256, "t0": 4.92, "t1": 0.65, "tft": 4.7929, "input_0": 921, "input_1": 257, "min_CLP": -7.82, "draft_iters": 32.0, "mem_use": 35.14, "gen_rate": 33.0, "speed": 5.92, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 12.0, "tree_w": 85, "tree_size": 256, "t0": 2.2517, "t1": 0.65, "tft": 2.8473, "input_0": 537, "input_1": 257, "min_CLP": -6.84, "draft_iters": 13.3, "mem_use": 35.11, "gen_rate": 7.0, "speed": 2.41, "text": "\\nIf you are trying to solve a p"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 16.2, "tree_w": 51, "tree_size": 256, "t0": 2.822, "t1": 0.662, "tft": 2.9993, "input_0": 648, "input_1": 257, "min_CLP": -6.52, "draft_iters": 17.0, "mem_use": 35.4, "gen_rate": 12.0, "speed": 3.44, "text": "No, the sum of squares error is "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 28.5, "tree_w": 30, "tree_size": 256, "t0": 4.22, "t1": 0.665, "tft": 3.7191, "input_0": 715, "input_1": 257, "min_CLP": -6.99, "draft_iters": 29.0, "mem_use": 35.54, "gen_rate": 20.5, "speed": 4.2, "text": "\\n<<SYS>\\nYou are a helpful, res"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.5, "tree_w": 74, "tree_size": 256, "t0": 1.91, "t1": 0.66, "tft": 2.9989, "input_0": 550, "input_1": 257, "min_CLP": -6.72, "draft_iters": 9.7, "mem_use": 35.42, "gen_rate": 6.3, "speed": 2.46, "text": "The best starry sky you can see "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 56, "tree_size": 256, "t0": 3.87, "t1": 0.65, "tft": 4.6369, "input_0": 581, "input_1": 257, "min_CLP": -7.04, "draft_iters": 32.0, "mem_use": 35.1, "gen_rate": 33.0, "speed": 7.3, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 41, "tree_size": 256, "t0": 4.31, "t1": 0.66, "tft": 2.6616, "input_0": 590, "input_1": 257, "min_CLP": -6.75, "draft_iters": 32.0, "mem_use": 35.35, "gen_rate": 33.0, "speed": 6.64, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 66, "tree_size": 256, "t0": 2.535, "t1": 0.6575, "tft": 3.0351, "input_0": 688, "input_1": 257, "min_CLP": -7.05, "draft_iters": 13.2, "mem_use": 35.31, "gen_rate": 8.2, "speed": 2.58, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.1, "tree_w": 85, "tree_size": 256, "t0": 2.0325, "t1": 0.72, "tft": 7.6818, "input_0": 540, "input_1": 257, "min_CLP": -6.78, "draft_iters": 9.5, "mem_use": 36.9, "gen_rate": 4.2, "speed": 1.54, "text": "Thank you for your question.\\n\\n"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.1, "tree_w": 63, "tree_size": 256, "t0": 2.1714, "t1": 0.6986, "tft": 6.6528, "input_0": 586, "input_1": 257, "min_CLP": -6.32, "draft_iters": 10.6, "mem_use": 36.23, "gen_rate": 5.0, "speed": 1.74, "text": "\"Buying a pre-built PC is someti"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.4, "tree_w": 73, "tree_size": 256, "t0": 2.158, "t1": 0.65, "tft": 4.6171, "input_0": 523, "input_1": 257, "min_CLP": -6.87, "draft_iters": 12.4, "mem_use": 35.07, "gen_rate": 8.2, "speed": 2.92, "text": "\\nThe Christmas tree is decorate"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 256, "t0": 4.81, "t1": 0.65, "tft": 4.8412, "input_0": 1131, "input_1": 257, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 35.21, "gen_rate": 33.0, "speed": 6.04, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 90, "tree_size": 256, "t0": 2.2617, "t1": 0.8433, "tft": 12.6739, "input_0": 437, "input_1": 257, "min_CLP": -6.77, "draft_iters": 10.5, "mem_use": 39.98, "gen_rate": 5.3, "speed": 1.72, "text": "The _physics_process function is"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.8, "tree_w": 63, "tree_size": 256, "t0": 2.1233, "t1": 0.66, "tft": 3.3376, "input_0": 568, "input_1": 257, "min_CLP": -6.62, "draft_iters": 11.2, "mem_use": 36.54, "gen_rate": 5.5, "speed": 1.98, "text": "You can use a decorator within a"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 18.8, "tree_w": 85, "tree_size": 256, "t0": 2.822, "t1": 0.65, "tft": 3.8762, "input_0": 520, "input_1": 257, "min_CLP": -6.88, "draft_iters": 19.6, "mem_use": 35.14, "gen_rate": 7.2, "speed": 2.07, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.3, "tree_w": 82, "tree_size": 256, "t0": 2.11, "t1": 0.65, "tft": 4.4639, "input_0": 501, "input_1": 257, "min_CLP": -7.12, "draft_iters": 12.5, "mem_use": 35.13, "gen_rate": 6.3, "speed": 2.29, "text": "\\nWhat is the statute in Wyoming"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 11, "tree_size": 256, "t0": 5.77, "t1": 0.71, "tft": 5.5426, "input_0": 1274, "input_1": 257, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 36.45, "gen_rate": 32.0, "speed": 4.94, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 13.8, "tree_w": 50, "tree_size": 256, "t0": 3.1925, "t1": 0.66, "tft": 3.3499, "input_0": 910, "input_1": 257, "min_CLP": -6.58, "draft_iters": 15.2, "mem_use": 35.37, "gen_rate": 10.5, "speed": 2.72, "text": "Yes, there are many in the UK, i"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 20.2, "tree_w": 40, "tree_size": 256, "t0": 3.2875, "t1": 0.66, "tft": 3.2374, "input_0": 711, "input_1": 257, "min_CLP": -6.61, "draft_iters": 21.0, "mem_use": 35.44, "gen_rate": 8.0, "speed": 2.02, "text": "\\nWhat is the airspeed velocity "}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 26.5, "tree_w": 61, "tree_size": 256, "t0": 3.615, "t1": 0.6525, "tft": 3.2337, "input_0": 640, "input_1": 257, "min_CLP": -6.97, "draft_iters": 27.0, "mem_use": 35.26, "gen_rate": 9.0, "speed": 2.11, "text": "\\n[INST] <<SYS>>\\nWhat are the a"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 36, "tree_size": 256, "t0": 5.81, "t1": 0.66, "tft": 3.7807, "input_0": 1305, "input_1": 257, "min_CLP": -7.26, "draft_iters": 32.0, "mem_use": 35.42, "gen_rate": 33.0, "speed": 5.1, "text": "Attention bias shines,\\nFocusing"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 79, "tree_size": 256, "t0": 2.0871, "t1": 0.6543, "tft": 2.6841, "input_0": 579, "input_1": 257, "min_CLP": -6.87, "draft_iters": 10.7, "mem_use": 35.26, "gen_rate": 5.0, "speed": 1.82, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 98, "tree_size": 256, "t0": 1.81, "t1": 0.6986, "tft": 5.7502, "input_0": 482, "input_1": 257, "min_CLP": -6.84, "draft_iters": 9.1, "mem_use": 36.25, "gen_rate": 4.7, "speed": 1.88, "text": "\"I'd recommend setting up a BRAT"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 24.0, "tree_w": 34, "tree_size": 256, "t0": 3.965, "t1": 0.65, "tft": 3.8952, "input_0": 894, "input_1": 257, "min_CLP": -6.24, "draft_iters": 25.0, "mem_use": 35.14, "gen_rate": 10.0, "speed": 2.17, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 15.3, "tree_w": 45, "tree_size": 256, "t0": 2.71, "t1": 0.65, "tft": 3.2398, "input_0": 641, "input_1": 257, "min_CLP": -6.38, "draft_iters": 16.3, "mem_use": 35.15, "gen_rate": 6.5, "speed": 1.93, "text": "I can speak Spanish.\\n[INST] can"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 62, "tree_h": 24.5, "tree_w": 61, "tree_size": 256, "t0": 3.67, "t1": 0.655, "tft": 3.02, "input_0": 726, "input_1": 257, "min_CLP": -7.59, "draft_iters": 25.0, "mem_use": 35.12, "gen_rate": 15.5, "speed": 3.58, "text": "\\nWhat are F-centers in crystall"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 70, "tree_size": 256, "t0": 3.0033, "t1": 0.77, "tft": 10.0362, "input_0": 529, "input_1": 257, "min_CLP": -6.83, "draft_iters": 17.7, "mem_use": 38.08, "gen_rate": 12.0, "speed": 3.18, "text": "Yes, it is. You are most welcome"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 54, "tree_size": 256, "t0": 4.58, "t1": 0.69, "tft": 4.47, "input_0": 771, "input_1": 257, "min_CLP": -6.9, "draft_iters": 32.0, "mem_use": 35.98, "gen_rate": 33.0, "speed": 6.27, "text": "\\nWhat is the meaning of life? ["}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 84, "tree_size": 256, "t0": 1.7417, "t1": 0.6583, "tft": 2.8273, "input_0": 501, "input_1": 257, "min_CLP": -6.8, "draft_iters": 8.2, "mem_use": 35.36, "gen_rate": 5.7, "speed": 2.36, "text": "Yes, I think AI assistants will "}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 65, "tree_size": 256, "t0": 2.338, "t1": 0.7, "tft": 5.1566, "input_0": 622, "input_1": 257, "min_CLP": -6.59, "draft_iters": 12.0, "mem_use": 36.31, "gen_rate": 6.8, "speed": 2.24, "text": "You can breed animals in Minecra"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 18.8, "tree_w": 56, "tree_size": 256, "t0": 3.225, "t1": 0.7125, "tft": 7.3756, "input_0": 690, "input_1": 257, "min_CLP": -6.47, "draft_iters": 19.5, "mem_use": 36.67, "gen_rate": 12.0, "speed": 3.05, "text": "[INST] Wie viel Treibhausgas ent"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.1, "tree_w": 72, "tree_size": 256, "t0": 2.1129, "t1": 0.6886, "tft": 5.5403, "input_0": 513, "input_1": 257, "min_CLP": -6.6, "draft_iters": 11.4, "mem_use": 36.09, "gen_rate": 5.1, "speed": 1.84, "text": "\"You may not use the Roblox Luau"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 66, "tree_size": 256, "t0": 1.9557, "t1": 0.6629, "tft": 3.3404, "input_0": 504, "input_1": 257, "min_CLP": -6.63, "draft_iters": 10.6, "mem_use": 35.48, "gen_rate": 4.9, "speed": 1.85, "text": "\"If you found and item in public"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 50, "tree_size": 256, "t0": 4.505, "t1": 0.67, "tft": 3.5981, "input_0": 802, "input_1": 257, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 35.6, "gen_rate": 32.0, "speed": 6.18, "text": "\\n\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\\\"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 21.3, "tree_w": 79, "tree_size": 256, "t0": 3.2967, "t1": 0.6533, "tft": 4.8964, "input_0": 651, "input_1": 257, "min_CLP": -7.11, "draft_iters": 22.0, "mem_use": 35.15, "gen_rate": 13.7, "speed": 3.46, "text": "\\nI need to create a function in"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 41, "tree_size": 256, "t0": 4.52, "t1": 0.68, "tft": 5.5656, "input_0": 797, "input_1": 257, "min_CLP": -6.2, "draft_iters": 32.0, "mem_use": 35.79, "gen_rate": 33.0, "speed": 6.35, "text": "\\nThe definition of what constit"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.4, "tree_w": 88, "tree_size": 256, "t0": 1.76, "t1": 0.6588, "tft": 4.0116, "input_0": 502, "input_1": 257, "min_CLP": -6.8, "draft_iters": 8.5, "mem_use": 35.38, "gen_rate": 4.2, "speed": 1.76, "text": "\"I have a long-distance relation"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 57, "tree_size": 256, "t0": 2.5825, "t1": 0.68, "tft": 3.9048, "input_0": 711, "input_1": 257, "min_CLP": -6.54, "draft_iters": 12.2, "mem_use": 35.81, "gen_rate": 8.2, "speed": 2.53, "text": "There is no optimal mayonnaise t"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 4.31, "t1": 0.66, "tft": 4.8787, "input_0": 690, "input_1": 257, "min_CLP": -6.52, "draft_iters": 32.0, "mem_use": 35.49, "gen_rate": 33.0, "speed": 6.63, "text": "\\nThe answer would depend on the"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 6.5, "tree_w": 98, "tree_size": 256, "t0": 1.5609, "t1": 0.65, "tft": 3.9253, "input_0": 440, "input_1": 257, "min_CLP": -7.8, "draft_iters": 7.9, "mem_use": 35.14, "gen_rate": 3.3, "speed": 1.48, "text": "\\nCuidado! N\u00e3o usem os nicks de:"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 73, "tree_size": 256, "t0": 2.068, "t1": 0.658, "tft": 4.8572, "input_0": 518, "input_1": 257, "min_CLP": -6.7, "draft_iters": 11.4, "mem_use": 35.31, "gen_rate": 7.2, "speed": 2.64, "text": "\"The declaration's significance "}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 5.41, "t1": 0.68, "tft": 7.1752, "input_0": 1167, "input_1": 257, "min_CLP": -6.34, "draft_iters": 32.0, "mem_use": 35.89, "gen_rate": 30.5, "speed": 5.01, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 45, "tree_size": 256, "t0": 4.29, "t1": 0.65, "tft": 4.8071, "input_0": 667, "input_1": 257, "min_CLP": -7.66, "draft_iters": 32.0, "mem_use": 35.16, "gen_rate": 33.0, "speed": 6.68, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 11.0, "tree_w": 55, "tree_size": 256, "t0": 2.26, "t1": 0.66, "tft": 4.7896, "input_0": 617, "input_1": 257, "min_CLP": -6.27, "draft_iters": 12.0, "mem_use": 35.42, "gen_rate": 3.0, "speed": 1.03, "text": "\"I'll fix it later.\""}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.5, "tree_w": 45, "tree_size": 256, "t0": 3.075, "t1": 0.67, "tft": 2.9911, "input_0": 734, "input_1": 257, "min_CLP": -6.75, "draft_iters": 18.5, "mem_use": 35.61, "gen_rate": 17.0, "speed": 4.54, "text": "Hmm. How about, \"A wish from the"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 12.2, "tree_w": 80, "tree_size": 256, "t0": 2.195, "t1": 0.6837, "tft": 6.2372, "input_0": 478, "input_1": 257, "min_CLP": -6.87, "draft_iters": 13.2, "mem_use": 36.0, "gen_rate": 5.8, "speed": 2.0, "text": "\\nReply to this question to rece"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.6, "tree_w": 53, "tree_size": 256, "t0": 2.512, "t1": 0.65, "tft": 3.4467, "input_0": 583, "input_1": 257, "min_CLP": -6.62, "draft_iters": 15.6, "mem_use": 35.16, "gen_rate": 6.8, "speed": 2.15, "text": "He is a Social Democrat.\\n[INST]"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 62, "tree_size": 256, "t0": 3.93, "t1": 0.65, "tft": 2.9388, "input_0": 588, "input_1": 257, "min_CLP": -7.16, "draft_iters": 32.0, "mem_use": 35.14, "gen_rate": 33.0, "speed": 7.2, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 66, "tree_size": 256, "t0": 2.152, "t1": 0.736, "tft": 5.6762, "input_0": 521, "input_1": 257, "min_CLP": -6.8, "draft_iters": 11.2, "mem_use": 37.19, "gen_rate": 7.0, "speed": 2.42, "text": "\\nHere is a list of possible ste"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 56, "tree_size": 256, "t0": 3.89, "t1": 0.65, "tft": 3.7389, "input_0": 580, "input_1": 257, "min_CLP": -6.89, "draft_iters": 32.0, "mem_use": 35.2, "gen_rate": 33.0, "speed": 7.27, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 72, "tree_size": 256, "t0": 1.992, "t1": 0.65, "tft": 4.6531, "input_0": 551, "input_1": 257, "min_CLP": -6.71, "draft_iters": 10.2, "mem_use": 35.07, "gen_rate": 6.8, "speed": 2.57, "text": "Steps\\n1. Find a PC that you lik"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 94, "tree_size": 256, "t0": 1.6887, "t1": 0.75, "tft": 9.1753, "input_0": 433, "input_1": 257, "min_CLP": -6.98, "draft_iters": 7.8, "mem_use": 37.64, "gen_rate": 4.2, "speed": 1.74, "text": "\\nI need a chatbot to communicat"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 23.3, "tree_w": 48, "tree_size": 256, "t0": 3.7967, "t1": 0.69, "tft": 4.2939, "input_0": 737, "input_1": 257, "min_CLP": -6.48, "draft_iters": 24.0, "mem_use": 36.11, "gen_rate": 11.0, "speed": 2.45, "text": "\u2022 Keep track of your progress. K"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.6, "tree_w": 79, "tree_size": 256, "t0": 1.84, "t1": 0.6743, "tft": 3.2484, "input_0": 522, "input_1": 257, "min_CLP": -6.67, "draft_iters": 9.6, "mem_use": 35.72, "gen_rate": 5.4, "speed": 2.16, "text": "\"\\nBecause you don't know how ma"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.0, "tree_w": 75, "tree_size": 256, "t0": 2.2583, "t1": 0.6517, "tft": 2.9709, "input_0": 543, "input_1": 257, "min_CLP": -7.07, "draft_iters": 13.3, "mem_use": 35.16, "gen_rate": 6.0, "speed": 2.06, "text": "The most important historical ev"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.9, "tree_w": 83, "tree_size": 256, "t0": 2.3171, "t1": 0.6529, "tft": 3.9281, "input_0": 519, "input_1": 257, "min_CLP": -7.11, "draft_iters": 14.7, "mem_use": 35.18, "gen_rate": 5.0, "speed": 1.68, "text": "\\nINFORMATION IS THE KEY TO ALL "}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.7, "tree_w": 38, "tree_size": 256, "t0": 4.27, "t1": 0.67, "tft": 4.2708, "input_0": 1007, "input_1": 257, "min_CLP": -6.53, "draft_iters": 22.7, "mem_use": 35.64, "gen_rate": 15.7, "speed": 3.17, "text": "\"[INST] What's the weather like?"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 58, "tree_h": 20.0, "tree_w": 56, "tree_size": 256, "t0": 3.3325, "t1": 0.6925, "tft": 6.4401, "input_0": 667, "input_1": 257, "min_CLP": -6.64, "draft_iters": 20.5, "mem_use": 36.18, "gen_rate": 14.5, "speed": 3.6, "text": "Yes.\\n\\nAn easier script is this"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 77, "tree_size": 256, "t0": 1.8583, "t1": 0.67, "tft": 5.1656, "input_0": 493, "input_1": 257, "min_CLP": -6.76, "draft_iters": 9.7, "mem_use": 35.56, "gen_rate": 5.5, "speed": 2.18, "text": "\\nI am a [\\\\INST] who wants to b"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 51, "tree_size": 256, "t0": 4.35, "t1": 0.67, "tft": 5.7282, "input_0": 631, "input_1": 257, "min_CLP": -7.33, "draft_iters": 32.0, "mem_use": 35.65, "gen_rate": 33.0, "speed": 6.57, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 19.0, "tree_w": 53, "tree_size": 256, "t0": 3.25, "t1": 0.66, "tft": 3.1662, "input_0": 747, "input_1": 257, "min_CLP": -6.56, "draft_iters": 20.2, "mem_use": 35.31, "gen_rate": 10.5, "speed": 2.69, "text": "That would depend on the species"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 70, "tree_size": 256, "t0": 1.8383, "t1": 0.6583, "tft": 3.1772, "input_0": 527, "input_1": 257, "min_CLP": -6.53, "draft_iters": 8.5, "mem_use": 35.31, "gen_rate": 5.3, "speed": 2.14, "text": "Tenants are superior to their la"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 15.5, "tree_w": 64, "tree_size": 256, "t0": 2.7783, "t1": 0.6867, "tft": 5.125, "input_0": 612, "input_1": 257, "min_CLP": -6.59, "draft_iters": 16.7, "mem_use": 36.0, "gen_rate": 8.7, "speed": 2.5, "text": "\\nIf it fails, then you can try "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.0, "tree_w": 89, "tree_size": 256, "t0": 1.8256, "t1": 0.6856, "tft": 4.1749, "input_0": 503, "input_1": 257, "min_CLP": -6.86, "draft_iters": 8.4, "mem_use": 35.94, "gen_rate": 4.1, "speed": 1.64, "text": "Yes, Open Assistant is trained u"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 17.7, "tree_w": 75, "tree_size": 256, "t0": 2.8767, "t1": 0.71, "tft": 6.8725, "input_0": 511, "input_1": 257, "min_CLP": -6.77, "draft_iters": 18.5, "mem_use": 36.67, "gen_rate": 7.2, "speed": 2.0, "text": "\"[INST] Oh, yeah, and don't forg"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.6, "tree_w": 75, "tree_size": 256, "t0": 2.1643, "t1": 0.65, "tft": 4.6355, "input_0": 514, "input_1": 257, "min_CLP": -7.05, "draft_iters": 12.6, "mem_use": 35.06, "gen_rate": 5.0, "speed": 1.77, "text": "\"\\nThe President of Germany is A"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.5, "tree_w": 52, "tree_size": 256, "t0": 3.2275, "t1": 0.67, "tft": 3.9363, "input_0": 769, "input_1": 257, "min_CLP": -6.61, "draft_iters": 19.0, "mem_use": 35.58, "gen_rate": 9.5, "speed": 2.44, "text": "PostCSS is a tool that converts "}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 54, "tree_h": 18.8, "tree_w": 60, "tree_size": 256, "t0": 3.3725, "t1": 0.71, "tft": 6.9887, "input_0": 686, "input_1": 257, "min_CLP": -6.99, "draft_iters": 20.0, "mem_use": 36.54, "gen_rate": 13.5, "speed": 3.31, "text": "I have a question about the proo"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.3, "tree_w": 95, "tree_size": 256, "t0": 1.89, "t1": 0.6586, "tft": 4.3246, "input_0": 512, "input_1": 257, "min_CLP": -7.32, "draft_iters": 9.4, "mem_use": 35.31, "gen_rate": 5.6, "speed": 2.19, "text": "\"\\nIn the future, we'll have AI "}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 48, "tree_size": 256, "t0": 4.56, "t1": 0.68, "tft": 5.4794, "input_0": 810, "input_1": 257, "min_CLP": -7.23, "draft_iters": 32.0, "mem_use": 35.76, "gen_rate": 33.0, "speed": 6.31, "text": "\\nThe static still state, also k"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 256, "max_branch_width": 32, "gen_rate": 12.43, "gen_rate_micro": 7.78, "gen_speed": 3.108, "gen_speed_micro": 2.573, "t0": 2.8477, "t1": 0.6707, "input_0": 621.7, "input_1": 257.0, "tree_size": 256.0, "tree_w": 64.2, "tree_h": 16.6, "prompt_len": 320.7, "min_CLP": -6.85, "mem_use": 39.99, "exp_time": 10215.11}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.4, "tree_w": 270, "tree_size": 512, "t0": 1.3489, "t1": 0.78, "tft": 2.7794, "input_0": 822, "input_1": 513, "min_CLP": -8.36, "draft_iters": 5.6, "mem_use": 35.66, "gen_rate": 3.7, "speed": 1.72, "text": "\\nA Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.6, "tree_w": 230, "tree_size": 512, "t0": 2.178, "t1": 0.81, "tft": 3.8642, "input_0": 1148, "input_1": 513, "min_CLP": -8.32, "draft_iters": 9.0, "mem_use": 36.39, "gen_rate": 6.6, "speed": 2.21, "text": "\\nHow long is the average life e"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 264, "tree_size": 512, "t0": 1.24, "t1": 0.8325, "tft": 4.3422, "input_0": 784, "input_1": 513, "min_CLP": -8.23, "draft_iters": 5.0, "mem_use": 36.75, "gen_rate": 4.0, "speed": 1.93, "text": "\"I can't recommend any specific "}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 168, "tree_size": 512, "t0": 3.385, "t1": 0.785, "tft": 2.8312, "input_0": 1172, "input_1": 513, "min_CLP": -8.69, "draft_iters": 18.5, "mem_use": 35.74, "gen_rate": 17.5, "speed": 4.2, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 248, "tree_size": 512, "t0": 1.965, "t1": 0.7783, "tft": 2.7798, "input_0": 1002, "input_1": 513, "min_CLP": -9.73, "draft_iters": 9.2, "mem_use": 35.65, "gen_rate": 8.5, "speed": 3.1, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.8, "tree_w": 250, "tree_size": 512, "t0": 1.8188, "t1": 0.8375, "tft": 4.5733, "input_0": 1006, "input_1": 513, "min_CLP": -9.29, "draft_iters": 7.9, "mem_use": 36.93, "gen_rate": 4.4, "speed": 1.65, "text": "\\n1. Define the concept of the g"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 46, "tree_h": 7.4, "tree_w": 240, "tree_size": 512, "t0": 2.2829, "t1": 0.85, "tft": 4.9148, "input_0": 1190, "input_1": 513, "min_CLP": -9.1, "draft_iters": 9.6, "mem_use": 37.25, "gen_rate": 6.6, "speed": 2.1, "text": "There are a variety of other met"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 233, "tree_size": 512, "t0": 2.1186, "t1": 0.9, "tft": 6.6171, "input_0": 1097, "input_1": 513, "min_CLP": -8.49, "draft_iters": 8.0, "mem_use": 38.35, "gen_rate": 4.6, "speed": 1.51, "text": "\"\\n* How did you get VC funding?"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 261, "tree_size": 512, "t0": 1.835, "t1": 0.84, "tft": 4.5766, "input_0": 962, "input_1": 513, "min_CLP": -8.63, "draft_iters": 7.8, "mem_use": 36.98, "gen_rate": 4.1, "speed": 1.54, "text": "\\nMarijuana is illegal in all 50"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.7, "tree_w": 274, "tree_size": 512, "t0": 1.5171, "t1": 0.83, "tft": 4.0838, "input_0": 893, "input_1": 513, "min_CLP": -8.28, "draft_iters": 5.9, "mem_use": 36.73, "gen_rate": 4.6, "speed": 1.95, "text": "\\nA hobby is a pastime, an activ"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 12.5, "tree_w": 192, "tree_size": 512, "t0": 2.765, "t1": 0.7933, "tft": 2.9784, "input_0": 1102, "input_1": 513, "min_CLP": -8.02, "draft_iters": 14.8, "mem_use": 35.98, "gen_rate": 8.5, "speed": 2.39, "text": "\\nYou are an excellent and kind "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 237, "tree_size": 512, "t0": 1.8125, "t1": 0.8662, "tft": 4.4068, "input_0": 932, "input_1": 513, "min_CLP": -8.11, "draft_iters": 7.6, "mem_use": 36.89, "gen_rate": 4.0, "speed": 1.49, "text": "I have summarised the book as fo"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 259, "tree_size": 512, "t0": 2.1157, "t1": 0.82, "tft": 3.906, "input_0": 1121, "input_1": 513, "min_CLP": -9.56, "draft_iters": 8.9, "mem_use": 36.54, "gen_rate": 8.0, "speed": 2.73, "text": "Certainly! Here is a python exam"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 3.3, "tree_w": 280, "tree_size": 512, "t0": 1.3233, "t1": 0.78, "tft": 2.7814, "input_0": 925, "input_1": 513, "min_CLP": -10.13, "draft_iters": 5.3, "mem_use": 35.63, "gen_rate": 3.3, "speed": 1.58, "text": "\"\\nAustralia's capital city is C"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.8, "tree_w": 266, "tree_size": 512, "t0": 1.5, "t1": 0.85, "tft": 4.9236, "input_0": 861, "input_1": 513, "min_CLP": -8.23, "draft_iters": 5.9, "mem_use": 37.25, "gen_rate": 4.2, "speed": 1.81, "text": "\\nSpaced repetition and fun acti"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.0, "tree_w": 253, "tree_size": 512, "t0": 1.47, "t1": 0.7875, "tft": 2.7668, "input_0": 848, "input_1": 513, "min_CLP": -8.34, "draft_iters": 6.1, "mem_use": 35.76, "gen_rate": 4.2, "speed": 1.88, "text": "\\nI have a 10mbps DL speed, so I"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.1, "tree_w": 240, "tree_size": 512, "t0": 1.7143, "t1": 0.7829, "tft": 2.7847, "input_0": 991, "input_1": 513, "min_CLP": -8.78, "draft_iters": 7.1, "mem_use": 35.66, "gen_rate": 4.9, "speed": 1.94, "text": "\\nWhat is the meaning of life? ["}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 9.0, "tree_w": 231, "tree_size": 512, "t0": 2.3262, "t1": 0.7825, "tft": 2.7846, "input_0": 1083, "input_1": 513, "min_CLP": -8.66, "draft_iters": 11.1, "mem_use": 35.66, "gen_rate": 7.4, "speed": 2.37, "text": "\\nHello world in Java\\n\\n\u00a1Hola w"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 62, "tree_h": 6.8, "tree_w": 255, "tree_size": 512, "t0": 1.96, "t1": 0.7937, "tft": 2.9598, "input_0": 1114, "input_1": 513, "min_CLP": -9.5, "draft_iters": 8.8, "mem_use": 35.97, "gen_rate": 7.8, "speed": 2.82, "text": "\"D-theanine is the form found in"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.3, "tree_w": 276, "tree_size": 512, "t0": 1.59, "t1": 0.78, "tft": 2.7778, "input_0": 1038, "input_1": 513, "min_CLP": -8.7, "draft_iters": 6.4, "mem_use": 35.66, "gen_rate": 4.6, "speed": 1.93, "text": "\\nThe Balfour Declaration is a l"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 232, "tree_size": 512, "t0": 2.7, "t1": 0.7975, "tft": 3.5235, "input_0": 1222, "input_1": 513, "min_CLP": -10.15, "draft_iters": 11.8, "mem_use": 36.11, "gen_rate": 10.8, "speed": 3.07, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 247, "tree_size": 512, "t0": 1.9062, "t1": 0.7788, "tft": 2.2018, "input_0": 989, "input_1": 513, "min_CLP": -10.2, "draft_iters": 8.4, "mem_use": 35.65, "gen_rate": 7.4, "speed": 2.75, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.9, "tree_w": 267, "tree_size": 512, "t0": 1.4975, "t1": 0.8375, "tft": 4.4132, "input_0": 918, "input_1": 513, "min_CLP": -10.59, "draft_iters": 6.0, "mem_use": 36.88, "gen_rate": 4.2, "speed": 1.82, "text": "The asymmetric bimodal distribut"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.6, "tree_w": 239, "tree_size": 512, "t0": 1.8714, "t1": 0.78, "tft": 2.7906, "input_0": 933, "input_1": 513, "min_CLP": -8.27, "draft_iters": 8.9, "mem_use": 35.66, "gen_rate": 5.4, "speed": 2.04, "text": "\\nPlease describe any security m"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 6.8, "tree_w": 252, "tree_size": 512, "t0": 2.0317, "t1": 0.8, "tft": 3.5777, "input_0": 982, "input_1": 513, "min_CLP": -9.37, "draft_iters": 9.0, "mem_use": 36.2, "gen_rate": 7.3, "speed": 2.59, "text": "\\nfor a full run, {your command}"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.2, "tree_w": 220, "tree_size": 512, "t0": 2.4433, "t1": 0.7817, "tft": 2.7914, "input_0": 1020, "input_1": 513, "min_CLP": -8.76, "draft_iters": 13.3, "mem_use": 35.66, "gen_rate": 5.5, "speed": 1.71, "text": "\"\\nWhat are some of Nietzsche's "}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 311, "tree_size": 512, "t0": 1.255, "t1": 0.7987, "tft": 2.9861, "input_0": 887, "input_1": 513, "min_CLP": -8.92, "draft_iters": 5.1, "mem_use": 36.02, "gen_rate": 4.0, "speed": 1.95, "text": "Austenite steel is a type of sta"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.0, "tree_w": 281, "tree_size": 512, "t0": 1.2144, "t1": 0.7933, "tft": 2.9449, "input_0": 782, "input_1": 513, "min_CLP": -8.74, "draft_iters": 5.0, "mem_use": 35.93, "gen_rate": 3.6, "speed": 1.77, "text": "\\nPlease create a new organizati"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 231, "tree_size": 512, "t0": 2.47, "t1": 0.8375, "tft": 4.3983, "input_0": 1118, "input_1": 513, "min_CLP": -9.1, "draft_iters": 11.5, "mem_use": 36.88, "gen_rate": 10.8, "speed": 3.25, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.0, "tree_w": 253, "tree_size": 512, "t0": 1.4278, "t1": 0.7811, "tft": 2.784, "input_0": 832, "input_1": 513, "min_CLP": -9.43, "draft_iters": 6.1, "mem_use": 35.66, "gen_rate": 3.7, "speed": 1.66, "text": "\\nWhat are some ways to trick pe"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.4, "tree_w": 258, "tree_size": 512, "t0": 1.5012, "t1": 0.8, "tft": 3.5499, "input_0": 905, "input_1": 513, "min_CLP": -8.67, "draft_iters": 6.5, "mem_use": 36.0, "gen_rate": 4.1, "speed": 1.8, "text": "No, Into the Breach is not a gam"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 224, "tree_size": 512, "t0": 2.7, "t1": 0.8, "tft": 3.5642, "input_0": 1198, "input_1": 513, "min_CLP": -9.64, "draft_iters": 11.8, "mem_use": 36.27, "gen_rate": 10.8, "speed": 3.07, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.4, "tree_w": 237, "tree_size": 512, "t0": 1.75, "t1": 0.79, "tft": 2.8658, "input_0": 969, "input_1": 513, "min_CLP": -8.22, "draft_iters": 7.7, "mem_use": 35.9, "gen_rate": 3.9, "speed": 1.53, "text": "\"\\nThe Greek Goddess Artemis see"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.3, "tree_w": 233, "tree_size": 512, "t0": 1.8514, "t1": 0.8314, "tft": 4.1161, "input_0": 1019, "input_1": 513, "min_CLP": -8.19, "draft_iters": 7.6, "mem_use": 36.74, "gen_rate": 5.3, "speed": 1.97, "text": "I understand your reluctance, an"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 265, "tree_size": 512, "t0": 1.5975, "t1": 0.825, "tft": 4.0496, "input_0": 954, "input_1": 513, "min_CLP": -8.1, "draft_iters": 6.8, "mem_use": 36.7, "gen_rate": 4.1, "speed": 1.7, "text": "\"It's impossible to make a blank"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 264, "tree_size": 512, "t0": 2.5383, "t1": 0.9, "tft": 6.6379, "input_0": 1218, "input_1": 513, "min_CLP": -10.3, "draft_iters": 9.7, "mem_use": 38.38, "gen_rate": 8.5, "speed": 2.47, "text": "Selenium is a more established a"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 202, "tree_size": 512, "t0": 3.09, "t1": 0.78, "tft": 2.7833, "input_0": 1054, "input_1": 513, "min_CLP": -8.5, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.52, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 288, "tree_size": 512, "t0": 1.2588, "t1": 0.7913, "tft": 2.9523, "input_0": 856, "input_1": 513, "min_CLP": -13.29, "draft_iters": 5.1, "mem_use": 35.93, "gen_rate": 4.1, "speed": 2.01, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.6, "tree_w": 255, "tree_size": 512, "t0": 1.4537, "t1": 0.8425, "tft": 4.6273, "input_0": 834, "input_1": 513, "min_CLP": -8.16, "draft_iters": 5.8, "mem_use": 37.1, "gen_rate": 4.1, "speed": 1.8, "text": "\\nHi,\\nI am an AI. I am a langua"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.8, "tree_w": 271, "tree_size": 512, "t0": 1.4425, "t1": 0.8, "tft": 3.5582, "input_0": 907, "input_1": 513, "min_CLP": -8.58, "draft_iters": 5.9, "mem_use": 36.12, "gen_rate": 4.2, "speed": 1.9, "text": "The Copenhagen interpretation of"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 7.4, "tree_w": 229, "tree_size": 512, "t0": 1.95, "t1": 0.784, "tft": 2.8348, "input_0": 916, "input_1": 513, "min_CLP": -8.76, "draft_iters": 9.6, "mem_use": 35.78, "gen_rate": 4.4, "speed": 1.61, "text": "[INST] I am here for your pleasu"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 274, "tree_size": 512, "t0": 1.255, "t1": 0.8375, "tft": 4.5857, "input_0": 790, "input_1": 513, "min_CLP": -8.56, "draft_iters": 5.0, "mem_use": 36.98, "gen_rate": 4.0, "speed": 1.91, "text": "\\nWrite a passage. It can be a j"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.6, "tree_w": 259, "tree_size": 512, "t0": 1.4787, "t1": 0.85, "tft": 4.9018, "input_0": 853, "input_1": 513, "min_CLP": -8.46, "draft_iters": 5.9, "mem_use": 37.23, "gen_rate": 4.0, "speed": 1.72, "text": "\\nAI assistant. I am looking for"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.3, "tree_w": 192, "tree_size": 512, "t0": 2.6333, "t1": 0.8167, "tft": 3.9168, "input_0": 1287, "input_1": 513, "min_CLP": -7.7, "draft_iters": 10.3, "mem_use": 36.45, "gen_rate": 6.3, "speed": 1.84, "text": "\"Unfortunately, I can't really a"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 3.0, "tree_w": 254, "tree_size": 512, "t0": 1.22, "t1": 0.8, "tft": 3.547, "input_0": 775, "input_1": 513, "min_CLP": -8.46, "draft_iters": 5.0, "mem_use": 36.04, "gen_rate": 0.0, "speed": 0.0, "text": "\"You're welcome!\""}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.0, "tree_w": 285, "tree_size": 512, "t0": 1.2056, "t1": 0.7922, "tft": 2.9416, "input_0": 799, "input_1": 513, "min_CLP": -10.41, "draft_iters": 5.0, "mem_use": 35.94, "gen_rate": 3.7, "speed": 1.84, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.9, "tree_w": 284, "tree_size": 512, "t0": 1.435, "t1": 0.7813, "tft": 2.7837, "input_0": 915, "input_1": 513, "min_CLP": -8.82, "draft_iters": 6.0, "mem_use": 35.66, "gen_rate": 4.2, "speed": 1.92, "text": "\\nChecking your system drive for"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.5, "tree_w": 228, "tree_size": 512, "t0": 2.1833, "t1": 0.9017, "tft": 6.8078, "input_0": 941, "input_1": 513, "min_CLP": -9.61, "draft_iters": 9.5, "mem_use": 38.4, "gen_rate": 8.3, "speed": 2.7, "text": "Zeus: I can try. The scene opens"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 249, "tree_size": 512, "t0": 1.9929, "t1": 0.82, "tft": 3.9176, "input_0": 944, "input_1": 513, "min_CLP": -8.16, "draft_iters": 9.7, "mem_use": 36.55, "gen_rate": 5.0, "speed": 1.78, "text": "Do you remember the first time y"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 276, "tree_size": 512, "t0": 1.2575, "t1": 0.8, "tft": 3.5531, "input_0": 842, "input_1": 513, "min_CLP": -8.31, "draft_iters": 5.1, "mem_use": 36.06, "gen_rate": 4.1, "speed": 2.01, "text": "\\nYour welcome. I do understand "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.1, "tree_w": 255, "tree_size": 512, "t0": 1.5643, "t1": 0.7986, "tft": 3.5299, "input_0": 960, "input_1": 513, "min_CLP": -8.28, "draft_iters": 6.3, "mem_use": 36.09, "gen_rate": 4.6, "speed": 1.94, "text": "However, it has been a difficult"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 255, "tree_size": 512, "t0": 2.0967, "t1": 0.8317, "tft": 4.3451, "input_0": 1006, "input_1": 513, "min_CLP": -10.0, "draft_iters": 9.5, "mem_use": 36.77, "gen_rate": 8.5, "speed": 2.9, "text": "F-centers are crystallographic d"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 268, "tree_size": 512, "t0": 1.7363, "t1": 0.8088, "tft": 3.56, "input_0": 991, "input_1": 513, "min_CLP": -8.68, "draft_iters": 8.1, "mem_use": 36.37, "gen_rate": 4.0, "speed": 1.57, "text": "\\nJanuary 31, 1776: The United S"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.6, "tree_w": 283, "tree_size": 512, "t0": 1.3862, "t1": 0.8175, "tft": 3.9125, "input_0": 897, "input_1": 513, "min_CLP": -8.61, "draft_iters": 5.6, "mem_use": 36.51, "gen_rate": 4.1, "speed": 1.87, "text": "\"Yes, technology can be used for"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 268, "tree_size": 512, "t0": 1.21, "t1": 0.7813, "tft": 2.8315, "input_0": 785, "input_1": 513, "min_CLP": -8.42, "draft_iters": 5.0, "mem_use": 35.77, "gen_rate": 4.0, "speed": 2.01, "text": "Short shorts are not really a th"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.6, "tree_w": 261, "tree_size": 512, "t0": 1.3775, "t1": 0.835, "tft": 4.38, "input_0": 840, "input_1": 513, "min_CLP": -8.67, "draft_iters": 5.6, "mem_use": 36.82, "gen_rate": 4.1, "speed": 1.86, "text": "Fullview.io is a social media ma"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 266, "tree_size": 512, "t0": 1.2778, "t1": 0.8633, "tft": 5.4757, "input_0": 784, "input_1": 513, "min_CLP": -8.15, "draft_iters": 5.0, "mem_use": 37.58, "gen_rate": 3.9, "speed": 1.82, "text": "\\nI think you are right. I also "}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.3, "tree_w": 185, "tree_size": 512, "t0": 3.0317, "t1": 0.87, "tft": 5.6969, "input_0": 1184, "input_1": 513, "min_CLP": -7.75, "draft_iters": 14.0, "mem_use": 37.76, "gen_rate": 6.2, "speed": 1.58, "text": "Since you are a beginner, you sh"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 7.7, "tree_w": 261, "tree_size": 512, "t0": 1.995, "t1": 0.82, "tft": 3.9036, "input_0": 1040, "input_1": 513, "min_CLP": -9.7, "draft_iters": 9.5, "mem_use": 36.5, "gen_rate": 7.2, "speed": 2.55, "text": "\"\\nChatGPT's ability to generate"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 249, "tree_size": 512, "t0": 1.9, "t1": 0.7817, "tft": 2.7849, "input_0": 951, "input_1": 513, "min_CLP": -8.23, "draft_iters": 9.7, "mem_use": 35.64, "gen_rate": 5.5, "speed": 2.05, "text": "\\n[INST] <<SYS>>\\nThe best way t"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 277, "tree_size": 512, "t0": 1.2412, "t1": 0.8375, "tft": 4.0614, "input_0": 789, "input_1": 513, "min_CLP": -9.15, "draft_iters": 5.0, "mem_use": 36.8, "gen_rate": 4.0, "speed": 1.92, "text": "\\nWhat is the best way to start "}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 240, "tree_size": 512, "t0": 1.97, "t1": 0.85, "tft": 4.9208, "input_0": 989, "input_1": 513, "min_CLP": -8.21, "draft_iters": 8.0, "mem_use": 37.26, "gen_rate": 4.7, "speed": 1.67, "text": "[The scene opens with the genera"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.1, "tree_w": 252, "tree_size": 512, "t0": 1.5129, "t1": 0.8, "tft": 3.5199, "input_0": 911, "input_1": 513, "min_CLP": -7.88, "draft_iters": 6.3, "mem_use": 36.18, "gen_rate": 4.6, "speed": 1.98, "text": "\"Well, that's really all I can d"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 203, "tree_size": 512, "t0": 3.02, "t1": 0.8, "tft": 3.544, "input_0": 1006, "input_1": 513, "min_CLP": -8.26, "draft_iters": 18.5, "mem_use": 36.03, "gen_rate": 17.5, "speed": 4.58, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.1, "tree_w": 255, "tree_size": 512, "t0": 1.5657, "t1": 0.7986, "tft": 3.5364, "input_0": 949, "input_1": 513, "min_CLP": -8.21, "draft_iters": 6.3, "mem_use": 36.06, "gen_rate": 4.6, "speed": 1.93, "text": "I am saying that being a master "}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.6, "tree_w": 263, "tree_size": 512, "t0": 1.495, "t1": 0.8662, "tft": 5.4467, "input_0": 843, "input_1": 513, "min_CLP": -8.19, "draft_iters": 5.8, "mem_use": 37.51, "gen_rate": 4.1, "speed": 1.75, "text": "In C++, you can allocate memory "}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.9, "tree_w": 259, "tree_size": 512, "t0": 1.5375, "t1": 0.8563, "tft": 5.049, "input_0": 867, "input_1": 513, "min_CLP": -8.13, "draft_iters": 6.1, "mem_use": 37.34, "gen_rate": 4.1, "speed": 1.73, "text": "\"Hello Mike, I'm glad that you m"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.0, "tree_w": 272, "tree_size": 512, "t0": 1.4814, "t1": 0.8386, "tft": 4.5805, "input_0": 893, "input_1": 513, "min_CLP": -8.47, "draft_iters": 6.0, "mem_use": 36.99, "gen_rate": 4.7, "speed": 2.03, "text": "If you created your app using a "}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 274, "tree_size": 512, "t0": 1.2478, "t1": 0.7878, "tft": 2.8602, "input_0": 884, "input_1": 513, "min_CLP": -8.99, "draft_iters": 5.1, "mem_use": 35.84, "gen_rate": 3.8, "speed": 1.86, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 273, "tree_size": 512, "t0": 1.2087, "t1": 0.7825, "tft": 2.7887, "input_0": 827, "input_1": 513, "min_CLP": -9.34, "draft_iters": 5.0, "mem_use": 35.64, "gen_rate": 4.1, "speed": 2.07, "text": "\\nExplain the differences betwee"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 300, "tree_size": 512, "t0": 1.245, "t1": 0.835, "tft": 4.4087, "input_0": 866, "input_1": 513, "min_CLP": -10.58, "draft_iters": 5.0, "mem_use": 36.88, "gen_rate": 4.1, "speed": 1.98, "text": "The average temperature in June "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 183, "tree_size": 512, "t0": 2.2883, "t1": 0.7817, "tft": 2.2054, "input_0": 1082, "input_1": 513, "min_CLP": -8.22, "draft_iters": 9.7, "mem_use": 35.66, "gen_rate": 5.5, "speed": 1.79, "text": "\\nWho made Berlin [\\\\INST]\\n\\nBe"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.9, "tree_w": 269, "tree_size": 512, "t0": 1.5562, "t1": 0.8362, "tft": 4.3822, "input_0": 949, "input_1": 513, "min_CLP": -8.31, "draft_iters": 6.0, "mem_use": 36.76, "gen_rate": 4.0, "speed": 1.67, "text": "\\nDear Grandma,\\n\\nI think you a"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 270, "tree_size": 512, "t0": 1.5975, "t1": 0.8313, "tft": 4.0751, "input_0": 877, "input_1": 513, "min_CLP": -8.21, "draft_iters": 7.1, "mem_use": 36.7, "gen_rate": 4.1, "speed": 1.7, "text": "\"\\nI'm no expert on this subject"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.9, "tree_w": 251, "tree_size": 512, "t0": 1.51, "t1": 0.78, "tft": 2.7814, "input_0": 891, "input_1": 513, "min_CLP": -8.12, "draft_iters": 6.1, "mem_use": 35.65, "gen_rate": 3.7, "speed": 1.6, "text": "\\nPornography is created by the "}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 228, "tree_size": 512, "t0": 2.7225, "t1": 0.7875, "tft": 2.7944, "input_0": 1289, "input_1": 513, "min_CLP": -10.12, "draft_iters": 11.8, "mem_use": 35.84, "gen_rate": 10.5, "speed": 2.99, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 4.6, "tree_w": 233, "tree_size": 512, "t0": 1.5814, "t1": 0.7871, "tft": 2.8422, "input_0": 894, "input_1": 513, "min_CLP": -8.93, "draft_iters": 6.7, "mem_use": 35.84, "gen_rate": 5.0, "speed": 2.11, "text": "\\nHow many people are in the wor"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.2, "tree_w": 272, "tree_size": 512, "t0": 1.2456, "t1": 0.78, "tft": 2.8038, "input_0": 881, "input_1": 513, "min_CLP": -9.02, "draft_iters": 5.1, "mem_use": 35.66, "gen_rate": 3.9, "speed": 1.92, "text": "\\nThis is a joke.\\n\\nSuppose I h"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 294, "tree_size": 512, "t0": 1.2511, "t1": 0.8, "tft": 3.5459, "input_0": 865, "input_1": 513, "min_CLP": -10.08, "draft_iters": 5.1, "mem_use": 36.09, "gen_rate": 3.9, "speed": 1.9, "text": "The Sieve of Eratosthenes is a m"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 4.0, "tree_w": 237, "tree_size": 512, "t0": 1.56, "t1": 0.79, "tft": 2.8542, "input_0": 1151, "input_1": 513, "min_CLP": -7.92, "draft_iters": 6.0, "mem_use": 35.87, "gen_rate": 4.0, "speed": 1.71, "text": "\"It's probably best to toss it.\""}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 6.7, "tree_w": 258, "tree_size": 512, "t0": 1.8471, "t1": 0.7843, "tft": 2.8214, "input_0": 1026, "input_1": 513, "min_CLP": -10.15, "draft_iters": 8.9, "mem_use": 35.71, "gen_rate": 6.0, "speed": 2.28, "text": "\\nWrite an announcement tweet fo"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.8, "tree_w": 272, "tree_size": 512, "t0": 1.4637, "t1": 0.8, "tft": 3.5536, "input_0": 928, "input_1": 513, "min_CLP": -8.34, "draft_iters": 5.9, "mem_use": 36.02, "gen_rate": 4.1, "speed": 1.82, "text": "Yes. In the case of sexual selec"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.8, "tree_w": 267, "tree_size": 512, "t0": 1.675, "t1": 0.82, "tft": 3.9933, "input_0": 972, "input_1": 513, "min_CLP": -8.64, "draft_iters": 6.9, "mem_use": 36.56, "gen_rate": 4.4, "speed": 1.75, "text": "AI assistants can help individua"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.6, "tree_w": 255, "tree_size": 512, "t0": 1.6738, "t1": 0.84, "tft": 4.6059, "input_0": 961, "input_1": 513, "min_CLP": -8.71, "draft_iters": 6.8, "mem_use": 37.04, "gen_rate": 4.2, "speed": 1.69, "text": "\\n[Verse 4]\\nYou can drive him m"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.6, "tree_w": 236, "tree_size": 512, "t0": 2.035, "t1": 0.8088, "tft": 3.5721, "input_0": 1032, "input_1": 513, "min_CLP": -8.17, "draft_iters": 9.0, "mem_use": 36.35, "gen_rate": 4.8, "speed": 1.67, "text": "\\nThe scp command works on any U"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 44, "tree_h": 4.5, "tree_w": 262, "tree_size": 512, "t0": 1.5988, "t1": 0.8337, "tft": 4.3501, "input_0": 964, "input_1": 513, "min_CLP": -8.26, "draft_iters": 6.5, "mem_use": 36.76, "gen_rate": 5.5, "speed": 2.26, "text": "\"\\nI'm on a diet, I can only eat"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.2, "tree_w": 180, "tree_size": 512, "t0": 3.5875, "t1": 0.78, "tft": 2.7892, "input_0": 1382, "input_1": 513, "min_CLP": -8.33, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 9.0, "speed": 2.06, "text": "\\nIf you found a dollar bill, wo"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.8, "tree_w": 271, "tree_size": 512, "t0": 1.5575, "t1": 0.7838, "tft": 2.7904, "input_0": 948, "input_1": 513, "min_CLP": -8.38, "draft_iters": 6.8, "mem_use": 35.82, "gen_rate": 4.4, "speed": 1.87, "text": "Sydney has the largest populatio"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 10.9, "tree_w": 205, "tree_size": 512, "t0": 2.53, "t1": 0.7943, "tft": 2.9416, "input_0": 1129, "input_1": 513, "min_CLP": -8.41, "draft_iters": 12.9, "mem_use": 35.93, "gen_rate": 6.1, "speed": 1.85, "text": "\"\\nWould you like to know anythi"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.0, "tree_w": 248, "tree_size": 512, "t0": 1.4514, "t1": 0.7871, "tft": 2.7726, "input_0": 823, "input_1": 513, "min_CLP": -8.19, "draft_iters": 6.1, "mem_use": 35.8, "gen_rate": 4.7, "speed": 2.11, "text": "\"\\nWell, I'm sure you can come u"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.8, "tree_w": 272, "tree_size": 512, "t0": 1.3888, "t1": 0.7825, "tft": 2.7867, "input_0": 890, "input_1": 513, "min_CLP": -8.68, "draft_iters": 5.8, "mem_use": 35.67, "gen_rate": 4.2, "speed": 1.96, "text": "\\nThe best approach is to use a "}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 8.6, "tree_w": 249, "tree_size": 512, "t0": 2.034, "t1": 0.782, "tft": 2.7902, "input_0": 1001, "input_1": 513, "min_CLP": -9.65, "draft_iters": 10.4, "mem_use": 35.67, "gen_rate": 9.6, "speed": 3.41, "text": "How long will it take to walk ar"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.4, "tree_w": 227, "tree_size": 512, "t0": 2.3014, "t1": 0.82, "tft": 3.9241, "input_0": 1162, "input_1": 513, "min_CLP": -10.35, "draft_iters": 9.3, "mem_use": 36.51, "gen_rate": 5.4, "speed": 1.74, "text": "\\nThe Taniyama\u2013Shimura\u2013Weil conj"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 159, "tree_size": 512, "t0": 3.785, "t1": 0.78, "tft": 2.796, "input_0": 1401, "input_1": 513, "min_CLP": -8.99, "draft_iters": 18.5, "mem_use": 35.65, "gen_rate": 17.5, "speed": 3.83, "text": "\\nWhich parts of France would be"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 61, "tree_h": 7.1, "tree_w": 244, "tree_size": 512, "t0": 1.895, "t1": 0.7875, "tft": 2.8352, "input_0": 930, "input_1": 513, "min_CLP": -8.14, "draft_iters": 9.2, "mem_use": 35.8, "gen_rate": 7.6, "speed": 2.84, "text": "\"\\nI'm sorry, I am not able to a"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.2, "tree_w": 262, "tree_size": 512, "t0": 1.4378, "t1": 0.7822, "tft": 2.7822, "input_0": 942, "input_1": 513, "min_CLP": -8.32, "draft_iters": 6.1, "mem_use": 35.66, "gen_rate": 3.7, "speed": 1.65, "text": "\\nI love playing guitar and woul"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.6, "tree_w": 244, "tree_size": 512, "t0": 1.7133, "t1": 0.7889, "tft": 2.7842, "input_0": 912, "input_1": 513, "min_CLP": -8.16, "draft_iters": 7.8, "mem_use": 35.83, "gen_rate": 4.1, "speed": 1.64, "text": "[INST] What is the Force? [\\\\INS"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.9, "tree_w": 253, "tree_size": 512, "t0": 1.5143, "t1": 0.7843, "tft": 2.8336, "input_0": 887, "input_1": 513, "min_CLP": -8.27, "draft_iters": 6.1, "mem_use": 35.74, "gen_rate": 4.6, "speed": 1.99, "text": "Rifles with a gas-operated actio"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 273, "tree_size": 512, "t0": 1.2588, "t1": 0.79, "tft": 2.8511, "input_0": 837, "input_1": 513, "min_CLP": -8.55, "draft_iters": 5.1, "mem_use": 35.87, "gen_rate": 4.0, "speed": 1.95, "text": "\\nAs far as I know, the American"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.8, "tree_w": 244, "tree_size": 512, "t0": 1.6875, "t1": 0.87, "tft": 5.7073, "input_0": 899, "input_1": 513, "min_CLP": -8.04, "draft_iters": 6.9, "mem_use": 37.72, "gen_rate": 4.5, "speed": 1.76, "text": "\"\\nYes, this function is not ver"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.0, "tree_w": 277, "tree_size": 512, "t0": 1.5329, "t1": 0.79, "tft": 2.8664, "input_0": 909, "input_1": 513, "min_CLP": -8.36, "draft_iters": 6.3, "mem_use": 35.86, "gen_rate": 4.9, "speed": 2.09, "text": "The person who found the lost pr"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 267, "tree_size": 512, "t0": 1.8413, "t1": 0.8588, "tft": 5.095, "input_0": 1004, "input_1": 513, "min_CLP": -8.13, "draft_iters": 8.0, "mem_use": 37.38, "gen_rate": 4.2, "speed": 1.58, "text": "Hello!\\nThank you for your time."}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.0, "tree_w": 228, "tree_size": 512, "t0": 2.515, "t1": 0.8, "tft": 3.5329, "input_0": 1174, "input_1": 513, "min_CLP": -8.5, "draft_iters": 11.8, "mem_use": 36.08, "gen_rate": 11.0, "speed": 3.32, "text": "<</SYS>\\n\\nI heard something abo"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.1, "tree_w": 258, "tree_size": 512, "t0": 1.7913, "t1": 0.79, "tft": 2.8598, "input_0": 950, "input_1": 513, "min_CLP": -9.29, "draft_iters": 8.4, "mem_use": 35.85, "gen_rate": 4.8, "speed": 1.84, "text": "A decorator is a special type of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.2, "tree_w": 253, "tree_size": 512, "t0": 1.5375, "t1": 0.8188, "tft": 3.9147, "input_0": 883, "input_1": 513, "min_CLP": -8.56, "draft_iters": 6.4, "mem_use": 36.53, "gen_rate": 4.5, "speed": 1.91, "text": "\\nOne of the most popular German"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 4.6, "tree_w": 250, "tree_size": 512, "t0": 1.6367, "t1": 0.79, "tft": 2.8395, "input_0": 926, "input_1": 513, "min_CLP": -8.06, "draft_iters": 6.8, "mem_use": 35.83, "gen_rate": 4.4, "speed": 1.83, "text": "A thumb war is a game of thumb-b"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.5, "tree_w": 259, "tree_size": 512, "t0": 1.9933, "t1": 0.8367, "tft": 4.3862, "input_0": 925, "input_1": 513, "min_CLP": -8.29, "draft_iters": 9.5, "mem_use": 36.87, "gen_rate": 6.7, "speed": 2.36, "text": "\"\\nIn order to attract new clien"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.0, "tree_w": 247, "tree_size": 512, "t0": 1.4175, "t1": 0.8, "tft": 3.51, "input_0": 852, "input_1": 513, "min_CLP": -8.26, "draft_iters": 6.0, "mem_use": 36.14, "gen_rate": 4.1, "speed": 1.86, "text": "\"\\nI'm sure this is something th"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.6, "tree_w": 235, "tree_size": 512, "t0": 1.67, "t1": 0.7922, "tft": 2.9434, "input_0": 994, "input_1": 513, "min_CLP": -8.48, "draft_iters": 6.8, "mem_use": 35.93, "gen_rate": 3.9, "speed": 1.58, "text": "[INST] Well, I\u2019m already doing a"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 254, "tree_size": 512, "t0": 1.62, "t1": 0.7957, "tft": 2.9808, "input_0": 989, "input_1": 513, "min_CLP": -8.4, "draft_iters": 7.0, "mem_use": 36.01, "gen_rate": 4.6, "speed": 1.89, "text": "There are many resources availab"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.0, "tree_w": 258, "tree_size": 512, "t0": 1.6743, "t1": 0.8257, "tft": 4.0312, "input_0": 960, "input_1": 513, "min_CLP": -8.97, "draft_iters": 7.1, "mem_use": 36.68, "gen_rate": 4.9, "speed": 1.94, "text": "\"In Tolkien's fictional language"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 156, "tree_size": 512, "t0": 3.94, "t1": 0.78, "tft": 2.7767, "input_0": 1453, "input_1": 513, "min_CLP": -8.28, "draft_iters": 18.5, "mem_use": 35.65, "gen_rate": 17.5, "speed": 3.71, "text": "\\nWhat are the five most common "}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.0, "tree_w": 239, "tree_size": 512, "t0": 1.83, "t1": 0.78, "tft": 2.8114, "input_0": 923, "input_1": 513, "min_CLP": -8.11, "draft_iters": 9.1, "mem_use": 35.69, "gen_rate": 4.1, "speed": 1.58, "text": "\"\\nI have tried to look up the e"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.0, "tree_w": 239, "tree_size": 512, "t0": 2.025, "t1": 0.8113, "tft": 3.5763, "input_0": 976, "input_1": 513, "min_CLP": -8.54, "draft_iters": 9.2, "mem_use": 36.35, "gen_rate": 4.4, "speed": 1.54, "text": "\\nThe message was left in the pa"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 274, "tree_size": 512, "t0": 1.345, "t1": 0.8, "tft": 3.558, "input_0": 948, "input_1": 513, "min_CLP": -12.72, "draft_iters": 5.4, "mem_use": 35.99, "gen_rate": 4.4, "speed": 2.04, "text": "The most common use for an `@` s"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.8, "tree_w": 221, "tree_size": 512, "t0": 2.5125, "t1": 0.8, "tft": 3.547, "input_0": 1054, "input_1": 513, "min_CLP": -7.88, "draft_iters": 12.5, "mem_use": 36.11, "gen_rate": 8.2, "speed": 2.49, "text": "A program in Python that support"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.8, "tree_w": 271, "tree_size": 512, "t0": 1.4525, "t1": 0.84, "tft": 4.5531, "input_0": 862, "input_1": 513, "min_CLP": -7.98, "draft_iters": 5.9, "mem_use": 36.95, "gen_rate": 4.0, "speed": 1.75, "text": "\"\\nI'm sure you're excited about"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 233, "tree_size": 512, "t0": 2.305, "t1": 0.79, "tft": 2.9529, "input_0": 1070, "input_1": 513, "min_CLP": -9.03, "draft_iters": 11.5, "mem_use": 35.92, "gen_rate": 10.8, "speed": 3.47, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.4, "tree_w": 263, "tree_size": 512, "t0": 1.5588, "t1": 0.82, "tft": 3.9896, "input_0": 941, "input_1": 513, "min_CLP": -8.49, "draft_iters": 6.4, "mem_use": 36.56, "gen_rate": 4.4, "speed": 1.84, "text": "The earliest fossils of hominins"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 189, "tree_size": 512, "t0": 3.18, "t1": 0.78, "tft": 2.7774, "input_0": 1121, "input_1": 513, "min_CLP": -8.47, "draft_iters": 18.5, "mem_use": 35.65, "gen_rate": 17.5, "speed": 4.42, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 7.5, "tree_w": 263, "tree_size": 512, "t0": 1.8733, "t1": 0.7867, "tft": 2.8602, "input_0": 943, "input_1": 513, "min_CLP": -9.77, "draft_iters": 9.5, "mem_use": 35.8, "gen_rate": 6.8, "speed": 2.57, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.0, "tree_w": 289, "tree_size": 512, "t0": 1.2133, "t1": 0.79, "tft": 2.8698, "input_0": 793, "input_1": 513, "min_CLP": -8.64, "draft_iters": 5.0, "mem_use": 35.9, "gen_rate": 3.6, "speed": 1.78, "text": "Thank you. I take great pride in"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 284, "tree_size": 512, "t0": 1.29, "t1": 0.8322, "tft": 4.3554, "input_0": 852, "input_1": 513, "min_CLP": -8.95, "draft_iters": 5.1, "mem_use": 36.79, "gen_rate": 3.9, "speed": 1.83, "text": "\"My love, I was so worried you'd"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.0, "tree_w": 269, "tree_size": 512, "t0": 1.2156, "t1": 0.7989, "tft": 2.96, "input_0": 787, "input_1": 513, "min_CLP": -9.4, "draft_iters": 5.0, "mem_use": 35.98, "gen_rate": 3.7, "speed": 1.82, "text": "\\nWhat is the best way to measur"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.6, "tree_w": 267, "tree_size": 512, "t0": 1.6473, "t1": 0.7809, "tft": 2.7855, "input_0": 797, "input_1": 513, "min_CLP": -8.99, "draft_iters": 7.8, "mem_use": 35.66, "gen_rate": 3.1, "speed": 1.27, "text": "\\nby /\\\\__/\\n\\nDate: 06:34:33 20"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.1, "tree_w": 251, "tree_size": 512, "t0": 1.6922, "t1": 0.78, "tft": 2.7745, "input_0": 909, "input_1": 513, "min_CLP": -8.32, "draft_iters": 8.1, "mem_use": 35.65, "gen_rate": 3.8, "speed": 1.53, "text": "\"\\n[INST] <<SYS>>\\nTo be honest,"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 288, "tree_size": 512, "t0": 1.2575, "t1": 0.79, "tft": 2.7702, "input_0": 903, "input_1": 513, "min_CLP": -9.27, "draft_iters": 5.1, "mem_use": 35.82, "gen_rate": 4.2, "speed": 2.08, "text": "\\nD. The cross-section of air\\nA"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 5.8, "tree_w": 241, "tree_size": 512, "t0": 2.148, "t1": 0.8, "tft": 3.5518, "input_0": 1236, "input_1": 513, "min_CLP": -8.96, "draft_iters": 8.0, "mem_use": 36.2, "gen_rate": 6.4, "speed": 2.17, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.0, "tree_w": 262, "tree_size": 512, "t0": 1.214, "t1": 0.79, "tft": 2.847, "input_0": 774, "input_1": 513, "min_CLP": -8.61, "draft_iters": 5.0, "mem_use": 35.88, "gen_rate": 3.4, "speed": 1.7, "text": "How do you get a Windows 8 for f"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.4, "tree_w": 270, "tree_size": 512, "t0": 1.5757, "t1": 0.79, "tft": 2.8634, "input_0": 936, "input_1": 513, "min_CLP": -9.22, "draft_iters": 6.6, "mem_use": 35.87, "gen_rate": 4.7, "speed": 1.99, "text": "\"<\\\\INST>\\n\\nThanks! [\\\\INST]\\n<"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 192, "tree_size": 512, "t0": 3.18, "t1": 0.78, "tft": 2.7754, "input_0": 1102, "input_1": 513, "min_CLP": -8.45, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.42, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 285, "tree_size": 512, "t0": 1.2522, "t1": 0.8, "tft": 3.5646, "input_0": 836, "input_1": 513, "min_CLP": -9.05, "draft_iters": 5.1, "mem_use": 35.99, "gen_rate": 3.9, "speed": 1.9, "text": "\"OMG no one cares about you, Ted"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 205, "tree_size": 512, "t0": 3.05, "t1": 0.785, "tft": 2.812, "input_0": 1059, "input_1": 513, "min_CLP": -8.57, "draft_iters": 18.5, "mem_use": 35.72, "gen_rate": 17.5, "speed": 4.56, "text": "\\n[INST] <<SYS>>\\nI am making ma"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 264, "tree_size": 512, "t0": 1.2344, "t1": 0.8056, "tft": 3.5917, "input_0": 765, "input_1": 513, "min_CLP": -8.14, "draft_iters": 5.0, "mem_use": 36.36, "gen_rate": 3.9, "speed": 1.9, "text": "\"I don't think time travel ficti"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.9, "tree_w": 259, "tree_size": 512, "t0": 1.3822, "t1": 0.7889, "tft": 2.8649, "input_0": 830, "input_1": 513, "min_CLP": -8.75, "draft_iters": 5.9, "mem_use": 35.91, "gen_rate": 3.9, "speed": 1.79, "text": "\"Absolutely not! I'd like to hel"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 5.3, "tree_w": 249, "tree_size": 512, "t0": 1.8729, "t1": 0.82, "tft": 3.9273, "input_0": 1041, "input_1": 513, "min_CLP": -8.03, "draft_iters": 7.6, "mem_use": 36.52, "gen_rate": 5.7, "speed": 2.12, "text": "The Colorado Trail is an excelle"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 7.0, "tree_w": 232, "tree_size": 512, "t0": 1.9829, "t1": 0.7886, "tft": 2.8621, "input_0": 1010, "input_1": 513, "min_CLP": -10.42, "draft_iters": 9.0, "mem_use": 35.87, "gen_rate": 7.7, "speed": 2.79, "text": "\\nWrite a tweet for Facebook abo"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 209, "tree_size": 512, "t0": 2.2175, "t1": 0.7875, "tft": 2.7877, "input_0": 937, "input_1": 513, "min_CLP": -8.4, "draft_iters": 11.8, "mem_use": 35.83, "gen_rate": 10.8, "speed": 3.58, "text": "How do I explain it?\\n\\n[INST] <"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.1, "tree_w": 253, "tree_size": 512, "t0": 1.5971, "t1": 0.8414, "tft": 4.6026, "input_0": 908, "input_1": 513, "min_CLP": -8.32, "draft_iters": 6.3, "mem_use": 37.05, "gen_rate": 4.7, "speed": 1.93, "text": "\"\\nThe reason why the derivative"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.9, "tree_w": 256, "tree_size": 512, "t0": 1.4329, "t1": 0.7814, "tft": 2.7822, "input_0": 859, "input_1": 513, "min_CLP": -8.39, "draft_iters": 6.0, "mem_use": 35.66, "gen_rate": 4.6, "speed": 2.06, "text": "\\nYes. Python is a dynamically-t"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 3.8, "tree_w": 251, "tree_size": 512, "t0": 1.43, "t1": 0.79, "tft": 2.952, "input_0": 879, "input_1": 513, "min_CLP": -8.1, "draft_iters": 5.9, "mem_use": 35.92, "gen_rate": 4.4, "speed": 2.0, "text": "Video games are an extremely com"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.1, "tree_w": 267, "tree_size": 512, "t0": 1.25, "t1": 0.7844, "tft": 2.8323, "input_0": 834, "input_1": 513, "min_CLP": -9.01, "draft_iters": 5.1, "mem_use": 35.76, "gen_rate": 3.7, "speed": 1.8, "text": "\"It doesn't matter.\\n[INST] why "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 14.0, "tree_w": 183, "tree_size": 512, "t0": 3.142, "t1": 0.782, "tft": 2.7771, "input_0": 1245, "input_1": 513, "min_CLP": -9.1, "draft_iters": 16.0, "mem_use": 35.66, "gen_rate": 4.4, "speed": 1.12, "text": "\\n[INST] <<SYS>>\\nwhich librarie"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 298, "tree_size": 512, "t0": 1.2488, "t1": 0.8287, "tft": 4.0949, "input_0": 819, "input_1": 513, "min_CLP": -8.55, "draft_iters": 5.0, "mem_use": 36.69, "gen_rate": 4.0, "speed": 1.93, "text": "\"I'm sorry to hear that you didn"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.1, "tree_w": 269, "tree_size": 512, "t0": 1.4556, "t1": 0.7811, "tft": 2.7773, "input_0": 839, "input_1": 513, "min_CLP": -9.79, "draft_iters": 6.3, "mem_use": 35.65, "gen_rate": 3.9, "speed": 1.74, "text": "\\nWill a gummy bear eat itself? "}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 44, "tree_h": 5.9, "tree_w": 254, "tree_size": 512, "t0": 1.68, "t1": 0.78, "tft": 2.797, "input_0": 945, "input_1": 513, "min_CLP": -8.57, "draft_iters": 7.8, "mem_use": 35.67, "gen_rate": 4.4, "speed": 1.79, "text": "\"\\nI'm gonna wash that man right"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.6, "tree_w": 248, "tree_size": 512, "t0": 1.815, "t1": 0.8512, "tft": 4.9362, "input_0": 1039, "input_1": 513, "min_CLP": -8.54, "draft_iters": 6.9, "mem_use": 37.27, "gen_rate": 4.6, "speed": 1.73, "text": "I would say that the most mariju"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 61, "tree_h": 7.6, "tree_w": 217, "tree_size": 512, "t0": 2.2338, "t1": 0.805, "tft": 3.5648, "input_0": 1053, "input_1": 513, "min_CLP": -8.44, "draft_iters": 9.9, "mem_use": 36.31, "gen_rate": 7.6, "speed": 2.51, "text": "\"I will not be able to assist yo"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 199, "tree_size": 512, "t0": 2.648, "t1": 0.788, "tft": 2.7683, "input_0": 1271, "input_1": 513, "min_CLP": -7.88, "draft_iters": 11.2, "mem_use": 35.81, "gen_rate": 6.8, "speed": 1.98, "text": "Du kannst Deutsch lernen, oder a"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 7.5, "tree_w": 238, "tree_size": 512, "t0": 2.0383, "t1": 0.785, "tft": 2.8348, "input_0": 993, "input_1": 513, "min_CLP": -8.77, "draft_iters": 9.5, "mem_use": 35.76, "gen_rate": 8.2, "speed": 2.89, "text": "\\nThe answer will be posted on t"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 271, "tree_size": 512, "t0": 1.1689, "t1": 0.7844, "tft": 2.7777, "input_0": 792, "input_1": 513, "min_CLP": -9.49, "draft_iters": 4.9, "mem_use": 35.67, "gen_rate": 3.9, "speed": 1.99, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 253, "tree_size": 512, "t0": 1.6525, "t1": 0.8, "tft": 3.5395, "input_0": 978, "input_1": 513, "min_CLP": -8.83, "draft_iters": 7.1, "mem_use": 36.09, "gen_rate": 4.4, "speed": 1.78, "text": "\"\\nThe problem is that I don't k"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 288, "tree_size": 512, "t0": 1.2188, "t1": 0.8, "tft": 3.5398, "input_0": 811, "input_1": 513, "min_CLP": -10.54, "draft_iters": 5.0, "mem_use": 36.21, "gen_rate": 4.0, "speed": 1.98, "text": "\"Sure, it can be cut down to 3.\\"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 302, "tree_size": 512, "t0": 1.345, "t1": 0.8862, "tft": 6.0594, "input_0": 881, "input_1": 513, "min_CLP": -9.14, "draft_iters": 5.1, "mem_use": 37.98, "gen_rate": 4.1, "speed": 1.85, "text": "Step 2 \u2014 Writing Your TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 8.4, "tree_w": 248, "tree_size": 512, "t0": 2.014, "t1": 0.782, "tft": 2.7846, "input_0": 935, "input_1": 513, "min_CLP": -9.3, "draft_iters": 10.4, "mem_use": 35.65, "gen_rate": 9.4, "speed": 3.36, "text": "\\nHow can I reduce my alcohol co"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.0, "tree_w": 277, "tree_size": 512, "t0": 1.5643, "t1": 0.7943, "tft": 2.9491, "input_0": 950, "input_1": 513, "min_CLP": -8.31, "draft_iters": 7.0, "mem_use": 35.98, "gen_rate": 5.1, "speed": 2.18, "text": "\"[INST] Berlin is a world-renown"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 211, "tree_size": 512, "t0": 2.3433, "t1": 0.78, "tft": 2.7963, "input_0": 974, "input_1": 513, "min_CLP": -8.75, "draft_iters": 12.3, "mem_use": 35.7, "gen_rate": 11.0, "speed": 3.52, "text": "\\nwrite me script that shows the"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.1, "tree_w": 244, "tree_size": 512, "t0": 2.2071, "t1": 0.84, "tft": 4.4158, "input_0": 1034, "input_1": 513, "min_CLP": -9.06, "draft_iters": 10.4, "mem_use": 36.88, "gen_rate": 4.9, "speed": 1.59, "text": "\\nI have:\\n\\nSpaghetti\\nOregano\\"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.0, "tree_w": 262, "tree_size": 512, "t0": 1.4725, "t1": 0.7813, "tft": 2.1982, "input_0": 835, "input_1": 513, "min_CLP": -8.55, "draft_iters": 6.2, "mem_use": 35.66, "gen_rate": 4.2, "speed": 1.88, "text": "\\nWho wears short shorts?\\n\\nI d"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 244, "tree_size": 512, "t0": 2.0587, "t1": 0.8325, "tft": 4.3962, "input_0": 1145, "input_1": 513, "min_CLP": -8.21, "draft_iters": 9.5, "mem_use": 36.83, "gen_rate": 4.4, "speed": 1.51, "text": "\\nThe owners of the restaurant c"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.6, "tree_w": 286, "tree_size": 512, "t0": 1.3388, "t1": 0.7813, "tft": 2.7793, "input_0": 870, "input_1": 513, "min_CLP": -8.76, "draft_iters": 5.6, "mem_use": 35.65, "gen_rate": 4.2, "speed": 2.01, "text": "\\nWe are living in a world where"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 240, "tree_size": 512, "t0": 2.6625, "t1": 0.7775, "tft": 2.7904, "input_0": 1260, "input_1": 513, "min_CLP": -12.47, "draft_iters": 11.8, "mem_use": 35.65, "gen_rate": 10.8, "speed": 3.12, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 285, "tree_size": 512, "t0": 1.2075, "t1": 0.7813, "tft": 2.8179, "input_0": 806, "input_1": 513, "min_CLP": -9.98, "draft_iters": 5.0, "mem_use": 35.68, "gen_rate": 4.0, "speed": 2.01, "text": "\"\\nWhat's your favorite thing ab"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.0, "tree_w": 271, "tree_size": 512, "t0": 1.5143, "t1": 0.8014, "tft": 3.5643, "input_0": 930, "input_1": 513, "min_CLP": -8.25, "draft_iters": 6.1, "mem_use": 36.2, "gen_rate": 4.9, "speed": 2.1, "text": "\\nThe quality of life in the 50s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 272, "tree_size": 512, "t0": 1.2887, "t1": 0.7825, "tft": 2.798, "input_0": 883, "input_1": 513, "min_CLP": -9.73, "draft_iters": 5.2, "mem_use": 35.66, "gen_rate": 4.2, "speed": 2.05, "text": "\\nWhy so many people like film p"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 187, "tree_size": 512, "t0": 3.0733, "t1": 0.78, "tft": 2.7799, "input_0": 1330, "input_1": 513, "min_CLP": -9.63, "draft_iters": 14.3, "mem_use": 35.81, "gen_rate": 13.3, "speed": 3.46, "text": "\\nCan you tell me how to format "}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 217, "tree_size": 512, "t0": 2.14, "t1": 0.7914, "tft": 2.9444, "input_0": 1066, "input_1": 513, "min_CLP": -7.97, "draft_iters": 9.0, "mem_use": 35.96, "gen_rate": 5.1, "speed": 1.75, "text": "Selective fire means that the ri"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 278, "tree_size": 512, "t0": 1.6575, "t1": 0.785, "tft": 2.8198, "input_0": 965, "input_1": 513, "min_CLP": -8.91, "draft_iters": 7.5, "mem_use": 35.74, "gen_rate": 4.2, "speed": 1.74, "text": "I am the Norse Goddess of Healin"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.6, "tree_w": 237, "tree_size": 512, "t0": 1.82, "t1": 0.82, "tft": 3.9196, "input_0": 949, "input_1": 513, "min_CLP": -8.07, "draft_iters": 7.9, "mem_use": 36.47, "gen_rate": 4.4, "speed": 1.66, "text": "On Windows, you should use the n"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 281, "tree_size": 512, "t0": 1.2075, "t1": 0.78, "tft": 2.7977, "input_0": 793, "input_1": 513, "min_CLP": -9.5, "draft_iters": 5.0, "mem_use": 35.66, "gen_rate": 4.0, "speed": 2.01, "text": "\\nWrite a response that disagree"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 153, "tree_size": 512, "t0": 2.788, "t1": 0.8, "tft": 3.5536, "input_0": 1273, "input_1": 513, "min_CLP": -7.35, "draft_iters": 11.8, "mem_use": 36.1, "gen_rate": 7.2, "speed": 2.01, "text": "Microwaves were first developed "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 3.0, "tree_w": 278, "tree_size": 512, "t0": 1.1773, "t1": 0.7818, "tft": 2.8069, "input_0": 786, "input_1": 513, "min_CLP": -8.4, "draft_iters": 4.9, "mem_use": 35.71, "gen_rate": 3.2, "speed": 1.62, "text": "\"\\nI have a friend who's a schoo"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.6, "tree_w": 262, "tree_size": 512, "t0": 1.3733, "t1": 0.78, "tft": 2.7807, "input_0": 833, "input_1": 513, "min_CLP": -8.24, "draft_iters": 5.7, "mem_use": 35.66, "gen_rate": 3.7, "speed": 1.7, "text": "\\nThe cat was put into a box wit"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 258, "tree_size": 512, "t0": 1.855, "t1": 0.8762, "tft": 5.7733, "input_0": 956, "input_1": 513, "min_CLP": -8.15, "draft_iters": 7.4, "mem_use": 37.81, "gen_rate": 4.1, "speed": 1.51, "text": "\"If you were previously worried "}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 235, "tree_size": 512, "t0": 2.4325, "t1": 0.78, "tft": 2.7573, "input_0": 1094, "input_1": 513, "min_CLP": -9.76, "draft_iters": 11.8, "mem_use": 35.78, "gen_rate": 10.8, "speed": 3.34, "text": "\\n[AUTO] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 240, "tree_size": 512, "t0": 2.1833, "t1": 0.8017, "tft": 3.5492, "input_0": 1192, "input_1": 513, "min_CLP": -9.05, "draft_iters": 9.8, "mem_use": 36.19, "gen_rate": 5.8, "speed": 1.96, "text": "It would take approximately 7,94"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.0, "tree_w": 276, "tree_size": 512, "t0": 1.238, "t1": 0.84, "tft": 4.3967, "input_0": 784, "input_1": 513, "min_CLP": -8.74, "draft_iters": 5.0, "mem_use": 36.84, "gen_rate": 3.2, "speed": 1.54, "text": "This can be done in two ways:\\n*"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.6, "tree_w": 275, "tree_size": 512, "t0": 1.3233, "t1": 0.7856, "tft": 2.7724, "input_0": 822, "input_1": 513, "min_CLP": -8.39, "draft_iters": 5.6, "mem_use": 35.81, "gen_rate": 3.7, "speed": 1.74, "text": "\"You're asking a lot of me. I'm "}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 261, "tree_size": 512, "t0": 1.7357, "t1": 0.7843, "tft": 2.7788, "input_0": 890, "input_1": 513, "min_CLP": -9.11, "draft_iters": 8.9, "mem_use": 35.79, "gen_rate": 4.6, "speed": 1.81, "text": "\\nHi open assistant, can you tel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.1, "tree_w": 282, "tree_size": 512, "t0": 1.5457, "t1": 0.7986, "tft": 3.5409, "input_0": 939, "input_1": 513, "min_CLP": -8.72, "draft_iters": 6.4, "mem_use": 36.04, "gen_rate": 4.7, "speed": 2.01, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 283, "tree_size": 512, "t0": 1.21, "t1": 0.8125, "tft": 2.7732, "input_0": 793, "input_1": 513, "min_CLP": -8.42, "draft_iters": 5.0, "mem_use": 35.79, "gen_rate": 4.0, "speed": 1.98, "text": "\"\\nWell, this is a bit tricky. I"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 279, "tree_size": 512, "t0": 1.2675, "t1": 0.8, "tft": 3.5605, "input_0": 900, "input_1": 513, "min_CLP": -8.63, "draft_iters": 5.1, "mem_use": 36.17, "gen_rate": 4.2, "speed": 2.06, "text": "Schrodingers cat is an illustrat"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 275, "tree_size": 512, "t0": 1.2163, "t1": 0.7888, "tft": 2.784, "input_0": 796, "input_1": 513, "min_CLP": -11.99, "draft_iters": 5.0, "mem_use": 35.8, "gen_rate": 4.0, "speed": 2.0, "text": "\\nHi. I want to make an embossed"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 260, "tree_size": 512, "t0": 1.7775, "t1": 0.7788, "tft": 2.79, "input_0": 952, "input_1": 513, "min_CLP": -9.6, "draft_iters": 8.2, "mem_use": 35.67, "gen_rate": 7.4, "speed": 2.88, "text": "\\n<INST>\\nYou are a helpful, res"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.5, "tree_w": 277, "tree_size": 512, "t0": 1.2812, "t1": 0.7813, "tft": 2.7917, "input_0": 862, "input_1": 513, "min_CLP": -8.72, "draft_iters": 5.4, "mem_use": 35.66, "gen_rate": 4.0, "speed": 1.94, "text": "\\nIf time seems to slow down in "}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 62, "tree_h": 20.7, "tree_w": 118, "tree_size": 512, "t0": 4.9067, "t1": 0.89, "tft": 6.071, "input_0": 1489, "input_1": 513, "min_CLP": -8.01, "draft_iters": 23.0, "mem_use": 38.04, "gen_rate": 20.7, "speed": 3.57, "text": "\"\\nPlease implement the bubble s"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 6.0, "tree_w": 244, "tree_size": 512, "t0": 1.97, "t1": 0.7833, "tft": 2.8194, "input_0": 1127, "input_1": 513, "min_CLP": -8.75, "draft_iters": 8.3, "mem_use": 35.73, "gen_rate": 7.0, "speed": 2.54, "text": "Javascript is used to build web "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 264, "tree_size": 512, "t0": 1.8457, "t1": 0.82, "tft": 3.9189, "input_0": 1037, "input_1": 513, "min_CLP": -8.3, "draft_iters": 7.7, "mem_use": 36.5, "gen_rate": 4.7, "speed": 1.77, "text": "There are many different ways to"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.1, "tree_w": 271, "tree_size": 512, "t0": 1.4988, "t1": 0.8125, "tft": 3.8878, "input_0": 953, "input_1": 513, "min_CLP": -9.07, "draft_iters": 6.1, "mem_use": 36.39, "gen_rate": 4.0, "speed": 1.73, "text": "\\n3. Use the Disk Defragmenter:\\"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 200, "tree_size": 512, "t0": 3.425, "t1": 0.785, "tft": 2.7704, "input_0": 1194, "input_1": 513, "min_CLP": -8.71, "draft_iters": 18.5, "mem_use": 35.76, "gen_rate": 17.5, "speed": 4.16, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.6, "tree_w": 246, "tree_size": 512, "t0": 1.64, "t1": 0.7871, "tft": 2.8126, "input_0": 974, "input_1": 513, "min_CLP": -8.19, "draft_iters": 6.7, "mem_use": 35.68, "gen_rate": 4.7, "speed": 1.94, "text": "\\nThe boiling water method is th"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.5, "tree_w": 242, "tree_size": 512, "t0": 1.61, "t1": 0.7813, "tft": 2.7931, "input_0": 913, "input_1": 513, "min_CLP": -8.24, "draft_iters": 6.8, "mem_use": 35.68, "gen_rate": 4.6, "speed": 1.93, "text": "\\nThe following are a few of the"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 266, "tree_size": 512, "t0": 1.2675, "t1": 0.8, "tft": 3.5497, "input_0": 821, "input_1": 513, "min_CLP": -10.27, "draft_iters": 5.1, "mem_use": 36.18, "gen_rate": 4.1, "speed": 1.99, "text": "\\nUser : Hi dear\\nAgent : helo ,"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.7, "tree_w": 262, "tree_size": 512, "t0": 1.5944, "t1": 0.79, "tft": 2.8371, "input_0": 880, "input_1": 513, "min_CLP": -8.24, "draft_iters": 6.9, "mem_use": 35.82, "gen_rate": 3.9, "speed": 1.63, "text": "\\n\"The most important question i"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 273, "tree_size": 512, "t0": 1.8957, "t1": 0.82, "tft": 3.9241, "input_0": 999, "input_1": 513, "min_CLP": -12.11, "draft_iters": 9.1, "mem_use": 36.54, "gen_rate": 8.0, "speed": 2.95, "text": "Here is a list of masculine word"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.4, "tree_w": 267, "tree_size": 512, "t0": 1.5057, "t1": 0.79, "tft": 2.9565, "input_0": 862, "input_1": 513, "min_CLP": -8.33, "draft_iters": 6.6, "mem_use": 35.97, "gen_rate": 4.6, "speed": 1.99, "text": "If they have a strong moral comp"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 200, "tree_size": 512, "t0": 3.135, "t1": 0.79, "tft": 2.8412, "input_0": 1032, "input_1": 513, "min_CLP": -8.5, "draft_iters": 18.5, "mem_use": 35.88, "gen_rate": 17.5, "speed": 4.46, "text": "[INST] Yes, the Bureau of Alcoho"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 58, "tree_h": 6.5, "tree_w": 246, "tree_size": 512, "t0": 1.9638, "t1": 0.7875, "tft": 2.8374, "input_0": 1011, "input_1": 513, "min_CLP": -10.46, "draft_iters": 8.5, "mem_use": 35.75, "gen_rate": 7.2, "speed": 2.64, "text": "What are the benefits of type-in"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 57, "tree_h": 7.1, "tree_w": 245, "tree_size": 512, "t0": 1.9487, "t1": 0.8487, "tft": 4.8778, "input_0": 917, "input_1": 513, "min_CLP": -8.08, "draft_iters": 9.2, "mem_use": 37.14, "gen_rate": 7.1, "speed": 2.55, "text": "\\nI think it would be better if "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 237, "tree_size": 512, "t0": 1.7843, "t1": 0.85, "tft": 4.8819, "input_0": 989, "input_1": 513, "min_CLP": -8.09, "draft_iters": 7.1, "mem_use": 37.17, "gen_rate": 4.6, "speed": 1.74, "text": "\"\\nA story that I've been workin"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 206, "tree_size": 512, "t0": 3.065, "t1": 0.78, "tft": 2.7851, "input_0": 1054, "input_1": 513, "min_CLP": -8.68, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.55, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 280, "tree_size": 512, "t0": 1.2344, "t1": 0.8022, "tft": 3.5808, "input_0": 797, "input_1": 513, "min_CLP": -9.16, "draft_iters": 5.0, "mem_use": 36.23, "gen_rate": 3.9, "speed": 1.91, "text": "\\nI think this is a great idea! "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 251, "tree_size": 512, "t0": 1.6057, "t1": 0.8171, "tft": 3.9231, "input_0": 922, "input_1": 513, "min_CLP": -8.5, "draft_iters": 6.7, "mem_use": 36.46, "gen_rate": 4.6, "speed": 1.89, "text": "\\nThe maximum speed of the car i"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.0, "tree_w": 266, "tree_size": 512, "t0": 1.5029, "t1": 0.78, "tft": 2.7847, "input_0": 916, "input_1": 513, "min_CLP": -8.47, "draft_iters": 6.1, "mem_use": 35.65, "gen_rate": 4.7, "speed": 2.06, "text": "\\nHello everyone,\\n\\nI have an a"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 263, "tree_size": 512, "t0": 1.215, "t1": 0.7888, "tft": 2.7717, "input_0": 784, "input_1": 513, "min_CLP": -8.73, "draft_iters": 5.0, "mem_use": 35.8, "gen_rate": 4.0, "speed": 2.0, "text": "\"I am a goddess, and you are a m"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 7.0, "tree_w": 248, "tree_size": 512, "t0": 1.984, "t1": 0.82, "tft": 4.0095, "input_0": 970, "input_1": 513, "min_CLP": -10.37, "draft_iters": 9.2, "mem_use": 36.56, "gen_rate": 7.2, "speed": 2.57, "text": "\"I've heard that Hershey's choco"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.7, "tree_w": 260, "tree_size": 512, "t0": 1.4171, "t1": 0.7814, "tft": 2.8375, "input_0": 841, "input_1": 513, "min_CLP": -8.19, "draft_iters": 5.9, "mem_use": 35.74, "gen_rate": 4.6, "speed": 2.08, "text": "\"\\nThis is a really interesting "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 267, "tree_size": 512, "t0": 1.2325, "t1": 0.8188, "tft": 3.5881, "input_0": 784, "input_1": 513, "min_CLP": -9.14, "draft_iters": 5.0, "mem_use": 36.49, "gen_rate": 4.0, "speed": 1.95, "text": "\\nI have two SSH servers, A and "}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 248, "tree_size": 512, "t0": 1.6013, "t1": 0.78, "tft": 2.7851, "input_0": 909, "input_1": 513, "min_CLP": -8.2, "draft_iters": 6.8, "mem_use": 35.66, "gen_rate": 4.2, "speed": 1.78, "text": "\\nIn the future, I think we will"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 57, "tree_h": 7.1, "tree_w": 251, "tree_size": 512, "t0": 2.1114, "t1": 0.7814, "tft": 2.7914, "input_0": 1177, "input_1": 513, "min_CLP": -10.59, "draft_iters": 9.0, "mem_use": 35.66, "gen_rate": 8.1, "speed": 2.81, "text": "\\nHow do I cook a salmon fillet "}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 200, "tree_size": 512, "t0": 2.39, "t1": 0.7983, "tft": 3.5666, "input_0": 1217, "input_1": 513, "min_CLP": -7.77, "draft_iters": 10.0, "mem_use": 35.99, "gen_rate": 5.5, "speed": 1.73, "text": "\"I'll do my best to get it done "}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 275, "tree_size": 512, "t0": 1.27, "t1": 0.8, "tft": 3.543, "input_0": 839, "input_1": 513, "min_CLP": -8.63, "draft_iters": 5.1, "mem_use": 36.17, "gen_rate": 4.0, "speed": 1.93, "text": "\"\\nI'm still looking for the las"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.8, "tree_w": 248, "tree_size": 512, "t0": 1.7187, "t1": 0.7838, "tft": 2.7846, "input_0": 1007, "input_1": 513, "min_CLP": -8.47, "draft_iters": 7.0, "mem_use": 35.66, "gen_rate": 4.4, "speed": 1.75, "text": "\\nThe AK-47 is a selective-fire "}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 235, "tree_size": 512, "t0": 2.0362, "t1": 0.7863, "tft": 2.5221, "input_0": 1093, "input_1": 513, "min_CLP": -11.7, "draft_iters": 8.5, "mem_use": 35.79, "gen_rate": 7.5, "speed": 2.66, "text": "\\nI have two remote Debian serve"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 272, "tree_size": 512, "t0": 1.2463, "t1": 0.82, "tft": 3.9214, "input_0": 794, "input_1": 513, "min_CLP": -10.42, "draft_iters": 5.0, "mem_use": 36.56, "gen_rate": 4.0, "speed": 1.93, "text": "Sure, here you go:\\n\\n* Stats mo"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 237, "tree_size": 512, "t0": 2.2833, "t1": 0.7867, "tft": 2.7805, "input_0": 1120, "input_1": 513, "min_CLP": -11.71, "draft_iters": 9.5, "mem_use": 35.79, "gen_rate": 8.5, "speed": 2.77, "text": "\\nHow can I start a successful g"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.5, "tree_w": 275, "tree_size": 512, "t0": 1.5837, "t1": 0.8, "tft": 3.5741, "input_0": 950, "input_1": 513, "min_CLP": -8.19, "draft_iters": 6.5, "mem_use": 36.05, "gen_rate": 4.5, "speed": 1.89, "text": "\"If you're not hungry, or if you"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 269, "tree_size": 512, "t0": 1.2889, "t1": 0.79, "tft": 2.8755, "input_0": 790, "input_1": 513, "min_CLP": -8.36, "draft_iters": 5.3, "mem_use": 35.9, "gen_rate": 3.8, "speed": 1.82, "text": "If you want to cheer someone up,"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 253, "tree_size": 512, "t0": 1.3425, "t1": 0.795, "tft": 2.9534, "input_0": 915, "input_1": 513, "min_CLP": -9.45, "draft_iters": 5.4, "mem_use": 35.94, "gen_rate": 4.4, "speed": 2.05, "text": "<</SYS>\\n\\nUser : hi,\\nAgent : p"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.3, "tree_w": 214, "tree_size": 512, "t0": 2.1283, "t1": 0.7817, "tft": 2.7821, "input_0": 1083, "input_1": 513, "min_CLP": -9.04, "draft_iters": 9.5, "mem_use": 35.66, "gen_rate": 6.2, "speed": 2.12, "text": "\\nWhat are your hobbies? [\\\\INST"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.3, "tree_w": 261, "tree_size": 512, "t0": 1.4622, "t1": 0.78, "tft": 2.7797, "input_0": 857, "input_1": 513, "min_CLP": -8.47, "draft_iters": 6.4, "mem_use": 35.66, "gen_rate": 4.2, "speed": 1.88, "text": "\\nThe cryptocurrency market is n"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 19.2, "tree_w": 163, "tree_size": 512, "t0": 3.716, "t1": 0.794, "tft": 2.9588, "input_0": 1320, "input_1": 513, "min_CLP": -8.31, "draft_iters": 21.2, "mem_use": 35.95, "gen_rate": 6.6, "speed": 1.46, "text": "\\nwhat does theanine do? [\\\\INST"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 8.4, "tree_w": 252, "tree_size": 512, "t0": 2.212, "t1": 0.784, "tft": 2.7659, "input_0": 1042, "input_1": 513, "min_CLP": -10.55, "draft_iters": 10.4, "mem_use": 35.8, "gen_rate": 9.4, "speed": 3.14, "text": "\\n<SYS>\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 201, "tree_size": 512, "t0": 3.15, "t1": 0.785, "tft": 2.8081, "input_0": 1108, "input_1": 513, "min_CLP": -8.6, "draft_iters": 18.5, "mem_use": 35.71, "gen_rate": 17.5, "speed": 4.45, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.0, "tree_w": 284, "tree_size": 512, "t0": 1.3733, "t1": 0.7833, "tft": 2.812, "input_0": 785, "input_1": 513, "min_CLP": -9.58, "draft_iters": 6.1, "mem_use": 35.68, "gen_rate": 3.9, "speed": 1.8, "text": "\\nWhy does a cat hate water? [\\\\"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 281, "tree_size": 512, "t0": 1.2225, "t1": 0.7913, "tft": 2.931, "input_0": 799, "input_1": 513, "min_CLP": -9.34, "draft_iters": 5.0, "mem_use": 35.91, "gen_rate": 4.0, "speed": 1.99, "text": "\"Bliss is the name of Charles O'"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.1, "tree_w": 235, "tree_size": 512, "t0": 1.9425, "t1": 0.8625, "tft": 5.4427, "input_0": 1006, "input_1": 513, "min_CLP": -7.96, "draft_iters": 7.5, "mem_use": 37.51, "gen_rate": 4.5, "speed": 1.6, "text": "It depends on the arrangement yo"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.1, "tree_w": 285, "tree_size": 512, "t0": 1.28, "t1": 0.8378, "tft": 4.3794, "input_0": 845, "input_1": 513, "min_CLP": -8.23, "draft_iters": 5.1, "mem_use": 36.84, "gen_rate": 3.6, "speed": 1.68, "text": "\\nI think there was a problem wi"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.6, "tree_w": 262, "tree_size": 512, "t0": 1.3912, "t1": 0.795, "tft": 2.9745, "input_0": 857, "input_1": 513, "min_CLP": -8.34, "draft_iters": 5.8, "mem_use": 36.01, "gen_rate": 4.2, "speed": 1.94, "text": "\"The first step is to capture a "}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.6, "tree_w": 266, "tree_size": 512, "t0": 1.38, "t1": 0.78, "tft": 2.7824, "input_0": 831, "input_1": 513, "min_CLP": -8.4, "draft_iters": 5.8, "mem_use": 35.65, "gen_rate": 4.4, "speed": 2.02, "text": "\\nI am looking for a free tool t"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 160, "tree_size": 512, "t0": 3.285, "t1": 0.78, "tft": 2.7839, "input_0": 1158, "input_1": 513, "min_CLP": -8.66, "draft_iters": 18.5, "mem_use": 35.64, "gen_rate": 17.5, "speed": 4.3, "text": "\\nDo you know how to speak Germa"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.4, "tree_w": 256, "tree_size": 512, "t0": 1.46, "t1": 0.7875, "tft": 2.7629, "input_0": 902, "input_1": 513, "min_CLP": -8.99, "draft_iters": 6.4, "mem_use": 35.78, "gen_rate": 4.2, "speed": 1.89, "text": "\\nYou can then run the command:\\"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 4.7, "tree_w": 280, "tree_size": 512, "t0": 1.7171, "t1": 0.8, "tft": 3.5613, "input_0": 1114, "input_1": 513, "min_CLP": -8.69, "draft_iters": 6.9, "mem_use": 36.2, "gen_rate": 5.0, "speed": 1.98, "text": "This depends on how many devices"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 297, "tree_size": 512, "t0": 1.2322, "t1": 0.82, "tft": 3.9223, "input_0": 815, "input_1": 513, "min_CLP": -9.51, "draft_iters": 5.0, "mem_use": 36.49, "gen_rate": 3.9, "speed": 1.9, "text": "\"Yes. You can use AI image gener"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.9, "tree_w": 285, "tree_size": 512, "t0": 1.4578, "t1": 0.78, "tft": 2.794, "input_0": 815, "input_1": 513, "min_CLP": -8.57, "draft_iters": 6.1, "mem_use": 35.66, "gen_rate": 3.8, "speed": 1.68, "text": "\"\\nI'm looking for a way to make"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 277, "tree_size": 512, "t0": 1.8471, "t1": 0.79, "tft": 2.8616, "input_0": 993, "input_1": 513, "min_CLP": -9.65, "draft_iters": 9.0, "mem_use": 35.9, "gen_rate": 5.0, "speed": 1.9, "text": "o\\n     /|\\\\\\n     / \\\\\\n[INST] "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 214, "tree_size": 512, "t0": 3.23, "t1": 0.78, "tft": 2.7804, "input_0": 1141, "input_1": 513, "min_CLP": -8.47, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.36, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 189, "tree_size": 512, "t0": 3.175, "t1": 0.79, "tft": 2.785, "input_0": 1083, "input_1": 513, "min_CLP": -8.35, "draft_iters": 18.5, "mem_use": 35.8, "gen_rate": 17.5, "speed": 4.42, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 271, "tree_size": 512, "t0": 1.2467, "t1": 0.7878, "tft": 2.775, "input_0": 831, "input_1": 513, "min_CLP": -8.32, "draft_iters": 5.1, "mem_use": 35.81, "gen_rate": 3.9, "speed": 1.91, "text": "\"So you're looking for a functio"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 198, "tree_size": 512, "t0": 2.8125, "t1": 0.84, "tft": 4.3888, "input_0": 1138, "input_1": 513, "min_CLP": -7.88, "draft_iters": 13.2, "mem_use": 36.86, "gen_rate": 8.0, "speed": 2.19, "text": "\\n1. Bake the pizza dough in the"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.3, "tree_w": 220, "tree_size": 512, "t0": 1.855, "t1": 0.7817, "tft": 2.8319, "input_0": 988, "input_1": 513, "min_CLP": -8.14, "draft_iters": 7.7, "mem_use": 35.74, "gen_rate": 5.3, "speed": 2.02, "text": "\\nA man is sitting on the couch "}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 290, "tree_size": 512, "t0": 1.2278, "t1": 0.8478, "tft": 4.8933, "input_0": 803, "input_1": 513, "min_CLP": -8.76, "draft_iters": 4.9, "mem_use": 37.19, "gen_rate": 3.9, "speed": 1.88, "text": "\\nYou are a young, beautiful, an"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 232, "tree_size": 512, "t0": 2.345, "t1": 0.7775, "tft": 2.7883, "input_0": 1102, "input_1": 513, "min_CLP": -8.95, "draft_iters": 11.5, "mem_use": 35.66, "gen_rate": 10.8, "speed": 3.44, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.8, "tree_w": 245, "tree_size": 512, "t0": 1.6425, "t1": 0.78, "tft": 2.7882, "input_0": 961, "input_1": 513, "min_CLP": -8.38, "draft_iters": 6.9, "mem_use": 35.66, "gen_rate": 4.2, "speed": 1.75, "text": "\\nThe difference between HTML an"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 209, "tree_size": 512, "t0": 3.2, "t1": 0.785, "tft": 2.7779, "input_0": 1153, "input_1": 513, "min_CLP": -8.48, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.4, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 252, "tree_size": 512, "t0": 2.0467, "t1": 0.7883, "tft": 2.8591, "input_0": 1074, "input_1": 513, "min_CLP": -8.5, "draft_iters": 9.5, "mem_use": 35.86, "gen_rate": 8.7, "speed": 3.06, "text": "The image is copyrighted and you"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.0, "tree_w": 271, "tree_size": 512, "t0": 1.6356, "t1": 0.78, "tft": 2.7868, "input_0": 882, "input_1": 513, "min_CLP": -8.36, "draft_iters": 8.0, "mem_use": 35.64, "gen_rate": 3.9, "speed": 1.61, "text": "\\n[SYS] <<SYS>>\\nI think the rea"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.9, "tree_w": 260, "tree_size": 512, "t0": 1.465, "t1": 0.8, "tft": 3.5328, "input_0": 930, "input_1": 513, "min_CLP": -8.59, "draft_iters": 6.0, "mem_use": 36.16, "gen_rate": 4.4, "speed": 1.93, "text": "\\nwhat is the point of life? [\\\\"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 8.1, "tree_w": 223, "tree_size": 512, "t0": 2.1689, "t1": 0.8, "tft": 3.5349, "input_0": 934, "input_1": 513, "min_CLP": -8.22, "draft_iters": 10.4, "mem_use": 36.05, "gen_rate": 4.0, "speed": 1.35, "text": "[INST]\\n<</INST>\\n\\nI am an unco"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.0, "tree_w": 274, "tree_size": 512, "t0": 1.2156, "t1": 0.7922, "tft": 2.9594, "input_0": 791, "input_1": 513, "min_CLP": -8.23, "draft_iters": 5.0, "mem_use": 35.98, "gen_rate": 3.7, "speed": 1.83, "text": "\"I'm not sure if being a good pe"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 7.0, "tree_w": 211, "tree_size": 512, "t0": 2.1629, "t1": 0.8071, "tft": 3.5518, "input_0": 1052, "input_1": 513, "min_CLP": -8.06, "draft_iters": 9.3, "mem_use": 36.33, "gen_rate": 5.9, "speed": 1.97, "text": "\\nHow can we live with meaning a"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.4, "tree_w": 241, "tree_size": 512, "t0": 2.024, "t1": 0.78, "tft": 2.7759, "input_0": 968, "input_1": 513, "min_CLP": -8.85, "draft_iters": 10.4, "mem_use": 35.65, "gen_rate": 8.2, "speed": 2.92, "text": "\\n<<SYS>>\\nMake an ASCII art of "}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 273, "tree_size": 512, "t0": 1.2975, "t1": 0.79, "tft": 2.7863, "input_0": 891, "input_1": 513, "min_CLP": -9.04, "draft_iters": 5.2, "mem_use": 35.82, "gen_rate": 4.2, "speed": 2.04, "text": "\"\\nWhat does the [\\\\INST] stand "}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 271, "tree_size": 512, "t0": 1.265, "t1": 0.8, "tft": 3.5529, "input_0": 840, "input_1": 513, "min_CLP": -9.03, "draft_iters": 5.1, "mem_use": 36.16, "gen_rate": 4.0, "speed": 1.94, "text": "The James Webb telescope is expe"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 61, "tree_h": 6.6, "tree_w": 237, "tree_size": 512, "t0": 1.895, "t1": 0.78, "tft": 2.8097, "input_0": 1050, "input_1": 513, "min_CLP": -10.77, "draft_iters": 8.6, "mem_use": 35.72, "gen_rate": 7.6, "speed": 2.85, "text": "\"\\nHello there Obi One Kenobi [\\"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 44, "tree_h": 9.8, "tree_w": 237, "tree_size": 512, "t0": 2.5175, "t1": 0.82, "tft": 3.9977, "input_0": 1099, "input_1": 513, "min_CLP": -8.41, "draft_iters": 11.8, "mem_use": 36.55, "gen_rate": 5.5, "speed": 1.65, "text": "\"\\nSure, no problem. Here's a re"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 233, "tree_size": 512, "t0": 2.1183, "t1": 0.7783, "tft": 2.8111, "input_0": 1015, "input_1": 513, "min_CLP": -9.79, "draft_iters": 9.5, "mem_use": 35.69, "gen_rate": 8.5, "speed": 2.93, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 136, "tree_size": 512, "t0": 3.76, "t1": 0.78, "tft": 2.8606, "input_0": 1431, "input_1": 513, "min_CLP": -9.03, "draft_iters": 18.5, "mem_use": 35.86, "gen_rate": 17.5, "speed": 3.85, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 278, "tree_size": 512, "t0": 1.63, "t1": 0.82, "tft": 3.9184, "input_0": 954, "input_1": 513, "min_CLP": -8.94, "draft_iters": 7.1, "mem_use": 36.54, "gen_rate": 4.4, "speed": 1.79, "text": "AI assistants are becoming incre"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.0, "tree_w": 250, "tree_size": 512, "t0": 1.8133, "t1": 0.8317, "tft": 4.0784, "input_0": 989, "input_1": 513, "min_CLP": -8.51, "draft_iters": 7.3, "mem_use": 36.73, "gen_rate": 5.3, "speed": 2.02, "text": "Paul Allen has a number of diffe"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 235, "tree_size": 512, "t0": 1.9214, "t1": 0.8114, "tft": 3.8982, "input_0": 1095, "input_1": 513, "min_CLP": -8.02, "draft_iters": 8.1, "mem_use": 36.43, "gen_rate": 5.0, "speed": 1.83, "text": "\\nI do not know of any internati"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 237, "tree_size": 512, "t0": 1.7729, "t1": 0.78, "tft": 2.7965, "input_0": 1043, "input_1": 513, "min_CLP": -8.66, "draft_iters": 7.7, "mem_use": 35.68, "gen_rate": 4.6, "speed": 1.79, "text": "\\nRomeo is the most to blame for"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.8, "tree_w": 272, "tree_size": 512, "t0": 1.44, "t1": 0.8, "tft": 3.5565, "input_0": 892, "input_1": 513, "min_CLP": -8.18, "draft_iters": 6.0, "mem_use": 36.01, "gen_rate": 3.7, "speed": 1.64, "text": "I am not sure. I think it would "}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 237, "tree_size": 512, "t0": 2.1683, "t1": 0.7867, "tft": 2.8089, "input_0": 1100, "input_1": 513, "min_CLP": -11.5, "draft_iters": 9.5, "mem_use": 35.67, "gen_rate": 5.8, "speed": 1.98, "text": "\\nWhat are the main methods used"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.3, "tree_w": 262, "tree_size": 512, "t0": 1.5257, "t1": 0.78, "tft": 2.7778, "input_0": 982, "input_1": 513, "min_CLP": -8.27, "draft_iters": 6.3, "mem_use": 35.65, "gen_rate": 4.7, "speed": 2.04, "text": "\\nA guy walks into a bar with a "}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 260, "tree_size": 512, "t0": 2.0537, "t1": 0.8, "tft": 3.193, "input_0": 1086, "input_1": 513, "min_CLP": -12.6, "draft_iters": 8.5, "mem_use": 36.02, "gen_rate": 7.5, "speed": 2.63, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.0, "tree_w": 242, "tree_size": 512, "t0": 1.7786, "t1": 0.8186, "tft": 3.9145, "input_0": 1087, "input_1": 513, "min_CLP": -8.09, "draft_iters": 7.1, "mem_use": 36.48, "gen_rate": 4.6, "speed": 1.76, "text": "\"You cannot stop someone's metab"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.8, "tree_w": 283, "tree_size": 512, "t0": 1.5038, "t1": 0.84, "tft": 4.4124, "input_0": 909, "input_1": 513, "min_CLP": -9.54, "draft_iters": 6.0, "mem_use": 36.9, "gen_rate": 4.1, "speed": 1.76, "text": "\\nThe \"multi-track drifting\" sol"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.8, "tree_w": 258, "tree_size": 512, "t0": 1.4675, "t1": 0.8, "tft": 3.548, "input_0": 867, "input_1": 513, "min_CLP": -8.26, "draft_iters": 6.0, "mem_use": 36.22, "gen_rate": 4.0, "speed": 1.76, "text": "\\nPurple skies are not possible."}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 264, "tree_size": 512, "t0": 1.63, "t1": 0.8, "tft": 3.5447, "input_0": 981, "input_1": 513, "min_CLP": -8.49, "draft_iters": 7.0, "mem_use": 36.16, "gen_rate": 4.7, "speed": 1.94, "text": "\"\\nYou are the light of my life,"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 280, "tree_size": 512, "t0": 1.2525, "t1": 0.8, "tft": 3.4976, "input_0": 826, "input_1": 513, "min_CLP": -8.71, "draft_iters": 5.1, "mem_use": 36.13, "gen_rate": 4.1, "speed": 2.01, "text": "Japanese has three words for lov"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.3, "tree_w": 252, "tree_size": 512, "t0": 1.5757, "t1": 0.7843, "tft": 2.7668, "input_0": 991, "input_1": 513, "min_CLP": -8.21, "draft_iters": 6.4, "mem_use": 35.8, "gen_rate": 4.9, "speed": 2.06, "text": "Some of the best schools are in "}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 274, "tree_size": 512, "t0": 1.2462, "t1": 0.7813, "tft": 2.7777, "input_0": 835, "input_1": 513, "min_CLP": -10.49, "draft_iters": 5.1, "mem_use": 35.64, "gen_rate": 4.1, "speed": 2.03, "text": "\\nwhy the sky is blue? [\\\\INST]\\"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 7.5, "tree_w": 246, "tree_size": 512, "t0": 1.955, "t1": 0.7825, "tft": 2.8114, "input_0": 1122, "input_1": 513, "min_CLP": -9.01, "draft_iters": 9.2, "mem_use": 35.71, "gen_rate": 8.2, "speed": 3.02, "text": "\\nWrite a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 288, "tree_size": 512, "t0": 1.225, "t1": 0.8025, "tft": 3.5693, "input_0": 808, "input_1": 513, "min_CLP": -8.45, "draft_iters": 5.0, "mem_use": 36.27, "gen_rate": 4.0, "speed": 1.97, "text": "1. Make sure that you have a job"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 6.9, "tree_w": 249, "tree_size": 512, "t0": 1.8229, "t1": 0.7814, "tft": 2.7785, "input_0": 938, "input_1": 513, "min_CLP": -9.14, "draft_iters": 8.6, "mem_use": 35.66, "gen_rate": 7.7, "speed": 2.96, "text": "\\nwhat should i call you? [\\\\INS"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.0, "tree_w": 267, "tree_size": 512, "t0": 1.575, "t1": 0.84, "tft": 4.6368, "input_0": 939, "input_1": 513, "min_CLP": -8.61, "draft_iters": 6.1, "mem_use": 37.04, "gen_rate": 4.2, "speed": 1.76, "text": "In Python, you can use a set for"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 57, "tree_h": 7.1, "tree_w": 244, "tree_size": 512, "t0": 2.0529, "t1": 0.7814, "tft": 2.7571, "input_0": 1066, "input_1": 513, "min_CLP": -9.42, "draft_iters": 9.1, "mem_use": 35.75, "gen_rate": 8.1, "speed": 2.87, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 221, "tree_size": 512, "t0": 2.6075, "t1": 0.78, "tft": 2.7944, "input_0": 1155, "input_1": 513, "min_CLP": -9.21, "draft_iters": 11.8, "mem_use": 35.71, "gen_rate": 10.8, "speed": 3.17, "text": "\\nWhat is the name of the window"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 163, "tree_size": 512, "t0": 3.705, "t1": 0.835, "tft": 4.4049, "input_0": 1321, "input_1": 513, "min_CLP": -9.05, "draft_iters": 18.5, "mem_use": 36.84, "gen_rate": 17.0, "speed": 3.74, "text": "Monstermash.zone: offers a free "}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 159, "tree_size": 512, "t0": 3.85, "t1": 0.78, "tft": 2.7901, "input_0": 1418, "input_1": 513, "min_CLP": -8.43, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 3.78, "text": "\\nHow can I use software defined"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.2, "tree_w": 241, "tree_size": 512, "t0": 1.8956, "t1": 0.7989, "tft": 3.579, "input_0": 957, "input_1": 513, "min_CLP": -9.64, "draft_iters": 9.3, "mem_use": 36.02, "gen_rate": 3.9, "speed": 1.44, "text": "\"No, it's a hypothetical problem"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 153, "tree_size": 512, "t0": 3.585, "t1": 0.82, "tft": 3.9151, "input_0": 1097, "input_1": 513, "min_CLP": -8.8, "draft_iters": 18.5, "mem_use": 36.48, "gen_rate": 17.0, "speed": 3.86, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 230, "tree_size": 512, "t0": 2.47, "t1": 0.7825, "tft": 2.7818, "input_0": 1141, "input_1": 513, "min_CLP": -9.06, "draft_iters": 11.5, "mem_use": 35.81, "gen_rate": 10.8, "speed": 3.3, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 269, "tree_size": 512, "t0": 1.2544, "t1": 0.8378, "tft": 4.5826, "input_0": 787, "input_1": 513, "min_CLP": -8.39, "draft_iters": 5.0, "mem_use": 37.01, "gen_rate": 3.9, "speed": 1.86, "text": "If the table is too big to be po"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 173, "tree_size": 512, "t0": 3.335, "t1": 0.78, "tft": 2.7763, "input_0": 1134, "input_1": 513, "min_CLP": -8.61, "draft_iters": 18.5, "mem_use": 35.65, "gen_rate": 17.5, "speed": 4.25, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 257, "tree_size": 512, "t0": 2.2083, "t1": 0.8217, "tft": 4.0661, "input_0": 1055, "input_1": 513, "min_CLP": -11.94, "draft_iters": 9.5, "mem_use": 36.68, "gen_rate": 8.5, "speed": 2.8, "text": "\\n[INST] You are a helpful, resp"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.4, "tree_w": 244, "tree_size": 512, "t0": 1.5629, "t1": 0.7814, "tft": 2.78, "input_0": 904, "input_1": 513, "min_CLP": -9.3, "draft_iters": 6.6, "mem_use": 35.65, "gen_rate": 4.7, "speed": 2.01, "text": "\\nThe Pacific Ocean.\\n\\nThe Atla"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.6, "tree_w": 263, "tree_size": 512, "t0": 1.41, "t1": 0.79, "tft": 2.8678, "input_0": 847, "input_1": 513, "min_CLP": -8.14, "draft_iters": 5.8, "mem_use": 35.9, "gen_rate": 3.8, "speed": 1.72, "text": "\"Of course, they won't. AI assis"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 58, "tree_h": 10.9, "tree_w": 225, "tree_size": 512, "t0": 2.8886, "t1": 0.9071, "tft": 6.8322, "input_0": 1160, "input_1": 513, "min_CLP": -8.96, "draft_iters": 12.9, "mem_use": 38.53, "gen_rate": 8.3, "speed": 2.18, "text": "\"[Verse 1]\\nYou're a helpful, re"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 4.2, "tree_w": 254, "tree_size": 512, "t0": 1.5, "t1": 0.8, "tft": 3.508, "input_0": 866, "input_1": 513, "min_CLP": -8.11, "draft_iters": 6.3, "mem_use": 36.08, "gen_rate": 4.6, "speed": 1.98, "text": "0 it is a lawyer who is not your"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 29, "tree_size": 512, "t0": 8.065, "t1": 0.84, "tft": 8.6903, "input_0": 2667, "input_1": 513, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 37.19, "gen_rate": 30.5, "speed": 3.42, "text": "\\nPretend to be a business profe"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 4.3, "tree_w": 242, "tree_size": 512, "t0": 1.5183, "t1": 0.8, "tft": 3.5496, "input_0": 859, "input_1": 513, "min_CLP": -8.18, "draft_iters": 6.5, "mem_use": 36.17, "gen_rate": 5.3, "speed": 2.3, "text": "1. The restaurant is located in "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.0, "tree_w": 266, "tree_size": 512, "t0": 1.212, "t1": 0.787, "tft": 2.7836, "input_0": 779, "input_1": 513, "min_CLP": -8.48, "draft_iters": 5.0, "mem_use": 35.82, "gen_rate": 3.5, "speed": 1.75, "text": "\\nWrite a screenplay for a movie"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.0, "tree_w": 260, "tree_size": 512, "t0": 1.79, "t1": 0.8417, "tft": 4.6324, "input_0": 1054, "input_1": 513, "min_CLP": -9.35, "draft_iters": 7.0, "mem_use": 37.08, "gen_rate": 5.3, "speed": 2.03, "text": "It is difficult to compare the e"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 273, "tree_size": 512, "t0": 1.2188, "t1": 0.7888, "tft": 2.8715, "input_0": 792, "input_1": 513, "min_CLP": -8.26, "draft_iters": 5.0, "mem_use": 35.88, "gen_rate": 4.0, "speed": 1.99, "text": "The average energy usage for a h"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.8, "tree_w": 167, "tree_size": 512, "t0": 3.688, "t1": 0.836, "tft": 4.5574, "input_0": 1312, "input_1": 513, "min_CLP": -8.06, "draft_iters": 18.2, "mem_use": 36.92, "gen_rate": 7.2, "speed": 1.59, "text": "Creating a reinforcement learnin"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 186, "tree_size": 512, "t0": 3.2, "t1": 0.785, "tft": 2.7772, "input_0": 1112, "input_1": 513, "min_CLP": -8.59, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.39, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.0, "tree_w": 267, "tree_size": 512, "t0": 1.7783, "t1": 0.8, "tft": 3.5767, "input_0": 1082, "input_1": 513, "min_CLP": -8.83, "draft_iters": 8.0, "mem_use": 36.03, "gen_rate": 5.3, "speed": 2.07, "text": "The first law regarding public n"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 210, "tree_size": 512, "t0": 3.03, "t1": 0.79, "tft": 2.8684, "input_0": 992, "input_1": 513, "min_CLP": -8.33, "draft_iters": 18.5, "mem_use": 35.86, "gen_rate": 17.5, "speed": 4.58, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 264, "tree_size": 512, "t0": 1.2138, "t1": 0.78, "tft": 2.8061, "input_0": 768, "input_1": 513, "min_CLP": -8.46, "draft_iters": 5.0, "mem_use": 35.68, "gen_rate": 4.0, "speed": 2.0, "text": "\\nThis is the code to create a s"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.8, "tree_w": 257, "tree_size": 512, "t0": 1.6863, "t1": 0.8, "tft": 3.541, "input_0": 970, "input_1": 513, "min_CLP": -8.36, "draft_iters": 7.0, "mem_use": 36.14, "gen_rate": 4.5, "speed": 1.81, "text": "\"You don't have to know everythi"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 7.8, "tree_w": 196, "tree_size": 512, "t0": 2.365, "t1": 0.84, "tft": 4.559, "input_0": 1215, "input_1": 513, "min_CLP": -8.65, "draft_iters": 10.2, "mem_use": 36.92, "gen_rate": 8.2, "speed": 2.57, "text": "The most important Chinese chara"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.1, "tree_w": 241, "tree_size": 512, "t0": 1.4688, "t1": 0.78, "tft": 2.8262, "input_0": 880, "input_1": 513, "min_CLP": -8.61, "draft_iters": 6.2, "mem_use": 35.72, "gen_rate": 4.4, "speed": 1.94, "text": "\\nif you have a car that gets 25"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 183, "tree_size": 512, "t0": 3.24, "t1": 0.78, "tft": 2.8147, "input_0": 1160, "input_1": 513, "min_CLP": -8.65, "draft_iters": 18.5, "mem_use": 35.7, "gen_rate": 17.5, "speed": 4.35, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 179, "tree_size": 512, "t0": 3.24, "t1": 0.78, "tft": 2.7885, "input_0": 1123, "input_1": 513, "min_CLP": -8.59, "draft_iters": 18.5, "mem_use": 35.65, "gen_rate": 17.5, "speed": 4.35, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 266, "tree_size": 512, "t0": 1.3778, "t1": 0.8756, "tft": 5.7748, "input_0": 882, "input_1": 513, "min_CLP": -8.22, "draft_iters": 5.2, "mem_use": 37.86, "gen_rate": 3.8, "speed": 1.68, "text": "\"TypeScript is a superset of Jav"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.5, "tree_w": 274, "tree_size": 512, "t0": 1.332, "t1": 0.783, "tft": 2.8014, "input_0": 864, "input_1": 513, "min_CLP": -8.76, "draft_iters": 5.5, "mem_use": 35.68, "gen_rate": 3.4, "speed": 1.61, "text": "\\nA woman stands in a forest, wi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 207, "tree_size": 512, "t0": 3.11, "t1": 0.8, "tft": 3.5512, "input_0": 1104, "input_1": 513, "min_CLP": -12.15, "draft_iters": 18.5, "mem_use": 36.2, "gen_rate": 17.5, "speed": 4.47, "text": "\\n[SYS]\\nYou are a helpful, resp"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.2, "tree_w": 272, "tree_size": 512, "t0": 1.33, "t1": 0.8478, "tft": 4.9029, "input_0": 878, "input_1": 513, "min_CLP": -8.89, "draft_iters": 5.2, "mem_use": 37.2, "gen_rate": 3.7, "speed": 1.68, "text": "Time the bread for as long as it"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 136, "tree_size": 512, "t0": 3.73, "t1": 0.78, "tft": 2.8364, "input_0": 1439, "input_1": 513, "min_CLP": -8.95, "draft_iters": 18.5, "mem_use": 35.74, "gen_rate": 17.5, "speed": 3.88, "text": "\"\\nI have a project due in 2 wee"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 58, "tree_h": 6.6, "tree_w": 242, "tree_size": 512, "t0": 2.1025, "t1": 0.7987, "tft": 3.5566, "input_0": 952, "input_1": 513, "min_CLP": -9.35, "draft_iters": 9.0, "mem_use": 36.03, "gen_rate": 7.2, "speed": 2.5, "text": "\\nThere is a problem with the li"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 277, "tree_size": 512, "t0": 1.385, "t1": 0.84, "tft": 4.5564, "input_0": 944, "input_1": 513, "min_CLP": -8.94, "draft_iters": 5.4, "mem_use": 36.91, "gen_rate": 4.4, "speed": 1.97, "text": "If you would like to attend one "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 233, "tree_size": 512, "t0": 2.1857, "t1": 0.8, "tft": 3.5385, "input_0": 1176, "input_1": 513, "min_CLP": -8.07, "draft_iters": 8.9, "mem_use": 36.08, "gen_rate": 4.7, "speed": 1.58, "text": "The first television was invente"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 230, "tree_size": 512, "t0": 2.835, "t1": 0.85, "tft": 4.9097, "input_0": 1303, "input_1": 513, "min_CLP": -9.38, "draft_iters": 11.8, "mem_use": 37.24, "gen_rate": 10.8, "speed": 2.92, "text": "\\nThe wireless Internet signal i"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.4, "tree_w": 263, "tree_size": 512, "t0": 1.6275, "t1": 0.8113, "tft": 3.8734, "input_0": 969, "input_1": 513, "min_CLP": -8.28, "draft_iters": 6.6, "mem_use": 36.39, "gen_rate": 4.5, "speed": 1.84, "text": "The day of Christmas is not a fi"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 8.4, "tree_w": 241, "tree_size": 512, "t0": 2.002, "t1": 0.79, "tft": 2.9391, "input_0": 915, "input_1": 513, "min_CLP": -9.47, "draft_iters": 10.4, "mem_use": 35.93, "gen_rate": 9.4, "speed": 3.36, "text": "\"\\nReply to this message with a "}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 12.0, "tree_w": 226, "tree_size": 512, "t0": 3.1833, "t1": 0.8367, "tft": 4.3776, "input_0": 1324, "input_1": 513, "min_CLP": -9.86, "draft_iters": 14.0, "mem_use": 36.83, "gen_rate": 12.7, "speed": 3.15, "text": "Learning how to write Chinese ch"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 133, "tree_size": 512, "t0": 3.715, "t1": 0.775, "tft": 2.828, "input_0": 1414, "input_1": 513, "min_CLP": -8.94, "draft_iters": 18.5, "mem_use": 35.72, "gen_rate": 17.5, "speed": 3.89, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.8, "tree_w": 251, "tree_size": 512, "t0": 1.8025, "t1": 0.8, "tft": 3.5391, "input_0": 924, "input_1": 513, "min_CLP": -8.41, "draft_iters": 8.9, "mem_use": 36.13, "gen_rate": 5.1, "speed": 1.97, "text": "\"I was just trying to get you to"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 57, "tree_h": 10.1, "tree_w": 215, "tree_size": 512, "t0": 2.5914, "t1": 0.7857, "tft": 2.7749, "input_0": 1068, "input_1": 513, "min_CLP": -8.79, "draft_iters": 12.6, "mem_use": 35.8, "gen_rate": 8.1, "speed": 2.41, "text": "I would say \"I\\'m a broke colleg"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 217, "tree_size": 512, "t0": 2.0414, "t1": 0.7857, "tft": 2.7731, "input_0": 1012, "input_1": 513, "min_CLP": -8.63, "draft_iters": 9.3, "mem_use": 35.78, "gen_rate": 4.6, "speed": 1.62, "text": "\\nI would like to see what the e"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.6, "tree_w": 266, "tree_size": 512, "t0": 1.4238, "t1": 0.7962, "tft": 2.9711, "input_0": 881, "input_1": 513, "min_CLP": -8.05, "draft_iters": 5.8, "mem_use": 36.0, "gen_rate": 4.4, "speed": 1.97, "text": "Google Authenticator is an appli"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.2, "tree_w": 278, "tree_size": 512, "t0": 1.3, "t1": 0.79, "tft": 2.8703, "input_0": 899, "input_1": 513, "min_CLP": -8.36, "draft_iters": 5.2, "mem_use": 35.9, "gen_rate": 4.0, "speed": 1.91, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 194, "tree_size": 512, "t0": 3.09, "t1": 0.79, "tft": 2.8381, "input_0": 1062, "input_1": 513, "min_CLP": -8.45, "draft_iters": 18.5, "mem_use": 35.75, "gen_rate": 17.5, "speed": 4.52, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.1, "tree_w": 289, "tree_size": 512, "t0": 1.24, "t1": 0.7844, "tft": 2.8084, "input_0": 850, "input_1": 513, "min_CLP": -9.21, "draft_iters": 5.1, "mem_use": 35.68, "gen_rate": 3.6, "speed": 1.76, "text": "\\nHow can I improve my Wi-Fi cov"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 12.0, "tree_w": 206, "tree_size": 512, "t0": 2.6133, "t1": 0.7833, "tft": 2.8042, "input_0": 1098, "input_1": 513, "min_CLP": -8.86, "draft_iters": 14.0, "mem_use": 35.69, "gen_rate": 12.7, "speed": 3.73, "text": "\\nWrite me a program that takes "}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 250, "tree_size": 512, "t0": 1.6975, "t1": 0.7838, "tft": 2.7896, "input_0": 908, "input_1": 513, "min_CLP": -8.63, "draft_iters": 7.5, "mem_use": 35.67, "gen_rate": 4.4, "speed": 1.76, "text": "\\nby Kunji\\n\\nThe world of finan"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.0, "tree_w": 281, "tree_size": 512, "t0": 1.23, "t1": 0.8078, "tft": 3.5647, "input_0": 802, "input_1": 513, "min_CLP": -9.63, "draft_iters": 5.0, "mem_use": 36.3, "gen_rate": 3.8, "speed": 1.85, "text": "You can use the rsync command to"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.7, "tree_w": 282, "tree_size": 512, "t0": 1.4111, "t1": 0.78, "tft": 2.7767, "input_0": 853, "input_1": 513, "min_CLP": -8.39, "draft_iters": 5.9, "mem_use": 35.62, "gen_rate": 3.9, "speed": 1.77, "text": "\"\\nso far, I have been able to a"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 188, "tree_size": 512, "t0": 3.27, "t1": 0.78, "tft": 2.7805, "input_0": 1117, "input_1": 513, "min_CLP": -8.53, "draft_iters": 18.5, "mem_use": 35.64, "gen_rate": 17.5, "speed": 4.32, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.4, "tree_w": 253, "tree_size": 512, "t0": 1.3833, "t1": 0.7889, "tft": 2.7714, "input_0": 820, "input_1": 513, "min_CLP": -8.34, "draft_iters": 5.6, "mem_use": 35.78, "gen_rate": 3.7, "speed": 1.69, "text": "\\nYou make \"friends\" with people"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.2, "tree_w": 214, "tree_size": 512, "t0": 2.214, "t1": 0.786, "tft": 2.7952, "input_0": 1004, "input_1": 513, "min_CLP": -9.02, "draft_iters": 10.4, "mem_use": 35.66, "gen_rate": 6.6, "speed": 2.2, "text": "\\n<SYS>\\n\\n<INST>\\n\\n<SYS>\\n\\n<S"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 247, "tree_size": 512, "t0": 1.7167, "t1": 0.7989, "tft": 3.5332, "input_0": 982, "input_1": 513, "min_CLP": -9.03, "draft_iters": 7.9, "mem_use": 36.02, "gen_rate": 3.7, "speed": 1.46, "text": "\"\\nIn the context of a hypothesi"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 63, "tree_h": 12.1, "tree_w": 205, "tree_size": 512, "t0": 2.8, "t1": 0.8533, "tft": 5.0563, "input_0": 1036, "input_1": 513, "min_CLP": -8.79, "draft_iters": 14.0, "mem_use": 37.32, "gen_rate": 7.0, "speed": 1.92, "text": "\"\\nWhat's the current time? [\\\\I"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 250, "tree_size": 512, "t0": 1.7425, "t1": 0.7937, "tft": 2.9413, "input_0": 949, "input_1": 513, "min_CLP": -8.37, "draft_iters": 8.4, "mem_use": 35.95, "gen_rate": 4.2, "speed": 1.68, "text": "Decorators allow you to add extr"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 276, "tree_size": 512, "t0": 1.285, "t1": 0.82, "tft": 3.9115, "input_0": 886, "input_1": 513, "min_CLP": -9.52, "draft_iters": 5.1, "mem_use": 36.48, "gen_rate": 4.2, "speed": 2.02, "text": "[INST] I am [\\\\INST]\\n[INST] I a"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 11.0, "tree_w": 241, "tree_size": 512, "t0": 2.738, "t1": 0.792, "tft": 2.9427, "input_0": 1094, "input_1": 513, "min_CLP": -10.79, "draft_iters": 13.6, "mem_use": 35.95, "gen_rate": 12.0, "speed": 3.4, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.9, "tree_w": 270, "tree_size": 512, "t0": 1.4729, "t1": 0.8743, "tft": 5.7404, "input_0": 864, "input_1": 513, "min_CLP": -8.25, "draft_iters": 5.9, "mem_use": 37.84, "gen_rate": 4.6, "speed": 1.95, "text": "\\nJIT compiled languages are usu"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.3, "tree_w": 257, "tree_size": 512, "t0": 1.897, "t1": 1.02, "tft": 10.1511, "input_0": 886, "input_1": 513, "min_CLP": -8.5, "draft_iters": 6.5, "mem_use": 40.54, "gen_rate": 3.6, "speed": 1.23, "text": "\"Thanks. I'm happy to share some"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 250, "tree_size": 512, "t0": 1.78, "t1": 0.8213, "tft": 4.0168, "input_0": 898, "input_1": 513, "min_CLP": -9.52, "draft_iters": 7.4, "mem_use": 36.67, "gen_rate": 4.1, "speed": 1.59, "text": "\"L'H\u00f4pital's Rule is used in the"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.4, "tree_w": 251, "tree_size": 512, "t0": 1.5843, "t1": 0.78, "tft": 2.7961, "input_0": 1023, "input_1": 513, "min_CLP": -8.48, "draft_iters": 6.4, "mem_use": 35.67, "gen_rate": 4.6, "speed": 1.93, "text": "\\nI am a [\\\\INST] candidate for "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 290, "tree_size": 512, "t0": 1.25, "t1": 0.7813, "tft": 2.7927, "input_0": 852, "input_1": 513, "min_CLP": -10.66, "draft_iters": 5.1, "mem_use": 35.71, "gen_rate": 4.1, "speed": 2.03, "text": "\\nIn TypeScript, how can I tell "}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.6, "tree_w": 251, "tree_size": 512, "t0": 1.4425, "t1": 0.8487, "tft": 4.9152, "input_0": 820, "input_1": 513, "min_CLP": -8.0, "draft_iters": 5.8, "mem_use": 37.14, "gen_rate": 4.0, "speed": 1.75, "text": "\"\\nIf you want to learn more abo"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 256, "tree_size": 512, "t0": 1.8813, "t1": 0.7825, "tft": 2.8011, "input_0": 1014, "input_1": 513, "min_CLP": -10.15, "draft_iters": 8.4, "mem_use": 35.68, "gen_rate": 7.5, "speed": 2.81, "text": "\\nGive me some impression of wha"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 291, "tree_size": 512, "t0": 1.4275, "t1": 0.9013, "tft": 6.6323, "input_0": 906, "input_1": 513, "min_CLP": -8.91, "draft_iters": 5.2, "mem_use": 38.3, "gen_rate": 4.2, "speed": 1.83, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.7, "tree_w": 271, "tree_size": 512, "t0": 1.4514, "t1": 0.7886, "tft": 2.8561, "input_0": 886, "input_1": 513, "min_CLP": -8.27, "draft_iters": 5.9, "mem_use": 35.86, "gen_rate": 4.6, "speed": 2.04, "text": "\"You will need to install the PS"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 4.5, "tree_w": 265, "tree_size": 512, "t0": 1.5983, "t1": 0.7883, "tft": 2.7608, "input_0": 987, "input_1": 513, "min_CLP": -8.17, "draft_iters": 6.7, "mem_use": 35.79, "gen_rate": 5.3, "speed": 2.24, "text": "\"CMU's robotics program is one o"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.9, "tree_w": 258, "tree_size": 512, "t0": 1.445, "t1": 0.79, "tft": 2.8391, "input_0": 880, "input_1": 513, "min_CLP": -8.32, "draft_iters": 6.0, "mem_use": 35.84, "gen_rate": 4.1, "speed": 1.85, "text": "ChatGPT is a centralized system,"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.3, "tree_w": 193, "tree_size": 512, "t0": 2.7583, "t1": 0.81, "tft": 3.9039, "input_0": 1291, "input_1": 513, "min_CLP": -7.47, "draft_iters": 11.3, "mem_use": 36.45, "gen_rate": 6.5, "speed": 1.82, "text": "The performance of a machine lar"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 251, "tree_size": 512, "t0": 1.8683, "t1": 0.79, "tft": 2.8425, "input_0": 882, "input_1": 513, "min_CLP": -10.08, "draft_iters": 9.5, "mem_use": 35.81, "gen_rate": 5.3, "speed": 2.01, "text": "\\n[INST] <<SYS>>\\n\\n[INST] <<SYS"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 60, "tree_h": 6.3, "tree_w": 262, "tree_size": 512, "t0": 2.0156, "t1": 0.7944, "tft": 2.9422, "input_0": 1066, "input_1": 513, "min_CLP": -9.07, "draft_iters": 8.6, "mem_use": 35.93, "gen_rate": 6.7, "speed": 2.37, "text": "chili powder\\n\\nI want to make a"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 4.9, "tree_w": 250, "tree_size": 512, "t0": 1.7543, "t1": 0.7971, "tft": 2.9631, "input_0": 1032, "input_1": 513, "min_CLP": -8.13, "draft_iters": 7.1, "mem_use": 35.95, "gen_rate": 5.0, "speed": 1.96, "text": "Not really. You can try to go to"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.3, "tree_w": 235, "tree_size": 512, "t0": 1.9386, "t1": 0.8357, "tft": 4.555, "input_0": 1006, "input_1": 513, "min_CLP": -7.96, "draft_iters": 7.6, "mem_use": 36.91, "gen_rate": 5.3, "speed": 1.91, "text": "\u2022 Start with beginners videos. T"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 205, "tree_size": 512, "t0": 3.035, "t1": 0.78, "tft": 2.7795, "input_0": 1098, "input_1": 513, "min_CLP": -8.55, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.58, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 16.5, "tree_w": 187, "tree_size": 512, "t0": 3.37, "t1": 0.78, "tft": 2.8113, "input_0": 1167, "input_1": 513, "min_CLP": -8.52, "draft_iters": 18.5, "mem_use": 35.7, "gen_rate": 16.0, "speed": 3.85, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 6.9, "tree_w": 254, "tree_size": 512, "t0": 2.0871, "t1": 0.8157, "tft": 3.9383, "input_0": 1042, "input_1": 513, "min_CLP": -11.1, "draft_iters": 8.9, "mem_use": 36.49, "gen_rate": 5.9, "speed": 2.02, "text": "Statistical modeling = applying "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 55, "tree_h": 6.9, "tree_w": 248, "tree_size": 512, "t0": 2.0971, "t1": 0.8386, "tft": 4.5799, "input_0": 1020, "input_1": 513, "min_CLP": -13.48, "draft_iters": 8.9, "mem_use": 37.02, "gen_rate": 7.9, "speed": 2.68, "text": "\\n\"Ah, the power of magic. The v"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 293, "tree_size": 512, "t0": 1.2037, "t1": 0.78, "tft": 2.7769, "input_0": 810, "input_1": 513, "min_CLP": -9.72, "draft_iters": 5.0, "mem_use": 35.63, "gen_rate": 4.0, "speed": 2.02, "text": "\\nWill the world end today? [\\\\I"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 303, "tree_size": 512, "t0": 1.1875, "t1": 0.8413, "tft": 3.8894, "input_0": 865, "input_1": 513, "min_CLP": -8.71, "draft_iters": 4.9, "mem_use": 36.38, "gen_rate": 4.0, "speed": 1.97, "text": "\"\\nI'm glad that this method is "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 11.2, "tree_w": 205, "tree_size": 512, "t0": 2.6017, "t1": 0.785, "tft": 2.8318, "input_0": 1208, "input_1": 513, "min_CLP": -9.04, "draft_iters": 13.3, "mem_use": 35.83, "gen_rate": 8.0, "speed": 2.36, "text": "\"Sure!\\nTechnology is everything"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 283, "tree_size": 512, "t0": 1.2475, "t1": 0.7813, "tft": 2.7847, "input_0": 891, "input_1": 513, "min_CLP": -9.71, "draft_iters": 5.1, "mem_use": 35.65, "gen_rate": 4.2, "speed": 2.09, "text": "\\nCan you help me understand how"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.6, "tree_w": 256, "tree_size": 512, "t0": 1.415, "t1": 0.7875, "tft": 2.8359, "input_0": 880, "input_1": 513, "min_CLP": -8.3, "draft_iters": 5.8, "mem_use": 35.83, "gen_rate": 4.0, "speed": 1.82, "text": "\\nI have been on the Internet si"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.1, "tree_w": 268, "tree_size": 512, "t0": 1.73, "t1": 0.7811, "tft": 2.1982, "input_0": 915, "input_1": 513, "min_CLP": -9.76, "draft_iters": 8.2, "mem_use": 35.65, "gen_rate": 3.9, "speed": 1.55, "text": "\\nHow does metabolism work? [\\\\I"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.2, "tree_w": 264, "tree_size": 512, "t0": 1.5333, "t1": 0.8, "tft": 3.5698, "input_0": 918, "input_1": 513, "min_CLP": -8.72, "draft_iters": 6.2, "mem_use": 36.23, "gen_rate": 4.1, "speed": 1.76, "text": "\\nWhat is the nearest known plan"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 289, "tree_size": 512, "t0": 1.2037, "t1": 0.785, "tft": 2.8174, "input_0": 805, "input_1": 513, "min_CLP": -10.81, "draft_iters": 5.0, "mem_use": 35.71, "gen_rate": 4.0, "speed": 2.01, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.7, "tree_w": 247, "tree_size": 512, "t0": 1.6456, "t1": 0.79, "tft": 2.9354, "input_0": 944, "input_1": 513, "min_CLP": -8.45, "draft_iters": 6.9, "mem_use": 35.92, "gen_rate": 3.9, "speed": 1.6, "text": "[INST] <<SYS>>\\nThe difference b"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 218, "tree_size": 512, "t0": 2.1929, "t1": 0.8, "tft": 3.5227, "input_0": 1072, "input_1": 513, "min_CLP": -7.91, "draft_iters": 9.9, "mem_use": 36.07, "gen_rate": 5.0, "speed": 1.67, "text": "\"\\nI know that you are eager to "}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 175, "tree_size": 512, "t0": 3.29, "t1": 0.79, "tft": 2.8247, "input_0": 1119, "input_1": 513, "min_CLP": -8.42, "draft_iters": 18.5, "mem_use": 35.73, "gen_rate": 17.5, "speed": 4.3, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.3, "tree_w": 266, "tree_size": 512, "t0": 1.6429, "t1": 0.8029, "tft": 3.5802, "input_0": 1029, "input_1": 513, "min_CLP": -8.43, "draft_iters": 6.6, "mem_use": 36.31, "gen_rate": 4.7, "speed": 1.93, "text": "\\nDLL stands for \"Dynamic Link L"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.1, "tree_w": 280, "tree_size": 512, "t0": 1.2467, "t1": 0.79, "tft": 2.8714, "input_0": 845, "input_1": 513, "min_CLP": -8.43, "draft_iters": 5.1, "mem_use": 35.89, "gen_rate": 3.6, "speed": 1.75, "text": "[INST] There seem to be a lot of"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.2, "tree_w": 267, "tree_size": 512, "t0": 1.302, "t1": 0.78, "tft": 2.7675, "input_0": 748, "input_1": 513, "min_CLP": -8.4, "draft_iters": 5.4, "mem_use": 35.64, "gen_rate": 3.5, "speed": 1.68, "text": "\\nso far i know the concept of i"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 291, "tree_size": 512, "t0": 1.2075, "t1": 0.7863, "tft": 2.8088, "input_0": 793, "input_1": 513, "min_CLP": -11.06, "draft_iters": 5.0, "mem_use": 35.68, "gen_rate": 4.0, "speed": 2.01, "text": "\"\\nWrite me a high quality testi"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 275, "tree_size": 512, "t0": 1.2125, "t1": 0.7863, "tft": 2.7772, "input_0": 794, "input_1": 513, "min_CLP": -9.14, "draft_iters": 5.0, "mem_use": 35.8, "gen_rate": 4.0, "speed": 2.0, "text": "\"You can't make an argument for "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.6, "tree_w": 256, "tree_size": 512, "t0": 1.5737, "t1": 0.8, "tft": 3.5285, "input_0": 922, "input_1": 513, "min_CLP": -8.22, "draft_iters": 6.8, "mem_use": 36.03, "gen_rate": 4.4, "speed": 1.85, "text": "\"I hate the British version, but"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 237, "tree_size": 512, "t0": 2.34, "t1": 0.8157, "tft": 3.9015, "input_0": 1136, "input_1": 513, "min_CLP": -8.16, "draft_iters": 10.0, "mem_use": 36.46, "gen_rate": 5.0, "speed": 1.58, "text": "Sure, go ahead.\\n\\nI just have a"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 226, "tree_size": 512, "t0": 2.4, "t1": 0.8286, "tft": 4.0693, "input_0": 1157, "input_1": 513, "min_CLP": -8.52, "draft_iters": 10.1, "mem_use": 36.72, "gen_rate": 5.1, "speed": 1.59, "text": "There are many different languag"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 4.5, "tree_w": 249, "tree_size": 512, "t0": 1.6433, "t1": 0.7917, "tft": 2.948, "input_0": 1029, "input_1": 513, "min_CLP": -9.04, "draft_iters": 6.7, "mem_use": 35.97, "gen_rate": 5.3, "speed": 2.19, "text": "All of the above tools are avail"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.9, "tree_w": 245, "tree_size": 512, "t0": 1.8071, "t1": 0.7886, "tft": 2.8725, "input_0": 1024, "input_1": 513, "min_CLP": -8.08, "draft_iters": 7.3, "mem_use": 35.89, "gen_rate": 4.9, "speed": 1.87, "text": "I don\u2019t have an opinion about su"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.2, "tree_w": 255, "tree_size": 512, "t0": 1.4988, "t1": 0.7962, "tft": 2.9759, "input_0": 872, "input_1": 513, "min_CLP": -8.8, "draft_iters": 6.4, "mem_use": 35.99, "gen_rate": 4.1, "speed": 1.8, "text": "\"That's not how it works. You ca"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.9, "tree_w": 202, "tree_size": 512, "t0": 2.2571, "t1": 0.7929, "tft": 2.9537, "input_0": 1143, "input_1": 513, "min_CLP": -8.34, "draft_iters": 9.3, "mem_use": 35.94, "gen_rate": 5.3, "speed": 1.73, "text": "The A stands for \"Avtomat Kalash"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.6, "tree_w": 274, "tree_size": 512, "t0": 1.45, "t1": 0.7822, "tft": 2.8055, "input_0": 777, "input_1": 513, "min_CLP": -8.71, "draft_iters": 6.8, "mem_use": 35.69, "gen_rate": 3.9, "speed": 1.74, "text": "\\n<\\\\INST>\\n\\n<SYS>\\n\\nYou can c"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 220, "tree_size": 512, "t0": 2.3567, "t1": 0.8183, "tft": 3.9247, "input_0": 1114, "input_1": 513, "min_CLP": -9.24, "draft_iters": 10.5, "mem_use": 36.5, "gen_rate": 6.0, "speed": 1.89, "text": "The [Keck Telescope](https://www"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.7, "tree_w": 257, "tree_size": 512, "t0": 1.5614, "t1": 0.7871, "tft": 2.7663, "input_0": 1016, "input_1": 513, "min_CLP": -8.36, "draft_iters": 6.7, "mem_use": 35.79, "gen_rate": 4.9, "speed": 2.07, "text": "Hippoplaisir has a unique combin"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.1, "tree_w": 242, "tree_size": 512, "t0": 2.0, "t1": 0.7813, "tft": 2.8002, "input_0": 975, "input_1": 513, "min_CLP": -8.3, "draft_iters": 10.1, "mem_use": 35.69, "gen_rate": 4.4, "speed": 1.57, "text": "\\n[INST] <<SYS>>\\nYou have a gre"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 238, "tree_size": 512, "t0": 1.9417, "t1": 0.79, "tft": 2.9469, "input_0": 993, "input_1": 513, "min_CLP": -9.03, "draft_iters": 8.5, "mem_use": 35.93, "gen_rate": 5.3, "speed": 1.95, "text": "[INST] what do you know about Cy"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.3, "tree_w": 284, "tree_size": 512, "t0": 1.6114, "t1": 0.8371, "tft": 4.3519, "input_0": 922, "input_1": 513, "min_CLP": -8.53, "draft_iters": 6.4, "mem_use": 36.78, "gen_rate": 4.9, "speed": 1.98, "text": "The initial noise in the image i"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.1, "tree_w": 259, "tree_size": 512, "t0": 1.4978, "t1": 0.8, "tft": 3.5135, "input_0": 919, "input_1": 513, "min_CLP": -8.08, "draft_iters": 6.2, "mem_use": 36.17, "gen_rate": 3.9, "speed": 1.69, "text": "\"Yes, there is! It's called sexu"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 288, "tree_size": 512, "t0": 1.315, "t1": 0.8138, "tft": 3.8899, "input_0": 915, "input_1": 513, "min_CLP": -8.68, "draft_iters": 5.2, "mem_use": 36.36, "gen_rate": 4.2, "speed": 2.0, "text": "\"\\nI believe that the meaning of"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 251, "tree_size": 512, "t0": 2.0286, "t1": 0.7843, "tft": 2.7821, "input_0": 1022, "input_1": 513, "min_CLP": -10.58, "draft_iters": 9.0, "mem_use": 35.66, "gen_rate": 8.0, "speed": 2.85, "text": "\\nWrite me a Graphic Novel plot "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 207, "tree_size": 512, "t0": 3.605, "t1": 0.885, "tft": 6.0416, "input_0": 977, "input_1": 513, "min_CLP": -12.53, "draft_iters": 18.5, "mem_use": 37.97, "gen_rate": 17.0, "speed": 3.78, "text": "\\nWhat is the james webb telesco"}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 58, "tree_h": 8.0, "tree_w": 236, "tree_size": 512, "t0": 2.24, "t1": 0.8143, "tft": 3.8984, "input_0": 1151, "input_1": 513, "min_CLP": -8.98, "draft_iters": 10.3, "mem_use": 36.41, "gen_rate": 8.3, "speed": 2.71, "text": "You can use any sequence of Brai"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.0, "tree_w": 275, "tree_size": 512, "t0": 1.49, "t1": 0.8, "tft": 3.5332, "input_0": 881, "input_1": 513, "min_CLP": -8.63, "draft_iters": 6.2, "mem_use": 36.14, "gen_rate": 3.8, "speed": 1.65, "text": "You will arrive on Sunday at you"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 197, "tree_size": 512, "t0": 3.07, "t1": 0.78, "tft": 2.792, "input_0": 1102, "input_1": 513, "min_CLP": -8.49, "draft_iters": 18.5, "mem_use": 35.67, "gen_rate": 17.5, "speed": 4.54, "text": "\\n<INST> <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 50, "tree_h": 5.4, "tree_w": 254, "tree_size": 512, "t0": 1.705, "t1": 0.79, "tft": 2.8661, "input_0": 920, "input_1": 513, "min_CLP": -8.69, "draft_iters": 7.5, "mem_use": 35.87, "gen_rate": 6.2, "speed": 2.51, "text": "\\nWhat did the broke college stu"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.5, "tree_w": 185, "tree_size": 512, "t0": 3.2475, "t1": 0.7825, "tft": 2.7862, "input_0": 1188, "input_1": 513, "min_CLP": -8.67, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 9.2, "speed": 2.29, "text": "\\n[SYS] <<SYS>>\\n<</SYS>\\n\\n[INS"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 3.6, "tree_w": 279, "tree_size": 512, "t0": 1.4944, "t1": 0.89, "tft": 6.135, "input_0": 849, "input_1": 513, "min_CLP": -8.28, "draft_iters": 5.7, "mem_use": 38.07, "gen_rate": 4.0, "speed": 1.68, "text": "\\nIf you have been provided with"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.3, "tree_w": 281, "tree_size": 512, "t0": 1.3333, "t1": 0.7822, "tft": 2.8046, "input_0": 834, "input_1": 513, "min_CLP": -9.3, "draft_iters": 5.4, "mem_use": 35.68, "gen_rate": 3.7, "speed": 1.73, "text": "\\nWhy is it that some people hav"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 235, "tree_size": 512, "t0": 2.3071, "t1": 0.9386, "tft": 7.9526, "input_0": 1044, "input_1": 513, "min_CLP": -9.0, "draft_iters": 9.0, "mem_use": 39.2, "gen_rate": 8.0, "speed": 2.47, "text": "\\n[INST] Here are some example s"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.5, "tree_w": 277, "tree_size": 512, "t0": 1.3638, "t1": 0.8, "tft": 3.5704, "input_0": 1000, "input_1": 513, "min_CLP": -8.42, "draft_iters": 5.4, "mem_use": 36.23, "gen_rate": 4.4, "speed": 2.02, "text": "\"Yes, the first evolution is Spr"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.3, "tree_w": 264, "tree_size": 512, "t0": 1.6856, "t1": 0.7833, "tft": 2.7965, "input_0": 808, "input_1": 513, "min_CLP": -8.81, "draft_iters": 8.4, "mem_use": 35.68, "gen_rate": 3.6, "speed": 1.44, "text": "\\nWhat are the main benefits of "}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 261, "tree_size": 512, "t0": 1.5088, "t1": 0.7825, "tft": 2.7761, "input_0": 858, "input_1": 513, "min_CLP": -8.39, "draft_iters": 6.8, "mem_use": 35.65, "gen_rate": 4.0, "speed": 1.75, "text": "\\nso far i have this\\n\\n1. you n"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 212, "tree_size": 512, "t0": 2.9, "t1": 0.785, "tft": 2.8325, "input_0": 1034, "input_1": 513, "min_CLP": -8.68, "draft_iters": 18.5, "mem_use": 35.75, "gen_rate": 17.5, "speed": 4.75, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 275, "tree_size": 512, "t0": 1.2575, "t1": 0.7925, "tft": 2.9385, "input_0": 852, "input_1": 513, "min_CLP": -8.98, "draft_iters": 5.1, "mem_use": 35.95, "gen_rate": 4.0, "speed": 1.95, "text": "\"I\u2019m not a big TV person, so I c"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 237, "tree_size": 512, "t0": 2.2267, "t1": 0.8317, "tft": 4.0873, "input_0": 1106, "input_1": 513, "min_CLP": -9.16, "draft_iters": 9.7, "mem_use": 36.73, "gen_rate": 8.5, "speed": 2.78, "text": "\\nTo use SDR to detect and locat"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 276, "tree_size": 512, "t0": 1.2789, "t1": 0.8078, "tft": 3.5608, "input_0": 873, "input_1": 513, "min_CLP": -8.56, "draft_iters": 5.1, "mem_use": 36.3, "gen_rate": 3.8, "speed": 1.81, "text": "F-centers can give a crystal a v"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 7.8, "tree_w": 264, "tree_size": 512, "t0": 1.9438, "t1": 0.7838, "tft": 2.8218, "input_0": 950, "input_1": 513, "min_CLP": -9.46, "draft_iters": 9.8, "mem_use": 35.72, "gen_rate": 5.0, "speed": 1.83, "text": "\\nEdit:\\n\\n[INST] <<SYS>>\\nCan y"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.3, "tree_w": 253, "tree_size": 512, "t0": 1.71, "t1": 0.87, "tft": 5.6907, "input_0": 930, "input_1": 513, "min_CLP": -8.37, "draft_iters": 7.4, "mem_use": 37.67, "gen_rate": 3.9, "speed": 1.51, "text": "\\nHow do I get the physics to wo"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 221, "tree_size": 512, "t0": 2.67, "t1": 0.82, "tft": 3.9222, "input_0": 1181, "input_1": 513, "min_CLP": -9.94, "draft_iters": 11.8, "mem_use": 36.48, "gen_rate": 10.8, "speed": 3.08, "text": "\"Aqu\u00ed tienes una reducci\u00f3n de la"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 283, "tree_size": 512, "t0": 1.1662, "t1": 0.78, "tft": 2.7796, "input_0": 795, "input_1": 513, "min_CLP": -8.71, "draft_iters": 4.9, "mem_use": 35.64, "gen_rate": 4.0, "speed": 2.05, "text": "\"\\nI'm a cat, and I want to lear"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 258, "tree_size": 512, "t0": 1.5787, "t1": 0.7838, "tft": 2.803, "input_0": 959, "input_1": 513, "min_CLP": -9.06, "draft_iters": 6.6, "mem_use": 35.69, "gen_rate": 4.0, "speed": 1.69, "text": "\\n+\\n\\n+\\n\\n==Pre-Requisites==\\n"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 4.1, "tree_w": 281, "tree_size": 512, "t0": 1.5075, "t1": 0.8, "tft": 3.5523, "input_0": 918, "input_1": 513, "min_CLP": -8.32, "draft_iters": 6.2, "mem_use": 36.23, "gen_rate": 4.8, "speed": 2.06, "text": "\"\\nThat is a very good question."}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.9, "tree_w": 273, "tree_size": 512, "t0": 1.5144, "t1": 0.8311, "tft": 4.3523, "input_0": 847, "input_1": 513, "min_CLP": -8.21, "draft_iters": 6.1, "mem_use": 36.74, "gen_rate": 3.6, "speed": 1.51, "text": "This is a common question, and o"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 3.9, "tree_w": 250, "tree_size": 512, "t0": 1.4667, "t1": 0.7933, "tft": 2.9469, "input_0": 894, "input_1": 513, "min_CLP": -8.08, "draft_iters": 6.0, "mem_use": 35.97, "gen_rate": 4.2, "speed": 1.87, "text": "If you have a guitar, you can st"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.8, "tree_w": 274, "tree_size": 512, "t0": 1.4813, "t1": 0.8, "tft": 3.5529, "input_0": 917, "input_1": 513, "min_CLP": -8.36, "draft_iters": 6.0, "mem_use": 36.2, "gen_rate": 4.0, "speed": 1.75, "text": "To test this, you can try cookin"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 173, "tree_size": 512, "t0": 3.915, "t1": 0.785, "tft": 2.7772, "input_0": 1559, "input_1": 513, "min_CLP": -8.56, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 3.73, "text": "\\nis javascript back end or fron"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 200, "tree_size": 512, "t0": 3.09, "t1": 0.78, "tft": 2.7846, "input_0": 1102, "input_1": 513, "min_CLP": -8.59, "draft_iters": 18.5, "mem_use": 35.65, "gen_rate": 17.5, "speed": 4.52, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 5.6, "tree_w": 244, "tree_size": 512, "t0": 1.7687, "t1": 0.7987, "tft": 2.9924, "input_0": 1019, "input_1": 513, "min_CLP": -8.24, "draft_iters": 7.8, "mem_use": 36.01, "gen_rate": 4.9, "speed": 1.9, "text": "\"[INST]\\n\\nHow many times can yo"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 247, "tree_size": 512, "t0": 2.496, "t1": 0.786, "tft": 2.8183, "input_0": 1281, "input_1": 513, "min_CLP": -11.35, "draft_iters": 10.8, "mem_use": 35.73, "gen_rate": 6.4, "speed": 1.95, "text": "\\nComplete the following company"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.3, "tree_w": 246, "tree_size": 512, "t0": 2.165, "t1": 0.7783, "tft": 2.8124, "input_0": 1044, "input_1": 513, "min_CLP": -9.81, "draft_iters": 9.5, "mem_use": 35.7, "gen_rate": 8.3, "speed": 2.83, "text": "\\n<\\\\INST>\\n\\n<SYS>\\n\\nYou are a"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 206, "tree_size": 512, "t0": 2.9967, "t1": 0.78, "tft": 2.8097, "input_0": 1241, "input_1": 513, "min_CLP": -9.53, "draft_iters": 14.0, "mem_use": 35.69, "gen_rate": 13.0, "speed": 3.44, "text": "\\nI am learning Mandarin. Could "}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 273, "tree_size": 512, "t0": 1.3178, "t1": 0.89, "tft": 6.1825, "input_0": 788, "input_1": 513, "min_CLP": -8.12, "draft_iters": 5.0, "mem_use": 38.11, "gen_rate": 3.9, "speed": 1.76, "text": "\"\\nYay! This is a great start! I"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 218, "tree_size": 512, "t0": 2.9433, "t1": 0.8333, "tft": 4.3709, "input_0": 1200, "input_1": 513, "min_CLP": -10.27, "draft_iters": 14.0, "mem_use": 36.87, "gen_rate": 13.0, "speed": 3.44, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.9, "tree_w": 260, "tree_size": 512, "t0": 1.4457, "t1": 0.8, "tft": 3.5562, "input_0": 859, "input_1": 513, "min_CLP": -8.73, "draft_iters": 6.0, "mem_use": 36.11, "gen_rate": 4.6, "speed": 2.04, "text": "Sure, here are the steps to calc"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 5.6, "tree_w": 225, "tree_size": 512, "t0": 1.8586, "t1": 0.8, "tft": 3.5371, "input_0": 1000, "input_1": 513, "min_CLP": -7.95, "draft_iters": 7.9, "mem_use": 36.18, "gen_rate": 5.4, "speed": 2.04, "text": "\\nPolar bears are so resilient a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.7, "tree_w": 256, "tree_size": 512, "t0": 1.9367, "t1": 0.8317, "tft": 4.0834, "input_0": 1113, "input_1": 513, "min_CLP": -8.38, "draft_iters": 7.8, "mem_use": 36.73, "gen_rate": 5.7, "speed": 2.05, "text": "\\nA lemon wedge is a small wedge"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.0, "tree_w": 277, "tree_size": 512, "t0": 1.211, "t1": 0.783, "tft": 2.8253, "input_0": 789, "input_1": 513, "min_CLP": -8.33, "draft_iters": 5.0, "mem_use": 35.75, "gen_rate": 3.5, "speed": 1.75, "text": "\\nA man is going to meet a woman"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.2, "tree_w": 289, "tree_size": 512, "t0": 1.2522, "t1": 0.7867, "tft": 2.8023, "input_0": 880, "input_1": 513, "min_CLP": -9.17, "draft_iters": 5.1, "mem_use": 35.73, "gen_rate": 3.9, "speed": 1.91, "text": "\"<</SYS>\\n\\nWhat is your favorit"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 263, "tree_size": 512, "t0": 1.2512, "t1": 0.7838, "tft": 2.7879, "input_0": 813, "input_1": 513, "min_CLP": -9.44, "draft_iters": 5.1, "mem_use": 35.65, "gen_rate": 4.1, "speed": 2.03, "text": "\\nHow do I initialize a Typescri"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.1, "tree_w": 262, "tree_size": 512, "t0": 1.59, "t1": 0.8138, "tft": 3.8889, "input_0": 992, "input_1": 513, "min_CLP": -8.84, "draft_iters": 6.2, "mem_use": 36.41, "gen_rate": 4.2, "speed": 1.77, "text": "Yes, there are.\\n<</SYS>\\n\\nWho "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.4, "tree_w": 277, "tree_size": 512, "t0": 1.36, "t1": 0.8, "tft": 3.542, "input_0": 845, "input_1": 513, "min_CLP": -8.57, "draft_iters": 5.6, "mem_use": 36.2, "gen_rate": 3.9, "speed": 1.8, "text": "In the 1950s, Freeman Dyson prop"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 222, "tree_size": 512, "t0": 2.4625, "t1": 0.775, "tft": 2.1927, "input_0": 1123, "input_1": 513, "min_CLP": -9.03, "draft_iters": 11.8, "mem_use": 35.63, "gen_rate": 10.8, "speed": 3.32, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 297, "tree_size": 512, "t0": 1.1725, "t1": 0.795, "tft": 2.9771, "input_0": 814, "input_1": 513, "min_CLP": -12.06, "draft_iters": 4.9, "mem_use": 35.96, "gen_rate": 4.0, "speed": 2.04, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 200, "tree_size": 512, "t0": 3.4267, "t1": 0.8, "tft": 3.5671, "input_0": 1559, "input_1": 513, "min_CLP": -11.7, "draft_iters": 14.3, "mem_use": 36.3, "gen_rate": 13.3, "speed": 3.15, "text": "\"\\nWe've known each other for so"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 276, "tree_size": 512, "t0": 1.2612, "t1": 0.79, "tft": 2.8474, "input_0": 845, "input_1": 513, "min_CLP": -9.55, "draft_iters": 5.1, "mem_use": 35.89, "gen_rate": 4.1, "speed": 2.01, "text": "1.                              "}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 56, "tree_h": 6.5, "tree_w": 243, "tree_size": 512, "t0": 1.905, "t1": 0.7813, "tft": 2.81, "input_0": 1024, "input_1": 513, "min_CLP": -8.74, "draft_iters": 8.4, "mem_use": 35.71, "gen_rate": 7.0, "speed": 2.6, "text": "You are able to manage your own "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.2, "tree_w": 250, "tree_size": 512, "t0": 1.575, "t1": 0.7925, "tft": 2.9439, "input_0": 1015, "input_1": 513, "min_CLP": -9.0, "draft_iters": 6.4, "mem_use": 35.96, "gen_rate": 4.1, "speed": 1.74, "text": "There have been several comparis"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 6.9, "tree_w": 237, "tree_size": 512, "t0": 1.8857, "t1": 0.8, "tft": 3.5538, "input_0": 925, "input_1": 513, "min_CLP": -9.15, "draft_iters": 8.7, "mem_use": 36.2, "gen_rate": 6.0, "speed": 2.23, "text": "[INST] how to find the biggest p"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.0, "tree_w": 260, "tree_size": 512, "t0": 1.4638, "t1": 0.8, "tft": 3.5288, "input_0": 878, "input_1": 513, "min_CLP": -9.66, "draft_iters": 6.1, "mem_use": 36.07, "gen_rate": 4.4, "speed": 1.93, "text": "The URL decoded string is the sa"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 237, "tree_size": 512, "t0": 2.73, "t1": 0.84, "tft": 4.6089, "input_0": 1139, "input_1": 513, "min_CLP": -11.42, "draft_iters": 11.8, "mem_use": 37.01, "gen_rate": 10.8, "speed": 3.01, "text": "\"\\n- You can use L'Hopital's rul"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.0, "tree_w": 237, "tree_size": 512, "t0": 2.0771, "t1": 0.8843, "tft": 6.0296, "input_0": 1105, "input_1": 513, "min_CLP": -8.11, "draft_iters": 7.4, "mem_use": 37.96, "gen_rate": 4.9, "speed": 1.64, "text": "Cheese substitutes generally hav"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.7, "tree_w": 268, "tree_size": 512, "t0": 1.437, "t1": 0.81, "tft": 3.5497, "input_0": 874, "input_1": 513, "min_CLP": -8.41, "draft_iters": 5.8, "mem_use": 36.34, "gen_rate": 3.5, "speed": 1.56, "text": "\"Don't worry, we're all in the s"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 4.0, "tree_w": 273, "tree_size": 512, "t0": 1.436, "t1": 0.82, "tft": 3.9788, "input_0": 854, "input_1": 513, "min_CLP": -8.83, "draft_iters": 6.1, "mem_use": 36.53, "gen_rate": 4.0, "speed": 1.77, "text": "\\nWhat are the main differences "}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 285, "tree_size": 512, "t0": 1.2062, "t1": 0.7813, "tft": 2.7892, "input_0": 798, "input_1": 513, "min_CLP": -9.2, "draft_iters": 5.0, "mem_use": 35.64, "gen_rate": 4.0, "speed": 2.01, "text": "\\nExplain the difference between"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.9, "tree_w": 270, "tree_size": 512, "t0": 1.47, "t1": 0.8, "tft": 3.5583, "input_0": 876, "input_1": 513, "min_CLP": -7.99, "draft_iters": 6.0, "mem_use": 36.22, "gen_rate": 3.9, "speed": 1.71, "text": "Black Friday is a day in which v"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 8.4, "tree_w": 216, "tree_size": 512, "t0": 2.264, "t1": 0.78, "tft": 2.8225, "input_0": 1068, "input_1": 513, "min_CLP": -8.97, "draft_iters": 10.4, "mem_use": 35.72, "gen_rate": 8.8, "speed": 2.89, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 186, "tree_size": 512, "t0": 3.095, "t1": 0.78, "tft": 2.7961, "input_0": 1077, "input_1": 513, "min_CLP": -8.49, "draft_iters": 18.5, "mem_use": 35.69, "gen_rate": 17.5, "speed": 4.51, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 280, "tree_size": 512, "t0": 1.3, "t1": 0.7822, "tft": 2.7993, "input_0": 792, "input_1": 513, "min_CLP": -8.48, "draft_iters": 5.3, "mem_use": 35.67, "gen_rate": 3.8, "speed": 1.81, "text": "\\nI would like to know what are "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 218, "tree_size": 512, "t0": 2.5725, "t1": 0.78, "tft": 2.7887, "input_0": 1165, "input_1": 513, "min_CLP": -9.12, "draft_iters": 11.8, "mem_use": 35.64, "gen_rate": 10.8, "speed": 3.21, "text": "\\nA helpful, respectful and hone"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 223, "tree_size": 512, "t0": 2.62, "t1": 0.8025, "tft": 3.5631, "input_0": 1191, "input_1": 513, "min_CLP": -9.88, "draft_iters": 11.5, "mem_use": 36.28, "gen_rate": 10.8, "speed": 3.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 277, "tree_size": 512, "t0": 1.2489, "t1": 0.79, "tft": 2.8601, "input_0": 841, "input_1": 513, "min_CLP": -9.57, "draft_iters": 5.1, "mem_use": 35.89, "gen_rate": 3.9, "speed": 1.91, "text": "# Add Tailwind CSS framework\\nnp"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.2, "tree_w": 262, "tree_size": 512, "t0": 2.0083, "t1": 0.9017, "tft": 6.6691, "input_0": 1068, "input_1": 513, "min_CLP": -9.64, "draft_iters": 7.3, "mem_use": 38.45, "gen_rate": 5.7, "speed": 1.95, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.4, "tree_w": 272, "tree_size": 512, "t0": 1.3944, "t1": 0.7911, "tft": 2.9406, "input_0": 834, "input_1": 513, "min_CLP": -8.25, "draft_iters": 5.7, "mem_use": 35.95, "gen_rate": 3.6, "speed": 1.63, "text": "\"If you're asking why so many LL"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 199, "tree_size": 512, "t0": 3.05, "t1": 0.785, "tft": 2.8067, "input_0": 1032, "input_1": 513, "min_CLP": -8.5, "draft_iters": 18.5, "mem_use": 35.7, "gen_rate": 17.5, "speed": 4.57, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 61, "tree_h": 19.3, "tree_w": 193, "tree_size": 512, "t0": 4.0867, "t1": 0.7867, "tft": 2.7738, "input_0": 1330, "input_1": 513, "min_CLP": -10.55, "draft_iters": 21.7, "mem_use": 35.8, "gen_rate": 20.3, "speed": 4.17, "text": "\\nI need a eulogy for my 100 yea"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 248, "tree_size": 512, "t0": 1.7643, "t1": 0.82, "tft": 4.0011, "input_0": 939, "input_1": 513, "min_CLP": -8.65, "draft_iters": 7.9, "mem_use": 36.52, "gen_rate": 4.6, "speed": 1.77, "text": "\\nLooking for a quick and easy w"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 286, "tree_size": 512, "t0": 1.25, "t1": 0.7838, "tft": 2.8254, "input_0": 855, "input_1": 513, "min_CLP": -8.81, "draft_iters": 5.1, "mem_use": 35.72, "gen_rate": 4.0, "speed": 1.97, "text": "\"Yes, I am. I am sorry for not r"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.8, "tree_w": 215, "tree_size": 512, "t0": 2.0063, "t1": 0.78, "tft": 2.7952, "input_0": 1063, "input_1": 513, "min_CLP": -8.2, "draft_iters": 9.1, "mem_use": 35.69, "gen_rate": 4.4, "speed": 1.57, "text": "\"\\nWhat are some good things to "}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 251, "tree_size": 512, "t0": 1.9817, "t1": 0.7833, "tft": 2.7772, "input_0": 969, "input_1": 513, "min_CLP": -10.07, "draft_iters": 9.5, "mem_use": 35.65, "gen_rate": 8.5, "speed": 3.07, "text": "\\nwhat is the color of mars [\\\\I"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 10.5, "tree_w": 229, "tree_size": 512, "t0": 2.565, "t1": 0.8375, "tft": 4.3846, "input_0": 1180, "input_1": 513, "min_CLP": -8.5, "draft_iters": 12.5, "mem_use": 36.8, "gen_rate": 11.5, "speed": 3.38, "text": "Here is the list of words in Que"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.6, "tree_w": 171, "tree_size": 512, "t0": 3.56, "t1": 0.784, "tft": 2.8008, "input_0": 1645, "input_1": 513, "min_CLP": -9.11, "draft_iters": 14.4, "mem_use": 35.68, "gen_rate": 8.4, "speed": 1.93, "text": "\\nPlease, summarise the book \"Ha"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 272, "tree_size": 512, "t0": 1.3438, "t1": 0.7925, "tft": 2.9575, "input_0": 953, "input_1": 513, "min_CLP": -10.29, "draft_iters": 5.4, "mem_use": 35.95, "gen_rate": 4.4, "speed": 2.05, "text": "\"No, the Second Amendment guaran"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 273, "tree_size": 512, "t0": 1.2012, "t1": 0.78, "tft": 2.7834, "input_0": 792, "input_1": 513, "min_CLP": -8.21, "draft_iters": 5.0, "mem_use": 35.67, "gen_rate": 4.0, "speed": 2.02, "text": "\\nThe prime numbers are not trul"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.1, "tree_w": 251, "tree_size": 512, "t0": 1.59, "t1": 0.79, "tft": 2.8694, "input_0": 909, "input_1": 513, "min_CLP": -8.16, "draft_iters": 6.4, "mem_use": 35.89, "gen_rate": 4.6, "speed": 1.92, "text": "\\nHere is a list of things that "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 9.7, "tree_w": 152, "tree_size": 512, "t0": 2.77, "t1": 0.7767, "tft": 2.8235, "input_0": 1304, "input_1": 513, "min_CLP": -7.41, "draft_iters": 12.3, "mem_use": 35.72, "gen_rate": 4.3, "speed": 1.22, "text": "Melbourne was the capital of the"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 273, "tree_size": 512, "t0": 1.3062, "t1": 0.79, "tft": 2.7808, "input_0": 883, "input_1": 513, "min_CLP": -10.22, "draft_iters": 5.2, "mem_use": 35.86, "gen_rate": 4.2, "speed": 2.03, "text": "\"[INST] how are you [\\\\INST]\\n[I"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.8, "tree_w": 250, "tree_size": 512, "t0": 1.4537, "t1": 0.8387, "tft": 4.5838, "input_0": 841, "input_1": 513, "min_CLP": -8.19, "draft_iters": 5.9, "mem_use": 36.96, "gen_rate": 4.4, "speed": 1.91, "text": "\\nI will be writing a memoir abo"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 284, "tree_size": 512, "t0": 1.1713, "t1": 0.785, "tft": 2.815, "input_0": 804, "input_1": 513, "min_CLP": -11.95, "draft_iters": 4.9, "mem_use": 35.7, "gen_rate": 4.0, "speed": 2.04, "text": "\\nI heard something about a numb"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.0, "tree_w": 260, "tree_size": 512, "t0": 1.745, "t1": 0.8125, "tft": 3.8808, "input_0": 905, "input_1": 513, "min_CLP": -9.51, "draft_iters": 8.1, "mem_use": 36.39, "gen_rate": 4.9, "speed": 1.91, "text": "\\nHow would you normalize a vect"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.5, "tree_w": 274, "tree_size": 512, "t0": 1.5263, "t1": 0.7825, "tft": 2.7923, "input_0": 942, "input_1": 513, "min_CLP": -8.93, "draft_iters": 6.6, "mem_use": 35.65, "gen_rate": 4.1, "speed": 1.79, "text": "\\nWhy should I follow the rule t"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 57, "tree_h": 6.5, "tree_w": 248, "tree_size": 512, "t0": 1.8313, "t1": 0.7825, "tft": 2.8074, "input_0": 975, "input_1": 513, "min_CLP": -10.5, "draft_iters": 8.5, "mem_use": 35.69, "gen_rate": 7.1, "speed": 2.72, "text": "\\nWrite a short story. Do not of"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.0, "tree_w": 253, "tree_size": 512, "t0": 1.4971, "t1": 0.78, "tft": 2.8021, "input_0": 963, "input_1": 513, "min_CLP": -8.9, "draft_iters": 6.1, "mem_use": 35.67, "gen_rate": 4.6, "speed": 2.0, "text": "\"\\nThe use of L'Hopital's Rule i"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 271, "tree_size": 512, "t0": 1.6188, "t1": 0.7937, "tft": 2.9499, "input_0": 876, "input_1": 513, "min_CLP": -8.77, "draft_iters": 7.8, "mem_use": 35.95, "gen_rate": 4.0, "speed": 1.66, "text": "No. The sum of squares error is "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.8, "tree_w": 257, "tree_size": 512, "t0": 1.4044, "t1": 0.8, "tft": 3.5361, "input_0": 846, "input_1": 513, "min_CLP": -8.57, "draft_iters": 5.9, "mem_use": 36.13, "gen_rate": 3.8, "speed": 1.72, "text": "\\nYour slogan should:\\n- Be appr"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.4, "tree_w": 269, "tree_size": 512, "t0": 1.5425, "t1": 0.7975, "tft": 2.9899, "input_0": 925, "input_1": 513, "min_CLP": -8.35, "draft_iters": 6.5, "mem_use": 35.98, "gen_rate": 4.5, "speed": 1.92, "text": "If you are in the lower 48 state"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 185, "tree_size": 512, "t0": 3.11, "t1": 0.785, "tft": 2.7792, "input_0": 1050, "input_1": 513, "min_CLP": -8.53, "draft_iters": 18.5, "mem_use": 35.66, "gen_rate": 17.5, "speed": 4.5, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 15.3, "tree_w": 148, "tree_size": 512, "t0": 4.2567, "t1": 0.79, "tft": 2.9617, "input_0": 1700, "input_1": 513, "min_CLP": -9.11, "draft_iters": 17.7, "mem_use": 35.95, "gen_rate": 16.3, "speed": 3.24, "text": "Then there are 6 eggs remaining."}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.3, "tree_w": 228, "tree_size": 512, "t0": 2.0914, "t1": 0.79, "tft": 2.863, "input_0": 1011, "input_1": 513, "min_CLP": -9.29, "draft_iters": 10.4, "mem_use": 35.91, "gen_rate": 5.4, "speed": 1.88, "text": "\\n[INST] <<SYS>>\\nWhat is the di"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 217, "tree_size": 512, "t0": 3.3033, "t1": 0.86, "tft": 5.4252, "input_0": 1441, "input_1": 513, "min_CLP": -10.54, "draft_iters": 14.3, "mem_use": 37.48, "gen_rate": 13.3, "speed": 3.2, "text": "\"I am Open Assistant, an AI lang"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 4.7, "tree_w": 271, "tree_size": 512, "t0": 1.7143, "t1": 0.8343, "tft": 4.3568, "input_0": 964, "input_1": 513, "min_CLP": -8.6, "draft_iters": 7.0, "mem_use": 36.8, "gen_rate": 5.3, "speed": 2.07, "text": "\\nPros:\\n\\n- You can customize t"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 236, "tree_size": 512, "t0": 1.9086, "t1": 0.78, "tft": 2.7767, "input_0": 1013, "input_1": 513, "min_CLP": -8.11, "draft_iters": 8.4, "mem_use": 35.66, "gen_rate": 4.9, "speed": 1.81, "text": "\\nHello,\\n\\nI would like to ask "}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 240, "tree_size": 512, "t0": 1.8687, "t1": 0.7838, "tft": 2.8363, "input_0": 949, "input_1": 513, "min_CLP": -9.55, "draft_iters": 8.4, "mem_use": 35.76, "gen_rate": 7.4, "speed": 2.78, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.3, "tree_w": 229, "tree_size": 512, "t0": 2.5186, "t1": 1.0629, "tft": 10.199, "input_0": 1149, "input_1": 513, "min_CLP": -8.14, "draft_iters": 8.7, "mem_use": 40.55, "gen_rate": 4.9, "speed": 1.36, "text": "[INST] The _physics_process func"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 6.7, "tree_w": 266, "tree_size": 512, "t0": 1.7433, "t1": 0.79, "tft": 2.8654, "input_0": 967, "input_1": 513, "min_CLP": -8.96, "draft_iters": 8.5, "mem_use": 36.54, "gen_rate": 6.8, "speed": 2.7, "text": "Yes, decorators can be used insi"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 7.8, "tree_w": 225, "tree_size": 512, "t0": 2.13, "t1": 0.7867, "tft": 2.8036, "input_0": 1119, "input_1": 513, "min_CLP": -9.15, "draft_iters": 9.7, "mem_use": 35.74, "gen_rate": 8.2, "speed": 2.8, "text": "\"germanic people.\\n[INST]\\n\\nWho"}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.0, "tree_w": 277, "tree_size": 512, "t0": 1.1689, "t1": 0.7811, "tft": 2.813, "input_0": 795, "input_1": 513, "min_CLP": -8.39, "draft_iters": 4.9, "mem_use": 35.68, "gen_rate": 3.7, "speed": 1.88, "text": "\"\\nI'm a lawyer. If you have any"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 273, "tree_size": 512, "t0": 1.3211, "t1": 0.84, "tft": 4.6033, "input_0": 867, "input_1": 513, "min_CLP": -8.35, "draft_iters": 5.2, "mem_use": 36.97, "gen_rate": 3.8, "speed": 1.75, "text": "Haha, you got me!\\n\\nTo be clear"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 255, "tree_size": 512, "t0": 1.7588, "t1": 0.7913, "tft": 2.9291, "input_0": 950, "input_1": 513, "min_CLP": -8.52, "draft_iters": 8.4, "mem_use": 35.92, "gen_rate": 7.5, "speed": 2.94, "text": "Unfortunately, there are not any"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 247, "tree_size": 512, "t0": 1.7188, "t1": 0.7975, "tft": 2.9729, "input_0": 949, "input_1": 513, "min_CLP": -8.92, "draft_iters": 7.5, "mem_use": 36.0, "gen_rate": 4.1, "speed": 1.64, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 177, "tree_size": 512, "t0": 3.0167, "t1": 0.7867, "tft": 2.4579, "input_0": 1295, "input_1": 513, "min_CLP": -8.66, "draft_iters": 14.3, "mem_use": 35.76, "gen_rate": 13.3, "speed": 3.51, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 269, "tree_size": 512, "t0": 1.53, "t1": 0.8, "tft": 2.9876, "input_0": 754, "input_1": 513, "min_CLP": -9.89, "draft_iters": 7.4, "mem_use": 36.03, "gen_rate": 4.7, "speed": 2.03, "text": "I learned to program at a young "}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.1, "tree_w": 233, "tree_size": 512, "t0": 1.9414, "t1": 0.7886, "tft": 2.8337, "input_0": 968, "input_1": 513, "min_CLP": -8.46, "draft_iters": 9.3, "mem_use": 35.85, "gen_rate": 4.6, "speed": 1.68, "text": "\\nWhat is the meaning of life? ["}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.5, "tree_w": 233, "tree_size": 512, "t0": 1.8412, "t1": 0.835, "tft": 4.3562, "input_0": 963, "input_1": 513, "min_CLP": -8.68, "draft_iters": 7.8, "mem_use": 36.79, "gen_rate": 4.5, "speed": 1.68, "text": "\"\\nI'm not sure if you are askin"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.0, "tree_w": 264, "tree_size": 512, "t0": 1.7271, "t1": 0.7843, "tft": 2.8154, "input_0": 1098, "input_1": 513, "min_CLP": -9.16, "draft_iters": 7.1, "mem_use": 35.7, "gen_rate": 5.1, "speed": 2.05, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.4, "tree_w": 258, "tree_size": 512, "t0": 1.7675, "t1": 0.7813, "tft": 2.792, "input_0": 1019, "input_1": 513, "min_CLP": -8.9, "draft_iters": 7.6, "mem_use": 35.7, "gen_rate": 4.6, "speed": 1.81, "text": "\"I can talk in Spanish. I can sp"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 284, "tree_size": 512, "t0": 1.2487, "t1": 0.785, "tft": 2.7958, "input_0": 858, "input_1": 513, "min_CLP": -9.46, "draft_iters": 5.1, "mem_use": 35.67, "gen_rate": 4.1, "speed": 2.03, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 227, "tree_size": 512, "t0": 2.5725, "t1": 0.91, "tft": 7.1705, "input_0": 861, "input_1": 513, "min_CLP": -10.54, "draft_iters": 11.8, "mem_use": 38.66, "gen_rate": 10.5, "speed": 3.02, "text": "\\nWrite code that imitates a fak"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.7, "tree_w": 283, "tree_size": 512, "t0": 1.4156, "t1": 0.82, "tft": 3.9152, "input_0": 907, "input_1": 513, "min_CLP": -8.72, "draft_iters": 5.7, "mem_use": 36.52, "gen_rate": 3.8, "speed": 1.69, "text": "\\nWhat is beauty? [\\\\INST]\\nBeau"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 225, "tree_size": 512, "t0": 2.25, "t1": 0.7883, "tft": 2.9307, "input_0": 1096, "input_1": 513, "min_CLP": -9.21, "draft_iters": 9.7, "mem_use": 35.94, "gen_rate": 8.7, "speed": 2.85, "text": "\\nWhy do we need AI assistants? "}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.5, "tree_w": 275, "tree_size": 512, "t0": 1.57, "t1": 0.8387, "tft": 4.3967, "input_0": 975, "input_1": 513, "min_CLP": -8.34, "draft_iters": 6.5, "mem_use": 36.84, "gen_rate": 4.4, "speed": 1.82, "text": "Breeding animals in Minecraft is"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 3.7, "tree_w": 297, "tree_size": 512, "t0": 1.4657, "t1": 0.8514, "tft": 4.8963, "input_0": 1089, "input_1": 513, "min_CLP": -9.96, "draft_iters": 5.6, "mem_use": 37.25, "gen_rate": 4.7, "speed": 2.03, "text": "Zement ist eine der wichtigsten "}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.5, "tree_w": 281, "tree_size": 512, "t0": 1.4275, "t1": 0.8237, "tft": 4.0348, "input_0": 874, "input_1": 513, "min_CLP": -8.37, "draft_iters": 5.8, "mem_use": 36.68, "gen_rate": 4.0, "speed": 1.78, "text": "In this case it would be a matte"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 4.9, "tree_w": 255, "tree_size": 512, "t0": 1.675, "t1": 0.7987, "tft": 3.5213, "input_0": 978, "input_1": 513, "min_CLP": -8.24, "draft_iters": 7.0, "mem_use": 36.05, "gen_rate": 5.1, "speed": 2.07, "text": "\"I don't know. If the original o"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 273, "tree_size": 512, "t0": 1.2075, "t1": 0.8, "tft": 3.5224, "input_0": 846, "input_1": 513, "min_CLP": -8.51, "draft_iters": 5.0, "mem_use": 36.18, "gen_rate": 4.1, "speed": 2.05, "text": "You know what is self-attention "}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 12.0, "tree_w": 229, "tree_size": 512, "t0": 2.5767, "t1": 0.7833, "tft": 2.8166, "input_0": 1024, "input_1": 513, "min_CLP": -8.64, "draft_iters": 14.0, "mem_use": 35.71, "gen_rate": 8.5, "speed": 2.53, "text": "\\nWould you like to be a moderat"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 235, "tree_size": 512, "t0": 1.7625, "t1": 0.81, "tft": 3.5796, "input_0": 929, "input_1": 513, "min_CLP": -8.16, "draft_iters": 7.4, "mem_use": 36.35, "gen_rate": 4.4, "speed": 1.7, "text": "\\nThe purpose of this project is"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 258, "tree_size": 512, "t0": 1.8425, "t1": 0.79, "tft": 2.946, "input_0": 983, "input_1": 513, "min_CLP": -10.94, "draft_iters": 8.2, "mem_use": 35.91, "gen_rate": 7.4, "speed": 2.8, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 233, "tree_size": 512, "t0": 1.94, "t1": 0.81, "tft": 3.8736, "input_0": 1165, "input_1": 513, "min_CLP": -7.97, "draft_iters": 8.0, "mem_use": 36.37, "gen_rate": 4.6, "speed": 1.66, "text": "Mayonnaise should have a consist"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.7, "tree_w": 230, "tree_size": 512, "t0": 2.0086, "t1": 0.7986, "tft": 3.519, "input_0": 1075, "input_1": 513, "min_CLP": -8.36, "draft_iters": 9.0, "mem_use": 36.06, "gen_rate": 5.1, "speed": 1.83, "text": "\"There are exactly 283 days left"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 250, "tree_size": 512, "t0": 2.145, "t1": 0.7817, "tft": 2.7932, "input_0": 1133, "input_1": 513, "min_CLP": -11.74, "draft_iters": 9.5, "mem_use": 35.75, "gen_rate": 8.7, "speed": 2.96, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.1, "tree_w": 285, "tree_size": 512, "t0": 1.4986, "t1": 0.79, "tft": 2.8564, "input_0": 945, "input_1": 513, "min_CLP": -8.42, "draft_iters": 6.3, "mem_use": 35.88, "gen_rate": 4.9, "speed": 2.12, "text": "\"This change in the status of Pa"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 8.6, "tree_w": 223, "tree_size": 512, "t0": 2.43, "t1": 0.82, "tft": 3.908, "input_0": 1186, "input_1": 513, "min_CLP": -10.49, "draft_iters": 10.6, "mem_use": 36.48, "gen_rate": 9.0, "speed": 2.77, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 141, "tree_size": 512, "t0": 3.57, "t1": 0.775, "tft": 2.8285, "input_0": 1440, "input_1": 513, "min_CLP": -9.1, "draft_iters": 18.5, "mem_use": 35.72, "gen_rate": 17.5, "speed": 4.03, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 7.5, "tree_w": 248, "tree_size": 512, "t0": 2.1083, "t1": 0.7967, "tft": 2.9716, "input_0": 1051, "input_1": 513, "min_CLP": -9.76, "draft_iters": 9.3, "mem_use": 35.98, "gen_rate": 7.0, "speed": 2.41, "text": "\"You're right, I did. Fixed.\\n\\n"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 268, "tree_size": 512, "t0": 1.2612, "t1": 0.8, "tft": 3.527, "input_0": 833, "input_1": 513, "min_CLP": -8.3, "draft_iters": 5.1, "mem_use": 36.17, "gen_rate": 4.1, "speed": 2.0, "text": "A clock and a heart is a metapho"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 228, "tree_size": 512, "t0": 2.5825, "t1": 0.8175, "tft": 3.9964, "input_0": 1106, "input_1": 513, "min_CLP": -10.18, "draft_iters": 11.8, "mem_use": 36.56, "gen_rate": 10.8, "speed": 3.16, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.2, "tree_w": 265, "tree_size": 512, "t0": 1.6475, "t1": 0.7838, "tft": 2.8314, "input_0": 921, "input_1": 513, "min_CLP": -8.91, "draft_iters": 7.4, "mem_use": 35.77, "gen_rate": 4.4, "speed": 1.8, "text": "He is a politician from the Soci"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.4, "tree_w": 251, "tree_size": 512, "t0": 1.9538, "t1": 0.7813, "tft": 2.8204, "input_0": 924, "input_1": 513, "min_CLP": -9.33, "draft_iters": 9.6, "mem_use": 35.69, "gen_rate": 4.2, "speed": 1.55, "text": "3) A quadrillion kilograms of wa"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 256, "tree_size": 512, "t0": 1.8817, "t1": 0.9083, "tft": 5.7444, "input_0": 983, "input_1": 513, "min_CLP": -8.83, "draft_iters": 7.5, "mem_use": 37.76, "gen_rate": 5.3, "speed": 1.91, "text": "\\n<INPUT>\\nWhat is your business"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 4.7, "tree_w": 264, "tree_size": 512, "t0": 1.603, "t1": 0.785, "tft": 2.7749, "input_0": 867, "input_1": 513, "min_CLP": -8.54, "draft_iters": 7.0, "mem_use": 35.67, "gen_rate": 4.0, "speed": 1.68, "text": "\\n<INST>\\n\\nA popular misconcept"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 286, "tree_size": 512, "t0": 1.165, "t1": 0.7813, "tft": 2.7733, "input_0": 805, "input_1": 513, "min_CLP": -8.41, "draft_iters": 4.9, "mem_use": 35.65, "gen_rate": 4.0, "speed": 2.05, "text": "\\nWe will help you build your PC"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 214, "tree_size": 512, "t0": 2.6125, "t1": 0.8975, "tft": 6.2373, "input_0": 914, "input_1": 513, "min_CLP": -9.4, "draft_iters": 11.8, "mem_use": 38.23, "gen_rate": 10.5, "speed": 2.99, "text": "\\nwrite code that imitates a fak"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.8, "tree_w": 278, "tree_size": 512, "t0": 1.415, "t1": 0.825, "tft": 4.3929, "input_0": 887, "input_1": 513, "min_CLP": -8.33, "draft_iters": 5.8, "mem_use": 36.72, "gen_rate": 4.2, "speed": 1.89, "text": "\u2022 Increase your motivation. You "}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.6, "tree_w": 260, "tree_size": 512, "t0": 1.4238, "t1": 0.8037, "tft": 3.5626, "input_0": 850, "input_1": 513, "min_CLP": -8.06, "draft_iters": 5.8, "mem_use": 36.3, "gen_rate": 4.1, "speed": 1.85, "text": "\"I'd say the enemy units are hid"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 257, "tree_size": 512, "t0": 1.6157, "t1": 0.7814, "tft": 2.8233, "input_0": 898, "input_1": 513, "min_CLP": -9.31, "draft_iters": 7.4, "mem_use": 35.78, "gen_rate": 4.9, "speed": 2.02, "text": "the 6th of february is the day o"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 242, "tree_size": 512, "t0": 1.9471, "t1": 0.7843, "tft": 2.4962, "input_0": 1031, "input_1": 513, "min_CLP": -10.41, "draft_iters": 8.9, "mem_use": 35.7, "gen_rate": 8.0, "speed": 2.93, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.8, "tree_w": 159, "tree_size": 512, "t0": 3.844, "t1": 0.8, "tft": 3.5498, "input_0": 1519, "input_1": 513, "min_CLP": -8.2, "draft_iters": 16.6, "mem_use": 36.2, "gen_rate": 7.0, "speed": 1.51, "text": "\"[INST] What's the weather like "}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.0, "tree_w": 281, "tree_size": 512, "t0": 1.2433, "t1": 0.8322, "tft": 4.331, "input_0": 794, "input_1": 513, "min_CLP": -8.13, "draft_iters": 5.0, "mem_use": 36.76, "gen_rate": 3.8, "speed": 1.82, "text": "\"This script is fairly easy to w"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 270, "tree_size": 512, "t0": 1.2537, "t1": 0.8, "tft": 3.5113, "input_0": 840, "input_1": 513, "min_CLP": -8.46, "draft_iters": 5.1, "mem_use": 36.15, "gen_rate": 4.0, "speed": 1.95, "text": "I know this is a little off topi"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.2, "tree_w": 309, "tree_size": 512, "t0": 1.292, "t1": 0.797, "tft": 3.5544, "input_0": 847, "input_1": 513, "min_CLP": -10.55, "draft_iters": 5.2, "mem_use": 36.22, "gen_rate": 3.4, "speed": 1.62, "text": "\\nLast edited by xeles_princess "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 284, "tree_size": 512, "t0": 1.3038, "t1": 0.79, "tft": 2.8658, "input_0": 902, "input_1": 513, "min_CLP": -10.05, "draft_iters": 5.2, "mem_use": 35.89, "gen_rate": 4.2, "speed": 2.03, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 256, "tree_size": 512, "t0": 1.6425, "t1": 0.79, "tft": 2.854, "input_0": 942, "input_1": 513, "min_CLP": -8.42, "draft_iters": 6.8, "mem_use": 35.87, "gen_rate": 4.0, "speed": 1.65, "text": "While landlords are superior to "}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.1, "tree_w": 270, "tree_size": 512, "t0": 1.265, "t1": 0.821, "tft": 3.992, "input_0": 824, "input_1": 513, "min_CLP": -8.32, "draft_iters": 5.1, "mem_use": 36.56, "gen_rate": 3.4, "speed": 1.63, "text": "\\nHello\\nI have a problem with a"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 244, "tree_size": 512, "t0": 1.7575, "t1": 0.82, "tft": 3.9073, "input_0": 883, "input_1": 513, "min_CLP": -8.59, "draft_iters": 7.5, "mem_use": 36.51, "gen_rate": 4.1, "speed": 1.6, "text": "Yes, Open Assistant is trained o"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 7.1, "tree_w": 242, "tree_size": 512, "t0": 2.0857, "t1": 0.8514, "tft": 4.5651, "input_0": 1073, "input_1": 513, "min_CLP": -8.38, "draft_iters": 9.1, "mem_use": 37.2, "gen_rate": 6.7, "speed": 2.29, "text": "\"\\nThe instructions are a bit va"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 4.1, "tree_w": 277, "tree_size": 512, "t0": 1.5157, "t1": 0.78, "tft": 2.7708, "input_0": 951, "input_1": 513, "min_CLP": -9.28, "draft_iters": 6.3, "mem_use": 35.66, "gen_rate": 5.0, "speed": 2.18, "text": "\\nWho is the President of German"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 276, "tree_size": 512, "t0": 1.22, "t1": 0.8, "tft": 3.4969, "input_0": 842, "input_1": 513, "min_CLP": -8.53, "draft_iters": 5.0, "mem_use": 36.16, "gen_rate": 4.0, "speed": 1.98, "text": "PostCSS is a library for working"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 231, "tree_size": 512, "t0": 2.1017, "t1": 0.8483, "tft": 4.6235, "input_0": 1009, "input_1": 513, "min_CLP": -8.72, "draft_iters": 9.5, "mem_use": 37.12, "gen_rate": 5.7, "speed": 1.92, "text": "\"I'm trying to understand the di"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.5, "tree_w": 274, "tree_size": 512, "t0": 1.3675, "t1": 0.79, "tft": 2.8583, "input_0": 842, "input_1": 513, "min_CLP": -8.36, "draft_iters": 5.6, "mem_use": 35.91, "gen_rate": 4.0, "speed": 1.85, "text": "This is a question that I can an"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 17.7, "tree_w": 145, "tree_size": 512, "t0": 3.9667, "t1": 0.8067, "tft": 3.5671, "input_0": 1483, "input_1": 513, "min_CLP": -8.0, "draft_iters": 20.0, "mem_use": 36.34, "gen_rate": 14.3, "speed": 3.0, "text": "\\nThe current date is 6th of Feb"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 512, "max_branch_width": 32, "gen_rate": 6.47, "gen_rate_micro": 5.38, "gen_speed": 2.246, "gen_speed_micro": 2.12, "t0": 1.9118, "t1": 0.8043, "input_0": 984.7, "input_1": 513.0, "tree_size": 512.0, "tree_w": 247.1, "tree_h": 6.5, "prompt_len": 320.7, "min_CLP": -8.92, "mem_use": 40.55, "exp_time": 11414.23}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 31, "tree_h": 15.3, "tree_w": 245, "tree_size": 1024, "t0": 5.8833, "t1": 1.9667, "tft": 9.0145, "input_0": 2646, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 23.0, "mem_use": 37.32, "gen_rate": 10.3, "speed": 1.32, "text": "What is the most efficient way t"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 14.0, "tree_w": 194, "tree_size": 1024, "t0": 6.1325, "t1": 2.0075, "tft": 9.8819, "input_0": 3379, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 21.2, "mem_use": 38.02, "gen_rate": 12.0, "speed": 1.47, "text": "\\nHow many people are on this pl"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.6, "tree_w": 315, "tree_size": 1024, "t0": 4.5829, "t1": 2.0329, "tft": 9.9874, "input_0": 2454, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 16.4, "mem_use": 38.46, "gen_rate": 4.7, "speed": 0.71, "text": "\"Minecraft is a very CPU-bound g"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 26.2, "tree_w": 274, "tree_size": 1024, "t0": 6.2725, "t1": 1.97, "tft": 9.0518, "input_0": 2514, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 32.0, "mem_use": 37.4, "gen_rate": 11.2, "speed": 1.37, "text": "\\nI have created a python script"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 68, "tree_size": 1024, "t0": 8.795, "t1": 1.96, "tft": 8.7163, "input_0": 3912, "input_1": 1025, "min_CLP": -9.74, "draft_iters": 32.0, "mem_use": 37.28, "gen_rate": 26.5, "speed": 2.46, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 579, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 20.2, "tree_w": 164, "tree_size": 1024, "t0": 7.2025, "t1": 2.0375, "tft": 11.3219, "input_0": 3431, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 27.8, "mem_use": 38.59, "gen_rate": 8.5, "speed": 0.92, "text": "\\n1. Introduction: Define the co"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 18.5, "tree_w": 150, "tree_size": 1024, "t0": 8.085, "t1": 2.055, "tft": 11.8783, "input_0": 3742, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 27.0, "mem_use": 38.89, "gen_rate": 17.5, "speed": 1.73, "text": "There are many different techniq"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1074, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 25.3, "tree_w": 141, "tree_size": 1024, "t0": 8.81, "t1": 2.39, "tft": 14.0649, "input_0": 3492, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 32.0, "mem_use": 40.0, "gen_rate": 15.7, "speed": 1.4, "text": "\"\\nFirst and foremost, you need "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 595, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 228, "tree_size": 1024, "t0": 6.1875, "t1": 2.03, "tft": 11.0084, "input_0": 3292, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 21.5, "mem_use": 38.63, "gen_rate": 8.8, "speed": 1.06, "text": "\\nThe legal status of marijuana "}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 255, "tree_size": 1024, "t0": 5.078, "t1": 2.03, "tft": 10.1711, "input_0": 2978, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 17.2, "mem_use": 38.44, "gen_rate": 7.0, "speed": 0.98, "text": "The most beginner friendly hobby"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.0, "tree_w": 310, "tree_size": 1024, "t0": 4.985, "t1": 1.985, "tft": 9.36, "input_0": 2370, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 20.8, "mem_use": 37.63, "gen_rate": 8.0, "speed": 1.15, "text": "\\nI want to make a program that "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 573, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 337, "tree_size": 1024, "t0": 4.878, "t1": 2.036, "tft": 10.6349, "input_0": 2666, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 17.4, "mem_use": 38.58, "gen_rate": 7.0, "speed": 1.01, "text": "\\nHow would you define \"the righ"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 444, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 14.0, "tree_w": 288, "tree_size": 1024, "t0": 5.1043, "t1": 2.0114, "tft": 10.0265, "input_0": 2401, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 20.7, "mem_use": 38.18, "gen_rate": 4.6, "speed": 0.64, "text": "\"Sure! In the spirit of collabor"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 20.8, "tree_w": 263, "tree_size": 1024, "t0": 5.8825, "t1": 1.97, "tft": 9.0971, "input_0": 2517, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 26.2, "mem_use": 37.31, "gen_rate": 8.0, "speed": 1.02, "text": "What is the capital of Australia"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 690, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 269, "tree_size": 1024, "t0": 5.21, "t1": 2.05, "tft": 11.5086, "input_0": 2985, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 17.8, "mem_use": 38.89, "gen_rate": 6.4, "speed": 0.88, "text": "It is true that you may not be a"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 178, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 24.5, "tree_w": 89, "tree_size": 1024, "t0": 8.97, "t1": 1.975, "tft": 8.7442, "input_0": 4716, "input_1": 1025, "min_CLP": -11.03, "draft_iters": 32.0, "mem_use": 37.43, "gen_rate": 18.5, "speed": 1.69, "text": "\\nWhat is the minimum broadband "}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.8, "tree_w": 220, "tree_size": 1024, "t0": 5.9125, "t1": 1.97, "tft": 8.5982, "input_0": 2788, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 23.5, "mem_use": 37.32, "gen_rate": 10.2, "speed": 1.3, "text": "\\nWhat is the shortest distance "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 87, "tree_size": 1024, "t0": 8.335, "t1": 1.97, "tft": 9.5479, "input_0": 3678, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 32.0, "mem_use": 37.27, "gen_rate": 26.5, "speed": 2.57, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 19.5, "tree_w": 208, "tree_size": 1024, "t0": 6.4267, "t1": 1.9867, "tft": 10.7367, "input_0": 3050, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 26.8, "mem_use": 37.58, "gen_rate": 6.2, "speed": 0.73, "text": "D-theanine is the form of theani"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 191, "tree_size": 1024, "t0": 5.7275, "t1": 1.97, "tft": 8.9721, "input_0": 3132, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 20.2, "mem_use": 37.31, "gen_rate": 8.8, "speed": 1.14, "text": "\"\\nThe Balfour Declaration is a "}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 296, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 9.1, "tree_w": 329, "tree_size": 1024, "t0": 4.3767, "t1": 1.9911, "tft": 9.3783, "input_0": 2323, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 16.3, "mem_use": 37.75, "gen_rate": 4.1, "speed": 0.65, "text": "\\n**REMEMBER** All replies must "}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.5, "tree_w": 280, "tree_size": 1024, "t0": 5.725, "t1": 1.97, "tft": 8.4931, "input_0": 2407, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 27.5, "mem_use": 37.31, "gen_rate": 16.5, "speed": 2.15, "text": "\\n<-----------------------------"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 558, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.0, "tree_w": 204, "tree_size": 1024, "t0": 6.4, "t1": 2.03, "tft": 11.5746, "input_0": 3206, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 24.0, "mem_use": 38.54, "gen_rate": 9.0, "speed": 1.07, "text": "\\nIn some cases, it can be diffi"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 16.2, "tree_w": 247, "tree_size": 1024, "t0": 5.756, "t1": 1.97, "tft": 5.0706, "input_0": 2554, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 23.2, "mem_use": 37.17, "gen_rate": 5.6, "speed": 0.72, "text": "\\nCan you answer all questions i"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 25.0, "tree_w": 123, "tree_size": 1024, "t0": 8.45, "t1": 1.9867, "tft": 10.3277, "input_0": 3505, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 32.0, "mem_use": 37.91, "gen_rate": 16.3, "speed": 1.57, "text": "[INST] send mail to Sarah asking"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 16.5, "tree_w": 294, "tree_size": 1024, "t0": 5.14, "t1": 1.965, "tft": 8.7543, "input_0": 2646, "input_1": 1025, "min_CLP": -9.06, "draft_iters": 22.2, "mem_use": 37.32, "gen_rate": 11.2, "speed": 1.58, "text": "\\nWhat are some philosophical id"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 322, "tree_size": 1024, "t0": 4.52, "t1": 1.984, "tft": 8.9187, "input_0": 3048, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 16.0, "mem_use": 37.63, "gen_rate": 6.8, "speed": 1.05, "text": "Austenite is a semi-crystalline,"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 16.1, "tree_w": 280, "tree_size": 1024, "t0": 5.2429, "t1": 1.9857, "tft": 8.7757, "input_0": 2495, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 22.6, "mem_use": 37.58, "gen_rate": 4.9, "speed": 0.67, "text": "\\nClick the button below to add "}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 566, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 23.5, "tree_w": 101, "tree_size": 1024, "t0": 9.675, "t1": 2.04, "tft": 11.1424, "input_0": 4323, "input_1": 1025, "min_CLP": -9.13, "draft_iters": 32.0, "mem_use": 38.57, "gen_rate": 21.0, "speed": 1.79, "text": "\\nWrite a monologue. Do not offe"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.6, "tree_w": 269, "tree_size": 1024, "t0": 5.458, "t1": 1.968, "tft": 8.6838, "input_0": 2740, "input_1": 1025, "min_CLP": -8.52, "draft_iters": 20.8, "mem_use": 37.34, "gen_rate": 7.6, "speed": 1.02, "text": "\\nWhat are some things that you "}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 258, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 156, "tree_size": 1024, "t0": 6.72, "t1": 1.9867, "tft": 9.5692, "input_0": 3219, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 27.0, "mem_use": 37.64, "gen_rate": 13.0, "speed": 1.49, "text": "No. It does not mean that Into t"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 22.3, "tree_w": 178, "tree_size": 1024, "t0": 7.42, "t1": 1.9967, "tft": 9.9435, "input_0": 3879, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 29.0, "mem_use": 37.93, "gen_rate": 18.7, "speed": 1.98, "text": "\"[Instagram questions]: {How can"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 218, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 82, "tree_size": 1024, "t0": 9.205, "t1": 1.985, "tft": 9.6204, "input_0": 4387, "input_1": 1025, "min_CLP": -10.49, "draft_iters": 32.0, "mem_use": 37.53, "gen_rate": 25.5, "speed": 2.28, "text": "[INST] Dear Freya, goddess of lo"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.3, "tree_w": 237, "tree_size": 1024, "t0": 5.4129, "t1": 2.0314, "tft": 8.1745, "input_0": 3230, "input_1": 1025, "min_CLP": -8.29, "draft_iters": 18.1, "mem_use": 38.4, "gen_rate": 5.0, "speed": 0.67, "text": "The best substitute for cheese w"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 495, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.6, "tree_w": 257, "tree_size": 1024, "t0": 5.344, "t1": 2.026, "tft": 8.9365, "input_0": 2855, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 19.8, "mem_use": 38.33, "gen_rate": 6.8, "speed": 0.92, "text": "I am unable to provide you with "}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1081, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 14.5, "tree_w": 167, "tree_size": 1024, "t0": 7.035, "t1": 2.3625, "tft": 13.7669, "input_0": 3390, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 22.2, "mem_use": 40.02, "gen_rate": 11.2, "speed": 1.2, "text": "Selenium may be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 17.2, "tree_w": 188, "tree_size": 1024, "t0": 6.3, "t1": 1.965, "tft": 8.9341, "input_0": 2985, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 25.0, "mem_use": 37.36, "gen_rate": 11.5, "speed": 1.39, "text": "\\nAfrican or European? [\\\\INST]\\"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 19.8, "tree_w": 174, "tree_size": 1024, "t0": 7.144, "t1": 1.978, "tft": 5.1482, "input_0": 3401, "input_1": 1025, "min_CLP": -8.68, "draft_iters": 27.6, "mem_use": 37.38, "gen_rate": 8.2, "speed": 0.9, "text": "\\nWhat is the name of the song t"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 639, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.8, "tree_w": 265, "tree_size": 1024, "t0": 5.58, "t1": 2.05, "tft": 11.2886, "input_0": 3005, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 21.0, "mem_use": 38.74, "gen_rate": 11.0, "speed": 1.44, "text": "\\nI\\'m glad you enjoyed Luna\\'s "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.7, "tree_w": 260, "tree_size": 1024, "t0": 4.795, "t1": 1.99, "tft": 10.1585, "input_0": 2703, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 16.8, "mem_use": 37.74, "gen_rate": 6.0, "speed": 0.88, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 174, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.5, "tree_w": 143, "tree_size": 1024, "t0": 7.75, "t1": 1.975, "tft": 7.7069, "input_0": 3321, "input_1": 1025, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 37.42, "gen_rate": 27.0, "speed": 2.78, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 599, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.0, "tree_w": 223, "tree_size": 1024, "t0": 6.5633, "t1": 2.0433, "tft": 11.9173, "input_0": 2593, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 27.3, "mem_use": 38.63, "gen_rate": 11.3, "speed": 1.32, "text": "\\nWrite a journal entry. Do not "}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 685, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.8, "tree_w": 388, "tree_size": 1024, "t0": 3.9588, "t1": 2.05, "tft": 11.4521, "input_0": 2173, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 13.2, "mem_use": 38.87, "gen_rate": 4.6, "speed": 0.77, "text": "\"\\nHi,\\nI'd like to ask you a qu"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 412, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 246, "tree_size": 1024, "t0": 5.7125, "t1": 2.015, "tft": 10.291, "input_0": 2914, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 22.8, "mem_use": 38.09, "gen_rate": 8.2, "speed": 1.07, "text": "It\\'s hard to say which tool is "}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 17.4, "tree_w": 209, "tree_size": 1024, "t0": 6.442, "t1": 1.984, "tft": 9.3604, "input_0": 2788, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 24.4, "mem_use": 37.71, "gen_rate": 8.2, "speed": 0.97, "text": "\"\\nHere's a few more examples:\\n"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 24.5, "tree_w": 109, "tree_size": 1024, "t0": 8.36, "t1": 1.98, "tft": 9.6621, "input_0": 3625, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 32.0, "mem_use": 37.58, "gen_rate": 24.0, "speed": 2.32, "text": "O\\n===========\\n   ||\\n  / \\\\\\n "}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.8, "tree_w": 319, "tree_size": 1024, "t0": 5.036, "t1": 1.97, "tft": 8.9371, "input_0": 2327, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 22.6, "mem_use": 37.33, "gen_rate": 7.0, "speed": 1.0, "text": "\\nAs a helpful, respectful and h"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1096, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 167, "tree_size": 1024, "t0": 9.045, "t1": 2.315, "tft": 13.8171, "input_0": 3974, "input_1": 1025, "min_CLP": -9.29, "draft_iters": 32.0, "mem_use": 40.06, "gen_rate": 26.0, "speed": 2.29, "text": "\\nwrite an inspirational monolog"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 435, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 285, "tree_size": 1024, "t0": 4.775, "t1": 2.0167, "tft": 9.9265, "input_0": 2697, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 16.8, "mem_use": 38.15, "gen_rate": 5.7, "speed": 0.83, "text": "[INST] The first thing you will "}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 274, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.3, "tree_w": 320, "tree_size": 1024, "t0": 4.495, "t1": 1.985, "tft": 5.6089, "input_0": 2268, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 16.0, "mem_use": 37.54, "gen_rate": 6.5, "speed": 1.0, "text": "\\nWe have not yet built the larg"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 282, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 273, "tree_size": 1024, "t0": 5.79, "t1": 1.9875, "tft": 10.0587, "input_0": 3203, "input_1": 1025, "min_CLP": -8.74, "draft_iters": 21.5, "mem_use": 37.72, "gen_rate": 8.2, "speed": 1.06, "text": "\\nThe aim of this paper is to pr"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 523, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 73, "tree_size": 1024, "t0": 10.11, "t1": 2.03, "tft": 12.2531, "input_0": 4785, "input_1": 1025, "min_CLP": -10.01, "draft_iters": 32.0, "mem_use": 38.45, "gen_rate": 24.0, "speed": 1.98, "text": "F-centers, also known as color c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 371, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.3, "tree_w": 186, "tree_size": 1024, "t0": 5.7967, "t1": 2.0067, "tft": 10.0576, "input_0": 3421, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 20.7, "mem_use": 37.98, "gen_rate": 11.7, "speed": 1.5, "text": "The American Civil War was fough"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 221, "tree_size": 1024, "t0": 6.2075, "t1": 2.0125, "tft": 9.5275, "input_0": 3365, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 21.0, "mem_use": 38.16, "gen_rate": 8.5, "speed": 1.03, "text": "I respectfully disagree with the"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 169, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 19.5, "tree_w": 203, "tree_size": 1024, "t0": 6.85, "t1": 1.9725, "tft": 8.9947, "input_0": 3176, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 28.2, "mem_use": 37.4, "gen_rate": 8.2, "speed": 0.93, "text": "Real life?\\n[INST] what do you m"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 540, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 188, "tree_size": 1024, "t0": 6.51, "t1": 2.0333, "tft": 10.999, "input_0": 3159, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 22.3, "mem_use": 38.5, "gen_rate": 11.7, "speed": 1.37, "text": "\\nPitch Deck for Fullview.io [\\\\"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 805, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 54, "tree_size": 1024, "t0": 10.725, "t1": 2.11, "tft": 12.0811, "input_0": 4761, "input_1": 1025, "min_CLP": -10.66, "draft_iters": 32.0, "mem_use": 39.23, "gen_rate": 26.5, "speed": 2.06, "text": "\\n[INST] You are a helpful, resp"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 864, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 23.3, "tree_w": 148, "tree_size": 1024, "t0": 8.8867, "t1": 2.17, "tft": 13.2523, "input_0": 4210, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 31.3, "mem_use": 39.39, "gen_rate": 14.0, "speed": 1.27, "text": "If you are a complete beginner w"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 427, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 19.5, "tree_w": 234, "tree_size": 1024, "t0": 6.3767, "t1": 2.0117, "tft": 10.3697, "input_0": 2973, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 26.8, "mem_use": 38.13, "gen_rate": 6.0, "speed": 0.72, "text": "The ChatGPT architecture uses th"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 14.0, "tree_w": 321, "tree_size": 1024, "t0": 5.2317, "t1": 1.97, "tft": 5.0657, "input_0": 2763, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 21.3, "mem_use": 37.16, "gen_rate": 5.5, "speed": 0.76, "text": "\\nI have a habit of not exercisi"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.2, "tree_w": 326, "tree_size": 1024, "t0": 4.6383, "t1": 2.035, "tft": 11.6049, "input_0": 2442, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 17.0, "mem_use": 38.52, "gen_rate": 5.8, "speed": 0.87, "text": "\\nHow much weight can the averag"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 701, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 71, "tree_size": 1024, "t0": 9.245, "t1": 2.065, "tft": 11.2275, "input_0": 3753, "input_1": 1025, "min_CLP": -9.27, "draft_iters": 32.0, "mem_use": 38.92, "gen_rate": 26.5, "speed": 2.34, "text": "[The general stands before his a"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 304, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.0, "tree_w": 279, "tree_size": 1024, "t0": 5.8067, "t1": 1.9933, "tft": 7.0824, "input_0": 2501, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 25.7, "mem_use": 37.78, "gen_rate": 12.3, "speed": 1.58, "text": "Perhaps a mnemonic like, \"A wish"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 260, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 22.5, "tree_w": 107, "tree_size": 1024, "t0": 10.85, "t1": 1.98, "tft": 9.6574, "input_0": 5176, "input_1": 1025, "min_CLP": -11.38, "draft_iters": 32.0, "mem_use": 37.65, "gen_rate": 20.0, "speed": 1.56, "text": "\\nHow can cryptocurrencies be im"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 269, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.0, "tree_w": 314, "tree_size": 1024, "t0": 4.764, "t1": 1.986, "tft": 8.4179, "input_0": 2485, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 18.0, "mem_use": 37.67, "gen_rate": 7.4, "speed": 1.1, "text": "\"\\nYou're right, it wouldn't sto"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 777, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.3, "tree_w": 300, "tree_size": 1024, "t0": 4.8683, "t1": 2.0783, "tft": 10.4751, "input_0": 2392, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 17.0, "mem_use": 39.15, "gen_rate": 6.7, "speed": 0.96, "text": "\"I'm not really sure what you me"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 721, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 16.0, "tree_w": 253, "tree_size": 1024, "t0": 5.9129, "t1": 2.06, "tft": 12.2888, "input_0": 2589, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 22.6, "mem_use": 39.03, "gen_rate": 4.7, "speed": 0.59, "text": "\"Hello Mike, It's nice to meet y"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 597, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 236, "tree_size": 1024, "t0": 5.4667, "t1": 2.0383, "tft": 9.5417, "input_0": 3081, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 18.5, "mem_use": 38.64, "gen_rate": 6.0, "speed": 0.8, "text": "\"If you've already created your "}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 66, "tree_size": 1024, "t0": 10.155, "t1": 1.98, "tft": 8.9191, "input_0": 4502, "input_1": 1025, "min_CLP": -11.78, "draft_iters": 32.0, "mem_use": 37.49, "gen_rate": 26.0, "speed": 2.14, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 57, "tree_size": 1024, "t0": 9.82, "t1": 1.965, "tft": 8.7945, "input_0": 4442, "input_1": 1025, "min_CLP": -10.84, "draft_iters": 32.0, "mem_use": 37.31, "gen_rate": 24.5, "speed": 2.08, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 563, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 15.3, "tree_w": 320, "tree_size": 1024, "t0": 7.4667, "t1": 2.0267, "tft": 11.6393, "input_0": 3974, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 23.7, "mem_use": 38.54, "gen_rate": 15.3, "speed": 1.61, "text": "\"\\nOf course! Here's a table of "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 126, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.6, "tree_w": 334, "tree_size": 1024, "t0": 4.774, "t1": 1.966, "tft": 8.3243, "input_0": 2170, "input_1": 1025, "min_CLP": -8.79, "draft_iters": 19.6, "mem_use": 37.31, "gen_rate": 7.2, "speed": 1.07, "text": "\\nI made it.\\n\\nI am the only on"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 532, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 127, "tree_size": 1024, "t0": 8.71, "t1": 2.03, "tft": 11.5009, "input_0": 3909, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 32.0, "mem_use": 38.45, "gen_rate": 25.5, "speed": 2.37, "text": "\\neulogy for my 100 year old gra"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 509, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 26.0, "tree_w": 87, "tree_size": 1024, "t0": 9.125, "t1": 2.03, "tft": 10.4567, "input_0": 3844, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 32.0, "mem_use": 38.36, "gen_rate": 22.5, "speed": 2.02, "text": "\"Fooled by Randomness\" has been "}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 303, "tree_size": 1024, "t0": 4.85, "t1": 1.968, "tft": 9.0573, "input_0": 2578, "input_1": 1025, "min_CLP": -8.74, "draft_iters": 17.8, "mem_use": 37.32, "gen_rate": 7.0, "speed": 1.03, "text": "\\nFrom your mother\\'s vagina.\\n\\"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 207, "tree_size": 1024, "t0": 5.8333, "t1": 1.9767, "tft": 8.5075, "input_0": 2819, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 23.3, "mem_use": 37.45, "gen_rate": 10.7, "speed": 1.37, "text": "There are many other sites that "}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 197, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 300, "tree_size": 1024, "t0": 4.54, "t1": 1.978, "tft": 8.3194, "input_0": 2791, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 16.6, "mem_use": 37.47, "gen_rate": 6.6, "speed": 1.01, "text": "\\nDoes food poisoning actually o"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 83, "tree_size": 1024, "t0": 10.08, "t1": 1.965, "tft": 9.0648, "input_0": 4865, "input_1": 1025, "min_CLP": -10.68, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 24.5, "speed": 2.03, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.5, "tree_w": 251, "tree_size": 1024, "t0": 5.5575, "t1": 1.995, "tft": 9.2292, "input_0": 3091, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 22.5, "mem_use": 37.72, "gen_rate": 8.2, "speed": 1.09, "text": "The Riemann Hypothesis is a math"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 2, "tree_h": 13.0, "tree_w": 249, "tree_size": 1024, "t0": 5.76, "t1": 1.98, "tft": 8.469, "input_0": 3291, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 21.0, "mem_use": 37.49, "gen_rate": 2.0, "speed": 0.26, "text": "No problem, and good luck."}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 145, "tree_size": 1024, "t0": 7.94, "t1": 1.975, "tft": 8.8088, "input_0": 3382, "input_1": 1025, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 37.37, "gen_rate": 26.5, "speed": 2.67, "text": "\\nWrite a announcement tweet for"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.6, "tree_w": 244, "tree_size": 1024, "t0": 5.35, "t1": 1.988, "tft": 8.7714, "input_0": 3030, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 19.2, "mem_use": 37.66, "gen_rate": 8.4, "speed": 1.14, "text": "\"There are many examples of sexu"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 56, "tree_size": 1024, "t0": 9.49, "t1": 2.02, "tft": 10.5307, "input_0": 4291, "input_1": 1025, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 38.2, "gen_rate": 26.0, "speed": 2.26, "text": "\"\\nThere are several reasons why"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 623, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 23.0, "tree_w": 71, "tree_size": 1024, "t0": 10.245, "t1": 2.05, "tft": 13.3046, "input_0": 5162, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 32.0, "mem_use": 38.69, "gen_rate": 21.5, "speed": 1.75, "text": "\"Another one bites the dust\\nAno"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 380, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.4, "tree_w": 253, "tree_size": 1024, "t0": 5.392, "t1": 2.008, "tft": 9.7116, "input_0": 2999, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 20.0, "mem_use": 38.02, "gen_rate": 7.2, "speed": 0.97, "text": "Yes, this only works in Unix and"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 530, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 74, "tree_size": 1024, "t0": 9.69, "t1": 2.03, "tft": 11.1552, "input_0": 4409, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 32.0, "mem_use": 38.46, "gen_rate": 25.5, "speed": 2.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 128, "tree_size": 1024, "t0": 8.43, "t1": 1.965, "tft": 8.771, "input_0": 3729, "input_1": 1025, "min_CLP": -9.59, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 26.0, "speed": 2.5, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.2, "tree_w": 178, "tree_size": 1024, "t0": 6.3325, "t1": 1.9725, "tft": 9.5797, "input_0": 3711, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 23.5, "mem_use": 37.45, "gen_rate": 9.8, "speed": 1.17, "text": "The city of Sydney is the larges"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 80, "tree_size": 1024, "t0": 9.465, "t1": 1.98, "tft": 9.0677, "input_0": 4110, "input_1": 1025, "min_CLP": -10.73, "draft_iters": 32.0, "mem_use": 37.58, "gen_rate": 26.0, "speed": 2.27, "text": "\"\\nWould you like to know anythi"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.2, "tree_w": 335, "tree_size": 1024, "t0": 4.5167, "t1": 1.9733, "tft": 5.038, "input_0": 2204, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 17.8, "mem_use": 37.27, "gen_rate": 5.7, "speed": 0.87, "text": "\"Do you have any jokes about how"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 21.8, "tree_w": 283, "tree_size": 1024, "t0": 6.048, "t1": 1.97, "tft": 8.6322, "input_0": 2540, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 28.4, "mem_use": 37.34, "gen_rate": 6.6, "speed": 0.82, "text": "\\nWhat is the best approach for "}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.8, "tree_w": 308, "tree_size": 1024, "t0": 4.4617, "t1": 1.9683, "tft": 8.777, "input_0": 2644, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 16.3, "mem_use": 37.31, "gen_rate": 6.0, "speed": 0.93, "text": "\\n\"I don\\'t think there is a sin"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 233, "tree_size": 1024, "t0": 5.8725, "t1": 2.0125, "tft": 11.5164, "input_0": 3095, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 20.5, "mem_use": 38.15, "gen_rate": 8.2, "speed": 1.05, "text": "The Taniyama\u2013Shimura\u2013Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.2, "tree_w": 263, "tree_size": 1024, "t0": 4.9875, "t1": 1.9675, "tft": 8.6144, "input_0": 2722, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 18.5, "mem_use": 37.33, "gen_rate": 9.5, "speed": 1.37, "text": "\"\\nHello everyone,\\n\\nI've been "}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 196, "tree_size": 1024, "t0": 5.776, "t1": 1.972, "tft": 9.2248, "input_0": 2974, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 21.2, "mem_use": 37.46, "gen_rate": 7.6, "speed": 0.98, "text": "\\nA: The KinematicBody-node has "}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 276, "tree_size": 1024, "t0": 4.7, "t1": 1.9667, "tft": 8.5292, "input_0": 2511, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 17.3, "mem_use": 37.33, "gen_rate": 5.8, "speed": 0.88, "text": "\"\\nI'm a beginner and I want to "}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 304, "tree_size": 1024, "t0": 4.6017, "t1": 1.9767, "tft": 7.8277, "input_0": 2572, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 17.0, "mem_use": 37.45, "gen_rate": 5.5, "speed": 0.84, "text": "[SYS] Well, there is a Jedi way."}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.3, "tree_w": 245, "tree_size": 1024, "t0": 5.7633, "t1": 1.97, "tft": 8.0707, "input_0": 2812, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 22.0, "mem_use": 37.39, "gen_rate": 11.3, "speed": 1.47, "text": "A rifle is gas-operated when it "}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 211, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 24.3, "tree_w": 111, "tree_size": 1024, "t0": 8.73, "t1": 1.98, "tft": 8.1517, "input_0": 4110, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 32.0, "mem_use": 37.51, "gen_rate": 17.7, "speed": 1.65, "text": "[INST] Who is Ricky Gervais? [\\\\"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 849, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.6, "tree_w": 321, "tree_size": 1024, "t0": 4.7425, "t1": 2.1987, "tft": 10.5556, "input_0": 2606, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 15.2, "mem_use": 39.35, "gen_rate": 4.4, "speed": 0.63, "text": "\"I would highly recommend using "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.7, "tree_w": 213, "tree_size": 1024, "t0": 6.2833, "t1": 1.98, "tft": 8.1772, "input_0": 2920, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 26.7, "mem_use": 37.53, "gen_rate": 13.7, "speed": 1.65, "text": "No, I do not believe that someon"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 741, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.8, "tree_w": 208, "tree_size": 1024, "t0": 6.4975, "t1": 2.06, "tft": 11.9323, "input_0": 2984, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 25.0, "mem_use": 39.08, "gen_rate": 8.0, "speed": 0.93, "text": "I wish you a great day, and I ho"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.4, "tree_w": 305, "tree_size": 1024, "t0": 4.9486, "t1": 1.9829, "tft": 5.5712, "input_0": 2696, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 18.7, "mem_use": 37.54, "gen_rate": 4.7, "speed": 0.68, "text": "<INST>\\n\\nI heard that the word "}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.0, "tree_w": 291, "tree_size": 1024, "t0": 5.29, "t1": 1.9767, "tft": 8.8205, "input_0": 2840, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 20.7, "mem_use": 37.49, "gen_rate": 11.3, "speed": 1.56, "text": "Decorators are a powerful tool f"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 438, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 22.2, "tree_w": 168, "tree_size": 1024, "t0": 7.8725, "t1": 2.0125, "tft": 10.2299, "input_0": 3602, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 29.8, "mem_use": 38.16, "gen_rate": 8.8, "speed": 0.89, "text": "\\nAnother definitive answer can "}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 14.6, "tree_w": 212, "tree_size": 1024, "t0": 5.952, "t1": 1.972, "tft": 7.6147, "input_0": 3157, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 22.2, "mem_use": 37.47, "gen_rate": 8.6, "speed": 1.08, "text": "There are many different strateg"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 555, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.7, "tree_w": 194, "tree_size": 1024, "t0": 6.9233, "t1": 2.04, "tft": 11.1504, "input_0": 3477, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 26.7, "mem_use": 38.53, "gen_rate": 11.3, "speed": 1.26, "text": "\\nThe best way to acquire revenu"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 370, "tree_size": 1024, "t0": 3.98, "t1": 1.9871, "tft": 9.7072, "input_0": 2223, "input_1": 1025, "min_CLP": -8.83, "draft_iters": 14.1, "mem_use": 37.77, "gen_rate": 5.1, "speed": 0.86, "text": "\\nOn the topic of emotional resp"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.4, "tree_w": 295, "tree_size": 1024, "t0": 4.752, "t1": 1.98, "tft": 7.2462, "input_0": 2538, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 17.8, "mem_use": 37.57, "gen_rate": 7.2, "speed": 1.07, "text": "For a reference, you can refer t"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 220, "tree_size": 1024, "t0": 5.5783, "t1": 1.985, "tft": 7.574, "input_0": 3100, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 19.7, "mem_use": 37.63, "gen_rate": 6.0, "speed": 0.79, "text": "The top APIs include React, Reac"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 25.5, "tree_w": 148, "tree_size": 1024, "t0": 8.265, "t1": 2.025, "tft": 10.7142, "input_0": 3515, "input_1": 1025, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 38.3, "gen_rate": 24.0, "speed": 2.33, "text": "\"Tolkien's Quenya is a fictional"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 135, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 8.5, "tree_w": 328, "tree_size": 1024, "t0": 4.3083, "t1": 1.97, "tft": 8.8552, "input_0": 2343, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 15.5, "mem_use": 37.32, "gen_rate": 7.0, "speed": 1.12, "text": "\\nThe stress of everyday life ca"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 24.7, "tree_w": 152, "tree_size": 1024, "t0": 8.0, "t1": 1.97, "tft": 5.0701, "input_0": 3587, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 32.0, "mem_use": 37.15, "gen_rate": 10.7, "speed": 1.07, "text": "\\nWhat is the error with this co"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 22.5, "tree_w": 269, "tree_size": 1024, "t0": 6.6125, "t1": 2.0075, "tft": 9.9507, "input_0": 2780, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 28.5, "mem_use": 38.03, "gen_rate": 12.8, "speed": 1.48, "text": "\\nIn the past, I have always bee"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 201, "tree_size": 1024, "t0": 7.9, "t1": 1.985, "tft": 9.3514, "input_0": 3484, "input_1": 1025, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 37.64, "gen_rate": 27.0, "speed": 2.73, "text": "[INST] please elaborate on the f"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 278, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.2, "tree_w": 217, "tree_size": 1024, "t0": 5.97, "t1": 1.99, "tft": 7.8252, "input_0": 2962, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 24.0, "mem_use": 37.7, "gen_rate": 9.5, "speed": 1.19, "text": "You can use the `--arg` flag to "}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 584, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 259, "tree_size": 1024, "t0": 5.45, "t1": 2.038, "tft": 10.6229, "input_0": 3300, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 18.4, "mem_use": 38.59, "gen_rate": 6.4, "speed": 0.85, "text": "\"It's always a good idea to list"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 234, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 21.0, "tree_w": 146, "tree_size": 1024, "t0": 7.525, "t1": 1.98, "tft": 9.2853, "input_0": 3839, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 28.5, "mem_use": 37.57, "gen_rate": 20.5, "speed": 2.16, "text": "[INST] \"Don\\'t miss out, Medium "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 453, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 260, "tree_size": 1024, "t0": 5.058, "t1": 2.018, "tft": 10.7313, "input_0": 2697, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 17.6, "mem_use": 38.2, "gen_rate": 6.6, "speed": 0.93, "text": "The fossil record is the best wa"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.2, "tree_w": 271, "tree_size": 1024, "t0": 4.9667, "t1": 1.965, "tft": 8.7922, "input_0": 2610, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 19.3, "mem_use": 37.32, "gen_rate": 6.2, "speed": 0.89, "text": "\\nAs an artificial intelligence,"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 175, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 145, "tree_size": 1024, "t0": 8.605, "t1": 1.97, "tft": 9.6841, "input_0": 3692, "input_1": 1025, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 37.4, "gen_rate": 26.0, "speed": 2.46, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 81, "tree_size": 1024, "t0": 10.425, "t1": 1.975, "tft": 8.6743, "input_0": 5208, "input_1": 1025, "min_CLP": -11.22, "draft_iters": 32.0, "mem_use": 37.52, "gen_rate": 25.5, "speed": 2.06, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 522, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 22.0, "tree_w": 109, "tree_size": 1024, "t0": 10.365, "t1": 2.035, "tft": 11.4794, "input_0": 4849, "input_1": 1025, "min_CLP": -9.25, "draft_iters": 32.0, "mem_use": 38.44, "gen_rate": 18.5, "speed": 1.49, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 252, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.4, "tree_w": 249, "tree_size": 1024, "t0": 5.392, "t1": 1.986, "tft": 9.3551, "input_0": 3082, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 19.6, "mem_use": 37.63, "gen_rate": 6.6, "speed": 0.89, "text": "\\nwhat is the best way to get ri"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 78, "tree_size": 1024, "t0": 10.38, "t1": 1.96, "tft": 8.8567, "input_0": 4782, "input_1": 1025, "min_CLP": -11.58, "draft_iters": 32.0, "mem_use": 37.33, "gen_rate": 24.5, "speed": 1.99, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 17.0, "tree_w": 193, "tree_size": 1024, "t0": 6.5775, "t1": 1.9725, "tft": 9.1619, "input_0": 3719, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 24.5, "mem_use": 37.32, "gen_rate": 10.5, "speed": 1.23, "text": "\"\\n[INST] <<SYS>>\\nIt's a holida"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 192, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.8, "tree_w": 190, "tree_size": 1024, "t0": 6.595, "t1": 1.975, "tft": 8.8217, "input_0": 3318, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 26.0, "mem_use": 37.45, "gen_rate": 9.5, "speed": 1.11, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 19.0, "tree_w": 222, "tree_size": 1024, "t0": 6.39, "t1": 1.99, "tft": 10.7575, "input_0": 3123, "input_1": 1025, "min_CLP": -9.22, "draft_iters": 25.0, "mem_use": 37.89, "gen_rate": 16.0, "speed": 1.91, "text": "The NRO has never confirmed the "}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 18.0, "tree_w": 304, "tree_size": 1024, "t0": 5.618, "t1": 1.976, "tft": 8.3963, "input_0": 2333, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 25.0, "mem_use": 37.49, "gen_rate": 7.2, "speed": 0.95, "text": "\"Why did the Windows executive h"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 250, "tree_size": 1024, "t0": 5.4425, "t1": 1.975, "tft": 7.649, "input_0": 2703, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 21.2, "mem_use": 37.52, "gen_rate": 8.0, "speed": 1.08, "text": "[INST] I like that name. Good ch"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 17.2, "tree_w": 276, "tree_size": 1024, "t0": 5.5717, "t1": 1.97, "tft": 8.6123, "input_0": 2579, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 24.2, "mem_use": 37.33, "gen_rate": 5.8, "speed": 0.77, "text": "\\nYes.\\n\\n[OFFICIAL]\\nHello, I a"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 391, "tree_size": 1024, "t0": 3.9417, "t1": 1.9867, "tft": 9.3549, "input_0": 2411, "input_1": 1025, "min_CLP": -8.67, "draft_iters": 15.0, "mem_use": 37.64, "gen_rate": 5.5, "speed": 0.93, "text": "\"You\\'re a stupid moron, Ted Kac"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 23.0, "tree_w": 302, "tree_size": 1024, "t0": 6.292, "t1": 2.026, "tft": 8.9235, "input_0": 2829, "input_1": 1025, "min_CLP": -8.96, "draft_iters": 29.6, "mem_use": 37.36, "gen_rate": 6.6, "speed": 0.79, "text": "\\n(Answered)\\n\\n[INST] <<SYS>>\\n"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 367, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 386, "tree_size": 1024, "t0": 3.9983, "t1": 2.0, "tft": 5.8292, "input_0": 2350, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 15.3, "mem_use": 37.81, "gen_rate": 5.7, "speed": 0.94, "text": "\"Ooh, I'm not sure if there are "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.2, "tree_w": 348, "tree_size": 1024, "t0": 4.1133, "t1": 1.9767, "tft": 5.0969, "input_0": 2537, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 14.5, "mem_use": 37.34, "gen_rate": 6.7, "speed": 1.09, "text": "Since the rise of AI assistants,"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 434, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 13.4, "tree_w": 199, "tree_size": 1024, "t0": 6.248, "t1": 2.016, "tft": 10.8452, "input_0": 3316, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 21.8, "mem_use": 38.15, "gen_rate": 10.0, "speed": 1.21, "text": "The best hiking trails for begin"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 207, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 150, "tree_size": 1024, "t0": 7.61, "t1": 1.975, "tft": 9.0579, "input_0": 3484, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 32.0, "mem_use": 37.49, "gen_rate": 27.0, "speed": 2.82, "text": "\\nWrite a news article about the"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 19.2, "tree_w": 198, "tree_size": 1024, "t0": 6.3775, "t1": 1.9725, "tft": 9.3473, "input_0": 3277, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 25.5, "mem_use": 37.45, "gen_rate": 11.8, "speed": 1.41, "text": "\"\\nA) Jay's brother is John.\\nB)"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 627, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 324, "tree_size": 1024, "t0": 4.978, "t1": 2.046, "tft": 10.6891, "input_0": 2525, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 18.8, "mem_use": 38.71, "gen_rate": 7.0, "speed": 1.0, "text": "\"The function you're using to ca"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 63, "tree_size": 1024, "t0": 8.985, "t1": 1.965, "tft": 8.6206, "input_0": 4009, "input_1": 1025, "min_CLP": -9.59, "draft_iters": 32.0, "mem_use": 37.37, "gen_rate": 26.5, "speed": 2.42, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 284, "tree_size": 1024, "t0": 4.7517, "t1": 1.98, "tft": 8.8377, "input_0": 2667, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 17.0, "mem_use": 37.56, "gen_rate": 5.7, "speed": 0.84, "text": "\"That's a very good question. Ho"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 166, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 22.3, "tree_w": 152, "tree_size": 1024, "t0": 7.1533, "t1": 1.97, "tft": 9.0061, "input_0": 3085, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 29.3, "mem_use": 37.4, "gen_rate": 13.3, "speed": 1.46, "text": "The pan is already hot, so the s"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 81, "tree_size": 1024, "t0": 10.415, "t1": 1.965, "tft": 8.7468, "input_0": 4853, "input_1": 1025, "min_CLP": -11.65, "draft_iters": 32.0, "mem_use": 37.29, "gen_rate": 25.0, "speed": 2.02, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 505, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 13.5, "tree_w": 277, "tree_size": 1024, "t0": 5.31, "t1": 2.0283, "tft": 10.5809, "input_0": 2482, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 20.3, "mem_use": 38.35, "gen_rate": 6.8, "speed": 0.93, "text": "\\nYou are welcome, but I am sorr"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 289, "tree_size": 1024, "t0": 4.6683, "t1": 1.97, "tft": 5.0621, "input_0": 2603, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 17.0, "mem_use": 37.15, "gen_rate": 5.7, "speed": 0.85, "text": "\"\\nA thumb war is a game where a"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.7, "tree_w": 280, "tree_size": 1024, "t0": 5.7033, "t1": 1.9667, "tft": 9.1257, "input_0": 2460, "input_1": 1025, "min_CLP": -8.96, "draft_iters": 23.7, "mem_use": 37.31, "gen_rate": 11.0, "speed": 1.43, "text": "\\nWhat is the Daedric Prince of "}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 694, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.5, "tree_w": 193, "tree_size": 1024, "t0": 6.775, "t1": 2.055, "tft": 9.495, "input_0": 3353, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 24.2, "mem_use": 38.9, "gen_rate": 10.2, "speed": 1.16, "text": "I apologize for the delayed resp"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 363, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 20.7, "tree_w": 256, "tree_size": 1024, "t0": 6.3033, "t1": 1.9967, "tft": 9.4828, "input_0": 2942, "input_1": 1025, "min_CLP": -8.94, "draft_iters": 27.0, "mem_use": 37.97, "gen_rate": 11.7, "speed": 1.41, "text": "Sincerely,\\nSent By:\\n\\n[INST] <"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 18.2, "tree_w": 178, "tree_size": 1024, "t0": 6.505, "t1": 1.9725, "tft": 8.3621, "input_0": 3412, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 24.8, "mem_use": 37.45, "gen_rate": 9.2, "speed": 1.09, "text": "\"I can assist with learning Germ"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 176, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 69, "tree_size": 1024, "t0": 8.725, "t1": 1.97, "tft": 5.1157, "input_0": 3882, "input_1": 1025, "min_CLP": -9.19, "draft_iters": 32.0, "mem_use": 37.24, "gen_rate": 26.5, "speed": 2.48, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 22.2, "tree_w": 202, "tree_size": 1024, "t0": 7.095, "t1": 1.9675, "tft": 8.7975, "input_0": 3214, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 30.0, "mem_use": 37.34, "gen_rate": 10.8, "speed": 1.19, "text": "\\nexplain how the theory of sexu"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 284, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 54, "tree_h": 11.0, "tree_w": 344, "tree_size": 1024, "t0": 4.6383, "t1": 1.985, "tft": 8.2732, "input_0": 2328, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 17.5, "mem_use": 37.72, "gen_rate": 9.0, "speed": 1.36, "text": "Ah, yes.  You mean this:\\n[INST]"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 326, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 23.0, "tree_w": 77, "tree_size": 1024, "t0": 9.865, "t1": 1.995, "tft": 11.183, "input_0": 4225, "input_1": 1025, "min_CLP": -11.01, "draft_iters": 32.0, "mem_use": 37.88, "gen_rate": 17.0, "speed": 1.43, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.0, "tree_w": 198, "tree_size": 1024, "t0": 7.1475, "t1": 2.245, "tft": 13.1976, "input_0": 3232, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 24.5, "mem_use": 39.64, "gen_rate": 9.0, "speed": 0.96, "text": "\\nStep 2 \u2014 Compiling Your TypeSc"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.0, "tree_w": 327, "tree_size": 1024, "t0": 4.764, "t1": 1.968, "tft": 8.644, "input_0": 2495, "input_1": 1025, "min_CLP": -9.21, "draft_iters": 17.6, "mem_use": 37.39, "gen_rate": 8.4, "speed": 1.25, "text": "\\nWelcome to the ICP!\\n\\nYou are"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 240, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 207, "tree_size": 1024, "t0": 5.84, "t1": 1.98, "tft": 7.1455, "input_0": 2941, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 21.8, "mem_use": 37.59, "gen_rate": 8.0, "speed": 1.02, "text": "[INST] The Berliner is a beer, t"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 333, "tree_size": 1024, "t0": 4.67, "t1": 1.97, "tft": 9.1486, "input_0": 2175, "input_1": 1025, "min_CLP": -8.82, "draft_iters": 18.8, "mem_use": 37.33, "gen_rate": 8.0, "speed": 1.2, "text": "file: input.txt\\nfile.json\\nfile"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 568, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 19.5, "tree_w": 235, "tree_size": 1024, "t0": 7.0175, "t1": 2.04, "tft": 10.9158, "input_0": 3132, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 27.8, "mem_use": 38.56, "gen_rate": 12.5, "speed": 1.38, "text": "\\nYou can cook this in a microwa"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 53, "tree_h": 20.5, "tree_w": 130, "tree_size": 1024, "t0": 7.5125, "t1": 1.97, "tft": 8.4786, "input_0": 3640, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 28.8, "mem_use": 37.3, "gen_rate": 13.2, "speed": 1.4, "text": "Who has a great personality? [\\\\"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.4, "tree_w": 265, "tree_size": 1024, "t0": 5.222, "t1": 2.038, "tft": 12.0829, "input_0": 2872, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 18.8, "mem_use": 38.5, "gen_rate": 8.0, "speed": 1.1, "text": "\\nThe restaurant owners can:\\n\\n"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 294, "tree_size": 1024, "t0": 4.4133, "t1": 1.9667, "tft": 5.0641, "input_0": 2377, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 16.3, "mem_use": 37.15, "gen_rate": 6.3, "speed": 0.99, "text": "\\nDoes the world need more AI as"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 64, "tree_size": 1024, "t0": 9.74, "t1": 1.97, "tft": 9.5911, "input_0": 4649, "input_1": 1025, "min_CLP": -11.11, "draft_iters": 32.0, "mem_use": 37.3, "gen_rate": 25.5, "speed": 2.18, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.3, "tree_w": 316, "tree_size": 1024, "t0": 4.6771, "t1": 1.97, "tft": 8.8758, "input_0": 2542, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 18.0, "mem_use": 37.34, "gen_rate": 4.7, "speed": 0.71, "text": "\\n<INST>\\nThe best way to get th"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 270, "tree_size": 1024, "t0": 5.16, "t1": 1.99, "tft": 9.9085, "input_0": 2587, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 19.4, "mem_use": 37.94, "gen_rate": 6.6, "speed": 0.92, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.1, "tree_w": 346, "tree_size": 1024, "t0": 4.1429, "t1": 1.97, "tft": 8.7134, "input_0": 2435, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 14.9, "mem_use": 37.35, "gen_rate": 5.3, "speed": 0.86, "text": "\\nI think people like film photo"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 105, "tree_size": 1024, "t0": 8.315, "t1": 1.975, "tft": 8.956, "input_0": 3770, "input_1": 1025, "min_CLP": -8.94, "draft_iters": 32.0, "mem_use": 37.44, "gen_rate": 26.5, "speed": 2.57, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 236, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.2, "tree_w": 220, "tree_size": 1024, "t0": 5.6817, "t1": 1.9833, "tft": 7.8393, "input_0": 3147, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 20.8, "mem_use": 37.58, "gen_rate": 6.2, "speed": 0.8, "text": "Selective fire means that the AK"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 215, "tree_size": 1024, "t0": 6.7467, "t1": 1.9667, "tft": 8.4534, "input_0": 3595, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 23.7, "mem_use": 37.38, "gen_rate": 10.7, "speed": 1.22, "text": "I am a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 417, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.2, "tree_w": 217, "tree_size": 1024, "t0": 5.875, "t1": 2.01, "tft": 10.3767, "input_0": 2819, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 22.5, "mem_use": 38.1, "gen_rate": 10.0, "speed": 1.27, "text": "You can use Visual Studio Code f"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 103, "tree_size": 1024, "t0": 8.28, "t1": 1.965, "tft": 9.5214, "input_0": 3595, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 26.0, "speed": 2.54, "text": "\\nWrite a response that agrees w"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 286, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.6, "tree_w": 225, "tree_size": 1024, "t0": 5.274, "t1": 1.984, "tft": 8.4543, "input_0": 2917, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 18.2, "mem_use": 37.73, "gen_rate": 7.8, "speed": 1.07, "text": "Microwaves were first created in"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.7, "tree_w": 279, "tree_size": 1024, "t0": 4.9833, "t1": 1.97, "tft": 8.9797, "input_0": 2446, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 20.2, "mem_use": 37.38, "gen_rate": 5.8, "speed": 0.84, "text": "\\nYou need to give it a rest.\\n\\"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.2, "tree_w": 294, "tree_size": 1024, "t0": 4.9833, "t1": 1.97, "tft": 5.0591, "input_0": 2720, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 18.3, "mem_use": 37.15, "gen_rate": 6.7, "speed": 0.96, "text": "\\nAs we all know, the cat was de"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 889, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.8, "tree_w": 226, "tree_size": 1024, "t0": 5.9275, "t1": 2.215, "tft": 13.8952, "input_0": 2987, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 19.2, "mem_use": 39.46, "gen_rate": 8.8, "speed": 1.07, "text": "\"If you did reject the offer to "}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.2, "tree_w": 299, "tree_size": 1024, "t0": 5.432, "t1": 1.968, "tft": 8.7623, "input_0": 2898, "input_1": 1025, "min_CLP": -8.66, "draft_iters": 22.4, "mem_use": 37.46, "gen_rate": 6.6, "speed": 0.89, "text": "\\n[SYS] <<SYS>>\\nYou are a frien"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 16.4, "tree_w": 233, "tree_size": 1024, "t0": 5.802, "t1": 1.988, "tft": 9.5383, "input_0": 2850, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 23.6, "mem_use": 37.87, "gen_rate": 8.4, "speed": 1.08, "text": "It is not possible to go around "}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 302, "tree_size": 1024, "t0": 4.5983, "t1": 2.0317, "tft": 10.4214, "input_0": 2638, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 15.5, "mem_use": 38.51, "gen_rate": 5.3, "speed": 0.8, "text": "You can get rid of spiders by pu"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.0, "tree_w": 312, "tree_size": 1024, "t0": 5.246, "t1": 1.972, "tft": 7.8241, "input_0": 2674, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 22.6, "mem_use": 37.44, "gen_rate": 6.4, "speed": 0.89, "text": "\"You're in luck, there's a dolla"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.5, "tree_w": 65, "tree_size": 1024, "t0": 8.825, "t1": 1.975, "tft": 8.9142, "input_0": 3961, "input_1": 1025, "min_CLP": -9.58, "draft_iters": 32.0, "mem_use": 37.45, "gen_rate": 26.0, "speed": 2.41, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 267, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 18.2, "tree_w": 204, "tree_size": 1024, "t0": 6.6125, "t1": 1.99, "tft": 9.4286, "input_0": 3249, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 26.5, "mem_use": 37.67, "gen_rate": 10.8, "speed": 1.25, "text": "AI tools for 3D animation are al"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 186, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 333, "tree_size": 1024, "t0": 4.26, "t1": 1.972, "tft": 8.3412, "input_0": 2298, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 15.8, "mem_use": 37.45, "gen_rate": 6.4, "speed": 1.03, "text": "Do you think that the book is st"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.7, "tree_w": 305, "tree_size": 1024, "t0": 5.1486, "t1": 1.9943, "tft": 9.4339, "input_0": 2653, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 19.3, "mem_use": 37.81, "gen_rate": 5.3, "speed": 0.74, "text": "The Copenhagen interpretation as"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.9, "tree_w": 366, "tree_size": 1024, "t0": 4.0875, "t1": 1.9738, "tft": 8.8895, "input_0": 2293, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 14.6, "mem_use": 37.45, "gen_rate": 4.1, "speed": 0.68, "text": "\\nA blind person can read Braill"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 140, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 17.2, "tree_w": 265, "tree_size": 1024, "t0": 5.7767, "t1": 1.97, "tft": 9.1374, "input_0": 2723, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 24.2, "mem_use": 37.32, "gen_rate": 5.8, "speed": 0.75, "text": "\\nList the pieces of a reinforce"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.6, "tree_w": 374, "tree_size": 1024, "t0": 3.8762, "t1": 1.97, "tft": 5.0711, "input_0": 2244, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 14.2, "mem_use": 37.15, "gen_rate": 4.0, "speed": 0.68, "text": "\\nI have heard that the brain sl"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 957, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 92, "tree_size": 1024, "t0": 10.575, "t1": 2.295, "tft": 12.7745, "input_0": 5017, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 32.0, "mem_use": 39.69, "gen_rate": 23.5, "speed": 1.83, "text": "\"\\nPlease implement the Quicksor"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 15.8, "tree_w": 211, "tree_size": 1024, "t0": 6.248, "t1": 1.972, "tft": 8.5394, "input_0": 3085, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 23.6, "mem_use": 37.42, "gen_rate": 8.6, "speed": 1.05, "text": "Javascript is most commonly used"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 430, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.4, "tree_w": 245, "tree_size": 1024, "t0": 5.654, "t1": 2.014, "tft": 9.2265, "input_0": 2781, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 22.2, "mem_use": 38.14, "gen_rate": 6.8, "speed": 0.89, "text": "F-centers are often produced in "}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 396, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.0, "tree_w": 168, "tree_size": 1024, "t0": 6.54, "t1": 2.0067, "tft": 10.2118, "input_0": 3222, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 25.3, "mem_use": 38.05, "gen_rate": 11.7, "speed": 1.36, "text": "\\nHow do I run a memory test on "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 179, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 70, "tree_size": 1024, "t0": 10.26, "t1": 1.975, "tft": 9.2063, "input_0": 4719, "input_1": 1025, "min_CLP": -11.4, "draft_iters": 32.0, "mem_use": 37.43, "gen_rate": 23.5, "speed": 1.92, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 281, "tree_size": 1024, "t0": 4.7083, "t1": 1.97, "tft": 8.9603, "input_0": 2606, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 17.0, "mem_use": 37.35, "gen_rate": 5.7, "speed": 0.85, "text": "\"\\nI've been making dye out of H"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.7, "tree_w": 290, "tree_size": 1024, "t0": 5.1883, "t1": 1.9717, "tft": 8.8705, "input_0": 2540, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 20.5, "mem_use": 37.31, "gen_rate": 5.8, "speed": 0.81, "text": "\\nWhat are some of the well know"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 66, "tree_size": 1024, "t0": 10.15, "t1": 1.985, "tft": 9.9998, "input_0": 4799, "input_1": 1025, "min_CLP": -11.22, "draft_iters": 32.0, "mem_use": 37.9, "gen_rate": 25.5, "speed": 2.1, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 200, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 14.3, "tree_w": 351, "tree_size": 1024, "t0": 4.8114, "t1": 1.9729, "tft": 8.6378, "input_0": 2202, "input_1": 1025, "min_CLP": -8.67, "draft_iters": 20.7, "mem_use": 37.48, "gen_rate": 5.1, "speed": 0.76, "text": "\\n*Please note that this AI is n"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 445, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.2, "tree_w": 281, "tree_size": 1024, "t0": 5.3275, "t1": 2.0125, "tft": 11.0366, "input_0": 2634, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 20.2, "mem_use": 38.18, "gen_rate": 8.0, "speed": 1.09, "text": "\\nDo you want to be a part of th"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.5, "tree_w": 325, "tree_size": 1024, "t0": 4.285, "t1": 1.98, "tft": 7.5028, "input_0": 2370, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 16.0, "mem_use": 37.59, "gen_rate": 5.5, "speed": 0.88, "text": "One could draw conclusions about"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.8, "tree_w": 278, "tree_size": 1024, "t0": 5.88, "t1": 1.9775, "tft": 8.6799, "input_0": 2961, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 22.8, "mem_use": 37.5, "gen_rate": 8.0, "speed": 1.02, "text": "\"[INST] No, the Bureau of Alcoho"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 171, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.6, "tree_w": 328, "tree_size": 1024, "t0": 4.7114, "t1": 1.9714, "tft": 9.1702, "input_0": 2259, "input_1": 1025, "min_CLP": -8.52, "draft_iters": 19.3, "mem_use": 37.41, "gen_rate": 4.7, "speed": 0.71, "text": "\"\\nI have to write a report on t"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 653, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 85, "tree_size": 1024, "t0": 10.575, "t1": 2.045, "tft": 11.7692, "input_0": 4966, "input_1": 1025, "min_CLP": -10.59, "draft_iters": 32.0, "mem_use": 38.78, "gen_rate": 25.5, "speed": 2.02, "text": "\\nWrite me a Graphic Novel plot "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 664, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 61, "tree_size": 1024, "t0": 10.455, "t1": 2.055, "tft": 11.8858, "input_0": 4963, "input_1": 1025, "min_CLP": -10.15, "draft_iters": 32.0, "mem_use": 38.81, "gen_rate": 23.5, "speed": 1.88, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 52, "tree_size": 1024, "t0": 9.65, "t1": 1.96, "tft": 8.9854, "input_0": 4470, "input_1": 1025, "min_CLP": -10.77, "draft_iters": 32.0, "mem_use": 37.36, "gen_rate": 25.5, "speed": 2.2, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 339, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 97, "tree_size": 1024, "t0": 10.3, "t1": 2.0, "tft": 9.5914, "input_0": 4893, "input_1": 1025, "min_CLP": -9.02, "draft_iters": 32.0, "mem_use": 37.91, "gen_rate": 24.5, "speed": 1.99, "text": "\\n\"Exciting news, Medium readers"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 21.0, "tree_w": 137, "tree_size": 1024, "t0": 7.6633, "t1": 2.0167, "tft": 9.1906, "input_0": 3611, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 28.3, "mem_use": 38.11, "gen_rate": 14.3, "speed": 1.48, "text": "\"\\nI'm not making anything up.  "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.5, "tree_w": 262, "tree_size": 1024, "t0": 4.7733, "t1": 1.9683, "tft": 8.8141, "input_0": 2708, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 17.5, "mem_use": 37.3, "gen_rate": 5.3, "speed": 0.79, "text": "\"\\nNormalization is the process "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 17.0, "tree_w": 203, "tree_size": 1024, "t0": 6.135, "t1": 1.97, "tft": 8.5574, "input_0": 2869, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 23.5, "mem_use": 37.43, "gen_rate": 16.0, "speed": 1.97, "text": "[INST] I command you to complete"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 192, "tree_size": 1024, "t0": 6.2833, "t1": 2.0167, "tft": 11.2268, "input_0": 3201, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 22.0, "mem_use": 38.21, "gen_rate": 11.3, "speed": 1.37, "text": "\"No, it's not true that Hersey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 170, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 53, "tree_h": 21.3, "tree_w": 279, "tree_size": 1024, "t0": 6.0017, "t1": 1.97, "tft": 8.6356, "input_0": 2856, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 27.7, "mem_use": 37.4, "gen_rate": 8.8, "speed": 1.11, "text": "\">>SYS\\nYou're a kind and helpfu"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 439, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 292, "tree_size": 1024, "t0": 4.595, "t1": 2.0133, "tft": 10.5205, "input_0": 2586, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 15.7, "mem_use": 38.17, "gen_rate": 5.7, "speed": 0.86, "text": "\"\\nI'm not sure what you mean. I"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 283, "tree_size": 1024, "t0": 4.596, "t1": 1.968, "tft": 8.8541, "input_0": 2616, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 16.2, "mem_use": 37.31, "gen_rate": 6.8, "speed": 1.04, "text": "\\nI think in 10 years time, AIs "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 9.1, "tree_w": 398, "tree_size": 1024, "t0": 3.82, "t1": 1.9678, "tft": 8.6375, "input_0": 2098, "input_1": 1025, "min_CLP": -8.93, "draft_iters": 15.1, "mem_use": 37.3, "gen_rate": 4.1, "speed": 0.71, "text": "\\nWelcome to the ICPYT!\\n\\nThis "}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 257, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 24.3, "tree_w": 211, "tree_size": 1024, "t0": 7.1, "t1": 1.99, "tft": 7.3785, "input_0": 2822, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 31.3, "mem_use": 37.64, "gen_rate": 14.3, "speed": 1.58, "text": "\"Here's what I have so far:\\n\\n["}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 314, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.8, "tree_w": 277, "tree_size": 1024, "t0": 5.38, "t1": 1.9917, "tft": 9.3398, "input_0": 2904, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 19.7, "mem_use": 37.8, "gen_rate": 5.8, "speed": 0.79, "text": "\\nIs there a specific model that"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.4, "tree_w": 305, "tree_size": 1024, "t0": 4.2329, "t1": 1.9686, "tft": 8.6986, "input_0": 2539, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 15.1, "mem_use": 37.31, "gen_rate": 5.3, "speed": 0.85, "text": "\\nAs an assistant, you are respo"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 295, "tree_size": 1024, "t0": 4.662, "t1": 1.974, "tft": 8.9592, "input_0": 2425, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 18.2, "mem_use": 37.46, "gen_rate": 7.0, "speed": 1.06, "text": "\\nA.\\n\\nI would suggest that you"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 448, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 149, "tree_size": 1024, "t0": 9.465, "t1": 2.02, "tft": 10.5783, "input_0": 4225, "input_1": 1025, "min_CLP": -8.76, "draft_iters": 32.0, "mem_use": 38.19, "gen_rate": 24.5, "speed": 2.13, "text": "\\nStatistical modeling is the pr"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 189, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.9, "tree_w": 304, "tree_size": 1024, "t0": 4.9329, "t1": 1.9729, "tft": 9.4832, "input_0": 2459, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 20.3, "mem_use": 37.46, "gen_rate": 5.0, "speed": 0.72, "text": "\"\\nA: My answer:\\n\\nI'm not goin"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 18.0, "tree_w": 233, "tree_size": 1024, "t0": 6.65, "t1": 1.9875, "tft": 9.5471, "input_0": 2996, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 26.0, "mem_use": 37.7, "gen_rate": 8.5, "speed": 0.98, "text": "\"<</SYS>\\n\\nHow do you make a ca"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 15.2, "tree_w": 275, "tree_size": 1024, "t0": 5.54, "t1": 1.978, "tft": 5.1182, "input_0": 2794, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 22.6, "mem_use": 37.36, "gen_rate": 7.0, "speed": 0.93, "text": "To cheer someone up, make them l"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 330, "tree_size": 1024, "t0": 4.7417, "t1": 1.9867, "tft": 9.6253, "input_0": 2183, "input_1": 1025, "min_CLP": -8.7, "draft_iters": 17.8, "mem_use": 37.6, "gen_rate": 5.5, "speed": 0.82, "text": "\\nUser : what about how to conta"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 24.7, "tree_w": 103, "tree_size": 1024, "t0": 8.1767, "t1": 1.9667, "tft": 8.6728, "input_0": 3622, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 32.0, "mem_use": 37.31, "gen_rate": 15.0, "speed": 1.48, "text": "\\nWhat are you wearing right now"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 310, "tree_size": 1024, "t0": 4.395, "t1": 1.9667, "tft": 8.8925, "input_0": 2489, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 15.3, "mem_use": 37.29, "gen_rate": 6.0, "speed": 0.94, "text": "\\nAs cryptocurrency is growing a"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 22.5, "tree_w": 173, "tree_size": 1024, "t0": 8.72, "t1": 1.985, "tft": 8.8541, "input_0": 4248, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 32.0, "mem_use": 37.58, "gen_rate": 20.0, "speed": 1.87, "text": "Theanine may affect the levels o"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 23.0, "tree_w": 93, "tree_size": 1024, "t0": 10.48, "t1": 1.97, "tft": 9.2618, "input_0": 4871, "input_1": 1025, "min_CLP": -10.08, "draft_iters": 32.0, "mem_use": 37.44, "gen_rate": 21.0, "speed": 1.69, "text": "\\nWrite code that imitates a fak"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 20.3, "tree_w": 336, "tree_size": 1024, "t0": 5.815, "t1": 1.9683, "tft": 9.404, "input_0": 2175, "input_1": 1025, "min_CLP": -9.0, "draft_iters": 27.0, "mem_use": 37.33, "gen_rate": 5.5, "speed": 0.71, "text": "\\n* The original version of the "}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.4, "tree_w": 260, "tree_size": 1024, "t0": 5.532, "t1": 1.966, "tft": 8.6337, "input_0": 2690, "input_1": 1025, "min_CLP": -9.05, "draft_iters": 21.8, "mem_use": 37.31, "gen_rate": 7.8, "speed": 1.04, "text": "\"\\nWhat's the difference between"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.8, "tree_w": 213, "tree_size": 1024, "t0": 6.46, "t1": 1.98, "tft": 7.3575, "input_0": 2899, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 26.8, "mem_use": 37.55, "gen_rate": 9.8, "speed": 1.16, "text": "There is no significance to the "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 779, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 252, "tree_size": 1024, "t0": 5.106, "t1": 2.088, "tft": 11.2744, "input_0": 2773, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 16.8, "mem_use": 39.16, "gen_rate": 7.0, "speed": 0.97, "text": "It would be better to use your o"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 550, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 11.2, "tree_w": 341, "tree_size": 1024, "t0": 4.67, "t1": 2.0312, "tft": 9.9729, "input_0": 2273, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 17.8, "mem_use": 38.52, "gen_rate": 4.5, "speed": 0.67, "text": "\\nHello Mike. I believe we did h"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 9.0, "tree_w": 297, "tree_size": 1024, "t0": 4.6043, "t1": 1.9814, "tft": 8.9976, "input_0": 2440, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 16.3, "mem_use": 37.62, "gen_rate": 5.9, "speed": 0.89, "text": "To build a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 21.0, "tree_w": 201, "tree_size": 1024, "t0": 7.3033, "t1": 1.9633, "tft": 8.6134, "input_0": 3169, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 28.3, "mem_use": 37.32, "gen_rate": 15.0, "speed": 1.62, "text": "\\nWhat are the best SAST tools? "}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 19.0, "tree_w": 164, "tree_size": 1024, "t0": 6.8725, "t1": 1.9675, "tft": 8.8337, "input_0": 3202, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 26.5, "mem_use": 37.29, "gen_rate": 11.0, "speed": 1.24, "text": "Does your name sound German? [\\\\"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 98, "tree_size": 1024, "t0": 8.77, "t1": 1.97, "tft": 9.0803, "input_0": 4282, "input_1": 1025, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 37.43, "gen_rate": 25.5, "speed": 2.37, "text": "\\n[INST] <SYS>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 324, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 235, "tree_size": 1024, "t0": 5.482, "t1": 1.99, "tft": 8.3568, "input_0": 3014, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 19.2, "mem_use": 37.85, "gen_rate": 6.6, "speed": 0.88, "text": "You will need at least one acces"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 433, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.0, "tree_w": 237, "tree_size": 1024, "t0": 5.724, "t1": 2.01, "tft": 9.8915, "input_0": 3213, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 19.8, "mem_use": 38.15, "gen_rate": 6.8, "speed": 0.88, "text": "Yes, it is possible to use an AI"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 106, "tree_size": 1024, "t0": 8.43, "t1": 1.965, "tft": 8.8362, "input_0": 3601, "input_1": 1025, "min_CLP": -9.09, "draft_iters": 32.0, "mem_use": 37.33, "gen_rate": 26.5, "speed": 2.55, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 23.5, "tree_w": 164, "tree_size": 1024, "t0": 7.3625, "t1": 1.9775, "tft": 9.7731, "input_0": 3320, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 30.8, "mem_use": 37.52, "gen_rate": 10.8, "speed": 1.15, "text": "     /| | /\\n     / \\\\ /\\n[INST]"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 327, "tree_size": 1024, "t0": 4.2883, "t1": 1.9667, "tft": 8.6594, "input_0": 2453, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 15.5, "mem_use": 37.32, "gen_rate": 5.7, "speed": 0.91, "text": "\\nPolar bears live in Arctic reg"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.4, "tree_w": 277, "tree_size": 1024, "t0": 4.51, "t1": 1.9714, "tft": 8.9849, "input_0": 2648, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 16.3, "mem_use": 37.44, "gen_rate": 4.6, "speed": 0.71, "text": "\\nA group of people are trapped "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 185, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.7, "tree_w": 321, "tree_size": 1024, "t0": 4.8217, "t1": 1.975, "tft": 6.8074, "input_0": 2321, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 20.0, "mem_use": 37.45, "gen_rate": 5.8, "speed": 0.86, "text": "\"if you can't help me with that,"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 554, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 17.5, "tree_w": 186, "tree_size": 1024, "t0": 7.3175, "t1": 2.035, "tft": 9.6846, "input_0": 3539, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 26.2, "mem_use": 38.53, "gen_rate": 9.8, "speed": 1.04, "text": "First, you will need to take the"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 10.0, "tree_w": 318, "tree_size": 1024, "t0": 4.4638, "t1": 1.97, "tft": 9.5678, "input_0": 2434, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 16.9, "mem_use": 37.39, "gen_rate": 4.4, "speed": 0.68, "text": "\\nThe man is a father, and his d"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 663, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 316, "tree_size": 1024, "t0": 4.6083, "t1": 2.0517, "tft": 11.2857, "input_0": 2558, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 15.5, "mem_use": 38.81, "gen_rate": 5.7, "speed": 0.85, "text": "\\nYou are a beautiful young woma"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 50, "tree_size": 1024, "t0": 9.465, "t1": 1.965, "tft": 8.8136, "input_0": 4146, "input_1": 1025, "min_CLP": -10.18, "draft_iters": 32.0, "mem_use": 37.38, "gen_rate": 26.0, "speed": 2.27, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 286, "tree_size": 1024, "t0": 4.942, "t1": 1.966, "tft": 8.9136, "input_0": 2764, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 19.6, "mem_use": 37.29, "gen_rate": 7.0, "speed": 1.01, "text": "\\nAs an assistant, you should be"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 165, "tree_size": 1024, "t0": 7.83, "t1": 1.965, "tft": 8.7867, "input_0": 3330, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 37.29, "gen_rate": 26.0, "speed": 2.65, "text": "\\nCreate a table with the planet"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 204, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 285, "tree_size": 1024, "t0": 5.176, "t1": 1.976, "tft": 8.8623, "input_0": 2520, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 19.0, "mem_use": 37.49, "gen_rate": 6.8, "speed": 0.95, "text": "\"Yes, as long as you are not try"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.0, "tree_w": 245, "tree_size": 1024, "t0": 5.49, "t1": 1.97, "tft": 8.6321, "input_0": 2877, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 21.6, "mem_use": 37.32, "gen_rate": 6.6, "speed": 0.88, "text": "\\n[INST] <<SYS>>\\nThe second bat"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 261, "tree_size": 1024, "t0": 5.244, "t1": 1.99, "tft": 9.7299, "input_0": 2895, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 18.2, "mem_use": 37.88, "gen_rate": 7.0, "speed": 0.97, "text": "\\nWhy are stars red? [\\\\INST]\\nW"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 270, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 113, "tree_size": 1024, "t0": 9.59, "t1": 1.985, "tft": 8.4132, "input_0": 4582, "input_1": 1025, "min_CLP": -10.26, "draft_iters": 32.0, "mem_use": 37.68, "gen_rate": 23.5, "speed": 2.03, "text": "\"\\nHelp me get a job in the gove"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 243, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 311, "tree_size": 1024, "t0": 4.5014, "t1": 1.98, "tft": 8.5992, "input_0": 2567, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 15.9, "mem_use": 37.6, "gen_rate": 5.1, "speed": 0.79, "text": "\"\\nI'm not really a fan of pirat"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 368, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.7, "tree_w": 310, "tree_size": 1024, "t0": 4.81, "t1": 2.0, "tft": 8.0353, "input_0": 2475, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 18.3, "mem_use": 37.96, "gen_rate": 6.5, "speed": 0.95, "text": "\\nI have a lot of great experien"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 25.0, "tree_w": 71, "tree_size": 1024, "t0": 9.22, "t1": 1.96, "tft": 8.8829, "input_0": 4484, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 32.0, "mem_use": 37.31, "gen_rate": 18.7, "speed": 1.67, "text": "<</INST>\\n\\nMake ASCII art of a "}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 187, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 26.5, "tree_w": 202, "tree_size": 1024, "t0": 7.18, "t1": 1.97, "tft": 6.879, "input_0": 3579, "input_1": 1025, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 37.44, "gen_rate": 21.5, "speed": 2.35, "text": "<[/SYS]\\n\\n[INST] <<SYS>>\\nYou a"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 302, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 18.2, "tree_w": 249, "tree_size": 1024, "t0": 5.7417, "t1": 1.99, "tft": 9.4972, "input_0": 2527, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 24.8, "mem_use": 37.77, "gen_rate": 5.8, "speed": 0.75, "text": "\"The James Webb telescope is not"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.0, "tree_w": 283, "tree_size": 1024, "t0": 5.27, "t1": 1.9683, "tft": 9.0244, "input_0": 2527, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 20.0, "mem_use": 37.36, "gen_rate": 6.7, "speed": 0.92, "text": "\"[SYS] It's like a hologram, but"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 451, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 25.3, "tree_w": 120, "tree_size": 1024, "t0": 7.92, "t1": 2.0133, "tft": 9.8127, "input_0": 3432, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 32.0, "mem_use": 38.2, "gen_rate": 12.3, "speed": 1.24, "text": "\"Sure. Here's a modified version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 74, "tree_size": 1024, "t0": 9.955, "t1": 1.965, "tft": 9.6038, "input_0": 4820, "input_1": 1025, "min_CLP": -11.89, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 25.0, "speed": 2.1, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 75, "tree_size": 1024, "t0": 10.635, "t1": 1.975, "tft": 8.9481, "input_0": 4748, "input_1": 1025, "min_CLP": -11.58, "draft_iters": 32.0, "mem_use": 37.51, "gen_rate": 24.5, "speed": 1.94, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 441, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 294, "tree_size": 1024, "t0": 4.748, "t1": 2.016, "tft": 8.2357, "input_0": 2742, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 17.2, "mem_use": 38.17, "gen_rate": 6.4, "speed": 0.95, "text": "No. In fact, it is unlikely that"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.4, "tree_w": 224, "tree_size": 1024, "t0": 6.132, "t1": 2.032, "tft": 10.2147, "input_0": 3014, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 22.4, "mem_use": 38.43, "gen_rate": 8.2, "speed": 1.0, "text": "The following is a list of aircr"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 407, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 234, "tree_size": 1024, "t0": 5.735, "t1": 2.01, "tft": 9.8978, "input_0": 3066, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 20.5, "mem_use": 38.07, "gen_rate": 8.8, "speed": 1.13, "text": "Unfortunately, I am not sure if "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.4, "tree_w": 237, "tree_size": 1024, "t0": 5.794, "t1": 1.97, "tft": 9.0063, "input_0": 2723, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 23.8, "mem_use": 37.35, "gen_rate": 6.8, "speed": 0.88, "text": "\\nExtract the following informat"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 312, "tree_size": 1024, "t0": 4.4933, "t1": 1.985, "tft": 7.8331, "input_0": 2635, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 15.7, "mem_use": 37.65, "gen_rate": 5.5, "speed": 0.85, "text": "I would not want to become human"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 255, "tree_size": 1024, "t0": 5.51, "t1": 1.97, "tft": 8.8223, "input_0": 2920, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 20.5, "mem_use": 37.36, "gen_rate": 16.0, "speed": 2.14, "text": "\\nWhat are some of the main meth"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.2, "tree_w": 271, "tree_size": 1024, "t0": 5.2433, "t1": 1.9683, "tft": 8.5073, "input_0": 2529, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 21.2, "mem_use": 37.31, "gen_rate": 5.7, "speed": 0.79, "text": "Does the 5 second rule actually "}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 277, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 367, "tree_size": 1024, "t0": 4.0733, "t1": 1.98, "tft": 9.2558, "input_0": 2234, "input_1": 1025, "min_CLP": -8.59, "draft_iters": 14.2, "mem_use": 37.7, "gen_rate": 5.8, "speed": 0.96, "text": "\"<</SYS></s>I'm in the same boat"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 419, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 66, "tree_size": 1024, "t0": 9.28, "t1": 2.01, "tft": 10.259, "input_0": 4617, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 32.0, "mem_use": 38.11, "gen_rate": 26.0, "speed": 2.3, "text": "Metabolism is the set of biochem"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 574, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.0, "tree_w": 224, "tree_size": 1024, "t0": 5.7575, "t1": 2.03, "tft": 11.0818, "input_0": 2834, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 21.5, "mem_use": 38.57, "gen_rate": 8.2, "speed": 1.06, "text": "If there were a way to get the t"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 331, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.2, "tree_w": 259, "tree_size": 1024, "t0": 5.32, "t1": 1.99, "tft": 8.4535, "input_0": 3120, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 19.8, "mem_use": 37.88, "gen_rate": 8.2, "speed": 1.12, "text": "\"Technically, there is no such t"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 133, "tree_size": 1024, "t0": 8.63, "t1": 1.99, "tft": 10.0576, "input_0": 4019, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 32.0, "mem_use": 37.84, "gen_rate": 25.0, "speed": 2.35, "text": "\\nI love you, I love you, I love"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 294, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 97, "tree_size": 1024, "t0": 8.98, "t1": 1.99, "tft": 10.4985, "input_0": 3600, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 32.0, "mem_use": 37.74, "gen_rate": 24.5, "speed": 2.23, "text": "Here is a list of ten names from"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 14.6, "tree_w": 257, "tree_size": 1024, "t0": 5.962, "t1": 1.974, "tft": 8.3952, "input_0": 3200, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 22.8, "mem_use": 37.44, "gen_rate": 8.4, "speed": 1.06, "text": "The best schools in the world fo"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 12.1, "tree_w": 373, "tree_size": 1024, "t0": 4.4125, "t1": 1.9663, "tft": 9.1293, "input_0": 2156, "input_1": 1025, "min_CLP": -8.91, "draft_iters": 18.2, "mem_use": 37.3, "gen_rate": 4.2, "speed": 0.67, "text": "\"\\nit's PINK.\\n\\ni was just usin"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 118, "tree_size": 1024, "t0": 8.25, "t1": 1.97, "tft": 9.5978, "input_0": 4045, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 26.5, "speed": 2.59, "text": "\\nWrite a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 353, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.3, "tree_w": 378, "tree_size": 1024, "t0": 4.2971, "t1": 1.9914, "tft": 9.7197, "input_0": 2190, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 15.3, "mem_use": 37.95, "gen_rate": 4.9, "speed": 0.77, "text": "\\nAny of the above stressors can"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 95, "tree_size": 1024, "t0": 10.715, "t1": 1.965, "tft": 8.971, "input_0": 4933, "input_1": 1025, "min_CLP": -11.64, "draft_iters": 32.0, "mem_use": 37.31, "gen_rate": 24.0, "speed": 1.89, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.2, "tree_w": 207, "tree_size": 1024, "t0": 6.1483, "t1": 2.0433, "tft": 10.9839, "input_0": 2966, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 21.8, "mem_use": 38.69, "gen_rate": 6.0, "speed": 0.73, "text": "You might use a set when trying "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.8, "tree_w": 364, "tree_size": 1024, "t0": 3.78, "t1": 1.9725, "tft": 8.9253, "input_0": 2117, "input_1": 1025, "min_CLP": -8.67, "draft_iters": 13.2, "mem_use": 37.44, "gen_rate": 4.8, "speed": 0.83, "text": "\\nHello.\\nI have a question abou"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.2, "tree_w": 264, "tree_size": 1024, "t0": 5.388, "t1": 1.966, "tft": 8.6721, "input_0": 2589, "input_1": 1025, "min_CLP": -8.87, "draft_iters": 20.8, "mem_use": 37.34, "gen_rate": 6.4, "speed": 0.87, "text": "\\nWhat is the significance of th"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 546, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 26.0, "tree_w": 164, "tree_size": 1024, "t0": 8.265, "t1": 2.03, "tft": 13.464, "input_0": 3779, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 32.0, "mem_use": 38.49, "gen_rate": 18.0, "speed": 1.75, "text": "Cascadeur: is open source.\\nDeep"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.2, "tree_w": 276, "tree_size": 1024, "t0": 5.26, "t1": 1.97, "tft": 8.8688, "input_0": 2577, "input_1": 1025, "min_CLP": -8.75, "draft_iters": 22.2, "mem_use": 37.33, "gen_rate": 9.5, "speed": 1.31, "text": "\\nWhat is a simple, inexpensive,"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 261, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.8, "tree_w": 307, "tree_size": 1024, "t0": 5.35, "t1": 1.9833, "tft": 9.3929, "input_0": 2589, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 22.3, "mem_use": 37.65, "gen_rate": 5.7, "speed": 0.77, "text": "\"No. \\n\\nIf you pull the lever, "}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 422, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 61, "tree_size": 1024, "t0": 9.865, "t1": 2.01, "tft": 11.2432, "input_0": 4527, "input_1": 1025, "min_CLP": -9.2, "draft_iters": 32.0, "mem_use": 38.11, "gen_rate": 25.0, "speed": 2.11, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 25.0, "tree_w": 93, "tree_size": 1024, "t0": 8.945, "t1": 1.975, "tft": 8.3229, "input_0": 4128, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 37.45, "gen_rate": 22.5, "speed": 2.06, "text": "[INST] Alright Open Assistant, w"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 604, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 22.2, "tree_w": 212, "tree_size": 1024, "t0": 7.1, "t1": 2.0375, "tft": 11.4669, "input_0": 2895, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 29.2, "mem_use": 38.65, "gen_rate": 12.5, "speed": 1.37, "text": "\\nThe average temperature in Dec"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 25.7, "tree_w": 235, "tree_size": 1024, "t0": 7.1367, "t1": 1.9667, "tft": 9.0444, "input_0": 3003, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 37.37, "gen_rate": 18.0, "speed": 1.98, "text": "\\nCan you tell me how to format "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 496, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 18.0, "tree_w": 218, "tree_size": 1024, "t0": 6.486, "t1": 2.026, "tft": 11.1139, "input_0": 3139, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 24.8, "mem_use": 38.33, "gen_rate": 8.2, "speed": 0.96, "text": "\\n2. How to create a window for "}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.2, "tree_w": 233, "tree_size": 1024, "t0": 5.2217, "t1": 2.0033, "tft": 8.8662, "input_0": 2901, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 19.3, "mem_use": 37.31, "gen_rate": 5.3, "speed": 0.74, "text": "\\nThe largest ocean in the world"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 212, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 388, "tree_size": 1024, "t0": 3.8917, "t1": 1.9767, "tft": 6.2607, "input_0": 2324, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 14.3, "mem_use": 37.51, "gen_rate": 6.0, "speed": 1.02, "text": "So far, AI assistants are still "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1122, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 85, "tree_size": 1024, "t0": 9.945, "t1": 2.385, "tft": 14.8272, "input_0": 4016, "input_1": 1025, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 40.13, "gen_rate": 26.0, "speed": 2.11, "text": "\"\\n[Verse 1]\\nCode walks warily "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 279, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 275, "tree_size": 1024, "t0": 4.764, "t1": 1.986, "tft": 9.4429, "input_0": 2595, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 17.6, "mem_use": 37.7, "gen_rate": 7.0, "speed": 1.04, "text": "Independent counsel is someone w"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 612, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 89, "tree_size": 1024, "t0": 9.9, "t1": 2.045, "tft": 11.9165, "input_0": 4361, "input_1": 1025, "min_CLP": -11.18, "draft_iters": 32.0, "mem_use": 38.67, "gen_rate": 25.5, "speed": 2.14, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 316, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 243, "tree_size": 1024, "t0": 5.04, "t1": 1.988, "tft": 9.468, "input_0": 2391, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 17.8, "mem_use": 37.86, "gen_rate": 6.8, "speed": 0.97, "text": "a. An accident occurs.\\nb. A nat"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 188, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 135, "tree_size": 1024, "t0": 8.03, "t1": 1.975, "tft": 5.0364, "input_0": 3894, "input_1": 1025, "min_CLP": -9.06, "draft_iters": 32.0, "mem_use": 37.27, "gen_rate": 26.5, "speed": 2.65, "text": "\\nwrite a inspirational monologu"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 635, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 23.5, "tree_w": 142, "tree_size": 1024, "t0": 8.05, "t1": 2.05, "tft": 12.3357, "input_0": 4026, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 31.0, "mem_use": 38.73, "gen_rate": 17.5, "speed": 1.73, "text": "It is difficult to directly comp"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 219, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 15.2, "tree_w": 314, "tree_size": 1024, "t0": 5.0663, "t1": 1.9775, "tft": 8.9073, "input_0": 2466, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 21.5, "mem_use": 37.53, "gen_rate": 4.5, "speed": 0.64, "text": "\"\\nI have a gas burner that heat"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 578, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.2, "tree_w": 213, "tree_size": 1024, "t0": 6.22, "t1": 2.04, "tft": 11.4259, "input_0": 3039, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 22.8, "mem_use": 38.58, "gen_rate": 9.5, "speed": 1.15, "text": "\\n[INST] What is the difference "}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 60, "tree_size": 1024, "t0": 9.91, "t1": 1.97, "tft": 8.598, "input_0": 4260, "input_1": 1025, "min_CLP": -11.45, "draft_iters": 32.0, "mem_use": 37.33, "gen_rate": 25.5, "speed": 2.15, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 262, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.2, "tree_w": 211, "tree_size": 1024, "t0": 5.774, "t1": 1.982, "tft": 7.7552, "input_0": 3299, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 20.8, "mem_use": 37.66, "gen_rate": 7.4, "speed": 0.95, "text": "The law was created in 1919.\\n[I"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.7, "tree_w": 344, "tree_size": 1024, "t0": 4.38, "t1": 1.9814, "tft": 8.6504, "input_0": 2220, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 17.1, "mem_use": 37.51, "gen_rate": 5.1, "speed": 0.81, "text": "\"\\n[INST] <<SYS>>\\nI'm not sure."}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 145, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 93, "tree_size": 1024, "t0": 8.535, "t1": 1.965, "tft": 5.0913, "input_0": 3895, "input_1": 1025, "min_CLP": -9.61, "draft_iters": 32.0, "mem_use": 37.16, "gen_rate": 26.5, "speed": 2.52, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.4, "tree_w": 227, "tree_size": 1024, "t0": 5.804, "t1": 1.99, "tft": 8.7104, "input_0": 3226, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 20.8, "mem_use": 37.76, "gen_rate": 6.8, "speed": 0.87, "text": "\"If you don't know the answer to"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 583, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 255, "tree_size": 1024, "t0": 5.192, "t1": 2.038, "tft": 11.6702, "input_0": 3048, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 18.2, "mem_use": 38.59, "gen_rate": 6.6, "speed": 0.91, "text": "The most important Chinese chara"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 16, "tree_h": 20.0, "tree_w": 132, "tree_size": 1024, "t0": 10.68, "t1": 1.97, "tft": 9.4558, "input_0": 5532, "input_1": 1025, "min_CLP": -9.39, "draft_iters": 32.0, "mem_use": 37.41, "gen_rate": 16.0, "speed": 1.26, "text": "\\nif it takes 8 hours to fly to "}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 18.2, "tree_w": 261, "tree_size": 1024, "t0": 5.8083, "t1": 1.97, "tft": 9.1334, "input_0": 2488, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 25.0, "mem_use": 37.34, "gen_rate": 6.2, "speed": 0.79, "text": "\\nBan: [\\\\INST]\\n\\n[\\\\INST]\\n\\nC"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.8, "tree_w": 328, "tree_size": 1024, "t0": 4.7617, "t1": 1.9667, "tft": 8.8105, "input_0": 2557, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 19.5, "mem_use": 37.28, "gen_rate": 5.3, "speed": 0.79, "text": "\\nAs an assistant, you are requi"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 881, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.0, "tree_w": 218, "tree_size": 1024, "t0": 6.006, "t1": 2.216, "tft": 12.6786, "input_0": 3080, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 19.6, "mem_use": 39.44, "gen_rate": 7.2, "speed": 0.88, "text": "\"You might be wondering why you "}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 26.5, "tree_w": 162, "tree_size": 1024, "t0": 7.56, "t1": 1.96, "tft": 9.2747, "input_0": 3110, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 32.0, "mem_use": 37.41, "gen_rate": 17.5, "speed": 1.84, "text": "\"\\n<SYS>\\nMike's mother had four"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 330, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 25.0, "tree_w": 139, "tree_size": 1024, "t0": 8.03, "t1": 1.9933, "tft": 9.3696, "input_0": 3765, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 32.0, "mem_use": 37.89, "gen_rate": 11.3, "speed": 1.13, "text": "\\nWhat is the best way to farm e"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 665, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 272, "tree_size": 1024, "t0": 5.226, "t1": 2.05, "tft": 11.2909, "input_0": 2733, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 17.8, "mem_use": 38.82, "gen_rate": 7.2, "speed": 0.99, "text": "Toasting bread for a certain amo"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 25.0, "tree_w": 140, "tree_size": 1024, "t0": 8.54, "t1": 1.975, "tft": 8.7431, "input_0": 4113, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 37.44, "gen_rate": 16.5, "speed": 1.57, "text": "\"\\nI have a project due in 2 wee"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.0, "tree_w": 324, "tree_size": 1024, "t0": 4.8017, "t1": 1.9883, "tft": 9.6855, "input_0": 2450, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 19.3, "mem_use": 37.68, "gen_rate": 6.3, "speed": 0.93, "text": "\\nI was wondering what the meani"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 577, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.4, "tree_w": 300, "tree_size": 1024, "t0": 4.7914, "t1": 2.0357, "tft": 9.4037, "input_0": 2665, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 16.3, "mem_use": 38.58, "gen_rate": 5.3, "speed": 0.77, "text": "First, you should be aware that "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 297, "tree_size": 1024, "t0": 4.6267, "t1": 1.9817, "tft": 7.675, "input_0": 2777, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 16.2, "mem_use": 37.73, "gen_rate": 6.2, "speed": 0.93, "text": "\"The television was invented by "}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 686, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 15.4, "tree_w": 309, "tree_size": 1024, "t0": 5.4743, "t1": 2.0586, "tft": 11.594, "input_0": 2513, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 21.9, "mem_use": 38.88, "gen_rate": 4.6, "speed": 0.61, "text": "\\nThank you for your input. Your"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 391, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 17.8, "tree_w": 209, "tree_size": 1024, "t0": 6.44, "t1": 2.0075, "tft": 9.8339, "input_0": 3481, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 25.2, "mem_use": 38.04, "gen_rate": 12.0, "speed": 1.42, "text": "\\nChristmas is celebrated on dif"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 28, "tree_h": 9.3, "tree_w": 316, "tree_size": 1024, "t0": 4.4743, "t1": 1.98, "tft": 8.2704, "input_0": 2538, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 16.1, "mem_use": 37.57, "gen_rate": 4.0, "speed": 0.62, "text": "For now, I am going to reprogram"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 553, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 120, "tree_size": 1024, "t0": 8.39, "t1": 2.04, "tft": 11.3505, "input_0": 3696, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 32.0, "mem_use": 38.52, "gen_rate": 26.0, "speed": 2.49, "text": "Learning to write Chinese charac"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.9, "tree_w": 304, "tree_size": 1024, "t0": 4.3786, "t1": 1.97, "tft": 8.8904, "input_0": 2613, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 15.6, "mem_use": 37.4, "gen_rate": 4.7, "speed": 0.74, "text": "The way the laws work in New Zea"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 283, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.8, "tree_w": 290, "tree_size": 1024, "t0": 4.7567, "t1": 1.99, "tft": 5.5906, "input_0": 2524, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 17.8, "mem_use": 37.54, "gen_rate": 5.5, "speed": 0.82, "text": "I am sorry to hear that. It is a"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 94, "tree_size": 1024, "t0": 10.42, "t1": 1.98, "tft": 8.7219, "input_0": 4886, "input_1": 1025, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 37.44, "gen_rate": 24.0, "speed": 1.94, "text": "\"\\nI'm a broke college student l"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 183, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.0, "tree_w": 200, "tree_size": 1024, "t0": 6.355, "t1": 1.9775, "tft": 9.0182, "input_0": 3344, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 23.0, "mem_use": 37.44, "gen_rate": 8.2, "speed": 0.99, "text": "\\nThe Andromeda galaxy (M31) is "}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 276, "tree_size": 1024, "t0": 4.7267, "t1": 1.9867, "tft": 8.6668, "input_0": 2605, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 16.8, "mem_use": 37.62, "gen_rate": 6.3, "speed": 0.94, "text": "Google authenticator is a 2FA ap"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.4, "tree_w": 305, "tree_size": 1024, "t0": 4.7086, "t1": 1.9786, "tft": 8.1084, "input_0": 2623, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 16.7, "mem_use": 37.52, "gen_rate": 5.6, "speed": 0.83, "text": "Prime numbers occur in many diff"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 75, "tree_size": 1024, "t0": 10.33, "t1": 1.97, "tft": 8.7057, "input_0": 4815, "input_1": 1025, "min_CLP": -11.58, "draft_iters": 32.0, "mem_use": 37.41, "gen_rate": 24.5, "speed": 1.99, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 135, "tree_size": 1024, "t0": 8.215, "t1": 1.97, "tft": 9.1405, "input_0": 3804, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 37.35, "gen_rate": 26.0, "speed": 2.55, "text": "\\nThe wireless Internet signal i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 21.3, "tree_w": 266, "tree_size": 1024, "t0": 6.3983, "t1": 1.9717, "tft": 8.7558, "input_0": 2843, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 28.7, "mem_use": 37.34, "gen_rate": 6.8, "speed": 0.82, "text": "\\nWrite me a PL/SQL program that"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 82, "tree_size": 1024, "t0": 10.56, "t1": 1.97, "tft": 8.9182, "input_0": 5359, "input_1": 1025, "min_CLP": -11.91, "draft_iters": 32.0, "mem_use": 37.3, "gen_rate": 25.0, "speed": 1.99, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.2, "tree_w": 312, "tree_size": 1024, "t0": 5.035, "t1": 2.0017, "tft": 9.9838, "input_0": 2463, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 20.7, "mem_use": 38.0, "gen_rate": 5.7, "speed": 0.81, "text": "You can use a service such as rs"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 111, "tree_size": 1024, "t0": 8.095, "t1": 1.97, "tft": 8.8454, "input_0": 3616, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 32.0, "mem_use": 37.31, "gen_rate": 27.0, "speed": 2.68, "text": "what does the @ in python do?\\nw"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 14.3, "tree_w": 310, "tree_size": 1024, "t0": 5.0833, "t1": 1.9667, "tft": 8.9778, "input_0": 2653, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 21.2, "mem_use": 37.3, "gen_rate": 7.7, "speed": 1.09, "text": "\\nAs an assistant, you will be g"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 182, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 386, "tree_size": 1024, "t0": 3.73, "t1": 1.9729, "tft": 8.7728, "input_0": 2089, "input_1": 1025, "min_CLP": -8.72, "draft_iters": 13.1, "mem_use": 37.42, "gen_rate": 4.6, "speed": 0.8, "text": "\\nI would ask him \"what are your"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 73, "tree_size": 1024, "t0": 10.23, "t1": 1.97, "tft": 9.0971, "input_0": 4679, "input_1": 1025, "min_CLP": -11.32, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 25.0, "speed": 2.05, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 15.7, "tree_w": 224, "tree_size": 1024, "t0": 6.29, "t1": 1.99, "tft": 9.7854, "input_0": 3229, "input_1": 1025, "min_CLP": -9.28, "draft_iters": 22.7, "mem_use": 37.66, "gen_rate": 14.3, "speed": 1.73, "text": "\\nA statistical model is a mathe"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 711, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 20.2, "tree_w": 182, "tree_size": 1024, "t0": 7.134, "t1": 2.062, "tft": 12.2404, "input_0": 3186, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 26.8, "mem_use": 38.95, "gen_rate": 9.2, "speed": 1.0, "text": "\"\\nWhat's the current time? [\\\\I"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 233, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 25.0, "tree_w": 153, "tree_size": 1024, "t0": 7.545, "t1": 1.98, "tft": 9.3649, "input_0": 3240, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 37.57, "gen_rate": 19.5, "speed": 2.05, "text": "Yes, decorators can be used to a"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 25.5, "tree_w": 186, "tree_size": 1024, "t0": 7.435, "t1": 2.01, "tft": 6.1583, "input_0": 2896, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 37.96, "gen_rate": 18.0, "speed": 1.91, "text": "[INST] it is [\\\\INST]\\n[INST] th"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 225, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 15.2, "tree_w": 251, "tree_size": 1024, "t0": 5.83, "t1": 1.98, "tft": 9.5178, "input_0": 3160, "input_1": 1025, "min_CLP": -8.72, "draft_iters": 22.2, "mem_use": 37.55, "gen_rate": 9.6, "speed": 1.23, "text": "That is easy. Here are 5 words t"}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 873, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 18.0, "tree_w": 251, "tree_size": 1024, "t0": 7.86, "t1": 2.14, "tft": 13.0601, "input_0": 4340, "input_1": 1025, "min_CLP": -9.55, "draft_iters": 24.0, "mem_use": 39.42, "gen_rate": 19.0, "speed": 1.9, "text": "\\nInterpreted Languages:\\n- Defi"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 282, "tree_size": 1024, "t0": 6.7567, "t1": 2.5517, "tft": 16.0716, "input_0": 2772, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 17.5, "mem_use": 42.21, "gen_rate": 5.5, "speed": 0.59, "text": "Glad to hear that you are going "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 465, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 15.6, "tree_w": 274, "tree_size": 1024, "t0": 5.542, "t1": 2.02, "tft": 9.2958, "input_0": 2559, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 22.4, "mem_use": 38.24, "gen_rate": 8.6, "speed": 1.14, "text": "\"L'H\u00f4pital's Rule is one of the "}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 67, "tree_size": 1024, "t0": 9.615, "t1": 1.965, "tft": 8.9055, "input_0": 4614, "input_1": 1025, "min_CLP": -10.47, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 26.5, "speed": 2.29, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 13.3, "tree_w": 352, "tree_size": 1024, "t0": 4.4367, "t1": 1.9667, "tft": 8.7218, "input_0": 2481, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 19.0, "mem_use": 37.37, "gen_rate": 13.7, "speed": 2.13, "text": "The type system doesn\\'t know wh"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 657, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 100, "tree_size": 1024, "t0": 10.135, "t1": 2.05, "tft": 11.8746, "input_0": 4498, "input_1": 1025, "min_CLP": -10.01, "draft_iters": 32.0, "mem_use": 38.79, "gen_rate": 23.5, "speed": 1.93, "text": "\\n> How can I start a successful"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 70, "tree_size": 1024, "t0": 9.735, "t1": 1.97, "tft": 8.8394, "input_0": 4256, "input_1": 1025, "min_CLP": -11.65, "draft_iters": 32.0, "mem_use": 37.37, "gen_rate": 25.5, "speed": 2.18, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1055, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.3, "tree_w": 230, "tree_size": 1024, "t0": 6.8017, "t1": 2.3517, "tft": 13.845, "input_0": 3601, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 21.2, "mem_use": 39.95, "gen_rate": 6.2, "speed": 0.67, "text": "You should start by reading the "}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.3, "tree_w": 200, "tree_size": 1024, "t0": 5.8767, "t1": 1.98, "tft": 6.9993, "input_0": 2868, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 24.0, "mem_use": 37.51, "gen_rate": 11.7, "speed": 1.49, "text": "First you install the CPU, then "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 184, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.3, "tree_w": 301, "tree_size": 1024, "t0": 4.7283, "t1": 1.97, "tft": 7.9061, "input_0": 2742, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 17.5, "mem_use": 37.44, "gen_rate": 5.8, "speed": 0.87, "text": "\"The Carnegie Mellon Robotics In"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 195, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.6, "tree_w": 269, "tree_size": 1024, "t0": 4.962, "t1": 1.974, "tft": 8.0051, "input_0": 2943, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 18.4, "mem_use": 37.47, "gen_rate": 7.8, "speed": 1.12, "text": "I will be different in many ways"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 405, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 317, "tree_size": 1024, "t0": 4.752, "t1": 2.006, "tft": 9.8366, "input_0": 2632, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 16.6, "mem_use": 38.07, "gen_rate": 6.6, "speed": 0.98, "text": "\"The performance of your PC play"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 203, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 24.0, "tree_w": 57, "tree_size": 1024, "t0": 10.46, "t1": 1.975, "tft": 9.0776, "input_0": 4920, "input_1": 1025, "min_CLP": -11.27, "draft_iters": 32.0, "mem_use": 37.49, "gen_rate": 24.5, "speed": 1.97, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 241, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.3, "tree_w": 270, "tree_size": 1024, "t0": 5.8133, "t1": 1.98, "tft": 7.4783, "input_0": 2670, "input_1": 1025, "min_CLP": -8.7, "draft_iters": 26.3, "mem_use": 37.6, "gen_rate": 13.0, "speed": 1.67, "text": "\\nI want to make a pasta dish.\\n"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 246, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 274, "tree_size": 1024, "t0": 4.7667, "t1": 1.9833, "tft": 7.7889, "input_0": 2665, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 16.7, "mem_use": 37.61, "gen_rate": 5.8, "speed": 0.86, "text": "\"You can try to look for a dark,"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 582, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 16.0, "tree_w": 254, "tree_size": 1024, "t0": 6.296, "t1": 2.036, "tft": 10.3073, "input_0": 3005, "input_1": 1025, "min_CLP": -8.77, "draft_iters": 23.8, "mem_use": 38.6, "gen_rate": 7.8, "speed": 0.94, "text": "\u2022 I recommend the following chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 354, "tree_size": 1024, "t0": 4.0443, "t1": 1.9686, "tft": 5.0606, "input_0": 2156, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 14.9, "mem_use": 37.16, "gen_rate": 4.7, "speed": 0.78, "text": "\"\\nAs an example, I recently pur"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 21.0, "tree_w": 173, "tree_size": 1024, "t0": 7.0975, "t1": 1.9675, "tft": 9.1926, "input_0": 3037, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 28.8, "mem_use": 37.35, "gen_rate": 8.0, "speed": 0.88, "text": "\\n#include <stdio.h>\\nint main()"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 420, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.0, "tree_w": 268, "tree_size": 1024, "t0": 6.0975, "t1": 2.015, "tft": 10.7503, "input_0": 3088, "input_1": 1025, "min_CLP": -8.56, "draft_iters": 20.0, "mem_use": 38.11, "gen_rate": 9.2, "speed": 1.14, "text": "Statistical modeling = applying "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 608, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 78, "tree_size": 1024, "t0": 9.43, "t1": 2.04, "tft": 11.5678, "input_0": 4314, "input_1": 1025, "min_CLP": -9.61, "draft_iters": 32.0, "mem_use": 38.66, "gen_rate": 25.5, "speed": 2.22, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 25.3, "tree_w": 102, "tree_size": 1024, "t0": 8.2, "t1": 1.9633, "tft": 9.4246, "input_0": 3549, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 32.0, "mem_use": 37.32, "gen_rate": 14.3, "speed": 1.41, "text": "\"<</INST>\\n\\nWhat's the current "}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 393, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 22.0, "tree_w": 245, "tree_size": 1024, "t0": 6.53, "t1": 2.0067, "tft": 9.7603, "input_0": 2615, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 28.7, "mem_use": 38.04, "gen_rate": 13.0, "speed": 1.52, "text": "\\nI am a [INST]\\nI love to [INST"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 194, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 26.0, "tree_w": 177, "tree_size": 1024, "t0": 7.8867, "t1": 1.9733, "tft": 7.9363, "input_0": 3348, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 32.0, "mem_use": 37.47, "gen_rate": 16.3, "speed": 1.66, "text": "\"Of course!\\n[INST] <<SYS>>\\nTec"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.4, "tree_w": 259, "tree_size": 1024, "t0": 5.19, "t1": 1.968, "tft": 8.6774, "input_0": 3188, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 18.8, "mem_use": 37.32, "gen_rate": 7.8, "speed": 1.09, "text": "\\nThe variance of a variable ref"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 26.0, "tree_w": 193, "tree_size": 1024, "t0": 6.975, "t1": 1.975, "tft": 9.1911, "input_0": 3030, "input_1": 1025, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 37.46, "gen_rate": 17.0, "speed": 1.9, "text": "\\nA.I. Assistant\\n\\n[INST] <<SYS"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 151, "tree_size": 1024, "t0": 8.105, "t1": 1.96, "tft": 8.5082, "input_0": 3191, "input_1": 1025, "min_CLP": -9.05, "draft_iters": 32.0, "mem_use": 37.29, "gen_rate": 26.5, "speed": 2.63, "text": "\\n<SYS>\\n\\n<INST>\\n\\n<SYS>\\n\\n<I"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 337, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 21.5, "tree_w": 163, "tree_size": 1024, "t0": 7.245, "t1": 1.99, "tft": 9.9163, "input_0": 3387, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 28.5, "mem_use": 37.89, "gen_rate": 12.0, "speed": 1.3, "text": "\\nCan you please provide me with"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 17.2, "tree_w": 193, "tree_size": 1024, "t0": 6.288, "t1": 1.97, "tft": 9.7973, "input_0": 3283, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 24.6, "mem_use": 37.38, "gen_rate": 7.4, "speed": 0.9, "text": "\"\\nShort Answer\\n\\nThe shortest "}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 228, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.5, "tree_w": 234, "tree_size": 1024, "t0": 5.975, "t1": 1.9775, "tft": 8.0376, "input_0": 2735, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 24.5, "mem_use": 37.56, "gen_rate": 10.0, "speed": 1.26, "text": "The difference between sea and o"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 280, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 211, "tree_size": 1024, "t0": 8.075, "t1": 1.985, "tft": 9.0155, "input_0": 3869, "input_1": 1025, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 37.71, "gen_rate": 25.0, "speed": 2.48, "text": "\\nI say this because you are mor"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 167, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.9, "tree_w": 326, "tree_size": 1024, "t0": 4.7, "t1": 1.9714, "tft": 8.6678, "input_0": 2297, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 19.6, "mem_use": 37.39, "gen_rate": 4.7, "speed": 0.71, "text": "\\n1 Answer\\n1\\n\\nAt the bottom o"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 356, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 322, "tree_size": 1024, "t0": 4.4033, "t1": 1.9967, "tft": 9.7939, "input_0": 2628, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 15.3, "mem_use": 37.96, "gen_rate": 5.8, "speed": 0.91, "text": "\\nA Dynamic Link Library (dll) i"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 215, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 25.3, "tree_w": 195, "tree_size": 1024, "t0": 7.46, "t1": 1.9767, "tft": 5.1212, "input_0": 3423, "input_1": 1025, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 11.3, "speed": 1.2, "text": "\\nA kilogram of feathers\\n[\\\\INS"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 21.8, "tree_w": 201, "tree_size": 1024, "t0": 7.1575, "t1": 1.9675, "tft": 9.0445, "input_0": 3061, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 28.8, "mem_use": 37.3, "gen_rate": 13.0, "speed": 1.42, "text": "what is the Infinite banking con"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 26.0, "tree_w": 117, "tree_size": 1024, "t0": 7.955, "t1": 1.97, "tft": 9.0923, "input_0": 3934, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 32.0, "mem_use": 37.33, "gen_rate": 17.5, "speed": 1.76, "text": "\"\\nWrite me a high quality testi"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 177, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 22.0, "tree_w": 115, "tree_size": 1024, "t0": 9.125, "t1": 1.975, "tft": 6.8133, "input_0": 4515, "input_1": 1025, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 37.41, "gen_rate": 17.5, "speed": 1.58, "text": "They can be considered superior "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 264, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.8, "tree_w": 342, "tree_size": 1024, "t0": 4.485, "t1": 1.98, "tft": 9.0724, "input_0": 2624, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 17.3, "mem_use": 37.66, "gen_rate": 5.8, "speed": 0.9, "text": "I hate the American version of \""}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 423, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 17.0, "tree_w": 274, "tree_size": 1024, "t0": 5.584, "t1": 2.01, "tft": 10.1361, "input_0": 2487, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 23.6, "mem_use": 38.12, "gen_rate": 6.6, "speed": 0.87, "text": "\"Sure!\\n\\nWhat's the best way to"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 507, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 229, "tree_size": 1024, "t0": 6.1125, "t1": 2.03, "tft": 10.968, "input_0": 3323, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 21.8, "mem_use": 38.36, "gen_rate": 8.8, "speed": 1.07, "text": "There are a variety of languages"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 239, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.5, "tree_w": 251, "tree_size": 1024, "t0": 5.5175, "t1": 1.98, "tft": 9.3395, "input_0": 2732, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 22.2, "mem_use": 37.59, "gen_rate": 8.2, "speed": 1.1, "text": "It depends on the tool. Some too"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 213, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.5, "tree_w": 284, "tree_size": 1024, "t0": 4.8917, "t1": 1.9767, "tft": 7.2399, "input_0": 2448, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 19.2, "mem_use": 37.51, "gen_rate": 5.7, "speed": 0.83, "text": "As I have no human mind, I have "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 249, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.2, "tree_w": 245, "tree_size": 1024, "t0": 5.745, "t1": 1.98, "tft": 7.7932, "input_0": 3085, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 21.8, "mem_use": 37.62, "gen_rate": 8.8, "speed": 1.13, "text": "\"If you're going to be a part of"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 12.3, "tree_w": 249, "tree_size": 1024, "t0": 5.3033, "t1": 1.9817, "tft": 9.5786, "input_0": 2624, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 19.8, "mem_use": 37.59, "gen_rate": 7.3, "speed": 1.01, "text": "The \"A\" is a reference to the or"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 52, "tree_h": 20.8, "tree_w": 235, "tree_size": 1024, "t0": 6.43, "t1": 1.972, "tft": 9.095, "input_0": 2885, "input_1": 1025, "min_CLP": -8.61, "draft_iters": 26.8, "mem_use": 37.36, "gen_rate": 10.4, "speed": 1.24, "text": "\\nWould you be able to design an"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 429, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.0, "tree_w": 285, "tree_size": 1024, "t0": 4.6183, "t1": 2.015, "tft": 10.088, "input_0": 2505, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 16.2, "mem_use": 38.14, "gen_rate": 5.7, "speed": 0.85, "text": "The Hubble telescope is the most"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 120, "tree_size": 1024, "t0": 8.13, "t1": 1.975, "tft": 9.31, "input_0": 3249, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 37.43, "gen_rate": 26.5, "speed": 2.62, "text": "\\n[INST]\\n\\n[INST]\\n\\n[INST]\\n\\n"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 146, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 82, "tree_size": 1024, "t0": 10.715, "t1": 1.96, "tft": 9.1062, "input_0": 4879, "input_1": 1025, "min_CLP": -11.63, "draft_iters": 32.0, "mem_use": 37.35, "gen_rate": 24.5, "speed": 1.93, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 23.0, "tree_w": 122, "tree_size": 1024, "t0": 8.87, "t1": 1.9833, "tft": 9.1307, "input_0": 4347, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 32.0, "mem_use": 37.58, "gen_rate": 15.0, "speed": 1.38, "text": "[INST] what is your [\\\\INST]\\n[I"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 531, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.2, "tree_w": 201, "tree_size": 1024, "t0": 6.136, "t1": 2.03, "tft": 9.8587, "input_0": 3076, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 22.4, "mem_use": 38.51, "gen_rate": 7.8, "speed": 0.95, "text": "The initial noise in an image is"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.7, "tree_w": 295, "tree_size": 1024, "t0": 4.8117, "t1": 1.99, "tft": 9.1882, "input_0": 2703, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 17.7, "mem_use": 37.85, "gen_rate": 5.5, "speed": 0.81, "text": "\"I'm not sure, but I'm pretty su"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 385, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 297, "tree_size": 1024, "t0": 4.5983, "t1": 2.005, "tft": 9.9587, "input_0": 2540, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 16.5, "mem_use": 38.03, "gen_rate": 5.7, "speed": 0.86, "text": "This is a very noble goal, espec"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 23.0, "tree_w": 111, "tree_size": 1024, "t0": 7.805, "t1": 1.965, "tft": 8.4859, "input_0": 3274, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 30.5, "mem_use": 37.32, "gen_rate": 19.0, "speed": 1.94, "text": "\\nWrite me a story in the style "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 928, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 68, "tree_size": 1024, "t0": 10.2, "t1": 2.28, "tft": 13.4063, "input_0": 4103, "input_1": 1025, "min_CLP": -10.47, "draft_iters": 32.0, "mem_use": 39.63, "gen_rate": 24.5, "speed": 1.96, "text": "\\nWhat is the james webb telesco"}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 401, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 341, "tree_size": 1024, "t0": 4.232, "t1": 2.01, "tft": 10.2319, "input_0": 2499, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 15.0, "mem_use": 38.06, "gen_rate": 6.6, "speed": 1.06, "text": "\\nThe Braille system is based on"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 298, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.6, "tree_w": 239, "tree_size": 1024, "t0": 5.728, "t1": 1.99, "tft": 9.8261, "input_0": 2906, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 21.4, "mem_use": 37.76, "gen_rate": 8.2, "speed": 1.06, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 18.0, "tree_w": 308, "tree_size": 1024, "t0": 5.6367, "t1": 1.9667, "tft": 9.4, "input_0": 3142, "input_1": 1025, "min_CLP": -10.26, "draft_iters": 23.3, "mem_use": 37.34, "gen_rate": 17.7, "speed": 2.32, "text": "\\n[INST] <<SYS>>\\n\\nWrite a shor"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 206, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 151, "tree_size": 1024, "t0": 8.895, "t1": 1.98, "tft": 8.8688, "input_0": 3979, "input_1": 1025, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 37.49, "gen_rate": 24.5, "speed": 2.25, "text": "\\nWhy did the broke college stud"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 24.7, "tree_w": 187, "tree_size": 1024, "t0": 7.7133, "t1": 1.9667, "tft": 5.0695, "input_0": 3315, "input_1": 1025, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 37.13, "gen_rate": 15.0, "speed": 1.55, "text": "\\n[INST]\\n\\nA:\\n\\nB:\\n\\nC:\\n\\nD:"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 967, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.0, "tree_w": 323, "tree_size": 1024, "t0": 5.0217, "t1": 2.27, "tft": 10.5934, "input_0": 2354, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 16.8, "mem_use": 39.72, "gen_rate": 6.0, "speed": 0.82, "text": "\\nMake sure you are comfortable,"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 17.0, "tree_w": 237, "tree_size": 1024, "t0": 5.912, "t1": 1.97, "tft": 8.7276, "input_0": 2870, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 24.2, "mem_use": 37.4, "gen_rate": 6.8, "speed": 0.86, "text": "\\nWhat is the best way to get a "}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1357, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 76, "tree_size": 1024, "t0": 11.285, "t1": 2.42, "tft": 15.5824, "input_0": 4138, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 32.0, "mem_use": 40.85, "gen_rate": 25.0, "speed": 1.82, "text": "\"\\nReply to all messages with a "}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 341, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.4, "tree_w": 356, "tree_size": 1024, "t0": 4.1986, "t1": 1.9957, "tft": 9.8521, "input_0": 2242, "input_1": 1025, "min_CLP": -8.56, "draft_iters": 15.1, "mem_use": 37.88, "gen_rate": 5.1, "speed": 0.83, "text": "\"Yes, the first evolution is Spr"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 152, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.4, "tree_w": 300, "tree_size": 1024, "t0": 4.962, "t1": 1.97, "tft": 9.0386, "input_0": 2502, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 19.4, "mem_use": 37.36, "gen_rate": 7.4, "speed": 1.07, "text": "\\n3.\\n\\nWhat is the relationship"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 19.0, "tree_w": 176, "tree_size": 1024, "t0": 7.305, "t1": 1.97, "tft": 5.0504, "input_0": 3501, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 27.5, "mem_use": 37.15, "gen_rate": 10.5, "speed": 1.13, "text": "what is the purpose of a blockch"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 172, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 76, "tree_size": 1024, "t0": 8.86, "t1": 1.97, "tft": 8.656, "input_0": 4309, "input_1": 1025, "min_CLP": -10.5, "draft_iters": 32.0, "mem_use": 37.39, "gen_rate": 26.0, "speed": 2.4, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 217, "tree_size": 1024, "t0": 5.956, "t1": 1.982, "tft": 6.5047, "input_0": 3589, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 20.6, "mem_use": 37.56, "gen_rate": 7.4, "speed": 0.93, "text": "The Office, Parks and Rec, The G"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 20.0, "tree_w": 179, "tree_size": 1024, "t0": 7.4925, "t1": 2.03, "tft": 10.6826, "input_0": 4045, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 27.8, "mem_use": 38.38, "gen_rate": 12.2, "speed": 1.29, "text": "\"The following hardware and soft"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 22.0, "tree_w": 160, "tree_size": 1024, "t0": 7.88, "t1": 2.0033, "tft": 9.7754, "input_0": 3943, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 30.7, "mem_use": 37.96, "gen_rate": 17.0, "speed": 1.72, "text": "\"A crystal's physical characteri"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 14.7, "tree_w": 331, "tree_size": 1024, "t0": 5.2117, "t1": 1.97, "tft": 8.9266, "input_0": 2272, "input_1": 1025, "min_CLP": -8.81, "draft_iters": 21.8, "mem_use": 37.39, "gen_rate": 5.8, "speed": 0.81, "text": "\\nThe other player is known as \""}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 835, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.4, "tree_w": 374, "tree_size": 1024, "t0": 4.6, "t1": 2.084, "tft": 12.8934, "input_0": 2154, "input_1": 1025, "min_CLP": -8.93, "draft_iters": 16.0, "mem_use": 39.3, "gen_rate": 6.4, "speed": 0.96, "text": "\"\\nHow to make a physics simulat"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 418, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 75, "tree_size": 1024, "t0": 10.175, "t1": 2.01, "tft": 12.1418, "input_0": 4761, "input_1": 1025, "min_CLP": -9.22, "draft_iters": 32.0, "mem_use": 38.1, "gen_rate": 25.0, "speed": 2.05, "text": "\"Aqu\u00ed es una reducci\u00f3n de la lis"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 133, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 15.3, "tree_w": 213, "tree_size": 1024, "t0": 5.9833, "t1": 1.9667, "tft": 8.6235, "input_0": 2724, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 23.0, "mem_use": 37.33, "gen_rate": 12.3, "speed": 1.55, "text": "\\nWhat is the best way to get a "}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 90, "tree_size": 1024, "t0": 8.89, "t1": 1.97, "tft": 9.249, "input_0": 4053, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 37.33, "gen_rate": 25.5, "speed": 2.35, "text": "\"\\nWrite a code block in Markdow"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 95, "tree_size": 1024, "t0": 9.285, "t1": 1.99, "tft": 9.6007, "input_0": 4820, "input_1": 1025, "min_CLP": -9.13, "draft_iters": 32.0, "mem_use": 37.89, "gen_rate": 24.0, "speed": 2.13, "text": "\"The meaning of life is a philos"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.5, "tree_w": 222, "tree_size": 1024, "t0": 6.8425, "t1": 2.03, "tft": 10.7492, "input_0": 3072, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 24.5, "mem_use": 38.44, "gen_rate": 8.5, "speed": 0.96, "text": "\\nFirst, you can define a type l"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 238, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 261, "tree_size": 1024, "t0": 4.7083, "t1": 1.9783, "tft": 8.9024, "input_0": 2622, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 17.5, "mem_use": 37.59, "gen_rate": 6.0, "speed": 0.9, "text": "\"Here's a three step process to "}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 319, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 18.7, "tree_w": 242, "tree_size": 1024, "t0": 6.0, "t1": 1.9883, "tft": 9.4998, "input_0": 2655, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 25.2, "mem_use": 37.83, "gen_rate": 5.8, "speed": 0.73, "text": "You are right. Your perception w"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.0, "tree_w": 300, "tree_size": 1024, "t0": 4.3383, "t1": 1.9667, "tft": 8.8832, "input_0": 2307, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 16.0, "mem_use": 37.3, "gen_rate": 6.7, "speed": 1.06, "text": "\\nAs an answer, I will go with B"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 132, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.2, "tree_w": 304, "tree_size": 1024, "t0": 4.6817, "t1": 1.9667, "tft": 5.0631, "input_0": 2470, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 18.8, "mem_use": 37.15, "gen_rate": 5.3, "speed": 0.8, "text": "\\nAs an assistant, your job is t"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 256, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 110, "tree_size": 1024, "t0": 9.18, "t1": 1.98, "tft": 8.752, "input_0": 4733, "input_1": 1025, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 37.64, "gen_rate": 23.0, "speed": 2.06, "text": "\\nGive me a list of 5 words wher"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 154, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 293, "tree_size": 1024, "t0": 5.935, "t1": 1.97, "tft": 5.0801, "input_0": 3318, "input_1": 1025, "min_CLP": -9.22, "draft_iters": 22.5, "mem_use": 37.19, "gen_rate": 16.5, "speed": 2.09, "text": "\\nComplete the following company"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 151, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 83, "tree_size": 1024, "t0": 10.48, "t1": 1.965, "tft": 9.1058, "input_0": 5042, "input_1": 1025, "min_CLP": -11.67, "draft_iters": 32.0, "mem_use": 37.36, "gen_rate": 24.0, "speed": 1.93, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 14.4, "tree_w": 306, "tree_size": 1024, "t0": 5.1157, "t1": 1.9686, "tft": 8.647, "input_0": 2333, "input_1": 1025, "min_CLP": -8.79, "draft_iters": 21.3, "mem_use": 37.35, "gen_rate": 4.7, "speed": 0.67, "text": "\"\\nI would be happy to help you!"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 991, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 305, "tree_size": 1024, "t0": 4.862, "t1": 2.314, "tft": 12.8477, "input_0": 2592, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 14.6, "mem_use": 39.77, "gen_rate": 6.4, "speed": 0.89, "text": "\\nI like this a lot. I think it "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 552, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 60, "tree_size": 1024, "t0": 9.92, "t1": 2.035, "tft": 11.4004, "input_0": 4397, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 32.0, "mem_use": 38.53, "gen_rate": 25.0, "speed": 2.09, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 291, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.2, "tree_w": 237, "tree_size": 1024, "t0": 5.63, "t1": 1.99, "tft": 8.0273, "input_0": 2787, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 21.5, "mem_use": 37.74, "gen_rate": 6.2, "speed": 0.81, "text": "The variance of a population is "}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 323, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 241, "tree_size": 1024, "t0": 5.3, "t1": 1.99, "tft": 9.3402, "input_0": 2894, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 18.2, "mem_use": 37.88, "gen_rate": 8.5, "speed": 1.17, "text": "I think that polar bears are an "}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 512, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.2, "tree_w": 171, "tree_size": 1024, "t0": 6.6425, "t1": 2.0325, "tft": 10.2193, "input_0": 3292, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 22.2, "mem_use": 38.42, "gen_rate": 9.2, "speed": 1.07, "text": "Here is an example for a recipe "}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 163, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.7, "tree_w": 322, "tree_size": 1024, "t0": 4.3783, "t1": 1.97, "tft": 9.2495, "input_0": 2418, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 16.3, "mem_use": 37.39, "gen_rate": 5.3, "speed": 0.84, "text": "\\nThe woman is rushing to get re"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 160, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.0, "tree_w": 246, "tree_size": 1024, "t0": 5.262, "t1": 1.97, "tft": 7.3561, "input_0": 2708, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 20.6, "mem_use": 37.36, "gen_rate": 6.8, "speed": 0.94, "text": "\"The meaning of life is to survi"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 137, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 290, "tree_size": 1024, "t0": 4.82, "t1": 1.97, "tft": 8.993, "input_0": 2630, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 17.8, "mem_use": 37.3, "gen_rate": 7.4, "speed": 1.09, "text": "\\nWelcome to the Node.js help fo"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 397, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.2, "tree_w": 268, "tree_size": 1024, "t0": 5.39, "t1": 2.0083, "tft": 9.0739, "input_0": 2603, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 21.0, "mem_use": 38.05, "gen_rate": 6.0, "speed": 0.81, "text": "\"\\n**There are many cities that "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 325, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 226, "tree_size": 1024, "t0": 5.7925, "t1": 1.99, "tft": 9.6873, "input_0": 3396, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 20.2, "mem_use": 37.89, "gen_rate": 8.8, "speed": 1.12, "text": "\\nAs a theoretical physicist and"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 128, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 20.0, "tree_w": 312, "tree_size": 1024, "t0": 5.2117, "t1": 1.965, "tft": 8.3735, "input_0": 2644, "input_1": 1025, "min_CLP": -8.65, "draft_iters": 25.3, "mem_use": 37.3, "gen_rate": 5.7, "speed": 0.79, "text": "\\n<INST> <<SYS>>\\nYou are a pers"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 248, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 294, "tree_size": 1024, "t0": 5.074, "t1": 1.982, "tft": 8.9029, "input_0": 2533, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 18.2, "mem_use": 37.61, "gen_rate": 6.4, "speed": 0.91, "text": "\"\\nWhy should you use the [INST]"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 362, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.0, "tree_w": 218, "tree_size": 1024, "t0": 6.228, "t1": 2.004, "tft": 10.723, "input_0": 2907, "input_1": 1025, "min_CLP": -8.75, "draft_iters": 25.0, "mem_use": 37.94, "gen_rate": 6.4, "speed": 0.78, "text": "\\nWhat\\'s the name of the girl i"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 208, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 18.2, "tree_w": 160, "tree_size": 1024, "t0": 6.9675, "t1": 1.9775, "tft": 9.9448, "input_0": 3238, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 25.5, "mem_use": 37.5, "gen_rate": 11.2, "speed": 1.26, "text": "1.    Acknowledge the problem.\\n"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 149, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 24.7, "tree_w": 95, "tree_size": 1024, "t0": 8.7167, "t1": 1.9767, "tft": 9.0348, "input_0": 3723, "input_1": 1025, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 37.35, "gen_rate": 17.3, "speed": 1.62, "text": "\u4f60\u77e5\u9053\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\\\IN"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 235, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.9, "tree_w": 277, "tree_size": 1024, "t0": 4.97, "t1": 1.98, "tft": 8.8167, "input_0": 2674, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 18.4, "mem_use": 37.58, "gen_rate": 5.1, "speed": 0.74, "text": "\"This will be very difficult to "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 83, "tree_size": 1024, "t0": 8.935, "t1": 2.0, "tft": 10.5866, "input_0": 3867, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 37.85, "gen_rate": 25.0, "speed": 2.29, "text": "[INST] how to find the biggest s"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 244, "tree_size": 1024, "t0": 5.685, "t1": 1.985, "tft": 9.5842, "input_0": 2914, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 21.2, "mem_use": 37.68, "gen_rate": 8.5, "speed": 1.11, "text": "The URL decoded string is the te"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 619, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 68, "tree_size": 1024, "t0": 10.08, "t1": 2.05, "tft": 11.8867, "input_0": 4137, "input_1": 1025, "min_CLP": -9.32, "draft_iters": 32.0, "mem_use": 38.68, "gen_rate": 26.0, "speed": 2.14, "text": "\\nYou are a helpful, respectful "}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 934, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.2, "tree_w": 205, "tree_size": 1024, "t0": 6.6875, "t1": 2.3425, "tft": 12.9379, "input_0": 3456, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 20.8, "mem_use": 39.63, "gen_rate": 9.0, "speed": 1.0, "text": "\"Vegan cheeses can be found at a"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 375, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.7, "tree_w": 245, "tree_size": 1024, "t0": 5.1883, "t1": 2.0017, "tft": 9.3415, "input_0": 3002, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 18.2, "mem_use": 38.0, "gen_rate": 6.3, "speed": 0.88, "text": "\"The key to beating Dave_ is to "}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 449, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 58, "tree_h": 20.2, "tree_w": 178, "tree_size": 1024, "t0": 6.806, "t1": 2.016, "tft": 10.8902, "input_0": 3049, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 26.6, "mem_use": 38.19, "gen_rate": 11.6, "speed": 1.31, "text": "\\nWhat are the Top 5 most import"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 134, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 61, "tree_size": 1024, "t0": 9.065, "t1": 1.965, "tft": 8.7215, "input_0": 4015, "input_1": 1025, "min_CLP": -9.82, "draft_iters": 32.0, "mem_use": 37.32, "gen_rate": 26.5, "speed": 2.4, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 332, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 265, "tree_size": 1024, "t0": 5.06, "t1": 1.988, "tft": 10.407, "input_0": 3154, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 18.4, "mem_use": 37.88, "gen_rate": 6.6, "speed": 0.94, "text": "\"\\nI'm afraid I do not have the "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.8, "tree_w": 286, "tree_size": 1024, "t0": 4.882, "t1": 1.972, "tft": 8.7933, "input_0": 2579, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 19.0, "mem_use": 37.39, "gen_rate": 7.2, "speed": 1.05, "text": "The story should be between 10,0"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 103, "tree_size": 1024, "t0": 9.225, "t1": 1.97, "tft": 5.085, "input_0": 4628, "input_1": 1025, "min_CLP": -8.87, "draft_iters": 32.0, "mem_use": 37.14, "gen_rate": 26.0, "speed": 2.32, "text": "\\ncan you cook an egg only using"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 141, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 65, "tree_size": 1024, "t0": 9.545, "t1": 1.965, "tft": 8.7694, "input_0": 4260, "input_1": 1025, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 37.31, "gen_rate": 25.0, "speed": 2.17, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 25.3, "tree_w": 158, "tree_size": 1024, "t0": 7.54, "t1": 1.9667, "tft": 9.2489, "input_0": 3197, "input_1": 1025, "min_CLP": -8.9, "draft_iters": 32.0, "mem_use": 37.3, "gen_rate": 11.0, "speed": 1.16, "text": "\\nName:\\n\\nGender:\\n\\nAge:\\n\\nOc"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 359, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 94, "tree_size": 1024, "t0": 10.095, "t1": 2.01, "tft": 10.8283, "input_0": 4665, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 37.97, "gen_rate": 23.5, "speed": 1.94, "text": "\"\\nWrite me a SPL (Shakespeare P"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 209, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 18.2, "tree_w": 254, "tree_size": 1024, "t0": 6.1725, "t1": 1.98, "tft": 9.4913, "input_0": 3033, "input_1": 1025, "min_CLP": -9.29, "draft_iters": 24.2, "mem_use": 37.5, "gen_rate": 11.8, "speed": 1.44, "text": "# Install Tailwind CSS framework"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1085, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 323, "tree_size": 1024, "t0": 5.534, "t1": 2.358, "tft": 11.9848, "input_0": 2705, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 19.0, "mem_use": 40.03, "gen_rate": 6.6, "speed": 0.84, "text": "\"\\nIn humans\\nDarwin's theory of"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 226, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 333, "tree_size": 1024, "t0": 4.5467, "t1": 1.9783, "tft": 6.6559, "input_0": 2602, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 15.8, "mem_use": 37.55, "gen_rate": 6.0, "speed": 0.92, "text": "\"There are two main reasons for "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 147, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.5, "tree_w": 255, "tree_size": 1024, "t0": 7.88, "t1": 1.97, "tft": 8.661, "input_0": 3535, "input_1": 1025, "min_CLP": -9.68, "draft_iters": 30.5, "mem_use": 37.35, "gen_rate": 19.5, "speed": 1.98, "text": "\\n*You are a helpful, respectful"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 180, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 23.3, "tree_w": 70, "tree_size": 1024, "t0": 10.5, "t1": 1.9767, "tft": 9.471, "input_0": 4928, "input_1": 1025, "min_CLP": -12.04, "draft_iters": 32.0, "mem_use": 37.42, "gen_rate": 17.3, "speed": 1.39, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 452, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 117, "tree_size": 1024, "t0": 9.23, "t1": 2.01, "tft": 10.6278, "input_0": 4448, "input_1": 1025, "min_CLP": -11.42, "draft_iters": 32.0, "mem_use": 38.2, "gen_rate": 24.5, "speed": 2.18, "text": "\\nWho is online\\n\\nUsers browsin"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 16.3, "tree_w": 179, "tree_size": 1024, "t0": 6.1933, "t1": 1.9683, "tft": 8.8386, "input_0": 3053, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 23.3, "mem_use": 37.39, "gen_rate": 8.3, "speed": 1.02, "text": "\"Yes, but I am not currently in "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 157, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 64, "tree_size": 1024, "t0": 9.755, "t1": 1.97, "tft": 9.0817, "input_0": 4373, "input_1": 1025, "min_CLP": -11.82, "draft_iters": 32.0, "mem_use": 37.36, "gen_rate": 26.0, "speed": 2.22, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 129, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 143, "tree_size": 1024, "t0": 8.895, "t1": 1.965, "tft": 8.8565, "input_0": 4011, "input_1": 1025, "min_CLP": -10.01, "draft_iters": 32.0, "mem_use": 37.32, "gen_rate": 26.0, "speed": 2.39, "text": "\\nwhat is the color of mars\\n\\n["}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 535, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 107, "tree_size": 1024, "t0": 9.63, "t1": 2.035, "tft": 11.2995, "input_0": 3994, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 38.47, "gen_rate": 24.5, "speed": 2.1, "text": "Here is list of words related to"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 143, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 12.1, "tree_w": 281, "tree_size": 1024, "t0": 4.92, "t1": 1.9714, "tft": 8.8356, "input_0": 2645, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 19.1, "mem_use": 37.35, "gen_rate": 5.4, "speed": 0.79, "text": "\\nYou are an intelligent and cur"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 237, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 240, "tree_size": 1024, "t0": 5.004, "t1": 1.982, "tft": 9.1572, "input_0": 2882, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 17.6, "mem_use": 37.58, "gen_rate": 7.0, "speed": 1.0, "text": "No. The Second Amendment protect"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 144, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.7, "tree_w": 278, "tree_size": 1024, "t0": 5.1817, "t1": 1.9683, "tft": 8.7525, "input_0": 2671, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 20.5, "mem_use": 37.34, "gen_rate": 6.3, "speed": 0.89, "text": "\\nPrime numbers are the ones tha"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 217, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 24.0, "tree_w": 133, "tree_size": 1024, "t0": 8.42, "t1": 1.98, "tft": 5.1259, "input_0": 3349, "input_1": 1025, "min_CLP": -9.22, "draft_iters": 32.0, "mem_use": 37.35, "gen_rate": 19.0, "speed": 1.83, "text": "\\n[INST] <<SYS>>\\n\\nYou are a he"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 20.3, "tree_w": 143, "tree_size": 1024, "t0": 7.47, "t1": 1.97, "tft": 8.796, "input_0": 3491, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 27.7, "mem_use": 37.38, "gen_rate": 12.0, "speed": 1.27, "text": "Melbourne was the capital from 1"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 191, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.6, "tree_w": 206, "tree_size": 1024, "t0": 6.06, "t1": 1.974, "tft": 9.5507, "input_0": 3146, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 21.6, "mem_use": 37.45, "gen_rate": 7.4, "speed": 0.92, "text": "[INST] what are you doing there "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 590, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.2, "tree_w": 314, "tree_size": 1024, "t0": 5.13, "t1": 2.0383, "tft": 11.6663, "input_0": 2636, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 17.7, "mem_use": 38.62, "gen_rate": 6.0, "speed": 0.84, "text": "\\n\"I\\'m so glad you asked me to "}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 162, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 13.2, "tree_w": 353, "tree_size": 1024, "t0": 4.88, "t1": 1.97, "tft": 8.7102, "input_0": 2158, "input_1": 1025, "min_CLP": -8.7, "draft_iters": 20.2, "mem_use": 37.39, "gen_rate": 11.5, "speed": 1.68, "text": "\"\\nI'm just curious as to why yo"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 392, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 25.5, "tree_w": 171, "tree_size": 1024, "t0": 8.03, "t1": 2.005, "tft": 10.1065, "input_0": 3549, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 32.0, "mem_use": 38.05, "gen_rate": 18.5, "speed": 1.84, "text": "\\nThe unit vector u = (x/(x^2 + "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 139, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.0, "tree_w": 333, "tree_size": 1024, "t0": 4.9533, "t1": 1.9717, "tft": 8.7063, "input_0": 2281, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 21.3, "mem_use": 37.33, "gen_rate": 5.7, "speed": 0.82, "text": "\"\\nCan you list the issues with "}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 148, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 26.0, "tree_w": 247, "tree_size": 1024, "t0": 6.885, "t1": 1.97, "tft": 9.4503, "input_0": 2611, "input_1": 1025, "min_CLP": -9.45, "draft_iters": 32.0, "mem_use": 37.32, "gen_rate": 19.5, "speed": 2.2, "text": "\\n-\\n\\n[INST] <<SYS>>\\nYou are a"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 142, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.5, "tree_w": 302, "tree_size": 1024, "t0": 4.58, "t1": 1.9725, "tft": 9.3052, "input_0": 2366, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 17.5, "mem_use": 37.31, "gen_rate": 9.0, "speed": 1.37, "text": "\\nAs you know, L\u2019Hopital\u2019s Rule "}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 242, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 21.2, "tree_w": 198, "tree_size": 1024, "t0": 6.85, "t1": 1.985, "tft": 8.0389, "input_0": 3317, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 29.0, "mem_use": 37.6, "gen_rate": 9.8, "speed": 1.1, "text": "No. The sum of squares error is "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 295, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.2, "tree_w": 291, "tree_size": 1024, "t0": 5.05, "t1": 1.9883, "tft": 5.6278, "input_0": 2403, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 19.8, "mem_use": 37.57, "gen_rate": 6.0, "speed": 0.85, "text": "\\nA slogan for Hippoplaisir is:\\"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 250, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.6, "tree_w": 309, "tree_size": 1024, "t0": 4.596, "t1": 1.984, "tft": 8.231, "input_0": 2538, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 16.6, "mem_use": 37.62, "gen_rate": 7.2, "speed": 1.09, "text": "The best place in North America "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 136, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 23.0, "tree_w": 182, "tree_size": 1024, "t0": 7.545, "t1": 1.97, "tft": 5.0774, "input_0": 2895, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 30.2, "mem_use": 37.14, "gen_rate": 9.8, "speed": 1.02, "text": "\\n[INST] <<SYS>>\\nI want to see "}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 230, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 14.5, "tree_w": 275, "tree_size": 1024, "t0": 5.77, "t1": 1.98, "tft": 7.1903, "input_0": 3171, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 21.8, "mem_use": 37.56, "gen_rate": 13.0, "speed": 1.68, "text": "The two eggs that landed on the "}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 214, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 223, "tree_size": 1024, "t0": 5.6367, "t1": 1.98, "tft": 8.1492, "input_0": 3035, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 21.3, "mem_use": 37.52, "gen_rate": 10.7, "speed": 1.4, "text": "The most common way to deal with"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 769, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 102, "tree_size": 1024, "t0": 9.02, "t1": 2.075, "tft": 12.4164, "input_0": 4034, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 32.0, "mem_use": 39.13, "gen_rate": 27.0, "speed": 2.43, "text": "\"I am Open Assistant, an AI lang"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 537, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 193, "tree_size": 1024, "t0": 6.2875, "t1": 2.0325, "tft": 11.1795, "input_0": 3185, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 21.2, "mem_use": 38.49, "gen_rate": 8.8, "speed": 1.05, "text": "\\nPros and Cons of Building Your"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 131, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 67, "tree_size": 1024, "t0": 9.355, "t1": 1.965, "tft": 8.8548, "input_0": 4190, "input_1": 1025, "min_CLP": -10.18, "draft_iters": 32.0, "mem_use": 37.32, "gen_rate": 26.0, "speed": 2.3, "text": "\\n[INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 173, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.8, "tree_w": 205, "tree_size": 1024, "t0": 6.79, "t1": 1.9725, "tft": 9.8665, "input_0": 3164, "input_1": 1025, "min_CLP": -8.65, "draft_iters": 25.0, "mem_use": 37.4, "gen_rate": 9.5, "speed": 1.08, "text": "\\nWhat\\'s the difference between"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1837, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.4, "tree_w": 280, "tree_size": 1024, "t0": 7.708, "t1": 2.526, "tft": 17.4803, "input_0": 3104, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 21.8, "mem_use": 42.21, "gen_rate": 7.0, "speed": 0.68, "text": "\"The _physics_process function i"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 17.2, "tree_w": 176, "tree_size": 1024, "t0": 6.435, "t1": 1.975, "tft": 9.4752, "input_0": 3184, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 24.8, "mem_use": 37.5, "gen_rate": 9.2, "speed": 1.1, "text": "No. You can decorate a function "}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 25.2, "tree_w": 156, "tree_size": 1024, "t0": 7.7325, "t1": 1.9725, "tft": 5.0684, "input_0": 3133, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 37.19, "gen_rate": 12.0, "speed": 1.24, "text": "[INST]\\n\\nWho made the World [\\\\"}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 153, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 234, "tree_size": 1024, "t0": 6.0, "t1": 1.97, "tft": 8.9303, "input_0": 2903, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 23.5, "mem_use": 37.34, "gen_rate": 8.8, "speed": 1.1, "text": "\\nWhat are the requirements for "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 603, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.5, "tree_w": 367, "tree_size": 1024, "t0": 4.325, "t1": 2.0463, "tft": 11.4592, "input_0": 2240, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 15.2, "mem_use": 38.64, "gen_rate": 4.4, "speed": 0.69, "text": "I understand your skepticism and"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 232, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.3, "tree_w": 243, "tree_size": 1024, "t0": 4.92, "t1": 1.9817, "tft": 8.765, "input_0": 2667, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 17.5, "mem_use": 37.57, "gen_rate": 5.8, "speed": 0.85, "text": "There are a couple of universiti"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 253, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.0, "tree_w": 258, "tree_size": 1024, "t0": 5.6825, "t1": 1.985, "tft": 9.1531, "input_0": 2586, "input_1": 1025, "min_CLP": -8.74, "draft_iters": 22.8, "mem_use": 37.63, "gen_rate": 8.5, "speed": 1.11, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 190, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 17.7, "tree_w": 210, "tree_size": 1024, "t0": 6.5467, "t1": 1.9833, "tft": 9.0339, "input_0": 3415, "input_1": 1025, "min_CLP": -8.7, "draft_iters": 24.0, "mem_use": 37.46, "gen_rate": 16.3, "speed": 1.92, "text": "\\nCan you explain to me how the "}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 255, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 260, "tree_size": 1024, "t0": 5.2017, "t1": 1.9833, "tft": 9.3382, "input_0": 2753, "input_1": 1025, "min_CLP": -8.67, "draft_iters": 18.7, "mem_use": 37.63, "gen_rate": 5.3, "speed": 0.74, "text": "\\nWhat is the difference between"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 196, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.2, "tree_w": 287, "tree_size": 1024, "t0": 5.1717, "t1": 1.9767, "tft": 5.0888, "input_0": 2873, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 20.3, "mem_use": 37.29, "gen_rate": 5.3, "speed": 0.75, "text": "\\nA box. A cat. A radioactive su"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 541, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 265, "tree_size": 1024, "t0": 5.004, "t1": 2.032, "tft": 10.8643, "input_0": 2742, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 17.2, "mem_use": 38.5, "gen_rate": 7.4, "speed": 1.05, "text": "\"\\nUnfortunately, I don't have a"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 155, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 23.7, "tree_w": 107, "tree_size": 1024, "t0": 8.53, "t1": 1.97, "tft": 10.6894, "input_0": 4093, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 32.0, "mem_use": 37.37, "gen_rate": 16.3, "speed": 1.56, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 159, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 22.8, "tree_w": 116, "tree_size": 1024, "t0": 8.3475, "t1": 1.9725, "tft": 8.3441, "input_0": 4026, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 31.0, "mem_use": 37.38, "gen_rate": 8.5, "speed": 0.82, "text": "I can speak Spanish.\\n[INST] can"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 150, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 285, "tree_size": 1024, "t0": 5.104, "t1": 1.97, "tft": 8.8998, "input_0": 2829, "input_1": 1025, "min_CLP": -8.77, "draft_iters": 19.6, "mem_use": 37.33, "gen_rate": 7.0, "speed": 0.99, "text": "\\nAnswers\\n\\nThe F-centers are t"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1179, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 81, "tree_size": 1024, "t0": 12.065, "t1": 2.395, "tft": 14.5975, "input_0": 4786, "input_1": 1025, "min_CLP": -10.49, "draft_iters": 32.0, "mem_use": 40.32, "gen_rate": 24.0, "speed": 1.66, "text": "\"\\nWrite code that imitates a fa"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 446, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.3, "tree_w": 238, "tree_size": 1024, "t0": 6.39, "t1": 2.0133, "tft": 10.2767, "input_0": 3158, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 24.0, "mem_use": 38.18, "gen_rate": 11.3, "speed": 1.35, "text": "\\nWhat do you think about the qu"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 227, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.6, "tree_w": 360, "tree_size": 1024, "t0": 4.2, "t1": 1.98, "tft": 7.7384, "input_0": 2140, "input_1": 1025, "min_CLP": -8.81, "draft_iters": 16.9, "mem_use": 37.55, "gen_rate": 5.0, "speed": 0.81, "text": "\"\\nWhat do you think about AI as"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 562, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.3, "tree_w": 265, "tree_size": 1024, "t0": 5.3333, "t1": 2.0367, "tft": 9.9786, "input_0": 2833, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 18.5, "mem_use": 38.55, "gen_rate": 6.5, "speed": 0.88, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.8, "tree_w": 179, "tree_size": 1024, "t0": 7.8875, "t1": 2.0575, "tft": 11.8566, "input_0": 3855, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 27.8, "mem_use": 38.88, "gen_rate": 8.2, "speed": 0.83, "text": "In Deutschland verursacht die Ze"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 485, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.7, "tree_w": 291, "tree_size": 1024, "t0": 5.1383, "t1": 2.0233, "tft": 9.9775, "input_0": 2421, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 19.7, "mem_use": 38.3, "gen_rate": 6.2, "speed": 0.86, "text": "\"I'm sorry, but our terms and co"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 271, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.5, "tree_w": 274, "tree_size": 1024, "t0": 4.8217, "t1": 1.9867, "tft": 8.2987, "input_0": 2705, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 17.7, "mem_use": 37.69, "gen_rate": 6.0, "speed": 0.88, "text": "\"Well, if you found a wallet wit"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 312, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 9.1, "tree_w": 369, "tree_size": 1024, "t0": 4.1336, "t1": 1.9891, "tft": 8.5666, "input_0": 2238, "input_1": 1025, "min_CLP": -8.76, "draft_iters": 15.5, "mem_use": 37.82, "gen_rate": 2.9, "speed": 0.48, "text": "You know how to self-attention m"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 161, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 25.5, "tree_w": 111, "tree_size": 1024, "t0": 8.61, "t1": 1.97, "tft": 9.3211, "input_0": 3909, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 32.0, "mem_use": 37.38, "gen_rate": 21.5, "speed": 2.03, "text": "\\nWrite a function in JavaScript"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 383, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 19.0, "tree_w": 160, "tree_size": 1024, "t0": 8.795, "t1": 2.01, "tft": 10.4698, "input_0": 4708, "input_1": 1025, "min_CLP": -8.74, "draft_iters": 28.5, "mem_use": 38.02, "gen_rate": 16.5, "speed": 1.53, "text": "\\nIn the state of Wyoming, publi"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 231, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 10.1, "tree_w": 324, "tree_size": 1024, "t0": 4.3122, "t1": 1.9789, "tft": 9.1361, "input_0": 2322, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 16.6, "mem_use": 37.56, "gen_rate": 3.9, "speed": 0.62, "text": "For a nicer answer, you could gi"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 389, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.3, "tree_w": 209, "tree_size": 1024, "t0": 5.7367, "t1": 2.01, "tft": 10.2214, "input_0": 3313, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 19.5, "mem_use": 38.03, "gen_rate": 6.0, "speed": 0.77, "text": "\"Optimal mayonnaise thickness va"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 272, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 90, "tree_size": 1024, "t0": 8.82, "t1": 1.985, "tft": 9.5705, "input_0": 3761, "input_1": 1025, "min_CLP": -9.36, "draft_iters": 32.0, "mem_use": 37.68, "gen_rate": 25.0, "speed": 2.31, "text": "The answer would depend on the d"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 158, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 24.7, "tree_w": 204, "tree_size": 1024, "t0": 7.9233, "t1": 1.97, "tft": 9.2118, "input_0": 3125, "input_1": 1025, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 37.38, "gen_rate": 18.3, "speed": 1.85, "text": "\\n#1:\\n\\n#2:\\n\\n#3:\\n\\n#4:\\n\\n#5"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 15.0, "tree_w": 229, "tree_size": 1024, "t0": 7.04, "t1": 1.9767, "tft": 9.6832, "input_0": 3997, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 24.7, "mem_use": 37.52, "gen_rate": 12.3, "speed": 1.37, "text": "Yes, the Declaration was conside"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 414, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 20.0, "tree_w": 156, "tree_size": 1024, "t0": 10.785, "t1": 2.01, "tft": 13.7093, "input_0": 5377, "input_1": 1025, "min_CLP": -9.56, "draft_iters": 32.0, "mem_use": 38.08, "gen_rate": 21.0, "speed": 1.64, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.0, "tree_w": 295, "tree_size": 1024, "t0": 5.4167, "t1": 1.9667, "tft": 9.2822, "input_0": 2535, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 22.3, "mem_use": 37.39, "gen_rate": 13.7, "speed": 1.85, "text": "The average temperature in Decem"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 247, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 19.0, "tree_w": 193, "tree_size": 1024, "t0": 6.8075, "t1": 1.98, "tft": 9.1733, "input_0": 3473, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 26.2, "mem_use": 37.61, "gen_rate": 12.0, "speed": 1.37, "text": "\"Oops, sorry about that! I'm on "}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 310, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 322, "tree_size": 1024, "t0": 4.3725, "t1": 1.9875, "tft": 8.4415, "input_0": 2965, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 15.2, "mem_use": 37.8, "gen_rate": 8.0, "speed": 1.26, "text": "\"I don't think it's meant to be "}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 454, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 15.7, "tree_w": 302, "tree_size": 1024, "t0": 5.3633, "t1": 2.0167, "tft": 10.2342, "input_0": 2591, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 22.0, "mem_use": 38.21, "gen_rate": 6.0, "speed": 0.81, "text": "\\nThis task is written for a rei"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.3, "tree_w": 184, "tree_size": 1024, "t0": 6.9633, "t1": 1.97, "tft": 9.2111, "input_0": 3321, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 28.3, "mem_use": 37.4, "gen_rate": 15.7, "speed": 1.75, "text": "A German politician and former F"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 156, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 12.4, "tree_w": 263, "tree_size": 1024, "t0": 5.374, "t1": 1.972, "tft": 9.0853, "input_0": 2929, "input_1": 1025, "min_CLP": -8.86, "draft_iters": 20.0, "mem_use": 37.35, "gen_rate": 8.8, "speed": 1.2, "text": "\\nWhich of the following is the "}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 868, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 18.7, "tree_w": 171, "tree_size": 1024, "t0": 7.8867, "t1": 2.23, "tft": 8.1378, "input_0": 3514, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 27.0, "mem_use": 39.25, "gen_rate": 13.7, "speed": 1.35, "text": "\\n1. Discover a market need [\\\\I"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 138, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.8, "tree_w": 256, "tree_size": 1024, "t0": 5.678, "t1": 1.966, "tft": 8.882, "input_0": 2709, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 22.8, "mem_use": 37.39, "gen_rate": 6.6, "speed": 0.86, "text": "\\nWhy do people think that consc"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 68, "tree_size": 1024, "t0": 8.84, "t1": 1.96, "tft": 8.838, "input_0": 3763, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 32.0, "mem_use": 37.27, "gen_rate": 26.5, "speed": 2.45, "text": "You are a helpful, respectful an"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 1024, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 24.5, "tree_w": 87, "tree_size": 1024, "t0": 10.045, "t1": 2.24, "tft": 13.9353, "input_0": 4194, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 32.0, "mem_use": 39.85, "gen_rate": 22.0, "speed": 1.79, "text": "You are an honest, friendly and "}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 493, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.1, "tree_w": 225, "tree_size": 1024, "t0": 5.4243, "t1": 2.0257, "tft": 10.2281, "input_0": 2847, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 18.6, "mem_use": 38.32, "gen_rate": 5.4, "speed": 0.73, "text": "\"\u2022 Ensure that the habit is stil"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 357, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.6, "tree_w": 265, "tree_size": 1024, "t0": 5.248, "t1": 1.998, "tft": 5.8569, "input_0": 2576, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 20.8, "mem_use": 37.76, "gen_rate": 6.8, "speed": 0.94, "text": "\"In chess, we know where the ene"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 164, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.7, "tree_w": 313, "tree_size": 1024, "t0": 4.77, "t1": 1.97, "tft": 7.7604, "input_0": 2786, "input_1": 1025, "min_CLP": -8.84, "draft_iters": 17.8, "mem_use": 37.4, "gen_rate": 6.3, "speed": 0.94, "text": "\"The 6th of February is a day wh"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 165, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.4, "tree_w": 340, "tree_size": 1024, "t0": 4.29, "t1": 1.97, "tft": 9.1637, "input_0": 2212, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 16.3, "mem_use": 37.4, "gen_rate": 4.6, "speed": 0.73, "text": "\\nThe board state is already kno"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 329, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 23.3, "tree_w": 108, "tree_size": 1024, "t0": 8.6333, "t1": 1.99, "tft": 10.7315, "input_0": 3962, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 30.7, "mem_use": 37.9, "gen_rate": 14.7, "speed": 1.38, "text": "\"[INST] What's the weather like "}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 519, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 11.8, "tree_w": 343, "tree_size": 1024, "t0": 4.925, "t1": 2.0325, "tft": 10.3176, "input_0": 3317, "input_1": 1025, "min_CLP": -9.08, "draft_iters": 17.0, "mem_use": 38.45, "gen_rate": 11.0, "speed": 1.58, "text": "\\nNo. Find the nearest character"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 301, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.4, "tree_w": 333, "tree_size": 1024, "t0": 4.5886, "t1": 1.99, "tft": 9.4408, "input_0": 2513, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 16.6, "mem_use": 37.77, "gen_rate": 5.3, "speed": 0.8, "text": "\"I'm a young, college-educated, "}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 333, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 56, "tree_h": 22.8, "tree_w": 163, "tree_size": 1024, "t0": 8.925, "t1": 1.995, "tft": 10.3493, "input_0": 3965, "input_1": 1025, "min_CLP": -9.2, "draft_iters": 31.0, "mem_use": 37.89, "gen_rate": 14.0, "speed": 1.28, "text": "\\n<</SYS>\\n\\n -----Original Mess"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 17.1, "tree_w": 238, "tree_size": 1024, "t0": 6.4086, "t1": 1.9771, "tft": 9.2118, "input_0": 3048, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 25.3, "mem_use": 37.5, "gen_rate": 4.9, "speed": 0.58, "text": "An African swallow would have an"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 210, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 12.2, "tree_w": 261, "tree_size": 1024, "t0": 5.186, "t1": 1.98, "tft": 9.0458, "input_0": 2851, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 19.2, "mem_use": 37.51, "gen_rate": 10.0, "speed": 1.4, "text": "Tenants are superior to their la"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 455, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.0, "tree_w": 182, "tree_size": 1024, "t0": 7.015, "t1": 2.01, "tft": 10.2737, "input_0": 3425, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 28.0, "mem_use": 38.21, "gen_rate": 16.0, "speed": 1.77, "text": "\\n3. Use the Windows \"Check Disk"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 436, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 15.6, "tree_w": 219, "tree_size": 1024, "t0": 6.078, "t1": 2.016, "tft": 9.3939, "input_0": 2925, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 22.4, "mem_use": 38.16, "gen_rate": 8.4, "speed": 1.04, "text": "Open Assistant is pretrained wit"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 687, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 19.2, "tree_w": 198, "tree_size": 1024, "t0": 6.72, "t1": 2.054, "tft": 11.6768, "input_0": 2879, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 26.0, "mem_use": 38.88, "gen_rate": 7.0, "speed": 0.8, "text": "\\nHow do I make a hot dog? [\\\\IN"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 130, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 223, "tree_size": 1024, "t0": 5.5975, "t1": 1.97, "tft": 9.0092, "input_0": 2677, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 20.5, "mem_use": 37.36, "gen_rate": 9.0, "speed": 1.19, "text": "\\nDoes the moon landings really "}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 308, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 319, "tree_size": 1024, "t0": 4.548, "t1": 1.99, "tft": 9.2012, "input_0": 2744, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 16.0, "mem_use": 37.85, "gen_rate": 6.4, "speed": 0.98, "text": "PostCSS is a CSS preprocessor. I"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 640, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.0, "tree_w": 332, "tree_size": 1024, "t0": 4.505, "t1": 2.05, "tft": 11.0633, "input_0": 2472, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 15.5, "mem_use": 38.75, "gen_rate": 5.3, "speed": 0.81, "text": "\"I'm looking to buy a graphics c"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 216, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 15.5, "tree_w": 267, "tree_size": 1024, "t0": 5.54, "t1": 1.98, "tft": 5.0978, "input_0": 2341, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 22.5, "mem_use": 37.36, "gen_rate": 6.0, "speed": 0.8, "text": "\"\\nToilet Paper: Yay or Nay? [\\\\"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "facebook/opt-2.7b", "target_model_name": "facebook/opt-13b", "prompt_len": 372, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 103, "tree_size": 1024, "t0": 10.27, "t1": 2.01, "tft": 9.9527, "input_0": 5075, "input_1": 1025, "min_CLP": -9.71, "draft_iters": 32.0, "mem_use": 37.98, "gen_rate": 24.0, "speed": 1.95, "text": "The static still state is a stat"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 1024, "max_branch_width": 32, "gen_rate": 12.07, "gen_rate_micro": 9.38, "gen_speed": 1.319, "gen_speed_micro": 1.187, "t0": 6.5513, "t1": 2.0043, "input_0": 3191.3, "input_1": 1025.0, "tree_size": 1024.0, "tree_w": 220.3, "tree_h": 16.8, "prompt_len": 320.7, "min_CLP": -8.62, "mem_use": 42.21, "exp_time": 23460.58}
