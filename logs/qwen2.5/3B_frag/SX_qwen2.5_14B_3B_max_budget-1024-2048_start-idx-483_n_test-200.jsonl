{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-3B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "1024, 2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 200, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-30 14:05:31", "date": "250330", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 22.5, "tree_w": 140, "tree_size": 1024, "t0": 10.13, "t1": 2.385, "tft": 18.0768, "input_0": 4613, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 31.5, "mem_use": 50.5, "gen_rate": 8.5, "speed": 0.68, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 124, "tree_size": 1024, "t0": 11.6, "t1": 2.33, "tft": 9.579, "input_0": 4406, "input_1": 1025, "min_CLP": -8.85, "draft_iters": 32.0, "mem_use": 50.2, "gen_rate": 25.5, "speed": 1.83, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.2, "tree_w": 170, "tree_size": 1024, "t0": 7.916, "t1": 2.322, "tft": 11.3769, "input_0": 3653, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 23.6, "mem_use": 50.2, "gen_rate": 7.8, "speed": 0.76, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 177, "tree_size": 1024, "t0": 7.305, "t1": 2.3575, "tft": 12.3141, "input_0": 3549, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 20.0, "mem_use": 52.74, "gen_rate": 8.8, "speed": 0.91, "text": "\"It's important to note that as "}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 18.5, "tree_w": 102, "tree_size": 1024, "t0": 12.96, "t1": 2.33, "tft": 12.794, "input_0": 5572, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 32.0, "mem_use": 50.62, "gen_rate": 19.5, "speed": 1.28, "text": "Certainly! Here are some of the "}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 59, "tree_size": 1024, "t0": 11.175, "t1": 2.34, "tft": 11.2902, "input_0": 3922, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 32.0, "mem_use": 50.81, "gen_rate": 25.5, "speed": 1.89, "text": "I don\\'t remember, but i know th"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 18.2, "tree_w": 155, "tree_size": 1024, "t0": 9.545, "t1": 2.325, "tft": 13.1442, "input_0": 4482, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 28.5, "mem_use": 50.41, "gen_rate": 8.5, "speed": 0.72, "text": "To enhance the visual quality of"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.8, "tree_w": 178, "tree_size": 1024, "t0": 7.752, "t1": 2.33, "tft": 10.563, "input_0": 3353, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 23.2, "mem_use": 50.65, "gen_rate": 6.4, "speed": 0.63, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 18.5, "tree_w": 140, "tree_size": 1024, "t0": 8.4425, "t1": 2.33, "tft": 11.8988, "input_0": 3686, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 27.0, "mem_use": 50.44, "gen_rate": 8.5, "speed": 0.79, "text": "\"In that case, the cat in Schr\u00f6d"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 18.5, "tree_w": 178, "tree_size": 1024, "t0": 8.4725, "t1": 2.3525, "tft": 12.9462, "input_0": 3914, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 27.2, "mem_use": 52.42, "gen_rate": 9.5, "speed": 0.88, "text": "\"It's a good idea to set up your"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 24.0, "tree_w": 191, "tree_size": 1024, "t0": 9.01, "t1": 2.32, "tft": 13.7252, "input_0": 3617, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 32.0, "mem_use": 50.19, "gen_rate": 0.0, "speed": 0.0, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.7, "tree_w": 133, "tree_size": 1024, "t0": 9.7667, "t1": 2.32, "tft": 10.8589, "input_0": 4126, "input_1": 1025, "min_CLP": -8.65, "draft_iters": 30.3, "mem_use": 50.21, "gen_rate": 12.0, "speed": 0.99, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfC\u00f3"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.4, "tree_w": 252, "tree_size": 1024, "t0": 6.744, "t1": 2.334, "tft": 12.1833, "input_0": 3404, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 19.2, "mem_use": 50.19, "gen_rate": 8.4, "speed": 0.93, "text": "F-centers, also known as color c"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 16.2, "tree_w": 231, "tree_size": 1024, "t0": 8.17, "t1": 2.4175, "tft": 16.0567, "input_0": 3576, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 25.2, "mem_use": 54.75, "gen_rate": 9.8, "speed": 0.92, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.7, "tree_w": 146, "tree_size": 1024, "t0": 9.3033, "t1": 2.36, "tft": 13.912, "input_0": 4154, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 28.0, "mem_use": 51.83, "gen_rate": 12.0, "speed": 1.03, "text": "Apologies for the confusion. The"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 17.2, "tree_w": 143, "tree_size": 1024, "t0": 9.39, "t1": 2.33, "tft": 9.8854, "input_0": 4299, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 27.2, "mem_use": 50.62, "gen_rate": 12.0, "speed": 1.02, "text": "Certainly, AI assistants have th"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 16.2, "tree_w": 212, "tree_size": 1024, "t0": 7.7883, "t1": 2.3483, "tft": 15.9818, "input_0": 3624, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 23.8, "mem_use": 52.53, "gen_rate": 6.2, "speed": 0.61, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.5, "tree_w": 139, "tree_size": 1024, "t0": 9.615, "t1": 2.35, "tft": 13.9856, "input_0": 4245, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 28.0, "mem_use": 52.49, "gen_rate": 10.2, "speed": 0.86, "text": "Die Zementproduktion ist f\u00fcr etw"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 16.0, "tree_w": 186, "tree_size": 1024, "t0": 7.2167, "t1": 2.36, "tft": 13.1233, "input_0": 3227, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 23.3, "mem_use": 51.84, "gen_rate": 5.3, "speed": 0.56, "text": "Im sorry, I cannot engage in dis"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 241, "tree_size": 1024, "t0": 6.2033, "t1": 2.3367, "tft": 9.8961, "input_0": 3158, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 18.3, "mem_use": 50.87, "gen_rate": 11.0, "speed": 1.29, "text": "If the person who lost the prope"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 24.0, "tree_w": 84, "tree_size": 1024, "t0": 11.885, "t1": 2.34, "tft": 10.8254, "input_0": 4832, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 32.0, "mem_use": 50.45, "gen_rate": 22.0, "speed": 1.55, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u7684\u8ad6\u6587\u4f86\u7372\u53d6\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1a\\n1. Vaswani"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 60, "tree_size": 1024, "t0": 12.87, "t1": 2.325, "tft": 12.7006, "input_0": 5811, "input_1": 1025, "min_CLP": -9.27, "draft_iters": 32.0, "mem_use": 50.25, "gen_rate": 24.0, "speed": 1.58, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.7, "tree_w": 141, "tree_size": 1024, "t0": 9.4633, "t1": 2.3533, "tft": 13.6625, "input_0": 4462, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 27.3, "mem_use": 51.54, "gen_rate": 10.7, "speed": 0.9, "text": "\"In general, public nudity is co"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.8, "tree_w": 182, "tree_size": 1024, "t0": 7.5075, "t1": 2.33, "tft": 9.6162, "input_0": 3533, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 22.0, "mem_use": 50.65, "gen_rate": 9.2, "speed": 0.94, "text": "\"There are many ways to deliver "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.5, "tree_w": 210, "tree_size": 1024, "t0": 7.8375, "t1": 2.355, "tft": 13.0628, "input_0": 3611, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 23.5, "mem_use": 51.54, "gen_rate": 8.0, "speed": 0.79, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 17.8, "tree_w": 190, "tree_size": 1024, "t0": 8.1625, "t1": 2.3475, "tft": 12.5217, "input_0": 3720, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 25.2, "mem_use": 50.91, "gen_rate": 13.8, "speed": 1.31, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 269, "tree_size": 1024, "t0": 6.448, "t1": 2.322, "tft": 11.3893, "input_0": 3329, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 18.6, "mem_use": 50.18, "gen_rate": 6.8, "speed": 0.78, "text": "Here is a list of nicknames you "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 17.8, "tree_w": 146, "tree_size": 1024, "t0": 9.3625, "t1": 2.335, "tft": 14.9747, "input_0": 4288, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 27.5, "mem_use": 50.58, "gen_rate": 12.5, "speed": 1.07, "text": "\"Yes, the Balfour Declaration wa"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 22.0, "tree_w": 131, "tree_size": 1024, "t0": 11.735, "t1": 2.345, "tft": 13.8424, "input_0": 4822, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 32.0, "mem_use": 51.34, "gen_rate": 17.0, "speed": 1.21, "text": "\"Felices: \\n1. \u00ab(I Can't Get No)"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 15.7, "tree_w": 172, "tree_size": 1024, "t0": 10.46, "t1": 2.33, "tft": 12.0443, "input_0": 5276, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 27.7, "mem_use": 50.27, "gen_rate": 13.0, "speed": 1.02, "text": "\"Sure, here's a table with the a"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 17.8, "tree_w": 245, "tree_size": 1024, "t0": 6.9275, "t1": 2.34, "tft": 11.8325, "input_0": 2638, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 24.5, "mem_use": 50.68, "gen_rate": 4.5, "speed": 0.49, "text": "```<|endoftext|>Human: What is t"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.3, "tree_w": 193, "tree_size": 1024, "t0": 6.9217, "t1": 2.3467, "tft": 11.062, "input_0": 3414, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 20.8, "mem_use": 51.04, "gen_rate": 6.5, "speed": 0.7, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 17.2, "tree_w": 144, "tree_size": 1024, "t0": 9.2925, "t1": 2.365, "tft": 15.2451, "input_0": 4477, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 26.8, "mem_use": 51.81, "gen_rate": 9.8, "speed": 0.84, "text": "Sure, here is a step-by-step gui"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 20.3, "tree_w": 159, "tree_size": 1024, "t0": 10.2867, "t1": 2.3167, "tft": 13.4146, "input_0": 4731, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 30.3, "mem_use": 50.29, "gen_rate": 12.0, "speed": 0.95, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 18.5, "tree_w": 198, "tree_size": 1024, "t0": 10.265, "t1": 2.325, "tft": 11.0988, "input_0": 4658, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 29.0, "mem_use": 50.21, "gen_rate": 6.0, "speed": 0.48, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 18.0, "tree_w": 147, "tree_size": 1024, "t0": 8.804, "t1": 2.412, "tft": 14.5105, "input_0": 3952, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 26.6, "mem_use": 54.34, "gen_rate": 9.2, "speed": 0.82, "text": "Discovery:\\n- Find a market need"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 133, "tree_size": 1024, "t0": 10.14, "t1": 2.32, "tft": 12.3298, "input_0": 4179, "input_1": 1025, "min_CLP": -10.02, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 25.5, "speed": 2.05, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 19.8, "tree_w": 127, "tree_size": 1024, "t0": 9.5825, "t1": 2.3275, "tft": 11.369, "input_0": 4352, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 28.8, "mem_use": 50.07, "gen_rate": 12.0, "speed": 1.01, "text": "\"To build a PC, you'll need to f"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 16.2, "tree_w": 306, "tree_size": 1024, "t0": 6.28, "t1": 2.412, "tft": 14.8505, "input_0": 2444, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 22.4, "mem_use": 54.33, "gen_rate": 8.0, "speed": 0.92, "text": "Hey there! How can I help you to"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 16.4, "tree_w": 157, "tree_size": 1024, "t0": 8.126, "t1": 2.364, "tft": 12.8489, "input_0": 3748, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 24.8, "mem_use": 52.13, "gen_rate": 8.8, "speed": 0.84, "text": "\"\u2022 Focus on the benefits. When y"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.2, "tree_w": 178, "tree_size": 1024, "t0": 7.44, "t1": 2.3483, "tft": 11.6339, "input_0": 3474, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 22.2, "mem_use": 51.38, "gen_rate": 6.2, "speed": 0.63, "text": "\"You're right, the player does h"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.0, "tree_w": 158, "tree_size": 1024, "t0": 8.7, "t1": 2.3225, "tft": 11.0154, "input_0": 3824, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 26.0, "mem_use": 50.25, "gen_rate": 9.5, "speed": 0.86, "text": "Yes, I can. Here are some of the"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.2, "tree_w": 242, "tree_size": 1024, "t0": 7.3575, "t1": 2.33, "tft": 12.7858, "input_0": 3678, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 21.5, "mem_use": 50.27, "gen_rate": 9.2, "speed": 0.95, "text": "In the context of a turn-based s"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 30, "tree_h": 22.0, "tree_w": 121, "tree_size": 1024, "t0": 10.3467, "t1": 2.3433, "tft": 14.7175, "input_0": 4386, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 31.0, "mem_use": 51.1, "gen_rate": 10.0, "speed": 0.79, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 22.5, "tree_w": 89, "tree_size": 1024, "t0": 11.61, "t1": 2.365, "tft": 6.9572, "input_0": 5003, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 51.59, "gen_rate": 19.5, "speed": 1.4, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 167, "tree_size": 1024, "t0": 9.805, "t1": 2.35, "tft": 11.0915, "input_0": 3940, "input_1": 1025, "min_CLP": -11.54, "draft_iters": 32.0, "mem_use": 51.05, "gen_rate": 27.0, "speed": 2.22, "text": "Hi there! How can I assist you t"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 258, "tree_size": 1024, "t0": 5.898, "t1": 2.348, "tft": 11.5933, "input_0": 2991, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 16.6, "mem_use": 51.15, "gen_rate": 6.6, "speed": 0.8, "text": "\"With eyes as blue as the ocean "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.0, "tree_w": 157, "tree_size": 1024, "t0": 8.48, "t1": 2.3325, "tft": 11.3083, "input_0": 3674, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 25.0, "mem_use": 50.55, "gen_rate": 9.5, "speed": 0.88, "text": "It is difficult to say with cert"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.2, "tree_w": 133, "tree_size": 1024, "t0": 8.95, "t1": 2.3325, "tft": 14.2224, "input_0": 3859, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 26.5, "mem_use": 50.52, "gen_rate": 9.0, "speed": 0.8, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 17.5, "tree_w": 146, "tree_size": 1024, "t0": 9.41, "t1": 2.405, "tft": 12.6562, "input_0": 4599, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 27.5, "mem_use": 51.84, "gen_rate": 10.5, "speed": 0.89, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 18.0, "tree_w": 115, "tree_size": 1024, "t0": 10.43, "t1": 2.3567, "tft": 13.6242, "input_0": 4690, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 28.7, "mem_use": 51.76, "gen_rate": 14.3, "speed": 1.12, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 27, "tree_h": 19.0, "tree_w": 131, "tree_size": 1024, "t0": 9.765, "t1": 2.395, "tft": 17.2984, "input_0": 4513, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 28.0, "mem_use": 53.23, "gen_rate": 13.5, "speed": 1.11, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 132, "tree_size": 1024, "t0": 10.46, "t1": 2.32, "tft": 11.5133, "input_0": 4551, "input_1": 1025, "min_CLP": -7.25, "draft_iters": 30.3, "mem_use": 50.06, "gen_rate": 10.7, "speed": 0.83, "text": "The current President of Germany"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.6, "tree_w": 194, "tree_size": 1024, "t0": 7.14, "t1": 2.344, "tft": 12.9032, "input_0": 3067, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 23.4, "mem_use": 50.99, "gen_rate": 7.4, "speed": 0.78, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.8, "tree_w": 252, "tree_size": 1024, "t0": 7.23, "t1": 2.362, "tft": 13.9853, "input_0": 3169, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 21.4, "mem_use": 52.88, "gen_rate": 8.4, "speed": 0.88, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.0, "tree_w": 152, "tree_size": 1024, "t0": 9.8067, "t1": 2.3333, "tft": 10.7388, "input_0": 4267, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 29.3, "mem_use": 50.58, "gen_rate": 11.3, "speed": 0.93, "text": "- Introduction to the topic: Def"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.0, "tree_w": 139, "tree_size": 1024, "t0": 10.375, "t1": 2.345, "tft": 13.6943, "input_0": 4390, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 31.5, "mem_use": 51.44, "gen_rate": 16.0, "speed": 1.26, "text": "I apologize for the confusion. A"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 1024, "max_branch_width": 32, "gen_rate": 11.46, "gen_rate_micro": 10.31, "gen_speed": 0.982, "gen_speed_micro": 0.947, "t0": 9.0187, "t1": 2.346, "input_0": 4016.4, "input_1": 1025.0, "tree_size": 1024.0, "tree_w": 165.9, "tree_h": 17.9, "prompt_len": 310.2, "min_CLP": -7.9, "mem_use": 54.75, "exp_time": 3018.63}
