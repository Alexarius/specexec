{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-3B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024, 2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 540, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-27 17:37:45", "date": "250327", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.7, "tree_w": 1, "tree_size": 16, "t0": 1.9733, "t1": 0.29, "tft": 4.5779, "input_0": 60, "input_1": 17, "min_CLP": -1.67, "draft_iters": 14.7, "mem_use": 44.09, "gen_rate": 12.3, "speed": 5.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.97, "t1": 0.2929, "tft": 3.2249, "input_0": 37, "input_1": 17, "min_CLP": -3.25, "draft_iters": 7.3, "mem_use": 45.63, "gen_rate": 4.7, "speed": 3.74, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.8375, "t1": 0.2913, "tft": 3.4284, "input_0": 34, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.2, "mem_use": 46.53, "gen_rate": 4.2, "speed": 3.77, "text": "\"I can't give you detailed speci"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 3, "tree_size": 16, "t0": 1.51, "t1": 0.2825, "tft": 2.2494, "input_0": 52, "input_1": 17, "min_CLP": -2.47, "draft_iters": 11.2, "mem_use": 44.27, "gen_rate": 10.0, "speed": 5.57, "text": "\"Certainly! Here's a Python scri"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.816, "t1": 0.279, "tft": 1.8922, "input_0": 35, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.0, "mem_use": 44.11, "gen_rate": 3.3, "speed": 3.01, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.8, "tree_w": 2, "tree_size": 16, "t0": 1.3317, "t1": 0.2983, "tft": 4.1316, "input_0": 48, "input_1": 17, "min_CLP": -2.49, "draft_iters": 9.8, "mem_use": 46.67, "gen_rate": 6.0, "speed": 3.69, "text": "Certainly! Here\\'s a bullet list"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 3, "tree_size": 16, "t0": 1.1483, "t1": 0.2933, "tft": 4.1827, "input_0": 45, "input_1": 17, "min_CLP": -3.27, "draft_iters": 8.5, "mem_use": 47.26, "gen_rate": 5.3, "speed": 3.7, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.5, "tree_w": 3, "tree_size": 16, "t0": 1.2667, "t1": 0.3083, "tft": 5.3214, "input_0": 54, "input_1": 17, "min_CLP": -2.76, "draft_iters": 9.5, "mem_use": 49.43, "gen_rate": 5.8, "speed": 3.7, "text": "Sure, I can offer some advice on"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.344, "t1": 0.296, "tft": 3.7965, "input_0": 46, "input_1": 17, "min_CLP": -2.97, "draft_iters": 10.0, "mem_use": 46.86, "gen_rate": 8.0, "speed": 4.88, "text": "Sure, here is a list of the lega"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 1.3375, "t1": 0.295, "tft": 3.42, "input_0": 52, "input_1": 17, "min_CLP": -2.73, "draft_iters": 9.8, "mem_use": 46.23, "gen_rate": 9.0, "speed": 5.53, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 8.3, "tree_w": 4, "tree_size": 16, "t0": 1.21, "t1": 0.2883, "tft": 2.5401, "input_0": 39, "input_1": 17, "min_CLP": -3.48, "draft_iters": 9.3, "mem_use": 44.77, "gen_rate": 7.2, "speed": 4.78, "text": "Here is your code:\\n``If thou ar"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 1.175, "t1": 0.2983, "tft": 3.681, "input_0": 46, "input_1": 17, "min_CLP": -2.88, "draft_iters": 9.0, "mem_use": 46.61, "gen_rate": 5.8, "speed": 3.96, "text": "Here\\'s a slightly shorter versi"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 7.2, "tree_w": 3, "tree_size": 16, "t0": 1.1425, "t1": 0.2925, "tft": 2.9518, "input_0": 48, "input_1": 17, "min_CLP": -2.66, "draft_iters": 8.2, "mem_use": 45.82, "gen_rate": 8.0, "speed": 5.57, "text": "Sure, here are some examples in "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.0, "tree_w": 4, "tree_size": 16, "t0": 1.6533, "t1": 0.2767, "tft": 1.9781, "input_0": 48, "input_1": 17, "min_CLP": -4.09, "draft_iters": 13.0, "mem_use": 44.09, "gen_rate": 12.3, "speed": 6.38, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.8557, "t1": 0.2929, "tft": 3.9497, "input_0": 40, "input_1": 17, "min_CLP": -3.06, "draft_iters": 6.3, "mem_use": 47.23, "gen_rate": 4.7, "speed": 4.11, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 1.355, "t1": 0.28, "tft": 1.9984, "input_0": 47, "input_1": 17, "min_CLP": -2.92, "draft_iters": 10.2, "mem_use": 44.43, "gen_rate": 8.5, "speed": 5.2, "text": "The minimum broadband upload spe"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 1.5, "t1": 0.28, "tft": 2.0742, "input_0": 46, "input_1": 17, "min_CLP": -3.0, "draft_iters": 11.3, "mem_use": 44.11, "gen_rate": 10.7, "speed": 5.99, "text": "\"Sure! Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 12.3, "tree_w": 3, "tree_size": 16, "t0": 1.6667, "t1": 0.2767, "tft": 1.5089, "input_0": 46, "input_1": 17, "min_CLP": -3.43, "draft_iters": 13.3, "mem_use": 44.08, "gen_rate": 12.7, "speed": 6.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.875, "t1": 0.28, "tft": 2.0961, "input_0": 33, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.6, "mem_use": 44.63, "gen_rate": 4.6, "speed": 4.0, "text": "D-theanine is the mirror image o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.18, "t1": 0.278, "tft": 2.2406, "input_0": 42, "input_1": 17, "min_CLP": -3.28, "draft_iters": 9.0, "mem_use": 44.1, "gen_rate": 7.8, "speed": 5.35, "text": "What is the Balfour Declaration?"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.9575, "t1": 0.2925, "tft": 2.3437, "input_0": 42, "input_1": 17, "min_CLP": -4.0, "draft_iters": 6.8, "mem_use": 44.94, "gen_rate": 4.5, "speed": 3.59, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.8867, "t1": 0.2733, "tft": 1.278, "input_0": 39, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.7, "mem_use": 44.09, "gen_rate": 2.7, "speed": 2.29, "text": "Hello, how can I assist you toda"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 1.302, "t1": 0.292, "tft": 3.678, "input_0": 50, "input_1": 17, "min_CLP": -2.83, "draft_iters": 9.6, "mem_use": 46.45, "gen_rate": 6.6, "speed": 4.14, "text": "For an asymmetric bimodal distri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 5, "tree_size": 16, "t0": 1.1267, "t1": 0.2817, "tft": 1.7361, "input_0": 44, "input_1": 17, "min_CLP": -3.13, "draft_iters": 8.3, "mem_use": 44.16, "gen_rate": 5.3, "speed": 3.79, "text": "1. Understanding the Question: T"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 19, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.89, "t1": 0.286, "tft": 2.7681, "input_0": 39, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.6, "mem_use": 45.13, "gen_rate": 3.8, "speed": 3.23, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.18, "t1": 0.285, "tft": 1.7454, "input_0": 61, "input_1": 17, "min_CLP": -2.93, "draft_iters": 17.0, "mem_use": 44.13, "gen_rate": 17.0, "speed": 6.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8218, "t1": 0.2845, "tft": 2.8671, "input_0": 36, "input_1": 17, "min_CLP": -3.52, "draft_iters": 6.1, "mem_use": 44.8, "gen_rate": 3.1, "speed": 2.79, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.19, "t1": 0.285, "tft": 2.5643, "input_0": 48, "input_1": 17, "min_CLP": -3.16, "draft_iters": 9.0, "mem_use": 44.66, "gen_rate": 5.8, "speed": 3.9, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.9775, "t1": 0.2975, "tft": 3.3527, "input_0": 39, "input_1": 17, "min_CLP": -3.37, "draft_iters": 7.4, "mem_use": 46.59, "gen_rate": 4.5, "speed": 3.53, "text": "\"Ah, the magic of Disney! The po"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.8433, "t1": 0.2767, "tft": 1.2727, "input_0": 53, "input_1": 17, "min_CLP": -3.51, "draft_iters": 14.3, "mem_use": 44.14, "gen_rate": 14.3, "speed": 6.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 48, "tree_h": 10.1, "tree_w": 2, "tree_size": 16, "t0": 1.4313, "t1": 0.285, "tft": 2.9832, "input_0": 47, "input_1": 17, "min_CLP": -2.37, "draft_iters": 11.1, "mem_use": 44.84, "gen_rate": 6.0, "speed": 3.5, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 1.0929, "t1": 0.2943, "tft": 2.478, "input_0": 42, "input_1": 17, "min_CLP": -3.86, "draft_iters": 8.1, "mem_use": 45.25, "gen_rate": 4.7, "speed": 3.4, "text": "[ANSWER]: Alright, I will post a"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.8933, "t1": 0.2822, "tft": 1.8443, "input_0": 36, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.7, "mem_use": 44.6, "gen_rate": 3.8, "speed": 3.21, "text": "Freyja, the goddess of love, fer"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.83, "t1": 0.2937, "tft": 3.0368, "input_0": 37, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.0, "mem_use": 46.25, "gen_rate": 4.2, "speed": 3.79, "text": "Vegetarian cheese is a good and "}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 1.2175, "t1": 0.2925, "tft": 3.1732, "input_0": 50, "input_1": 17, "min_CLP": -3.27, "draft_iters": 9.0, "mem_use": 46.29, "gen_rate": 8.8, "speed": 5.79, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 1.34, "t1": 0.3025, "tft": 6.0475, "input_0": 50, "input_1": 17, "min_CLP": -3.32, "draft_iters": 9.8, "mem_use": 49.02, "gen_rate": 8.5, "speed": 5.18, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 1.0043, "t1": 0.2786, "tft": 2.094, "input_0": 41, "input_1": 17, "min_CLP": -3.28, "draft_iters": 7.4, "mem_use": 44.12, "gen_rate": 5.0, "speed": 3.9, "text": "\"I'm sorry, but I can't answer t"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.64, "t1": 0.2767, "tft": 3.2593, "input_0": 48, "input_1": 17, "min_CLP": -2.96, "draft_iters": 13.0, "mem_use": 44.65, "gen_rate": 11.3, "speed": 5.92, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 1.1612, "t1": 0.2987, "tft": 3.8451, "input_0": 42, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.9, "mem_use": 47.03, "gen_rate": 4.4, "speed": 3.0, "text": "Sure, I can try to act like I ha"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.4, "tree_w": 2, "tree_size": 16, "t0": 1.412, "t1": 0.282, "tft": 2.8345, "input_0": 54, "input_1": 17, "min_CLP": -3.0, "draft_iters": 10.4, "mem_use": 45.06, "gen_rate": 7.2, "speed": 4.25, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.6527, "t1": 0.2791, "tft": 1.4623, "input_0": 28, "input_1": 17, "min_CLP": -3.9, "draft_iters": 4.8, "mem_use": 44.35, "gen_rate": 3.0, "speed": 3.22, "text": "\"I am a god of war, not a servan"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.9567, "t1": 0.295, "tft": 4.4857, "input_0": 44, "input_1": 17, "min_CLP": -3.41, "draft_iters": 7.2, "mem_use": 46.85, "gen_rate": 5.7, "speed": 4.54, "text": "\"Your monologue presents a compe"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.7444, "t1": 0.2967, "tft": 3.9549, "input_0": 30, "input_1": 17, "min_CLP": -3.83, "draft_iters": 5.6, "mem_use": 47.28, "gen_rate": 3.7, "speed": 3.52, "text": "[INST] Thank you for the informa"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 1.172, "t1": 0.292, "tft": 2.8808, "input_0": 52, "input_1": 17, "min_CLP": -2.65, "draft_iters": 8.6, "mem_use": 45.62, "gen_rate": 6.4, "speed": 4.38, "text": "Determining the \"best\" SAST tool"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.185, "t1": 0.285, "tft": 2.9002, "input_0": 45, "input_1": 17, "min_CLP": -3.03, "draft_iters": 9.0, "mem_use": 44.88, "gen_rate": 6.0, "speed": 4.09, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 1.43, "t1": 0.28, "tft": 2.6557, "input_0": 41, "input_1": 17, "min_CLP": -3.75, "draft_iters": 11.2, "mem_use": 44.61, "gen_rate": 8.8, "speed": 5.12, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 1.17, "t1": 0.28, "tft": 2.4674, "input_0": 47, "input_1": 17, "min_CLP": -3.0, "draft_iters": 8.8, "mem_use": 44.12, "gen_rate": 5.7, "speed": 3.92, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 1.45, "t1": 0.31, "tft": 6.0107, "input_0": 48, "input_1": 17, "min_CLP": -3.12, "draft_iters": 11.2, "mem_use": 49.58, "gen_rate": 8.8, "speed": 5.0, "text": "\"Certainly! Here's a revised ver"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.7325, "t1": 0.295, "tft": 2.5769, "input_0": 32, "input_1": 17, "min_CLP": -3.81, "draft_iters": 5.2, "mem_use": 45.87, "gen_rate": 4.1, "speed": 4.02, "text": "Thank you for your time, Agent. "}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.715, "t1": 0.29, "tft": 1.8579, "input_0": 28, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.2, "mem_use": 44.88, "gen_rate": 3.2, "speed": 3.18, "text": "\"Alright, I understand and appre"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 9.7, "tree_w": 4, "tree_size": 16, "t0": 1.4633, "t1": 0.29, "tft": 1.4751, "input_0": 48, "input_1": 17, "min_CLP": -2.62, "draft_iters": 10.7, "mem_use": 44.4, "gen_rate": 6.3, "speed": 3.62, "text": "\u70b9\u51fb\u7387 (CTR) \u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u9886\u57df\u7684\u91cd\u8981\u8bdd\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.2, "tree_w": 3, "tree_size": 16, "t0": 1.495, "t1": 0.295, "tft": 3.7966, "input_0": 51, "input_1": 17, "min_CLP": -2.82, "draft_iters": 11.2, "mem_use": 46.29, "gen_rate": 6.0, "speed": 3.35, "text": "F-centers are crystallographic d"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 1.2, "t1": 0.29, "tft": 2.7954, "input_0": 41, "input_1": 17, "min_CLP": -2.6, "draft_iters": 9.0, "mem_use": 45.51, "gen_rate": 7.2, "speed": 4.83, "text": "Sure, here are some more importa"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.0067, "t1": 0.2917, "tft": 3.1494, "input_0": 43, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.5, "mem_use": 45.84, "gen_rate": 5.3, "speed": 4.12, "text": "Yes, it is possible for technolo"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.737, "t1": 0.281, "tft": 1.7533, "input_0": 31, "input_1": 17, "min_CLP": -3.24, "draft_iters": 5.4, "mem_use": 44.29, "gen_rate": 3.4, "speed": 3.34, "text": "People all over the world wear s"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 1.0733, "t1": 0.3, "tft": 3.9707, "input_0": 39, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.8, "mem_use": 46.7, "gen_rate": 5.3, "speed": 3.89, "text": "Sure! Here is a pitch deck for F"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.9625, "t1": 0.3025, "tft": 4.7013, "input_0": 39, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.9, "mem_use": 47.95, "gen_rate": 4.2, "speed": 3.36, "text": "\"You're right, my apologies. I s"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 7.0, "tree_w": 3, "tree_size": 16, "t0": 1.1138, "t1": 0.3025, "tft": 4.7181, "input_0": 50, "input_1": 17, "min_CLP": -2.83, "draft_iters": 8.0, "mem_use": 48.12, "gen_rate": 4.9, "speed": 3.45, "text": "Yes, for a complete beginner wit"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.6, "tree_w": 2, "tree_size": 16, "t0": 1.416, "t1": 0.294, "tft": 3.3868, "input_0": 46, "input_1": 17, "min_CLP": -2.69, "draft_iters": 10.6, "mem_use": 45.77, "gen_rate": 7.2, "speed": 4.21, "text": "\"As an AI language model, I do n"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 4.8, "tree_w": 5, "tree_size": 16, "t0": 0.7844, "t1": 0.2811, "tft": 1.6635, "input_0": 34, "input_1": 17, "min_CLP": -3.57, "draft_iters": 5.8, "mem_use": 44.12, "gen_rate": 4.3, "speed": 4.07, "text": "Best way to form a new habit is "}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.7, "tree_w": 2, "tree_size": 16, "t0": 1.6733, "t1": 0.29, "tft": 3.0814, "input_0": 59, "input_1": 17, "min_CLP": -3.03, "draft_iters": 12.7, "mem_use": 46.53, "gen_rate": 11.7, "speed": 5.95, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.3, "tree_w": 4, "tree_size": 16, "t0": 0.8771, "t1": 0.2957, "tft": 4.2806, "input_0": 39, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.3, "mem_use": 47.37, "gen_rate": 4.6, "speed": 3.89, "text": "[The Spartan general leads his a"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8429, "t1": 0.2843, "tft": 2.0682, "input_0": 36, "input_1": 17, "min_CLP": -3.63, "draft_iters": 6.1, "mem_use": 45.07, "gen_rate": 4.7, "speed": 4.19, "text": "\"Thank you for the feedback! It'"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.8544, "t1": 0.2856, "tft": 2.6418, "input_0": 37, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.3, "mem_use": 44.78, "gen_rate": 4.3, "speed": 3.8, "text": "The proof-of-stake concept is a "}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.7378, "t1": 0.2867, "tft": 2.066, "input_0": 34, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.3, "mem_use": 44.91, "gen_rate": 3.6, "speed": 3.47, "text": "Adolph Hitler was not the only p"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 1.59, "t1": 0.2933, "tft": 3.7459, "input_0": 54, "input_1": 17, "min_CLP": -2.95, "draft_iters": 12.0, "mem_use": 46.98, "gen_rate": 11.0, "speed": 5.85, "text": "\"Sure, I'd be happy to explain h"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.8971, "t1": 0.2914, "tft": 4.2668, "input_0": 37, "input_1": 17, "min_CLP": -3.28, "draft_iters": 6.7, "mem_use": 47.5, "gen_rate": 5.0, "speed": 4.21, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.5, "tree_w": 3, "tree_size": 16, "t0": 1.185, "t1": 0.295, "tft": 4.0069, "input_0": 48, "input_1": 17, "min_CLP": -3.01, "draft_iters": 8.5, "mem_use": 46.7, "gen_rate": 6.7, "speed": 4.52, "text": "\"Implementing two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.8017, "t1": 0.2817, "tft": 1.6734, "input_0": 39, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.7, "mem_use": 44.53, "gen_rate": 5.3, "speed": 4.94, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 1.085, "t1": 0.2812, "tft": 1.6555, "input_0": 42, "input_1": 17, "min_CLP": -3.31, "draft_iters": 8.1, "mem_use": 44.12, "gen_rate": 5.2, "speed": 3.84, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.7133, "t1": 0.2967, "tft": 3.9613, "input_0": 58, "input_1": 17, "min_CLP": -2.32, "draft_iters": 13.0, "mem_use": 46.94, "gen_rate": 11.7, "speed": 5.82, "text": "Sure, here is the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.98, "t1": 0.2787, "tft": 1.3812, "input_0": 39, "input_1": 17, "min_CLP": -3.57, "draft_iters": 7.2, "mem_use": 44.07, "gen_rate": 4.5, "speed": 3.58, "text": "The city of Berlin was founded b"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 2.0, "t1": 0.295, "tft": 3.2619, "input_0": 48, "input_1": 17, "min_CLP": -2.94, "draft_iters": 16.0, "mem_use": 46.4, "gen_rate": 16.0, "speed": 6.98, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.19, "t1": 0.2917, "tft": 3.4978, "input_0": 44, "input_1": 17, "min_CLP": -2.67, "draft_iters": 8.8, "mem_use": 46.26, "gen_rate": 5.5, "speed": 3.71, "text": "Sure. The criticism of \"Fooled b"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 1.0633, "t1": 0.27, "tft": 1.6095, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 8.3, "mem_use": 44.08, "gen_rate": 2.7, "speed": 1.99, "text": "Where does pornography come from"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 27, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.7867, "t1": 0.2844, "tft": 1.8211, "input_0": 33, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.8, "mem_use": 44.4, "gen_rate": 3.0, "speed": 2.8, "text": "You can check the timezone by go"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.9357, "t1": 0.2886, "tft": 1.5844, "input_0": 37, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.0, "mem_use": 44.48, "gen_rate": 5.1, "speed": 4.21, "text": "\"It's a common belief that if fo"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.4, "tree_w": 4, "tree_size": 16, "t0": 1.225, "t1": 0.2825, "tft": 1.766, "input_0": 44, "input_1": 17, "min_CLP": -2.96, "draft_iters": 9.4, "mem_use": 44.2, "gen_rate": 4.6, "speed": 3.07, "text": "def solve(number):\\n    if numbe"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 7.0, "tree_w": 3, "tree_size": 16, "t0": 1.085, "t1": 0.2825, "tft": 3.102, "input_0": 47, "input_1": 17, "min_CLP": -2.71, "draft_iters": 8.0, "mem_use": 44.96, "gen_rate": 8.0, "speed": 5.85, "text": "Sure! The Sieve of Eratosthenes "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.8757, "t1": 0.2871, "tft": 1.8346, "input_0": 38, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.6, "mem_use": 44.52, "gen_rate": 4.1, "speed": 3.56, "text": "\"You're welcome! It's always a g"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.02, "t1": 0.2844, "tft": 1.5228, "input_0": 39, "input_1": 17, "min_CLP": -3.04, "draft_iters": 7.7, "mem_use": 44.23, "gen_rate": 3.6, "speed": 2.74, "text": "Here\\'s a draft announcement twe"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.91, "t1": 0.2863, "tft": 2.6279, "input_0": 36, "input_1": 17, "min_CLP": -3.14, "draft_iters": 6.9, "mem_use": 44.85, "gen_rate": 4.0, "speed": 3.34, "text": "Sexual selection can also affect"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9417, "t1": 0.2917, "tft": 3.0745, "input_0": 43, "input_1": 17, "min_CLP": -2.86, "draft_iters": 7.0, "mem_use": 45.89, "gen_rate": 6.2, "speed": 4.99, "text": "Sure, AI assistants can also be "}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.18, "t1": 0.295, "tft": 3.7084, "input_0": 63, "input_1": 17, "min_CLP": -2.24, "draft_iters": 17.0, "mem_use": 46.92, "gen_rate": 17.0, "speed": 6.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.9557, "t1": 0.2943, "tft": 3.0611, "input_0": 41, "input_1": 17, "min_CLP": -3.0, "draft_iters": 6.9, "mem_use": 45.41, "gen_rate": 4.7, "speed": 3.77, "text": "The scp command is a Unix-based "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.215, "t1": 0.3, "tft": 4.0932, "input_0": 69, "input_1": 17, "min_CLP": -3.03, "draft_iters": 17.0, "mem_use": 46.05, "gen_rate": 17.0, "speed": 6.76, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9683, "t1": 0.28, "tft": 1.2791, "input_0": 42, "input_1": 17, "min_CLP": -3.07, "draft_iters": 7.0, "mem_use": 44.14, "gen_rate": 5.5, "speed": 4.39, "text": "It is not illegal to keep a foun"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.065, "t1": 0.2812, "tft": 2.0892, "input_0": 44, "input_1": 17, "min_CLP": -2.96, "draft_iters": 7.8, "mem_use": 44.43, "gen_rate": 4.6, "speed": 3.43, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 4, "tree_size": 16, "t0": 1.4733, "t1": 0.28, "tft": 2.0758, "input_0": 47, "input_1": 17, "min_CLP": -3.53, "draft_iters": 11.7, "mem_use": 44.73, "gen_rate": 11.7, "speed": 6.66, "text": "\"[INST] 5 second rule is a dange"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 13, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.724, "t1": 0.28, "tft": 1.3254, "input_0": 32, "input_1": 17, "min_CLP": -3.63, "draft_iters": 5.4, "mem_use": 44.41, "gen_rate": 2.6, "speed": 2.6, "text": "\"I'm glad you liked it! Feel fre"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.7, "tree_w": 1, "tree_size": 16, "t0": 2.0133, "t1": 0.28, "tft": 2.0877, "input_0": 57, "input_1": 17, "min_CLP": -1.9, "draft_iters": 15.7, "mem_use": 44.18, "gen_rate": 12.3, "speed": 5.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.8583, "t1": 0.285, "tft": 1.8495, "input_0": 41, "input_1": 17, "min_CLP": -3.46, "draft_iters": 6.2, "mem_use": 44.15, "gen_rate": 5.3, "speed": 4.66, "text": "Walking around the world is a ch"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.8, "tree_w": 2, "tree_size": 16, "t0": 1.43, "t1": 0.2967, "tft": 3.833, "input_0": 49, "input_1": 17, "min_CLP": -2.46, "draft_iters": 10.8, "mem_use": 45.89, "gen_rate": 5.8, "speed": 3.38, "text": "Sure, I can try to explain it in"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.195, "t1": 0.285, "tft": 1.8687, "input_0": 62, "input_1": 17, "min_CLP": -2.58, "draft_iters": 17.0, "mem_use": 44.15, "gen_rate": 17.0, "speed": 6.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 3, "tree_size": 16, "t0": 1.4675, "t1": 0.29, "tft": 2.3664, "input_0": 56, "input_1": 17, "min_CLP": -2.68, "draft_iters": 11.2, "mem_use": 44.46, "gen_rate": 8.0, "speed": 4.56, "text": "In Godot Engine 3.x, you can cre"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 3, "tree_size": 16, "t0": 1.91, "t1": 0.2867, "tft": 1.8332, "input_0": 58, "input_1": 17, "min_CLP": -1.95, "draft_iters": 14.3, "mem_use": 44.12, "gen_rate": 12.3, "speed": 5.63, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9771, "t1": 0.2871, "tft": 1.4959, "input_0": 41, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.0, "mem_use": 44.43, "gen_rate": 5.1, "speed": 4.07, "text": "Ah, young one, the path to becom"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.808, "t1": 0.282, "tft": 1.91, "input_0": 35, "input_1": 17, "min_CLP": -3.27, "draft_iters": 5.9, "mem_use": 44.29, "gen_rate": 3.5, "speed": 3.2, "text": "\"A gas-operated rifle is a type "}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.045, "t1": 0.2833, "tft": 2.5946, "input_0": 46, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.7, "mem_use": 44.53, "gen_rate": 5.7, "speed": 4.27, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9514, "t1": 0.2929, "tft": 4.1048, "input_0": 41, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.0, "mem_use": 47.39, "gen_rate": 4.7, "speed": 3.79, "text": "I see. In that case, I would rec"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 1.1375, "t1": 0.285, "tft": 1.941, "input_0": 41, "input_1": 17, "min_CLP": -3.33, "draft_iters": 8.5, "mem_use": 44.6, "gen_rate": 8.0, "speed": 5.63, "text": "Yes, if someone finds lost prope"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 8.5, "tree_w": 4, "tree_size": 16, "t0": 1.2567, "t1": 0.2967, "tft": 4.0096, "input_0": 46, "input_1": 17, "min_CLP": -3.45, "draft_iters": 9.5, "mem_use": 47.49, "gen_rate": 7.2, "speed": 4.61, "text": "Xin ch\u00e0o, b\u1ea1n c\u00f3 kh\u1ecfe kh\u00f4ng?\\n\\n"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.6845, "t1": 0.2836, "tft": 1.932, "input_0": 31, "input_1": 17, "min_CLP": -3.7, "draft_iters": 5.0, "mem_use": 44.97, "gen_rate": 3.3, "speed": 3.37, "text": "\"I think it's important to note "}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 12.2, "tree_w": 2, "tree_size": 16, "t0": 1.7075, "t1": 0.2825, "tft": 1.7447, "input_0": 56, "input_1": 17, "min_CLP": -2.58, "draft_iters": 13.2, "mem_use": 44.48, "gen_rate": 12.0, "speed": 6.03, "text": "Sure, here\\'s an example:\\n\\n```"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 1.0233, "t1": 0.2917, "tft": 2.6701, "input_0": 43, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.7, "mem_use": 45.92, "gen_rate": 5.7, "speed": 4.32, "text": "In order to compile a list of th"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.7445, "t1": 0.2836, "tft": 1.9738, "input_0": 33, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.5, "mem_use": 44.45, "gen_rate": 2.9, "speed": 2.83, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 1.304, "t1": 0.296, "tft": 3.949, "input_0": 52, "input_1": 17, "min_CLP": -2.9, "draft_iters": 9.6, "mem_use": 46.45, "gen_rate": 6.6, "speed": 4.13, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.03, "t1": 0.29, "tft": 2.3221, "input_0": 39, "input_1": 17, "min_CLP": -3.54, "draft_iters": 7.8, "mem_use": 45.07, "gen_rate": 6.6, "speed": 5.0, "text": "As an AI language model, I am ca"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 1.146, "t1": 0.284, "tft": 1.7396, "input_0": 40, "input_1": 17, "min_CLP": -2.84, "draft_iters": 8.6, "mem_use": 44.61, "gen_rate": 6.6, "speed": 4.61, "text": "Certainly! In this essay, I will"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.302, "t1": 0.286, "tft": 2.1298, "input_0": 48, "input_1": 17, "min_CLP": -2.88, "draft_iters": 10.0, "mem_use": 44.75, "gen_rate": 7.2, "speed": 4.53, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 6, "tree_size": 16, "t0": 0.98, "t1": 0.2883, "tft": 3.0761, "input_0": 34, "input_1": 17, "min_CLP": -3.87, "draft_iters": 7.5, "mem_use": 46.02, "gen_rate": 5.3, "speed": 4.21, "text": "\"Sure, here's a poem in Quenya t"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.9833, "t1": 0.2767, "tft": 2.1169, "input_0": 37, "input_1": 17, "min_CLP": -3.56, "draft_iters": 7.5, "mem_use": 44.12, "gen_rate": 5.7, "speed": 4.5, "text": "I am not a human, but I can help"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.9925, "t1": 0.275, "tft": 1.8303, "input_0": 41, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.2, "mem_use": 44.16, "gen_rate": 4.1, "speed": 3.25, "text": "The error with the code is that "}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.8, "tree_w": 7, "tree_size": 16, "t0": 0.7562, "t1": 0.2888, "tft": 2.5015, "input_0": 31, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.8, "mem_use": 45.55, "gen_rate": 4.4, "speed": 4.2, "text": "The message left by the you in t"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.2975, "t1": 0.2825, "tft": 1.8783, "input_0": 48, "input_1": 17, "min_CLP": -3.22, "draft_iters": 10.0, "mem_use": 44.77, "gen_rate": 9.2, "speed": 5.86, "text": "Certainly! The `@` symbol in Pyt"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 1.1217, "t1": 0.28, "tft": 2.355, "input_0": 43, "input_1": 17, "min_CLP": -3.07, "draft_iters": 8.7, "mem_use": 44.9, "gen_rate": 6.0, "speed": 4.28, "text": "\"One way to achieve this is by u"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.248, "t1": 0.288, "tft": 3.7194, "input_0": 46, "input_1": 17, "min_CLP": -2.84, "draft_iters": 9.2, "mem_use": 46.68, "gen_rate": 7.2, "speed": 4.7, "text": "\"It's important to be cautious w"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 1.0986, "t1": 0.2814, "tft": 2.4551, "input_0": 43, "input_1": 17, "min_CLP": -3.01, "draft_iters": 8.3, "mem_use": 44.68, "gen_rate": 5.4, "speed": 3.94, "text": "Absolutely! Here\\'s the updated "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.6725, "t1": 0.295, "tft": 4.3065, "input_0": 52, "input_1": 17, "min_CLP": -2.47, "draft_iters": 13.0, "mem_use": 46.04, "gen_rate": 8.8, "speed": 4.45, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 1.02, "t1": 0.2771, "tft": 1.5026, "input_0": 43, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.6, "mem_use": 44.1, "gen_rate": 5.3, "speed": 4.07, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.7083, "t1": 0.28, "tft": 1.6497, "input_0": 30, "input_1": 17, "min_CLP": -3.9, "draft_iters": 5.2, "mem_use": 44.33, "gen_rate": 2.8, "speed": 2.79, "text": "\"Attention mechanism, a subtle y"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 22, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.9071, "t1": 0.2843, "tft": 1.7112, "input_0": 43, "input_1": 17, "min_CLP": -3.16, "draft_iters": 6.6, "mem_use": 44.58, "gen_rate": 3.1, "speed": 2.64, "text": "Thank you, I try my best to prov"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.0033, "t1": 0.2967, "tft": 3.0101, "input_0": 42, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.5, "mem_use": 46.16, "gen_rate": 5.3, "speed": 4.1, "text": "Thou art the sun that shineth br"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.09, "t1": 0.288, "tft": 1.8854, "input_0": 45, "input_1": 17, "min_CLP": -3.24, "draft_iters": 8.0, "mem_use": 44.75, "gen_rate": 6.6, "speed": 4.79, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.6, "tree_w": 7, "tree_size": 16, "t0": 0.9043, "t1": 0.2843, "tft": 1.8554, "input_0": 34, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.6, "mem_use": 44.14, "gen_rate": 5.0, "speed": 4.2, "text": "Sure, here are some words in Que"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0833, "t1": 0.2867, "tft": 1.5173, "input_0": 43, "input_1": 17, "min_CLP": -2.8, "draft_iters": 8.0, "mem_use": 44.13, "gen_rate": 5.7, "speed": 4.14, "text": "\"Presidents' Day, officially kno"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.8744, "t1": 0.29, "tft": 1.8516, "input_0": 35, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.3, "mem_use": 44.43, "gen_rate": 3.8, "speed": 3.25, "text": "\"Yes, a kilogram of feathers is "}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.985, "t1": 0.2967, "tft": 3.1517, "input_0": 43, "input_1": 17, "min_CLP": -2.91, "draft_iters": 7.0, "mem_use": 45.23, "gen_rate": 6.0, "speed": 4.69, "text": "Yes, the US National Reconnaissa"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.7089, "t1": 0.2833, "tft": 1.6474, "input_0": 32, "input_1": 17, "min_CLP": -3.95, "draft_iters": 5.2, "mem_use": 44.5, "gen_rate": 3.6, "speed": 3.59, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 21, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.8667, "t1": 0.2833, "tft": 1.6916, "input_0": 36, "input_1": 17, "min_CLP": -3.46, "draft_iters": 6.5, "mem_use": 44.58, "gen_rate": 3.5, "speed": 3.05, "text": "\"Well, it's good to meet you, Op"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 5, "tree_size": 16, "t0": 1.0757, "t1": 0.2786, "tft": 1.3909, "input_0": 43, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.9, "mem_use": 44.13, "gen_rate": 4.9, "speed": 3.58, "text": "Yes, the ATF (Bureau of Alcohol,"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 36, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.7685, "t1": 0.29, "tft": 2.3585, "input_0": 33, "input_1": 17, "min_CLP": -3.7, "draft_iters": 5.4, "mem_use": 44.81, "gen_rate": 2.8, "speed": 2.61, "text": "\"oh my gosh, seriously? that\\'s "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.9356, "t1": 0.2856, "tft": 1.7532, "input_0": 39, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.8, "mem_use": 44.24, "gen_rate": 3.9, "speed": 3.19, "text": "There is a possibility that your"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.7, "tree_w": 5, "tree_size": 16, "t0": 0.785, "t1": 0.295, "tft": 2.6082, "input_0": 34, "input_1": 17, "min_CLP": -3.52, "draft_iters": 5.7, "mem_use": 45.47, "gen_rate": 3.3, "speed": 3.06, "text": "Certainly, there are few fiction"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.8562, "t1": 0.2875, "tft": 1.6983, "input_0": 36, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.4, "mem_use": 44.57, "gen_rate": 4.0, "speed": 3.5, "text": "\"No, I won't try to take over th"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 1.295, "t1": 0.2975, "tft": 3.1982, "input_0": 47, "input_1": 17, "min_CLP": -2.94, "draft_iters": 9.8, "mem_use": 45.78, "gen_rate": 8.5, "speed": 5.34, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.7813, "t1": 0.2875, "tft": 2.6762, "input_0": 32, "input_1": 17, "min_CLP": -3.76, "draft_iters": 5.8, "mem_use": 44.52, "gen_rate": 4.0, "speed": 3.75, "text": "\"Open Assistant: The Open Source"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.0743, "t1": 0.29, "tft": 1.6243, "input_0": 42, "input_1": 17, "min_CLP": -3.41, "draft_iters": 7.7, "mem_use": 44.42, "gen_rate": 5.0, "speed": 3.67, "text": "Sure, I can illustrate the solut"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 1.375, "t1": 0.3, "tft": 3.6828, "input_0": 41, "input_1": 17, "min_CLP": -2.89, "draft_iters": 10.2, "mem_use": 46.76, "gen_rate": 8.2, "speed": 4.93, "text": "The reason why the function does"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.9287, "t1": 0.2863, "tft": 2.3968, "input_0": 40, "input_1": 17, "min_CLP": -3.07, "draft_iters": 6.6, "mem_use": 44.11, "gen_rate": 4.5, "speed": 3.7, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.779, "t1": 0.282, "tft": 1.6989, "input_0": 33, "input_1": 17, "min_CLP": -3.74, "draft_iters": 5.8, "mem_use": 44.66, "gen_rate": 3.2, "speed": 3.02, "text": "The question is not whether vide"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 1.0043, "t1": 0.2857, "tft": 1.7886, "input_0": 44, "input_1": 17, "min_CLP": -3.49, "draft_iters": 7.6, "mem_use": 44.28, "gen_rate": 4.6, "speed": 3.55, "text": "This matters because the brownin"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 1.152, "t1": 0.284, "tft": 1.626, "input_0": 50, "input_1": 17, "min_CLP": -2.95, "draft_iters": 8.6, "mem_use": 44.13, "gen_rate": 7.0, "speed": 4.88, "text": "The choice of libraries for deve"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0757, "t1": 0.2929, "tft": 3.6255, "input_0": 43, "input_1": 17, "min_CLP": -3.01, "draft_iters": 8.0, "mem_use": 46.21, "gen_rate": 5.0, "speed": 3.66, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.5, "tree_w": 4, "tree_size": 16, "t0": 0.9175, "t1": 0.2838, "tft": 1.6174, "input_0": 41, "input_1": 17, "min_CLP": -3.23, "draft_iters": 6.5, "mem_use": 44.08, "gen_rate": 4.6, "speed": 3.85, "text": "Yes, a thumb war can be consider"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.821, "t1": 0.284, "tft": 2.094, "input_0": 36, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.9, "mem_use": 44.17, "gen_rate": 3.5, "speed": 3.17, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 1.1983, "t1": 0.2933, "tft": 4.1007, "input_0": 45, "input_1": 17, "min_CLP": -2.92, "draft_iters": 9.0, "mem_use": 47.45, "gen_rate": 6.0, "speed": 4.02, "text": "As of my last update in 2021, so"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.8389, "t1": 0.2967, "tft": 2.9519, "input_0": 33, "input_1": 17, "min_CLP": -3.15, "draft_iters": 6.2, "mem_use": 45.43, "gen_rate": 3.8, "speed": 3.33, "text": "I apologize for any confusion. A"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 3, "tree_size": 16, "t0": 1.13, "t1": 0.2817, "tft": 1.6057, "input_0": 42, "input_1": 17, "min_CLP": -3.0, "draft_iters": 8.5, "mem_use": 44.38, "gen_rate": 5.5, "speed": 3.89, "text": "Sure! Here are some resources yo"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.0117, "t1": 0.2867, "tft": 1.5929, "input_0": 41, "input_1": 17, "min_CLP": -3.28, "draft_iters": 7.5, "mem_use": 44.36, "gen_rate": 5.3, "speed": 4.11, "text": "\"In the United States of America"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.9586, "t1": 0.2814, "tft": 2.0287, "input_0": 42, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.1, "mem_use": 44.13, "gen_rate": 5.0, "speed": 4.03, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.8, "tree_w": 4, "tree_size": 16, "t0": 0.9567, "t1": 0.2883, "tft": 2.2002, "input_0": 42, "input_1": 17, "min_CLP": -3.21, "draft_iters": 6.8, "mem_use": 44.94, "gen_rate": 5.5, "speed": 4.42, "text": "Sure, I can do that. However, I "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 2.095, "t1": 0.285, "tft": 2.6931, "input_0": 70, "input_1": 17, "min_CLP": -2.82, "draft_iters": 16.0, "mem_use": 44.96, "gen_rate": 16.0, "speed": 6.71, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 1.384, "t1": 0.296, "tft": 4.1182, "input_0": 48, "input_1": 17, "min_CLP": -2.67, "draft_iters": 10.4, "mem_use": 47.47, "gen_rate": 7.8, "speed": 4.65, "text": "\"Sure! Here's a simplified versi"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.8367, "t1": 0.28, "tft": 1.99, "input_0": 55, "input_1": 17, "min_CLP": -3.63, "draft_iters": 14.0, "mem_use": 44.13, "gen_rate": 14.0, "speed": 6.61, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.7587, "t1": 0.2825, "tft": 1.8804, "input_0": 34, "input_1": 17, "min_CLP": -3.83, "draft_iters": 5.5, "mem_use": 44.69, "gen_rate": 4.2, "speed": 4.07, "text": "Berlin is known for its producti"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 9.6, "tree_w": 2, "tree_size": 16, "t0": 1.428, "t1": 0.276, "tft": 1.7511, "input_0": 52, "input_1": 17, "min_CLP": -3.03, "draft_iters": 10.6, "mem_use": 44.17, "gen_rate": 9.4, "speed": 5.51, "text": "Sure, here\\'s a Python script th"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.7, "tree_w": 3, "tree_size": 16, "t0": 1.4086, "t1": 0.2971, "tft": 3.7026, "input_0": 48, "input_1": 17, "min_CLP": -2.89, "draft_iters": 10.7, "mem_use": 46.67, "gen_rate": 4.6, "speed": 2.68, "text": "## Vegetarian\\n Microwave Pasta "}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0783, "t1": 0.2817, "tft": 1.2537, "input_0": 41, "input_1": 17, "min_CLP": -3.44, "draft_iters": 8.0, "mem_use": 44.08, "gen_rate": 5.5, "speed": 4.05, "text": "The question \"Who wears short sh"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.075, "t1": 0.2933, "tft": 3.298, "input_0": 41, "input_1": 17, "min_CLP": -3.21, "draft_iters": 8.0, "mem_use": 46.35, "gen_rate": 6.0, "speed": 4.39, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.8417, "t1": 0.28, "tft": 1.506, "input_0": 35, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.2, "mem_use": 44.09, "gen_rate": 5.3, "speed": 4.75, "text": "As an AI assistant, I am program"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.1, "tree_w": 8, "tree_size": 16, "t0": 0.6808, "t1": 0.2775, "tft": 1.3738, "input_0": 27, "input_1": 17, "min_CLP": -4.31, "draft_iters": 5.1, "mem_use": 44.07, "gen_rate": 2.8, "speed": 2.87, "text": "\u300c\u6211\u6b63\u5728\u770b\u4e00\u90e8\u7535\u5f71\u300d\\n[INST] \u8bf7\u63d0\u4f9b\u7ffb\u8bd1\u4efb\u52a1\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.058, "t1": 0.284, "tft": 1.6404, "input_0": 38, "input_1": 17, "min_CLP": -2.96, "draft_iters": 8.0, "mem_use": 44.23, "gen_rate": 6.4, "speed": 4.77, "text": "Sure, I can give you an example "}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 1.1329, "t1": 0.29, "tft": 3.5524, "input_0": 44, "input_1": 17, "min_CLP": -3.1, "draft_iters": 8.4, "mem_use": 45.29, "gen_rate": 5.0, "speed": 3.51, "text": "In general, the quality of life "}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.16, "t1": 0.29, "tft": 1.7471, "input_0": 62, "input_1": 17, "min_CLP": -2.77, "draft_iters": 17.0, "mem_use": 44.18, "gen_rate": 17.0, "speed": 6.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.97, "t1": 0.2856, "tft": 1.4803, "input_0": 39, "input_1": 17, "min_CLP": -3.19, "draft_iters": 7.1, "mem_use": 44.39, "gen_rate": 4.1, "speed": 3.28, "text": "In reStructuredText (rst), you c"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.18, "t1": 0.29, "tft": 2.404, "input_0": 46, "input_1": 17, "min_CLP": -2.94, "draft_iters": 8.8, "mem_use": 44.73, "gen_rate": 6.8, "speed": 4.63, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9538, "t1": 0.2863, "tft": 2.0494, "input_0": 40, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.1, "mem_use": 44.27, "gen_rate": 4.5, "speed": 3.63, "text": "\"I'm a goddess of love, fertilit"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 2, "tree_size": 16, "t0": 1.4775, "t1": 0.2975, "tft": 3.0963, "input_0": 50, "input_1": 17, "min_CLP": -2.63, "draft_iters": 11.0, "mem_use": 45.49, "gen_rate": 8.0, "speed": 4.51, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 1.37, "t1": 0.276, "tft": 1.8764, "input_0": 45, "input_1": 17, "min_CLP": -2.88, "draft_iters": 10.4, "mem_use": 44.17, "gen_rate": 7.0, "speed": 4.25, "text": "As a helpful assistant, I would "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.3475, "t1": 0.2875, "tft": 2.6149, "input_0": 49, "input_1": 17, "min_CLP": -3.07, "draft_iters": 10.0, "mem_use": 45.01, "gen_rate": 9.0, "speed": 5.5, "text": "Microwave ovens were not a commo"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 1.132, "t1": 0.281, "tft": 1.5325, "input_0": 40, "input_1": 17, "min_CLP": -3.32, "draft_iters": 8.5, "mem_use": 44.27, "gen_rate": 4.1, "speed": 2.9, "text": "[INST] <<SYS>>\\nYou are an intel"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.17, "t1": 0.275, "tft": 1.9924, "input_0": 65, "input_1": 17, "min_CLP": -2.57, "draft_iters": 17.0, "mem_use": 44.1, "gen_rate": 17.0, "speed": 6.93, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.4, "tree_w": 4, "tree_size": 16, "t0": 0.8786, "t1": 0.3043, "tft": 5.4089, "input_0": 39, "input_1": 17, "min_CLP": -3.09, "draft_iters": 6.4, "mem_use": 48.41, "gen_rate": 5.0, "speed": 4.23, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.88, "t1": 0.28, "tft": 1.4523, "input_0": 38, "input_1": 17, "min_CLP": -3.14, "draft_iters": 6.6, "mem_use": 44.41, "gen_rate": 5.0, "speed": 4.32, "text": "\"When you encounter a technical "}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 45, "tree_h": 10.8, "tree_w": 2, "tree_size": 16, "t0": 1.4825, "t1": 0.2825, "tft": 2.9454, "input_0": 45, "input_1": 17, "min_CLP": -2.5, "draft_iters": 11.8, "mem_use": 45.28, "gen_rate": 5.6, "speed": 3.19, "text": "If we assume that the walker can"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.717, "t1": 0.292, "tft": 3.4405, "input_0": 35, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.2, "mem_use": 46.55, "gen_rate": 3.4, "speed": 3.37, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.97, "t1": 0.2812, "tft": 1.4436, "input_0": 39, "input_1": 17, "min_CLP": -4.05, "draft_iters": 7.2, "mem_use": 44.39, "gen_rate": 4.4, "speed": 3.5, "text": "What do you call a broke college"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.9438, "t1": 0.2812, "tft": 1.6288, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 7.0, "mem_use": 44.43, "gen_rate": 4.0, "speed": 3.26, "text": "\"You're welcome!\\n[INST] Is ther"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.185, "t1": 0.2875, "tft": 2.7979, "input_0": 47, "input_1": 17, "min_CLP": -3.21, "draft_iters": 8.8, "mem_use": 44.9, "gen_rate": 8.0, "speed": 5.43, "text": "Certainly! There are several 3D "}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.155, "t1": 0.28, "tft": 2.0491, "input_0": 63, "input_1": 17, "min_CLP": -2.32, "draft_iters": 17.0, "mem_use": 44.41, "gen_rate": 17.0, "speed": 6.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.8256, "t1": 0.2867, "tft": 2.4698, "input_0": 35, "input_1": 17, "min_CLP": -3.78, "draft_iters": 6.2, "mem_use": 45.09, "gen_rate": 3.9, "speed": 3.5, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 1.0012, "t1": 0.28, "tft": 1.601, "input_0": 42, "input_1": 17, "min_CLP": -3.41, "draft_iters": 7.4, "mem_use": 44.43, "gen_rate": 4.5, "speed": 3.51, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 8.5, "tree_w": 7, "tree_size": 16, "t0": 1.18, "t1": 0.275, "tft": 1.6166, "input_0": 33, "input_1": 17, "min_CLP": -3.34, "draft_iters": 9.5, "mem_use": 44.15, "gen_rate": 3.0, "speed": 2.06, "text": "Pieces of a reinforcement learni"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 1.8733, "t1": 0.28, "tft": 1.5176, "input_0": 59, "input_1": 17, "min_CLP": -1.98, "draft_iters": 14.3, "mem_use": 44.12, "gen_rate": 12.3, "speed": 5.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 1.0167, "t1": 0.3, "tft": 5.5637, "input_0": 37, "input_1": 17, "min_CLP": -3.59, "draft_iters": 7.7, "mem_use": 48.39, "gen_rate": 5.3, "speed": 4.06, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 24, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.78, "t1": 0.2788, "tft": 1.64, "input_0": 32, "input_1": 17, "min_CLP": -3.36, "draft_iters": 5.9, "mem_use": 44.25, "gen_rate": 3.0, "speed": 2.84, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.8814, "t1": 0.2914, "tft": 3.0384, "input_0": 38, "input_1": 17, "min_CLP": -3.1, "draft_iters": 6.6, "mem_use": 45.78, "gen_rate": 4.7, "speed": 4.03, "text": "While carbon crystals, such as d"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0771, "t1": 0.2929, "tft": 2.7808, "input_0": 44, "input_1": 17, "min_CLP": -2.99, "draft_iters": 8.0, "mem_use": 45.55, "gen_rate": 5.3, "speed": 3.86, "text": "The \"chkdsk\" command with the \"/"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 1.5033, "t1": 0.2833, "tft": 1.8485, "input_0": 53, "input_1": 17, "min_CLP": -2.8, "draft_iters": 11.3, "mem_use": 44.38, "gen_rate": 11.3, "speed": 6.36, "text": "To approach and solve the proble"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.91, "t1": 0.2757, "tft": 1.7372, "input_0": 40, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.9, "mem_use": 44.2, "gen_rate": 5.4, "speed": 4.57, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 3, "tree_size": 16, "t0": 1.8567, "t1": 0.2733, "tft": 1.7485, "input_0": 52, "input_1": 17, "min_CLP": -3.09, "draft_iters": 14.7, "mem_use": 44.18, "gen_rate": 14.7, "speed": 6.88, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.198, "t1": 0.282, "tft": 2.2294, "input_0": 50, "input_1": 17, "min_CLP": -3.0, "draft_iters": 8.8, "mem_use": 45.18, "gen_rate": 7.0, "speed": 4.73, "text": "As an AI language model, I can d"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 1.0022, "t1": 0.2867, "tft": 1.4663, "input_0": 39, "input_1": 17, "min_CLP": -3.48, "draft_iters": 7.4, "mem_use": 44.5, "gen_rate": 3.6, "speed": 2.76, "text": "Q: Is there a purpose to our exi"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 13.3, "tree_w": 1, "tree_size": 16, "t0": 1.845, "t1": 0.2967, "tft": 3.146, "input_0": 55, "input_1": 17, "min_CLP": -3.1, "draft_iters": 14.3, "mem_use": 45.82, "gen_rate": 6.8, "speed": 3.2, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.828, "t1": 0.284, "tft": 2.018, "input_0": 34, "input_1": 17, "min_CLP": -4.14, "draft_iters": 6.1, "mem_use": 44.74, "gen_rate": 3.3, "speed": 2.97, "text": "One can draw the conclusion that"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.845, "t1": 0.289, "tft": 1.5775, "input_0": 33, "input_1": 17, "min_CLP": -3.77, "draft_iters": 6.4, "mem_use": 44.58, "gen_rate": 3.3, "speed": 2.91, "text": "The ATF is an organization that "}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.074, "t1": 0.286, "tft": 1.7827, "input_0": 46, "input_1": 17, "min_CLP": -2.91, "draft_iters": 7.8, "mem_use": 44.32, "gen_rate": 6.8, "speed": 5.01, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.8, "tree_w": 1, "tree_size": 16, "t0": 1.9083, "t1": 0.295, "tft": 4.4855, "input_0": 55, "input_1": 17, "min_CLP": -2.02, "draft_iters": 14.8, "mem_use": 47.12, "gen_rate": 6.2, "speed": 2.8, "text": "Chapter 4: The Aftermath (Revise"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.4, "tree_w": 3, "tree_size": 16, "t0": 1.1029, "t1": 0.2914, "tft": 4.3567, "input_0": 44, "input_1": 17, "min_CLP": -3.61, "draft_iters": 8.4, "mem_use": 47.04, "gen_rate": 5.7, "speed": 4.1, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.6691, "t1": 0.2755, "tft": 1.3875, "input_0": 32, "input_1": 17, "min_CLP": -3.89, "draft_iters": 4.9, "mem_use": 44.11, "gen_rate": 2.9, "speed": 3.08, "text": "In the style of Pablo Neruda, my"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.5, "tree_w": 2, "tree_size": 16, "t0": 1.5175, "t1": 0.29, "tft": 2.4637, "input_0": 50, "input_1": 17, "min_CLP": -3.08, "draft_iters": 11.5, "mem_use": 45.27, "gen_rate": 9.8, "speed": 5.39, "text": "Certainly, I can add information"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 1.1083, "t1": 0.29, "tft": 3.008, "input_0": 42, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.3, "mem_use": 45.72, "gen_rate": 6.2, "speed": 4.42, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.7933, "t1": 0.2733, "tft": 2.0783, "input_0": 54, "input_1": 17, "min_CLP": -3.07, "draft_iters": 14.0, "mem_use": 44.09, "gen_rate": 10.7, "speed": 5.15, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.7056, "t1": 0.2833, "tft": 1.4615, "input_0": 33, "input_1": 17, "min_CLP": -3.79, "draft_iters": 5.1, "mem_use": 44.39, "gen_rate": 3.7, "speed": 3.72, "text": "\"Freyja: I will not submit to an"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 2, "tree_size": 16, "t0": 1.548, "t1": 0.29, "tft": 3.5755, "input_0": 59, "input_1": 17, "min_CLP": -2.66, "draft_iters": 11.6, "mem_use": 45.97, "gen_rate": 7.4, "speed": 4.03, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 1.0029, "t1": 0.2829, "tft": 1.8129, "input_0": 38, "input_1": 17, "min_CLP": -3.5, "draft_iters": 7.4, "mem_use": 44.33, "gen_rate": 4.7, "speed": 3.68, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.5, "tree_w": 3, "tree_size": 16, "t0": 1.2475, "t1": 0.29, "tft": 2.7935, "input_0": 42, "input_1": 17, "min_CLP": -3.01, "draft_iters": 9.5, "mem_use": 45.67, "gen_rate": 8.2, "speed": 5.38, "text": "\"Certainly, here's a more organi"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.9743, "t1": 0.2771, "tft": 1.9592, "input_0": 41, "input_1": 17, "min_CLP": -3.52, "draft_iters": 7.3, "mem_use": 44.13, "gen_rate": 5.3, "speed": 4.23, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 2.115, "t1": 0.275, "tft": 2.338, "input_0": 57, "input_1": 17, "min_CLP": -3.07, "draft_iters": 16.0, "mem_use": 44.13, "gen_rate": 16.0, "speed": 6.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 1.16, "t1": 0.2843, "tft": 1.883, "input_0": 44, "input_1": 17, "min_CLP": -3.16, "draft_iters": 8.7, "mem_use": 44.78, "gen_rate": 4.6, "speed": 3.16, "text": "\"Sure, I'll do both.\\nHere's my "}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.778, "t1": 0.283, "tft": 2.3695, "input_0": 32, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.8, "mem_use": 45.01, "gen_rate": 3.4, "speed": 3.2, "text": "Thank you for the feedback! Here"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.8967, "t1": 0.275, "tft": 1.763, "input_0": 39, "input_1": 17, "min_CLP": -3.46, "draft_iters": 6.8, "mem_use": 44.11, "gen_rate": 5.8, "speed": 4.97, "text": "The AK-47 is a type of assault r"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 1.1567, "t1": 0.2783, "tft": 1.9583, "input_0": 44, "input_1": 17, "min_CLP": -3.07, "draft_iters": 8.7, "mem_use": 44.46, "gen_rate": 5.5, "speed": 3.83, "text": "\"To copy a directory of files fr"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.3425, "t1": 0.29, "tft": 2.8055, "input_0": 55, "input_1": 17, "min_CLP": -2.51, "draft_iters": 10.0, "mem_use": 45.85, "gen_rate": 8.8, "speed": 5.36, "text": "1. Stats modeling is the applica"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 1.11, "t1": 0.284, "tft": 1.6055, "input_0": 46, "input_1": 17, "min_CLP": -3.18, "draft_iters": 8.2, "mem_use": 44.44, "gen_rate": 6.8, "speed": 4.89, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.9671, "t1": 0.2886, "tft": 2.0712, "input_0": 39, "input_1": 17, "min_CLP": -2.98, "draft_iters": 7.1, "mem_use": 44.94, "gen_rate": 5.1, "speed": 4.09, "text": "While there is no harm in allowi"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 11, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.646, "t1": 0.286, "tft": 1.5747, "input_0": 28, "input_1": 17, "min_CLP": -3.97, "draft_iters": 4.6, "mem_use": 44.59, "gen_rate": 2.2, "speed": 2.37, "text": "I would recommend that you try t"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 10, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.645, "t1": 0.29, "tft": 3.0234, "input_0": 29, "input_1": 17, "min_CLP": -3.58, "draft_iters": 4.8, "mem_use": 44.69, "gen_rate": 2.5, "speed": 2.69, "text": "The instruction is to tell more "}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 20, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.83, "t1": 0.2775, "tft": 1.4846, "input_0": 33, "input_1": 17, "min_CLP": -3.94, "draft_iters": 6.2, "mem_use": 44.1, "gen_rate": 2.5, "speed": 2.25, "text": "\"I'm thinking of my next task or"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.9671, "t1": 0.2786, "tft": 1.618, "input_0": 42, "input_1": 17, "min_CLP": -3.22, "draft_iters": 7.1, "mem_use": 44.1, "gen_rate": 4.7, "speed": 3.78, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.9433, "t1": 0.28, "tft": 2.2107, "input_0": 56, "input_1": 17, "min_CLP": -2.94, "draft_iters": 15.3, "mem_use": 44.64, "gen_rate": 15.3, "speed": 6.9, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.078, "t1": 0.282, "tft": 1.5737, "input_0": 44, "input_1": 17, "min_CLP": -2.86, "draft_iters": 7.8, "mem_use": 44.41, "gen_rate": 6.6, "speed": 4.85, "text": "Certainly! Below is an example o"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.16, "t1": 0.28, "tft": 1.6299, "input_0": 63, "input_1": 17, "min_CLP": -2.42, "draft_iters": 17.0, "mem_use": 44.19, "gen_rate": 17.0, "speed": 6.97, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 1.096, "t1": 0.272, "tft": 2.0661, "input_0": 45, "input_1": 17, "min_CLP": -3.22, "draft_iters": 8.2, "mem_use": 44.16, "gen_rate": 6.6, "speed": 4.82, "text": "This is due to the phenomenon of"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.05, "t1": 0.2817, "tft": 1.755, "input_0": 42, "input_1": 17, "min_CLP": -3.36, "draft_iters": 7.8, "mem_use": 44.72, "gen_rate": 6.7, "speed": 5.02, "text": "The significance of the Windows "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.8675, "t1": 0.2975, "tft": 4.4835, "input_0": 38, "input_1": 17, "min_CLP": -3.39, "draft_iters": 6.2, "mem_use": 47.78, "gen_rate": 4.8, "speed": 4.07, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.8011, "t1": 0.2944, "tft": 3.2256, "input_0": 34, "input_1": 17, "min_CLP": -3.4, "draft_iters": 5.9, "mem_use": 46.51, "gen_rate": 3.9, "speed": 3.55, "text": "\"I see! In that case, I can unde"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.8713, "t1": 0.2812, "tft": 2.255, "input_0": 36, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.6, "mem_use": 44.78, "gen_rate": 4.0, "speed": 3.47, "text": "To build a Dyson sphere, a civil"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.7, "tree_w": 3, "tree_size": 16, "t0": 1.7667, "t1": 0.2767, "tft": 1.8795, "input_0": 58, "input_1": 17, "min_CLP": -2.12, "draft_iters": 13.7, "mem_use": 44.11, "gen_rate": 12.3, "speed": 6.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 22, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.9043, "t1": 0.2786, "tft": 1.4163, "input_0": 36, "input_1": 17, "min_CLP": -3.46, "draft_iters": 6.7, "mem_use": 44.1, "gen_rate": 3.1, "speed": 2.65, "text": "I understand how to speak German"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.178, "t1": 0.28, "tft": 1.7922, "input_0": 44, "input_1": 17, "min_CLP": -2.51, "draft_iters": 9.0, "mem_use": 44.3, "gen_rate": 6.4, "speed": 4.39, "text": "Certainly! As a Linux shell, I w"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.8486, "t1": 0.2814, "tft": 2.5764, "input_0": 38, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.4, "mem_use": 45.18, "gen_rate": 4.6, "speed": 4.04, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.9883, "t1": 0.2933, "tft": 3.5177, "input_0": 42, "input_1": 17, "min_CLP": -2.96, "draft_iters": 7.3, "mem_use": 45.77, "gen_rate": 5.5, "speed": 4.3, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.7613, "t1": 0.275, "tft": 1.6005, "input_0": 35, "input_1": 17, "min_CLP": -3.72, "draft_iters": 5.5, "mem_use": 44.16, "gen_rate": 4.4, "speed": 4.22, "text": "\"Sure, I'd be happy to write a h"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.8722, "t1": 0.2789, "tft": 2.482, "input_0": 36, "input_1": 17, "min_CLP": -3.64, "draft_iters": 6.6, "mem_use": 44.52, "gen_rate": 3.8, "speed": 3.29, "text": "\"     o\\n     /|\\\\\\n     / \\\\\\n["}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.7, "tree_w": 2, "tree_size": 16, "t0": 1.7733, "t1": 0.2767, "tft": 1.7451, "input_0": 58, "input_1": 17, "min_CLP": -1.9, "draft_iters": 13.7, "mem_use": 44.11, "gen_rate": 12.3, "speed": 6.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.1975, "t1": 0.28, "tft": 2.194, "input_0": 42, "input_1": 17, "min_CLP": -2.83, "draft_iters": 9.2, "mem_use": 44.47, "gen_rate": 4.8, "speed": 3.22, "text": "Yes, there is a true and most et"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 1.0325, "t1": 0.2863, "tft": 2.2412, "input_0": 42, "input_1": 17, "min_CLP": -3.39, "draft_iters": 7.4, "mem_use": 44.39, "gen_rate": 4.6, "speed": 3.52, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.0683, "t1": 0.2983, "tft": 3.335, "input_0": 45, "input_1": 17, "min_CLP": -3.19, "draft_iters": 7.5, "mem_use": 46.43, "gen_rate": 5.3, "speed": 3.92, "text": "\"Alright, let's get started! Fir"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.4, "tree_w": 5, "tree_size": 16, "t0": 1.1325, "t1": 0.2875, "tft": 1.5344, "input_0": 38, "input_1": 17, "min_CLP": -3.76, "draft_iters": 8.4, "mem_use": 44.27, "gen_rate": 4.5, "speed": 3.18, "text": "[INST] <<SYS>>\\nYou are an exper"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.9889, "t1": 0.2978, "tft": 4.2733, "input_0": 40, "input_1": 17, "min_CLP": -3.16, "draft_iters": 7.2, "mem_use": 47.14, "gen_rate": 3.8, "speed": 2.94, "text": "\"I'm sorry, but I am not able to"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 1.0587, "t1": 0.2775, "tft": 1.6347, "input_0": 43, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.9, "mem_use": 44.14, "gen_rate": 4.6, "speed": 3.46, "text": "\"Sure, I can try to create an AS"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 1.135, "t1": 0.2767, "tft": 1.883, "input_0": 46, "input_1": 17, "min_CLP": -2.98, "draft_iters": 8.5, "mem_use": 44.1, "gen_rate": 5.5, "speed": 3.9, "text": "\"HTML (Hypertext Markup Language"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.0, "tree_w": 2, "tree_size": 16, "t0": 1.5675, "t1": 0.2775, "tft": 1.4965, "input_0": 54, "input_1": 17, "min_CLP": -2.86, "draft_iters": 12.0, "mem_use": 44.13, "gen_rate": 9.8, "speed": 5.28, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.87, "t1": 0.2811, "tft": 1.4942, "input_0": 35, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.6, "mem_use": 44.5, "gen_rate": 3.7, "speed": 3.19, "text": "The image is protected by copyri"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.15, "t1": 0.275, "tft": 1.7364, "input_0": 63, "input_1": 17, "min_CLP": -2.85, "draft_iters": 17.0, "mem_use": 44.12, "gen_rate": 17.0, "speed": 7.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.212, "t1": 0.288, "tft": 2.722, "input_0": 46, "input_1": 17, "min_CLP": -3.02, "draft_iters": 9.2, "mem_use": 45.18, "gen_rate": 7.4, "speed": 4.93, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8389, "t1": 0.2856, "tft": 1.8882, "input_0": 37, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.1, "mem_use": 44.88, "gen_rate": 3.6, "speed": 3.16, "text": "Alright, in that case, positions"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.0, "tree_w": 8, "tree_size": 16, "t0": 0.5764, "t1": 0.2909, "tft": 1.7539, "input_0": 26, "input_1": 17, "min_CLP": -3.85, "draft_iters": 4.0, "mem_use": 44.73, "gen_rate": 3.0, "speed": 3.46, "text": "Ah, but is it the studios that c"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.8025, "t1": 0.295, "tft": 2.6124, "input_0": 35, "input_1": 17, "min_CLP": -3.43, "draft_iters": 5.9, "mem_use": 45.45, "gen_rate": 4.1, "speed": 3.76, "text": "\"That sounds like a very introsp"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 27, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.968, "t1": 0.27, "tft": 1.4869, "input_0": 37, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.6, "mem_use": 44.08, "gen_rate": 5.4, "speed": 4.34, "text": "\"Here's an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.8312, "t1": 0.285, "tft": 1.4722, "input_0": 36, "input_1": 17, "min_CLP": -3.95, "draft_iters": 6.0, "mem_use": 44.41, "gen_rate": 4.4, "speed": 3.93, "text": "Sure, I am known as \"OpenAssista"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.0017, "t1": 0.2817, "tft": 2.8291, "input_0": 43, "input_1": 17, "min_CLP": -3.24, "draft_iters": 7.5, "mem_use": 45.16, "gen_rate": 5.8, "speed": 4.55, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.6, "tree_w": 5, "tree_size": 16, "t0": 0.7889, "t1": 0.2844, "tft": 1.6141, "input_0": 35, "input_1": 17, "min_CLP": -3.35, "draft_iters": 5.6, "mem_use": 44.2, "gen_rate": 3.8, "speed": 3.52, "text": "Motion Matching is a technique u"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 2, "tree_size": 16, "t0": 1.7067, "t1": 0.3, "tft": 3.3858, "input_0": 48, "input_1": 17, "min_CLP": -2.39, "draft_iters": 12.7, "mem_use": 45.84, "gen_rate": 10.7, "speed": 5.32, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.4, "tree_w": 2, "tree_size": 16, "t0": 1.44, "t1": 0.288, "tft": 2.4797, "input_0": 49, "input_1": 17, "min_CLP": -2.73, "draft_iters": 10.4, "mem_use": 44.16, "gen_rate": 8.0, "speed": 4.63, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.8344, "t1": 0.29, "tft": 1.9444, "input_0": 34, "input_1": 17, "min_CLP": -3.89, "draft_iters": 6.0, "mem_use": 44.54, "gen_rate": 3.7, "speed": 3.26, "text": "\u300c\u671b\u3080\u300d(nozomu) is the Kanji for wi"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.9863, "t1": 0.2875, "tft": 3.9416, "input_0": 41, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.2, "mem_use": 45.84, "gen_rate": 4.2, "speed": 3.34, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.9438, "t1": 0.2938, "tft": 3.1887, "input_0": 41, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.8, "mem_use": 46.28, "gen_rate": 4.8, "speed": 3.84, "text": "\"Paul Allen's plane collection i"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.065, "t1": 0.29, "tft": 3.1165, "input_0": 42, "input_1": 17, "min_CLP": -2.99, "draft_iters": 7.7, "mem_use": 45.72, "gen_rate": 6.2, "speed": 4.56, "text": "Certainly, here is an example of"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.13, "t1": 0.275, "tft": 1.4815, "input_0": 61, "input_1": 17, "min_CLP": -2.65, "draft_iters": 17.0, "mem_use": 44.18, "gen_rate": 17.0, "speed": 7.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.7957, "t1": 0.2814, "tft": 1.974, "input_0": 35, "input_1": 17, "min_CLP": -3.26, "draft_iters": 6.0, "mem_use": 44.81, "gen_rate": 5.0, "speed": 4.65, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.17, "t1": 0.28, "tft": 2.4196, "input_0": 44, "input_1": 17, "min_CLP": -3.42, "draft_iters": 9.0, "mem_use": 44.22, "gen_rate": 5.1, "speed": 3.55, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 1, "tree_size": 16, "t0": 1.8367, "t1": 0.2733, "tft": 1.7453, "input_0": 60, "input_1": 17, "min_CLP": -1.82, "draft_iters": 14.3, "mem_use": 44.1, "gen_rate": 12.3, "speed": 5.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.2, "tree_w": 3, "tree_size": 16, "t0": 1.095, "t1": 0.2817, "tft": 2.5204, "input_0": 43, "input_1": 17, "min_CLP": -3.51, "draft_iters": 8.2, "mem_use": 44.94, "gen_rate": 5.8, "speed": 4.24, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.8643, "t1": 0.29, "tft": 3.1436, "input_0": 38, "input_1": 17, "min_CLP": -3.34, "draft_iters": 6.4, "mem_use": 45.75, "gen_rate": 4.7, "speed": 4.08, "text": "\"There are several ways to stop "}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.9011, "t1": 0.2989, "tft": 3.9558, "input_0": 37, "input_1": 17, "min_CLP": -3.03, "draft_iters": 6.6, "mem_use": 46.65, "gen_rate": 3.7, "speed": 3.06, "text": "Multi-track drifting is a propos"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.4, "tree_w": 3, "tree_size": 16, "t0": 1.12, "t1": 0.286, "tft": 3.1837, "input_0": 40, "input_1": 17, "min_CLP": -2.79, "draft_iters": 8.4, "mem_use": 45.25, "gen_rate": 6.8, "speed": 4.84, "text": "\"It is theoretically possible fo"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 2.03, "t1": 0.29, "tft": 2.4495, "input_0": 48, "input_1": 17, "min_CLP": -3.71, "draft_iters": 16.0, "mem_use": 45.08, "gen_rate": 15.7, "speed": 6.76, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.7, "tree_w": 2, "tree_size": 16, "t0": 1.4171, "t1": 0.2871, "tft": 2.3941, "input_0": 46, "input_1": 17, "min_CLP": -2.69, "draft_iters": 10.7, "mem_use": 44.86, "gen_rate": 5.4, "speed": 3.18, "text": "In Japanese, you can say:\\n\\n- \""}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.03, "t1": 0.2833, "tft": 1.7213, "input_0": 43, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.7, "mem_use": 44.39, "gen_rate": 5.7, "speed": 4.32, "text": "Some of the best universities fo"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.1817, "t1": 0.2783, "tft": 1.7717, "input_0": 44, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.8, "mem_use": 44.08, "gen_rate": 6.0, "speed": 4.11, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.5, "tree_w": 3, "tree_size": 16, "t0": 1.4825, "t1": 0.2775, "tft": 1.5186, "input_0": 49, "input_1": 17, "min_CLP": -2.47, "draft_iters": 11.5, "mem_use": 44.22, "gen_rate": 9.2, "speed": 5.26, "text": "Here is a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.8163, "t1": 0.285, "tft": 2.5923, "input_0": 40, "input_1": 17, "min_CLP": -3.68, "draft_iters": 5.9, "mem_use": 45.35, "gen_rate": 4.4, "speed": 3.97, "text": "1. Financial stress: To address "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.8171, "t1": 0.28, "tft": 1.6135, "input_0": 37, "input_1": 17, "min_CLP": -3.28, "draft_iters": 6.0, "mem_use": 44.08, "gen_rate": 4.1, "speed": 3.78, "text": "Hello! I am an AI language model"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 2, "tree_size": 16, "t0": 1.482, "t1": 0.294, "tft": 3.7935, "input_0": 51, "input_1": 17, "min_CLP": -2.75, "draft_iters": 11.2, "mem_use": 46.75, "gen_rate": 6.6, "speed": 3.72, "text": "\"One example of where you might "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.8914, "t1": 0.2886, "tft": 1.7365, "input_0": 35, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.7, "mem_use": 44.37, "gen_rate": 4.7, "speed": 4.0, "text": "Yes, you are correct. Hairy bitt"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 28, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.6, "t1": 0.2833, "tft": 2.0055, "input_0": 27, "input_1": 17, "min_CLP": -4.24, "draft_iters": 4.4, "mem_use": 44.16, "gen_rate": 3.1, "speed": 3.52, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 1.1, "t1": 0.2956, "tft": 3.5205, "input_0": 41, "input_1": 17, "min_CLP": -2.94, "draft_iters": 8.2, "mem_use": 46.35, "gen_rate": 3.8, "speed": 2.71, "text": "Certainly! Here are some open so"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.5, "tree_w": 3, "tree_size": 16, "t0": 1.3, "t1": 0.29, "tft": 1.9872, "input_0": 44, "input_1": 17, "min_CLP": -3.02, "draft_iters": 9.5, "mem_use": 44.16, "gen_rate": 8.2, "speed": 5.2, "text": "To use software defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 1.0057, "t1": 0.2857, "tft": 2.5039, "input_0": 39, "input_1": 17, "min_CLP": -3.3, "draft_iters": 7.4, "mem_use": 44.86, "gen_rate": 4.6, "speed": 3.53, "text": "No, there is no most ethical res"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 7.6, "tree_w": 5, "tree_size": 16, "t0": 1.1471, "t1": 0.2971, "tft": 3.3395, "input_0": 45, "input_1": 17, "min_CLP": -3.1, "draft_iters": 8.6, "mem_use": 45.73, "gen_rate": 6.0, "speed": 4.16, "text": "1. m\u00eb - pronounced as \"may\"\\n2. "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.0257, "t1": 0.28, "tft": 1.4814, "input_0": 41, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.7, "mem_use": 44.41, "gen_rate": 4.9, "speed": 3.72, "text": "\"Sure, here's a story about how "}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.055, "t1": 0.2937, "tft": 3.8979, "input_0": 42, "input_1": 17, "min_CLP": -3.36, "draft_iters": 8.0, "mem_use": 47.17, "gen_rate": 5.2, "speed": 3.89, "text": "\"I apologize for any confusion c"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9329, "t1": 0.2757, "tft": 1.6052, "input_0": 39, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.0, "mem_use": 44.12, "gen_rate": 4.7, "speed": 3.89, "text": "In ReStructuredText (rst), you c"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.6, "tree_w": 3, "tree_size": 16, "t0": 1.54, "t1": 0.294, "tft": 3.1449, "input_0": 56, "input_1": 17, "min_CLP": -2.27, "draft_iters": 11.6, "mem_use": 46.13, "gen_rate": 8.4, "speed": 4.58, "text": "\"Sure! Here's an example code to"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 2.0567, "t1": 0.2767, "tft": 2.3265, "input_0": 59, "input_1": 17, "min_CLP": -3.09, "draft_iters": 16.0, "mem_use": 44.1, "gen_rate": 13.3, "speed": 5.7, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.3, "tree_w": 8, "tree_size": 16, "t0": 0.582, "t1": 0.288, "tft": 1.691, "input_0": 26, "input_1": 17, "min_CLP": -4.02, "draft_iters": 4.3, "mem_use": 44.56, "gen_rate": 3.3, "speed": 3.8, "text": "\"That's a difficult question to "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8637, "t1": 0.3112, "tft": 5.7051, "input_0": 40, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.1, "mem_use": 49.73, "gen_rate": 4.0, "speed": 3.4, "text": "\"Yes, I'd be happy to give it a "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.6, "tree_w": 5, "tree_size": 16, "t0": 0.786, "t1": 0.289, "tft": 2.4387, "input_0": 36, "input_1": 17, "min_CLP": -3.9, "draft_iters": 5.6, "mem_use": 44.93, "gen_rate": 3.5, "speed": 3.25, "text": "\"0 independent counsel is a lawy"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 1.0357, "t1": 0.2986, "tft": 3.8433, "input_0": 40, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.4, "mem_use": 46.79, "gen_rate": 4.6, "speed": 3.43, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.8, "tree_w": 5, "tree_size": 16, "t0": 0.802, "t1": 0.294, "tft": 2.2187, "input_0": 32, "input_1": 17, "min_CLP": -3.66, "draft_iters": 5.8, "mem_use": 45.16, "gen_rate": 3.3, "speed": 3.01, "text": "\"1. A new competitor restaurant "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.98, "t1": 0.2878, "tft": 1.8517, "input_0": 37, "input_1": 17, "min_CLP": -3.3, "draft_iters": 7.1, "mem_use": 44.43, "gen_rate": 3.6, "speed": 2.81, "text": "```python\\ndef inspirational_mon"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 1.175, "t1": 0.2967, "tft": 4.3476, "input_0": 48, "input_1": 17, "min_CLP": -2.66, "draft_iters": 8.3, "mem_use": 46.92, "gen_rate": 5.7, "speed": 3.85, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.2, "tree_w": 3, "tree_size": 16, "t0": 1.1317, "t1": 0.29, "tft": 1.7449, "input_0": 43, "input_1": 17, "min_CLP": -3.17, "draft_iters": 8.2, "mem_use": 44.62, "gen_rate": 6.7, "speed": 4.69, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 1.14, "t1": 0.2929, "tft": 4.2663, "input_0": 47, "input_1": 17, "min_CLP": -2.88, "draft_iters": 8.6, "mem_use": 46.58, "gen_rate": 5.6, "speed": 3.88, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.2083, "t1": 0.28, "tft": 1.7798, "input_0": 43, "input_1": 17, "min_CLP": -2.96, "draft_iters": 9.2, "mem_use": 44.14, "gen_rate": 6.2, "speed": 4.14, "text": "\"Certainly! Here's an implementa"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 2, "tree_size": 16, "t0": 1.96, "t1": 0.2867, "tft": 2.1575, "input_0": 49, "input_1": 17, "min_CLP": -3.2, "draft_iters": 15.3, "mem_use": 44.87, "gen_rate": 15.3, "speed": 6.82, "text": "\"The laws for nudity in Wyoming "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.185, "t1": 0.28, "tft": 1.7046, "input_0": 62, "input_1": 17, "min_CLP": -2.59, "draft_iters": 17.0, "mem_use": 44.59, "gen_rate": 17.0, "speed": 6.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 1.1457, "t1": 0.2857, "tft": 2.0835, "input_0": 45, "input_1": 17, "min_CLP": -3.15, "draft_iters": 8.1, "mem_use": 44.18, "gen_rate": 4.7, "speed": 3.3, "text": "To code the Snake game in C with"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 1.182, "t1": 0.29, "tft": 2.4704, "input_0": 50, "input_1": 17, "min_CLP": -3.1, "draft_iters": 8.4, "mem_use": 45.07, "gen_rate": 6.6, "speed": 4.48, "text": "\"It's natural to feel this way, "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.7225, "t1": 0.3, "tft": 3.7483, "input_0": 49, "input_1": 17, "min_CLP": -2.56, "draft_iters": 13.0, "mem_use": 46.66, "gen_rate": 11.2, "speed": 5.57, "text": "Certainly, here is a list of som"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 7.0, "tree_w": 5, "tree_size": 16, "t0": 1.14, "t1": 0.2833, "tft": 1.7986, "input_0": 44, "input_1": 17, "min_CLP": -2.99, "draft_iters": 8.0, "mem_use": 44.3, "gen_rate": 2.7, "speed": 1.87, "text": "The total travel time would be 2"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.7525, "t1": 0.2775, "tft": 1.9209, "input_0": 55, "input_1": 17, "min_CLP": -2.29, "draft_iters": 13.0, "mem_use": 44.21, "gen_rate": 9.5, "speed": 4.68, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 4, "tree_size": 16, "t0": 0.905, "t1": 0.2762, "tft": 1.5343, "input_0": 38, "input_1": 17, "min_CLP": -3.21, "draft_iters": 6.8, "mem_use": 44.1, "gen_rate": 4.1, "speed": 3.5, "text": "Yes, I am a conversational AI la"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.98, "t1": 0.3067, "tft": 4.9116, "input_0": 42, "input_1": 17, "min_CLP": -2.99, "draft_iters": 7.2, "mem_use": 47.88, "gen_rate": 5.3, "speed": 4.15, "text": "\"TypeScript offers several advan"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 1.342, "t1": 0.284, "tft": 1.991, "input_0": 46, "input_1": 17, "min_CLP": -3.38, "draft_iters": 10.2, "mem_use": 44.22, "gen_rate": 7.8, "speed": 4.8, "text": "\"The name of the fourth child is"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.6, "tree_w": 3, "tree_size": 16, "t0": 1.482, "t1": 0.294, "tft": 2.3362, "input_0": 42, "input_1": 17, "min_CLP": -3.66, "draft_iters": 11.6, "mem_use": 45.26, "gen_rate": 8.4, "speed": 4.72, "text": "[INST] Do not farm experience in"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.975, "t1": 0.2937, "tft": 3.8543, "input_0": 41, "input_1": 17, "min_CLP": -3.2, "draft_iters": 7.0, "mem_use": 47.03, "gen_rate": 4.0, "speed": 3.15, "text": "It depends on the type of bread "}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.9514, "t1": 0.2829, "tft": 1.6051, "input_0": 43, "input_1": 17, "min_CLP": -3.39, "draft_iters": 6.9, "mem_use": 44.35, "gen_rate": 5.0, "speed": 4.06, "text": "Yes, you are on the right track "}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 27, "tree_h": 8.3, "tree_w": 3, "tree_size": 16, "t0": 1.2, "t1": 0.28, "tft": 2.1433, "input_0": 45, "input_1": 17, "min_CLP": -3.02, "draft_iters": 9.3, "mem_use": 44.86, "gen_rate": 9.0, "speed": 6.07, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.212, "t1": 0.292, "tft": 3.7479, "input_0": 47, "input_1": 17, "min_CLP": -2.95, "draft_iters": 9.0, "mem_use": 46.59, "gen_rate": 7.8, "speed": 5.19, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 1.15, "t1": 0.284, "tft": 2.467, "input_0": 46, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.6, "mem_use": 44.99, "gen_rate": 7.0, "speed": 4.88, "text": "The television was invented by J"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.24, "t1": 0.2983, "tft": 4.0693, "input_0": 48, "input_1": 17, "min_CLP": -2.63, "draft_iters": 9.0, "mem_use": 47.32, "gen_rate": 6.3, "speed": 4.11, "text": "By trying these methods, you sho"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.12, "t1": 0.298, "tft": 2.9459, "input_0": 45, "input_1": 17, "min_CLP": -2.83, "draft_iters": 8.0, "mem_use": 45.65, "gen_rate": 6.6, "speed": 4.66, "text": "The reason why there are multipl"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8325, "t1": 0.285, "tft": 1.8528, "input_0": 36, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.1, "mem_use": 44.67, "gen_rate": 4.8, "speed": 4.26, "text": "\"Oh, you're right. I am an AI. I"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 1.148, "t1": 0.296, "tft": 3.8035, "input_0": 49, "input_1": 17, "min_CLP": -2.71, "draft_iters": 8.4, "mem_use": 46.47, "gen_rate": 7.6, "speed": 5.27, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 2.125, "t1": 0.285, "tft": 1.5435, "input_0": 68, "input_1": 17, "min_CLP": -2.69, "draft_iters": 16.5, "mem_use": 44.29, "gen_rate": 16.5, "speed": 6.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 1.0629, "t1": 0.2871, "tft": 2.4277, "input_0": 39, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.9, "mem_use": 44.92, "gen_rate": 5.0, "speed": 3.69, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.686, "t1": 0.282, "tft": 1.5854, "input_0": 29, "input_1": 17, "min_CLP": -3.77, "draft_iters": 5.0, "mem_use": 44.39, "gen_rate": 3.4, "speed": 3.51, "text": "\"Oh, you're a broke college stud"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.355, "t1": 0.2875, "tft": 1.9458, "input_0": 53, "input_1": 17, "min_CLP": -2.74, "draft_iters": 10.0, "mem_use": 44.41, "gen_rate": 8.2, "speed": 5.03, "text": "The Sagittarius A* black hole is"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.6673, "t1": 0.2836, "tft": 2.1697, "input_0": 30, "input_1": 17, "min_CLP": -3.85, "draft_iters": 4.8, "mem_use": 44.79, "gen_rate": 3.0, "speed": 3.15, "text": "Google Authenticator is a mobile"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 3, "tree_size": 16, "t0": 1.008, "t1": 0.284, "tft": 3.0436, "input_0": 42, "input_1": 17, "min_CLP": -2.79, "draft_iters": 7.4, "mem_use": 44.57, "gen_rate": 6.4, "speed": 4.95, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.04, "t1": 0.2814, "tft": 1.4799, "input_0": 42, "input_1": 17, "min_CLP": -2.83, "draft_iters": 7.7, "mem_use": 44.33, "gen_rate": 5.3, "speed": 4.01, "text": "\"Here's a sample script using Ro"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.7, "tree_w": 2, "tree_size": 16, "t0": 1.73, "t1": 0.28, "tft": 2.0006, "input_0": 48, "input_1": 17, "min_CLP": -2.95, "draft_iters": 13.7, "mem_use": 44.18, "gen_rate": 12.0, "speed": 5.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.6, "tree_w": 7, "tree_size": 16, "t0": 0.8787, "t1": 0.285, "tft": 1.5202, "input_0": 34, "input_1": 17, "min_CLP": -3.68, "draft_iters": 6.6, "mem_use": 44.22, "gen_rate": 4.1, "speed": 3.55, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.4, "tree_w": 7, "tree_size": 16, "t0": 0.61, "t1": 0.28, "tft": 1.3752, "input_0": 27, "input_1": 17, "min_CLP": -3.93, "draft_iters": 4.4, "mem_use": 44.13, "gen_rate": 3.8, "speed": 4.24, "text": "\"[INST] Hey, I'm a writer workin"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0833, "t1": 0.2933, "tft": 2.5675, "input_0": 47, "input_1": 17, "min_CLP": -3.81, "draft_iters": 8.0, "mem_use": 45.31, "gen_rate": 5.3, "speed": 3.87, "text": "In that case, you can use your l"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.2333, "t1": 0.275, "tft": 1.7634, "input_0": 51, "input_1": 17, "min_CLP": -2.86, "draft_iters": 9.2, "mem_use": 44.09, "gen_rate": 5.7, "speed": 3.75, "text": "In Python, the `@` symbol has tw"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.021, "t1": 0.282, "tft": 1.7452, "input_0": 41, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.5, "mem_use": 44.1, "gen_rate": 3.9, "speed": 3.0, "text": "ChatGPT is an impressive convers"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.9388, "t1": 0.2863, "tft": 1.4718, "input_0": 41, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.6, "mem_use": 44.41, "gen_rate": 4.5, "speed": 3.67, "text": "Hello, Adolf Hitler. It is a ple"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 46, "tree_h": 5.8, "tree_w": 8, "tree_size": 16, "t0": 0.912, "t1": 0.282, "tft": 1.2778, "input_0": 34, "input_1": 17, "min_CLP": -3.8, "draft_iters": 6.8, "mem_use": 44.14, "gen_rate": 4.6, "speed": 3.85, "text": "Certainly! Here\\'s a Malbolge pr"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.8, "tree_w": 2, "tree_size": 16, "t0": 1.44, "t1": 0.2925, "tft": 2.2632, "input_0": 53, "input_1": 17, "min_CLP": -3.11, "draft_iters": 10.8, "mem_use": 44.84, "gen_rate": 8.8, "speed": 5.06, "text": "\"Sure, I'd be happy to explain e"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.8933, "t1": 0.2922, "tft": 3.8471, "input_0": 37, "input_1": 17, "min_CLP": -3.19, "draft_iters": 6.6, "mem_use": 47.35, "gen_rate": 3.8, "speed": 3.18, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 1.1986, "t1": 0.2814, "tft": 2.3572, "input_0": 48, "input_1": 17, "min_CLP": -2.89, "draft_iters": 8.7, "mem_use": 44.65, "gen_rate": 5.0, "speed": 3.37, "text": "Decorators can do many things th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.0, "tree_w": 8, "tree_size": 16, "t0": 0.555, "t1": 0.2908, "tft": 2.8925, "input_0": 26, "input_1": 17, "min_CLP": -4.01, "draft_iters": 4.0, "mem_use": 45.77, "gen_rate": 2.7, "speed": 3.15, "text": "\"That's not how this works, Agen"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 18, "tree_h": 5.4, "tree_w": 8, "tree_size": 16, "t0": 0.85, "t1": 0.2843, "tft": 2.2364, "input_0": 34, "input_1": 17, "min_CLP": -4.28, "draft_iters": 6.4, "mem_use": 44.63, "gen_rate": 2.6, "speed": 2.27, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 1.1371, "t1": 0.2971, "tft": 4.2773, "input_0": 41, "input_1": 17, "min_CLP": -2.97, "draft_iters": 8.7, "mem_use": 47.53, "gen_rate": 4.6, "speed": 3.18, "text": "Sure, here are some simple code "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 1.33, "t1": 0.346, "tft": 10.3205, "input_0": 52, "input_1": 17, "min_CLP": -2.84, "draft_iters": 9.8, "mem_use": 53.57, "gen_rate": 6.4, "speed": 3.82, "text": "\"Certainly! Here's an example of"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 1.116, "t1": 0.294, "tft": 3.2647, "input_0": 40, "input_1": 17, "min_CLP": -3.73, "draft_iters": 8.4, "mem_use": 45.87, "gen_rate": 8.0, "speed": 5.68, "text": "\"L'H\u00f4pital's Rule is widely used"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.926, "t1": 0.28, "tft": 1.8565, "input_0": 38, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.8, "mem_use": 44.14, "gen_rate": 4.0, "speed": 3.32, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.19, "t1": 0.28, "tft": 1.8835, "input_0": 61, "input_1": 17, "min_CLP": -2.19, "draft_iters": 17.0, "mem_use": 44.26, "gen_rate": 17.0, "speed": 6.89, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.8514, "t1": 0.2986, "tft": 3.6341, "input_0": 37, "input_1": 17, "min_CLP": -3.53, "draft_iters": 6.3, "mem_use": 47.04, "gen_rate": 4.7, "speed": 4.11, "text": "\"Sure! Since you're aiming for a"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.0967, "t1": 0.285, "tft": 2.236, "input_0": 45, "input_1": 17, "min_CLP": -3.59, "draft_iters": 7.8, "mem_use": 44.2, "gen_rate": 5.3, "speed": 3.86, "text": "In 1950, the world was vastly di"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 1.0243, "t1": 0.3129, "tft": 5.4356, "input_0": 43, "input_1": 17, "min_CLP": -2.84, "draft_iters": 7.3, "mem_use": 49.21, "gen_rate": 5.1, "speed": 3.85, "text": "\"Creating your own stable diffus"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.9414, "t1": 0.2857, "tft": 1.6956, "input_0": 41, "input_1": 17, "min_CLP": -3.61, "draft_iters": 6.9, "mem_use": 44.55, "gen_rate": 4.7, "speed": 3.84, "text": "The order in which you install t"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.97, "t1": 0.286, "tft": 2.1158, "input_0": 38, "input_1": 17, "min_CLP": -3.39, "draft_iters": 7.2, "mem_use": 44.39, "gen_rate": 6.4, "speed": 5.1, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.624, "t1": 0.286, "tft": 1.6157, "input_0": 28, "input_1": 17, "min_CLP": -4.12, "draft_iters": 4.5, "mem_use": 44.46, "gen_rate": 3.3, "speed": 3.63, "text": "I will be more free, more open, "}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 3, "tree_size": 16, "t0": 1.3033, "t1": 0.295, "tft": 3.3307, "input_0": 51, "input_1": 17, "min_CLP": -2.84, "draft_iters": 9.7, "mem_use": 45.81, "gen_rate": 5.7, "speed": 3.55, "text": "The primary components of a PC t"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 1.2586, "t1": 0.2857, "tft": 2.4008, "input_0": 48, "input_1": 17, "min_CLP": -3.39, "draft_iters": 9.6, "mem_use": 44.52, "gen_rate": 5.7, "speed": 3.7, "text": "Yes, it is true that the KeyHole"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.9429, "t1": 0.2857, "tft": 1.7562, "input_0": 38, "input_1": 17, "min_CLP": -3.39, "draft_iters": 7.0, "mem_use": 44.7, "gen_rate": 5.3, "speed": 4.3, "text": "\"Here's a recipe you can make wi"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.9986, "t1": 0.2886, "tft": 2.1608, "input_0": 42, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.3, "mem_use": 44.76, "gen_rate": 5.0, "speed": 3.89, "text": "One way to see the stars more cl"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.1014, "t1": 0.2971, "tft": 3.5115, "input_0": 44, "input_1": 17, "min_CLP": -3.34, "draft_iters": 8.0, "mem_use": 46.67, "gen_rate": 4.6, "speed": 3.27, "text": "Here are some YouTube channels t"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 1.003, "t1": 0.279, "tft": 1.5025, "input_0": 36, "input_1": 17, "min_CLP": -3.79, "draft_iters": 7.5, "mem_use": 44.1, "gen_rate": 3.4, "speed": 2.65, "text": "[INST] Output a detailed respons"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 31, "tree_h": 8.5, "tree_w": 3, "tree_size": 16, "t0": 1.2425, "t1": 0.285, "tft": 1.9171, "input_0": 41, "input_1": 17, "min_CLP": -3.05, "draft_iters": 9.5, "mem_use": 44.24, "gen_rate": 7.8, "speed": 5.09, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.0437, "t1": 0.2963, "tft": 2.7272, "input_0": 40, "input_1": 17, "min_CLP": -3.66, "draft_iters": 7.8, "mem_use": 45.68, "gen_rate": 4.1, "speed": 3.08, "text": "\"Statistical modeling, it's what"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.195, "t1": 0.295, "tft": 4.7406, "input_0": 61, "input_1": 17, "min_CLP": -2.56, "draft_iters": 17.0, "mem_use": 46.85, "gen_rate": 17.0, "speed": 6.83, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 16, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.874, "t1": 0.284, "tft": 1.4991, "input_0": 33, "input_1": 17, "min_CLP": -3.29, "draft_iters": 6.6, "mem_use": 44.08, "gen_rate": 3.2, "speed": 2.77, "text": "The current date is not provided"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.9178, "t1": 0.2967, "tft": 2.9169, "input_0": 37, "input_1": 17, "min_CLP": -3.26, "draft_iters": 6.7, "mem_use": 45.57, "gen_rate": 4.1, "speed": 3.39, "text": "\"Yes, that's a great approach to"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.718, "t1": 0.285, "tft": 1.6105, "input_0": 32, "input_1": 17, "min_CLP": -3.7, "draft_iters": 5.1, "mem_use": 44.45, "gen_rate": 3.2, "speed": 3.2, "text": "\"Hey, that's so not true, dude! "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 1.3833, "t1": 0.285, "tft": 1.8736, "input_0": 49, "input_1": 17, "min_CLP": -2.82, "draft_iters": 10.2, "mem_use": 44.14, "gen_rate": 7.2, "speed": 4.29, "text": "Variance is a measure of the spr"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 1.02, "t1": 0.2883, "tft": 1.62, "input_0": 43, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.3, "mem_use": 44.49, "gen_rate": 5.3, "speed": 4.07, "text": "Sure, as an AI language model, I"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 1.02, "t1": 0.28, "tft": 1.8959, "input_0": 40, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.5, "mem_use": 44.08, "gen_rate": 5.3, "speed": 4.11, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.8883, "t1": 0.2967, "tft": 3.1177, "input_0": 39, "input_1": 17, "min_CLP": -3.49, "draft_iters": 6.5, "mem_use": 45.42, "gen_rate": 5.5, "speed": 4.65, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.8, "tree_w": 2, "tree_size": 16, "t0": 1.518, "t1": 0.28, "tft": 1.7665, "input_0": 48, "input_1": 17, "min_CLP": -2.5, "draft_iters": 11.8, "mem_use": 44.27, "gen_rate": 7.6, "speed": 4.23, "text": "\" Bob has two sons, John and Jay"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 2, "tree_size": 16, "t0": 1.635, "t1": 0.2825, "tft": 2.1076, "input_0": 57, "input_1": 17, "min_CLP": -3.23, "draft_iters": 12.2, "mem_use": 44.66, "gen_rate": 8.2, "speed": 4.31, "text": "The oceans in the world are:\\n1."}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.2, "tree_w": 8, "tree_size": 16, "t0": 0.717, "t1": 0.289, "tft": 1.8904, "input_0": 31, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.2, "mem_use": 44.9, "gen_rate": 3.4, "speed": 3.37, "text": "One of the most important things"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 3, "tree_size": 16, "t0": 1.5317, "t1": 0.2867, "tft": 1.6982, "input_0": 48, "input_1": 17, "min_CLP": -2.99, "draft_iters": 11.8, "mem_use": 44.31, "gen_rate": 5.3, "speed": 2.94, "text": "# Import the necessary modules\\n"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.0717, "t1": 0.2967, "tft": 3.1046, "input_0": 44, "input_1": 17, "min_CLP": -3.08, "draft_iters": 7.7, "mem_use": 45.41, "gen_rate": 5.5, "speed": 4.02, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 25, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.968, "t1": 0.282, "tft": 1.9289, "input_0": 42, "input_1": 17, "min_CLP": -3.65, "draft_iters": 7.2, "mem_use": 44.55, "gen_rate": 5.0, "speed": 4.0, "text": "I don\\'t have enough information"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8425, "t1": 0.2788, "tft": 1.9306, "input_0": 39, "input_1": 17, "min_CLP": -3.39, "draft_iters": 6.1, "mem_use": 44.09, "gen_rate": 4.1, "speed": 3.69, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 1.0156, "t1": 0.28, "tft": 1.6278, "input_0": 40, "input_1": 17, "min_CLP": -3.71, "draft_iters": 7.4, "mem_use": 44.2, "gen_rate": 4.0, "speed": 3.09, "text": "def test_docker_container():\\n  "}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.8625, "t1": 0.2812, "tft": 1.5935, "input_0": 32, "input_1": 17, "min_CLP": -3.84, "draft_iters": 6.4, "mem_use": 44.35, "gen_rate": 4.2, "speed": 3.72, "text": "They are on a higher moral level"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.685, "t1": 0.288, "tft": 1.9959, "input_0": 28, "input_1": 17, "min_CLP": -3.78, "draft_iters": 5.1, "mem_use": 44.87, "gen_rate": 3.5, "speed": 3.59, "text": "\"I have no problem with dysfunct"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 23, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.964, "t1": 0.296, "tft": 2.7563, "input_0": 40, "input_1": 17, "min_CLP": -2.98, "draft_iters": 7.0, "mem_use": 45.72, "gen_rate": 4.6, "speed": 3.65, "text": "\"Certainly! I'm here to help you"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 1.3267, "t1": 0.2983, "tft": 3.0452, "input_0": 52, "input_1": 17, "min_CLP": -2.62, "draft_iters": 9.8, "mem_use": 46.24, "gen_rate": 6.2, "speed": 3.8, "text": "There are several languages that"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.8478, "t1": 0.2833, "tft": 2.2383, "input_0": 38, "input_1": 17, "min_CLP": -3.27, "draft_iters": 6.2, "mem_use": 44.69, "gen_rate": 3.6, "speed": 3.14, "text": "All of these tools are available"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.7311, "t1": 0.2856, "tft": 1.9602, "input_0": 34, "input_1": 17, "min_CLP": -3.51, "draft_iters": 5.2, "mem_use": 44.56, "gen_rate": 3.7, "speed": 3.6, "text": "That is because I am programmed "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.1, "tree_w": 5, "tree_size": 16, "t0": 1.0862, "t1": 0.29, "tft": 1.7652, "input_0": 39, "input_1": 17, "min_CLP": -3.37, "draft_iters": 8.1, "mem_use": 44.77, "gen_rate": 4.0, "speed": 2.91, "text": "I can understand that you want t"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 1.19, "t1": 0.288, "tft": 2.9455, "input_0": 46, "input_1": 17, "min_CLP": -2.84, "draft_iters": 8.8, "mem_use": 44.78, "gen_rate": 6.4, "speed": 4.32, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.955, "t1": 0.2883, "tft": 2.0188, "input_0": 38, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.0, "mem_use": 44.21, "gen_rate": 5.3, "speed": 4.3, "text": "\"Sure, I can give you an idea of"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9629, "t1": 0.29, "tft": 3.4926, "input_0": 41, "input_1": 17, "min_CLP": -3.27, "draft_iters": 7.1, "mem_use": 45.87, "gen_rate": 4.9, "speed": 3.88, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.864, "t1": 0.286, "tft": 1.7005, "input_0": 37, "input_1": 17, "min_CLP": -3.64, "draft_iters": 6.3, "mem_use": 44.36, "gen_rate": 3.2, "speed": 2.79, "text": "Hippoplaisir\u2019s unique selling po"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.175, "t1": 0.285, "tft": 1.8773, "input_0": 64, "input_1": 17, "min_CLP": -2.17, "draft_iters": 17.0, "mem_use": 44.18, "gen_rate": 17.0, "speed": 6.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 1.1014, "t1": 0.2857, "tft": 2.0108, "input_0": 40, "input_1": 17, "min_CLP": -3.44, "draft_iters": 8.4, "mem_use": 44.67, "gen_rate": 4.6, "speed": 3.3, "text": "\"I am a large language model tra"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.048, "t1": 0.286, "tft": 3.7143, "input_0": 43, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.0, "mem_use": 46.35, "gen_rate": 7.0, "speed": 5.24, "text": "When creating new images using t"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.8236, "t1": 0.2818, "tft": 2.4731, "input_0": 35, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.2, "mem_use": 45.14, "gen_rate": 3.3, "speed": 2.96, "text": "Yes, theories of sexual selectio"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 3, "tree_size": 16, "t0": 1.0383, "t1": 0.29, "tft": 3.0025, "input_0": 40, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.8, "mem_use": 45.57, "gen_rate": 5.3, "speed": 4.02, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.16, "t1": 0.285, "tft": 1.2737, "input_0": 59, "input_1": 17, "min_CLP": -2.82, "draft_iters": 17.0, "mem_use": 44.13, "gen_rate": 17.0, "speed": 6.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 1.0943, "t1": 0.3014, "tft": 6.4119, "input_0": 46, "input_1": 17, "min_CLP": -2.97, "draft_iters": 8.1, "mem_use": 48.86, "gen_rate": 5.1, "speed": 3.68, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.4, "tree_w": 3, "tree_size": 16, "t0": 1.13, "t1": 0.29, "tft": 2.9526, "input_0": 50, "input_1": 17, "min_CLP": -3.17, "draft_iters": 8.4, "mem_use": 45.27, "gen_rate": 6.8, "speed": 4.79, "text": "To transform other text words or"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 1.19, "t1": 0.286, "tft": 2.5924, "input_0": 39, "input_1": 17, "min_CLP": -3.32, "draft_iters": 9.2, "mem_use": 45.13, "gen_rate": 6.4, "speed": 4.33, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 1.278, "t1": 0.28, "tft": 1.4889, "input_0": 47, "input_1": 17, "min_CLP": -2.76, "draft_iters": 9.8, "mem_use": 44.16, "gen_rate": 7.0, "speed": 4.49, "text": "\"## Step 1: Understand the conte"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.7786, "t1": 0.2857, "tft": 1.8797, "input_0": 35, "input_1": 17, "min_CLP": -3.8, "draft_iters": 5.7, "mem_use": 44.49, "gen_rate": 3.7, "speed": 3.49, "text": "Sure! Here\\'s another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 1.1157, "t1": 0.2757, "tft": 1.2711, "input_0": 47, "input_1": 17, "min_CLP": -3.2, "draft_iters": 8.3, "mem_use": 44.12, "gen_rate": 5.4, "speed": 3.9, "text": "There are currently several know"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.88, "t1": 0.308, "tft": 5.1341, "input_0": 34, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.5, "mem_use": 48.92, "gen_rate": 4.0, "speed": 3.37, "text": "I apologize for not meeting your"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.9857, "t1": 0.2843, "tft": 1.6155, "input_0": 42, "input_1": 17, "min_CLP": -4.07, "draft_iters": 7.3, "mem_use": 44.2, "gen_rate": 5.0, "speed": 3.95, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.9456, "t1": 0.3233, "tft": 7.0817, "input_0": 39, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.9, "mem_use": 51.15, "gen_rate": 4.1, "speed": 3.25, "text": "Thank you for providing the exam"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.9357, "t1": 0.2943, "tft": 3.1676, "input_0": 41, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.0, "mem_use": 45.38, "gen_rate": 5.0, "speed": 4.07, "text": "Spritesla is the first and final"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.8611, "t1": 0.2822, "tft": 1.8597, "input_0": 36, "input_1": 17, "min_CLP": -3.36, "draft_iters": 6.4, "mem_use": 44.22, "gen_rate": 3.6, "speed": 3.11, "text": "The human genome is a complex an"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 1.202, "t1": 0.284, "tft": 2.2333, "input_0": 47, "input_1": 17, "min_CLP": -3.18, "draft_iters": 8.8, "mem_use": 44.09, "gen_rate": 8.0, "speed": 5.39, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.823, "t1": 0.285, "tft": 1.8108, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.0, "mem_use": 44.33, "gen_rate": 3.6, "speed": 3.25, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.0467, "t1": 0.2867, "tft": 1.8548, "input_0": 43, "input_1": 17, "min_CLP": -3.21, "draft_iters": 7.7, "mem_use": 44.63, "gen_rate": 6.0, "speed": 4.5, "text": "Here are some popular TV shows t"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 2, "tree_size": 16, "t0": 1.4367, "t1": 0.2933, "tft": 3.3011, "input_0": 52, "input_1": 17, "min_CLP": -2.51, "draft_iters": 10.8, "mem_use": 46.24, "gen_rate": 5.7, "speed": 3.28, "text": "Certainly! Here are some softwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 1.1462, "t1": 0.2975, "tft": 2.981, "input_0": 49, "input_1": 17, "min_CLP": -3.18, "draft_iters": 8.4, "mem_use": 45.36, "gen_rate": 4.2, "speed": 2.95, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 2, "tree_size": 16, "t0": 1.554, "t1": 0.278, "tft": 1.6368, "input_0": 56, "input_1": 17, "min_CLP": -2.86, "draft_iters": 11.6, "mem_use": 44.27, "gen_rate": 6.8, "speed": 3.71, "text": "[INST] <<SYS>>\\nYou are an AI as"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 1.258, "t1": 0.294, "tft": 3.7027, "input_0": 42, "input_1": 17, "min_CLP": -2.9, "draft_iters": 9.6, "mem_use": 46.9, "gen_rate": 6.6, "speed": 4.26, "text": "\"Here's the same first-person co"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 44, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 1.0922, "t1": 0.2889, "tft": 3.1771, "input_0": 45, "input_1": 17, "min_CLP": -3.13, "draft_iters": 8.1, "mem_use": 45.39, "gen_rate": 4.9, "speed": 3.54, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.9033, "t1": 0.2733, "tft": 1.7326, "input_0": 56, "input_1": 17, "min_CLP": -2.08, "draft_iters": 14.7, "mem_use": 44.11, "gen_rate": 12.3, "speed": 5.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 7.0, "tree_w": 3, "tree_size": 16, "t0": 1.06, "t1": 0.278, "tft": 1.6349, "input_0": 46, "input_1": 17, "min_CLP": -3.07, "draft_iters": 8.0, "mem_use": 44.2, "gen_rate": 4.0, "speed": 2.99, "text": "```markdown\\nThis is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 5, "tree_size": 16, "t0": 1.2433, "t1": 0.2817, "tft": 2.4873, "input_0": 47, "input_1": 17, "min_CLP": -3.03, "draft_iters": 9.3, "mem_use": 45.23, "gen_rate": 5.8, "speed": 3.82, "text": "\"I'm sorry, but I'm an AI langua"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 1.0262, "t1": 0.295, "tft": 3.0542, "input_0": 40, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.6, "mem_use": 46.18, "gen_rate": 4.0, "speed": 3.03, "text": "You can use the spread operator "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.9713, "t1": 0.2838, "tft": 1.7259, "input_0": 40, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.2, "mem_use": 44.71, "gen_rate": 4.4, "speed": 3.49, "text": "Sure! Here is a training plan fo"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.91, "t1": 0.285, "tft": 2.3542, "input_0": 41, "input_1": 17, "min_CLP": -3.0, "draft_iters": 6.8, "mem_use": 45.19, "gen_rate": 4.1, "speed": 3.45, "text": "My assumption that the second ba"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 3, "tree_size": 16, "t0": 1.148, "t1": 0.282, "tft": 1.5133, "input_0": 44, "input_1": 17, "min_CLP": -3.01, "draft_iters": 8.4, "mem_use": 44.1, "gen_rate": 7.0, "speed": 4.91, "text": "JavaScript is a programming lang"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 2.015, "t1": 0.275, "tft": 1.7722, "input_0": 56, "input_1": 17, "min_CLP": -2.91, "draft_iters": 16.0, "mem_use": 44.09, "gen_rate": 16.0, "speed": 6.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.8367, "t1": 0.2833, "tft": 2.1093, "input_0": 41, "input_1": 17, "min_CLP": -3.14, "draft_iters": 14.7, "mem_use": 44.81, "gen_rate": 14.0, "speed": 6.6, "text": "[INST] Now make that list into 2"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.995, "t1": 0.28, "tft": 2.0056, "input_0": 39, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.5, "mem_use": 44.22, "gen_rate": 6.2, "speed": 4.84, "text": "\"Hippoplaisir is a psychologists"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.729, "t1": 0.281, "tft": 1.9075, "input_0": 34, "input_1": 17, "min_CLP": -3.57, "draft_iters": 5.2, "mem_use": 44.22, "gen_rate": 3.5, "speed": 3.47, "text": "Here\\'s a poem I came up with fo"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 1.288, "t1": 0.274, "tft": 1.6444, "input_0": 51, "input_1": 17, "min_CLP": -3.2, "draft_iters": 9.6, "mem_use": 44.2, "gen_rate": 7.8, "speed": 4.99, "text": "\"I'd be happy to help you learn "}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9575, "t1": 0.3012, "tft": 5.1337, "input_0": 42, "input_1": 17, "min_CLP": -3.13, "draft_iters": 7.0, "mem_use": 48.98, "gen_rate": 4.1, "speed": 3.28, "text": "\"Thank you for providing the scr"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 1.135, "t1": 0.29, "tft": 3.8001, "input_0": 46, "input_1": 17, "min_CLP": -2.88, "draft_iters": 8.6, "mem_use": 46.59, "gen_rate": 4.4, "speed": 3.08, "text": "\"Sure! Let's try to explain it i"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.8, "tree_w": 3, "tree_size": 16, "t0": 1.5275, "t1": 0.2825, "tft": 2.549, "input_0": 53, "input_1": 17, "min_CLP": -2.79, "draft_iters": 11.8, "mem_use": 45.03, "gen_rate": 9.5, "speed": 5.24, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0733, "t1": 0.2833, "tft": 2.7037, "input_0": 51, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.0, "mem_use": 45.2, "gen_rate": 5.7, "speed": 4.17, "text": "From polar bears, we can learn a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 1.1133, "t1": 0.2933, "tft": 3.3032, "input_0": 46, "input_1": 17, "min_CLP": -3.18, "draft_iters": 8.2, "mem_use": 46.25, "gen_rate": 5.5, "speed": 3.92, "text": "Lemon wedges for serving are sim"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.772, "t1": 0.282, "tft": 1.5244, "input_0": 33, "input_1": 17, "min_CLP": -3.72, "draft_iters": 5.7, "mem_use": 44.28, "gen_rate": 3.3, "speed": 3.13, "text": "\"[INST] Hey, I\u2019m here! Who are y"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.9413, "t1": 0.2875, "tft": 1.8874, "input_0": 39, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.8, "mem_use": 44.24, "gen_rate": 4.2, "speed": 3.46, "text": "\"Don't worry, it's all part of t"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 1.1914, "t1": 0.2757, "tft": 2.2651, "input_0": 40, "input_1": 17, "min_CLP": -3.43, "draft_iters": 9.1, "mem_use": 44.13, "gen_rate": 4.6, "speed": 3.11, "text": "`npm init -y` is used to initial"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.2, "tree_w": 3, "tree_size": 16, "t0": 0.9967, "t1": 0.2917, "tft": 2.756, "input_0": 44, "input_1": 17, "min_CLP": -2.92, "draft_iters": 7.2, "mem_use": 45.71, "gen_rate": 6.0, "speed": 4.66, "text": "There are a few examples of citi"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 1.0629, "t1": 0.2914, "tft": 3.2255, "input_0": 44, "input_1": 17, "min_CLP": -3.04, "draft_iters": 7.9, "mem_use": 45.23, "gen_rate": 4.6, "speed": 3.38, "text": "Freeman Dyson was known for defe"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 1.0, "t1": 0.2778, "tft": 1.4032, "input_0": 43, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.3, "mem_use": 44.08, "gen_rate": 3.6, "speed": 2.78, "text": "\"Certainly! I can help you with "}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 9.5, "tree_w": 2, "tree_size": 16, "t0": 1.36, "t1": 0.28, "tft": 2.5756, "input_0": 48, "input_1": 17, "min_CLP": -3.41, "draft_iters": 10.5, "mem_use": 44.82, "gen_rate": 3.5, "speed": 2.13, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.0, "tree_w": 2, "tree_size": 16, "t0": 1.9133, "t1": 0.2933, "tft": 2.8582, "input_0": 53, "input_1": 17, "min_CLP": -1.97, "draft_iters": 15.0, "mem_use": 45.43, "gen_rate": 11.7, "speed": 5.29, "text": "Sure, here are the complete lyri"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.164, "t1": 0.278, "tft": 1.7557, "input_0": 41, "input_1": 17, "min_CLP": -3.64, "draft_iters": 8.8, "mem_use": 44.45, "gen_rate": 6.6, "speed": 4.57, "text": "1.    Work pressure and job inse"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.9314, "t1": 0.2786, "tft": 1.5132, "input_0": 39, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.9, "mem_use": 44.12, "gen_rate": 5.6, "speed": 4.6, "text": "\"Here's a simple explanation of "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 1.0257, "t1": 0.2843, "tft": 1.8913, "input_0": 41, "input_1": 17, "min_CLP": -3.06, "draft_iters": 7.6, "mem_use": 44.68, "gen_rate": 4.7, "speed": 3.6, "text": "Tensorflow and PyTorch are both "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.95, "t1": 0.285, "tft": 2.5886, "input_0": 41, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.9, "mem_use": 45.12, "gen_rate": 4.5, "speed": 3.64, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 3, "tree_size": 16, "t0": 1.395, "t1": 0.2825, "tft": 2.5103, "input_0": 50, "input_1": 17, "min_CLP": -3.31, "draft_iters": 10.5, "mem_use": 44.79, "gen_rate": 9.8, "speed": 5.81, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.205, "t1": 0.295, "tft": 3.8622, "input_0": 65, "input_1": 17, "min_CLP": -1.52, "draft_iters": 17.0, "mem_use": 46.92, "gen_rate": 17.0, "speed": 6.8, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 1.0113, "t1": 0.3037, "tft": 4.8794, "input_0": 42, "input_1": 17, "min_CLP": -3.32, "draft_iters": 7.4, "mem_use": 48.49, "gen_rate": 4.5, "speed": 3.42, "text": "\"I don't have personal experienc"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.9729, "t1": 0.2914, "tft": 2.6235, "input_0": 43, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.1, "mem_use": 45.49, "gen_rate": 4.7, "speed": 3.72, "text": "\"It's important to focus on your"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.5, "tree_w": 3, "tree_size": 16, "t0": 1.385, "t1": 0.2917, "tft": 2.9562, "input_0": 48, "input_1": 17, "min_CLP": -2.52, "draft_iters": 10.5, "mem_use": 45.88, "gen_rate": 5.5, "speed": 3.28, "text": "While all the reasons mentioned "}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 28, "tree_h": 10.5, "tree_w": 2, "tree_size": 16, "t0": 1.52, "t1": 0.2825, "tft": 1.9299, "input_0": 49, "input_1": 17, "min_CLP": -2.54, "draft_iters": 11.5, "mem_use": 44.12, "gen_rate": 7.0, "speed": 3.9, "text": "The difference between sets and "}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 1.214, "t1": 0.294, "tft": 2.7231, "input_0": 45, "input_1": 17, "min_CLP": -3.14, "draft_iters": 9.0, "mem_use": 45.45, "gen_rate": 7.4, "speed": 4.92, "text": "To calculate the number of days "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 2.16, "t1": 0.285, "tft": 1.9063, "input_0": 62, "input_1": 17, "min_CLP": -2.66, "draft_iters": 16.5, "mem_use": 44.28, "gen_rate": 16.5, "speed": 6.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 1.0443, "t1": 0.2786, "tft": 1.5004, "input_0": 42, "input_1": 17, "min_CLP": -3.22, "draft_iters": 7.9, "mem_use": 44.16, "gen_rate": 5.0, "speed": 3.78, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.9267, "t1": 0.2789, "tft": 1.5146, "input_0": 45, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.6, "mem_use": 44.15, "gen_rate": 3.6, "speed": 2.95, "text": "To farm experience quickly in Mi"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 28, "tree_h": 5.4, "tree_w": 4, "tree_size": 16, "t0": 0.8886, "t1": 0.2814, "tft": 1.2729, "input_0": 39, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.4, "mem_use": 44.1, "gen_rate": 4.0, "speed": 3.41, "text": "Hello, Freyja! I have a question"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 1.0129, "t1": 0.2929, "tft": 3.0716, "input_0": 39, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.6, "mem_use": 45.37, "gen_rate": 5.1, "speed": 3.94, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 1.31, "t1": 0.282, "tft": 1.9845, "input_0": 53, "input_1": 17, "min_CLP": -3.19, "draft_iters": 9.8, "mem_use": 44.5, "gen_rate": 6.8, "speed": 4.27, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.196, "t1": 0.306, "tft": 5.6725, "input_0": 51, "input_1": 17, "min_CLP": -3.14, "draft_iters": 9.0, "mem_use": 49.58, "gen_rate": 7.0, "speed": 4.65, "text": "Yes, the degree of sexual dimorp"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.8913, "t1": 0.2875, "tft": 1.8673, "input_0": 41, "input_1": 17, "min_CLP": -3.23, "draft_iters": 6.5, "mem_use": 44.63, "gen_rate": 4.2, "speed": 3.62, "text": "Large language models (LLMs) are"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.7857, "t1": 0.2843, "tft": 2.0113, "input_0": 34, "input_1": 17, "min_CLP": -3.76, "draft_iters": 5.9, "mem_use": 44.19, "gen_rate": 4.6, "speed": 4.27, "text": "\"Sure, here's a joke that might "}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.3, "tree_w": 3, "tree_size": 16, "t0": 1.3414, "t1": 0.2857, "tft": 2.179, "input_0": 47, "input_1": 17, "min_CLP": -2.94, "draft_iters": 10.3, "mem_use": 44.41, "gen_rate": 5.7, "speed": 3.52, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 1.1414, "t1": 0.2957, "tft": 2.8176, "input_0": 46, "input_1": 17, "min_CLP": -2.67, "draft_iters": 8.6, "mem_use": 45.88, "gen_rate": 5.3, "speed": 3.68, "text": "I hope this helps you get starte"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.9962, "t1": 0.2863, "tft": 1.9098, "input_0": 41, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.4, "mem_use": 44.27, "gen_rate": 4.9, "speed": 3.81, "text": "\"Yes, I am an AI model designed "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.15, "t1": 0.285, "tft": 1.904, "input_0": 62, "input_1": 17, "min_CLP": -3.35, "draft_iters": 17.0, "mem_use": 44.25, "gen_rate": 17.0, "speed": 6.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 1.2257, "t1": 0.2829, "tft": 1.4979, "input_0": 46, "input_1": 17, "min_CLP": -3.13, "draft_iters": 9.0, "mem_use": 44.08, "gen_rate": 4.9, "speed": 3.22, "text": "Mars is a planet in our solar sy"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 38, "tree_h": 6.6, "tree_w": 6, "tree_size": 16, "t0": 1.0, "t1": 0.2909, "tft": 3.3419, "input_0": 35, "input_1": 17, "min_CLP": -3.65, "draft_iters": 7.6, "mem_use": 46.32, "gen_rate": 3.5, "speed": 2.67, "text": "In Quenya, \"I love you\" can be e"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 1.38, "t1": 0.28, "tft": 2.0638, "input_0": 47, "input_1": 17, "min_CLP": -2.69, "draft_iters": 10.4, "mem_use": 44.17, "gen_rate": 6.8, "speed": 4.09, "text": "The book \"Harry Potter and the D"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.7386, "t1": 0.2857, "tft": 2.0234, "input_0": 31, "input_1": 17, "min_CLP": -3.55, "draft_iters": 5.6, "mem_use": 44.71, "gen_rate": 4.6, "speed": 4.47, "text": "\"The ATF does not restrict peopl"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0786, "t1": 0.2786, "tft": 1.8746, "input_0": 45, "input_1": 17, "min_CLP": -2.95, "draft_iters": 8.0, "mem_use": 44.17, "gen_rate": 4.7, "speed": 3.47, "text": "No, there is no known formula th"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.8822, "t1": 0.2867, "tft": 1.9756, "input_0": 36, "input_1": 17, "min_CLP": -3.34, "draft_iters": 6.4, "mem_use": 44.61, "gen_rate": 3.6, "speed": 3.05, "text": "\"I'd be happy to help you with t"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.9989, "t1": 0.2822, "tft": 1.7755, "input_0": 42, "input_1": 17, "min_CLP": -3.09, "draft_iters": 7.2, "mem_use": 44.28, "gen_rate": 3.8, "speed": 2.95, "text": "Before Canberra was established "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 2, "tree_size": 16, "t0": 1.9033, "t1": 0.28, "tft": 1.4795, "input_0": 56, "input_1": 17, "min_CLP": -3.23, "draft_iters": 15.0, "mem_use": 44.46, "gen_rate": 15.0, "speed": 6.87, "text": "write a eulogy for my 100 year o"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 1.1757, "t1": 0.2943, "tft": 3.3601, "input_0": 44, "input_1": 17, "min_CLP": -3.28, "draft_iters": 8.9, "mem_use": 46.69, "gen_rate": 5.6, "speed": 3.79, "text": "\"I'm sorry, but I cannot write a"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8263, "t1": 0.2825, "tft": 1.5306, "input_0": 36, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.1, "mem_use": 44.28, "gen_rate": 4.0, "speed": 3.6, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 2.125, "t1": 0.295, "tft": 2.7016, "input_0": 52, "input_1": 17, "min_CLP": -2.51, "draft_iters": 16.5, "mem_use": 45.57, "gen_rate": 16.0, "speed": 6.62, "text": "Let vector A be a vector with it"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.232, "t1": 0.278, "tft": 1.3984, "input_0": 49, "input_1": 17, "min_CLP": -2.96, "draft_iters": 9.2, "mem_use": 44.14, "gen_rate": 6.8, "speed": 4.5, "text": "Certainly! Here are some of the "}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.8044, "t1": 0.2789, "tft": 1.4941, "input_0": 36, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.8, "mem_use": 44.2, "gen_rate": 4.2, "speed": 3.9, "text": "I, a humble soul in the Elder Sc"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0867, "t1": 0.2817, "tft": 2.1634, "input_0": 42, "input_1": 17, "min_CLP": -3.0, "draft_iters": 8.0, "mem_use": 44.14, "gen_rate": 6.7, "speed": 4.88, "text": "L\u2019Hopital\u2019s Rule is a mathematic"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.7, "tree_w": 1, "tree_size": 16, "t0": 1.9067, "t1": 0.2833, "tft": 2.1312, "input_0": 52, "input_1": 17, "min_CLP": -2.33, "draft_iters": 14.7, "mem_use": 44.71, "gen_rate": 12.0, "speed": 5.48, "text": "Variance is the sum of all devia"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 14, "tree_h": 5.5, "tree_w": 4, "tree_size": 16, "t0": 0.86, "t1": 0.2825, "tft": 2.4441, "input_0": 34, "input_1": 17, "min_CLP": -3.46, "draft_iters": 6.5, "mem_use": 45.01, "gen_rate": 3.5, "speed": 3.06, "text": "\"Ride your way to wellness: Hipp"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 1.075, "t1": 0.2867, "tft": 2.0351, "input_0": 44, "input_1": 17, "min_CLP": -3.39, "draft_iters": 7.8, "mem_use": 44.79, "gen_rate": 6.0, "speed": 4.4, "text": "To see the best starry sky in th"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.6, "tree_w": 2, "tree_size": 16, "t0": 1.42, "t1": 0.278, "tft": 1.2809, "input_0": 51, "input_1": 17, "min_CLP": -3.37, "draft_iters": 10.6, "mem_use": 44.14, "gen_rate": 8.0, "speed": 4.71, "text": "\"Certainly! Here's a top 10 list"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 4, "tree_size": 16, "t0": 0.9333, "t1": 0.2867, "tft": 2.5997, "input_0": 40, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.7, "mem_use": 44.69, "gen_rate": 5.3, "speed": 4.37, "text": "If two eggs landed on a pillow, "}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 1.038, "t1": 0.286, "tft": 1.82, "input_0": 38, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.8, "mem_use": 44.56, "gen_rate": 6.6, "speed": 4.98, "text": "There are several ways to cope w"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9857, "t1": 0.2957, "tft": 4.3254, "input_0": 41, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.1, "mem_use": 47.65, "gen_rate": 4.6, "speed": 3.56, "text": "1. Establish clear objectives an"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 1.014, "t1": 0.29, "tft": 3.3153, "input_0": 43, "input_1": 17, "min_CLP": -2.89, "draft_iters": 7.4, "mem_use": 46.32, "gen_rate": 6.4, "speed": 4.91, "text": "It ultimately depends on your pe"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.935, "t1": 0.2762, "tft": 1.6193, "input_0": 36, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.0, "mem_use": 44.1, "gen_rate": 4.2, "speed": 3.5, "text": "\"I can't calculate how many days"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.1, "tree_w": 5, "tree_size": 16, "t0": 1.1257, "t1": 0.2857, "tft": 1.7118, "input_0": 46, "input_1": 17, "min_CLP": -3.62, "draft_iters": 8.1, "mem_use": 44.35, "gen_rate": 5.3, "speed": 3.74, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9386, "t1": 0.32, "tft": 7.6092, "input_0": 43, "input_1": 17, "min_CLP": -3.06, "draft_iters": 7.0, "mem_use": 51.18, "gen_rate": 5.0, "speed": 3.98, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 1.045, "t1": 0.284, "tft": 3.121, "input_0": 42, "input_1": 17, "min_CLP": -2.97, "draft_iters": 7.7, "mem_use": 44.52, "gen_rate": 3.7, "speed": 2.79, "text": "\"Yes, you can use a decorator wi"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.7967, "t1": 0.2833, "tft": 1.5227, "input_0": 51, "input_1": 17, "min_CLP": -2.75, "draft_iters": 14.0, "mem_use": 44.23, "gen_rate": 14.0, "speed": 6.73, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.9325, "t1": 0.2775, "tft": 1.5079, "input_0": 41, "input_1": 17, "min_CLP": -3.12, "draft_iters": 6.9, "mem_use": 44.23, "gen_rate": 4.1, "speed": 3.41, "text": "\"Sure, I can help with that! In "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.892, "t1": 0.294, "tft": 3.5403, "input_0": 39, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.5, "mem_use": 46.77, "gen_rate": 3.2, "speed": 2.7, "text": "\"I'm sorry if my previous respon"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 1.218, "t1": 0.284, "tft": 2.6974, "input_0": 44, "input_1": 17, "min_CLP": -2.9, "draft_iters": 9.2, "mem_use": 44.65, "gen_rate": 7.2, "speed": 4.8, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.7, "tree_w": 2, "tree_size": 16, "t0": 1.7133, "t1": 0.28, "tft": 2.345, "input_0": 60, "input_1": 17, "min_CLP": -3.78, "draft_iters": 12.7, "mem_use": 44.84, "gen_rate": 12.0, "speed": 6.02, "text": "\"What is the airspeed velocity o"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.9009, "t1": 0.2855, "tft": 1.7719, "input_0": 37, "input_1": 17, "min_CLP": -2.95, "draft_iters": 6.6, "mem_use": 44.43, "gen_rate": 3.1, "speed": 2.6, "text": "\"Sure! Stable diffusion is a typ"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 1.2233, "t1": 0.29, "tft": 2.0055, "input_0": 41, "input_1": 17, "min_CLP": -3.88, "draft_iters": 9.2, "mem_use": 44.68, "gen_rate": 6.7, "speed": 4.4, "text": "Attention bias, transformer bias"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.8288, "t1": 0.2875, "tft": 2.2508, "input_0": 32, "input_1": 17, "min_CLP": -3.7, "draft_iters": 6.0, "mem_use": 44.46, "gen_rate": 4.0, "speed": 3.58, "text": "The state of the cat is uncertai"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 5, "tree_size": 16, "t0": 0.7875, "t1": 0.2975, "tft": 3.3146, "input_0": 34, "input_1": 17, "min_CLP": -3.21, "draft_iters": 5.5, "mem_use": 46.44, "gen_rate": 4.0, "speed": 3.69, "text": "\"Based on your symptoms and tole"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.0714, "t1": 0.2829, "tft": 2.3997, "input_0": 38, "input_1": 17, "min_CLP": -3.32, "draft_iters": 8.0, "mem_use": 44.22, "gen_rate": 4.6, "speed": 3.38, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 3, "tree_size": 16, "t0": 1.53, "t1": 0.278, "tft": 1.8668, "input_0": 54, "input_1": 17, "min_CLP": -3.27, "draft_iters": 11.8, "mem_use": 44.24, "gen_rate": 6.8, "speed": 3.76, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfEn"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.6, "tree_w": 5, "tree_size": 16, "t0": 0.7836, "t1": 0.2836, "tft": 2.1636, "input_0": 34, "input_1": 17, "min_CLP": -3.48, "draft_iters": 5.6, "mem_use": 44.22, "gen_rate": 3.2, "speed": 2.98, "text": "F-centers are defects in a cryst"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 8.4, "tree_w": 4, "tree_size": 16, "t0": 1.24, "t1": 0.3, "tft": 5.3106, "input_0": 44, "input_1": 17, "min_CLP": -3.47, "draft_iters": 9.4, "mem_use": 48.78, "gen_rate": 8.8, "speed": 5.73, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 1.1617, "t1": 0.29, "tft": 3.0247, "input_0": 44, "input_1": 17, "min_CLP": -3.15, "draft_iters": 8.8, "mem_use": 45.86, "gen_rate": 5.8, "speed": 4.03, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.84, "t1": 0.2838, "tft": 1.7434, "input_0": 36, "input_1": 17, "min_CLP": -3.56, "draft_iters": 6.2, "mem_use": 44.65, "gen_rate": 4.1, "speed": 3.68, "text": "I think the replacement of human"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 1.0183, "t1": 0.29, "tft": 3.8427, "input_0": 44, "input_1": 17, "min_CLP": -3.0, "draft_iters": 7.3, "mem_use": 46.55, "gen_rate": 6.2, "speed": 4.72, "text": "Breeding animals in Minecraft is"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9637, "t1": 0.2913, "tft": 3.5815, "input_0": 43, "input_1": 17, "min_CLP": -3.36, "draft_iters": 7.1, "mem_use": 46.51, "gen_rate": 4.5, "speed": 3.59, "text": "Die Zementproduktion hat einen h"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.8929, "t1": 0.2929, "tft": 3.0603, "input_0": 40, "input_1": 17, "min_CLP": -3.28, "draft_iters": 6.6, "mem_use": 45.86, "gen_rate": 4.7, "speed": 3.99, "text": "I apologize for the confusion, b"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8237, "t1": 0.28, "tft": 2.4559, "input_0": 34, "input_1": 17, "min_CLP": -3.6, "draft_iters": 6.1, "mem_use": 44.89, "gen_rate": 4.5, "speed": 4.07, "text": "It depends on the situation. If "}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 1.91, "t1": 0.2833, "tft": 1.5915, "input_0": 59, "input_1": 17, "min_CLP": -3.15, "draft_iters": 14.7, "mem_use": 44.48, "gen_rate": 14.7, "speed": 6.69, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u7684\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1a\\n1. Vaswani"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 2, "tree_size": 16, "t0": 1.6633, "t1": 0.2767, "tft": 1.8776, "input_0": 59, "input_1": 17, "min_CLP": -2.04, "draft_iters": 12.3, "mem_use": 44.28, "gen_rate": 11.0, "speed": 5.66, "text": "\"Here's a JavaScript function th"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9563, "t1": 0.2925, "tft": 3.1191, "input_0": 39, "input_1": 17, "min_CLP": -3.02, "draft_iters": 7.1, "mem_use": 45.57, "gen_rate": 4.0, "speed": 3.21, "text": "It is illegal to be naked in pub"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.87, "t1": 0.285, "tft": 1.9929, "input_0": 38, "input_1": 17, "min_CLP": -3.3, "draft_iters": 6.3, "mem_use": 44.68, "gen_rate": 3.8, "speed": 3.29, "text": "How about you write the poem dow"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.8475, "t1": 0.2938, "tft": 3.057, "input_0": 39, "input_1": 17, "min_CLP": -3.25, "draft_iters": 6.1, "mem_use": 45.56, "gen_rate": 4.0, "speed": 3.51, "text": "The optimal thickness for mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 4, "tree_size": 16, "t0": 1.332, "t1": 0.284, "tft": 2.42, "input_0": 45, "input_1": 17, "min_CLP": -2.61, "draft_iters": 10.0, "mem_use": 44.94, "gen_rate": 7.0, "speed": 4.33, "text": "In that case, if you live in a E"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 4, "tree_size": 16, "t0": 1.1967, "t1": 0.28, "tft": 1.8736, "input_0": 38, "input_1": 17, "min_CLP": -3.59, "draft_iters": 9.3, "mem_use": 44.2, "gen_rate": 5.5, "speed": 3.72, "text": "def generate_nicknames():\\n    n"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 1.076, "t1": 0.286, "tft": 2.3692, "input_0": 41, "input_1": 17, "min_CLP": -3.11, "draft_iters": 8.0, "mem_use": 44.61, "gen_rate": 6.6, "speed": 4.85, "text": "\"Yes, the Balfour Declaration wa"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 2, "tree_size": 16, "t0": 1.56, "t1": 0.2967, "tft": 3.9197, "input_0": 47, "input_1": 17, "min_CLP": -2.99, "draft_iters": 12.0, "mem_use": 45.37, "gen_rate": 12.0, "speed": 6.48, "text": "\"Canciones felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 2, "tree_size": 16, "t0": 1.468, "t1": 0.288, "tft": 1.5313, "input_0": 53, "input_1": 17, "min_CLP": -2.45, "draft_iters": 11.0, "mem_use": 44.3, "gen_rate": 7.0, "speed": 3.99, "text": "Here is a table with the average"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 10.4, "tree_w": 3, "tree_size": 16, "t0": 1.51, "t1": 0.284, "tft": 1.8569, "input_0": 48, "input_1": 17, "min_CLP": -2.72, "draft_iters": 11.4, "mem_use": 44.7, "gen_rate": 9.2, "speed": 5.13, "text": "Oh, I apologize for that! Here i"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 21, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.738, "t1": 0.284, "tft": 2.56, "input_0": 30, "input_1": 17, "min_CLP": -3.52, "draft_iters": 5.5, "mem_use": 45.07, "gen_rate": 2.1, "speed": 2.05, "text": "Sure! How about, \"Wish like the "}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 3, "tree_size": 16, "t0": 1.405, "t1": 0.29, "tft": 3.3813, "input_0": 53, "input_1": 17, "min_CLP": -2.69, "draft_iters": 10.7, "mem_use": 45.83, "gen_rate": 5.7, "speed": 3.35, "text": "Building a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.9414, "t1": 0.28, "tft": 2.4163, "input_0": 40, "input_1": 17, "min_CLP": -3.21, "draft_iters": 7.0, "mem_use": 44.31, "gen_rate": 4.9, "speed": 3.98, "text": "Frank-Walter Steinmeier (born 20"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.13, "t1": 0.275, "tft": 1.509, "input_0": 61, "input_1": 17, "min_CLP": -2.53, "draft_iters": 17.0, "mem_use": 44.23, "gen_rate": 17.0, "speed": 7.07, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 1.0133, "t1": 0.3, "tft": 4.8427, "input_0": 42, "input_1": 17, "min_CLP": -3.21, "draft_iters": 7.4, "mem_use": 48.36, "gen_rate": 4.0, "speed": 3.05, "text": "1. **Discovery:**\\n   - Identify"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.9633, "t1": 0.28, "tft": 2.0333, "input_0": 59, "input_1": 17, "min_CLP": -1.83, "draft_iters": 15.3, "mem_use": 44.13, "gen_rate": 12.3, "speed": 5.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 3, "tree_size": 16, "t0": 1.8367, "t1": 0.2867, "tft": 1.6321, "input_0": 58, "input_1": 17, "min_CLP": -2.06, "draft_iters": 14.3, "mem_use": 44.09, "gen_rate": 12.3, "speed": 5.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 1.36, "t1": 0.3, "tft": 4.7152, "input_0": 50, "input_1": 17, "min_CLP": -2.94, "draft_iters": 10.0, "mem_use": 48.36, "gen_rate": 6.0, "speed": 3.63, "text": "Hey there! How can I assist you "}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.9343, "t1": 0.2914, "tft": 2.8394, "input_0": 38, "input_1": 17, "min_CLP": -3.68, "draft_iters": 6.9, "mem_use": 46.16, "gen_rate": 4.7, "speed": 3.85, "text": "\u2022 Make it a part of your daily r"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.9429, "t1": 0.29, "tft": 2.5956, "input_0": 39, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.0, "mem_use": 45.41, "gen_rate": 4.7, "speed": 3.81, "text": "You are right, it is possible to"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.8867, "t1": 0.2811, "tft": 1.8643, "input_0": 32, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.8, "mem_use": 44.28, "gen_rate": 3.8, "speed": 3.24, "text": "noted\\n[INST] Please list the to"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.9067, "t1": 0.2778, "tft": 1.7757, "input_0": 37, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.8, "mem_use": 44.3, "gen_rate": 4.0, "speed": 3.38, "text": "In the context of the game Into "}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 1.2022, "t1": 0.2833, "tft": 2.8475, "input_0": 45, "input_1": 17, "min_CLP": -2.97, "draft_iters": 9.1, "mem_use": 45.12, "gen_rate": 3.8, "speed": 2.54, "text": "[API_REQUEST]: curl -X GET https"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 8.9, "tree_w": 3, "tree_size": 16, "t0": 1.2913, "t1": 0.2912, "tft": 2.7929, "input_0": 43, "input_1": 17, "min_CLP": -2.65, "draft_iters": 9.9, "mem_use": 45.65, "gen_rate": 4.9, "speed": 3.08, "text": "Here is a simpler script to find"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.9833, "t1": 0.2856, "tft": 2.1719, "input_0": 42, "input_1": 17, "min_CLP": -3.57, "draft_iters": 7.1, "mem_use": 45.07, "gen_rate": 3.8, "speed": 2.97, "text": "\"Hello! How can I help you today"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.225, "t1": 0.285, "tft": 2.9645, "input_0": 58, "input_1": 17, "min_CLP": -3.1, "draft_iters": 17.0, "mem_use": 45.18, "gen_rate": 17.0, "speed": 6.77, "text": "\"Of all the joys in life that I "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.879, "t1": 0.282, "tft": 2.2443, "input_0": 36, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.4, "mem_use": 44.58, "gen_rate": 3.6, "speed": 3.1, "text": "\"The airspeed velocity of a Euro"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 1.0117, "t1": 0.285, "tft": 2.4775, "input_0": 41, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.5, "mem_use": 44.54, "gen_rate": 5.7, "speed": 4.38, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9486, "t1": 0.2971, "tft": 3.0477, "input_0": 41, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.1, "mem_use": 45.87, "gen_rate": 5.0, "speed": 4.02, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.9543, "t1": 0.2971, "tft": 3.0388, "input_0": 40, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.1, "mem_use": 45.79, "gen_rate": 4.7, "speed": 3.77, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 3, "tree_size": 16, "t0": 1.0433, "t1": 0.2933, "tft": 4.8811, "input_0": 43, "input_1": 17, "min_CLP": -2.9, "draft_iters": 7.7, "mem_use": 47.26, "gen_rate": 5.3, "speed": 3.99, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 2.195, "t1": 0.285, "tft": 1.6043, "input_0": 62, "input_1": 17, "min_CLP": -3.09, "draft_iters": 17.0, "mem_use": 44.09, "gen_rate": 17.0, "speed": 6.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.756, "t1": 0.282, "tft": 2.6227, "input_0": 33, "input_1": 17, "min_CLP": -3.68, "draft_iters": 5.4, "mem_use": 45.01, "gen_rate": 3.4, "speed": 3.27, "text": "PostCSS is a tool that transform"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.3, "tree_w": 4, "tree_size": 16, "t0": 1.55, "t1": 0.29, "tft": 4.1815, "input_0": 41, "input_1": 17, "min_CLP": -3.57, "draft_iters": 12.3, "mem_use": 46.91, "gen_rate": 11.7, "speed": 6.33, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.5, "tree_w": 3, "tree_size": 16, "t0": 1.3483, "t1": 0.28, "tft": 1.9579, "input_0": 46, "input_1": 17, "min_CLP": -3.02, "draft_iters": 10.5, "mem_use": 44.6, "gen_rate": 5.5, "speed": 3.37, "text": "The Contrarian Nature of Sufferi"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 1.09, "t1": 0.29, "tft": 3.569, "input_0": 43, "input_1": 17, "min_CLP": -3.42, "draft_iters": 8.2, "mem_use": 45.46, "gen_rate": 5.5, "speed": 3.99, "text": "I apologize for the confusion. H"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 16, "max_branch_width": 32, "gen_rate": 6.37, "gen_rate_micro": 5.37, "gen_speed": 4.196, "gen_speed_micro": 4.009, "t0": 1.1592, "t1": 0.2869, "input_0": 43.2, "input_1": 17.0, "tree_size": 16.0, "tree_w": 4.0, "tree_h": 7.7, "prompt_len": 298.0, "min_CLP": -3.19, "mem_use": 53.57, "exp_time": 5996.02}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 1.2043, "t1": 0.2943, "tft": 2.2929, "input_0": 94, "input_1": 33, "min_CLP": -4.09, "draft_iters": 8.7, "mem_use": 44.18, "gen_rate": 5.0, "speed": 3.34, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 6, "tree_size": 32, "t0": 1.62, "t1": 0.3, "tft": 3.3203, "input_0": 95, "input_1": 33, "min_CLP": -3.82, "draft_iters": 12.2, "mem_use": 45.73, "gen_rate": 6.6, "speed": 3.44, "text": "You are correct; my apologies fo"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 1.1114, "t1": 0.3057, "tft": 3.6418, "input_0": 82, "input_1": 33, "min_CLP": -4.2, "draft_iters": 8.0, "mem_use": 46.63, "gen_rate": 5.0, "speed": 3.53, "text": "1. Minecraft: Minecraft is a san"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 16.7, "tree_w": 4, "tree_size": 32, "t0": 2.2967, "t1": 0.2967, "tft": 3.225, "input_0": 126, "input_1": 33, "min_CLP": -3.69, "draft_iters": 17.7, "mem_use": 44.36, "gen_rate": 16.0, "speed": 6.17, "text": "\"```python\\nimport sympy as sp\\n"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.3643, "t1": 0.29, "tft": 2.0859, "input_0": 103, "input_1": 33, "min_CLP": -3.79, "draft_iters": 10.0, "mem_use": 44.2, "gen_rate": 5.1, "speed": 3.11, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 1.2714, "t1": 0.3057, "tft": 4.8305, "input_0": 91, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.3, "mem_use": 46.76, "gen_rate": 4.9, "speed": 3.08, "text": "1. Introduction: Define what \"li"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 1.675, "t1": 0.3075, "tft": 4.8514, "input_0": 117, "input_1": 33, "min_CLP": -3.42, "draft_iters": 12.0, "mem_use": 47.35, "gen_rate": 8.0, "speed": 4.03, "text": "There are a variety of other opt"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 1.44, "t1": 0.324, "tft": 5.3689, "input_0": 113, "input_1": 33, "min_CLP": -3.53, "draft_iters": 10.2, "mem_use": 49.53, "gen_rate": 7.4, "speed": 4.19, "text": "To attract the right customers f"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 1.5575, "t1": 0.305, "tft": 4.2176, "input_0": 106, "input_1": 33, "min_CLP": -3.71, "draft_iters": 11.2, "mem_use": 46.96, "gen_rate": 8.2, "speed": 4.42, "text": "\"I'm sorry, as an AI language mo"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 5, "tree_size": 32, "t0": 1.4925, "t1": 0.3075, "tft": 4.0262, "input_0": 116, "input_1": 33, "min_CLP": -3.5, "draft_iters": 10.8, "mem_use": 46.33, "gen_rate": 8.5, "speed": 4.72, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 60, "tree_h": 18.8, "tree_w": 5, "tree_size": 32, "t0": 2.5825, "t1": 0.3025, "tft": 3.5327, "input_0": 110, "input_1": 33, "min_CLP": -3.51, "draft_iters": 19.8, "mem_use": 44.86, "gen_rate": 15.0, "speed": 5.2, "text": "Here is a revised version of you"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 1.41, "t1": 0.3083, "tft": 3.8789, "input_0": 101, "input_1": 33, "min_CLP": -3.52, "draft_iters": 10.2, "mem_use": 46.7, "gen_rate": 5.5, "speed": 3.2, "text": "Here is a shorter version:\\n\\n\"F"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 12.2, "tree_w": 6, "tree_size": 32, "t0": 1.84, "t1": 0.31, "tft": 3.2265, "input_0": 114, "input_1": 33, "min_CLP": -3.5, "draft_iters": 13.2, "mem_use": 45.92, "gen_rate": 10.5, "speed": 4.89, "text": "\"Sure! Here's an example Python "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 18.0, "tree_w": 9, "tree_size": 32, "t0": 2.32, "t1": 0.3, "tft": 2.2229, "input_0": 68, "input_1": 33, "min_CLP": -4.45, "draft_iters": 18.5, "mem_use": 44.18, "gen_rate": 19.0, "speed": 7.26, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.5, "tree_w": 7, "tree_size": 32, "t0": 1.36, "t1": 0.3083, "tft": 4.5435, "input_0": 103, "input_1": 33, "min_CLP": -3.73, "draft_iters": 9.5, "mem_use": 47.32, "gen_rate": 6.3, "speed": 3.8, "text": "\"If you're finding it challengin"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.7, "tree_w": 5, "tree_size": 32, "t0": 1.6233, "t1": 0.2967, "tft": 2.7049, "input_0": 104, "input_1": 33, "min_CLP": -3.35, "draft_iters": 11.7, "mem_use": 44.52, "gen_rate": 11.0, "speed": 5.73, "text": "To determine the minimum broadba"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 4, "tree_size": 32, "t0": 1.8267, "t1": 0.2967, "tft": 2.3628, "input_0": 119, "input_1": 33, "min_CLP": -3.46, "draft_iters": 13.3, "mem_use": 44.2, "gen_rate": 13.3, "speed": 6.28, "text": "\"Sure! Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 3.87, "t1": 0.29, "tft": 1.7042, "input_0": 125, "input_1": 33, "min_CLP": -3.6, "draft_iters": 32.0, "mem_use": 44.18, "gen_rate": 32.0, "speed": 7.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 24.0, "tree_w": 2, "tree_size": 32, "t0": 3.1467, "t1": 0.2967, "tft": 2.834, "input_0": 127, "input_1": 33, "min_CLP": -3.23, "draft_iters": 24.7, "mem_use": 44.72, "gen_rate": 20.0, "speed": 5.8, "text": "D-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.5, "tree_w": 4, "tree_size": 32, "t0": 1.715, "t1": 0.29, "tft": 2.6481, "input_0": 111, "input_1": 33, "min_CLP": -4.0, "draft_iters": 12.5, "mem_use": 44.19, "gen_rate": 8.2, "speed": 4.11, "text": "\"The Balfour Declaration was a l"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 6.4, "tree_w": 11, "tree_size": 32, "t0": 1.05, "t1": 0.302, "tft": 2.5726, "input_0": 86, "input_1": 33, "min_CLP": -4.75, "draft_iters": 7.4, "mem_use": 45.04, "gen_rate": 4.4, "speed": 3.25, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 19, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 1.28, "t1": 0.2983, "tft": 1.6418, "input_0": 82, "input_1": 33, "min_CLP": -4.05, "draft_iters": 9.2, "mem_use": 44.18, "gen_rate": 3.2, "speed": 2.01, "text": "\"Hello there! I'm not sure I und"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 1.4243, "t1": 0.3071, "tft": 4.3658, "input_0": 106, "input_1": 33, "min_CLP": -3.55, "draft_iters": 10.0, "mem_use": 46.55, "gen_rate": 4.9, "speed": 2.8, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.2, "tree_w": 4, "tree_size": 32, "t0": 1.765, "t1": 0.29, "tft": 2.0813, "input_0": 107, "input_1": 33, "min_CLP": -3.87, "draft_iters": 13.2, "mem_use": 44.26, "gen_rate": 8.5, "speed": 4.14, "text": "Certainly! Here is a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.3, "tree_w": 8, "tree_size": 32, "t0": 1.4414, "t1": 0.3071, "tft": 3.4575, "input_0": 97, "input_1": 33, "min_CLP": -4.02, "draft_iters": 10.3, "mem_use": 45.23, "gen_rate": 5.1, "speed": 2.95, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.225, "t1": 0.2967, "tft": 2.0852, "input_0": 86, "input_1": 33, "min_CLP": -4.08, "draft_iters": 9.0, "mem_use": 44.23, "gen_rate": 5.3, "speed": 3.5, "text": "Nietzsche\\'s ideas are still rel"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 9, "tree_size": 32, "t0": 1.0283, "t1": 0.3, "tft": 3.3198, "input_0": 81, "input_1": 33, "min_CLP": -4.12, "draft_iters": 7.5, "mem_use": 44.9, "gen_rate": 5.3, "speed": 4.02, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.76, "t1": 0.29, "tft": 2.7547, "input_0": 142, "input_1": 33, "min_CLP": -3.83, "draft_iters": 12.0, "mem_use": 44.75, "gen_rate": 9.0, "speed": 4.39, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 61, "tree_h": 19.3, "tree_w": 5, "tree_size": 32, "t0": 2.4967, "t1": 0.3033, "tft": 3.606, "input_0": 91, "input_1": 33, "min_CLP": -4.18, "draft_iters": 20.0, "mem_use": 46.69, "gen_rate": 20.3, "speed": 7.25, "text": "\"La, la, la, la, la, la, la, la,"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 1.464, "t1": 0.29, "tft": 1.4188, "input_0": 98, "input_1": 33, "min_CLP": -4.13, "draft_iters": 10.8, "mem_use": 44.23, "gen_rate": 7.6, "speed": 4.34, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.3, "tree_w": 6, "tree_size": 32, "t0": 1.3886, "t1": 0.3014, "tft": 3.3532, "input_0": 95, "input_1": 33, "min_CLP": -3.67, "draft_iters": 10.3, "mem_use": 44.94, "gen_rate": 4.6, "speed": 2.7, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.5, "tree_w": 8, "tree_size": 32, "t0": 1.6367, "t1": 0.3, "tft": 2.6061, "input_0": 94, "input_1": 33, "min_CLP": -4.18, "draft_iters": 12.3, "mem_use": 45.35, "gen_rate": 5.3, "speed": 2.75, "text": "[Mathematical questions]: {How c"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.9586, "t1": 0.2957, "tft": 1.8959, "input_0": 84, "input_1": 33, "min_CLP": -4.2, "draft_iters": 6.7, "mem_use": 44.69, "gen_rate": 4.7, "speed": 3.75, "text": "In the name of love and fertilit"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 1.0571, "t1": 0.3029, "tft": 3.502, "input_0": 77, "input_1": 33, "min_CLP": -3.93, "draft_iters": 7.7, "mem_use": 46.35, "gen_rate": 4.7, "speed": 3.47, "text": "There are many substitutes for c"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.4775, "t1": 0.3025, "tft": 3.7768, "input_0": 106, "input_1": 33, "min_CLP": -3.76, "draft_iters": 11.0, "mem_use": 46.39, "gen_rate": 8.8, "speed": 4.92, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 1.5725, "t1": 0.32, "tft": 6.4612, "input_0": 119, "input_1": 33, "min_CLP": -3.67, "draft_iters": 11.2, "mem_use": 49.12, "gen_rate": 8.8, "speed": 4.62, "text": "Selenium may be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 1.1757, "t1": 0.29, "tft": 2.2398, "input_0": 81, "input_1": 33, "min_CLP": -4.22, "draft_iters": 8.7, "mem_use": 44.21, "gen_rate": 4.9, "speed": 3.32, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 24.7, "tree_w": 3, "tree_size": 32, "t0": 3.26, "t1": 0.2967, "tft": 3.9067, "input_0": 127, "input_1": 33, "min_CLP": -3.72, "draft_iters": 25.7, "mem_use": 44.75, "gen_rate": 16.0, "speed": 4.5, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 8, "tree_size": 32, "t0": 1.2543, "t1": 0.3043, "tft": 4.2596, "input_0": 94, "input_1": 33, "min_CLP": -3.83, "draft_iters": 9.3, "mem_use": 47.12, "gen_rate": 4.7, "speed": 3.02, "text": "Of course, I can try to act like"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.4, "tree_w": 5, "tree_size": 32, "t0": 1.536, "t1": 0.294, "tft": 3.5389, "input_0": 103, "input_1": 33, "min_CLP": -3.73, "draft_iters": 11.4, "mem_use": 45.15, "gen_rate": 8.0, "speed": 4.37, "text": "The Copenhagen interpretation of"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.9033, "t1": 0.2911, "tft": 1.5313, "input_0": 76, "input_1": 33, "min_CLP": -4.66, "draft_iters": 6.6, "mem_use": 44.44, "gen_rate": 4.0, "speed": 3.35, "text": "Foolish mortal. My power is not "}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 2, "tree_size": 32, "t0": 3.915, "t1": 0.3, "tft": 5.6717, "input_0": 129, "input_1": 33, "min_CLP": -3.2, "draft_iters": 31.0, "mem_use": 46.94, "gen_rate": 31.5, "speed": 7.47, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 21.0, "tree_w": 6, "tree_size": 32, "t0": 2.63, "t1": 0.31, "tft": 4.1232, "input_0": 91, "input_1": 33, "min_CLP": -3.91, "draft_iters": 21.5, "mem_use": 47.38, "gen_rate": 22.0, "speed": 7.49, "text": "\"Certainly! It sounds like you a"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.5433, "t1": 0.3067, "tft": 3.0724, "input_0": 135, "input_1": 33, "min_CLP": -3.7, "draft_iters": 11.0, "mem_use": 45.72, "gen_rate": 10.7, "speed": 5.75, "text": "Choosing the \"best\" SAST tool ca"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 14.0, "tree_w": 5, "tree_size": 32, "t0": 2.05, "t1": 0.3, "tft": 3.4856, "input_0": 141, "input_1": 33, "min_CLP": -3.54, "draft_iters": 15.0, "mem_use": 44.97, "gen_rate": 11.0, "speed": 4.68, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 8.7, "tree_w": 11, "tree_size": 32, "t0": 1.275, "t1": 0.295, "tft": 3.4659, "input_0": 75, "input_1": 33, "min_CLP": -4.68, "draft_iters": 9.7, "mem_use": 44.71, "gen_rate": 7.5, "speed": 4.78, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.0, "tree_w": 5, "tree_size": 32, "t0": 1.875, "t1": 0.2925, "tft": 2.9341, "input_0": 124, "input_1": 33, "min_CLP": -3.65, "draft_iters": 14.0, "mem_use": 44.22, "gen_rate": 10.0, "speed": 4.61, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 57, "tree_h": 15.2, "tree_w": 5, "tree_size": 32, "t0": 2.132, "t1": 0.326, "tft": 6.202, "input_0": 123, "input_1": 33, "min_CLP": -3.65, "draft_iters": 16.2, "mem_use": 49.67, "gen_rate": 11.4, "speed": 4.64, "text": "\"Alright, I'll try to amp up the"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 13, "tree_size": 32, "t0": 0.7612, "t1": 0.3037, "tft": 2.7482, "input_0": 60, "input_1": 33, "min_CLP": -4.87, "draft_iters": 5.5, "mem_use": 45.96, "gen_rate": 4.0, "speed": 3.75, "text": "I saw it with my own eyes, the d"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 30, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.8063, "t1": 0.3013, "tft": 2.0217, "input_0": 60, "input_1": 33, "min_CLP": -4.58, "draft_iters": 5.9, "mem_use": 44.98, "gen_rate": 3.8, "speed": 3.38, "text": "I hope you understand now. Also,"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 1.325, "t1": 0.3, "tft": 1.5023, "input_0": 101, "input_1": 33, "min_CLP": -3.65, "draft_iters": 10.0, "mem_use": 44.49, "gen_rate": 8.0, "speed": 4.92, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.8, "tree_w": 4, "tree_size": 32, "t0": 2.1125, "t1": 0.3075, "tft": 4.3027, "input_0": 121, "input_1": 33, "min_CLP": -3.54, "draft_iters": 15.8, "mem_use": 46.39, "gen_rate": 9.8, "speed": 4.03, "text": "F-centers, or color centers, are"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 4, "tree_size": 32, "t0": 2.04, "t1": 0.3067, "tft": 3.8771, "input_0": 133, "input_1": 33, "min_CLP": -3.59, "draft_iters": 15.0, "mem_use": 45.6, "gen_rate": 10.7, "speed": 4.54, "text": "In addition to the events mentio"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 1.36, "t1": 0.3033, "tft": 3.7377, "input_0": 97, "input_1": 33, "min_CLP": -3.81, "draft_iters": 9.8, "mem_use": 45.94, "gen_rate": 6.3, "speed": 3.81, "text": "Yes, technology has the potentia"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 1.2163, "t1": 0.2975, "tft": 1.7519, "input_0": 92, "input_1": 33, "min_CLP": -3.87, "draft_iters": 8.8, "mem_use": 44.39, "gen_rate": 4.1, "speed": 2.72, "text": "In real life, there is no specif"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.5, "tree_w": 8, "tree_size": 32, "t0": 1.455, "t1": 0.3125, "tft": 4.2282, "input_0": 92, "input_1": 33, "min_CLP": -3.98, "draft_iters": 10.5, "mem_use": 46.79, "gen_rate": 8.0, "speed": 4.53, "text": "\"Certainly! Here's a pitch deck "}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.2417, "t1": 0.3183, "tft": 5.262, "input_0": 95, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.0, "mem_use": 48.05, "gen_rate": 5.3, "speed": 3.42, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 1.28, "t1": 0.314, "tft": 5.0875, "input_0": 98, "input_1": 33, "min_CLP": -3.65, "draft_iters": 9.0, "mem_use": 48.21, "gen_rate": 6.4, "speed": 4.01, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.7, "tree_w": 7, "tree_size": 32, "t0": 1.4243, "t1": 0.3057, "tft": 3.9352, "input_0": 83, "input_1": 33, "min_CLP": -3.91, "draft_iters": 10.7, "mem_use": 45.87, "gen_rate": 5.6, "speed": 3.22, "text": "\"My response is based on an anal"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 1.17, "t1": 0.298, "tft": 2.1643, "input_0": 85, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.6, "mem_use": 44.21, "gen_rate": 7.2, "speed": 4.9, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 5, "tree_size": 32, "t0": 1.788, "t1": 0.304, "tft": 3.2438, "input_0": 118, "input_1": 33, "min_CLP": -3.48, "draft_iters": 12.6, "mem_use": 46.62, "gen_rate": 6.8, "speed": 3.25, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 1.1333, "t1": 0.3083, "tft": 4.5019, "input_0": 89, "input_1": 33, "min_CLP": -3.83, "draft_iters": 8.0, "mem_use": 47.47, "gen_rate": 5.5, "speed": 3.82, "text": "[The general leads his army into"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.6, "tree_w": 9, "tree_size": 32, "t0": 0.9057, "t1": 0.3, "tft": 2.2131, "input_0": 73, "input_1": 33, "min_CLP": -4.03, "draft_iters": 6.6, "mem_use": 45.16, "gen_rate": 4.9, "speed": 4.03, "text": "I\\'m glad you liked it, and I un"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 4, "tree_size": 32, "t0": 2.75, "t1": 0.3, "tft": 3.0788, "input_0": 101, "input_1": 33, "min_CLP": -3.87, "draft_iters": 22.0, "mem_use": 44.88, "gen_rate": 22.5, "speed": 7.38, "text": "[INST] Please explain how the pr"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 4.05, "t1": 0.31, "tft": 2.2229, "input_0": 122, "input_1": 33, "min_CLP": -3.09, "draft_iters": 32.0, "mem_use": 45.0, "gen_rate": 33.0, "speed": 7.58, "text": "I am sorry to say that, but stop"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 1.272, "t1": 0.316, "tft": 4.0806, "input_0": 94, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.2, "mem_use": 47.08, "gen_rate": 6.4, "speed": 4.03, "text": "void pointers are a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 1.24, "t1": 0.314, "tft": 4.4271, "input_0": 98, "input_1": 33, "min_CLP": -4.05, "draft_iters": 9.0, "mem_use": 47.59, "gen_rate": 6.8, "speed": 4.38, "text": "\"I'm sorry to hear that you miss"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 1.425, "t1": 0.3117, "tft": 4.6116, "input_0": 100, "input_1": 33, "min_CLP": -3.72, "draft_iters": 10.2, "mem_use": 46.8, "gen_rate": 7.3, "speed": 4.22, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 1.518, "t1": 0.3, "tft": 1.7209, "input_0": 100, "input_1": 33, "min_CLP": -3.86, "draft_iters": 10.8, "mem_use": 44.62, "gen_rate": 4.8, "speed": 2.63, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.4, "tree_w": 7, "tree_size": 32, "t0": 1.1757, "t1": 0.2986, "tft": 2.1336, "input_0": 94, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.4, "mem_use": 44.21, "gen_rate": 5.1, "speed": 3.49, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 24.0, "tree_w": 2, "tree_size": 32, "t0": 3.175, "t1": 0.32, "tft": 4.2491, "input_0": 131, "input_1": 33, "min_CLP": -3.16, "draft_iters": 24.5, "mem_use": 47.04, "gen_rate": 22.0, "speed": 6.3, "text": "\"Sure, here's the table with an "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.1, "tree_w": 10, "tree_size": 32, "t0": 0.8644, "t1": 0.2967, "tft": 1.5552, "input_0": 73, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.1, "mem_use": 44.16, "gen_rate": 3.6, "speed": 3.07, "text": "Berlin was founded in the 13th c"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 6, "tree_size": 32, "t0": 1.33, "t1": 0.3083, "tft": 3.2839, "input_0": 95, "input_1": 33, "min_CLP": -3.73, "draft_iters": 9.7, "mem_use": 46.5, "gen_rate": 5.5, "speed": 3.36, "text": "\"Dear friends and family,\\n\\nAs "}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.3, "tree_w": 6, "tree_size": 32, "t0": 1.5733, "t1": 0.3083, "tft": 4.0193, "input_0": 108, "input_1": 33, "min_CLP": -3.42, "draft_iters": 11.3, "mem_use": 46.35, "gen_rate": 6.7, "speed": 3.54, "text": "Sure! One of the main criticisms"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 1.3383, "t1": 0.295, "tft": 1.8112, "input_0": 98, "input_1": 33, "min_CLP": -4.28, "draft_iters": 9.7, "mem_use": 44.18, "gen_rate": 6.5, "speed": 3.98, "text": "The origins of pornography can b"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 1.0263, "t1": 0.2962, "tft": 2.5621, "input_0": 79, "input_1": 33, "min_CLP": -4.19, "draft_iters": 7.5, "mem_use": 44.49, "gen_rate": 4.4, "speed": 3.3, "text": "You can check your timezone on t"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.8222, "t1": 0.2944, "tft": 1.7593, "input_0": 66, "input_1": 33, "min_CLP": -4.48, "draft_iters": 5.9, "mem_use": 44.58, "gen_rate": 4.1, "speed": 3.68, "text": "The five second rule is based on"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 1.74, "t1": 0.3, "tft": 1.9809, "input_0": 93, "input_1": 33, "min_CLP": -3.81, "draft_iters": 13.0, "mem_use": 44.3, "gen_rate": 6.5, "speed": 3.19, "text": "12 - 2 - 5 = 5 eggs left."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.4, "tree_w": 5, "tree_size": 32, "t0": 1.802, "t1": 0.3, "tft": 3.323, "input_0": 110, "input_1": 33, "min_CLP": -3.48, "draft_iters": 13.4, "mem_use": 45.05, "gen_rate": 7.6, "speed": 3.62, "text": "\"Sure, I'd be happy to explain s"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 23, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.905, "t1": 0.295, "tft": 2.1325, "input_0": 75, "input_1": 33, "min_CLP": -4.13, "draft_iters": 6.5, "mem_use": 44.62, "gen_rate": 2.9, "speed": 2.39, "text": "\"It's best to dispose of any ing"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 5, "tree_size": 32, "t0": 2.145, "t1": 0.295, "tft": 1.7884, "input_0": 119, "input_1": 33, "min_CLP": -3.52, "draft_iters": 16.5, "mem_use": 44.33, "gen_rate": 16.5, "speed": 6.76, "text": "Sure, here\\'s an announcement tw"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 8, "tree_size": 32, "t0": 1.0571, "t1": 0.2986, "tft": 3.1733, "input_0": 89, "input_1": 33, "min_CLP": -4.2, "draft_iters": 7.4, "mem_use": 44.94, "gen_rate": 4.9, "speed": 3.58, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.6, "tree_w": 6, "tree_size": 32, "t0": 1.478, "t1": 0.304, "tft": 3.2876, "input_0": 117, "input_1": 33, "min_CLP": -3.63, "draft_iters": 10.6, "mem_use": 45.99, "gen_rate": 7.6, "speed": 4.27, "text": "Certainly! AI assistants can als"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 10, "tree_size": 32, "t0": 1.155, "t1": 0.3117, "tft": 4.4164, "input_0": 75, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.5, "mem_use": 47.0, "gen_rate": 5.7, "speed": 3.87, "text": "\"Certainly! Here's a rewritten v"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 1.4183, "t1": 0.3067, "tft": 3.5181, "input_0": 110, "input_1": 33, "min_CLP": -3.65, "draft_iters": 10.2, "mem_use": 45.5, "gen_rate": 6.0, "speed": 3.48, "text": "Yes, this method works on Unix a"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 24.0, "tree_w": 3, "tree_size": 32, "t0": 3.26, "t1": 0.3, "tft": 4.6369, "input_0": 161, "input_1": 33, "min_CLP": -3.99, "draft_iters": 25.0, "mem_use": 46.14, "gen_rate": 23.0, "speed": 6.46, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 10, "tree_size": 32, "t0": 1.12, "t1": 0.2933, "tft": 1.5599, "input_0": 83, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.3, "mem_use": 44.23, "gen_rate": 5.5, "speed": 3.89, "text": "The task involves a simple quest"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 1.318, "t1": 0.29, "tft": 2.2918, "input_0": 87, "input_1": 33, "min_CLP": -3.83, "draft_iters": 9.8, "mem_use": 44.52, "gen_rate": 8.2, "speed": 5.1, "text": "Sydney is the largest city in Au"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.2312, "t1": 0.2975, "tft": 2.3939, "input_0": 89, "input_1": 33, "min_CLP": -4.29, "draft_iters": 9.0, "mem_use": 44.82, "gen_rate": 4.2, "speed": 2.78, "text": "\"Thank you for sharing that info"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.8329, "t1": 0.29, "tft": 1.5328, "input_0": 71, "input_1": 33, "min_CLP": -4.57, "draft_iters": 6.0, "mem_use": 44.5, "gen_rate": 4.6, "speed": 4.07, "text": "\"I'm glad you liked it! Here's a"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 25.0, "tree_w": 4, "tree_size": 32, "t0": 3.13, "t1": 0.295, "tft": 3.2839, "input_0": 121, "input_1": 33, "min_CLP": -2.93, "draft_iters": 25.5, "mem_use": 44.27, "gen_rate": 18.0, "speed": 5.26, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.288, "t1": 0.288, "tft": 2.1359, "input_0": 101, "input_1": 33, "min_CLP": -3.97, "draft_iters": 9.6, "mem_use": 44.24, "gen_rate": 6.6, "speed": 4.19, "text": "The time it would take to walk a"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 22.0, "tree_w": 3, "tree_size": 32, "t0": 3.1, "t1": 0.305, "tft": 4.259, "input_0": 160, "input_1": 33, "min_CLP": -3.1, "draft_iters": 23.0, "mem_use": 45.99, "gen_rate": 16.5, "speed": 4.84, "text": "\"The solution to the Taniyama-Sh"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.96, "t1": 0.3, "tft": 1.9064, "input_0": 125, "input_1": 33, "min_CLP": -2.58, "draft_iters": 32.0, "mem_use": 44.24, "gen_rate": 33.0, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.674, "t1": 0.3, "tft": 2.8759, "input_0": 118, "input_1": 33, "min_CLP": -3.56, "draft_iters": 12.0, "mem_use": 44.55, "gen_rate": 7.2, "speed": 3.65, "text": "\"Here's an example of a basic fi"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 21.0, "tree_w": 6, "tree_size": 32, "t0": 2.75, "t1": 0.295, "tft": 2.2744, "input_0": 122, "input_1": 33, "min_CLP": -4.16, "draft_iters": 21.5, "mem_use": 44.22, "gen_rate": 21.0, "speed": 6.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 1.11, "t1": 0.298, "tft": 1.6688, "input_0": 85, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.2, "mem_use": 44.53, "gen_rate": 4.0, "speed": 2.84, "text": "In the Jedi Order, the path to a"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 9, "tree_size": 32, "t0": 0.9612, "t1": 0.2937, "tft": 2.1175, "input_0": 77, "input_1": 33, "min_CLP": -4.16, "draft_iters": 6.9, "mem_use": 44.39, "gen_rate": 4.0, "speed": 3.19, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.1633, "t1": 0.2967, "tft": 2.8869, "input_0": 83, "input_1": 33, "min_CLP": -4.34, "draft_iters": 8.5, "mem_use": 44.63, "gen_rate": 5.3, "speed": 3.65, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 1.0713, "t1": 0.3175, "tft": 4.3093, "input_0": 86, "input_1": 33, "min_CLP": -3.9, "draft_iters": 7.6, "mem_use": 47.49, "gen_rate": 4.2, "speed": 3.06, "text": "Yes, using regular expressions f"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.4, "tree_w": 8, "tree_size": 32, "t0": 1.4014, "t1": 0.2957, "tft": 2.5196, "input_0": 86, "input_1": 33, "min_CLP": -4.01, "draft_iters": 10.4, "mem_use": 44.69, "gen_rate": 4.6, "speed": 2.69, "text": "Yes, it is reasonable to compens"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 1.42, "t1": 0.31, "tft": 4.4477, "input_0": 111, "input_1": 33, "min_CLP": -3.62, "draft_iters": 10.0, "mem_use": 47.59, "gen_rate": 6.0, "speed": 3.47, "text": "Xin ch\u00e0o! How can I help you tod"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.8422, "t1": 0.3056, "tft": 2.2171, "input_0": 67, "input_1": 33, "min_CLP": -4.45, "draft_iters": 6.0, "mem_use": 45.06, "gen_rate": 3.6, "speed": 3.1, "text": "This is one of the best examples"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 19.0, "tree_w": 3, "tree_size": 32, "t0": 2.6433, "t1": 0.3, "tft": 2.1193, "input_0": 130, "input_1": 33, "min_CLP": -3.63, "draft_iters": 19.7, "mem_use": 44.58, "gen_rate": 17.0, "speed": 5.77, "text": "Sure! Here\\'s an example of how "}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 1.49, "t1": 0.31, "tft": 3.2182, "input_0": 95, "input_1": 33, "min_CLP": -3.48, "draft_iters": 10.8, "mem_use": 46.01, "gen_rate": 8.0, "speed": 4.45, "text": "Here is a list of the top 10 mos"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.4, "tree_w": 12, "tree_size": 32, "t0": 1.0622, "t1": 0.3022, "tft": 2.4314, "input_0": 82, "input_1": 33, "min_CLP": -4.35, "draft_iters": 7.4, "mem_use": 44.54, "gen_rate": 4.2, "speed": 3.09, "text": "\"To win a thumb war, you should "}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.0, "tree_w": 4, "tree_size": 32, "t0": 2.068, "t1": 0.308, "tft": 4.3762, "input_0": 112, "input_1": 33, "min_CLP": -3.31, "draft_iters": 15.0, "mem_use": 46.55, "gen_rate": 7.2, "speed": 3.03, "text": "\"Sure, I can offer some advice o"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 1.1829, "t1": 0.3014, "tft": 2.755, "input_0": 84, "input_1": 33, "min_CLP": -4.46, "draft_iters": 8.4, "mem_use": 45.17, "gen_rate": 5.3, "speed": 3.56, "text": "\"As a language model, I don't ha"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.9, "tree_w": 11, "tree_size": 32, "t0": 0.9656, "t1": 0.3022, "tft": 1.9481, "input_0": 76, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.9, "mem_use": 44.7, "gen_rate": 3.8, "speed": 2.98, "text": "[INST] Shall I start off by sayi"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.2, "tree_w": 6, "tree_size": 32, "t0": 1.338, "t1": 0.3, "tft": 2.7679, "input_0": 106, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.2, "mem_use": 44.84, "gen_rate": 6.6, "speed": 4.02, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 10, "tree_size": 32, "t0": 1.245, "t1": 0.3017, "tft": 3.6522, "input_0": 94, "input_1": 33, "min_CLP": -4.4, "draft_iters": 9.0, "mem_use": 46.12, "gen_rate": 5.8, "speed": 3.77, "text": "\"Here's a poem in Quenya to expr"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.5, "tree_w": 6, "tree_size": 32, "t0": 1.475, "t1": 0.2967, "tft": 2.2989, "input_0": 108, "input_1": 33, "min_CLP": -4.16, "draft_iters": 10.5, "mem_use": 44.22, "gen_rate": 6.5, "speed": 3.67, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 1.2483, "t1": 0.2983, "tft": 2.076, "input_0": 93, "input_1": 33, "min_CLP": -3.75, "draft_iters": 8.7, "mem_use": 44.26, "gen_rate": 6.0, "speed": 3.87, "text": "The error in the code is a missi"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 28.5, "tree_w": 2, "tree_size": 32, "t0": 3.75, "t1": 0.31, "tft": 2.6522, "input_0": 134, "input_1": 33, "min_CLP": -3.5, "draft_iters": 29.0, "mem_use": 45.65, "gen_rate": 21.5, "speed": 5.29, "text": "Dear future me, hello. If you ar"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.0, "tree_w": 6, "tree_size": 32, "t0": 1.7925, "t1": 0.3, "tft": 2.6716, "input_0": 111, "input_1": 33, "min_CLP": -3.77, "draft_iters": 13.0, "mem_use": 44.87, "gen_rate": 9.0, "speed": 4.31, "text": "In the second context, the `@` s"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 1.63, "t1": 0.3, "tft": 2.7847, "input_0": 109, "input_1": 33, "min_CLP": -3.58, "draft_iters": 12.0, "mem_use": 44.99, "gen_rate": 11.3, "speed": 5.89, "text": "\"To achieve this, you can use th"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 1.3467, "t1": 0.305, "tft": 3.9254, "input_0": 103, "input_1": 33, "min_CLP": -3.72, "draft_iters": 9.8, "mem_use": 46.78, "gen_rate": 5.5, "speed": 3.33, "text": "\"It's understandable to feel a b"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.7, "tree_w": 5, "tree_size": 32, "t0": 1.9567, "t1": 0.2933, "tft": 2.7144, "input_0": 125, "input_1": 33, "min_CLP": -3.81, "draft_iters": 14.7, "mem_use": 44.78, "gen_rate": 11.7, "speed": 5.19, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.8, "tree_w": 4, "tree_size": 32, "t0": 1.965, "t1": 0.305, "tft": 5.4454, "input_0": 116, "input_1": 33, "min_CLP": -3.48, "draft_iters": 14.8, "mem_use": 46.14, "gen_rate": 9.2, "speed": 4.08, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.5, "tree_w": 7, "tree_size": 32, "t0": 1.325, "t1": 0.2917, "tft": 2.175, "input_0": 97, "input_1": 33, "min_CLP": -4.07, "draft_iters": 9.5, "mem_use": 44.2, "gen_rate": 6.2, "speed": 3.82, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 20.0, "tree_w": 4, "tree_size": 32, "t0": 2.6533, "t1": 0.2967, "tft": 1.7444, "input_0": 111, "input_1": 33, "min_CLP": -4.56, "draft_iters": 20.7, "mem_use": 44.42, "gen_rate": 21.0, "speed": 7.12, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 1.0471, "t1": 0.2986, "tft": 1.8929, "input_0": 82, "input_1": 33, "min_CLP": -4.14, "draft_iters": 7.6, "mem_use": 44.67, "gen_rate": 5.1, "speed": 3.82, "text": "\"Thank you! I'm programmed to pr"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.1688, "t1": 0.305, "tft": 3.4238, "input_0": 82, "input_1": 33, "min_CLP": -4.33, "draft_iters": 8.5, "mem_use": 46.26, "gen_rate": 4.0, "speed": 2.71, "text": "Thou art a sun that shineth brig"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 1.4, "t1": 0.3075, "tft": 2.3541, "input_0": 96, "input_1": 33, "min_CLP": -3.84, "draft_iters": 10.2, "mem_use": 44.84, "gen_rate": 8.0, "speed": 4.68, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.5, "tree_w": 4, "tree_size": 32, "t0": 2.685, "t1": 0.295, "tft": 2.3805, "input_0": 118, "input_1": 33, "min_CLP": -2.97, "draft_iters": 21.0, "mem_use": 44.24, "gen_rate": 18.0, "speed": 6.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.6, "tree_w": 4, "tree_size": 32, "t0": 1.7986, "t1": 0.2943, "tft": 1.9678, "input_0": 104, "input_1": 33, "min_CLP": -3.37, "draft_iters": 13.6, "mem_use": 44.22, "gen_rate": 5.3, "speed": 2.53, "text": "\"Sure! Presidents Day, officiall"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 10, "tree_size": 32, "t0": 1.3975, "t1": 0.2975, "tft": 2.146, "input_0": 82, "input_1": 33, "min_CLP": -4.49, "draft_iters": 10.2, "mem_use": 44.52, "gen_rate": 9.0, "speed": 5.31, "text": "True, a kilogram of feathers is "}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.498, "t1": 0.3, "tft": 3.3852, "input_0": 98, "input_1": 33, "min_CLP": -3.74, "draft_iters": 11.0, "mem_use": 45.33, "gen_rate": 7.0, "speed": 3.9, "text": "The existence and capabilities o"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.931, "t1": 0.294, "tft": 1.7942, "input_0": 70, "input_1": 33, "min_CLP": -4.53, "draft_iters": 6.8, "mem_use": 44.6, "gen_rate": 3.3, "speed": 2.69, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 7.4, "tree_w": 7, "tree_size": 32, "t0": 1.168, "t1": 0.29, "tft": 1.8377, "input_0": 93, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.4, "mem_use": 44.67, "gen_rate": 4.8, "speed": 3.29, "text": "\"Certainly, I'll be known as Opi"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 5, "tree_size": 32, "t0": 1.488, "t1": 0.29, "tft": 1.6627, "input_0": 100, "input_1": 33, "min_CLP": -3.63, "draft_iters": 11.0, "mem_use": 44.22, "gen_rate": 7.0, "speed": 3.94, "text": "Yes, the ATF (Bureau of Alcohol,"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.8542, "t1": 0.2933, "tft": 2.348, "input_0": 74, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.2, "mem_use": 44.91, "gen_rate": 3.0, "speed": 2.61, "text": "\"Ted who? That dude\\'s like anci"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.896, "t1": 0.292, "tft": 2.1306, "input_0": 67, "input_1": 33, "min_CLP": -4.17, "draft_iters": 6.6, "mem_use": 44.33, "gen_rate": 3.4, "speed": 2.86, "text": "The given text is missing or inc"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.1933, "t1": 0.3083, "tft": 2.8995, "input_0": 89, "input_1": 33, "min_CLP": -3.91, "draft_iters": 8.5, "mem_use": 45.57, "gen_rate": 6.7, "speed": 4.44, "text": "Certainly! Here are a few fictio"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 8, "tree_size": 32, "t0": 1.07, "t1": 0.296, "tft": 1.9683, "input_0": 83, "input_1": 33, "min_CLP": -4.04, "draft_iters": 7.4, "mem_use": 44.67, "gen_rate": 6.4, "speed": 4.68, "text": "I am an AI language model. My pu"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.642, "t1": 0.302, "tft": 3.5646, "input_0": 113, "input_1": 33, "min_CLP": -3.48, "draft_iters": 12.0, "mem_use": 45.87, "gen_rate": 8.2, "speed": 4.22, "text": "\"If you're a beginner hiker and "}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.8829, "t1": 0.2929, "tft": 2.776, "input_0": 64, "input_1": 33, "min_CLP": -4.32, "draft_iters": 6.6, "mem_use": 44.62, "gen_rate": 4.6, "speed": 3.88, "text": "\"Open Assistant: The Open Source"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.8, "tree_w": 9, "tree_size": 32, "t0": 1.676, "t1": 0.298, "tft": 1.7687, "input_0": 89, "input_1": 33, "min_CLP": -3.92, "draft_iters": 12.8, "mem_use": 44.51, "gen_rate": 8.2, "speed": 4.15, "text": "Sure! Here is a diagram to illus"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 1.322, "t1": 0.312, "tft": 3.7473, "input_0": 99, "input_1": 33, "min_CLP": -3.57, "draft_iters": 9.8, "mem_use": 46.85, "gen_rate": 6.8, "speed": 4.17, "text": "The reason your code does not co"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 6, "tree_size": 32, "t0": 1.685, "t1": 0.29, "tft": 2.4389, "input_0": 120, "input_1": 33, "min_CLP": -3.68, "draft_iters": 12.5, "mem_use": 44.2, "gen_rate": 8.0, "speed": 4.05, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.4, "tree_w": 8, "tree_size": 32, "t0": 1.0171, "t1": 0.2929, "tft": 2.0409, "input_0": 83, "input_1": 33, "min_CLP": -4.14, "draft_iters": 7.4, "mem_use": 44.75, "gen_rate": 5.3, "speed": 4.03, "text": "\"I'm sorry, but I cannot provide"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 5.3, "tree_w": 11, "tree_size": 32, "t0": 0.92, "t1": 0.2933, "tft": 1.9812, "input_0": 67, "input_1": 33, "min_CLP": -4.32, "draft_iters": 6.3, "mem_use": 44.38, "gen_rate": 3.3, "speed": 2.74, "text": "The heat from the pan helps to c"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.352, "t1": 0.294, "tft": 2.1793, "input_0": 83, "input_1": 33, "min_CLP": -3.64, "draft_iters": 10.0, "mem_use": 44.22, "gen_rate": 6.4, "speed": 3.89, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 1.325, "t1": 0.3017, "tft": 3.8483, "input_0": 93, "input_1": 33, "min_CLP": -3.69, "draft_iters": 9.7, "mem_use": 46.3, "gen_rate": 5.8, "speed": 3.58, "text": "\"As an AI language model, I apol"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 27, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 1.0375, "t1": 0.2925, "tft": 2.0304, "input_0": 79, "input_1": 33, "min_CLP": -4.19, "draft_iters": 7.6, "mem_use": 44.18, "gen_rate": 3.4, "speed": 2.54, "text": "Your task is to generate an appr"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 12, "tree_size": 32, "t0": 1.3467, "t1": 0.2933, "tft": 2.7563, "input_0": 83, "input_1": 33, "min_CLP": -4.3, "draft_iters": 10.3, "mem_use": 44.26, "gen_rate": 5.5, "speed": 3.35, "text": "The lyrics to the third verse of"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.4783, "t1": 0.31, "tft": 4.2829, "input_0": 107, "input_1": 33, "min_CLP": -3.88, "draft_iters": 11.0, "mem_use": 47.55, "gen_rate": 7.0, "speed": 3.92, "text": "As of my last update in early 20"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 8, "tree_size": 32, "t0": 1.3143, "t1": 0.3014, "tft": 3.0952, "input_0": 94, "input_1": 33, "min_CLP": -4.06, "draft_iters": 9.7, "mem_use": 45.53, "gen_rate": 5.1, "speed": 3.18, "text": "\"I'm sorry, I don't think that's"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 1.346, "t1": 0.294, "tft": 1.9905, "input_0": 99, "input_1": 33, "min_CLP": -3.75, "draft_iters": 9.8, "mem_use": 44.48, "gen_rate": 6.6, "speed": 4.03, "text": "There are many resources availab"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 1.38, "t1": 0.2975, "tft": 2.4645, "input_0": 90, "input_1": 33, "min_CLP": -4.02, "draft_iters": 10.0, "mem_use": 44.45, "gen_rate": 4.8, "speed": 2.83, "text": "Here are some potential methods "}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 1.18, "t1": 0.3, "tft": 2.509, "input_0": 92, "input_1": 33, "min_CLP": -3.9, "draft_iters": 8.2, "mem_use": 44.22, "gen_rate": 5.5, "speed": 3.72, "text": "\"The theory of sexual selection "}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 1.3963, "t1": 0.3, "tft": 2.3643, "input_0": 92, "input_1": 33, "min_CLP": -3.96, "draft_iters": 10.2, "mem_use": 45.03, "gen_rate": 4.1, "speed": 2.43, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.0, "tree_w": 5, "tree_size": 32, "t0": 2.3967, "t1": 0.31, "tft": 3.4722, "input_0": 130, "input_1": 33, "min_CLP": -3.44, "draft_iters": 17.0, "mem_use": 45.06, "gen_rate": 13.7, "speed": 5.05, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 13.0, "tree_w": 5, "tree_size": 32, "t0": 1.8733, "t1": 0.3133, "tft": 4.6832, "input_0": 104, "input_1": 33, "min_CLP": -3.5, "draft_iters": 14.0, "mem_use": 47.57, "gen_rate": 13.7, "speed": 6.26, "text": "\"Certainly! Here's a shorter ver"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.2533, "t1": 0.295, "tft": 2.4281, "input_0": 91, "input_1": 33, "min_CLP": -3.95, "draft_iters": 8.8, "mem_use": 44.23, "gen_rate": 5.3, "speed": 3.44, "text": "To reduce your alcohol consumpti"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.85, "t1": 0.302, "tft": 2.2903, "input_0": 70, "input_1": 33, "min_CLP": -4.56, "draft_iters": 6.0, "mem_use": 44.79, "gen_rate": 3.2, "speed": 2.78, "text": "The city is home to several worl"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 4, "tree_size": 32, "t0": 1.8875, "t1": 0.295, "tft": 1.9454, "input_0": 123, "input_1": 33, "min_CLP": -3.44, "draft_iters": 13.5, "mem_use": 44.26, "gen_rate": 8.8, "speed": 4.02, "text": "Here is a Python script that sav"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 18.5, "tree_w": 6, "tree_size": 32, "t0": 2.495, "t1": 0.3075, "tft": 3.8406, "input_0": 104, "input_1": 33, "min_CLP": -4.09, "draft_iters": 19.2, "mem_use": 46.77, "gen_rate": 13.8, "speed": 4.9, "text": "## Vegetarian\\nSpicy Tomato and "}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.94, "t1": 0.3, "tft": 1.5354, "input_0": 127, "input_1": 33, "min_CLP": -3.13, "draft_iters": 32.0, "mem_use": 44.17, "gen_rate": 33.0, "speed": 7.79, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 1.2086, "t1": 0.31, "tft": 3.6239, "input_0": 90, "input_1": 33, "min_CLP": -3.76, "draft_iters": 8.6, "mem_use": 46.44, "gen_rate": 5.1, "speed": 3.39, "text": "Here are some steps the restaura"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 1.2433, "t1": 0.295, "tft": 1.6733, "input_0": 91, "input_1": 33, "min_CLP": -4.09, "draft_iters": 9.0, "mem_use": 44.18, "gen_rate": 5.8, "speed": 3.79, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 1.2286, "t1": 0.2929, "tft": 1.3814, "input_0": 94, "input_1": 33, "min_CLP": -4.12, "draft_iters": 8.7, "mem_use": 44.17, "gen_rate": 5.1, "speed": 3.38, "text": "The task is to translate the giv"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.7, "tree_w": 6, "tree_size": 32, "t0": 1.5917, "t1": 0.2983, "tft": 2.0759, "input_0": 101, "input_1": 33, "min_CLP": -3.69, "draft_iters": 11.7, "mem_use": 44.33, "gen_rate": 6.3, "speed": 3.35, "text": "\"Sure, I can give you an example"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 7, "tree_size": 32, "t0": 1.278, "t1": 0.308, "tft": 3.763, "input_0": 95, "input_1": 33, "min_CLP": -3.74, "draft_iters": 9.2, "mem_use": 45.39, "gen_rate": 6.4, "speed": 4.04, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 1.2722, "t1": 0.2989, "tft": 1.9472, "input_0": 80, "input_1": 33, "min_CLP": -4.19, "draft_iters": 9.2, "mem_use": 44.28, "gen_rate": 4.1, "speed": 2.62, "text": "\"The assistant will help you wit"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 1.248, "t1": 0.302, "tft": 1.7692, "input_0": 101, "input_1": 33, "min_CLP": -4.02, "draft_iters": 8.6, "mem_use": 44.48, "gen_rate": 6.8, "speed": 4.38, "text": "\"Sure, I'd be happy to explain i"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.3, "tree_w": 7, "tree_size": 32, "t0": 1.5283, "t1": 0.295, "tft": 2.8945, "input_0": 104, "input_1": 33, "min_CLP": -3.77, "draft_iters": 11.3, "mem_use": 44.82, "gen_rate": 6.2, "speed": 3.38, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 1.0567, "t1": 0.295, "tft": 2.2719, "input_0": 86, "input_1": 33, "min_CLP": -4.19, "draft_iters": 7.7, "mem_use": 44.37, "gen_rate": 5.3, "speed": 3.94, "text": "\"I'm a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.2, "tree_w": 5, "tree_size": 32, "t0": 1.925, "t1": 0.3075, "tft": 3.5217, "input_0": 122, "input_1": 33, "min_CLP": -3.44, "draft_iters": 14.2, "mem_use": 45.59, "gen_rate": 8.0, "speed": 3.58, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 4.05, "t1": 0.3, "tft": 3.0253, "input_0": 133, "input_1": 33, "min_CLP": -2.95, "draft_iters": 32.0, "mem_use": 44.26, "gen_rate": 33.0, "speed": 7.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 5, "tree_size": 32, "t0": 1.592, "t1": 0.306, "tft": 3.16, "input_0": 104, "input_1": 33, "min_CLP": -3.87, "draft_iters": 11.2, "mem_use": 45.1, "gen_rate": 6.4, "speed": 3.37, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 4.04, "t1": 0.3, "tft": 1.8903, "input_0": 128, "input_1": 33, "min_CLP": -2.53, "draft_iters": 32.0, "mem_use": 44.37, "gen_rate": 33.0, "speed": 7.59, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 1.2991, "t1": 0.2964, "tft": 2.2818, "input_0": 90, "input_1": 33, "min_CLP": -4.0, "draft_iters": 9.3, "mem_use": 44.2, "gen_rate": 2.9, "speed": 1.82, "text": "This task involves creating a qu"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 7, "tree_size": 32, "t0": 1.4625, "t1": 0.3225, "tft": 5.8638, "input_0": 94, "input_1": 33, "min_CLP": -3.86, "draft_iters": 10.5, "mem_use": 48.51, "gen_rate": 8.2, "speed": 4.63, "text": "\"If your friends are not happy w"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.99, "t1": 0.29, "tft": 1.6773, "input_0": 124, "input_1": 33, "min_CLP": -2.72, "draft_iters": 32.0, "mem_use": 44.5, "gen_rate": 33.0, "speed": 7.72, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 7, "tree_size": 32, "t0": 1.2017, "t1": 0.3083, "tft": 3.2592, "input_0": 91, "input_1": 33, "min_CLP": -3.78, "draft_iters": 8.5, "mem_use": 45.38, "gen_rate": 5.5, "speed": 3.64, "text": "To go around the world by boat a"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 1.2483, "t1": 0.31, "tft": 3.7849, "input_0": 96, "input_1": 33, "min_CLP": -3.92, "draft_iters": 9.0, "mem_use": 46.64, "gen_rate": 5.5, "speed": 3.53, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.9733, "t1": 0.2933, "tft": 1.6122, "input_0": 86, "input_1": 33, "min_CLP": -4.78, "draft_iters": 7.0, "mem_use": 44.48, "gen_rate": 3.7, "speed": 2.9, "text": "\"I'm afraid your sense of humor "}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 10, "tree_size": 32, "t0": 1.1271, "t1": 0.2971, "tft": 1.7962, "input_0": 87, "input_1": 33, "min_CLP": -4.29, "draft_iters": 8.1, "mem_use": 44.52, "gen_rate": 4.7, "speed": 3.31, "text": "\"You're welcome! Do you have any"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 5, "tree_size": 32, "t0": 1.54, "t1": 0.304, "tft": 3.2208, "input_0": 105, "input_1": 33, "min_CLP": -3.56, "draft_iters": 10.8, "mem_use": 45.0, "gen_rate": 6.4, "speed": 3.47, "text": "Sure! Here are three examples of"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.99, "t1": 0.3, "tft": 3.0744, "input_0": 132, "input_1": 33, "min_CLP": -2.32, "draft_iters": 32.0, "mem_use": 44.5, "gen_rate": 33.0, "speed": 7.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.806, "t1": 0.304, "tft": 2.7824, "input_0": 62, "input_1": 33, "min_CLP": -4.41, "draft_iters": 5.9, "mem_use": 45.18, "gen_rate": 3.2, "speed": 2.89, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.9, "tree_w": 8, "tree_size": 32, "t0": 1.3543, "t1": 0.3014, "tft": 1.9007, "input_0": 91, "input_1": 33, "min_CLP": -4.16, "draft_iters": 9.9, "mem_use": 44.52, "gen_rate": 4.9, "speed": 2.93, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.5, "tree_w": 5, "tree_size": 32, "t0": 1.8275, "t1": 0.2975, "tft": 2.0611, "input_0": 108, "input_1": 33, "min_CLP": -3.67, "draft_iters": 13.5, "mem_use": 44.24, "gen_rate": 10.0, "speed": 4.71, "text": "Reinforcement learning is a type"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.8, "tree_w": 9, "tree_size": 32, "t0": 1.994, "t1": 0.298, "tft": 2.0507, "input_0": 93, "input_1": 33, "min_CLP": -3.84, "draft_iters": 14.8, "mem_use": 44.21, "gen_rate": 6.4, "speed": 2.79, "text": "Detailed Instructions: Given a s"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 12.0, "tree_w": 4, "tree_size": 32, "t0": 1.775, "t1": 0.315, "tft": 5.6754, "input_0": 99, "input_1": 33, "min_CLP": -3.69, "draft_iters": 13.0, "mem_use": 48.49, "gen_rate": 8.0, "speed": 3.83, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.2175, "t1": 0.2975, "tft": 1.9475, "input_0": 106, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.5, "mem_use": 44.34, "gen_rate": 4.5, "speed": 2.97, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.66, "t1": 0.3075, "tft": 3.6763, "input_0": 109, "input_1": 33, "min_CLP": -3.72, "draft_iters": 12.0, "mem_use": 45.88, "gen_rate": 8.8, "speed": 4.45, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 1.4233, "t1": 0.31, "tft": 3.4157, "input_0": 100, "input_1": 33, "min_CLP": -3.74, "draft_iters": 10.2, "mem_use": 45.64, "gen_rate": 5.8, "speed": 3.36, "text": "In option 2, the command \"chkdsk"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.88, "t1": 0.3, "tft": 2.3045, "input_0": 122, "input_1": 33, "min_CLP": -2.64, "draft_iters": 32.0, "mem_use": 44.48, "gen_rate": 33.0, "speed": 7.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.94, "t1": 0.3, "tft": 2.1013, "input_0": 135, "input_1": 33, "min_CLP": -2.49, "draft_iters": 32.0, "mem_use": 44.29, "gen_rate": 33.0, "speed": 7.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 5, "tree_size": 32, "t0": 3.27, "t1": 0.3, "tft": 2.414, "input_0": 125, "input_1": 33, "min_CLP": -3.69, "draft_iters": 25.0, "mem_use": 44.27, "gen_rate": 25.5, "speed": 7.14, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 1.0629, "t1": 0.3071, "tft": 2.747, "input_0": 83, "input_1": 33, "min_CLP": -4.06, "draft_iters": 7.6, "mem_use": 45.27, "gen_rate": 4.6, "speed": 3.34, "text": "\"I'm sorry, but it's not helpful"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 13, "tree_h": 10.2, "tree_w": 8, "tree_size": 32, "t0": 1.5275, "t1": 0.3, "tft": 1.5059, "input_0": 79, "input_1": 33, "min_CLP": -4.13, "draft_iters": 11.2, "mem_use": 44.6, "gen_rate": 3.2, "speed": 1.78, "text": "\"Ok, let's chat! What would you "}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 6, "tree_size": 32, "t0": 1.804, "t1": 0.31, "tft": 3.7713, "input_0": 94, "input_1": 33, "min_CLP": -4.15, "draft_iters": 13.0, "mem_use": 45.92, "gen_rate": 6.4, "speed": 3.02, "text": "meliss\u00eb, noun lover (fem.)\\nmeld"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.2, "tree_w": 12, "tree_size": 32, "t0": 0.875, "t1": 0.3037, "tft": 2.2393, "input_0": 64, "input_1": 33, "min_CLP": -4.47, "draft_iters": 6.2, "mem_use": 44.84, "gen_rate": 4.4, "speed": 3.72, "text": "I think one can draw that the an"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 7, "tree_size": 32, "t0": 1.7075, "t1": 0.295, "tft": 1.6392, "input_0": 85, "input_1": 33, "min_CLP": -4.23, "draft_iters": 13.0, "mem_use": 44.68, "gen_rate": 8.2, "speed": 4.11, "text": "The ATF gun walking scandal, als"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 6, "tree_size": 32, "t0": 1.525, "t1": 0.3, "tft": 1.9928, "input_0": 113, "input_1": 33, "min_CLP": -4.03, "draft_iters": 10.5, "mem_use": 44.42, "gen_rate": 8.8, "speed": 4.79, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.2, "tree_w": 5, "tree_size": 32, "t0": 1.905, "t1": 0.315, "tft": 5.7498, "input_0": 109, "input_1": 33, "min_CLP": -3.42, "draft_iters": 14.2, "mem_use": 47.22, "gen_rate": 5.8, "speed": 2.63, "text": "\"Certainly! Here's a revised end"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 26.5, "tree_w": 2, "tree_size": 32, "t0": 3.42, "t1": 0.315, "tft": 4.7256, "input_0": 136, "input_1": 33, "min_CLP": -4.33, "draft_iters": 27.0, "mem_use": 47.14, "gen_rate": 27.5, "speed": 7.37, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 1.085, "t1": 0.295, "tft": 1.5581, "input_0": 88, "input_1": 33, "min_CLP": -4.05, "draft_iters": 7.9, "mem_use": 44.2, "gen_rate": 3.3, "speed": 2.39, "text": "\"Sure, I can do that! Here's a N"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.7, "tree_w": 5, "tree_size": 32, "t0": 2.5533, "t1": 0.3, "tft": 2.5386, "input_0": 127, "input_1": 33, "min_CLP": -3.09, "draft_iters": 19.7, "mem_use": 45.37, "gen_rate": 12.0, "speed": 4.21, "text": "Certainly! Here\\'s the updated a"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.0, "tree_w": 7, "tree_size": 32, "t0": 1.755, "t1": 0.305, "tft": 3.0339, "input_0": 120, "input_1": 33, "min_CLP": -3.8, "draft_iters": 13.0, "mem_use": 45.82, "gen_rate": 9.2, "speed": 4.49, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.3, "tree_w": 6, "tree_size": 32, "t0": 2.1033, "t1": 0.2933, "tft": 2.4307, "input_0": 137, "input_1": 33, "min_CLP": -3.77, "draft_iters": 15.3, "mem_use": 44.18, "gen_rate": 11.0, "speed": 4.59, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 7.3, "tree_w": 12, "tree_size": 32, "t0": 1.0986, "t1": 0.2929, "tft": 1.5021, "input_0": 74, "input_1": 33, "min_CLP": -4.64, "draft_iters": 8.3, "mem_use": 44.48, "gen_rate": 5.9, "speed": 4.21, "text": "I am a goddess, not an entertain"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 4, "tree_size": 32, "t0": 1.665, "t1": 0.3025, "tft": 3.7435, "input_0": 115, "input_1": 33, "min_CLP": -3.53, "draft_iters": 12.2, "mem_use": 46.07, "gen_rate": 9.2, "speed": 4.7, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.0, "tree_w": 5, "tree_size": 32, "t0": 1.84, "t1": 0.29, "tft": 2.3892, "input_0": 118, "input_1": 33, "min_CLP": -4.05, "draft_iters": 14.0, "mem_use": 44.42, "gen_rate": 7.2, "speed": 3.38, "text": "The task is asking you to explai"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 10.2, "tree_w": 7, "tree_size": 32, "t0": 1.482, "t1": 0.3, "tft": 2.947, "input_0": 95, "input_1": 33, "min_CLP": -3.99, "draft_iters": 11.2, "mem_use": 45.77, "gen_rate": 9.2, "speed": 5.16, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 27, "tree_h": 12.5, "tree_w": 5, "tree_size": 32, "t0": 1.785, "t1": 0.2975, "tft": 2.2106, "input_0": 98, "input_1": 33, "min_CLP": -3.73, "draft_iters": 13.5, "mem_use": 44.22, "gen_rate": 6.8, "speed": 3.24, "text": "\"Sure, I'd be happy to answer th"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 7, "tree_size": 32, "t0": 1.6025, "t1": 0.3, "tft": 2.5313, "input_0": 108, "input_1": 33, "min_CLP": -3.39, "draft_iters": 11.2, "mem_use": 44.23, "gen_rate": 8.0, "speed": 4.2, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 1.1, "t1": 0.2971, "tft": 2.5081, "input_0": 85, "input_1": 33, "min_CLP": -4.0, "draft_iters": 7.6, "mem_use": 44.87, "gen_rate": 4.7, "speed": 3.37, "text": "\"Alright, I'll write my version "}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.9, "tree_w": 12, "tree_size": 32, "t0": 1.1011, "t1": 0.3067, "tft": 2.7477, "input_0": 81, "input_1": 33, "min_CLP": -4.58, "draft_iters": 7.9, "mem_use": 45.1, "gen_rate": 3.7, "speed": 2.61, "text": "I apologize for the error in my "}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.68, "t1": 0.3, "tft": 2.0726, "input_0": 99, "input_1": 33, "min_CLP": -3.83, "draft_iters": 12.0, "mem_use": 44.2, "gen_rate": 7.6, "speed": 3.84, "text": "The AK-47, also known as the Kal"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 7, "tree_size": 32, "t0": 1.1617, "t1": 0.2983, "tft": 2.0778, "input_0": 86, "input_1": 33, "min_CLP": -3.8, "draft_iters": 8.3, "mem_use": 44.55, "gen_rate": 5.8, "speed": 4.0, "text": "\"Here's how you can accomplish t"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 15.3, "tree_w": 3, "tree_size": 32, "t0": 2.2133, "t1": 0.3067, "tft": 3.2135, "input_0": 130, "input_1": 33, "min_CLP": -3.63, "draft_iters": 16.3, "mem_use": 45.94, "gen_rate": 15.0, "speed": 5.95, "text": "1. Statistical modeling involves"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.366, "t1": 0.298, "tft": 1.9559, "input_0": 99, "input_1": 33, "min_CLP": -3.87, "draft_iters": 9.6, "mem_use": 44.53, "gen_rate": 7.2, "speed": 4.32, "text": "To start a successful gaming soc"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 5, "tree_size": 32, "t0": 1.522, "t1": 0.3, "tft": 2.609, "input_0": 98, "input_1": 33, "min_CLP": -3.53, "draft_iters": 11.2, "mem_use": 45.04, "gen_rate": 7.0, "speed": 3.84, "text": "While there is no immediate harm"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 2, "tree_h": 3.5, "tree_w": 18, "tree_size": 32, "t0": 0.605, "t1": 0.295, "tft": 1.7326, "input_0": 50, "input_1": 33, "min_CLP": -4.72, "draft_iters": 4.5, "mem_use": 44.68, "gen_rate": 1.0, "speed": 1.11, "text": "Tell them about a joke."}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 7.4, "tree_w": 11, "tree_size": 32, "t0": 1.1127, "t1": 0.2982, "tft": 4.6344, "input_0": 74, "input_1": 33, "min_CLP": -4.2, "draft_iters": 8.4, "mem_use": 44.79, "gen_rate": 3.2, "speed": 2.25, "text": " [TEACHER] Given the dialogue, t"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 1.12, "t1": 0.2925, "tft": 1.6157, "input_0": 81, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.1, "mem_use": 44.19, "gen_rate": 4.0, "speed": 2.83, "text": "\"I'm currently thinking about th"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 6, "tree_size": 32, "t0": 1.34, "t1": 0.296, "tft": 2.4434, "input_0": 108, "input_1": 33, "min_CLP": -3.94, "draft_iters": 9.6, "mem_use": 44.2, "gen_rate": 6.8, "speed": 4.15, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 3, "tree_size": 32, "t0": 3.28, "t1": 0.295, "tft": 2.6776, "input_0": 150, "input_1": 33, "min_CLP": -3.33, "draft_iters": 25.5, "mem_use": 44.73, "gen_rate": 26.0, "speed": 7.26, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 6, "tree_size": 32, "t0": 1.802, "t1": 0.296, "tft": 2.0619, "input_0": 105, "input_1": 33, "min_CLP": -3.6, "draft_iters": 13.2, "mem_use": 44.5, "gen_rate": 6.4, "speed": 3.05, "text": "Sure! Below is an example of HTM"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 1.3533, "t1": 0.29, "tft": 1.9193, "input_0": 96, "input_1": 33, "min_CLP": -3.87, "draft_iters": 9.8, "mem_use": 44.28, "gen_rate": 5.5, "speed": 3.35, "text": "To rewrite the phone conversatio"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 5, "tree_size": 32, "t0": 1.4875, "t1": 0.29, "tft": 2.722, "input_0": 110, "input_1": 33, "min_CLP": -3.56, "draft_iters": 10.5, "mem_use": 44.25, "gen_rate": 8.2, "speed": 4.64, "text": "\"The reason you can't see the st"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 26, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.8375, "t1": 0.2962, "tft": 2.119, "input_0": 72, "input_1": 33, "min_CLP": -4.47, "draft_iters": 5.9, "mem_use": 44.81, "gen_rate": 3.2, "speed": 2.86, "text": "The image was chosen to represen"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.7, "tree_w": 8, "tree_size": 32, "t0": 1.0857, "t1": 0.3129, "tft": 4.9046, "input_0": 95, "input_1": 33, "min_CLP": -3.93, "draft_iters": 7.7, "mem_use": 47.87, "gen_rate": 5.1, "speed": 3.67, "text": "\"It is not ethical or legal to u"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.9378, "t1": 0.3033, "tft": 3.3702, "input_0": 75, "input_1": 33, "min_CLP": -4.18, "draft_iters": 6.8, "mem_use": 46.61, "gen_rate": 3.9, "speed": 3.13, "text": "\"I understand your concern about"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.5, "tree_w": 10, "tree_size": 32, "t0": 0.9013, "t1": 0.2975, "tft": 2.5395, "input_0": 83, "input_1": 33, "min_CLP": -4.28, "draft_iters": 6.5, "mem_use": 44.87, "gen_rate": 4.5, "speed": 3.75, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.0, "tree_w": 6, "tree_size": 32, "t0": 2.59, "t1": 0.295, "tft": 2.0741, "input_0": 108, "input_1": 33, "min_CLP": -4.22, "draft_iters": 20.5, "mem_use": 44.2, "gen_rate": 19.5, "speed": 6.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 9, "tree_size": 32, "t0": 1.0437, "t1": 0.2913, "tft": 1.6598, "input_0": 85, "input_1": 33, "min_CLP": -3.96, "draft_iters": 7.5, "mem_use": 44.19, "gen_rate": 4.0, "speed": 3.0, "text": "Yes, I am familiar with the Germ"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 26.0, "tree_w": 2, "tree_size": 32, "t0": 3.41, "t1": 0.29, "tft": 1.9111, "input_0": 110, "input_1": 33, "min_CLP": -4.06, "draft_iters": 27.0, "mem_use": 44.39, "gen_rate": 23.0, "speed": 6.21, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 1.182, "t1": 0.31, "tft": 2.8576, "input_0": 88, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.4, "mem_use": 45.28, "gen_rate": 6.6, "speed": 4.43, "text": "To determine the number of acces"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.1833, "t1": 0.3083, "tft": 3.9339, "input_0": 94, "input_1": 33, "min_CLP": -3.9, "draft_iters": 8.5, "mem_use": 45.87, "gen_rate": 5.5, "speed": 3.69, "text": "\"Yes, AI image generators like S"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 13, "tree_size": 32, "t0": 0.9743, "t1": 0.2971, "tft": 2.0707, "input_0": 74, "input_1": 33, "min_CLP": -4.34, "draft_iters": 7.1, "mem_use": 44.25, "gen_rate": 4.9, "speed": 3.82, "text": "Sure, here are a few examples of"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 17.0, "tree_w": 6, "tree_size": 32, "t0": 2.25, "t1": 0.3033, "tft": 2.7642, "input_0": 89, "input_1": 33, "min_CLP": -4.37, "draft_iters": 18.0, "mem_use": 44.62, "gen_rate": 16.3, "speed": 6.4, "text": "o\\n     /|\\\\\\n     / \\\\\\n     | "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.5, "tree_w": 4, "tree_size": 32, "t0": 2.625, "t1": 0.29, "tft": 2.1877, "input_0": 112, "input_1": 33, "min_CLP": -4.15, "draft_iters": 21.0, "mem_use": 44.2, "gen_rate": 19.5, "speed": 6.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.8, "tree_w": 6, "tree_size": 32, "t0": 1.5975, "t1": 0.3, "tft": 2.3635, "input_0": 113, "input_1": 33, "min_CLP": -3.73, "draft_iters": 11.8, "mem_use": 44.56, "gen_rate": 9.5, "speed": 5.01, "text": "Yes, there is a widely accepted "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 1.13, "t1": 0.2914, "tft": 2.5178, "input_0": 89, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.3, "mem_use": 44.48, "gen_rate": 4.6, "speed": 3.21, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 1.3375, "t1": 0.3075, "tft": 3.4444, "input_0": 109, "input_1": 33, "min_CLP": -4.12, "draft_iters": 9.8, "mem_use": 46.53, "gen_rate": 8.2, "speed": 5.01, "text": "\"Alright, let's get started. The"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.7, "tree_w": 17, "tree_size": 32, "t0": 1.71, "t1": 0.2967, "tft": 1.8466, "input_0": 75, "input_1": 33, "min_CLP": -4.47, "draft_iters": 13.7, "mem_use": 44.37, "gen_rate": 13.0, "speed": 6.46, "text": "```\\n                /\\\\\\n      "}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.3329, "t1": 0.3171, "tft": 4.4462, "input_0": 96, "input_1": 33, "min_CLP": -3.94, "draft_iters": 9.6, "mem_use": 47.24, "gen_rate": 4.6, "speed": 2.77, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.364, "t1": 0.298, "tft": 2.1067, "input_0": 98, "input_1": 33, "min_CLP": -3.86, "draft_iters": 9.6, "mem_use": 44.24, "gen_rate": 6.4, "speed": 3.85, "text": "\"Sure, I can create ASCII art! H"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.5325, "t1": 0.295, "tft": 2.5033, "input_0": 111, "input_1": 33, "min_CLP": -3.19, "draft_iters": 11.0, "mem_use": 44.2, "gen_rate": 8.2, "speed": 4.51, "text": "HTML is a markup language used t"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.3, "tree_w": 5, "tree_size": 32, "t0": 1.84, "t1": 0.2933, "tft": 1.7748, "input_0": 124, "input_1": 33, "min_CLP": -3.2, "draft_iters": 13.3, "mem_use": 44.22, "gen_rate": 12.3, "speed": 5.78, "text": "\"Sure! Here's a table with the p"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.9088, "t1": 0.2962, "tft": 1.7935, "input_0": 75, "input_1": 33, "min_CLP": -4.35, "draft_iters": 6.5, "mem_use": 44.59, "gen_rate": 4.1, "speed": 3.42, "text": "\"Charles O'Rear, the photographe"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 20.3, "tree_w": 4, "tree_size": 32, "t0": 2.6467, "t1": 0.29, "tft": 2.129, "input_0": 113, "input_1": 33, "min_CLP": -3.98, "draft_iters": 21.0, "mem_use": 44.21, "gen_rate": 17.7, "speed": 6.02, "text": "Detailed Instructions: In this t"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 5, "tree_size": 32, "t0": 1.6125, "t1": 0.3075, "tft": 3.0688, "input_0": 107, "input_1": 33, "min_CLP": -3.83, "draft_iters": 11.5, "mem_use": 45.27, "gen_rate": 8.5, "speed": 4.43, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 1.1467, "t1": 0.3083, "tft": 2.0282, "input_0": 92, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.0, "mem_use": 44.98, "gen_rate": 5.3, "speed": 3.66, "text": "In this case, you might consider"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 1.1, "t1": 0.3043, "tft": 1.9783, "input_0": 83, "input_1": 33, "min_CLP": -4.06, "draft_iters": 7.7, "mem_use": 44.82, "gen_rate": 4.9, "speed": 3.46, "text": "\"Yes, if everyone just pirates t"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.7, "tree_w": 8, "tree_size": 32, "t0": 1.61, "t1": 0.3086, "tft": 2.6429, "input_0": 93, "input_1": 33, "min_CLP": -3.9, "draft_iters": 11.7, "mem_use": 45.55, "gen_rate": 5.1, "speed": 2.68, "text": "Thank you for your response. I u"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 11, "tree_size": 32, "t0": 1.1233, "t1": 0.2933, "tft": 1.7084, "input_0": 93, "input_1": 33, "min_CLP": -4.18, "draft_iters": 8.2, "mem_use": 44.18, "gen_rate": 5.5, "speed": 3.88, "text": "\"Sure! Here's a simple ASCII art"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 8.5, "tree_w": 8, "tree_size": 32, "t0": 1.3017, "t1": 0.295, "tft": 1.6585, "input_0": 99, "input_1": 33, "min_CLP": -4.04, "draft_iters": 9.5, "mem_use": 44.5, "gen_rate": 7.2, "speed": 4.49, "text": "\"Of course! Here are some of the"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.48, "t1": 0.3017, "tft": 3.2401, "input_0": 90, "input_1": 33, "min_CLP": -4.12, "draft_iters": 11.0, "mem_use": 45.25, "gen_rate": 6.2, "speed": 3.46, "text": "\"The James Webb Space Telescope "}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.9713, "t1": 0.2987, "tft": 1.8188, "input_0": 86, "input_1": 33, "min_CLP": -4.58, "draft_iters": 6.8, "mem_use": 44.3, "gen_rate": 4.4, "speed": 3.44, "text": "Motion Matching is an animation "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 4, "tree_size": 32, "t0": 2.7133, "t1": 0.31, "tft": 3.7878, "input_0": 129, "input_1": 33, "min_CLP": -3.03, "draft_iters": 21.0, "mem_use": 45.93, "gen_rate": 13.0, "speed": 4.31, "text": "\"Sure! Here's an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.0, "tree_w": 6, "tree_size": 32, "t0": 2.705, "t1": 0.3, "tft": 2.6969, "input_0": 86, "input_1": 33, "min_CLP": -3.76, "draft_iters": 21.5, "mem_use": 44.25, "gen_rate": 18.5, "speed": 6.15, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 1.0656, "t1": 0.2989, "tft": 2.3888, "input_0": 76, "input_1": 33, "min_CLP": -4.3, "draft_iters": 7.8, "mem_use": 44.63, "gen_rate": 3.8, "speed": 2.77, "text": "Sure! Here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.0, "tree_w": 5, "tree_size": 32, "t0": 1.535, "t1": 0.305, "tft": 4.2674, "input_0": 110, "input_1": 33, "min_CLP": -3.64, "draft_iters": 11.0, "mem_use": 45.94, "gen_rate": 6.2, "speed": 3.35, "text": "The idea of 100 monkeys on a typ"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 1.0429, "t1": 0.3086, "tft": 3.4467, "input_0": 86, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.4, "mem_use": 46.38, "gen_rate": 4.6, "speed": 3.38, "text": "\"Paul Allen's plane collection i"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 1.388, "t1": 0.308, "tft": 3.294, "input_0": 95, "input_1": 33, "min_CLP": -3.67, "draft_iters": 10.2, "mem_use": 45.81, "gen_rate": 6.8, "speed": 4.01, "text": "Yes, there is a similar case in "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.3, "tree_w": 7, "tree_size": 32, "t0": 1.5267, "t1": 0.3, "tft": 1.6431, "input_0": 99, "input_1": 33, "min_CLP": -3.97, "draft_iters": 11.3, "mem_use": 44.28, "gen_rate": 6.7, "speed": 3.65, "text": "\"Romeo is the character most to "}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 1.2833, "t1": 0.3017, "tft": 2.1299, "input_0": 94, "input_1": 33, "min_CLP": -4.01, "draft_iters": 9.2, "mem_use": 44.91, "gen_rate": 6.2, "speed": 3.89, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.4, "t1": 0.2983, "tft": 2.8823, "input_0": 98, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.0, "mem_use": 44.31, "gen_rate": 6.2, "speed": 3.63, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 8.4, "tree_w": 7, "tree_size": 32, "t0": 1.33, "t1": 0.3, "tft": 1.9252, "input_0": 93, "input_1": 33, "min_CLP": -3.8, "draft_iters": 9.4, "mem_use": 44.2, "gen_rate": 8.0, "speed": 4.91, "text": "Yes, the 5-second rule does exis"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.8325, "t1": 0.305, "tft": 2.8266, "input_0": 71, "input_1": 33, "min_CLP": -4.58, "draft_iters": 5.9, "mem_use": 45.03, "gen_rate": 4.1, "speed": 3.64, "text": "\"You're welcome! I'm glad to be "}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.3, "tree_w": 10, "tree_size": 32, "t0": 1.1117, "t1": 0.305, "tft": 3.4293, "input_0": 76, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.3, "mem_use": 45.84, "gen_rate": 6.3, "speed": 4.46, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 1.3667, "t1": 0.3117, "tft": 4.3127, "input_0": 95, "input_1": 33, "min_CLP": -3.8, "draft_iters": 9.8, "mem_use": 46.75, "gen_rate": 5.3, "speed": 3.18, "text": "\"Oh, the Multi-Track Drifting So"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.7, "tree_w": 5, "tree_size": 32, "t0": 1.7667, "t1": 0.3067, "tft": 3.367, "input_0": 129, "input_1": 33, "min_CLP": -3.96, "draft_iters": 12.7, "mem_use": 45.35, "gen_rate": 11.0, "speed": 5.3, "text": "\"It is theoretically possible to"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 3, "tree_size": 32, "t0": 3.205, "t1": 0.31, "tft": 2.485, "input_0": 121, "input_1": 33, "min_CLP": -4.05, "draft_iters": 25.0, "mem_use": 45.18, "gen_rate": 25.5, "speed": 7.26, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 5, "tree_size": 32, "t0": 1.565, "t1": 0.3025, "tft": 2.7628, "input_0": 94, "input_1": 33, "min_CLP": -3.94, "draft_iters": 11.5, "mem_use": 44.95, "gen_rate": 8.8, "speed": 4.69, "text": "In Japanese, \"love\" is \"\u611b (ai)\","}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 7.4, "tree_w": 10, "tree_size": 32, "t0": 1.1833, "t1": 0.2978, "tft": 1.8743, "input_0": 89, "input_1": 33, "min_CLP": -4.09, "draft_iters": 8.4, "mem_use": 44.49, "gen_rate": 4.4, "speed": 3.0, "text": "In Europe, some of the best univ"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 1.474, "t1": 0.3, "tft": 2.2192, "input_0": 118, "input_1": 33, "min_CLP": -3.77, "draft_iters": 10.4, "mem_use": 44.18, "gen_rate": 7.8, "speed": 4.4, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 17.0, "tree_w": 4, "tree_size": 32, "t0": 2.45, "t1": 0.3, "tft": 1.9683, "input_0": 143, "input_1": 33, "min_CLP": -2.99, "draft_iters": 18.0, "mem_use": 44.31, "gen_rate": 16.5, "speed": 6.01, "text": "Here is a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.0, "tree_w": 12, "tree_size": 32, "t0": 1.12, "t1": 0.3086, "tft": 2.9197, "input_0": 74, "input_1": 33, "min_CLP": -4.31, "draft_iters": 8.0, "mem_use": 45.44, "gen_rate": 5.3, "speed": 3.7, "text": "1. Financial stress: \\n    a. Cr"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 7, "tree_size": 32, "t0": 1.305, "t1": 0.3, "tft": 1.9838, "input_0": 90, "input_1": 33, "min_CLP": -3.98, "draft_iters": 9.2, "mem_use": 44.18, "gen_rate": 5.5, "speed": 3.42, "text": "As an AI language model, I don\\'"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.7, "tree_w": 6, "tree_size": 32, "t0": 1.61, "t1": 0.3133, "tft": 4.351, "input_0": 113, "input_1": 33, "min_CLP": -3.48, "draft_iters": 11.7, "mem_use": 46.85, "gen_rate": 6.3, "speed": 3.3, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 1.444, "t1": 0.3, "tft": 2.1388, "input_0": 102, "input_1": 33, "min_CLP": -4.17, "draft_iters": 10.4, "mem_use": 44.47, "gen_rate": 7.2, "speed": 4.13, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.8, "tree_w": 14, "tree_size": 32, "t0": 0.9213, "t1": 0.2962, "tft": 2.4135, "input_0": 64, "input_1": 33, "min_CLP": -4.95, "draft_iters": 6.8, "mem_use": 44.26, "gen_rate": 4.0, "speed": 3.28, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 1.3057, "t1": 0.3086, "tft": 4.0491, "input_0": 104, "input_1": 33, "min_CLP": -3.72, "draft_iters": 9.3, "mem_use": 46.44, "gen_rate": 4.9, "speed": 3.01, "text": "Here are some open-source 2D ani"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.685, "t1": 0.295, "tft": 2.769, "input_0": 117, "input_1": 33, "min_CLP": -3.43, "draft_iters": 12.0, "mem_use": 44.25, "gen_rate": 10.2, "speed": 5.18, "text": "To use software defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.8, "tree_w": 14, "tree_size": 32, "t0": 0.9045, "t1": 0.3064, "tft": 2.8091, "input_0": 65, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.8, "mem_use": 44.96, "gen_rate": 3.1, "speed": 2.55, "text": "\"Again, no, there isn't. \\n\\nThe"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 54, "tree_h": 18.0, "tree_w": 5, "tree_size": 32, "t0": 2.46, "t1": 0.305, "tft": 4.1139, "input_0": 119, "input_1": 33, "min_CLP": -3.77, "draft_iters": 18.8, "mem_use": 45.82, "gen_rate": 13.5, "speed": 4.88, "text": "1. m\u00eb (suffix) - \"m\u00eb\"\\n2. meles,"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 1.0567, "t1": 0.2967, "tft": 1.7554, "input_0": 79, "input_1": 33, "min_CLP": -4.14, "draft_iters": 7.7, "mem_use": 44.5, "gen_rate": 5.5, "speed": 4.07, "text": "\"As an AI language model, my pri"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.3, "tree_w": 8, "tree_size": 32, "t0": 1.0233, "t1": 0.315, "tft": 4.1076, "input_0": 84, "input_1": 33, "min_CLP": -4.01, "draft_iters": 7.3, "mem_use": 47.27, "gen_rate": 5.8, "speed": 4.36, "text": "I apologize for the confusion in"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 1.095, "t1": 0.2938, "tft": 2.0536, "input_0": 81, "input_1": 33, "min_CLP": -3.97, "draft_iters": 8.0, "mem_use": 44.21, "gen_rate": 4.2, "speed": 3.06, "text": "\"In reStructuredText (rst), you "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.7, "tree_w": 4, "tree_size": 32, "t0": 1.8933, "t1": 0.3067, "tft": 3.4981, "input_0": 143, "input_1": 33, "min_CLP": -3.12, "draft_iters": 13.7, "mem_use": 46.22, "gen_rate": 13.0, "speed": 5.9, "text": "\"Here's an example code for step"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 23, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 1.366, "t1": 0.296, "tft": 2.5664, "input_0": 92, "input_1": 33, "min_CLP": -4.19, "draft_iters": 10.0, "mem_use": 44.2, "gen_rate": 4.6, "speed": 2.77, "text": "This task is about translating a"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 9, "tree_size": 32, "t0": 0.9914, "t1": 0.3, "tft": 1.7694, "input_0": 82, "input_1": 33, "min_CLP": -4.11, "draft_iters": 7.1, "mem_use": 44.65, "gen_rate": 4.9, "speed": 3.76, "text": "Yes, there is a possibility that"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 11, "tree_size": 32, "t0": 1.0413, "t1": 0.3275, "tft": 5.9963, "input_0": 89, "input_1": 33, "min_CLP": -4.32, "draft_iters": 7.5, "mem_use": 49.82, "gen_rate": 4.1, "speed": 3.01, "text": "\"Yes, of course! Here it is:\\n\\n"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.97, "t1": 0.3033, "tft": 2.7665, "input_0": 88, "input_1": 33, "min_CLP": -4.36, "draft_iters": 6.8, "mem_use": 45.03, "gen_rate": 5.3, "speed": 4.2, "text": "0 An independent counsel is an i"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 1.1367, "t1": 0.3133, "tft": 3.9973, "input_0": 87, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.0, "mem_use": 46.88, "gen_rate": 3.7, "speed": 2.53, "text": "\"I apologize, but I'm afraid tha"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 1.205, "t1": 0.305, "tft": 2.4335, "input_0": 88, "input_1": 33, "min_CLP": -4.11, "draft_iters": 8.7, "mem_use": 45.25, "gen_rate": 5.8, "speed": 3.86, "text": "1. Economic downturn: If the loc"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.98, "t1": 0.3, "tft": 2.7454, "input_0": 126, "input_1": 33, "min_CLP": -4.13, "draft_iters": 32.0, "mem_use": 44.53, "gen_rate": 33.0, "speed": 7.71, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.5, "tree_w": 5, "tree_size": 32, "t0": 1.7425, "t1": 0.31, "tft": 5.0079, "input_0": 121, "input_1": 33, "min_CLP": -3.71, "draft_iters": 12.5, "mem_use": 47.0, "gen_rate": 9.2, "speed": 4.51, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 9, "tree_size": 32, "t0": 0.9971, "t1": 0.2914, "tft": 2.1242, "input_0": 86, "input_1": 33, "min_CLP": -3.91, "draft_iters": 7.1, "mem_use": 44.71, "gen_rate": 4.9, "speed": 3.76, "text": "To determine the most cost-effec"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.8, "tree_w": 5, "tree_size": 32, "t0": 1.655, "t1": 0.3075, "tft": 4.8997, "input_0": 127, "input_1": 33, "min_CLP": -3.45, "draft_iters": 11.8, "mem_use": 46.67, "gen_rate": 10.2, "speed": 5.23, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 1.0429, "t1": 0.2943, "tft": 2.1912, "input_0": 88, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.6, "mem_use": 44.23, "gen_rate": 4.9, "speed": 3.63, "text": "```lean\\nimport data.list.basic\\"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 18, "tree_h": 6.4, "tree_w": 11, "tree_size": 32, "t0": 1.046, "t1": 0.302, "tft": 2.4066, "input_0": 74, "input_1": 33, "min_CLP": -4.25, "draft_iters": 7.4, "mem_use": 44.96, "gen_rate": 3.6, "speed": 2.67, "text": "The law was created in 1995\\n[IN"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 1.3257, "t1": 0.2986, "tft": 2.0139, "input_0": 88, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.7, "mem_use": 44.68, "gen_rate": 5.0, "speed": 3.08, "text": "To help alleviate your symptoms "}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.19, "t1": 0.2975, "tft": 2.1714, "input_0": 84, "input_1": 33, "min_CLP": -4.04, "draft_iters": 8.8, "mem_use": 44.27, "gen_rate": 4.2, "speed": 2.86, "text": "\"Here is a simple implementation"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.2, "tree_w": 8, "tree_size": 32, "t0": 1.408, "t1": 0.304, "tft": 2.9431, "input_0": 98, "input_1": 33, "min_CLP": -4.21, "draft_iters": 10.2, "mem_use": 45.16, "gen_rate": 7.0, "speed": 4.09, "text": "\"It's natural to feel this way, "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 22.2, "tree_w": 2, "tree_size": 32, "t0": 3.07, "t1": 0.3075, "tft": 4.0375, "input_0": 139, "input_1": 33, "min_CLP": -3.21, "draft_iters": 23.0, "mem_use": 46.76, "gen_rate": 8.2, "speed": 2.44, "text": "Sure! Here is a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.8, "tree_w": 5, "tree_size": 32, "t0": 1.8425, "t1": 0.3, "tft": 2.0091, "input_0": 104, "input_1": 33, "min_CLP": -3.18, "draft_iters": 13.8, "mem_use": 44.39, "gen_rate": 9.0, "speed": 4.21, "text": "The total travel time would be t"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.4, "tree_w": 5, "tree_size": 32, "t0": 1.848, "t1": 0.298, "tft": 2.4126, "input_0": 120, "input_1": 33, "min_CLP": -3.78, "draft_iters": 13.4, "mem_use": 44.3, "gen_rate": 7.4, "speed": 3.45, "text": "\"```js\\n// Import the required m"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 1.19, "t1": 0.298, "tft": 1.913, "input_0": 90, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.8, "mem_use": 44.2, "gen_rate": 6.4, "speed": 4.31, "text": "Yes, I am capable of assisting y"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.4, "tree_w": 7, "tree_size": 32, "t0": 1.29, "t1": 0.312, "tft": 4.9345, "input_0": 92, "input_1": 33, "min_CLP": -3.72, "draft_iters": 9.4, "mem_use": 47.98, "gen_rate": 6.6, "speed": 4.12, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 20.0, "tree_w": 3, "tree_size": 32, "t0": 2.82, "t1": 0.3, "tft": 3.1802, "input_0": 102, "input_1": 33, "min_CLP": -2.89, "draft_iters": 21.0, "mem_use": 44.31, "gen_rate": 0.0, "speed": 0.0, "text": "Mike."}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.4, "tree_w": 7, "tree_size": 32, "t0": 1.1829, "t1": 0.3071, "tft": 2.5933, "input_0": 86, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.4, "mem_use": 45.35, "gen_rate": 5.4, "speed": 3.65, "text": "The best way to get experience p"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 1.278, "t1": 0.31, "tft": 4.0532, "input_0": 99, "input_1": 33, "min_CLP": -3.8, "draft_iters": 8.8, "mem_use": 47.12, "gen_rate": 6.4, "speed": 4.04, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 7, "tree_size": 32, "t0": 1.0975, "t1": 0.2913, "tft": 1.8122, "input_0": 81, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.0, "mem_use": 44.45, "gen_rate": 4.2, "speed": 3.06, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 9, "tree_size": 32, "t0": 1.2933, "t1": 0.3033, "tft": 2.7424, "input_0": 83, "input_1": 33, "min_CLP": -4.32, "draft_iters": 9.5, "mem_use": 44.96, "gen_rate": 5.3, "speed": 3.34, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 7, "tree_size": 32, "t0": 1.63, "t1": 0.305, "tft": 4.339, "input_0": 113, "input_1": 33, "min_CLP": -3.49, "draft_iters": 12.0, "mem_use": 46.69, "gen_rate": 8.5, "speed": 4.39, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.435, "t1": 0.2967, "tft": 3.0679, "input_0": 100, "input_1": 33, "min_CLP": -3.95, "draft_iters": 10.0, "mem_use": 45.08, "gen_rate": 5.8, "speed": 3.37, "text": "The television was invented by P"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 1.5325, "t1": 0.3125, "tft": 4.3773, "input_0": 99, "input_1": 33, "min_CLP": -3.61, "draft_iters": 11.2, "mem_use": 47.42, "gen_rate": 9.2, "speed": 5.01, "text": "\"I'm glad I could help. If you h"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 7, "tree_size": 32, "t0": 1.47, "t1": 0.305, "tft": 3.5693, "input_0": 104, "input_1": 33, "min_CLP": -3.75, "draft_iters": 10.7, "mem_use": 45.74, "gen_rate": 5.7, "speed": 3.19, "text": "There are multiple days in which"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 1.0986, "t1": 0.2943, "tft": 2.011, "input_0": 85, "input_1": 33, "min_CLP": -4.39, "draft_iters": 7.9, "mem_use": 44.77, "gen_rate": 5.9, "speed": 4.2, "text": "\"Understood. I'll try my best to"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.336, "t1": 0.308, "tft": 4.4353, "input_0": 104, "input_1": 33, "min_CLP": -3.71, "draft_iters": 9.6, "mem_use": 46.56, "gen_rate": 7.0, "speed": 4.25, "text": "One of the most difficult parts "}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 6, "tree_size": 32, "t0": 1.755, "t1": 0.2925, "tft": 1.6307, "input_0": 110, "input_1": 33, "min_CLP": -3.63, "draft_iters": 13.0, "mem_use": 44.39, "gen_rate": 8.5, "speed": 4.15, "text": "Yes, it is possible for you to o"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 1.1056, "t1": 0.3011, "tft": 2.6147, "input_0": 78, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.1, "mem_use": 45.01, "gen_rate": 3.7, "speed": 2.61, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.6, "tree_w": 12, "tree_size": 32, "t0": 1.0171, "t1": 0.2971, "tft": 2.0364, "input_0": 71, "input_1": 33, "min_CLP": -4.64, "draft_iters": 7.6, "mem_use": 44.48, "gen_rate": 5.3, "speed": 4.02, "text": "[INST] Tell me a joke mocking Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 5, "tree_size": 32, "t0": 1.7367, "t1": 0.29, "tft": 2.1621, "input_0": 114, "input_1": 33, "min_CLP": -3.49, "draft_iters": 12.7, "mem_use": 44.5, "gen_rate": 10.7, "speed": 5.26, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 1.165, "t1": 0.3017, "tft": 2.5192, "input_0": 86, "input_1": 33, "min_CLP": -4.29, "draft_iters": 8.5, "mem_use": 44.88, "gen_rate": 5.7, "speed": 3.86, "text": "Google Authenticator is a mobile"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 9.0, "tree_w": 5, "tree_size": 32, "t0": 1.375, "t1": 0.295, "tft": 3.4181, "input_0": 102, "input_1": 33, "min_CLP": -3.86, "draft_iters": 10.0, "mem_use": 44.67, "gen_rate": 6.8, "speed": 4.09, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.3867, "t1": 0.2983, "tft": 1.904, "input_0": 103, "input_1": 33, "min_CLP": -3.64, "draft_iters": 10.0, "mem_use": 44.43, "gen_rate": 5.3, "speed": 3.16, "text": "Here is a sample code in Roblox "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.2, "tree_w": 6, "tree_size": 32, "t0": 1.2575, "t1": 0.2925, "tft": 2.2891, "input_0": 103, "input_1": 33, "min_CLP": -3.87, "draft_iters": 9.2, "mem_use": 44.28, "gen_rate": 8.0, "speed": 5.16, "text": "To improve your Wi-Fi coverage i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 5.7, "tree_w": 14, "tree_size": 32, "t0": 0.923, "t1": 0.296, "tft": 1.8017, "input_0": 63, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.7, "mem_use": 44.31, "gen_rate": 3.7, "speed": 3.03, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 7, "tree_size": 32, "t0": 1.3671, "t1": 0.3, "tft": 1.5104, "input_0": 100, "input_1": 33, "min_CLP": -3.82, "draft_iters": 9.9, "mem_use": 44.23, "gen_rate": 5.0, "speed": 3.0, "text": "Here is a draft for a whitepaper"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 6, "tree_size": 32, "t0": 1.646, "t1": 0.302, "tft": 2.7422, "input_0": 98, "input_1": 33, "min_CLP": -3.79, "draft_iters": 12.4, "mem_use": 45.41, "gen_rate": 6.6, "speed": 3.38, "text": "You can use your local laptop as"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 1.1486, "t1": 0.2929, "tft": 2.1955, "input_0": 95, "input_1": 33, "min_CLP": -3.98, "draft_iters": 8.4, "mem_use": 44.18, "gen_rate": 5.6, "speed": 3.87, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 1.39, "t1": 0.2925, "tft": 1.9613, "input_0": 111, "input_1": 33, "min_CLP": -3.85, "draft_iters": 10.0, "mem_use": 44.2, "gen_rate": 9.2, "speed": 5.5, "text": "I think ChatGPT is an impressive"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.2157, "t1": 0.2971, "tft": 1.817, "input_0": 87, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.0, "mem_use": 44.5, "gen_rate": 4.9, "speed": 3.21, "text": "\"As a master psychologist, I wou"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 5.7, "tree_w": 10, "tree_size": 32, "t0": 0.9486, "t1": 0.2943, "tft": 1.7189, "input_0": 75, "input_1": 33, "min_CLP": -4.2, "draft_iters": 6.7, "mem_use": 44.23, "gen_rate": 3.7, "speed": 2.99, "text": "Hello, Malbolge program! How can"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 19.5, "tree_w": 7, "tree_size": 32, "t0": 2.51, "t1": 0.295, "tft": 2.5334, "input_0": 112, "input_1": 33, "min_CLP": -3.23, "draft_iters": 20.0, "mem_use": 44.93, "gen_rate": 18.0, "speed": 6.42, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 3, "tree_size": 32, "t0": 3.09, "t1": 0.315, "tft": 4.2812, "input_0": 132, "input_1": 33, "min_CLP": -4.66, "draft_iters": 24.0, "mem_use": 47.45, "gen_rate": 24.5, "speed": 7.2, "text": "The current date is 2023-02-06.\\"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.6, "tree_w": 6, "tree_size": 32, "t0": 1.4343, "t1": 0.2943, "tft": 3.0708, "input_0": 96, "input_1": 33, "min_CLP": -3.56, "draft_iters": 10.6, "mem_use": 44.74, "gen_rate": 5.4, "speed": 3.14, "text": "Yes, there is a difference betwe"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 1.1733, "t1": 0.3056, "tft": 3.2921, "input_0": 84, "input_1": 33, "min_CLP": -3.83, "draft_iters": 8.7, "mem_use": 45.86, "gen_rate": 4.2, "speed": 2.85, "text": "\"Hello, Agent. It's good to see "}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.9383, "t1": 0.3, "tft": 2.9143, "input_0": 59, "input_1": 33, "min_CLP": -4.53, "draft_iters": 7.0, "mem_use": 44.73, "gen_rate": 6.0, "speed": 4.85, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 4, "tree_size": 32, "t0": 1.8225, "t1": 0.3175, "tft": 4.7141, "input_0": 115, "input_1": 33, "min_CLP": -3.42, "draft_iters": 13.2, "mem_use": 47.63, "gen_rate": 8.0, "speed": 3.74, "text": "Sure! Here are some simple examp"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.4, "tree_w": 5, "tree_size": 32, "t0": 1.604, "t1": 0.368, "tft": 9.6303, "input_0": 123, "input_1": 33, "min_CLP": -3.54, "draft_iters": 11.4, "mem_use": 53.66, "gen_rate": 7.6, "speed": 3.85, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 1.15, "t1": 0.3033, "tft": 3.5861, "input_0": 86, "input_1": 33, "min_CLP": -4.15, "draft_iters": 8.2, "mem_use": 45.97, "gen_rate": 6.5, "speed": 4.47, "text": "\"L'H\u00f4pital's Rule, as a mathemat"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.0, "tree_w": 4, "tree_size": 32, "t0": 1.8767, "t1": 0.3, "tft": 1.9227, "input_0": 126, "input_1": 33, "min_CLP": -4.01, "draft_iters": 14.0, "mem_use": 44.24, "gen_rate": 11.7, "speed": 5.36, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 1.38, "t1": 0.294, "tft": 1.9712, "input_0": 103, "input_1": 33, "min_CLP": -3.9, "draft_iters": 9.8, "mem_use": 44.36, "gen_rate": 6.6, "speed": 3.95, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.0, "tree_w": 11, "tree_size": 32, "t0": 1.12, "t1": 0.3122, "tft": 4.1092, "input_0": 81, "input_1": 33, "min_CLP": -4.32, "draft_iters": 8.0, "mem_use": 47.14, "gen_rate": 3.7, "speed": 2.56, "text": "Sure, here are some name suggest"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.255, "t1": 0.2933, "tft": 2.4219, "input_0": 96, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.0, "mem_use": 44.3, "gen_rate": 5.7, "speed": 3.66, "text": "In 1950, the world was quite dif"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.0, "tree_w": 5, "tree_size": 32, "t0": 1.4275, "t1": 0.325, "tft": 6.2317, "input_0": 116, "input_1": 33, "min_CLP": -3.54, "draft_iters": 10.0, "mem_use": 49.3, "gen_rate": 8.2, "speed": 4.71, "text": "Creating your own stable diffusi"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 9, "tree_size": 32, "t0": 1.354, "t1": 0.302, "tft": 1.8422, "input_0": 90, "input_1": 33, "min_CLP": -4.26, "draft_iters": 10.0, "mem_use": 44.64, "gen_rate": 7.0, "speed": 4.23, "text": "1. Install CPU\\n2. Install RAM\\n"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.1933, "t1": 0.3017, "tft": 2.3536, "input_0": 97, "input_1": 33, "min_CLP": -3.9, "draft_iters": 8.5, "mem_use": 44.49, "gen_rate": 6.5, "speed": 4.35, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 11, "tree_size": 32, "t0": 0.9512, "t1": 0.2975, "tft": 1.793, "input_0": 75, "input_1": 33, "min_CLP": -4.28, "draft_iters": 6.8, "mem_use": 44.55, "gen_rate": 4.2, "speed": 3.4, "text": "I am an AI assistant designed to"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.555, "t1": 0.3, "tft": 3.9667, "input_0": 126, "input_1": 33, "min_CLP": -3.83, "draft_iters": 11.0, "mem_use": 45.91, "gen_rate": 9.0, "speed": 4.85, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 5, "tree_size": 32, "t0": 1.616, "t1": 0.298, "tft": 3.1522, "input_0": 105, "input_1": 33, "min_CLP": -3.93, "draft_iters": 11.8, "mem_use": 44.62, "gen_rate": 7.4, "speed": 3.87, "text": "The KeyHole series of spy satell"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 1.23, "t1": 0.2943, "tft": 2.4025, "input_0": 94, "input_1": 33, "min_CLP": -4.02, "draft_iters": 9.0, "mem_use": 44.79, "gen_rate": 5.0, "speed": 3.28, "text": "\"Sure, here's a recipe you can t"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 1.354, "t1": 0.298, "tft": 3.0409, "input_0": 97, "input_1": 33, "min_CLP": -3.68, "draft_iters": 9.8, "mem_use": 44.86, "gen_rate": 6.4, "speed": 3.88, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 1.182, "t1": 0.304, "tft": 3.9667, "input_0": 98, "input_1": 33, "min_CLP": -3.89, "draft_iters": 8.6, "mem_use": 46.77, "gen_rate": 7.2, "speed": 4.84, "text": "Here are some YouTube channels t"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.17, "t1": 0.295, "tft": 1.9473, "input_0": 87, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.5, "mem_use": 44.2, "gen_rate": 5.3, "speed": 3.64, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 7, "tree_size": 32, "t0": 1.4267, "t1": 0.29, "tft": 2.0073, "input_0": 95, "input_1": 33, "min_CLP": -3.81, "draft_iters": 10.3, "mem_use": 44.34, "gen_rate": 5.7, "speed": 3.3, "text": "\"The answer to this question is\\"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.8867, "t1": 0.3022, "tft": 3.017, "input_0": 67, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.6, "mem_use": 45.78, "gen_rate": 4.0, "speed": 3.37, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 4.14, "t1": 0.31, "tft": 5.9623, "input_0": 166, "input_1": 33, "min_CLP": -3.33, "draft_iters": 32.0, "mem_use": 46.94, "gen_rate": 33.0, "speed": 7.42, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 6.0, "tree_w": 9, "tree_size": 32, "t0": 1.03, "t1": 0.3, "tft": 1.6844, "input_0": 84, "input_1": 33, "min_CLP": -3.91, "draft_iters": 7.0, "mem_use": 44.18, "gen_rate": 4.0, "speed": 3.01, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 8, "tree_size": 32, "t0": 1.0843, "t1": 0.3071, "tft": 3.5598, "input_0": 85, "input_1": 33, "min_CLP": -3.68, "draft_iters": 7.7, "mem_use": 45.66, "gen_rate": 5.0, "speed": 3.59, "text": "\"Yes, that's a great approach to"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 9, "tree_size": 32, "t0": 0.97, "t1": 0.2971, "tft": 1.7621, "input_0": 73, "input_1": 33, "min_CLP": -4.46, "draft_iters": 7.0, "mem_use": 44.55, "gen_rate": 4.9, "speed": 3.83, "text": "\"Dude, that's just so not true! "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.8, "tree_w": 4, "tree_size": 32, "t0": 1.865, "t1": 0.2925, "tft": 2.2557, "input_0": 122, "input_1": 33, "min_CLP": -3.36, "draft_iters": 13.8, "mem_use": 44.23, "gen_rate": 10.0, "speed": 4.64, "text": "Yes, I can help you with that. V"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 8, "tree_size": 32, "t0": 1.1371, "t1": 0.2957, "tft": 2.0636, "input_0": 93, "input_1": 33, "min_CLP": -3.93, "draft_iters": 7.9, "mem_use": 44.59, "gen_rate": 4.9, "speed": 3.39, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 3, "tree_size": 32, "t0": 2.95, "t1": 0.29, "tft": 2.4512, "input_0": 118, "input_1": 33, "min_CLP": -3.35, "draft_iters": 22.5, "mem_use": 44.18, "gen_rate": 23.0, "speed": 7.1, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 1.125, "t1": 0.3033, "tft": 3.3998, "input_0": 96, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.0, "mem_use": 45.51, "gen_rate": 6.5, "speed": 4.55, "text": "\"You're welcome! I'm happy to he"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 1.155, "t1": 0.295, "tft": 2.4621, "input_0": 73, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.5, "mem_use": 44.37, "gen_rate": 5.5, "speed": 3.79, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 6, "tree_size": 32, "t0": 1.77, "t1": 0.3, "tft": 2.3489, "input_0": 109, "input_1": 33, "min_CLP": -4.26, "draft_iters": 13.3, "mem_use": 44.75, "gen_rate": 12.0, "speed": 5.8, "text": "The oceans of the world, sorted "}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.3, "tree_w": 12, "tree_size": 32, "t0": 0.8711, "t1": 0.3033, "tft": 2.1581, "input_0": 70, "input_1": 33, "min_CLP": -4.4, "draft_iters": 6.3, "mem_use": 44.99, "gen_rate": 4.0, "speed": 3.41, "text": "One of the best ways to get star"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.3, "tree_w": 4, "tree_size": 32, "t0": 1.96, "t1": 0.2967, "tft": 1.919, "input_0": 113, "input_1": 33, "min_CLP": -3.26, "draft_iters": 14.3, "mem_use": 44.41, "gen_rate": 11.7, "speed": 5.18, "text": "Here is a basic PyGame project e"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.2217, "t1": 0.31, "tft": 3.3921, "input_0": 99, "input_1": 33, "min_CLP": -3.98, "draft_iters": 8.8, "mem_use": 45.51, "gen_rate": 5.7, "speed": 3.71, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 27, "tree_h": 9.7, "tree_w": 7, "tree_size": 32, "t0": 1.4567, "t1": 0.2933, "tft": 2.3321, "input_0": 91, "input_1": 33, "min_CLP": -4.05, "draft_iters": 10.7, "mem_use": 44.65, "gen_rate": 9.0, "speed": 5.13, "text": "I\\'m sorry, but I\\'m not sure wh"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 0.9933, "t1": 0.2922, "tft": 2.1636, "input_0": 75, "input_1": 33, "min_CLP": -4.28, "draft_iters": 7.1, "mem_use": 44.18, "gen_rate": 3.8, "speed": 2.94, "text": "The Infinite Banking Concept, al"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 1.2917, "t1": 0.29, "tft": 1.9476, "input_0": 92, "input_1": 33, "min_CLP": -3.63, "draft_iters": 9.3, "mem_use": 44.3, "gen_rate": 5.5, "speed": 3.48, "text": "\"Here's an example of a high-qua"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 27, "tree_h": 4.1, "tree_w": 14, "tree_size": 32, "t0": 0.7125, "t1": 0.2925, "tft": 1.7393, "input_0": 60, "input_1": 33, "min_CLP": -4.49, "draft_iters": 5.1, "mem_use": 44.45, "gen_rate": 3.4, "speed": 3.36, "text": "Tenants are the ones that are pa"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.9538, "t1": 0.2987, "tft": 2.4137, "input_0": 76, "input_1": 33, "min_CLP": -4.33, "draft_iters": 6.9, "mem_use": 44.97, "gen_rate": 4.4, "speed": 3.5, "text": "\"I don't think it's a matter of "}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.336, "t1": 0.306, "tft": 3.0962, "input_0": 104, "input_1": 33, "min_CLP": -3.63, "draft_iters": 9.6, "mem_use": 45.81, "gen_rate": 6.8, "speed": 4.14, "text": "\"Yes, of course! As an AI langua"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 1.562, "t1": 0.3, "tft": 3.3381, "input_0": 118, "input_1": 33, "min_CLP": -3.72, "draft_iters": 11.2, "mem_use": 46.35, "gen_rate": 7.0, "speed": 3.75, "text": "\"The difficulty of learning a la"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.2517, "t1": 0.2983, "tft": 2.3658, "input_0": 94, "input_1": 33, "min_CLP": -3.76, "draft_iters": 8.8, "mem_use": 44.79, "gen_rate": 6.3, "speed": 4.08, "text": "\"Some of these tools offer a fre"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.6, "tree_w": 10, "tree_size": 32, "t0": 0.9311, "t1": 0.3011, "tft": 2.2257, "input_0": 75, "input_1": 33, "min_CLP": -4.11, "draft_iters": 6.6, "mem_use": 44.65, "gen_rate": 3.9, "speed": 3.16, "text": "I don\u2019t have personal opinions o"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 1.238, "t1": 0.304, "tft": 2.2361, "input_0": 81, "input_1": 33, "min_CLP": -3.98, "draft_iters": 9.2, "mem_use": 44.87, "gen_rate": 7.0, "speed": 4.54, "text": "I don\\'t know what you mean by \""}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 5, "tree_size": 32, "t0": 1.585, "t1": 0.3, "tft": 3.2189, "input_0": 121, "input_1": 33, "min_CLP": -3.77, "draft_iters": 11.2, "mem_use": 44.88, "gen_rate": 8.8, "speed": 4.66, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.7, "tree_w": 10, "tree_size": 32, "t0": 1.0689, "t1": 0.2956, "tft": 2.2396, "input_0": 76, "input_1": 33, "min_CLP": -4.36, "draft_iters": 7.7, "mem_use": 44.3, "gen_rate": 4.0, "speed": 2.94, "text": "\"<|bot|> I'm happy to help you d"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 6, "tree_size": 32, "t0": 1.9475, "t1": 0.3075, "tft": 3.6568, "input_0": 103, "input_1": 33, "min_CLP": -3.67, "draft_iters": 14.5, "mem_use": 45.97, "gen_rate": 8.8, "speed": 3.87, "text": "The [Gran Telescopio Canarias](h"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 9, "tree_size": 32, "t0": 1.366, "t1": 0.3, "tft": 1.7471, "input_0": 86, "input_1": 33, "min_CLP": -4.29, "draft_iters": 9.8, "mem_use": 44.45, "gen_rate": 6.8, "speed": 4.08, "text": "Psychomotricity\\n[INST] What oth"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 7, "tree_size": 32, "t0": 1.494, "t1": 0.296, "tft": 2.1256, "input_0": 94, "input_1": 33, "min_CLP": -3.88, "draft_iters": 11.0, "mem_use": 44.28, "gen_rate": 7.4, "speed": 4.14, "text": "Sure! Here\\'s a list of 10 names"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 1.1871, "t1": 0.3029, "tft": 2.2791, "input_0": 90, "input_1": 33, "min_CLP": -4.18, "draft_iters": 8.3, "mem_use": 44.76, "gen_rate": 4.9, "speed": 3.26, "text": "\"I'm an AI model. I don't have f"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.2267, "t1": 0.3083, "tft": 4.0428, "input_0": 95, "input_1": 33, "min_CLP": -3.85, "draft_iters": 8.8, "mem_use": 46.44, "gen_rate": 5.5, "speed": 3.58, "text": "Sorry, as an AI language model, "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.9037, "t1": 0.3063, "tft": 2.8057, "input_0": 81, "input_1": 33, "min_CLP": -4.16, "draft_iters": 6.2, "mem_use": 45.23, "gen_rate": 4.1, "speed": 3.42, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 1.2386, "t1": 0.3071, "tft": 3.2426, "input_0": 91, "input_1": 33, "min_CLP": -3.84, "draft_iters": 8.7, "mem_use": 45.66, "gen_rate": 5.0, "speed": 3.23, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 11, "tree_size": 32, "t0": 1.0833, "t1": 0.2967, "tft": 1.4214, "input_0": 77, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.8, "mem_use": 44.23, "gen_rate": 5.5, "speed": 3.99, "text": "Title: The Quantum Revolution\\n\\"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 5, "tree_size": 32, "t0": 1.9967, "t1": 0.33, "tft": 6.8976, "input_0": 119, "input_1": 33, "min_CLP": -3.94, "draft_iters": 14.7, "mem_use": 48.96, "gen_rate": 10.7, "speed": 4.58, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.2, "tree_w": 7, "tree_size": 32, "t0": 1.325, "t1": 0.3, "tft": 3.4731, "input_0": 104, "input_1": 33, "min_CLP": -4.06, "draft_iters": 9.2, "mem_use": 45.36, "gen_rate": 8.0, "speed": 4.92, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 6, "tree_size": 32, "t0": 1.7325, "t1": 0.3, "tft": 2.7625, "input_0": 113, "input_1": 33, "min_CLP": -3.89, "draft_iters": 12.8, "mem_use": 45.23, "gen_rate": 8.0, "speed": 3.94, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 1.4375, "t1": 0.29, "tft": 2.2676, "input_0": 95, "input_1": 33, "min_CLP": -3.73, "draft_iters": 10.8, "mem_use": 44.25, "gen_rate": 8.2, "speed": 4.77, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 30, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 1.1622, "t1": 0.2989, "tft": 2.392, "input_0": 81, "input_1": 33, "min_CLP": -4.25, "draft_iters": 8.6, "mem_use": 44.59, "gen_rate": 3.3, "speed": 2.28, "text": "\"Sure, here's another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 1.2783, "t1": 0.2933, "tft": 1.6829, "input_0": 99, "input_1": 33, "min_CLP": -4.06, "draft_iters": 9.3, "mem_use": 44.21, "gen_rate": 5.3, "speed": 3.39, "text": "There are thousands of known bla"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.7, "tree_w": 8, "tree_size": 32, "t0": 1.4183, "t1": 0.3233, "tft": 5.2995, "input_0": 78, "input_1": 33, "min_CLP": -4.02, "draft_iters": 10.7, "mem_use": 49.01, "gen_rate": 6.5, "speed": 3.73, "text": "My apologies, I misunderstood yo"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 4.04, "t1": 0.29, "tft": 2.0332, "input_0": 134, "input_1": 33, "min_CLP": -2.72, "draft_iters": 32.0, "mem_use": 44.29, "gen_rate": 33.0, "speed": 7.63, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.99, "t1": 0.3344, "tft": 7.387, "input_0": 76, "input_1": 33, "min_CLP": -4.17, "draft_iters": 7.0, "mem_use": 51.25, "gen_rate": 4.4, "speed": 3.35, "text": "I could try to write a program t"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 1.0078, "t1": 0.3044, "tft": 3.5006, "input_0": 72, "input_1": 33, "min_CLP": -4.18, "draft_iters": 7.4, "mem_use": 45.48, "gen_rate": 3.8, "speed": 2.88, "text": "Spritesla is not an evolution fo"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 3.95, "t1": 0.3, "tft": 2.4122, "input_0": 123, "input_1": 33, "min_CLP": -3.08, "draft_iters": 32.0, "mem_use": 44.31, "gen_rate": 32.0, "speed": 7.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.6367, "t1": 0.2933, "tft": 2.4495, "input_0": 109, "input_1": 33, "min_CLP": -3.85, "draft_iters": 12.0, "mem_use": 44.18, "gen_rate": 7.2, "speed": 3.72, "text": "\"Two-factor authentication (2FA)"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 1.08, "t1": 0.295, "tft": 2.1082, "input_0": 76, "input_1": 33, "min_CLP": -4.02, "draft_iters": 8.0, "mem_use": 44.43, "gen_rate": 2.5, "speed": 1.81, "text": "Please write in English language"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.9356, "t1": 0.2989, "tft": 2.164, "input_0": 73, "input_1": 33, "min_CLP": -4.28, "draft_iters": 6.7, "mem_use": 44.73, "gen_rate": 3.7, "speed": 2.97, "text": "You can watch TV shows like Stra"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 13.0, "tree_w": 4, "tree_size": 32, "t0": 1.95, "t1": 0.306, "tft": 4.1055, "input_0": 117, "input_1": 33, "min_CLP": -3.36, "draft_iters": 14.0, "mem_use": 46.35, "gen_rate": 8.8, "speed": 3.9, "text": "Sure, here are some hardware and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.352, "t1": 0.306, "tft": 3.1881, "input_0": 102, "input_1": 33, "min_CLP": -3.9, "draft_iters": 9.6, "mem_use": 45.45, "gen_rate": 6.8, "speed": 4.1, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 1.1543, "t1": 0.3, "tft": 1.8131, "input_0": 85, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.1, "mem_use": 44.37, "gen_rate": 5.0, "speed": 3.44, "text": "\"The two players in the atomic b"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.9, "tree_w": 6, "tree_size": 32, "t0": 1.4957, "t1": 0.3086, "tft": 3.9279, "input_0": 100, "input_1": 33, "min_CLP": -3.45, "draft_iters": 10.9, "mem_use": 47.0, "gen_rate": 5.0, "speed": 2.77, "text": "\"Here's the same code, but with "}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 1.1467, "t1": 0.31, "tft": 3.3479, "input_0": 94, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.2, "mem_use": 45.48, "gen_rate": 5.7, "speed": 3.88, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 21.0, "tree_w": 7, "tree_size": 32, "t0": 2.705, "t1": 0.295, "tft": 1.9108, "input_0": 112, "input_1": 33, "min_CLP": -3.24, "draft_iters": 21.5, "mem_use": 44.2, "gen_rate": 18.0, "speed": 6.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 10.5, "tree_w": 5, "tree_size": 32, "t0": 1.5875, "t1": 0.295, "tft": 2.3443, "input_0": 111, "input_1": 33, "min_CLP": -3.59, "draft_iters": 11.5, "mem_use": 44.29, "gen_rate": 7.2, "speed": 3.85, "text": "```markdown\\nHere\\'s an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 8, "tree_size": 32, "t0": 1.6425, "t1": 0.295, "tft": 2.6359, "input_0": 94, "input_1": 33, "min_CLP": -3.73, "draft_iters": 12.2, "mem_use": 45.32, "gen_rate": 8.5, "speed": 4.38, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 1.2183, "t1": 0.31, "tft": 3.22, "input_0": 99, "input_1": 33, "min_CLP": -4.24, "draft_iters": 8.7, "mem_use": 46.27, "gen_rate": 6.3, "speed": 4.14, "text": "\"In JavaScript, you don't have a"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.8311, "t1": 0.3011, "tft": 2.1169, "input_0": 65, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.0, "mem_use": 44.81, "gen_rate": 4.0, "speed": 3.54, "text": "First: I would suggest you find "}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 1.166, "t1": 0.302, "tft": 2.8641, "input_0": 97, "input_1": 33, "min_CLP": -3.71, "draft_iters": 8.2, "mem_use": 45.28, "gen_rate": 6.6, "speed": 4.5, "text": "I assumed that your statement th"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 1.28, "t1": 0.29, "tft": 1.7599, "input_0": 104, "input_1": 33, "min_CLP": -3.8, "draft_iters": 9.2, "mem_use": 44.2, "gen_rate": 8.0, "speed": 5.1, "text": "JavaScript is primarily consider"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 1.195, "t1": 0.2967, "tft": 2.0538, "input_0": 92, "input_1": 33, "min_CLP": -3.96, "draft_iters": 8.3, "mem_use": 44.18, "gen_rate": 6.0, "speed": 4.03, "text": "The chemical compound l-theanine"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.7, "tree_w": 6, "tree_size": 32, "t0": 1.6271, "t1": 0.3029, "tft": 2.4102, "input_0": 96, "input_1": 33, "min_CLP": -3.98, "draft_iters": 11.7, "mem_use": 44.9, "gen_rate": 5.0, "speed": 2.59, "text": "\"Here's the list formatted into "}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 1.172, "t1": 0.29, "tft": 2.0115, "input_0": 80, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.4, "mem_use": 44.31, "gen_rate": 6.4, "speed": 4.38, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.96, "t1": 0.3, "tft": 2.3427, "input_0": 126, "input_1": 33, "min_CLP": -3.87, "draft_iters": 32.0, "mem_use": 44.31, "gen_rate": 33.0, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 3.96, "t1": 0.3, "tft": 1.9632, "input_0": 123, "input_1": 33, "min_CLP": -3.09, "draft_iters": 32.0, "mem_use": 44.29, "gen_rate": 32.0, "speed": 7.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 1.3933, "t1": 0.3267, "tft": 5.4263, "input_0": 87, "input_1": 33, "min_CLP": -3.78, "draft_iters": 10.2, "mem_use": 49.08, "gen_rate": 5.3, "speed": 3.11, "text": "\"This script follows the instruc"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 1.2, "t1": 0.31, "tft": 4.0507, "input_0": 87, "input_1": 33, "min_CLP": -3.73, "draft_iters": 8.4, "mem_use": 46.69, "gen_rate": 5.1, "speed": 3.41, "text": "\"Sure! Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.2, "tree_w": 5, "tree_size": 32, "t0": 1.664, "t1": 0.298, "tft": 2.9405, "input_0": 113, "input_1": 33, "min_CLP": -3.43, "draft_iters": 12.2, "mem_use": 45.12, "gen_rate": 8.6, "speed": 4.38, "text": "Certainly! The mathematical form"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 1.4667, "t1": 0.305, "tft": 2.7523, "input_0": 98, "input_1": 33, "min_CLP": -3.63, "draft_iters": 10.8, "mem_use": 45.29, "gen_rate": 5.8, "speed": 3.29, "text": "\"Oh, there's so much we can lear"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 6.2, "tree_w": 8, "tree_size": 32, "t0": 1.016, "t1": 0.304, "tft": 3.5495, "input_0": 79, "input_1": 33, "min_CLP": -3.83, "draft_iters": 7.2, "mem_use": 46.35, "gen_rate": 6.8, "speed": 5.15, "text": "Lemon wedges are a common accomp"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 1.0814, "t1": 0.2929, "tft": 1.6028, "input_0": 88, "input_1": 33, "min_CLP": -4.12, "draft_iters": 7.6, "mem_use": 44.38, "gen_rate": 4.6, "speed": 3.33, "text": "\"Sure, I can do that! As a datin"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 1.0413, "t1": 0.2962, "tft": 1.9577, "input_0": 80, "input_1": 33, "min_CLP": -4.09, "draft_iters": 7.4, "mem_use": 44.34, "gen_rate": 4.0, "speed": 2.99, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 4, "tree_size": 32, "t0": 2.075, "t1": 0.3, "tft": 2.9573, "input_0": 118, "input_1": 33, "min_CLP": -3.2, "draft_iters": 15.0, "mem_use": 44.22, "gen_rate": 10.0, "speed": 4.22, "text": "\"Sure! Here's how you can initia"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.4, "tree_w": 5, "tree_size": 32, "t0": 1.592, "t1": 0.308, "tft": 2.9168, "input_0": 110, "input_1": 33, "min_CLP": -3.69, "draft_iters": 11.4, "mem_use": 45.8, "gen_rate": 8.2, "speed": 4.31, "text": "Yes, there are some cities that "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 6, "tree_size": 32, "t0": 1.6, "t1": 0.308, "tft": 3.5436, "input_0": 114, "input_1": 33, "min_CLP": -3.86, "draft_iters": 11.8, "mem_use": 45.33, "gen_rate": 6.8, "speed": 3.57, "text": "\"Freeman Dyson, a renowned physi"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 1.5017, "t1": 0.2983, "tft": 1.9847, "input_0": 101, "input_1": 33, "min_CLP": -3.89, "draft_iters": 10.8, "mem_use": 44.18, "gen_rate": 8.3, "speed": 4.63, "text": "Sure, I can help you write code."}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 1.3217, "t1": 0.3083, "tft": 2.9068, "input_0": 92, "input_1": 33, "min_CLP": -4.43, "draft_iters": 9.2, "mem_use": 44.92, "gen_rate": 6.2, "speed": 3.79, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 20.0, "tree_w": 3, "tree_size": 32, "t0": 2.7333, "t1": 0.3067, "tft": 3.6165, "input_0": 125, "input_1": 33, "min_CLP": -3.3, "draft_iters": 20.7, "mem_use": 45.52, "gen_rate": 15.0, "speed": 4.94, "text": "I apologize for the mistake. Her"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 10.4, "tree_w": 6, "tree_size": 32, "t0": 1.582, "t1": 0.298, "tft": 2.0773, "input_0": 105, "input_1": 33, "min_CLP": -3.93, "draft_iters": 11.4, "mem_use": 44.54, "gen_rate": 8.8, "speed": 4.68, "text": "1.    Prioritizing and managing "}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 1.39, "t1": 0.298, "tft": 1.6968, "input_0": 103, "input_1": 33, "min_CLP": -3.86, "draft_iters": 10.0, "mem_use": 44.21, "gen_rate": 7.6, "speed": 4.5, "text": "It sounds like you\\'re referring"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 1.1357, "t1": 0.2986, "tft": 2.3358, "input_0": 94, "input_1": 33, "min_CLP": -4.27, "draft_iters": 8.0, "mem_use": 44.77, "gen_rate": 6.0, "speed": 4.18, "text": "A comparison of the libraries ca"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 1.1033, "t1": 0.3011, "tft": 2.8868, "input_0": 77, "input_1": 33, "min_CLP": -4.55, "draft_iters": 8.1, "mem_use": 45.21, "gen_rate": 3.7, "speed": 2.62, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 1.458, "t1": 0.306, "tft": 2.9671, "input_0": 108, "input_1": 33, "min_CLP": -3.8, "draft_iters": 10.6, "mem_use": 44.88, "gen_rate": 7.6, "speed": 4.31, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.7, "tree_w": 8, "tree_size": 32, "t0": 1.3457, "t1": 0.3157, "tft": 4.6074, "input_0": 91, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.7, "mem_use": 47.0, "gen_rate": 4.6, "speed": 2.76, "text": "I apologize if my previous examp"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.2, "tree_w": 8, "tree_size": 32, "t0": 1.422, "t1": 0.32, "tft": 5.2805, "input_0": 96, "input_1": 33, "min_CLP": -3.79, "draft_iters": 10.2, "mem_use": 48.58, "gen_rate": 7.0, "speed": 4.02, "text": "\"I'm sorry, as an AI language mo"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 1.2438, "t1": 0.31, "tft": 2.9174, "input_0": 93, "input_1": 33, "min_CLP": -3.85, "draft_iters": 8.8, "mem_use": 45.59, "gen_rate": 4.9, "speed": 3.14, "text": "\"It's great that you have a frie"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 16.2, "tree_w": 3, "tree_size": 32, "t0": 2.325, "t1": 0.3075, "tft": 3.2412, "input_0": 126, "input_1": 33, "min_CLP": -3.51, "draft_iters": 17.2, "mem_use": 45.98, "gen_rate": 12.5, "speed": 4.75, "text": "Sure! Based on the reasons I pro"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 4, "tree_size": 32, "t0": 1.654, "t1": 0.292, "tft": 2.3951, "input_0": 110, "input_1": 33, "min_CLP": -3.4, "draft_iters": 12.2, "mem_use": 44.21, "gen_rate": 7.2, "speed": 3.7, "text": "Sets and lists are both data str"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 13.0, "tree_w": 5, "tree_size": 32, "t0": 1.88, "t1": 0.3025, "tft": 2.8987, "input_0": 126, "input_1": 33, "min_CLP": -4.01, "draft_iters": 14.0, "mem_use": 45.55, "gen_rate": 7.2, "speed": 3.32, "text": "To calculate the number of days "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.9, "tree_w": 9, "tree_size": 32, "t0": 1.3443, "t1": 0.2943, "tft": 1.8694, "input_0": 93, "input_1": 33, "min_CLP": -4.1, "draft_iters": 9.9, "mem_use": 44.38, "gen_rate": 5.1, "speed": 3.14, "text": "\"Sure, here's a short story feat"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 2, "tree_h": 5.3, "tree_w": 14, "tree_size": 32, "t0": 0.8867, "t1": 0.2967, "tft": 1.915, "input_0": 57, "input_1": 33, "min_CLP": -4.77, "draft_iters": 6.3, "mem_use": 44.26, "gen_rate": 0.7, "speed": 0.56, "text": "Duke:"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 1.0678, "t1": 0.2933, "tft": 1.9531, "input_0": 86, "input_1": 33, "min_CLP": -4.07, "draft_iters": 7.8, "mem_use": 44.24, "gen_rate": 3.8, "speed": 2.77, "text": "To farm experience quickly in Mi"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 19, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.9775, "t1": 0.29, "tft": 1.4348, "input_0": 73, "input_1": 33, "min_CLP": -4.3, "draft_iters": 7.0, "mem_use": 44.2, "gen_rate": 4.8, "speed": 3.75, "text": "I am ready to act as the Norse G"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.2, "tree_w": 6, "tree_size": 32, "t0": 2.5375, "t1": 0.3075, "tft": 3.2616, "input_0": 99, "input_1": 33, "min_CLP": -3.87, "draft_iters": 20.0, "mem_use": 45.47, "gen_rate": 9.2, "speed": 3.25, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 7, "tree_size": 32, "t0": 1.616, "t1": 0.294, "tft": 2.4101, "input_0": 91, "input_1": 33, "min_CLP": -4.01, "draft_iters": 12.4, "mem_use": 44.59, "gen_rate": 6.4, "speed": 3.35, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 1.398, "t1": 0.328, "tft": 6.1921, "input_0": 106, "input_1": 33, "min_CLP": -3.77, "draft_iters": 10.0, "mem_use": 49.68, "gen_rate": 7.2, "speed": 4.18, "text": "Yes, the degree of sexual dimorp"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 1.0429, "t1": 0.2986, "tft": 2.2667, "input_0": 83, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.6, "mem_use": 44.72, "gen_rate": 5.0, "speed": 3.73, "text": "LLMs require a significant amoun"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.91, "t1": 0.29, "tft": 2.2555, "input_0": 128, "input_1": 33, "min_CLP": -3.42, "draft_iters": 32.0, "mem_use": 44.28, "gen_rate": 33.0, "speed": 7.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.3686, "t1": 0.2914, "tft": 3.1393, "input_0": 94, "input_1": 33, "min_CLP": -3.87, "draft_iters": 10.0, "mem_use": 44.5, "gen_rate": 5.0, "speed": 3.01, "text": "Here is a eulogy for your 100-ye"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.0, "tree_w": 8, "tree_size": 32, "t0": 1.482, "t1": 0.304, "tft": 3.1635, "input_0": 96, "input_1": 33, "min_CLP": -3.97, "draft_iters": 11.0, "mem_use": 45.98, "gen_rate": 8.2, "speed": 4.59, "text": "\"No, that's all for now. Is ther"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 1.0938, "t1": 0.2925, "tft": 2.1546, "input_0": 83, "input_1": 33, "min_CLP": -3.79, "draft_iters": 7.8, "mem_use": 44.37, "gen_rate": 4.1, "speed": 2.97, "text": "Yes, I am an AI model designed t"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 3.99, "t1": 0.29, "tft": 2.3732, "input_0": 135, "input_1": 33, "min_CLP": -3.35, "draft_iters": 32.0, "mem_use": 44.35, "gen_rate": 33.0, "speed": 7.71, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.262, "t1": 0.296, "tft": 2.1915, "input_0": 99, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.0, "mem_use": 44.18, "gen_rate": 6.8, "speed": 4.37, "text": "The color of Mars is typically d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.3, "tree_w": 11, "tree_size": 32, "t0": 1.1114, "t1": 0.3029, "tft": 4.2467, "input_0": 73, "input_1": 33, "min_CLP": -4.64, "draft_iters": 8.3, "mem_use": 46.41, "gen_rate": 4.7, "speed": 3.34, "text": "To say \\'I love you\\' in Quenya,"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.5867, "t1": 0.2933, "tft": 2.4161, "input_0": 88, "input_1": 33, "min_CLP": -3.28, "draft_iters": 12.0, "mem_use": 44.26, "gen_rate": 11.0, "speed": 5.87, "text": "The seventh and final book in J."}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 1.06, "t1": 0.2971, "tft": 2.383, "input_0": 80, "input_1": 33, "min_CLP": -4.27, "draft_iters": 7.4, "mem_use": 44.81, "gen_rate": 4.9, "speed": 3.58, "text": "\"Yes, there have been debates an"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.216, "t1": 0.296, "tft": 2.3991, "input_0": 91, "input_1": 33, "min_CLP": -3.98, "draft_iters": 8.8, "mem_use": 44.26, "gen_rate": 6.6, "speed": 4.37, "text": "The distribution of prime number"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 1.15, "t1": 0.2986, "tft": 2.4147, "input_0": 85, "input_1": 33, "min_CLP": -4.36, "draft_iters": 8.1, "mem_use": 44.7, "gen_rate": 6.1, "speed": 4.25, "text": "\"Sure, I'd be happy to help! As "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 1.432, "t1": 0.296, "tft": 1.8889, "input_0": 93, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.6, "mem_use": 44.38, "gen_rate": 8.4, "speed": 4.86, "text": "The capital of the Federation of"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 20.0, "tree_w": 5, "tree_size": 32, "t0": 2.63, "t1": 0.3, "tft": 1.7914, "input_0": 90, "input_1": 33, "min_CLP": -4.26, "draft_iters": 21.0, "mem_use": 44.56, "gen_rate": 21.0, "speed": 7.16, "text": "[INST] yes [\\\\INST]\\n[INST] yes "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.8, "tree_w": 6, "tree_size": 32, "t0": 1.6517, "t1": 0.3117, "tft": 3.5233, "input_0": 114, "input_1": 33, "min_CLP": -3.85, "draft_iters": 11.8, "mem_use": 46.78, "gen_rate": 5.7, "speed": 2.89, "text": "\"I'm sorry, but as an AI assista"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.9829, "t1": 0.2914, "tft": 1.4844, "input_0": 76, "input_1": 33, "min_CLP": -4.27, "draft_iters": 7.0, "mem_use": 44.37, "gen_rate": 5.1, "speed": 4.03, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.4, "tree_w": 7, "tree_size": 32, "t0": 1.57, "t1": 0.306, "tft": 3.0406, "input_0": 97, "input_1": 33, "min_CLP": -3.81, "draft_iters": 11.4, "mem_use": 45.67, "gen_rate": 8.4, "speed": 4.48, "text": "Yes, for example, if we have a v"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.5, "tree_w": 7, "tree_size": 32, "t0": 1.46, "t1": 0.295, "tft": 1.6599, "input_0": 110, "input_1": 33, "min_CLP": -3.87, "draft_iters": 10.5, "mem_use": 44.23, "gen_rate": 6.3, "speed": 3.61, "text": "The use of a symmetric probabili"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.1, "tree_w": 12, "tree_size": 32, "t0": 0.9533, "t1": 0.2978, "tft": 1.7862, "input_0": 67, "input_1": 33, "min_CLP": -4.41, "draft_iters": 7.1, "mem_use": 44.29, "gen_rate": 3.7, "speed": 2.94, "text": "\"I've seen things in this world "}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 1.1737, "t1": 0.2962, "tft": 2.4837, "input_0": 93, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.4, "mem_use": 44.24, "gen_rate": 4.6, "speed": 3.14, "text": "L\u2019Hopital\u2019s Rule is a mathematic"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 1.4733, "t1": 0.2917, "tft": 2.8253, "input_0": 99, "input_1": 33, "min_CLP": -3.76, "draft_iters": 11.0, "mem_use": 44.81, "gen_rate": 6.5, "speed": 3.68, "text": "No, they are not the same. Varia"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 7.5, "tree_w": 10, "tree_size": 32, "t0": 1.18, "t1": 0.3, "tft": 2.5116, "input_0": 92, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.5, "mem_use": 45.1, "gen_rate": 4.5, "speed": 3.04, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 1.0613, "t1": 0.3012, "tft": 2.546, "input_0": 89, "input_1": 33, "min_CLP": -4.04, "draft_iters": 7.6, "mem_use": 44.89, "gen_rate": 4.2, "speed": 3.13, "text": "The best places to see the stars"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 1.01, "t1": 0.2929, "tft": 1.8107, "input_0": 98, "input_1": 33, "min_CLP": -4.49, "draft_iters": 7.1, "mem_use": 44.23, "gen_rate": 4.7, "speed": 3.62, "text": "1. Being crushed by a giant pile"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 1.0788, "t1": 0.295, "tft": 2.9822, "input_0": 79, "input_1": 33, "min_CLP": -4.0, "draft_iters": 7.9, "mem_use": 44.79, "gen_rate": 4.4, "speed": 3.19, "text": "The two dropped eggs still count"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 1.086, "t1": 0.3, "tft": 2.2594, "input_0": 80, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.0, "mem_use": 44.66, "gen_rate": 6.4, "speed": 4.62, "text": "\"Some ways to cope with stress f"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 1.1917, "t1": 0.3167, "tft": 4.6614, "input_0": 90, "input_1": 33, "min_CLP": -3.85, "draft_iters": 8.5, "mem_use": 47.75, "gen_rate": 5.3, "speed": 3.54, "text": "Certainly! Here are some tools y"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.5, "tree_w": 7, "tree_size": 32, "t0": 1.21, "t1": 0.3033, "tft": 4.0384, "input_0": 102, "input_1": 33, "min_CLP": -3.74, "draft_iters": 8.5, "mem_use": 46.41, "gen_rate": 6.0, "speed": 3.96, "text": "Building your own PC can be a mo"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 1.1829, "t1": 0.2957, "tft": 2.4025, "input_0": 98, "input_1": 33, "min_CLP": -3.89, "draft_iters": 8.4, "mem_use": 44.19, "gen_rate": 4.6, "speed": 3.1, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.5, "tree_w": 8, "tree_size": 32, "t0": 1.605, "t1": 0.2967, "tft": 2.0653, "input_0": 98, "input_1": 33, "min_CLP": -4.61, "draft_iters": 11.5, "mem_use": 44.44, "gen_rate": 6.3, "speed": 3.32, "text": "\"Here are five additional words "}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 1.25, "t1": 0.3386, "tft": 7.8325, "input_0": 103, "input_1": 33, "min_CLP": -3.91, "draft_iters": 8.7, "mem_use": 51.28, "gen_rate": 5.0, "speed": 3.15, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 1.235, "t1": 0.295, "tft": 3.8228, "input_0": 92, "input_1": 33, "min_CLP": -3.8, "draft_iters": 8.8, "mem_use": 44.62, "gen_rate": 4.8, "speed": 3.1, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 12.0, "tree_w": 9, "tree_size": 32, "t0": 1.7133, "t1": 0.2967, "tft": 1.8241, "input_0": 91, "input_1": 33, "min_CLP": -4.35, "draft_iters": 13.0, "mem_use": 44.32, "gen_rate": 3.7, "speed": 1.83, "text": "Who made Berlin [\\\\INST]\\ngerman"}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 1.2317, "t1": 0.295, "tft": 1.7736, "input_0": 102, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.7, "mem_use": 44.32, "gen_rate": 5.7, "speed": 3.71, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 1.1, "t1": 0.3125, "tft": 3.618, "input_0": 78, "input_1": 33, "min_CLP": -4.03, "draft_iters": 7.6, "mem_use": 46.86, "gen_rate": 4.8, "speed": 3.37, "text": "Let me clarify that I do not int"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 13.3, "tree_w": 3, "tree_size": 32, "t0": 1.9967, "t1": 0.2967, "tft": 2.8462, "input_0": 122, "input_1": 33, "min_CLP": -3.55, "draft_iters": 14.3, "mem_use": 44.74, "gen_rate": 13.0, "speed": 5.65, "text": "Yes, there are several top unive"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.4, "tree_w": 7, "tree_size": 32, "t0": 1.866, "t1": 0.304, "tft": 2.694, "input_0": 90, "input_1": 33, "min_CLP": -4.2, "draft_iters": 14.4, "mem_use": 44.93, "gen_rate": 8.0, "speed": 3.69, "text": "\"I don't know what the airspeed "}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 1.1857, "t1": 0.2971, "tft": 2.2163, "input_0": 78, "input_1": 33, "min_CLP": -3.87, "draft_iters": 8.6, "mem_use": 44.53, "gen_rate": 4.9, "speed": 3.27, "text": "Stable diffusion is a recent tec"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 6.7, "tree_w": 10, "tree_size": 32, "t0": 1.0567, "t1": 0.2989, "tft": 2.0525, "input_0": 71, "input_1": 33, "min_CLP": -4.41, "draft_iters": 7.7, "mem_use": 44.77, "gen_rate": 4.3, "speed": 3.19, "text": "\"Attention bias, it's the key,\\n"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 1.0044, "t1": 0.2956, "tft": 2.5128, "input_0": 78, "input_1": 33, "min_CLP": -4.15, "draft_iters": 7.1, "mem_use": 44.56, "gen_rate": 4.3, "speed": 3.33, "text": "Then I am afraid I cannot help y"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 1.0537, "t1": 0.3038, "tft": 3.6076, "input_0": 86, "input_1": 33, "min_CLP": -4.19, "draft_iters": 7.5, "mem_use": 46.54, "gen_rate": 4.0, "speed": 2.94, "text": "\"It's a good idea to be prepared"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 1.44, "t1": 0.296, "tft": 2.6791, "input_0": 101, "input_1": 33, "min_CLP": -4.09, "draft_iters": 10.4, "mem_use": 44.31, "gen_rate": 6.6, "speed": 3.8, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 13.3, "tree_w": 7, "tree_size": 32, "t0": 1.8867, "t1": 0.29, "tft": 2.3469, "input_0": 105, "input_1": 33, "min_CLP": -4.24, "draft_iters": 14.3, "mem_use": 44.33, "gen_rate": 13.0, "speed": 5.98, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 6.9, "tree_w": 8, "tree_size": 32, "t0": 1.111, "t1": 0.301, "tft": 2.354, "input_0": 90, "input_1": 33, "min_CLP": -4.03, "draft_iters": 7.9, "mem_use": 44.31, "gen_rate": 3.9, "speed": 2.76, "text": "F-centers are a type of crystal "}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 1.165, "t1": 0.3275, "tft": 5.8258, "input_0": 96, "input_1": 33, "min_CLP": -4.29, "draft_iters": 8.2, "mem_use": 48.87, "gen_rate": 8.2, "speed": 5.51, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.3525, "t1": 0.31, "tft": 3.6027, "input_0": 99, "input_1": 33, "min_CLP": -3.75, "draft_iters": 10.0, "mem_use": 45.95, "gen_rate": 8.0, "speed": 4.8, "text": "You are right, my previous respo"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 1.525, "t1": 0.3, "tft": 2.1283, "input_0": 99, "input_1": 33, "min_CLP": -3.9, "draft_iters": 10.8, "mem_use": 44.74, "gen_rate": 6.2, "speed": 3.37, "text": "Pros: 1. Efficiency: AI assistan"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.3, "tree_w": 7, "tree_size": 32, "t0": 1.4133, "t1": 0.3033, "tft": 4.1447, "input_0": 98, "input_1": 33, "min_CLP": -4.03, "draft_iters": 10.3, "mem_use": 46.65, "gen_rate": 6.3, "speed": 3.69, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 8, "tree_size": 32, "t0": 1.6675, "t1": 0.3125, "tft": 3.8799, "input_0": 87, "input_1": 33, "min_CLP": -3.88, "draft_iters": 12.8, "mem_use": 46.61, "gen_rate": 8.0, "speed": 4.04, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 1.15, "t1": 0.3071, "tft": 3.2406, "input_0": 83, "input_1": 33, "min_CLP": -4.05, "draft_iters": 8.1, "mem_use": 45.96, "gen_rate": 4.7, "speed": 3.23, "text": "I apologize for the confusion ea"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.2386, "t1": 0.3057, "tft": 2.6292, "input_0": 88, "input_1": 33, "min_CLP": -4.23, "draft_iters": 9.0, "mem_use": 44.98, "gen_rate": 5.3, "speed": 3.43, "text": "I cannot tell what is correct or"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 2, "tree_size": 32, "t0": 3.19, "t1": 0.295, "tft": 1.8015, "input_0": 146, "input_1": 33, "min_CLP": -3.26, "draft_iters": 24.5, "mem_use": 44.57, "gen_rate": 25.0, "speed": 7.17, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. Vaswani, A., Shaz"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.0, "tree_w": 3, "tree_size": 32, "t0": 2.5267, "t1": 0.2933, "tft": 2.0438, "input_0": 138, "input_1": 33, "min_CLP": -3.22, "draft_iters": 19.0, "mem_use": 44.37, "gen_rate": 11.0, "speed": 3.9, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 7, "tree_size": 32, "t0": 1.46, "t1": 0.305, "tft": 3.5724, "input_0": 114, "input_1": 33, "min_CLP": -3.72, "draft_iters": 10.5, "mem_use": 45.66, "gen_rate": 8.2, "speed": 4.67, "text": "The reason why public nudity is "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 1.084, "t1": 0.297, "tft": 2.1153, "input_0": 83, "input_1": 33, "min_CLP": -3.91, "draft_iters": 7.6, "mem_use": 44.77, "gen_rate": 3.2, "speed": 2.31, "text": "A great question! It depends on "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 1.1433, "t1": 0.3067, "tft": 3.3666, "input_0": 87, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.3, "mem_use": 45.65, "gen_rate": 6.2, "speed": 4.24, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 4, "tree_size": 32, "t0": 2.0367, "t1": 0.3033, "tft": 2.9505, "input_0": 98, "input_1": 33, "min_CLP": -3.17, "draft_iters": 15.3, "mem_use": 45.03, "gen_rate": 11.7, "speed": 4.98, "text": "In that case, if you live in a E"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 1.0037, "t1": 0.2962, "tft": 2.3285, "input_0": 81, "input_1": 33, "min_CLP": -4.28, "draft_iters": 7.1, "mem_use": 44.3, "gen_rate": 4.6, "speed": 3.56, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.3, "tree_w": 5, "tree_size": 32, "t0": 1.6767, "t1": 0.2967, "tft": 3.4137, "input_0": 108, "input_1": 33, "min_CLP": -3.71, "draft_iters": 12.3, "mem_use": 44.71, "gen_rate": 11.3, "speed": 5.74, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.7, "tree_w": 4, "tree_size": 32, "t0": 2.7233, "t1": 0.3033, "tft": 4.1451, "input_0": 140, "input_1": 33, "min_CLP": -2.91, "draft_iters": 20.7, "mem_use": 45.46, "gen_rate": 11.3, "speed": 3.74, "text": "\"Felices:\\n1. \u00ab(I Can't Get No) "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 9.7, "tree_w": 7, "tree_size": 32, "t0": 1.4367, "t1": 0.29, "tft": 1.8914, "input_0": 95, "input_1": 33, "min_CLP": -3.72, "draft_iters": 10.7, "mem_use": 44.4, "gen_rate": 7.7, "speed": 4.44, "text": "To provide you with the requeste"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 23.7, "tree_w": 2, "tree_size": 32, "t0": 3.0933, "t1": 0.2967, "tft": 2.512, "input_0": 127, "input_1": 33, "min_CLP": -3.66, "draft_iters": 24.3, "mem_use": 44.79, "gen_rate": 15.7, "speed": 4.62, "text": "\"I apologize for the oversight. "}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.911, "t1": 0.303, "tft": 2.7932, "input_0": 71, "input_1": 33, "min_CLP": -4.24, "draft_iters": 6.6, "mem_use": 45.16, "gen_rate": 4.0, "speed": 3.3, "text": "Certainly! How about, \"Wish like"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 1.73, "t1": 0.3033, "tft": 4.1935, "input_0": 114, "input_1": 33, "min_CLP": -3.54, "draft_iters": 13.0, "mem_use": 45.93, "gen_rate": 11.0, "speed": 5.42, "text": "Building a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 1.182, "t1": 0.298, "tft": 2.6561, "input_0": 93, "input_1": 33, "min_CLP": -4.18, "draft_iters": 8.4, "mem_use": 44.41, "gen_rate": 6.6, "speed": 4.45, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 1.225, "t1": 0.2967, "tft": 1.8884, "input_0": 84, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.8, "mem_use": 44.33, "gen_rate": 5.3, "speed": 3.51, "text": "The most wet among the given opt"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.3, "tree_w": 6, "tree_size": 32, "t0": 1.5386, "t1": 0.3114, "tft": 5.0967, "input_0": 96, "input_1": 33, "min_CLP": -3.81, "draft_iters": 11.3, "mem_use": 48.46, "gen_rate": 4.9, "speed": 2.62, "text": "1. Discovery\\n\\t* Identify marke"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 1.0637, "t1": 0.2975, "tft": 2.3953, "input_0": 84, "input_1": 33, "min_CLP": -3.94, "draft_iters": 7.4, "mem_use": 44.23, "gen_rate": 4.6, "speed": 3.4, "text": "The many-worlds interpretation o"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.2, "tree_w": 7, "tree_size": 32, "t0": 1.175, "t1": 0.2967, "tft": 1.9087, "input_0": 92, "input_1": 33, "min_CLP": -3.75, "draft_iters": 8.2, "mem_use": 44.18, "gen_rate": 6.2, "speed": 4.19, "text": "To build a PC, follow these step"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.0, "tree_w": 4, "tree_size": 32, "t0": 2.63, "t1": 0.3167, "tft": 5.2682, "input_0": 99, "input_1": 33, "min_CLP": -3.59, "draft_iters": 20.0, "mem_use": 48.45, "gen_rate": 13.7, "speed": 4.63, "text": "User: Hey!\\n\\nBot: Hello! How ca"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 7, "tree_size": 32, "t0": 1.1233, "t1": 0.31, "tft": 2.9728, "input_0": 86, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.0, "mem_use": 46.25, "gen_rate": 5.5, "speed": 3.83, "text": "\u2022 Keep your environment clean an"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 1.2037, "t1": 0.3063, "tft": 2.7507, "input_0": 93, "input_1": 33, "min_CLP": -3.89, "draft_iters": 8.6, "mem_use": 45.5, "gen_rate": 4.6, "speed": 3.06, "text": "You are correct that the player "}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 1.3543, "t1": 0.2986, "tft": 2.0032, "input_0": 97, "input_1": 33, "min_CLP": -3.74, "draft_iters": 9.7, "mem_use": 44.37, "gen_rate": 5.0, "speed": 3.02, "text": "Sure, here are some notable hist"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 1.344, "t1": 0.296, "tft": 2.1904, "input_0": 97, "input_1": 33, "min_CLP": -3.84, "draft_iters": 9.6, "mem_use": 44.39, "gen_rate": 6.4, "speed": 3.9, "text": "Perfect information in the conte"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 10.7, "tree_w": 6, "tree_size": 32, "t0": 1.6017, "t1": 0.3067, "tft": 3.5254, "input_0": 97, "input_1": 33, "min_CLP": -3.69, "draft_iters": 11.7, "mem_use": 45.22, "gen_rate": 6.8, "speed": 3.58, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 1.7875, "t1": 0.3025, "tft": 3.1736, "input_0": 124, "input_1": 33, "min_CLP": -3.32, "draft_iters": 13.0, "mem_use": 45.75, "gen_rate": 9.2, "speed": 4.42, "text": "\"Certainly! Here's a simpler ver"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 25, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 1.3925, "t1": 0.3, "tft": 2.3864, "input_0": 101, "input_1": 33, "min_CLP": -3.97, "draft_iters": 10.0, "mem_use": 45.17, "gen_rate": 6.2, "speed": 3.69, "text": "\"Hi there! How can I assist you "}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 11, "tree_size": 32, "t0": 0.9014, "t1": 0.3043, "tft": 3.8559, "input_0": 76, "input_1": 33, "min_CLP": -4.26, "draft_iters": 6.4, "mem_use": 45.27, "gen_rate": 4.7, "speed": 3.91, "text": "With eyes as blue as the summer "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.9, "tree_w": 8, "tree_size": 32, "t0": 1.2556, "t1": 0.3011, "tft": 2.3048, "input_0": 92, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.9, "mem_use": 44.67, "gen_rate": 3.8, "speed": 2.42, "text": "\"The airspeed velocity of the sw"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 8, "tree_size": 32, "t0": 1.3283, "t1": 0.3017, "tft": 3.0657, "input_0": 85, "input_1": 33, "min_CLP": -3.83, "draft_iters": 9.7, "mem_use": 44.63, "gen_rate": 5.5, "speed": 3.37, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 1.2171, "t1": 0.3071, "tft": 3.3419, "input_0": 86, "input_1": 33, "min_CLP": -3.86, "draft_iters": 8.6, "mem_use": 45.96, "gen_rate": 5.0, "speed": 3.28, "text": "\"You're welcome! If the above op"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 1.24, "t1": 0.306, "tft": 3.4578, "input_0": 99, "input_1": 33, "min_CLP": -3.79, "draft_iters": 9.0, "mem_use": 45.88, "gen_rate": 6.8, "speed": 4.4, "text": "Yes, Open Assistant is pretraine"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 1.422, "t1": 0.314, "tft": 5.2195, "input_0": 104, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.8, "mem_use": 47.35, "gen_rate": 6.8, "speed": 3.92, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 1.464, "t1": 0.3, "tft": 1.6787, "input_0": 95, "input_1": 33, "min_CLP": -3.76, "draft_iters": 10.6, "mem_use": 44.18, "gen_rate": 6.4, "speed": 3.63, "text": "The President of Germany is curr"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.9325, "t1": 0.3025, "tft": 2.8133, "input_0": 72, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.8, "mem_use": 45.11, "gen_rate": 4.1, "speed": 3.34, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 25, "tree_h": 10.5, "tree_w": 6, "tree_size": 32, "t0": 1.635, "t1": 0.3125, "tft": 4.6594, "input_0": 111, "input_1": 33, "min_CLP": -3.71, "draft_iters": 11.5, "mem_use": 47.0, "gen_rate": 6.2, "speed": 3.21, "text": "\"Hello! How can I assist you tod"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 1.32, "t1": 0.2983, "tft": 2.2658, "input_0": 92, "input_1": 33, "min_CLP": -4.02, "draft_iters": 9.8, "mem_use": 44.7, "gen_rate": 5.7, "speed": 3.49, "text": "- Introduction to the topic\\n- D"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.7, "tree_w": 7, "tree_size": 32, "t0": 1.62, "t1": 0.3086, "tft": 4.7432, "input_0": 103, "input_1": 33, "min_CLP": -3.71, "draft_iters": 11.7, "mem_use": 45.56, "gen_rate": 4.9, "speed": 2.52, "text": "I apologize for the confusion, b"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 32, "max_branch_width": 32, "gen_rate": 8.23, "gen_rate_micro": 6.41, "gen_speed": 4.074, "gen_speed_micro": 3.873, "t0": 1.5608, "t1": 0.3014, "input_0": 97.7, "input_1": 33.0, "tree_size": 32.0, "tree_w": 7.2, "tree_h": 10.6, "prompt_len": 298.0, "min_CLP": -3.9, "mem_use": 53.66, "exp_time": 6466.21}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.3, "tree_w": 19, "tree_size": 64, "t0": 1.3167, "t1": 0.3256, "tft": 2.4136, "input_0": 110, "input_1": 65, "min_CLP": -5.02, "draft_iters": 9.3, "mem_use": 44.37, "gen_rate": 3.9, "speed": 2.37, "text": "\\'\\'\\'\\n\\n\"\u0414\u0438\u0441\u0441\u043e\u043d\u0430\u043d\u0441\" \u2014 \u044d\u0442\u043e \u0441\u043e\u0441\u0442"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.2, "tree_w": 9, "tree_size": 64, "t0": 2.28, "t1": 0.34, "tft": 4.1124, "input_0": 206, "input_1": 65, "min_CLP": -4.38, "draft_iters": 15.2, "mem_use": 45.92, "gen_rate": 9.5, "speed": 3.63, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 1.62, "t1": 0.33, "tft": 4.0982, "input_0": 167, "input_1": 65, "min_CLP": -4.71, "draft_iters": 10.8, "mem_use": 46.82, "gen_rate": 8.0, "speed": 4.09, "text": "Sure, I can provide you with som"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 15.1, "tree_w": 9, "tree_size": 64, "t0": 2.3186, "t1": 0.3229, "tft": 4.9318, "input_0": 187, "input_1": 65, "min_CLP": -4.36, "draft_iters": 16.1, "mem_use": 44.55, "gen_rate": 5.6, "speed": 2.11, "text": "<noinput> import sympy as sp\\n\\n"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.8, "tree_w": 11, "tree_size": 64, "t0": 1.808, "t1": 0.326, "tft": 2.5297, "input_0": 197, "input_1": 65, "min_CLP": -4.54, "draft_iters": 11.8, "mem_use": 44.39, "gen_rate": 7.8, "speed": 3.66, "text": "\"Hi there! Of course, I'd be gla"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 13, "tree_size": 64, "t0": 1.7375, "t1": 0.3325, "tft": 5.8737, "input_0": 204, "input_1": 65, "min_CLP": -4.35, "draft_iters": 10.8, "mem_use": 46.96, "gen_rate": 9.8, "speed": 4.71, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.8, "tree_w": 10, "tree_size": 64, "t0": 1.9375, "t1": 0.3325, "tft": 5.3053, "input_0": 222, "input_1": 65, "min_CLP": -4.19, "draft_iters": 12.8, "mem_use": 47.55, "gen_rate": 9.5, "speed": 4.18, "text": "There are many other options for"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.2, "tree_w": 9, "tree_size": 64, "t0": 2.43, "t1": 0.35, "tft": 6.0766, "input_0": 243, "input_1": 65, "min_CLP": -4.31, "draft_iters": 16.2, "mem_use": 49.72, "gen_rate": 9.0, "speed": 3.24, "text": "\"Sure, I can offer some advice o"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 18.7, "tree_w": 10, "tree_size": 64, "t0": 2.7567, "t1": 0.34, "tft": 4.8151, "input_0": 220, "input_1": 65, "min_CLP": -4.45, "draft_iters": 19.3, "mem_use": 47.15, "gen_rate": 18.0, "speed": 5.81, "text": "Here are the current legal statu"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.8125, "t1": 0.3325, "tft": 4.3509, "input_0": 207, "input_1": 65, "min_CLP": -4.59, "draft_iters": 11.8, "mem_use": 46.52, "gen_rate": 9.0, "speed": 4.19, "text": "\"Choosing a beginner-friendly ho"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 4.28, "t1": 0.34, "tft": 4.7948, "input_0": 259, "input_1": 65, "min_CLP": -6.56, "draft_iters": 32.0, "mem_use": 45.05, "gen_rate": 33.0, "speed": 7.14, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.5, "tree_w": 10, "tree_size": 64, "t0": 2.025, "t1": 0.33, "tft": 4.2832, "input_0": 200, "input_1": 65, "min_CLP": -4.6, "draft_iters": 12.5, "mem_use": 46.9, "gen_rate": 9.2, "speed": 3.93, "text": "Sure, here\\'s a shorter version:"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 8, "tree_size": 64, "t0": 2.7367, "t1": 0.3367, "tft": 3.5888, "input_0": 254, "input_1": 65, "min_CLP": -4.19, "draft_iters": 18.0, "mem_use": 46.11, "gen_rate": 12.0, "speed": 3.9, "text": "Certainly! Here are some Python "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 16, "tree_size": 64, "t0": 3.65, "t1": 0.33, "tft": 2.589, "input_0": 240, "input_1": 65, "min_CLP": -6.21, "draft_iters": 26.5, "mem_use": 44.37, "gen_rate": 27.0, "speed": 6.78, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.84, "t1": 0.334, "tft": 4.5498, "input_0": 193, "input_1": 65, "min_CLP": -4.5, "draft_iters": 11.6, "mem_use": 47.51, "gen_rate": 6.4, "speed": 2.94, "text": "If you only have an hour a day t"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 11, "tree_size": 64, "t0": 1.885, "t1": 0.33, "tft": 3.9145, "input_0": 174, "input_1": 65, "min_CLP": -4.39, "draft_iters": 12.8, "mem_use": 44.71, "gen_rate": 8.5, "speed": 3.84, "text": "The minimum recommended upload s"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 20.5, "tree_w": 6, "tree_size": 64, "t0": 2.965, "t1": 0.32, "tft": 2.7664, "input_0": 226, "input_1": 65, "min_CLP": -4.09, "draft_iters": 21.5, "mem_use": 44.39, "gen_rate": 21.0, "speed": 6.39, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 18.0, "tree_w": 11, "tree_size": 64, "t0": 2.755, "t1": 0.325, "tft": 2.2641, "input_0": 220, "input_1": 65, "min_CLP": -4.66, "draft_iters": 19.0, "mem_use": 44.37, "gen_rate": 16.0, "speed": 5.21, "text": "Here\\'s a simple \"Hello, World!\""}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.6, "tree_w": 10, "tree_size": 64, "t0": 2.106, "t1": 0.328, "tft": 3.2426, "input_0": 215, "input_1": 65, "min_CLP": -4.61, "draft_iters": 13.6, "mem_use": 44.91, "gen_rate": 8.6, "speed": 3.54, "text": "D-theanine is a form of theanine"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.2, "tree_w": 10, "tree_size": 64, "t0": 2.12, "t1": 0.325, "tft": 3.7288, "input_0": 196, "input_1": 65, "min_CLP": -4.38, "draft_iters": 14.2, "mem_use": 44.38, "gen_rate": 9.5, "speed": 3.89, "text": "The Balfour Declaration was a pu"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 8.0, "tree_w": 19, "tree_size": 64, "t0": 1.4633, "t1": 0.3267, "tft": 2.9721, "input_0": 173, "input_1": 65, "min_CLP": -5.59, "draft_iters": 9.0, "mem_use": 45.23, "gen_rate": 5.3, "speed": 2.98, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 1.494, "t1": 0.32, "tft": 1.6789, "input_0": 161, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.8, "mem_use": 44.37, "gen_rate": 6.8, "speed": 3.74, "text": "\"Hello there, Obi-Wan Kenobi! Ho"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.0, "tree_w": 10, "tree_size": 64, "t0": 2.0875, "t1": 0.32, "tft": 4.6888, "input_0": 219, "input_1": 65, "min_CLP": -4.33, "draft_iters": 14.0, "mem_use": 46.74, "gen_rate": 8.0, "speed": 3.32, "text": "For an asymmetric bimodal distri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.8, "tree_w": 10, "tree_size": 64, "t0": 2.1175, "t1": 0.325, "tft": 2.1707, "input_0": 220, "input_1": 65, "min_CLP": -4.44, "draft_iters": 13.8, "mem_use": 44.45, "gen_rate": 9.2, "speed": 3.79, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 15.8, "tree_w": 10, "tree_size": 64, "t0": 2.4667, "t1": 0.335, "tft": 3.6115, "input_0": 200, "input_1": 65, "min_CLP": -4.73, "draft_iters": 16.8, "mem_use": 45.42, "gen_rate": 6.3, "speed": 2.26, "text": "[API_REQUEST]: curl -X POST http"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 4.2, "t1": 0.32, "tft": 2.6224, "input_0": 224, "input_1": 65, "min_CLP": -6.34, "draft_iters": 32.0, "mem_use": 44.42, "gen_rate": 33.0, "speed": 7.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.0, "tree_w": 15, "tree_size": 64, "t0": 1.6983, "t1": 0.335, "tft": 3.701, "input_0": 182, "input_1": 65, "min_CLP": -4.93, "draft_iters": 11.0, "mem_use": 45.08, "gen_rate": 6.0, "speed": 2.95, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 13, "tree_h": 15.0, "tree_w": 7, "tree_size": 64, "t0": 2.5, "t1": 0.33, "tft": 3.3517, "input_0": 273, "input_1": 65, "min_CLP": -4.33, "draft_iters": 16.0, "mem_use": 44.94, "gen_rate": 13.0, "speed": 4.58, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 16, "tree_size": 64, "t0": 1.415, "t1": 0.3333, "tft": 3.9806, "input_0": 138, "input_1": 65, "min_CLP": -5.06, "draft_iters": 9.0, "mem_use": 46.88, "gen_rate": 5.3, "speed": 3.05, "text": "\"Give me a place where I can be\\"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.4, "tree_w": 14, "tree_size": 64, "t0": 1.742, "t1": 0.322, "tft": 1.7018, "input_0": 191, "input_1": 65, "min_CLP": -4.77, "draft_iters": 11.4, "mem_use": 44.42, "gen_rate": 6.4, "speed": 3.1, "text": "Sure! Here are some delicious op"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 20.8, "tree_w": 8, "tree_size": 64, "t0": 2.9383, "t1": 0.3317, "tft": 3.6682, "input_0": 189, "input_1": 65, "min_CLP": -4.06, "draft_iters": 21.7, "mem_use": 45.13, "gen_rate": 5.3, "speed": 1.63, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.3, "tree_w": 9, "tree_size": 64, "t0": 2.4467, "t1": 0.3367, "tft": 3.6405, "input_0": 205, "input_1": 65, "min_CLP": -4.31, "draft_iters": 16.3, "mem_use": 45.53, "gen_rate": 12.7, "speed": 4.54, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 18, "tree_size": 64, "t0": 1.35, "t1": 0.3314, "tft": 2.1526, "input_0": 145, "input_1": 65, "min_CLP": -5.07, "draft_iters": 9.0, "mem_use": 44.88, "gen_rate": 5.0, "speed": 2.97, "text": "As the goddess of love, fertilit"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.7183, "t1": 0.3383, "tft": 3.6683, "input_0": 183, "input_1": 65, "min_CLP": -4.39, "draft_iters": 11.0, "mem_use": 46.54, "gen_rate": 5.8, "speed": 2.84, "text": "Yes, there are many non-dairy ch"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 12, "tree_size": 64, "t0": 1.626, "t1": 0.338, "tft": 4.0512, "input_0": 166, "input_1": 65, "min_CLP": -4.44, "draft_iters": 10.4, "mem_use": 46.58, "gen_rate": 7.0, "speed": 3.57, "text": "When selecting an internet servi"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 9, "tree_size": 64, "t0": 2.25, "t1": 0.35, "tft": 6.7071, "input_0": 230, "input_1": 65, "min_CLP": -4.76, "draft_iters": 14.3, "mem_use": 49.31, "gen_rate": 12.3, "speed": 4.74, "text": "Selenium may be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 1.5414, "t1": 0.33, "tft": 2.4919, "input_0": 148, "input_1": 65, "min_CLP": -4.49, "draft_iters": 10.0, "mem_use": 44.4, "gen_rate": 5.1, "speed": 2.75, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 18.5, "tree_w": 15, "tree_size": 64, "t0": 2.61, "t1": 0.33, "tft": 4.3853, "input_0": 156, "input_1": 65, "min_CLP": -4.55, "draft_iters": 19.0, "mem_use": 44.94, "gen_rate": 17.5, "speed": 5.95, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.0, "tree_w": 12, "tree_size": 64, "t0": 2.0025, "t1": 0.3375, "tft": 4.8358, "input_0": 203, "input_1": 65, "min_CLP": -4.62, "draft_iters": 13.0, "mem_use": 47.31, "gen_rate": 9.5, "speed": 4.06, "text": "\"I'm glad you enjoyed Luna's per"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 17.3, "tree_w": 8, "tree_size": 64, "t0": 2.7, "t1": 0.34, "tft": 3.8094, "input_0": 245, "input_1": 65, "min_CLP": -4.17, "draft_iters": 18.3, "mem_use": 45.34, "gen_rate": 15.0, "speed": 4.94, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 20, "tree_size": 64, "t0": 1.1429, "t1": 0.3314, "tft": 1.9044, "input_0": 132, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.1, "mem_use": 44.63, "gen_rate": 5.0, "speed": 3.4, "text": "Foolish mortal, you dare to chal"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.0, "tree_w": 15, "tree_size": 64, "t0": 2.67, "t1": 0.3367, "tft": 6.6959, "input_0": 203, "input_1": 65, "min_CLP": -4.67, "draft_iters": 19.0, "mem_use": 47.13, "gen_rate": 11.0, "speed": 3.66, "text": "\"In the Elder Scrolls universe, "}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.0, "tree_w": 17, "tree_size": 64, "t0": 2.62, "t1": 0.33, "tft": 4.4031, "input_0": 156, "input_1": 65, "min_CLP": -5.29, "draft_iters": 19.5, "mem_use": 47.57, "gen_rate": 19.5, "speed": 6.61, "text": "[INST] AI assistant. I am lookin"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.805, "t1": 0.3325, "tft": 3.9027, "input_0": 186, "input_1": 65, "min_CLP": -4.29, "draft_iters": 12.0, "mem_use": 45.91, "gen_rate": 8.2, "speed": 3.86, "text": "\"It's difficult to determine whi"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 8.0, "tree_w": 24, "tree_size": 64, "t0": 1.34, "t1": 0.33, "tft": 4.2868, "input_0": 117, "input_1": 65, "min_CLP": -5.23, "draft_iters": 9.0, "mem_use": 45.16, "gen_rate": 0.0, "speed": 0.0, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.0, "tree_w": 21, "tree_size": 64, "t0": 1.43, "t1": 0.3375, "tft": 4.1617, "input_0": 126, "input_1": 65, "min_CLP": -5.2, "draft_iters": 10.0, "mem_use": 44.9, "gen_rate": 4.1, "speed": 2.33, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.7, "tree_w": 11, "tree_size": 64, "t0": 2.1533, "t1": 0.3267, "tft": 3.1409, "input_0": 216, "input_1": 65, "min_CLP": -4.36, "draft_iters": 13.7, "mem_use": 44.41, "gen_rate": 11.7, "speed": 4.7, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 16.7, "tree_w": 10, "tree_size": 64, "t0": 2.43, "t1": 0.3533, "tft": 6.6459, "input_0": 188, "input_1": 65, "min_CLP": -4.41, "draft_iters": 17.3, "mem_use": 49.86, "gen_rate": 16.3, "speed": 5.87, "text": "\"Here's an updated version of th"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 25, "tree_size": 64, "t0": 1.0057, "t1": 0.3357, "tft": 2.7825, "input_0": 109, "input_1": 65, "min_CLP": -5.27, "draft_iters": 6.6, "mem_use": 46.15, "gen_rate": 4.6, "speed": 3.4, "text": "\"You see, there's this thing, th"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 7.2, "tree_w": 21, "tree_size": 64, "t0": 1.22, "t1": 0.334, "tft": 2.0953, "input_0": 120, "input_1": 65, "min_CLP": -5.08, "draft_iters": 8.2, "mem_use": 45.17, "gen_rate": 4.0, "speed": 2.58, "text": "If you have any other questions "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 18.7, "tree_w": 15, "tree_size": 64, "t0": 2.7167, "t1": 0.3267, "tft": 1.9681, "input_0": 189, "input_1": 65, "min_CLP": -5.24, "draft_iters": 19.3, "mem_use": 44.68, "gen_rate": 19.3, "speed": 6.36, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002\\"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 56, "tree_h": 15.4, "tree_w": 10, "tree_size": 64, "t0": 2.37, "t1": 0.334, "tft": 5.6073, "input_0": 199, "input_1": 65, "min_CLP": -4.29, "draft_iters": 16.4, "mem_use": 46.58, "gen_rate": 11.2, "speed": 4.14, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.2, "tree_w": 12, "tree_size": 64, "t0": 2.1375, "t1": 0.3475, "tft": 4.5757, "input_0": 199, "input_1": 65, "min_CLP": -4.57, "draft_iters": 14.2, "mem_use": 45.79, "gen_rate": 10.2, "speed": 4.13, "text": "Sure, here are some historical e"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 2.0825, "t1": 0.34, "tft": 4.18, "input_0": 217, "input_1": 65, "min_CLP": -4.55, "draft_iters": 13.0, "mem_use": 46.13, "gen_rate": 9.8, "speed": 4.03, "text": "\"I appreciate your question, and"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 19, "tree_size": 64, "t0": 1.15, "t1": 0.3233, "tft": 2.0541, "input_0": 129, "input_1": 65, "min_CLP": -4.89, "draft_iters": 7.2, "mem_use": 44.58, "gen_rate": 5.3, "speed": 3.62, "text": "The answer would be \"It depends "}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 21, "tree_size": 64, "t0": 1.32, "t1": 0.3283, "tft": 4.549, "input_0": 150, "input_1": 65, "min_CLP": -4.94, "draft_iters": 8.5, "mem_use": 46.98, "gen_rate": 5.7, "speed": 3.44, "text": "FullView.io is a cutting-edge pl"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.7917, "t1": 0.3417, "tft": 5.5765, "input_0": 165, "input_1": 65, "min_CLP": -4.62, "draft_iters": 12.2, "mem_use": 48.24, "gen_rate": 6.0, "speed": 2.82, "text": "You are correct, my apologies fo"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.0, "tree_w": 10, "tree_size": 64, "t0": 2.024, "t1": 0.34, "tft": 5.4877, "input_0": 213, "input_1": 65, "min_CLP": -4.43, "draft_iters": 13.0, "mem_use": 48.4, "gen_rate": 8.0, "speed": 3.39, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.6, "tree_w": 9, "tree_size": 64, "t0": 2.23, "t1": 0.332, "tft": 4.4806, "input_0": 182, "input_1": 65, "min_CLP": -4.48, "draft_iters": 15.6, "mem_use": 46.06, "gen_rate": 7.0, "speed": 2.73, "text": "I am an AI language model develo"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.9, "tree_w": 16, "tree_size": 64, "t0": 1.5714, "t1": 0.3243, "tft": 2.1522, "input_0": 179, "input_1": 65, "min_CLP": -4.86, "draft_iters": 9.9, "mem_use": 44.4, "gen_rate": 5.4, "speed": 2.86, "text": "\"The best way to form a new habi"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.5, "tree_w": 15, "tree_size": 64, "t0": 1.9325, "t1": 0.32, "tft": 3.5588, "input_0": 209, "input_1": 65, "min_CLP": -4.45, "draft_iters": 12.5, "mem_use": 46.81, "gen_rate": 9.8, "speed": 4.32, "text": "Understood. To directly answer t"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.3, "tree_w": 17, "tree_size": 64, "t0": 1.5483, "t1": 0.3333, "tft": 4.9116, "input_0": 186, "input_1": 65, "min_CLP": -4.7, "draft_iters": 9.3, "mem_use": 47.66, "gen_rate": 6.3, "speed": 3.37, "text": "[The scene opens with the Sparta"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 17, "tree_size": 64, "t0": 1.215, "t1": 0.3317, "tft": 2.2248, "input_0": 149, "input_1": 65, "min_CLP": -4.91, "draft_iters": 7.7, "mem_use": 45.35, "gen_rate": 5.3, "speed": 3.45, "text": "Yeah, I agree. Mnemonics can be "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 20, "tree_size": 64, "t0": 1.0525, "t1": 0.3337, "tft": 3.3814, "input_0": 116, "input_1": 65, "min_CLP": -5.02, "draft_iters": 6.9, "mem_use": 45.07, "gen_rate": 4.0, "speed": 2.89, "text": "The proof-of-stake model simply "}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 5.0, "tree_w": 24, "tree_size": 64, "t0": 0.918, "t1": 0.333, "tft": 2.5337, "input_0": 96, "input_1": 65, "min_CLP": -5.24, "draft_iters": 6.0, "mem_use": 45.19, "gen_rate": 3.9, "speed": 3.13, "text": "\"It's like the butterfly effect,"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.8475, "t1": 0.3375, "tft": 4.6528, "input_0": 187, "input_1": 65, "min_CLP": -4.46, "draft_iters": 11.8, "mem_use": 47.27, "gen_rate": 8.2, "speed": 3.78, "text": "Void pointers are a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.2, "tree_w": 16, "tree_size": 64, "t0": 1.674, "t1": 0.336, "tft": 4.866, "input_0": 172, "input_1": 65, "min_CLP": -4.69, "draft_iters": 11.2, "mem_use": 47.78, "gen_rate": 6.8, "speed": 3.38, "text": "\"I'm sorry, but I can't help you"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 8, "tree_size": 64, "t0": 2.2567, "t1": 0.3267, "tft": 4.951, "input_0": 227, "input_1": 65, "min_CLP": -4.4, "draft_iters": 14.7, "mem_use": 46.99, "gen_rate": 10.7, "speed": 4.13, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 21, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 1.855, "t1": 0.32, "tft": 2.1259, "input_0": 196, "input_1": 65, "min_CLP": -4.62, "draft_iters": 12.0, "mem_use": 44.81, "gen_rate": 10.5, "speed": 4.83, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 13, "tree_size": 64, "t0": 1.582, "t1": 0.322, "tft": 2.1021, "input_0": 175, "input_1": 65, "min_CLP": -4.51, "draft_iters": 10.2, "mem_use": 44.4, "gen_rate": 6.6, "speed": 3.46, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 4.35, "t1": 0.34, "tft": 5.1217, "input_0": 290, "input_1": 65, "min_CLP": -3.88, "draft_iters": 32.0, "mem_use": 47.23, "gen_rate": 33.0, "speed": 7.04, "text": "\"Sure, here's the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 15, "tree_size": 64, "t0": 1.6683, "t1": 0.3233, "tft": 1.7301, "input_0": 160, "input_1": 65, "min_CLP": -4.76, "draft_iters": 11.0, "mem_use": 44.35, "gen_rate": 5.5, "speed": 2.76, "text": "The city of Berlin was founded b"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.866, "t1": 0.336, "tft": 3.6655, "input_0": 192, "input_1": 65, "min_CLP": -4.53, "draft_iters": 12.0, "mem_use": 46.69, "gen_rate": 7.0, "speed": 3.18, "text": "\"Dear friends and family,\\n\\nAs "}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.0, "tree_w": 12, "tree_size": 64, "t0": 1.88, "t1": 0.3367, "tft": 4.3145, "input_0": 164, "input_1": 65, "min_CLP": -4.51, "draft_iters": 13.0, "mem_use": 46.55, "gen_rate": 11.0, "speed": 4.97, "text": "\"Certainly. Some critics have ta"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.2, "tree_w": 16, "tree_size": 64, "t0": 1.4362, "t1": 0.3237, "tft": 2.0406, "input_0": 154, "input_1": 65, "min_CLP": -5.05, "draft_iters": 9.2, "mem_use": 44.37, "gen_rate": 4.6, "speed": 2.63, "text": "The question \"Where does pornogr"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 28.3, "tree_w": 8, "tree_size": 64, "t0": 3.8833, "t1": 0.3333, "tft": 3.7158, "input_0": 212, "input_1": 65, "min_CLP": -5.18, "draft_iters": 29.0, "mem_use": 44.68, "gen_rate": 20.0, "speed": 4.74, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 17, "tree_size": 64, "t0": 1.518, "t1": 0.324, "tft": 1.801, "input_0": 162, "input_1": 65, "min_CLP": -4.79, "draft_iters": 9.8, "mem_use": 44.77, "gen_rate": 6.6, "speed": 3.58, "text": "The five second rule is actually"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 23.0, "tree_w": 8, "tree_size": 64, "t0": 3.14, "t1": 0.32, "tft": 1.9858, "input_0": 173, "input_1": 65, "min_CLP": -4.51, "draft_iters": 24.0, "mem_use": 44.49, "gen_rate": 5.0, "speed": 1.44, "text": "You have 5 eggs left."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 12, "tree_size": 64, "t0": 2.0433, "t1": 0.33, "tft": 3.7335, "input_0": 212, "input_1": 65, "min_CLP": -4.27, "draft_iters": 13.7, "mem_use": 45.24, "gen_rate": 10.7, "speed": 4.5, "text": "\"Sure, I'd be happy to explain s"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 12.5, "tree_w": 17, "tree_size": 64, "t0": 1.8783, "t1": 0.3217, "tft": 2.4256, "input_0": 150, "input_1": 65, "min_CLP": -4.92, "draft_iters": 13.3, "mem_use": 44.81, "gen_rate": 5.8, "speed": 2.65, "text": "No problem, happy to help!\\n\\n[I"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.5, "tree_w": 13, "tree_size": 64, "t0": 1.7067, "t1": 0.325, "tft": 2.5799, "input_0": 168, "input_1": 65, "min_CLP": -4.62, "draft_iters": 11.5, "mem_use": 44.52, "gen_rate": 6.0, "speed": 2.95, "text": "Here\\'s a potential announcement"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 16, "tree_size": 64, "t0": 1.492, "t1": 0.334, "tft": 3.5172, "input_0": 181, "input_1": 65, "min_CLP": -4.87, "draft_iters": 9.4, "mem_use": 45.13, "gen_rate": 6.8, "speed": 3.73, "text": "One example of sexual selection "}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.2, "tree_w": 11, "tree_size": 64, "t0": 1.818, "t1": 0.332, "tft": 3.7306, "input_0": 211, "input_1": 65, "min_CLP": -4.34, "draft_iters": 11.2, "mem_use": 46.18, "gen_rate": 7.2, "speed": 3.35, "text": "AI assistants can also be useful"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 4.38, "t1": 0.33, "tft": 5.9496, "input_0": 298, "input_1": 65, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 47.2, "gen_rate": 33.0, "speed": 7.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 1.6275, "t1": 0.3325, "tft": 4.049, "input_0": 181, "input_1": 65, "min_CLP": -4.55, "draft_iters": 10.5, "mem_use": 45.69, "gen_rate": 8.0, "speed": 4.07, "text": "The scp command is a Unix-based "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 4.28, "t1": 0.33, "tft": 5.5891, "input_0": 271, "input_1": 65, "min_CLP": -4.64, "draft_iters": 32.0, "mem_use": 46.34, "gen_rate": 33.0, "speed": 7.15, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 15, "tree_size": 64, "t0": 1.3533, "t1": 0.3233, "tft": 2.1462, "input_0": 156, "input_1": 65, "min_CLP": -4.86, "draft_iters": 8.7, "mem_use": 44.42, "gen_rate": 5.5, "speed": 3.28, "text": "\"No, it would not be illegal to "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.5, "tree_w": 14, "tree_size": 64, "t0": 1.575, "t1": 0.3217, "tft": 2.7794, "input_0": 170, "input_1": 65, "min_CLP": -4.59, "draft_iters": 10.5, "mem_use": 44.71, "gen_rate": 6.2, "speed": 3.24, "text": "\"Sydney is the largest city in A"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 11.2, "tree_w": 16, "tree_size": 64, "t0": 1.776, "t1": 0.328, "tft": 2.5108, "input_0": 157, "input_1": 65, "min_CLP": -5.08, "draft_iters": 12.2, "mem_use": 45.01, "gen_rate": 8.8, "speed": 4.18, "text": "Is the 5 second rule a good idea"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 24, "tree_size": 64, "t0": 1.0186, "t1": 0.3243, "tft": 1.789, "input_0": 103, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.9, "mem_use": 44.69, "gen_rate": 5.0, "speed": 3.73, "text": "\"Hey, don't feel bad about it. Y"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 4.15, "t1": 0.33, "tft": 3.5489, "input_0": 207, "input_1": 65, "min_CLP": -6.01, "draft_iters": 32.0, "mem_use": 44.46, "gen_rate": 33.0, "speed": 7.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.1, "tree_w": 16, "tree_size": 64, "t0": 1.3629, "t1": 0.3229, "tft": 3.1326, "input_0": 144, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.1, "mem_use": 44.43, "gen_rate": 5.1, "speed": 3.05, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.0, "tree_w": 7, "tree_size": 64, "t0": 2.8267, "t1": 0.3333, "tft": 5.6738, "input_0": 226, "input_1": 65, "min_CLP": -4.0, "draft_iters": 19.0, "mem_use": 46.18, "gen_rate": 13.3, "speed": 4.21, "text": "\"Sure, I'd be happy to explain i"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 13, "tree_size": 64, "t0": 1.576, "t1": 0.322, "tft": 2.3766, "input_0": 166, "input_1": 65, "min_CLP": -4.75, "draft_iters": 10.0, "mem_use": 44.43, "gen_rate": 6.8, "speed": 3.58, "text": "The best areas for a moderate wa"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.3, "tree_w": 9, "tree_size": 64, "t0": 2.3933, "t1": 0.33, "tft": 3.6879, "input_0": 227, "input_1": 65, "min_CLP": -4.32, "draft_iters": 16.3, "mem_use": 44.74, "gen_rate": 12.0, "speed": 4.4, "text": "To write a first-person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 9, "tree_size": 64, "t0": 1.99, "t1": 0.33, "tft": 2.3461, "input_0": 191, "input_1": 65, "min_CLP": -4.27, "draft_iters": 13.0, "mem_use": 44.41, "gen_rate": 11.3, "speed": 4.88, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 1.64, "t1": 0.326, "tft": 1.679, "input_0": 163, "input_1": 65, "min_CLP": -4.59, "draft_iters": 11.2, "mem_use": 44.72, "gen_rate": 7.6, "speed": 3.86, "text": "There is no set path to becoming"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.4, "tree_w": 16, "tree_size": 64, "t0": 1.2837, "t1": 0.325, "tft": 2.4113, "input_0": 139, "input_1": 65, "min_CLP": -4.74, "draft_iters": 8.4, "mem_use": 44.58, "gen_rate": 4.6, "speed": 2.88, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.6, "tree_w": 12, "tree_size": 64, "t0": 2.138, "t1": 0.324, "tft": 3.4744, "input_0": 188, "input_1": 65, "min_CLP": -4.97, "draft_iters": 14.6, "mem_use": 44.82, "gen_rate": 6.8, "speed": 2.76, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.4, "tree_w": 15, "tree_size": 64, "t0": 1.4614, "t1": 0.3357, "tft": 4.652, "input_0": 147, "input_1": 65, "min_CLP": -4.6, "draft_iters": 9.4, "mem_use": 47.67, "gen_rate": 4.9, "speed": 2.7, "text": "Yes, I understand your concern. "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.8, "tree_w": 16, "tree_size": 64, "t0": 1.61, "t1": 0.328, "tft": 3.274, "input_0": 139, "input_1": 65, "min_CLP": -4.78, "draft_iters": 10.8, "mem_use": 44.88, "gen_rate": 7.4, "speed": 3.81, "text": "\"Yes, it is considered ethical a"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.8, "tree_w": 14, "tree_size": 64, "t0": 1.718, "t1": 0.334, "tft": 4.8821, "input_0": 195, "input_1": 65, "min_CLP": -4.69, "draft_iters": 10.8, "mem_use": 47.78, "gen_rate": 6.6, "speed": 3.22, "text": "Xin ch\u00e0o! T\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd th\u00f4n"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 22, "tree_h": 6.2, "tree_w": 27, "tree_size": 64, "t0": 1.0556, "t1": 0.3322, "tft": 2.2867, "input_0": 103, "input_1": 65, "min_CLP": -5.21, "draft_iters": 7.2, "mem_use": 45.25, "gen_rate": 2.4, "speed": 1.76, "text": "So, it really happened. I was ri"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.8, "tree_w": 9, "tree_size": 64, "t0": 2.584, "t1": 0.332, "tft": 2.5221, "input_0": 232, "input_1": 65, "min_CLP": -4.0, "draft_iters": 17.6, "mem_use": 44.77, "gen_rate": 6.4, "speed": 2.2, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 13.5, "tree_w": 14, "tree_size": 64, "t0": 2.2467, "t1": 0.3333, "tft": 3.5696, "input_0": 240, "input_1": 65, "min_CLP": -4.81, "draft_iters": 14.5, "mem_use": 46.2, "gen_rate": 6.8, "speed": 2.65, "text": "1. Scorpions\\n2. Rammstein\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.6, "tree_w": 19, "tree_size": 64, "t0": 1.3444, "t1": 0.3289, "tft": 2.4352, "input_0": 145, "input_1": 65, "min_CLP": -4.99, "draft_iters": 8.6, "mem_use": 44.73, "gen_rate": 3.8, "speed": 2.25, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.7, "tree_w": 9, "tree_size": 64, "t0": 2.16, "t1": 0.3267, "tft": 4.7059, "input_0": 194, "input_1": 65, "min_CLP": -4.39, "draft_iters": 14.7, "mem_use": 46.74, "gen_rate": 11.0, "speed": 4.42, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.0, "tree_w": 18, "tree_size": 64, "t0": 1.2378, "t1": 0.3367, "tft": 2.8046, "input_0": 134, "input_1": 65, "min_CLP": -4.72, "draft_iters": 8.0, "mem_use": 45.36, "gen_rate": 4.0, "speed": 2.54, "text": "\"As an AI language model, I am n"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.4, "tree_w": 16, "tree_size": 64, "t0": 1.594, "t1": 0.326, "tft": 2.5996, "input_0": 169, "input_1": 65, "min_CLP": -4.88, "draft_iters": 10.4, "mem_use": 44.89, "gen_rate": 7.2, "speed": 3.75, "text": "I understand your request. In \u201cR"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.4, "tree_w": 11, "tree_size": 64, "t0": 2.014, "t1": 0.332, "tft": 3.0353, "input_0": 194, "input_1": 65, "min_CLP": -4.43, "draft_iters": 13.4, "mem_use": 45.03, "gen_rate": 7.4, "speed": 3.15, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.0, "tree_w": 20, "tree_size": 64, "t0": 1.6883, "t1": 0.3367, "tft": 3.7683, "input_0": 160, "input_1": 65, "min_CLP": -5.38, "draft_iters": 11.0, "mem_use": 46.3, "gen_rate": 6.7, "speed": 3.29, "text": "Certainly! Here\\'s a poem in Que"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.7925, "t1": 0.325, "tft": 2.5128, "input_0": 164, "input_1": 65, "min_CLP": -4.62, "draft_iters": 12.0, "mem_use": 44.41, "gen_rate": 8.2, "speed": 3.9, "text": "Sure, here are the five most com"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.0, "tree_w": 14, "tree_size": 64, "t0": 1.932, "t1": 0.332, "tft": 2.6139, "input_0": 185, "input_1": 65, "min_CLP": -4.51, "draft_iters": 13.0, "mem_use": 44.45, "gen_rate": 6.8, "speed": 3.0, "text": "\"The code has a syntax error. Th"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.0, "tree_w": 17, "tree_size": 64, "t0": 1.2343, "t1": 0.3429, "tft": 3.015, "input_0": 137, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.0, "mem_use": 45.84, "gen_rate": 5.4, "speed": 3.45, "text": "As a helpful assistant, I am hap"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.3, "tree_w": 12, "tree_size": 64, "t0": 1.9967, "t1": 0.33, "tft": 2.9096, "input_0": 234, "input_1": 65, "min_CLP": -4.67, "draft_iters": 12.3, "mem_use": 45.06, "gen_rate": 10.7, "speed": 4.59, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 11, "tree_size": 64, "t0": 1.9867, "t1": 0.3333, "tft": 3.2014, "input_0": 192, "input_1": 65, "min_CLP": -4.16, "draft_iters": 13.3, "mem_use": 45.18, "gen_rate": 11.0, "speed": 4.74, "text": "\"To create a Python program that"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 13.4, "tree_w": 10, "tree_size": 64, "t0": 2.168, "t1": 0.336, "tft": 4.6277, "input_0": 201, "input_1": 65, "min_CLP": -4.45, "draft_iters": 14.4, "mem_use": 46.97, "gen_rate": 8.6, "speed": 3.44, "text": "\"If your friends are insistent t"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.0, "tree_w": 8, "tree_size": 64, "t0": 2.89, "t1": 0.3333, "tft": 3.3796, "input_0": 220, "input_1": 65, "min_CLP": -4.53, "draft_iters": 20.0, "mem_use": 44.97, "gen_rate": 10.7, "speed": 3.31, "text": "Great suggestion! Here\\'s the up"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 15.2, "tree_w": 8, "tree_size": 64, "t0": 2.3975, "t1": 0.335, "tft": 6.4541, "input_0": 206, "input_1": 65, "min_CLP": -4.02, "draft_iters": 16.2, "mem_use": 46.33, "gen_rate": 10.2, "speed": 3.75, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.764, "t1": 0.328, "tft": 2.2749, "input_0": 190, "input_1": 65, "min_CLP": -4.47, "draft_iters": 11.0, "mem_use": 44.39, "gen_rate": 6.8, "speed": 3.25, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 15.2, "tree_w": 18, "tree_size": 64, "t0": 2.202, "t1": 0.334, "tft": 1.9296, "input_0": 131, "input_1": 65, "min_CLP": -5.37, "draft_iters": 16.2, "mem_use": 44.61, "gen_rate": 8.8, "speed": 3.47, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 1.564, "t1": 0.328, "tft": 2.1204, "input_0": 166, "input_1": 65, "min_CLP": -4.98, "draft_iters": 10.0, "mem_use": 44.86, "gen_rate": 6.8, "speed": 3.59, "text": "\"Thank you! I'm programmed to pr"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 12.8, "tree_w": 11, "tree_size": 64, "t0": 1.958, "t1": 0.34, "tft": 3.725, "input_0": 156, "input_1": 65, "min_CLP": -4.87, "draft_iters": 13.8, "mem_use": 46.45, "gen_rate": 10.2, "speed": 4.43, "text": "\"Thou art the bright sun that do"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 10, "tree_h": 22.0, "tree_w": 12, "tree_size": 64, "t0": 3.06, "t1": 0.34, "tft": 2.5898, "input_0": 150, "input_1": 65, "min_CLP": -4.97, "draft_iters": 23.0, "mem_use": 45.03, "gen_rate": 10.0, "speed": 2.94, "text": "[INST] Please provide a source r"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.5, "tree_w": 14, "tree_size": 64, "t0": 2.0517, "t1": 0.3217, "tft": 2.7712, "input_0": 211, "input_1": 65, "min_CLP": -5.06, "draft_iters": 13.5, "mem_use": 44.43, "gen_rate": 6.2, "speed": 2.6, "text": "Certainly! Here are some words t"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.7, "tree_w": 9, "tree_size": 64, "t0": 2.24, "t1": 0.3267, "tft": 2.5991, "input_0": 206, "input_1": 65, "min_CLP": -4.43, "draft_iters": 14.7, "mem_use": 44.41, "gen_rate": 11.7, "speed": 4.54, "text": "\"Presidents Day, officially know"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.1, "tree_w": 18, "tree_size": 64, "t0": 1.2567, "t1": 0.3278, "tft": 2.8246, "input_0": 141, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.1, "mem_use": 44.71, "gen_rate": 4.1, "speed": 2.59, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.0, "tree_w": 9, "tree_size": 64, "t0": 2.11, "t1": 0.335, "tft": 3.6309, "input_0": 204, "input_1": 65, "min_CLP": -4.22, "draft_iters": 14.0, "mem_use": 45.52, "gen_rate": 8.5, "speed": 3.48, "text": "The existence of the KeyHole ser"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.7, "tree_w": 21, "tree_size": 64, "t0": 1.2733, "t1": 0.3222, "tft": 2.0978, "input_0": 119, "input_1": 65, "min_CLP": -5.21, "draft_iters": 8.7, "mem_use": 44.79, "gen_rate": 3.6, "speed": 2.22, "text": "Why was the window feeling left "}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 7.2, "tree_w": 21, "tree_size": 64, "t0": 1.236, "t1": 0.33, "tft": 2.1298, "input_0": 122, "input_1": 65, "min_CLP": -5.13, "draft_iters": 8.2, "mem_use": 44.86, "gen_rate": 3.4, "speed": 2.17, "text": "Well then I am glad to hear that"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 64, "t0": 4.16, "t1": 0.33, "tft": 1.9418, "input_0": 222, "input_1": 65, "min_CLP": -5.92, "draft_iters": 32.0, "mem_use": 44.41, "gen_rate": 33.0, "speed": 7.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.9, "tree_w": 19, "tree_size": 64, "t0": 1.1675, "t1": 0.3313, "tft": 2.6234, "input_0": 116, "input_1": 65, "min_CLP": -5.0, "draft_iters": 7.9, "mem_use": 45.1, "gen_rate": 4.0, "speed": 2.67, "text": "\"Ha, he must be so out of touch."}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.6, "tree_w": 15, "tree_size": 64, "t0": 1.504, "t1": 0.32, "tft": 3.3627, "input_0": 163, "input_1": 65, "min_CLP": -4.66, "draft_iters": 9.6, "mem_use": 44.52, "gen_rate": 7.2, "speed": 3.94, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.7186, "t1": 0.3386, "tft": 3.0954, "input_0": 178, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.6, "mem_use": 45.75, "gen_rate": 5.1, "speed": 2.5, "text": "Sure, here are some examples of "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.3, "tree_w": 20, "tree_size": 64, "t0": 1.1611, "t1": 0.3267, "tft": 2.2146, "input_0": 134, "input_1": 65, "min_CLP": -5.11, "draft_iters": 7.3, "mem_use": 44.86, "gen_rate": 4.1, "speed": 2.76, "text": "\"Hey, I'm AI! I can't take over "}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.2, "tree_w": 13, "tree_size": 64, "t0": 1.584, "t1": 0.336, "tft": 4.1696, "input_0": 175, "input_1": 65, "min_CLP": -4.47, "draft_iters": 10.2, "mem_use": 46.06, "gen_rate": 7.8, "speed": 4.06, "text": "\"Based on your criteria, I would"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.6, "tree_w": 20, "tree_size": 64, "t0": 1.2829, "t1": 0.3286, "tft": 3.0765, "input_0": 130, "input_1": 65, "min_CLP": -5.05, "draft_iters": 8.6, "mem_use": 44.81, "gen_rate": 4.6, "speed": 2.83, "text": "\"Open Assistant: The Open Source"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.4, "tree_w": 13, "tree_size": 64, "t0": 1.646, "t1": 0.322, "tft": 2.3965, "input_0": 181, "input_1": 65, "min_CLP": -4.49, "draft_iters": 10.4, "mem_use": 44.7, "gen_rate": 7.6, "speed": 3.86, "text": "\"Sure! Here's a visual represent"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.3, "tree_w": 11, "tree_size": 64, "t0": 1.8667, "t1": 0.3267, "tft": 4.0018, "input_0": 168, "input_1": 65, "min_CLP": -4.4, "draft_iters": 12.3, "mem_use": 47.04, "gen_rate": 10.7, "speed": 4.86, "text": "This is because of the limitatio"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.5, "tree_w": 13, "tree_size": 64, "t0": 1.7225, "t1": 0.3325, "tft": 2.8636, "input_0": 163, "input_1": 65, "min_CLP": -4.51, "draft_iters": 11.5, "mem_use": 44.39, "gen_rate": 9.2, "speed": 4.5, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 7.0, "tree_w": 24, "tree_size": 64, "t0": 1.1629, "t1": 0.3314, "tft": 2.3621, "input_0": 98, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.0, "mem_use": 44.94, "gen_rate": 5.9, "speed": 3.92, "text": "I think that the OP\\'s question "}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 14, "tree_size": 64, "t0": 1.6233, "t1": 0.3267, "tft": 2.2512, "input_0": 168, "input_1": 65, "min_CLP": -5.02, "draft_iters": 10.3, "mem_use": 44.57, "gen_rate": 5.7, "speed": 2.9, "text": "The second batch of pancakes bro"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 4.17, "t1": 0.32, "tft": 2.4953, "input_0": 214, "input_1": 65, "min_CLP": -5.92, "draft_iters": 32.0, "mem_use": 44.41, "gen_rate": 33.0, "speed": 7.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.8, "tree_w": 13, "tree_size": 64, "t0": 1.762, "t1": 0.332, "tft": 4.3696, "input_0": 186, "input_1": 65, "min_CLP": -4.61, "draft_iters": 11.8, "mem_use": 46.5, "gen_rate": 8.4, "speed": 4.01, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 10.2, "tree_w": 16, "tree_size": 64, "t0": 1.6875, "t1": 0.3237, "tft": 2.3701, "input_0": 157, "input_1": 65, "min_CLP": -4.78, "draft_iters": 11.2, "mem_use": 44.37, "gen_rate": 5.0, "speed": 2.48, "text": "No, a thumb war is not violent. "}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 13.4, "tree_w": 18, "tree_size": 64, "t0": 2.0671, "t1": 0.3243, "tft": 3.2274, "input_0": 152, "input_1": 65, "min_CLP": -4.79, "draft_iters": 14.4, "mem_use": 44.45, "gen_rate": 4.6, "speed": 1.91, "text": "Rick Astley\\'s \"Never Gonna Give"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.7, "tree_w": 13, "tree_size": 64, "t0": 1.6271, "t1": 0.3371, "tft": 4.7192, "input_0": 172, "input_1": 65, "min_CLP": -4.46, "draft_iters": 10.7, "mem_use": 47.74, "gen_rate": 5.1, "speed": 2.62, "text": "The most marijuana-friendly coun"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.0, "tree_w": 14, "tree_size": 64, "t0": 1.682, "t1": 0.34, "tft": 3.3791, "input_0": 169, "input_1": 65, "min_CLP": -4.51, "draft_iters": 11.0, "mem_use": 45.72, "gen_rate": 8.2, "speed": 4.06, "text": "\"I apologize for any confusion c"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 10.2, "tree_w": 12, "tree_size": 64, "t0": 1.766, "t1": 0.326, "tft": 2.2347, "input_0": 203, "input_1": 65, "min_CLP": -4.47, "draft_iters": 11.2, "mem_use": 44.67, "gen_rate": 8.8, "speed": 4.21, "text": "There are several resources avai"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.814, "t1": 0.328, "tft": 3.0326, "input_0": 183, "input_1": 65, "min_CLP": -4.63, "draft_iters": 12.0, "mem_use": 44.64, "gen_rate": 6.4, "speed": 2.99, "text": "Tax fraud is a serious crime tha"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 4.32, "t1": 0.33, "tft": 2.6962, "input_0": 230, "input_1": 65, "min_CLP": -6.42, "draft_iters": 32.0, "mem_use": 44.41, "gen_rate": 33.0, "speed": 7.09, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 13, "tree_size": 64, "t0": 1.548, "t1": 0.33, "tft": 2.6645, "input_0": 178, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.0, "mem_use": 45.22, "gen_rate": 6.4, "speed": 3.41, "text": "I\\'m sorry, I\\'m not sure what y"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 13, "tree_size": 64, "t0": 1.6975, "t1": 0.33, "tft": 4.1289, "input_0": 168, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.8, "mem_use": 45.24, "gen_rate": 8.2, "speed": 4.07, "text": "\"1. \u00abStairway to Heaven\u00bb, Led Ze"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 24.3, "tree_w": 6, "tree_size": 64, "t0": 3.46, "t1": 0.34, "tft": 5.1258, "input_0": 237, "input_1": 65, "min_CLP": -4.05, "draft_iters": 25.3, "mem_use": 47.76, "gen_rate": 10.7, "speed": 2.8, "text": "Step 1 \u2014 Starting the TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 4.35, "t1": 0.32, "tft": 2.6983, "input_0": 230, "input_1": 65, "min_CLP": -6.14, "draft_iters": 32.0, "mem_use": 44.42, "gen_rate": 33.0, "speed": 7.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 19, "tree_size": 64, "t0": 1.236, "t1": 0.328, "tft": 3.3471, "input_0": 140, "input_1": 65, "min_CLP": -4.99, "draft_iters": 7.8, "mem_use": 44.98, "gen_rate": 6.4, "speed": 4.09, "text": "Berlin produces a wide range of "}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 20.7, "tree_w": 6, "tree_size": 64, "t0": 3.17, "t1": 0.3233, "tft": 3.0874, "input_0": 254, "input_1": 65, "min_CLP": -4.14, "draft_iters": 21.7, "mem_use": 44.45, "gen_rate": 19.3, "speed": 5.53, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 9, "tree_size": 64, "t0": 2.044, "t1": 0.34, "tft": 4.0196, "input_0": 176, "input_1": 65, "min_CLP": -4.49, "draft_iters": 13.8, "mem_use": 46.96, "gen_rate": 6.8, "speed": 2.86, "text": "## Vegetarian\\n Microwave Potato"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 7.5, "tree_w": 25, "tree_size": 64, "t0": 1.25, "t1": 0.33, "tft": 2.0241, "input_0": 114, "input_1": 65, "min_CLP": -5.12, "draft_iters": 8.5, "mem_use": 44.36, "gen_rate": 3.0, "speed": 1.89, "text": "An answer to this question is:"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.0, "tree_w": 13, "tree_size": 64, "t0": 1.5725, "t1": 0.34, "tft": 4.0136, "input_0": 172, "input_1": 65, "min_CLP": -4.65, "draft_iters": 10.0, "mem_use": 46.63, "gen_rate": 8.5, "speed": 4.44, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.5, "tree_w": 14, "tree_size": 64, "t0": 2.965, "t1": 0.33, "tft": 2.1301, "input_0": 204, "input_1": 65, "min_CLP": -5.54, "draft_iters": 21.0, "mem_use": 44.37, "gen_rate": 18.0, "speed": 5.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 7.6, "tree_w": 22, "tree_size": 64, "t0": 1.206, "t1": 0.326, "tft": 1.5972, "input_0": 107, "input_1": 65, "min_CLP": -5.43, "draft_iters": 8.6, "mem_use": 44.36, "gen_rate": 3.4, "speed": 2.22, "text": "He was not a good person. [INST]"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.8075, "t1": 0.325, "tft": 2.3027, "input_0": 166, "input_1": 65, "min_CLP": -4.4, "draft_iters": 12.0, "mem_use": 44.52, "gen_rate": 9.0, "speed": 4.22, "text": "Yes, I can provide an example of"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 16, "tree_size": 64, "t0": 1.852, "t1": 0.338, "tft": 4.3985, "input_0": 207, "input_1": 65, "min_CLP": -4.67, "draft_iters": 12.0, "mem_use": 45.58, "gen_rate": 6.8, "speed": 3.1, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.2, "tree_w": 25, "tree_size": 64, "t0": 0.9467, "t1": 0.3267, "tft": 2.3945, "input_0": 108, "input_1": 65, "min_CLP": -5.23, "draft_iters": 6.2, "mem_use": 44.47, "gen_rate": 4.2, "speed": 3.32, "text": "Higher quality of digital photos"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 12.2, "tree_w": 12, "tree_size": 64, "t0": 1.9983, "t1": 0.33, "tft": 2.0784, "input_0": 197, "input_1": 65, "min_CLP": -4.66, "draft_iters": 13.2, "mem_use": 44.67, "gen_rate": 7.0, "speed": 3.01, "text": "Sure, here\\'s a more detailed ex"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 12, "tree_size": 64, "t0": 1.7017, "t1": 0.3317, "tft": 3.2341, "input_0": 176, "input_1": 65, "min_CLP": -4.49, "draft_iters": 11.0, "mem_use": 45.01, "gen_rate": 5.5, "speed": 2.71, "text": "Selective fire refers to a firea"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.9, "tree_w": 16, "tree_size": 64, "t0": 1.3657, "t1": 0.3286, "tft": 3.036, "input_0": 137, "input_1": 65, "min_CLP": -4.89, "draft_iters": 8.9, "mem_use": 44.56, "gen_rate": 5.4, "speed": 3.2, "text": "I am a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 18.8, "tree_w": 9, "tree_size": 64, "t0": 2.835, "t1": 0.34, "tft": 4.6465, "input_0": 230, "input_1": 65, "min_CLP": -4.1, "draft_iters": 19.5, "mem_use": 45.78, "gen_rate": 13.8, "speed": 4.33, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 4.23, "t1": 0.32, "tft": 4.1629, "input_0": 208, "input_1": 65, "min_CLP": -6.36, "draft_iters": 32.0, "mem_use": 44.45, "gen_rate": 33.0, "speed": 7.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 12, "tree_size": 64, "t0": 2.0925, "t1": 0.3325, "tft": 3.6368, "input_0": 171, "input_1": 65, "min_CLP": -4.72, "draft_iters": 14.5, "mem_use": 45.29, "gen_rate": 8.2, "speed": 3.4, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 4.15, "t1": 0.33, "tft": 1.8944, "input_0": 193, "input_1": 65, "min_CLP": -5.44, "draft_iters": 32.0, "mem_use": 44.56, "gen_rate": 33.0, "speed": 7.36, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 1.56, "t1": 0.3267, "tft": 2.5168, "input_0": 163, "input_1": 65, "min_CLP": -4.88, "draft_iters": 10.3, "mem_use": 44.39, "gen_rate": 6.3, "speed": 3.35, "text": "\"The cat in Schr\u00f6dinger's though"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 1.645, "t1": 0.3467, "tft": 6.6124, "input_0": 180, "input_1": 65, "min_CLP": -4.54, "draft_iters": 10.5, "mem_use": 48.7, "gen_rate": 6.8, "speed": 3.43, "text": "\"It's understandable that your f"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.2, "tree_w": 10, "tree_size": 64, "t0": 2.04, "t1": 0.32, "tft": 1.8286, "input_0": 204, "input_1": 65, "min_CLP": -4.52, "draft_iters": 13.2, "mem_use": 44.69, "gen_rate": 10.0, "speed": 4.24, "text": "\"The best way to approach a tech"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.0, "tree_w": 9, "tree_size": 64, "t0": 2.57, "t1": 0.3333, "tft": 4.001, "input_0": 224, "input_1": 65, "min_CLP": -4.15, "draft_iters": 18.0, "mem_use": 45.57, "gen_rate": 11.3, "speed": 3.9, "text": "To estimate the time it would ta"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 18, "tree_size": 64, "t0": 1.3357, "t1": 0.3386, "tft": 3.8227, "input_0": 136, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.7, "mem_use": 46.83, "gen_rate": 5.0, "speed": 2.99, "text": "You might want to consider using"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 21, "tree_size": 64, "t0": 1.632, "t1": 0.33, "tft": 1.9092, "input_0": 142, "input_1": 65, "min_CLP": -5.4, "draft_iters": 11.4, "mem_use": 44.67, "gen_rate": 6.6, "speed": 3.36, "text": "\"What do you call a broke colleg"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 12.0, "tree_w": 10, "tree_size": 64, "t0": 2.035, "t1": 0.33, "tft": 2.2893, "input_0": 203, "input_1": 65, "min_CLP": -4.85, "draft_iters": 13.0, "mem_use": 44.71, "gen_rate": 9.0, "speed": 3.81, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 14, "tree_size": 64, "t0": 2.055, "t1": 0.3375, "tft": 3.7214, "input_0": 170, "input_1": 65, "min_CLP": -4.86, "draft_iters": 14.5, "mem_use": 45.18, "gen_rate": 8.2, "speed": 3.45, "text": "[INST] What are some AI tools fo"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 1.4317, "t1": 0.3217, "tft": 3.2849, "input_0": 163, "input_1": 65, "min_CLP": -4.78, "draft_iters": 9.0, "mem_use": 44.69, "gen_rate": 5.7, "speed": 3.23, "text": "The book \"Fooled by Randomness\" "}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 1.458, "t1": 0.33, "tft": 2.9918, "input_0": 155, "input_1": 65, "min_CLP": -4.97, "draft_iters": 9.6, "mem_use": 45.37, "gen_rate": 7.0, "speed": 3.91, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.8, "tree_w": 19, "tree_size": 64, "t0": 1.894, "t1": 0.324, "tft": 2.2379, "input_0": 157, "input_1": 65, "min_CLP": -4.97, "draft_iters": 13.6, "mem_use": 44.71, "gen_rate": 7.6, "speed": 3.43, "text": "\"Sure! Here's a simple Braille t"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 1.685, "t1": 0.3275, "tft": 3.0281, "input_0": 168, "input_1": 65, "min_CLP": -4.69, "draft_iters": 11.2, "mem_use": 44.43, "gen_rate": 8.2, "speed": 4.09, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 19, "tree_size": 64, "t0": 1.5883, "t1": 0.3217, "tft": 2.8478, "input_0": 137, "input_1": 65, "min_CLP": -5.09, "draft_iters": 11.2, "mem_use": 44.4, "gen_rate": 5.7, "speed": 2.96, "text": " [1]. Because adrenaline makes y"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.8, "tree_w": 16, "tree_size": 64, "t0": 1.9467, "t1": 0.34, "tft": 5.9494, "input_0": 153, "input_1": 65, "min_CLP": -4.85, "draft_iters": 13.8, "mem_use": 48.68, "gen_rate": 5.5, "speed": 2.41, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 1.4775, "t1": 0.3225, "tft": 2.4917, "input_0": 149, "input_1": 65, "min_CLP": -4.81, "draft_iters": 10.0, "mem_use": 44.53, "gen_rate": 9.0, "speed": 5.0, "text": "Javascript is commonly used for "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 31, "tree_h": 17.5, "tree_w": 12, "tree_size": 64, "t0": 2.665, "t1": 0.335, "tft": 4.0331, "input_0": 225, "input_1": 65, "min_CLP": -4.75, "draft_iters": 18.5, "mem_use": 46.07, "gen_rate": 15.5, "speed": 5.17, "text": "[INST] Can you give me example o"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 1.5075, "t1": 0.3325, "tft": 3.7087, "input_0": 156, "input_1": 65, "min_CLP": -4.5, "draft_iters": 10.0, "mem_use": 45.83, "gen_rate": 8.2, "speed": 4.48, "text": "The \"chkdsk\" command will automa"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.8, "tree_w": 8, "tree_size": 64, "t0": 2.2225, "t1": 0.3325, "tft": 3.1294, "input_0": 242, "input_1": 65, "min_CLP": -4.28, "draft_iters": 14.8, "mem_use": 44.67, "gen_rate": 10.8, "speed": 4.21, "text": "\"To approach and solve this prob"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.3, "tree_w": 15, "tree_size": 64, "t0": 1.4443, "t1": 0.3271, "tft": 2.7252, "input_0": 163, "input_1": 65, "min_CLP": -4.74, "draft_iters": 9.3, "mem_use": 44.48, "gen_rate": 5.3, "speed": 2.98, "text": "The boiling water method is a mo"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 4.32, "t1": 0.32, "tft": 2.9122, "input_0": 233, "input_1": 65, "min_CLP": -6.54, "draft_iters": 32.0, "mem_use": 44.46, "gen_rate": 33.0, "speed": 7.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 9, "tree_size": 64, "t0": 2.185, "t1": 0.3325, "tft": 2.9248, "input_0": 198, "input_1": 65, "min_CLP": -4.2, "draft_iters": 14.5, "mem_use": 45.46, "gen_rate": 8.8, "speed": 3.47, "text": "As an AI language model, I can d"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 11, "tree_h": 11.4, "tree_w": 22, "tree_size": 64, "t0": 1.652, "t1": 0.326, "tft": 1.6845, "input_0": 115, "input_1": 65, "min_CLP": -5.27, "draft_iters": 12.2, "mem_use": 44.79, "gen_rate": 2.2, "speed": 1.11, "text": "The AI is currently in dialogue "}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 19.2, "tree_w": 7, "tree_size": 64, "t0": 2.844, "t1": 0.336, "tft": 4.2287, "input_0": 186, "input_1": 65, "min_CLP": -4.28, "draft_iters": 20.2, "mem_use": 46.11, "gen_rate": 6.4, "speed": 2.01, "text": "Here are the feminine words from"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 5.5, "tree_w": 23, "tree_size": 64, "t0": 1.07, "t1": 0.325, "tft": 2.9858, "input_0": 133, "input_1": 65, "min_CLP": -5.43, "draft_iters": 6.5, "mem_use": 45.03, "gen_rate": 2.5, "speed": 1.79, "text": "I think the answerer is someone "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.7, "tree_w": 19, "tree_size": 64, "t0": 1.1329, "t1": 0.3286, "tft": 2.0301, "input_0": 113, "input_1": 65, "min_CLP": -4.99, "draft_iters": 7.7, "mem_use": 44.87, "gen_rate": 5.1, "speed": 3.52, "text": "I am not a lawyer, but the ATF i"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.2, "tree_w": 14, "tree_size": 64, "t0": 1.58, "t1": 0.3225, "tft": 2.2021, "input_0": 170, "input_1": 65, "min_CLP": -4.38, "draft_iters": 10.2, "mem_use": 44.61, "gen_rate": 8.5, "speed": 4.46, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 22.0, "tree_w": 7, "tree_size": 64, "t0": 3.22, "t1": 0.336, "tft": 7.1316, "input_0": 238, "input_1": 65, "min_CLP": -4.2, "draft_iters": 22.8, "mem_use": 47.41, "gen_rate": 6.4, "speed": 1.8, "text": "\"Sure! Here's an updated ending:"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 4.03, "t1": 0.33, "tft": 5.0893, "input_0": 184, "input_1": 65, "min_CLP": -4.56, "draft_iters": 32.0, "mem_use": 47.33, "gen_rate": 33.0, "speed": 7.57, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.2, "tree_w": 19, "tree_size": 64, "t0": 1.3117, "t1": 0.3233, "tft": 1.9043, "input_0": 152, "input_1": 65, "min_CLP": -5.16, "draft_iters": 8.2, "mem_use": 44.39, "gen_rate": 6.0, "speed": 3.67, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 4, "tree_size": 64, "t0": 4.31, "t1": 0.34, "tft": 2.8366, "input_0": 217, "input_1": 65, "min_CLP": -3.89, "draft_iters": 32.0, "mem_use": 45.56, "gen_rate": 32.0, "speed": 6.88, "text": "Absolutely! Here\\'s the updated "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.5, "tree_w": 10, "tree_size": 64, "t0": 2.565, "t1": 0.335, "tft": 3.2845, "input_0": 215, "input_1": 65, "min_CLP": -4.51, "draft_iters": 17.5, "mem_use": 46.01, "gen_rate": 9.2, "speed": 3.19, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.7, "tree_w": 12, "tree_size": 64, "t0": 2.3367, "t1": 0.3267, "tft": 2.9854, "input_0": 261, "input_1": 65, "min_CLP": -4.49, "draft_iters": 14.7, "mem_use": 44.37, "gen_rate": 11.7, "speed": 4.38, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 8.3, "tree_w": 20, "tree_size": 64, "t0": 1.3478, "t1": 0.3256, "tft": 1.7175, "input_0": 111, "input_1": 65, "min_CLP": -5.07, "draft_iters": 9.3, "mem_use": 44.67, "gen_rate": 4.6, "speed": 2.72, "text": "What? Why would I do that? I am "}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.2, "tree_w": 11, "tree_size": 64, "t0": 2.11, "t1": 0.334, "tft": 4.0439, "input_0": 192, "input_1": 65, "min_CLP": -4.29, "draft_iters": 14.2, "mem_use": 46.26, "gen_rate": 7.8, "speed": 3.19, "text": "\"No, this is not true. Hershey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 1.5067, "t1": 0.325, "tft": 3.0606, "input_0": 159, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.0, "mem_use": 44.61, "gen_rate": 5.5, "speed": 3.0, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 12, "tree_size": 64, "t0": 2.2475, "t1": 0.335, "tft": 3.2347, "input_0": 186, "input_1": 65, "min_CLP": -4.51, "draft_iters": 15.8, "mem_use": 45.96, "gen_rate": 8.2, "speed": 3.2, "text": "\"Certainly, I'd be happy to help"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 4.1, "t1": 0.32, "tft": 2.4336, "input_0": 199, "input_1": 65, "min_CLP": -6.18, "draft_iters": 32.0, "mem_use": 44.41, "gen_rate": 33.0, "speed": 7.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 4.27, "t1": 0.32, "tft": 2.7086, "input_0": 218, "input_1": 65, "min_CLP": -6.27, "draft_iters": 32.0, "mem_use": 44.42, "gen_rate": 33.0, "speed": 7.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.3, "tree_w": 9, "tree_size": 64, "t0": 2.1267, "t1": 0.33, "tft": 2.8066, "input_0": 200, "input_1": 65, "min_CLP": -4.64, "draft_iters": 14.3, "mem_use": 45.06, "gen_rate": 12.3, "speed": 5.03, "text": "\"Sure thing! Here's one way to w"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 1.4338, "t1": 0.3288, "tft": 2.8658, "input_0": 137, "input_1": 65, "min_CLP": -5.02, "draft_iters": 9.8, "mem_use": 45.29, "gen_rate": 4.4, "speed": 2.48, "text": "Certainly! Here are revised Haik"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 1.956, "t1": 0.322, "tft": 2.2899, "input_0": 200, "input_1": 65, "min_CLP": -4.54, "draft_iters": 13.0, "mem_use": 44.39, "gen_rate": 8.4, "speed": 3.69, "text": "The AK-47, also known as the Avt"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 14, "tree_size": 64, "t0": 1.558, "t1": 0.322, "tft": 2.3676, "input_0": 151, "input_1": 65, "min_CLP": -4.79, "draft_iters": 10.6, "mem_use": 44.74, "gen_rate": 6.4, "speed": 3.4, "text": "Copy a directory of files from s"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.3, "tree_w": 7, "tree_size": 64, "t0": 2.8933, "t1": 0.3367, "tft": 3.6363, "input_0": 208, "input_1": 65, "min_CLP": -4.01, "draft_iters": 20.3, "mem_use": 46.14, "gen_rate": 11.0, "speed": 3.4, "text": "Sure, here you go:\\n\\n* Statisti"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 4.55, "t1": 0.34, "tft": 2.5226, "input_0": 276, "input_1": 65, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 44.72, "gen_rate": 33.0, "speed": 6.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 11, "tree_size": 64, "t0": 1.795, "t1": 0.33, "tft": 3.0654, "input_0": 168, "input_1": 65, "min_CLP": -4.54, "draft_iters": 11.5, "mem_use": 45.23, "gen_rate": 8.5, "speed": 4.0, "text": "\"While it's not necessarily harm"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 18, "tree_size": 64, "t0": 1.1957, "t1": 0.3257, "tft": 2.2594, "input_0": 139, "input_1": 65, "min_CLP": -5.02, "draft_iters": 7.7, "mem_use": 44.87, "gen_rate": 4.6, "speed": 3.01, "text": "I suggest you say something like"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 18, "tree_size": 64, "t0": 1.3257, "t1": 0.3257, "tft": 5.2917, "input_0": 138, "input_1": 65, "min_CLP": -4.96, "draft_iters": 8.7, "mem_use": 44.98, "gen_rate": 4.7, "speed": 2.85, "text": "What is the next utterance of th"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.8, "tree_w": 12, "tree_size": 64, "t0": 1.9225, "t1": 0.325, "tft": 1.8334, "input_0": 180, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.8, "mem_use": 44.38, "gen_rate": 8.8, "speed": 3.89, "text": "\"I'm not thinking of anything in"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.4, "tree_w": 11, "tree_size": 64, "t0": 1.914, "t1": 0.324, "tft": 4.1211, "input_0": 200, "input_1": 65, "min_CLP": -4.5, "draft_iters": 12.4, "mem_use": 44.39, "gen_rate": 8.2, "speed": 3.67, "text": "Cryptocurrencies have the potent"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.0, "tree_w": 8, "tree_size": 64, "t0": 3.08, "t1": 0.33, "tft": 3.5063, "input_0": 264, "input_1": 65, "min_CLP": -4.73, "draft_iters": 20.7, "mem_use": 44.92, "gen_rate": 11.3, "speed": 3.33, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 19.8, "tree_w": 9, "tree_size": 64, "t0": 2.9575, "t1": 0.3225, "tft": 2.994, "input_0": 262, "input_1": 65, "min_CLP": -4.39, "draft_iters": 20.5, "mem_use": 44.69, "gen_rate": 11.5, "speed": 3.51, "text": "Here is an example HTML code tha"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 4.31, "t1": 0.32, "tft": 2.4206, "input_0": 281, "input_1": 65, "min_CLP": -7.54, "draft_iters": 32.0, "mem_use": 44.48, "gen_rate": 33.0, "speed": 7.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.0, "tree_w": 10, "tree_size": 64, "t0": 1.9325, "t1": 0.32, "tft": 3.9845, "input_0": 203, "input_1": 65, "min_CLP": -4.43, "draft_iters": 13.0, "mem_use": 44.44, "gen_rate": 9.5, "speed": 4.21, "text": "\"The reason you can't see the st"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.1, "tree_w": 22, "tree_size": 64, "t0": 1.07, "t1": 0.3325, "tft": 2.3713, "input_0": 105, "input_1": 65, "min_CLP": -5.16, "draft_iters": 7.1, "mem_use": 45.0, "gen_rate": 4.0, "speed": 2.85, "text": "\"The image was chosen as the def"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 18, "tree_size": 64, "t0": 1.31, "t1": 0.3387, "tft": 5.2328, "input_0": 142, "input_1": 65, "min_CLP": -4.75, "draft_iters": 8.4, "mem_use": 48.06, "gen_rate": 4.4, "speed": 2.66, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 8.2, "tree_w": 17, "tree_size": 64, "t0": 1.41, "t1": 0.335, "tft": 3.6258, "input_0": 158, "input_1": 65, "min_CLP": -4.8, "draft_iters": 9.2, "mem_use": 46.8, "gen_rate": 6.8, "speed": 3.91, "text": "\"It's possible that we may not h"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.8, "tree_w": 16, "tree_size": 64, "t0": 1.1967, "t1": 0.3267, "tft": 3.031, "input_0": 136, "input_1": 65, "min_CLP": -4.77, "draft_iters": 7.8, "mem_use": 45.06, "gen_rate": 5.7, "speed": 3.72, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 64, "t0": 4.3, "t1": 0.33, "tft": 2.975, "input_0": 221, "input_1": 65, "min_CLP": -5.3, "draft_iters": 32.0, "mem_use": 44.39, "gen_rate": 33.0, "speed": 7.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 30, "tree_h": 9.2, "tree_w": 14, "tree_size": 64, "t0": 1.6075, "t1": 0.3225, "tft": 1.7858, "input_0": 176, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.2, "mem_use": 44.38, "gen_rate": 7.5, "speed": 3.88, "text": "Yes, I am familiar with the Germ"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 26.0, "tree_w": 5, "tree_size": 64, "t0": 3.81, "t1": 0.32, "tft": 2.0803, "input_0": 194, "input_1": 65, "min_CLP": -5.03, "draft_iters": 27.0, "mem_use": 44.58, "gen_rate": 23.0, "speed": 5.56, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 15, "tree_size": 64, "t0": 1.3586, "t1": 0.3386, "tft": 3.1314, "input_0": 152, "input_1": 65, "min_CLP": -4.87, "draft_iters": 8.6, "mem_use": 45.47, "gen_rate": 5.1, "speed": 3.03, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 12, "tree_size": 64, "t0": 1.525, "t1": 0.3317, "tft": 4.4501, "input_0": 168, "input_1": 65, "min_CLP": -4.77, "draft_iters": 9.8, "mem_use": 46.06, "gen_rate": 5.7, "speed": 3.05, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.0, "tree_w": 24, "tree_size": 64, "t0": 1.184, "t1": 0.32, "tft": 2.2098, "input_0": 116, "input_1": 65, "min_CLP": -5.14, "draft_iters": 8.0, "mem_use": 44.44, "gen_rate": 6.4, "speed": 4.25, "text": "Sure! Here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.5, "tree_w": 14, "tree_size": 64, "t0": 2.305, "t1": 0.33, "tft": 3.1655, "input_0": 139, "input_1": 65, "min_CLP": -4.81, "draft_iters": 17.5, "mem_use": 44.81, "gen_rate": 17.0, "speed": 6.44, "text": "o\\n     /|\\\\\\n     / \\\\\\n     / "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 10, "tree_size": 64, "t0": 3.35, "t1": 0.33, "tft": 2.5495, "input_0": 242, "input_1": 65, "min_CLP": -6.5, "draft_iters": 23.5, "mem_use": 44.39, "gen_rate": 24.0, "speed": 6.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 1.5867, "t1": 0.325, "tft": 2.6126, "input_0": 169, "input_1": 65, "min_CLP": -4.69, "draft_iters": 10.2, "mem_use": 44.75, "gen_rate": 5.3, "speed": 2.79, "text": "The Trolley Problem is a thought"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.5, "tree_w": 19, "tree_size": 64, "t0": 1.3538, "t1": 0.3337, "tft": 2.8295, "input_0": 151, "input_1": 65, "min_CLP": -5.03, "draft_iters": 8.5, "mem_use": 44.67, "gen_rate": 4.0, "speed": 2.37, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 1.496, "t1": 0.328, "tft": 3.7953, "input_0": 167, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.8, "mem_use": 46.72, "gen_rate": 7.6, "speed": 4.16, "text": "\"Alright, let's get started. Fir"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 4.0, "t1": 0.32, "tft": 2.864, "input_0": 121, "input_1": 65, "min_CLP": -5.16, "draft_iters": 32.0, "mem_use": 44.56, "gen_rate": 33.0, "speed": 7.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 13, "tree_size": 64, "t0": 1.5917, "t1": 0.3317, "tft": 4.7341, "input_0": 154, "input_1": 65, "min_CLP": -4.62, "draft_iters": 10.7, "mem_use": 47.43, "gen_rate": 5.7, "speed": 2.95, "text": "Once upon a time, in a world fil"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 12.6, "tree_w": 11, "tree_size": 64, "t0": 2.102, "t1": 0.33, "tft": 2.3208, "input_0": 208, "input_1": 65, "min_CLP": -4.58, "draft_iters": 13.6, "mem_use": 44.43, "gen_rate": 9.0, "speed": 3.7, "text": "\"Certainly! Here's an ASCII art "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 18.0, "tree_w": 6, "tree_size": 64, "t0": 2.71, "t1": 0.33, "tft": 2.823, "input_0": 238, "input_1": 65, "min_CLP": -3.82, "draft_iters": 19.0, "mem_use": 44.39, "gen_rate": 18.0, "speed": 5.93, "text": "The main difference between HTML"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.0, "tree_w": 7, "tree_size": 64, "t0": 2.7475, "t1": 0.325, "tft": 2.0605, "input_0": 227, "input_1": 65, "min_CLP": -4.45, "draft_iters": 19.0, "mem_use": 44.41, "gen_rate": 8.0, "speed": 2.6, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.1, "tree_w": 17, "tree_size": 64, "t0": 1.2544, "t1": 0.3267, "tft": 2.0859, "input_0": 137, "input_1": 65, "min_CLP": -5.12, "draft_iters": 8.1, "mem_use": 44.78, "gen_rate": 3.6, "speed": 2.25, "text": "\"No, you can't. Charles O'Rear o"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 15.2, "tree_w": 16, "tree_size": 64, "t0": 2.1967, "t1": 0.3217, "tft": 2.354, "input_0": 151, "input_1": 65, "min_CLP": -5.01, "draft_iters": 16.2, "mem_use": 44.4, "gen_rate": 5.3, "speed": 2.12, "text": " [A]. The second batch has more "}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.4, "tree_w": 11, "tree_size": 64, "t0": 2.02, "t1": 0.328, "tft": 3.6095, "input_0": 201, "input_1": 65, "min_CLP": -4.3, "draft_iters": 13.4, "mem_use": 45.46, "gen_rate": 6.8, "speed": 2.9, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 17, "tree_size": 64, "t0": 1.3057, "t1": 0.33, "tft": 2.2478, "input_0": 154, "input_1": 65, "min_CLP": -4.76, "draft_iters": 8.3, "mem_use": 45.17, "gen_rate": 5.0, "speed": 3.06, "text": "\"If you're looking for a governm"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 20, "tree_size": 64, "t0": 1.3417, "t1": 0.3367, "tft": 2.153, "input_0": 122, "input_1": 65, "min_CLP": -5.05, "draft_iters": 9.0, "mem_use": 45.01, "gen_rate": 5.7, "speed": 3.38, "text": "\"Yes, I agree with you. \\n\\nIf e"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 21, "tree_size": 64, "t0": 1.205, "t1": 0.3383, "tft": 3.3555, "input_0": 132, "input_1": 65, "min_CLP": -4.88, "draft_iters": 7.8, "mem_use": 45.73, "gen_rate": 5.3, "speed": 3.45, "text": "\"Thank you for providing that in"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 27, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 1.565, "t1": 0.325, "tft": 1.6259, "input_0": 160, "input_1": 65, "min_CLP": -4.89, "draft_iters": 10.2, "mem_use": 44.37, "gen_rate": 6.8, "speed": 3.57, "text": "Here is an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 7.4, "tree_w": 17, "tree_size": 64, "t0": 1.285, "t1": 0.325, "tft": 2.065, "input_0": 144, "input_1": 65, "min_CLP": -4.77, "draft_iters": 8.4, "mem_use": 44.69, "gen_rate": 5.0, "speed": 3.1, "text": "Sure, I\\'d be happy to! My name "}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 1.4629, "t1": 0.33, "tft": 4.0468, "input_0": 163, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.6, "mem_use": 45.44, "gen_rate": 4.6, "speed": 2.55, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 1.4783, "t1": 0.3233, "tft": 1.8977, "input_0": 151, "input_1": 65, "min_CLP": -4.76, "draft_iters": 10.2, "mem_use": 44.49, "gen_rate": 5.3, "speed": 2.96, "text": "Motion matching is a technique u"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 24.3, "tree_w": 5, "tree_size": 64, "t0": 3.4433, "t1": 0.3333, "tft": 4.1449, "input_0": 225, "input_1": 65, "min_CLP": -3.93, "draft_iters": 25.0, "mem_use": 46.12, "gen_rate": 16.0, "speed": 4.23, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 12, "tree_size": 64, "t0": 4.21, "t1": 0.33, "tft": 2.9837, "input_0": 232, "input_1": 65, "min_CLP": -7.19, "draft_iters": 31.5, "mem_use": 44.44, "gen_rate": 32.0, "speed": 7.05, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 28, "tree_h": 8.7, "tree_w": 18, "tree_size": 64, "t0": 1.4129, "t1": 0.3257, "tft": 2.9296, "input_0": 135, "input_1": 65, "min_CLP": -4.83, "draft_iters": 9.7, "mem_use": 44.82, "gen_rate": 4.0, "speed": 2.3, "text": "Sure, here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 16, "tree_size": 64, "t0": 1.526, "t1": 0.33, "tft": 4.7217, "input_0": 179, "input_1": 65, "min_CLP": -4.48, "draft_iters": 10.0, "mem_use": 46.13, "gen_rate": 6.6, "speed": 3.55, "text": "\"No, 100 monkeys on a typewriter"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.8, "tree_w": 13, "tree_size": 64, "t0": 1.9, "t1": 0.336, "tft": 3.7363, "input_0": 192, "input_1": 65, "min_CLP": -4.54, "draft_iters": 12.8, "mem_use": 46.57, "gen_rate": 7.8, "speed": 3.49, "text": "Paul Allen has a large collectio"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 1.4943, "t1": 0.3343, "tft": 3.6087, "input_0": 167, "input_1": 65, "min_CLP": -5.01, "draft_iters": 9.6, "mem_use": 46.0, "gen_rate": 5.6, "speed": 3.04, "text": "Certainly! One example of a simi"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 13, "tree_size": 64, "t0": 1.868, "t1": 0.328, "tft": 1.8763, "input_0": 177, "input_1": 65, "min_CLP": -4.71, "draft_iters": 12.4, "mem_use": 44.47, "gen_rate": 6.8, "speed": 3.1, "text": "[Answer] In William Shakespeare\\"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 1.466, "t1": 0.334, "tft": 2.622, "input_0": 157, "input_1": 65, "min_CLP": -4.78, "draft_iters": 9.8, "mem_use": 45.1, "gen_rate": 7.2, "speed": 4.0, "text": "As an artificial intelligence, I"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 14, "tree_size": 64, "t0": 1.5017, "t1": 0.3283, "tft": 4.2508, "input_0": 159, "input_1": 65, "min_CLP": -4.65, "draft_iters": 9.7, "mem_use": 44.5, "gen_rate": 6.0, "speed": 3.27, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.95, "t1": 0.33, "tft": 2.2556, "input_0": 205, "input_1": 65, "min_CLP": -4.52, "draft_iters": 12.4, "mem_use": 44.39, "gen_rate": 6.6, "speed": 2.89, "text": "The 5-second rule is a popular m"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 9.5, "tree_w": 14, "tree_size": 64, "t0": 1.735, "t1": 0.33, "tft": 3.2186, "input_0": 197, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.5, "mem_use": 45.22, "gen_rate": 6.5, "speed": 3.15, "text": "\"You are welcome. I'm glad I cou"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.5, "tree_w": 12, "tree_size": 64, "t0": 1.93, "t1": 0.3383, "tft": 3.9459, "input_0": 195, "input_1": 65, "min_CLP": -4.63, "draft_iters": 12.5, "mem_use": 46.03, "gen_rate": 6.8, "speed": 3.01, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 1.986, "t1": 0.338, "tft": 4.8271, "input_0": 204, "input_1": 65, "min_CLP": -4.51, "draft_iters": 12.6, "mem_use": 46.94, "gen_rate": 7.2, "speed": 3.09, "text": "Oh, you\\'re referring to the \"mu"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 11, "tree_size": 64, "t0": 1.8625, "t1": 0.335, "tft": 3.6871, "input_0": 178, "input_1": 65, "min_CLP": -4.55, "draft_iters": 12.5, "mem_use": 45.53, "gen_rate": 8.5, "speed": 3.86, "text": "\"A completely purple sky is poss"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 4.08, "t1": 0.34, "tft": 2.8199, "input_0": 166, "input_1": 65, "min_CLP": -4.69, "draft_iters": 32.0, "mem_use": 45.37, "gen_rate": 33.0, "speed": 7.48, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.8, "tree_w": 10, "tree_size": 64, "t0": 2.455, "t1": 0.3325, "tft": 3.7211, "input_0": 219, "input_1": 65, "min_CLP": -4.46, "draft_iters": 16.8, "mem_use": 45.14, "gen_rate": 8.5, "speed": 3.05, "text": "Here are the translations for \"l"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 12, "tree_size": 64, "t0": 1.9725, "t1": 0.3225, "tft": 2.4994, "input_0": 182, "input_1": 65, "min_CLP": -4.61, "draft_iters": 13.0, "mem_use": 44.68, "gen_rate": 8.0, "speed": 3.49, "text": "In Europe, some of the best univ"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 14, "tree_size": 64, "t0": 1.945, "t1": 0.3275, "tft": 3.4731, "input_0": 234, "input_1": 65, "min_CLP": -4.44, "draft_iters": 11.8, "mem_use": 44.37, "gen_rate": 8.0, "speed": 3.52, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.7, "tree_w": 8, "tree_size": 64, "t0": 2.42, "t1": 0.3267, "tft": 2.1898, "input_0": 249, "input_1": 65, "min_CLP": -4.19, "draft_iters": 15.7, "mem_use": 44.5, "gen_rate": 12.3, "speed": 4.49, "text": "```cpp\\n#include <iostream>\\n#in"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 16, "tree_size": 64, "t0": 1.4183, "t1": 0.3417, "tft": 3.4155, "input_0": 162, "input_1": 65, "min_CLP": -4.88, "draft_iters": 8.5, "mem_use": 45.63, "gen_rate": 5.8, "speed": 3.31, "text": "\"1. Financial stress: \\n\\na. Bud"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.9, "tree_w": 13, "tree_size": 64, "t0": 1.5514, "t1": 0.3257, "tft": 3.7688, "input_0": 162, "input_1": 65, "min_CLP": -4.72, "draft_iters": 9.9, "mem_use": 44.37, "gen_rate": 5.3, "speed": 2.81, "text": "I am an AI language model, and m"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 10, "tree_size": 64, "t0": 2.2125, "t1": 0.3375, "tft": 5.4855, "input_0": 234, "input_1": 65, "min_CLP": -4.41, "draft_iters": 13.5, "mem_use": 47.04, "gen_rate": 8.2, "speed": 3.23, "text": "\"One example of where you might "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 12, "tree_size": 64, "t0": 2.1133, "t1": 0.3267, "tft": 3.2684, "input_0": 230, "input_1": 65, "min_CLP": -4.58, "draft_iters": 13.3, "mem_use": 44.66, "gen_rate": 11.0, "speed": 4.51, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 6.1, "tree_w": 24, "tree_size": 64, "t0": 1.0686, "t1": 0.3286, "tft": 2.4524, "input_0": 115, "input_1": 65, "min_CLP": -5.59, "draft_iters": 7.1, "mem_use": 44.45, "gen_rate": 4.1, "speed": 2.97, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.7083, "t1": 0.335, "tft": 4.7914, "input_0": 179, "input_1": 65, "min_CLP": -4.65, "draft_iters": 11.0, "mem_use": 46.63, "gen_rate": 5.8, "speed": 2.85, "text": "Sure, here are some additional o"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 23.5, "tree_w": 8, "tree_size": 64, "t0": 3.45, "t1": 0.33, "tft": 3.8481, "input_0": 235, "input_1": 65, "min_CLP": -5.72, "draft_iters": 24.0, "mem_use": 44.44, "gen_rate": 20.0, "speed": 5.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.7, "tree_w": 17, "tree_size": 64, "t0": 1.3517, "t1": 0.3333, "tft": 3.9262, "input_0": 150, "input_1": 65, "min_CLP": -4.78, "draft_iters": 8.7, "mem_use": 45.14, "gen_rate": 6.2, "speed": 3.66, "text": "The Unus Annus Trolley Problem i"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 20.4, "tree_w": 8, "tree_size": 64, "t0": 2.986, "t1": 0.336, "tft": 5.1346, "input_0": 190, "input_1": 65, "min_CLP": -4.54, "draft_iters": 21.4, "mem_use": 46.01, "gen_rate": 8.2, "speed": 2.47, "text": "1. m\u00eb (pronounced \"meh\")\\n2. mel"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 1.482, "t1": 0.328, "tft": 2.076, "input_0": 178, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.0, "mem_use": 44.69, "gen_rate": 6.6, "speed": 3.64, "text": "Once upon a time, in a world tha"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 10.2, "tree_w": 15, "tree_size": 64, "t0": 1.714, "t1": 0.338, "tft": 4.3764, "input_0": 178, "input_1": 65, "min_CLP": -4.72, "draft_iters": 11.2, "mem_use": 47.46, "gen_rate": 9.4, "speed": 4.58, "text": "I apologize for any confusion or"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.2, "tree_w": 11, "tree_size": 64, "t0": 1.8025, "t1": 0.32, "tft": 2.7366, "input_0": 167, "input_1": 65, "min_CLP": -4.66, "draft_iters": 12.2, "mem_use": 44.4, "gen_rate": 8.8, "speed": 4.12, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 21.7, "tree_w": 5, "tree_size": 64, "t0": 3.3567, "t1": 0.3367, "tft": 4.3452, "input_0": 286, "input_1": 65, "min_CLP": -3.64, "draft_iters": 22.7, "mem_use": 46.41, "gen_rate": 15.0, "speed": 4.06, "text": "\"Here's an example code for sett"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 14, "tree_size": 64, "t0": 2.595, "t1": 0.33, "tft": 2.9259, "input_0": 165, "input_1": 65, "min_CLP": -6.24, "draft_iters": 19.5, "mem_use": 44.39, "gen_rate": 20.0, "speed": 6.83, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.2, "tree_w": 18, "tree_size": 64, "t0": 1.2517, "t1": 0.3333, "tft": 2.0985, "input_0": 132, "input_1": 65, "min_CLP": -4.96, "draft_iters": 8.2, "mem_use": 44.84, "gen_rate": 6.2, "speed": 3.9, "text": "\"It's unlikely that AI assistant"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 20, "tree_size": 64, "t0": 1.3343, "t1": 0.3571, "tft": 6.2907, "input_0": 131, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.7, "mem_use": 50.01, "gen_rate": 4.7, "speed": 2.79, "text": "Absolutely!\\n\\n[Verse 1]\\nGarden"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 21, "tree_size": 64, "t0": 1.3386, "t1": 0.3343, "tft": 2.9718, "input_0": 125, "input_1": 65, "min_CLP": -4.99, "draft_iters": 9.1, "mem_use": 45.21, "gen_rate": 4.7, "speed": 2.82, "text": "0 Independent counsel is a perso"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.4, "tree_w": 15, "tree_size": 64, "t0": 1.474, "t1": 0.336, "tft": 4.5017, "input_0": 159, "input_1": 65, "min_CLP": -4.62, "draft_iters": 9.4, "mem_use": 47.07, "gen_rate": 6.6, "speed": 3.65, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 20, "tree_size": 64, "t0": 1.2583, "t1": 0.335, "tft": 2.6376, "input_0": 145, "input_1": 65, "min_CLP": -4.86, "draft_iters": 8.2, "mem_use": 45.44, "gen_rate": 5.7, "speed": 3.55, "text": "1. Economic downturn: If the eco"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 15.7, "tree_w": 13, "tree_size": 64, "t0": 2.2733, "t1": 0.3233, "tft": 4.11, "input_0": 163, "input_1": 65, "min_CLP": -5.45, "draft_iters": 16.3, "mem_use": 44.72, "gen_rate": 13.3, "speed": 5.13, "text": "[SYS] You are a helpful, respect"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 9, "tree_size": 64, "t0": 2.47, "t1": 0.33, "tft": 6.442, "input_0": 222, "input_1": 65, "min_CLP": -4.27, "draft_iters": 16.3, "mem_use": 47.2, "gen_rate": 10.7, "speed": 3.81, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 13, "tree_size": 64, "t0": 1.608, "t1": 0.328, "tft": 3.0726, "input_0": 167, "input_1": 65, "min_CLP": -4.46, "draft_iters": 10.6, "mem_use": 44.9, "gen_rate": 7.0, "speed": 3.61, "text": "To determine the most cost-effec"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 12, "tree_size": 64, "t0": 1.914, "t1": 0.332, "tft": 5.7774, "input_0": 195, "input_1": 65, "min_CLP": -4.35, "draft_iters": 12.6, "mem_use": 46.86, "gen_rate": 7.2, "speed": 3.21, "text": "Creating a reinforcement learnin"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 11, "tree_size": 64, "t0": 1.8425, "t1": 0.3225, "tft": 2.607, "input_0": 190, "input_1": 65, "min_CLP": -4.45, "draft_iters": 11.8, "mem_use": 44.42, "gen_rate": 8.0, "speed": 3.69, "text": "\"Sure! Here's an implementation "}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 1.3137, "t1": 0.3325, "tft": 2.8551, "input_0": 131, "input_1": 65, "min_CLP": -5.03, "draft_iters": 8.8, "mem_use": 45.15, "gen_rate": 4.4, "speed": 2.66, "text": "\"The law regarding public nudity"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.1, "tree_w": 18, "tree_size": 64, "t0": 1.5025, "t1": 0.33, "tft": 2.6531, "input_0": 147, "input_1": 65, "min_CLP": -4.75, "draft_iters": 10.1, "mem_use": 44.87, "gen_rate": 4.5, "speed": 2.45, "text": "## Assistant:\\nTo alleviate your"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 64, "t0": 4.16, "t1": 0.33, "tft": 2.6458, "input_0": 198, "input_1": 65, "min_CLP": -5.0, "draft_iters": 32.0, "mem_use": 44.46, "gen_rate": 33.0, "speed": 7.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.3, "tree_w": 17, "tree_size": 64, "t0": 1.5483, "t1": 0.3317, "tft": 3.0264, "input_0": 152, "input_1": 65, "min_CLP": -4.78, "draft_iters": 10.3, "mem_use": 45.35, "gen_rate": 6.5, "speed": 3.45, "text": "Overcoming the fear of looking d"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 24.5, "tree_w": 5, "tree_size": 64, "t0": 3.6, "t1": 0.335, "tft": 5.2285, "input_0": 268, "input_1": 65, "min_CLP": -4.65, "draft_iters": 25.5, "mem_use": 46.95, "gen_rate": 22.5, "speed": 5.72, "text": "Sure, here is a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 18.0, "tree_w": 8, "tree_size": 64, "t0": 2.736, "t1": 0.324, "tft": 2.555, "input_0": 223, "input_1": 65, "min_CLP": -4.17, "draft_iters": 19.0, "mem_use": 44.58, "gen_rate": 8.0, "speed": 2.61, "text": "The total travel time would be t"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.0, "tree_w": 5, "tree_size": 64, "t0": 3.2, "t1": 0.32, "tft": 2.5326, "input_0": 274, "input_1": 65, "min_CLP": -3.96, "draft_iters": 22.0, "mem_use": 44.49, "gen_rate": 11.3, "speed": 3.22, "text": "```python\\nimport discord\\nfrom "}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.7575, "t1": 0.3225, "tft": 2.3935, "input_0": 163, "input_1": 65, "min_CLP": -4.49, "draft_iters": 12.0, "mem_use": 44.39, "gen_rate": 8.2, "speed": 3.97, "text": "Yes, I am designed to be as capa"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.65, "t1": 0.3425, "tft": 5.5388, "input_0": 146, "input_1": 65, "min_CLP": -4.38, "draft_iters": 11.0, "mem_use": 48.17, "gen_rate": 8.8, "speed": 4.39, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 12.5, "tree_w": 13, "tree_size": 64, "t0": 1.92, "t1": 0.33, "tft": 4.4938, "input_0": 146, "input_1": 65, "min_CLP": -4.68, "draft_iters": 13.5, "mem_use": 44.5, "gen_rate": 2.0, "speed": 0.89, "text": "The answer is \"Mike\"."}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 18, "tree_size": 64, "t0": 1.3471, "t1": 0.3329, "tft": 2.7024, "input_0": 125, "input_1": 65, "min_CLP": -5.01, "draft_iters": 9.0, "mem_use": 45.54, "gen_rate": 4.9, "speed": 2.89, "text": "An account with experience point"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.3, "tree_w": 13, "tree_size": 64, "t0": 1.6114, "t1": 0.3371, "tft": 4.3408, "input_0": 174, "input_1": 65, "min_CLP": -4.51, "draft_iters": 10.3, "mem_use": 47.31, "gen_rate": 4.7, "speed": 2.42, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 1.48, "t1": 0.325, "tft": 2.1672, "input_0": 151, "input_1": 65, "min_CLP": -4.79, "draft_iters": 9.8, "mem_use": 44.63, "gen_rate": 5.5, "speed": 3.04, "text": "\"As an AI language model, I'm he"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.775, "t1": 0.33, "tft": 2.9977, "input_0": 170, "input_1": 65, "min_CLP": -5.29, "draft_iters": 11.8, "mem_use": 45.14, "gen_rate": 9.2, "speed": 4.39, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.3, "tree_w": 10, "tree_size": 64, "t0": 2.3233, "t1": 0.3333, "tft": 4.9786, "input_0": 243, "input_1": 65, "min_CLP": -4.28, "draft_iters": 15.3, "mem_use": 46.88, "gen_rate": 10.7, "speed": 4.02, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.7, "tree_w": 11, "tree_size": 64, "t0": 1.885, "t1": 0.33, "tft": 3.7872, "input_0": 175, "input_1": 65, "min_CLP": -4.43, "draft_iters": 12.7, "mem_use": 45.27, "gen_rate": 5.8, "speed": 2.64, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 10, "tree_size": 64, "t0": 2.1867, "t1": 0.34, "tft": 4.6177, "input_0": 227, "input_1": 65, "min_CLP": -4.48, "draft_iters": 14.0, "mem_use": 47.6, "gen_rate": 10.7, "speed": 4.22, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 14, "tree_size": 64, "t0": 1.5433, "t1": 0.335, "tft": 3.7987, "input_0": 186, "input_1": 65, "min_CLP": -4.64, "draft_iters": 9.7, "mem_use": 45.93, "gen_rate": 6.0, "speed": 3.2, "text": "The multiple days in which Chris"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 19, "tree_size": 64, "t0": 1.3383, "t1": 0.3267, "tft": 2.2857, "input_0": 128, "input_1": 65, "min_CLP": -4.94, "draft_iters": 9.0, "mem_use": 44.96, "gen_rate": 5.3, "speed": 3.2, "text": "\"I understand you are looking fo"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.865, "t1": 0.3275, "tft": 5.0231, "input_0": 210, "input_1": 65, "min_CLP": -4.54, "draft_iters": 11.8, "mem_use": 46.75, "gen_rate": 8.2, "speed": 3.76, "text": "One of the most difficult parts "}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.4, "tree_w": 12, "tree_size": 64, "t0": 1.94, "t1": 0.32, "tft": 2.2805, "input_0": 168, "input_1": 65, "min_CLP": -4.54, "draft_iters": 13.4, "mem_use": 44.58, "gen_rate": 6.4, "speed": 2.83, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.9, "tree_w": 16, "tree_size": 64, "t0": 1.5271, "t1": 0.3314, "tft": 3.1654, "input_0": 140, "input_1": 65, "min_CLP": -4.95, "draft_iters": 10.9, "mem_use": 45.2, "gen_rate": 4.9, "speed": 2.62, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 17, "tree_size": 64, "t0": 1.3357, "t1": 0.3257, "tft": 2.8846, "input_0": 137, "input_1": 65, "min_CLP": -5.55, "draft_iters": 8.9, "mem_use": 44.67, "gen_rate": 4.7, "speed": 2.84, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.7, "tree_w": 6, "tree_size": 64, "t0": 2.7833, "t1": 0.33, "tft": 2.4836, "input_0": 270, "input_1": 65, "min_CLP": -3.96, "draft_iters": 18.7, "mem_use": 44.69, "gen_rate": 13.0, "speed": 4.18, "text": "The distance between Sagittarius"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.0, "tree_w": 17, "tree_size": 64, "t0": 1.526, "t1": 0.33, "tft": 2.7647, "input_0": 163, "input_1": 65, "min_CLP": -4.91, "draft_iters": 10.0, "mem_use": 45.07, "gen_rate": 7.8, "speed": 4.2, "text": "Yes, Google Authenticator is a t"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.0, "tree_w": 10, "tree_size": 64, "t0": 2.165, "t1": 0.3325, "tft": 3.7508, "input_0": 208, "input_1": 65, "min_CLP": -4.56, "draft_iters": 14.0, "mem_use": 44.86, "gen_rate": 10.0, "speed": 4.01, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.886, "t1": 0.326, "tft": 2.7243, "input_0": 194, "input_1": 65, "min_CLP": -4.35, "draft_iters": 12.2, "mem_use": 44.62, "gen_rate": 9.0, "speed": 4.07, "text": "Here is the code that accomplish"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.7725, "t1": 0.3225, "tft": 2.7231, "input_0": 180, "input_1": 65, "min_CLP": -4.64, "draft_iters": 12.0, "mem_use": 44.47, "gen_rate": 10.8, "speed": 5.14, "text": "The answer is: To improve your W"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 10.2, "tree_w": 18, "tree_size": 64, "t0": 1.6025, "t1": 0.3238, "tft": 1.9487, "input_0": 130, "input_1": 65, "min_CLP": -4.93, "draft_iters": 11.2, "mem_use": 44.5, "gen_rate": 4.5, "speed": 2.33, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 15.5, "tree_w": 22, "tree_size": 64, "t0": 2.265, "t1": 0.32, "tft": 1.666, "input_0": 151, "input_1": 65, "min_CLP": -5.26, "draft_iters": 16.5, "mem_use": 44.42, "gen_rate": 8.0, "speed": 3.1, "text": "[INST] Write a whitepaper for ou"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.8075, "t1": 0.3325, "tft": 3.229, "input_0": 167, "input_1": 65, "min_CLP": -4.38, "draft_iters": 12.2, "mem_use": 45.6, "gen_rate": 10.2, "speed": 4.79, "text": "In that case, you can use the fo"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.0, "tree_w": 8, "tree_size": 64, "t0": 2.1925, "t1": 0.3225, "tft": 2.5287, "input_0": 217, "input_1": 65, "min_CLP": -4.39, "draft_iters": 14.0, "mem_use": 44.37, "gen_rate": 10.0, "speed": 3.98, "text": "In Python, the @ symbol is used "}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 1.395, "t1": 0.325, "tft": 2.4662, "input_0": 141, "input_1": 65, "min_CLP": -4.74, "draft_iters": 9.2, "mem_use": 44.39, "gen_rate": 6.2, "speed": 3.59, "text": "\"My thoughts on ChatGPT are quit"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 15, "tree_size": 64, "t0": 2.0225, "t1": 0.3275, "tft": 1.9622, "input_0": 181, "input_1": 65, "min_CLP": -4.96, "draft_iters": 14.0, "mem_use": 44.69, "gen_rate": 8.8, "speed": 3.72, "text": "\"The task of changing Adolf Hitl"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 13, "tree_size": 64, "t0": 1.826, "t1": 0.322, "tft": 2.671, "input_0": 207, "input_1": 65, "min_CLP": -4.51, "draft_iters": 11.6, "mem_use": 44.42, "gen_rate": 6.6, "speed": 3.07, "text": "Sure, I can help with that! Howe"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 64, "t0": 4.28, "t1": 0.33, "tft": 2.8732, "input_0": 197, "input_1": 65, "min_CLP": -5.38, "draft_iters": 32.0, "mem_use": 45.12, "gen_rate": 33.0, "speed": 7.17, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 8, "tree_size": 64, "t0": 3.515, "t1": 0.34, "tft": 5.2341, "input_0": 205, "input_1": 65, "min_CLP": -7.24, "draft_iters": 26.0, "mem_use": 47.63, "gen_rate": 26.5, "speed": 6.88, "text": "The current date is 2023-02-06.\\"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 11, "tree_size": 64, "t0": 1.9533, "t1": 0.3267, "tft": 3.8702, "input_0": 202, "input_1": 65, "min_CLP": -4.26, "draft_iters": 13.3, "mem_use": 44.93, "gen_rate": 11.0, "speed": 4.82, "text": "Decorators and wrapping function"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.8, "tree_w": 15, "tree_size": 64, "t0": 1.3325, "t1": 0.3313, "tft": 3.4697, "input_0": 139, "input_1": 65, "min_CLP": -4.69, "draft_iters": 8.8, "mem_use": 46.05, "gen_rate": 4.6, "speed": 2.77, "text": "Hello, dear Agent. How can I ass"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 26, "tree_size": 64, "t0": 1.1133, "t1": 0.3283, "tft": 3.5286, "input_0": 97, "input_1": 65, "min_CLP": -5.14, "draft_iters": 8.0, "mem_use": 44.92, "gen_rate": 6.0, "speed": 4.17, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 18.2, "tree_w": 8, "tree_size": 64, "t0": 2.716, "t1": 0.342, "tft": 5.3679, "input_0": 206, "input_1": 65, "min_CLP": -4.2, "draft_iters": 19.0, "mem_use": 47.82, "gen_rate": 10.0, "speed": 3.27, "text": "Sure! Here are some simple code "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.8883, "t1": 0.4033, "tft": 10.2501, "input_0": 203, "input_1": 65, "min_CLP": -4.49, "draft_iters": 12.0, "mem_use": 53.85, "gen_rate": 5.8, "speed": 2.55, "text": "Sure, I can provide you with an "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 9, "tree_size": 64, "t0": 2.9425, "t1": 0.3325, "tft": 3.7451, "input_0": 178, "input_1": 65, "min_CLP": -4.34, "draft_iters": 22.2, "mem_use": 46.16, "gen_rate": 8.2, "speed": 2.52, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 1.862, "t1": 0.322, "tft": 2.2358, "input_0": 164, "input_1": 65, "min_CLP": -4.28, "draft_iters": 12.6, "mem_use": 44.43, "gen_rate": 6.8, "speed": 3.11, "text": "Certainly! To help you with your"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 12, "tree_size": 64, "t0": 1.5925, "t1": 0.33, "tft": 2.1842, "input_0": 177, "input_1": 65, "min_CLP": -4.5, "draft_iters": 10.0, "mem_use": 44.55, "gen_rate": 8.0, "speed": 4.16, "text": "In TypeScript, you can use a typ"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.8, "tree_w": 13, "tree_size": 64, "t0": 1.8375, "t1": 0.3325, "tft": 4.5327, "input_0": 199, "input_1": 65, "min_CLP": -4.66, "draft_iters": 11.8, "mem_use": 47.33, "gen_rate": 9.5, "speed": 4.38, "text": "Certainly! Here are some tips to"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 14, "tree_size": 64, "t0": 1.726, "t1": 0.324, "tft": 2.473, "input_0": 177, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.6, "mem_use": 44.49, "gen_rate": 6.6, "speed": 3.22, "text": "The world in 1950 was quite diff"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.848, "t1": 0.348, "tft": 6.6188, "input_0": 194, "input_1": 65, "min_CLP": -4.35, "draft_iters": 11.8, "mem_use": 49.49, "gen_rate": 8.0, "speed": 3.64, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.4, "tree_w": 13, "tree_size": 64, "t0": 1.8, "t1": 0.328, "tft": 2.277, "input_0": 148, "input_1": 65, "min_CLP": -4.69, "draft_iters": 12.4, "mem_use": 44.83, "gen_rate": 7.6, "speed": 3.57, "text": "The order is as follows: 1. inst"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 15, "tree_size": 64, "t0": 1.588, "t1": 0.324, "tft": 2.8457, "input_0": 168, "input_1": 65, "min_CLP": -4.68, "draft_iters": 10.6, "mem_use": 44.68, "gen_rate": 6.6, "speed": 3.45, "text": "\"1. Carnegie Mellon University i"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 24, "tree_size": 64, "t0": 0.9814, "t1": 0.33, "tft": 2.0286, "input_0": 109, "input_1": 65, "min_CLP": -5.36, "draft_iters": 6.4, "mem_use": 44.74, "gen_rate": 4.9, "speed": 3.71, "text": "I have been trained by the peopl"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 9, "tree_size": 64, "t0": 2.26, "t1": 0.34, "tft": 4.6236, "input_0": 191, "input_1": 65, "min_CLP": -3.79, "draft_iters": 15.7, "mem_use": 46.1, "gen_rate": 11.3, "speed": 4.36, "text": "The two most important PC compon"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.5, "tree_w": 10, "tree_size": 64, "t0": 2.405, "t1": 0.33, "tft": 4.6067, "input_0": 197, "input_1": 65, "min_CLP": -4.3, "draft_iters": 16.5, "mem_use": 44.81, "gen_rate": 9.0, "speed": 3.29, "text": "Sure, I can help you with that!\\"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 4.66, "t1": 0.33, "tft": 3.5726, "input_0": 287, "input_1": 65, "min_CLP": -9.59, "draft_iters": 32.0, "mem_use": 44.98, "gen_rate": 33.0, "speed": 6.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 12, "tree_size": 64, "t0": 1.936, "t1": 0.326, "tft": 3.4088, "input_0": 205, "input_1": 65, "min_CLP": -4.59, "draft_iters": 12.8, "mem_use": 45.04, "gen_rate": 6.4, "speed": 2.83, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.9, "tree_w": 19, "tree_size": 64, "t0": 1.52, "t1": 0.3357, "tft": 4.2659, "input_0": 159, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.9, "mem_use": 46.96, "gen_rate": 4.7, "speed": 2.54, "text": "Sure, here are some beginner-fri"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 15.0, "tree_w": 9, "tree_size": 64, "t0": 2.13, "t1": 0.32, "tft": 2.9293, "input_0": 150, "input_1": 65, "min_CLP": -4.78, "draft_iters": 16.0, "mem_use": 44.39, "gen_rate": 9.0, "speed": 3.67, "text": "yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.0, "tree_w": 9, "tree_size": 64, "t0": 2.3067, "t1": 0.3233, "tft": 2.6784, "input_0": 258, "input_1": 65, "min_CLP": -4.53, "draft_iters": 15.0, "mem_use": 44.53, "gen_rate": 12.0, "speed": 4.56, "text": "To determine whether (A B)^T = A"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 21, "tree_size": 64, "t0": 1.2833, "t1": 0.335, "tft": 3.2118, "input_0": 151, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.0, "mem_use": 45.97, "gen_rate": 5.3, "speed": 3.29, "text": "\"Statistical modeling, it's what"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 4.32, "t1": 0.34, "tft": 7.141, "input_0": 208, "input_1": 65, "min_CLP": -4.54, "draft_iters": 32.0, "mem_use": 47.13, "gen_rate": 33.0, "speed": 7.07, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 16, "tree_size": 64, "t0": 1.46, "t1": 0.33, "tft": 1.9445, "input_0": 155, "input_1": 65, "min_CLP": -4.71, "draft_iters": 9.1, "mem_use": 44.37, "gen_rate": 4.7, "speed": 2.63, "text": "\"The current date is [current da"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 16, "tree_size": 64, "t0": 1.7425, "t1": 0.335, "tft": 4.0931, "input_0": 179, "input_1": 65, "min_CLP": -4.56, "draft_iters": 11.5, "mem_use": 45.85, "gen_rate": 8.8, "speed": 4.21, "text": "Yes, that\\'s a great point! Remo"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.4, "tree_w": 18, "tree_size": 64, "t0": 1.21, "t1": 0.325, "tft": 2.0389, "input_0": 118, "input_1": 65, "min_CLP": -5.01, "draft_iters": 8.4, "mem_use": 44.73, "gen_rate": 4.1, "speed": 2.68, "text": "\"That's just so wrong, dude! Tec"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 16.7, "tree_w": 6, "tree_size": 64, "t0": 2.55, "t1": 0.32, "tft": 2.3999, "input_0": 215, "input_1": 65, "min_CLP": -4.27, "draft_iters": 17.7, "mem_use": 44.42, "gen_rate": 12.0, "speed": 4.19, "text": "\"Sure! Variance is a measure of "}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 22.0, "tree_w": 10, "tree_size": 64, "t0": 3.03, "t1": 0.32, "tft": 2.1979, "input_0": 169, "input_1": 65, "min_CLP": -4.73, "draft_iters": 23.0, "mem_use": 44.78, "gen_rate": 5.3, "speed": 1.59, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 9.2, "tree_w": 19, "tree_size": 64, "t0": 1.464, "t1": 0.321, "tft": 2.5032, "input_0": 140, "input_1": 65, "min_CLP": -5.02, "draft_iters": 10.2, "mem_use": 44.36, "gen_rate": 3.3, "speed": 1.85, "text": "An assistant is a helpful and re"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 18, "tree_size": 64, "t0": 1.446, "t1": 0.336, "tft": 4.2672, "input_0": 139, "input_1": 65, "min_CLP": -5.01, "draft_iters": 9.8, "mem_use": 45.7, "gen_rate": 6.4, "speed": 3.58, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 13, "tree_size": 64, "t0": 2.645, "t1": 0.32, "tft": 3.7911, "input_0": 167, "input_1": 65, "min_CLP": -6.02, "draft_iters": 19.5, "mem_use": 44.56, "gen_rate": 20.0, "speed": 6.74, "text": "\"Jay's brother is John.<|endofte"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 1.475, "t1": 0.3283, "tft": 2.8949, "input_0": 156, "input_1": 65, "min_CLP": -4.77, "draft_iters": 9.8, "mem_use": 44.94, "gen_rate": 5.8, "speed": 3.23, "text": "Earth contains four oceans, the "}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 20, "tree_size": 64, "t0": 1.1171, "t1": 0.3357, "tft": 2.257, "input_0": 126, "input_1": 65, "min_CLP": -4.99, "draft_iters": 7.1, "mem_use": 45.18, "gen_rate": 4.7, "speed": 3.25, "text": "The first step is to assess your"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.7, "tree_w": 8, "tree_size": 64, "t0": 2.7533, "t1": 0.3267, "tft": 2.3048, "input_0": 225, "input_1": 65, "min_CLP": -4.31, "draft_iters": 18.7, "mem_use": 44.59, "gen_rate": 13.3, "speed": 4.33, "text": "To create a basic PyGame project"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 17, "tree_size": 64, "t0": 1.3686, "t1": 0.34, "tft": 3.7516, "input_0": 146, "input_1": 65, "min_CLP": -4.61, "draft_iters": 8.9, "mem_use": 45.69, "gen_rate": 4.7, "speed": 2.76, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.6, "tree_w": 17, "tree_size": 64, "t0": 1.49, "t1": 0.3257, "tft": 2.7226, "input_0": 127, "input_1": 65, "min_CLP": -4.93, "draft_iters": 10.6, "mem_use": 44.84, "gen_rate": 5.3, "speed": 2.91, "text": "I\\'m not sure what you\\'re askin"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 17, "tree_size": 64, "t0": 1.335, "t1": 0.3217, "tft": 2.2692, "input_0": 140, "input_1": 65, "min_CLP": -4.85, "draft_iters": 8.7, "mem_use": 44.37, "gen_rate": 5.8, "speed": 3.52, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.744, "t1": 0.324, "tft": 2.2356, "input_0": 170, "input_1": 65, "min_CLP": -4.53, "draft_iters": 12.0, "mem_use": 44.49, "gen_rate": 6.4, "speed": 3.1, "text": "\"Here is a high-quality testing "}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.8, "tree_w": 20, "tree_size": 64, "t0": 1.3262, "t1": 0.3225, "tft": 2.0547, "input_0": 143, "input_1": 65, "min_CLP": -5.05, "draft_iters": 8.8, "mem_use": 44.63, "gen_rate": 4.0, "speed": 2.42, "text": "Landlords provide housing for th"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 23, "tree_size": 64, "t0": 0.9988, "t1": 0.3338, "tft": 2.9103, "input_0": 105, "input_1": 65, "min_CLP": -5.38, "draft_iters": 6.5, "mem_use": 45.16, "gen_rate": 4.1, "speed": 3.1, "text": "\"I think the writing is poor and"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.0, "tree_w": 10, "tree_size": 64, "t0": 1.9875, "t1": 0.3325, "tft": 3.5812, "input_0": 208, "input_1": 65, "min_CLP": -4.45, "draft_iters": 13.0, "mem_use": 46.0, "gen_rate": 9.8, "speed": 4.2, "text": "\"Sure, I'm here to help! If you "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 11, "tree_size": 64, "t0": 1.815, "t1": 0.33, "tft": 3.9661, "input_0": 209, "input_1": 65, "min_CLP": -4.43, "draft_iters": 11.8, "mem_use": 46.53, "gen_rate": 8.2, "speed": 3.84, "text": "\"The ease or difficulty of learn"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.6, "tree_w": 8, "tree_size": 64, "t0": 2.572, "t1": 0.328, "tft": 3.0514, "input_0": 225, "input_1": 65, "min_CLP": -4.36, "draft_iters": 17.6, "mem_use": 44.98, "gen_rate": 7.0, "speed": 2.41, "text": "Among the tools I mentioned, the"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.9, "tree_w": 19, "tree_size": 64, "t0": 1.215, "t1": 0.3275, "tft": 2.5762, "input_0": 131, "input_1": 65, "min_CLP": -4.91, "draft_iters": 7.9, "mem_use": 44.84, "gen_rate": 4.2, "speed": 2.76, "text": "\"I don't have any personal feeli"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 14, "tree_size": 64, "t0": 1.4867, "t1": 0.33, "tft": 2.4289, "input_0": 150, "input_1": 65, "min_CLP": -4.78, "draft_iters": 10.2, "mem_use": 45.06, "gen_rate": 5.3, "speed": 2.94, "text": "No, it is not worth nothing to m"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 11, "tree_size": 64, "t0": 2.1175, "t1": 0.33, "tft": 3.8249, "input_0": 221, "input_1": 65, "min_CLP": -4.4, "draft_iters": 13.8, "mem_use": 45.07, "gen_rate": 8.0, "speed": 3.27, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 7.8, "tree_w": 16, "tree_size": 64, "t0": 1.35, "t1": 0.32, "tft": 2.3253, "input_0": 147, "input_1": 65, "min_CLP": -4.91, "draft_iters": 8.8, "mem_use": 44.49, "gen_rate": 8.0, "speed": 4.78, "text": "\"Sure, I would love to design an"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.3, "tree_w": 10, "tree_size": 64, "t0": 2.2133, "t1": 0.3367, "tft": 3.8451, "input_0": 224, "input_1": 65, "min_CLP": -4.6, "draft_iters": 14.3, "mem_use": 46.16, "gen_rate": 11.3, "speed": 4.45, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 22, "tree_h": 22.0, "tree_w": 11, "tree_size": 64, "t0": 3.02, "t1": 0.33, "tft": 1.9358, "input_0": 137, "input_1": 65, "min_CLP": -4.58, "draft_iters": 23.0, "mem_use": 44.64, "gen_rate": 22.0, "speed": 6.55, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 14, "tree_size": 64, "t0": 1.94, "t1": 0.324, "tft": 2.5111, "input_0": 182, "input_1": 65, "min_CLP": -4.81, "draft_iters": 13.0, "mem_use": 44.47, "gen_rate": 7.0, "speed": 3.09, "text": "Sure, here are 10 names from var"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 11, "tree_size": 64, "t0": 1.745, "t1": 0.3275, "tft": 2.8044, "input_0": 181, "input_1": 65, "min_CLP": -4.95, "draft_iters": 11.5, "mem_use": 44.95, "gen_rate": 8.8, "speed": 4.22, "text": "\"I'm an AI language model create"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 1.896, "t1": 0.332, "tft": 4.4694, "input_0": 195, "input_1": 65, "min_CLP": -4.47, "draft_iters": 12.6, "mem_use": 46.63, "gen_rate": 8.6, "speed": 3.86, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.1, "tree_w": 19, "tree_size": 64, "t0": 1.3087, "t1": 0.335, "tft": 2.9934, "input_0": 149, "input_1": 65, "min_CLP": -4.89, "draft_iters": 8.1, "mem_use": 45.42, "gen_rate": 4.6, "speed": 2.81, "text": "Yes, there is a similar theory c"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 1.672, "t1": 0.332, "tft": 3.9057, "input_0": 180, "input_1": 65, "min_CLP": -4.45, "draft_iters": 11.2, "mem_use": 45.85, "gen_rate": 6.4, "speed": 3.19, "text": "The meaning of life is a complex"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.5, "tree_w": 24, "tree_size": 64, "t0": 1.004, "t1": 0.325, "tft": 1.5194, "input_0": 110, "input_1": 65, "min_CLP": -5.2, "draft_iters": 6.5, "mem_use": 44.42, "gen_rate": 3.2, "speed": 2.4, "text": "Title: The Quantum Road\\n\\nMain "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.0, "tree_w": 8, "tree_size": 64, "t0": 2.5933, "t1": 0.35, "tft": 7.3247, "input_0": 235, "input_1": 65, "min_CLP": -4.8, "draft_iters": 17.0, "mem_use": 49.15, "gen_rate": 13.7, "speed": 4.64, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.875, "t1": 0.3325, "tft": 3.9108, "input_0": 200, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.0, "mem_use": 45.55, "gen_rate": 9.2, "speed": 4.19, "text": "To transform a word or expressio"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 1.54, "t1": 0.3375, "tft": 3.1255, "input_0": 149, "input_1": 65, "min_CLP": -4.6, "draft_iters": 10.5, "mem_use": 45.42, "gen_rate": 4.5, "speed": 2.4, "text": "The original departure time is n"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 4.12, "t1": 0.32, "tft": 2.5493, "input_0": 201, "input_1": 65, "min_CLP": -5.57, "draft_iters": 32.0, "mem_use": 44.44, "gen_rate": 33.0, "speed": 7.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 21, "tree_h": 19.5, "tree_w": 14, "tree_size": 64, "t0": 2.705, "t1": 0.325, "tft": 2.6778, "input_0": 152, "input_1": 65, "min_CLP": -5.24, "draft_iters": 20.0, "mem_use": 44.78, "gen_rate": 10.5, "speed": 3.46, "text": "You are a helpful assistant, who"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 15, "tree_size": 64, "t0": 1.74, "t1": 0.324, "tft": 2.5903, "input_0": 189, "input_1": 65, "min_CLP": -4.6, "draft_iters": 11.4, "mem_use": 44.4, "gen_rate": 7.2, "speed": 3.49, "text": "As of now, the number of black h"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 17, "tree_size": 64, "t0": 1.25, "t1": 0.355, "tft": 5.1952, "input_0": 143, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.0, "mem_use": 49.21, "gen_rate": 5.3, "speed": 3.32, "text": "My apologies, I misunderstood yo"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 11.2, "tree_w": 11, "tree_size": 64, "t0": 1.836, "t1": 0.322, "tft": 2.4211, "input_0": 198, "input_1": 65, "min_CLP": -4.55, "draft_iters": 12.2, "mem_use": 44.48, "gen_rate": 9.0, "speed": 4.17, "text": "The furthest back we can prove h"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.1, "tree_w": 17, "tree_size": 64, "t0": 1.3871, "t1": 0.3714, "tft": 7.7815, "input_0": 142, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.1, "mem_use": 51.44, "gen_rate": 5.6, "speed": 3.17, "text": "No, thank you. I will try to fig"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 17, "tree_size": 64, "t0": 1.3333, "t1": 0.3317, "tft": 3.9159, "input_0": 144, "input_1": 65, "min_CLP": -4.93, "draft_iters": 8.7, "mem_use": 45.66, "gen_rate": 5.8, "speed": 3.5, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.6, "tree_w": 13, "tree_size": 64, "t0": 1.7614, "t1": 0.3243, "tft": 2.514, "input_0": 192, "input_1": 65, "min_CLP": -4.58, "draft_iters": 11.6, "mem_use": 44.5, "gen_rate": 5.7, "speed": 2.74, "text": "\"The human genome, which consist"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.6, "tree_w": 12, "tree_size": 64, "t0": 1.928, "t1": 0.328, "tft": 3.0139, "input_0": 218, "input_1": 65, "min_CLP": -4.59, "draft_iters": 12.6, "mem_use": 44.37, "gen_rate": 8.6, "speed": 3.81, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.6, "tree_w": 14, "tree_size": 64, "t0": 1.6229, "t1": 0.3286, "tft": 2.4479, "input_0": 171, "input_1": 65, "min_CLP": -4.57, "draft_iters": 10.6, "mem_use": 44.62, "gen_rate": 4.7, "speed": 2.42, "text": "Here\\'s a plausible explanation:"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 14.0, "tree_w": 10, "tree_size": 64, "t0": 2.39, "t1": 0.33, "tft": 2.6959, "input_0": 256, "input_1": 65, "min_CLP": -4.45, "draft_iters": 15.0, "mem_use": 44.92, "gen_rate": 10.2, "speed": 3.77, "text": "Sure! Here are a few suggestions"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 8, "tree_size": 64, "t0": 2.4333, "t1": 0.3367, "tft": 5.0118, "input_0": 218, "input_1": 65, "min_CLP": -4.22, "draft_iters": 16.0, "mem_use": 46.53, "gen_rate": 10.7, "speed": 3.85, "text": "Sure, here are a few software an"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.3, "tree_w": 14, "tree_size": 64, "t0": 1.7183, "t1": 0.34, "tft": 3.689, "input_0": 177, "input_1": 65, "min_CLP": -4.62, "draft_iters": 11.3, "mem_use": 45.64, "gen_rate": 6.3, "speed": 3.08, "text": "When F-centers are present in a "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 64, "t0": 4.29, "t1": 0.33, "tft": 2.3181, "input_0": 221, "input_1": 65, "min_CLP": -5.65, "draft_iters": 32.0, "mem_use": 44.56, "gen_rate": 33.0, "speed": 7.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 23.0, "tree_w": 7, "tree_size": 64, "t0": 3.28, "t1": 0.33, "tft": 4.5951, "input_0": 201, "input_1": 65, "min_CLP": -4.1, "draft_iters": 24.0, "mem_use": 47.19, "gen_rate": 12.5, "speed": 3.46, "text": "\"Here's the commented code with "}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 1.834, "t1": 0.34, "tft": 3.6669, "input_0": 184, "input_1": 65, "min_CLP": -4.68, "draft_iters": 12.0, "mem_use": 45.67, "gen_rate": 6.4, "speed": 2.94, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 64, "t0": 4.23, "t1": 0.32, "tft": 2.0316, "input_0": 200, "input_1": 65, "min_CLP": -5.59, "draft_iters": 32.0, "mem_use": 44.39, "gen_rate": 33.0, "speed": 7.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 1.9, "t1": 0.325, "tft": 2.5736, "input_0": 176, "input_1": 65, "min_CLP": -4.61, "draft_iters": 13.0, "mem_use": 44.48, "gen_rate": 4.0, "speed": 1.8, "text": "```\\n```python\\nprint(\"Hello, Wo"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.8, "tree_w": 21, "tree_size": 64, "t0": 1.3133, "t1": 0.3417, "tft": 3.2988, "input_0": 130, "input_1": 65, "min_CLP": -5.02, "draft_iters": 8.8, "mem_use": 45.51, "gen_rate": 6.2, "speed": 3.73, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 12, "tree_size": 64, "t0": 2.1325, "t1": 0.335, "tft": 3.564, "input_0": 187, "input_1": 65, "min_CLP": -4.52, "draft_iters": 14.5, "mem_use": 46.47, "gen_rate": 8.2, "speed": 3.34, "text": "In JavaScript, you can use the `"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.81, "t1": 0.328, "tft": 2.2882, "input_0": 180, "input_1": 65, "min_CLP": -4.64, "draft_iters": 12.0, "mem_use": 45.0, "gen_rate": 7.2, "speed": 3.37, "text": "Sure. Here is a training plan fo"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 14, "tree_size": 64, "t0": 1.7525, "t1": 0.335, "tft": 3.5716, "input_0": 168, "input_1": 65, "min_CLP": -4.55, "draft_iters": 11.5, "mem_use": 45.48, "gen_rate": 8.0, "speed": 3.83, "text": "I apologize if my previous respo"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.83, "t1": 0.326, "tft": 2.3831, "input_0": 192, "input_1": 65, "min_CLP": -4.4, "draft_iters": 11.6, "mem_use": 44.39, "gen_rate": 6.4, "speed": 2.96, "text": "JavaScript is a versatile progra"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 64, "t0": 4.31, "t1": 0.32, "tft": 2.3941, "input_0": 222, "input_1": 65, "min_CLP": -6.58, "draft_iters": 32.0, "mem_use": 44.37, "gen_rate": 33.0, "speed": 7.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 13.0, "tree_w": 11, "tree_size": 64, "t0": 2.0586, "t1": 0.3329, "tft": 2.6872, "input_0": 186, "input_1": 65, "min_CLP": -4.57, "draft_iters": 14.0, "mem_use": 45.09, "gen_rate": 5.4, "speed": 2.27, "text": "Certainly! Here is the list in 2"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 1.605, "t1": 0.325, "tft": 2.4435, "input_0": 168, "input_1": 65, "min_CLP": -5.27, "draft_iters": 10.5, "mem_use": 44.5, "gen_rate": 8.2, "speed": 4.27, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 20, "tree_size": 64, "t0": 1.0663, "t1": 0.3287, "tft": 3.3118, "input_0": 119, "input_1": 65, "min_CLP": -5.05, "draft_iters": 6.9, "mem_use": 44.5, "gen_rate": 4.4, "speed": 3.14, "text": "\"Here's a poem for your valentin"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.3, "tree_w": 13, "tree_size": 64, "t0": 1.64, "t1": 0.3271, "tft": 2.2504, "input_0": 187, "input_1": 65, "min_CLP": -4.57, "draft_iters": 10.3, "mem_use": 44.48, "gen_rate": 5.0, "speed": 2.54, "text": "To effectively memorize Chinese "}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.2, "tree_w": 13, "tree_size": 64, "t0": 1.6775, "t1": 0.3525, "tft": 5.5432, "input_0": 200, "input_1": 65, "min_CLP": -4.85, "draft_iters": 10.2, "mem_use": 49.26, "gen_rate": 8.5, "speed": 4.19, "text": "\"Here's a rewritten version of t"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 15, "tree_size": 64, "t0": 1.718, "t1": 0.338, "tft": 4.8218, "input_0": 170, "input_1": 65, "min_CLP": -4.72, "draft_iters": 11.2, "mem_use": 46.88, "gen_rate": 6.4, "speed": 3.11, "text": "\"Sure! Think of Fermat's Last Th"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 21.0, "tree_w": 7, "tree_size": 64, "t0": 3.21, "t1": 0.3233, "tft": 3.4746, "input_0": 264, "input_1": 65, "min_CLP": -4.12, "draft_iters": 22.0, "mem_use": 45.31, "gen_rate": 17.3, "speed": 4.9, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.0, "tree_w": 11, "tree_size": 64, "t0": 2.008, "t1": 0.332, "tft": 3.3193, "input_0": 171, "input_1": 65, "min_CLP": -4.73, "draft_iters": 14.0, "mem_use": 45.48, "gen_rate": 7.6, "speed": 3.25, "text": "What we can learn from polar bea"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.7, "tree_w": 13, "tree_size": 64, "t0": 1.48, "t1": 0.3329, "tft": 4.0105, "input_0": 161, "input_1": 65, "min_CLP": -4.56, "draft_iters": 9.7, "mem_use": 46.54, "gen_rate": 4.9, "speed": 2.68, "text": "Lemon wedges are simply half or "}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 9.3, "tree_w": 16, "tree_size": 64, "t0": 1.5583, "t1": 0.325, "tft": 1.775, "input_0": 149, "input_1": 65, "min_CLP": -4.68, "draft_iters": 10.3, "mem_use": 44.57, "gen_rate": 5.0, "speed": 2.65, "text": "\"Sure! Let's get started. I\u2019ll b"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 1.49, "t1": 0.3229, "tft": 2.0379, "input_0": 147, "input_1": 65, "min_CLP": -4.55, "draft_iters": 10.0, "mem_use": 44.53, "gen_rate": 4.9, "speed": 2.68, "text": "\"I'm sorry to hear that. It's im"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 18.3, "tree_w": 7, "tree_size": 64, "t0": 2.8, "t1": 0.3233, "tft": 3.4912, "input_0": 230, "input_1": 65, "min_CLP": -4.04, "draft_iters": 19.3, "mem_use": 44.41, "gen_rate": 12.7, "speed": 4.05, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 1.446, "t1": 0.332, "tft": 3.4433, "input_0": 151, "input_1": 65, "min_CLP": -4.63, "draft_iters": 9.8, "mem_use": 45.99, "gen_rate": 6.4, "speed": 3.6, "text": "Yes, there are some cities that "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 15, "tree_size": 64, "t0": 1.63, "t1": 0.332, "tft": 3.8246, "input_0": 177, "input_1": 65, "min_CLP": -4.69, "draft_iters": 10.6, "mem_use": 45.52, "gen_rate": 6.6, "speed": 3.37, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.8, "tree_w": 13, "tree_size": 64, "t0": 1.65, "t1": 0.32, "tft": 2.1232, "input_0": 178, "input_1": 65, "min_CLP": -4.4, "draft_iters": 10.8, "mem_use": 44.36, "gen_rate": 6.0, "speed": 3.05, "text": "\"Certainly! I can help with codi"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 12.0, "tree_w": 14, "tree_size": 64, "t0": 1.915, "t1": 0.3325, "tft": 3.3205, "input_0": 176, "input_1": 65, "min_CLP": -5.12, "draft_iters": 13.0, "mem_use": 45.11, "gen_rate": 10.8, "speed": 4.78, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 22.7, "tree_w": 11, "tree_size": 64, "t0": 3.0867, "t1": 0.345, "tft": 4.9321, "input_0": 180, "input_1": 65, "min_CLP": -4.52, "draft_iters": 23.3, "mem_use": 45.71, "gen_rate": 5.3, "speed": 1.56, "text": "Of course! Here are the full lyr"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 10.0, "tree_w": 14, "tree_size": 64, "t0": 1.676, "t1": 0.33, "tft": 2.1928, "input_0": 172, "input_1": 65, "min_CLP": -4.74, "draft_iters": 11.0, "mem_use": 44.73, "gen_rate": 9.2, "speed": 4.58, "text": "1.    For work pressure and job "}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 11.0, "tree_w": 18, "tree_size": 64, "t0": 1.782, "t1": 0.324, "tft": 1.9437, "input_0": 177, "input_1": 65, "min_CLP": -5.36, "draft_iters": 12.0, "mem_use": 44.4, "gen_rate": 9.2, "speed": 4.37, "text": "def self_attention(q, k, v):\\n  "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.2, "tree_w": 17, "tree_size": 64, "t0": 1.6525, "t1": 0.3362, "tft": 2.7574, "input_0": 142, "input_1": 65, "min_CLP": -4.9, "draft_iters": 11.2, "mem_use": 44.96, "gen_rate": 4.2, "speed": 2.14, "text": "It is not possible to compare de"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 10, "tree_h": 9.5, "tree_w": 16, "tree_size": 64, "t0": 1.5375, "t1": 0.3325, "tft": 2.9343, "input_0": 132, "input_1": 65, "min_CLP": -4.97, "draft_iters": 10.5, "mem_use": 45.4, "gen_rate": 2.5, "speed": 1.34, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.2, "tree_w": 15, "tree_size": 64, "t0": 2.042, "t1": 0.334, "tft": 3.3868, "input_0": 169, "input_1": 65, "min_CLP": -5.21, "draft_iters": 14.2, "mem_use": 45.07, "gen_rate": 8.2, "speed": 3.45, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 4.44, "t1": 0.34, "tft": 5.5809, "input_0": 256, "input_1": 65, "min_CLP": -3.84, "draft_iters": 32.0, "mem_use": 47.2, "gen_rate": 27.5, "speed": 5.75, "text": "\"Yes, I do know what L'Hopital's"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.8, "tree_w": 13, "tree_size": 64, "t0": 1.774, "t1": 0.346, "tft": 5.8771, "input_0": 177, "input_1": 65, "min_CLP": -4.73, "draft_iters": 11.8, "mem_use": 48.77, "gen_rate": 8.4, "speed": 3.97, "text": "\"I don't have personal experienc"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 10.8, "tree_w": 13, "tree_size": 64, "t0": 1.844, "t1": 0.338, "tft": 3.3589, "input_0": 192, "input_1": 65, "min_CLP": -4.48, "draft_iters": 11.8, "mem_use": 45.78, "gen_rate": 8.6, "speed": 3.94, "text": "To beat Dave_ in your project, y"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 25.7, "tree_w": 4, "tree_size": 64, "t0": 3.7733, "t1": 0.34, "tft": 3.6291, "input_0": 275, "input_1": 65, "min_CLP": -3.72, "draft_iters": 26.3, "mem_use": 46.17, "gen_rate": 17.3, "speed": 4.22, "text": "Sure, here are the 3 most import"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 20.7, "tree_w": 10, "tree_size": 64, "t0": 3.0567, "t1": 0.3233, "tft": 2.9586, "input_0": 237, "input_1": 65, "min_CLP": -4.98, "draft_iters": 21.3, "mem_use": 44.4, "gen_rate": 15.7, "speed": 4.63, "text": "Explain the difference between s"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 17, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 4.36, "t1": 0.34, "tft": 3.5355, "input_0": 258, "input_1": 65, "min_CLP": -5.0, "draft_iters": 32.0, "mem_use": 45.73, "gen_rate": 17.0, "speed": 3.62, "text": "The answer would depend on the d"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.5, "tree_w": 13, "tree_size": 64, "t0": 1.905, "t1": 0.3267, "tft": 2.6539, "input_0": 180, "input_1": 65, "min_CLP": -4.55, "draft_iters": 12.5, "mem_use": 44.57, "gen_rate": 5.8, "speed": 2.61, "text": "\"Sure, I'd be happy to tell you "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 13.5, "tree_w": 11, "tree_size": 64, "t0": 2.2, "t1": 0.33, "tft": 2.8016, "input_0": 212, "input_1": 65, "min_CLP": -4.32, "draft_iters": 14.5, "mem_use": 44.45, "gen_rate": 9.0, "speed": 3.56, "text": "No, it is not possible to cook a"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 1.694, "t1": 0.322, "tft": 2.682, "input_0": 164, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.2, "mem_use": 44.43, "gen_rate": 7.8, "speed": 3.87, "text": "The best ways to farm experience"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 1.864, "t1": 0.322, "tft": 1.5286, "input_0": 182, "input_1": 65, "min_CLP": -4.66, "draft_iters": 12.6, "mem_use": 44.39, "gen_rate": 8.0, "speed": 3.65, "text": "Freyja was a Norse goddess assoc"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 13.0, "tree_w": 8, "tree_size": 64, "t0": 2.07, "t1": 0.34, "tft": 3.7743, "input_0": 209, "input_1": 65, "min_CLP": -4.34, "draft_iters": 14.0, "mem_use": 45.66, "gen_rate": 8.0, "speed": 3.33, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.7, "tree_w": 9, "tree_size": 64, "t0": 2.47, "t1": 0.3267, "tft": 2.972, "input_0": 193, "input_1": 65, "min_CLP": -4.57, "draft_iters": 17.7, "mem_use": 44.78, "gen_rate": 10.7, "speed": 3.81, "text": "# Add Tailwind CSS to the projec"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.3, "tree_w": 11, "tree_size": 64, "t0": 2.0633, "t1": 0.35, "tft": 6.4268, "input_0": 209, "input_1": 65, "min_CLP": -4.57, "draft_iters": 13.3, "mem_use": 49.87, "gen_rate": 11.3, "speed": 4.69, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.7725, "t1": 0.33, "tft": 2.6275, "input_0": 201, "input_1": 65, "min_CLP": -4.72, "draft_iters": 11.0, "mem_use": 44.91, "gen_rate": 8.5, "speed": 4.05, "text": "Large language models (LLMs) nee"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 64, "t0": 4.18, "t1": 0.33, "tft": 2.2714, "input_0": 192, "input_1": 65, "min_CLP": -5.4, "draft_iters": 32.0, "mem_use": 44.48, "gen_rate": 33.0, "speed": 7.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 14, "tree_size": 64, "t0": 1.726, "t1": 0.326, "tft": 4.4189, "input_0": 138, "input_1": 65, "min_CLP": -4.64, "draft_iters": 12.4, "mem_use": 44.69, "gen_rate": 6.4, "speed": 3.12, "text": "Here is a eulogy for your 100-ye"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 20.5, "tree_w": 15, "tree_size": 64, "t0": 2.9825, "t1": 0.3425, "tft": 3.4727, "input_0": 175, "input_1": 65, "min_CLP": -5.0, "draft_iters": 21.5, "mem_use": 46.17, "gen_rate": 5.5, "speed": 1.65, "text": "[INST] Is there anything else yo"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 13, "tree_size": 64, "t0": 1.694, "t1": 0.326, "tft": 2.686, "input_0": 171, "input_1": 65, "min_CLP": -4.54, "draft_iters": 11.4, "mem_use": 44.56, "gen_rate": 6.6, "speed": 3.27, "text": "Yes, I am an assistant. I am des"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 21.0, "tree_w": 10, "tree_size": 64, "t0": 2.885, "t1": 0.32, "tft": 3.5484, "input_0": 161, "input_1": 65, "min_CLP": -4.91, "draft_iters": 22.0, "mem_use": 44.53, "gen_rate": 2.5, "speed": 0.78, "text": "None of the above choices."}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 13, "tree_size": 64, "t0": 1.77, "t1": 0.328, "tft": 3.6306, "input_0": 178, "input_1": 65, "min_CLP": -4.48, "draft_iters": 11.6, "mem_use": 44.37, "gen_rate": 6.8, "speed": 3.24, "text": "The color of Mars is generally d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 21, "tree_size": 64, "t0": 1.205, "t1": 0.3383, "tft": 4.7567, "input_0": 112, "input_1": 65, "min_CLP": -5.29, "draft_iters": 8.0, "mem_use": 46.6, "gen_rate": 5.7, "speed": 3.67, "text": "In Quenya, you can say \"I love y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 4.27, "t1": 0.32, "tft": 2.9854, "input_0": 201, "input_1": 65, "min_CLP": -5.66, "draft_iters": 32.0, "mem_use": 44.45, "gen_rate": 33.0, "speed": 7.19, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 1.6029, "t1": 0.3314, "tft": 2.6521, "input_0": 175, "input_1": 65, "min_CLP": -4.8, "draft_iters": 10.3, "mem_use": 45.0, "gen_rate": 5.6, "speed": 2.88, "text": "Yes, the ATF is a federal agency"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 49, "tree_h": 13.6, "tree_w": 11, "tree_size": 64, "t0": 2.1343, "t1": 0.32, "tft": 3.695, "input_0": 189, "input_1": 65, "min_CLP": -4.27, "draft_iters": 14.6, "mem_use": 44.45, "gen_rate": 7.0, "speed": 2.85, "text": "Yes, there are several formulas "}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.9, "tree_w": 16, "tree_size": 64, "t0": 1.5243, "t1": 0.3286, "tft": 2.9883, "input_0": 174, "input_1": 65, "min_CLP": -4.68, "draft_iters": 9.9, "mem_use": 44.89, "gen_rate": 4.9, "speed": 2.62, "text": "\"I'm happy to help! As a babysit"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 7.0, "tree_w": 14, "tree_size": 64, "t0": 1.19, "t1": 0.32, "tft": 2.2297, "input_0": 119, "input_1": 65, "min_CLP": -5.24, "draft_iters": 8.0, "mem_use": 44.57, "gen_rate": 0.0, "speed": 0.0, "text": "The capital before Canberra was "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 29, "tree_h": 8.9, "tree_w": 18, "tree_size": 64, "t0": 1.4225, "t1": 0.3237, "tft": 1.8532, "input_0": 126, "input_1": 65, "min_CLP": -5.02, "draft_iters": 9.9, "mem_use": 44.75, "gen_rate": 3.6, "speed": 2.07, "text": "\"[INST] Yes, please share your e"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 1.5217, "t1": 0.3283, "tft": 3.8136, "input_0": 167, "input_1": 65, "min_CLP": -4.62, "draft_iters": 10.0, "mem_use": 46.97, "gen_rate": 5.5, "speed": 2.98, "text": "I can provide you with some guid"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 17, "tree_size": 64, "t0": 1.3167, "t1": 0.325, "tft": 1.9098, "input_0": 133, "input_1": 65, "min_CLP": -4.86, "draft_iters": 8.7, "mem_use": 44.56, "gen_rate": 5.8, "speed": 3.55, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 14, "tree_size": 64, "t0": 1.712, "t1": 0.338, "tft": 4.1875, "input_0": 169, "input_1": 65, "min_CLP": -4.5, "draft_iters": 11.4, "mem_use": 45.86, "gen_rate": 7.0, "speed": 3.41, "text": "\"Yes, for example, let's conside"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 1.5567, "t1": 0.325, "tft": 1.952, "input_0": 174, "input_1": 65, "min_CLP": -4.55, "draft_iters": 10.0, "mem_use": 44.42, "gen_rate": 6.2, "speed": 3.28, "text": "Sure, here are some potential is"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 1.3089, "t1": 0.3233, "tft": 1.8896, "input_0": 130, "input_1": 65, "min_CLP": -4.96, "draft_iters": 8.8, "mem_use": 44.48, "gen_rate": 3.6, "speed": 2.17, "text": "The sun has long since set upon "}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.0, "tree_w": 10, "tree_size": 64, "t0": 1.988, "t1": 0.32, "tft": 2.5695, "input_0": 205, "input_1": 65, "min_CLP": -4.37, "draft_iters": 13.0, "mem_use": 44.43, "gen_rate": 7.8, "speed": 3.37, "text": "Certainly! L\u2019Hopital\u2019s Rule is a"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 12, "tree_size": 64, "t0": 1.656, "t1": 0.334, "tft": 3.3601, "input_0": 174, "input_1": 65, "min_CLP": -4.49, "draft_iters": 11.0, "mem_use": 45.0, "gen_rate": 7.0, "speed": 3.52, "text": "Variance is a measure of how far"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 8.5, "tree_w": 15, "tree_size": 64, "t0": 1.43, "t1": 0.3325, "tft": 2.6461, "input_0": 145, "input_1": 65, "min_CLP": -4.74, "draft_iters": 9.5, "mem_use": 45.29, "gen_rate": 5.2, "speed": 2.98, "text": "\"Ride Your Way to Wellness: Tran"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 1.362, "t1": 0.328, "tft": 2.9937, "input_0": 144, "input_1": 65, "min_CLP": -4.91, "draft_iters": 9.0, "mem_use": 45.08, "gen_rate": 7.4, "speed": 4.38, "text": "The best places to see the stars"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 20, "tree_size": 64, "t0": 1.27, "t1": 0.3233, "tft": 2.4261, "input_0": 147, "input_1": 65, "min_CLP": -5.34, "draft_iters": 8.2, "mem_use": 44.42, "gen_rate": 5.3, "speed": 3.35, "text": "\"Sure, here's a top 10 list of t"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 20, "tree_size": 64, "t0": 1.5575, "t1": 0.3275, "tft": 3.9374, "input_0": 139, "input_1": 65, "min_CLP": -4.83, "draft_iters": 10.8, "mem_use": 44.98, "gen_rate": 9.2, "speed": 4.91, "text": "I apologize for the confusion, b"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.2, "tree_w": 16, "tree_size": 64, "t0": 1.478, "t1": 0.324, "tft": 2.8285, "input_0": 182, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.2, "mem_use": 44.85, "gen_rate": 7.4, "speed": 4.1, "text": "To cope with stress from financi"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.4, "tree_w": 12, "tree_size": 64, "t0": 1.7943, "t1": 0.3343, "tft": 5.1135, "input_0": 197, "input_1": 65, "min_CLP": -4.33, "draft_iters": 11.4, "mem_use": 47.94, "gen_rate": 5.4, "speed": 2.55, "text": "Sure, here are some tools that c"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.7, "tree_w": 10, "tree_size": 64, "t0": 2.0133, "t1": 0.34, "tft": 4.4881, "input_0": 241, "input_1": 65, "min_CLP": -4.25, "draft_iters": 12.7, "mem_use": 46.6, "gen_rate": 11.0, "speed": 4.67, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.0, "tree_w": 18, "tree_size": 64, "t0": 1.5229, "t1": 0.3243, "tft": 3.4107, "input_0": 164, "input_1": 65, "min_CLP": -4.92, "draft_iters": 10.0, "mem_use": 44.38, "gen_rate": 4.6, "speed": 2.47, "text": "Based on my current knowledge, t"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.3, "tree_w": 18, "tree_size": 64, "t0": 1.6, "t1": 0.3267, "tft": 2.8304, "input_0": 174, "input_1": 65, "min_CLP": -5.45, "draft_iters": 10.3, "mem_use": 44.63, "gen_rate": 6.0, "speed": 3.11, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.6, "tree_w": 12, "tree_size": 64, "t0": 1.6057, "t1": 0.3643, "tft": 8.153, "input_0": 171, "input_1": 65, "min_CLP": -4.62, "draft_iters": 10.6, "mem_use": 51.47, "gen_rate": 5.1, "speed": 2.61, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.7, "tree_w": 10, "tree_size": 64, "t0": 2.1233, "t1": 0.325, "tft": 4.4165, "input_0": 218, "input_1": 65, "min_CLP": -4.25, "draft_iters": 13.7, "mem_use": 44.81, "gen_rate": 6.7, "speed": 2.72, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 57, "tree_h": 27.5, "tree_w": 9, "tree_size": 64, "t0": 3.905, "t1": 0.335, "tft": 2.1892, "input_0": 218, "input_1": 65, "min_CLP": -5.17, "draft_iters": 28.0, "mem_use": 44.51, "gen_rate": 28.5, "speed": 6.72, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 15, "tree_size": 64, "t0": 1.7417, "t1": 0.3217, "tft": 1.9274, "input_0": 187, "input_1": 65, "min_CLP": -4.66, "draft_iters": 11.2, "mem_use": 44.51, "gen_rate": 5.3, "speed": 2.58, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 15, "tree_size": 64, "t0": 1.538, "t1": 0.334, "tft": 4.0198, "input_0": 188, "input_1": 65, "min_CLP": -4.83, "draft_iters": 9.6, "mem_use": 47.05, "gen_rate": 6.8, "speed": 3.63, "text": "\"I appreciate your skepticism. A"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 19.0, "tree_w": 6, "tree_size": 64, "t0": 2.94, "t1": 0.325, "tft": 3.2367, "input_0": 244, "input_1": 65, "min_CLP": -4.17, "draft_iters": 20.0, "mem_use": 44.93, "gen_rate": 18.5, "speed": 5.67, "text": "Yes, here are some of the top un"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.854, "t1": 0.338, "tft": 2.9325, "input_0": 173, "input_1": 65, "min_CLP": -4.86, "draft_iters": 12.4, "mem_use": 45.12, "gen_rate": 8.0, "speed": 3.65, "text": "\"I'm not asking about the specie"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 4.28, "t1": 0.32, "tft": 2.6411, "input_0": 214, "input_1": 65, "min_CLP": -4.87, "draft_iters": 32.0, "mem_use": 44.72, "gen_rate": 33.0, "speed": 7.16, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 7.5, "tree_w": 18, "tree_size": 64, "t0": 1.3062, "t1": 0.3287, "tft": 2.5263, "input_0": 140, "input_1": 65, "min_CLP": -5.43, "draft_iters": 8.5, "mem_use": 44.96, "gen_rate": 5.0, "speed": 3.06, "text": "\"Attention bias, you're the king"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 16.5, "tree_w": 8, "tree_size": 64, "t0": 2.575, "t1": 0.33, "tft": 2.8769, "input_0": 208, "input_1": 65, "min_CLP": -4.65, "draft_iters": 17.5, "mem_use": 44.75, "gen_rate": 16.5, "speed": 5.68, "text": "\"In the Schr\u00f6dinger's cat though"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 15, "tree_size": 64, "t0": 3.27, "t1": 0.325, "tft": 4.4345, "input_0": 241, "input_1": 65, "min_CLP": -5.37, "draft_iters": 22.5, "mem_use": 46.73, "gen_rate": 23.0, "speed": 6.39, "text": "\"[INST] Should I set up my kitch"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 20, "tree_size": 64, "t0": 1.64, "t1": 0.33, "tft": 3.0848, "input_0": 136, "input_1": 65, "min_CLP": -4.87, "draft_iters": 11.4, "mem_use": 44.5, "gen_rate": 6.6, "speed": 3.34, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 15.2, "tree_w": 9, "tree_size": 64, "t0": 2.364, "t1": 0.328, "tft": 2.7577, "input_0": 215, "input_1": 65, "min_CLP": -4.95, "draft_iters": 16.2, "mem_use": 44.52, "gen_rate": 8.2, "speed": 3.05, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfC\u00f3"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.5, "tree_w": 17, "tree_size": 64, "t0": 1.3587, "t1": 0.325, "tft": 2.5589, "input_0": 163, "input_1": 65, "min_CLP": -4.75, "draft_iters": 8.5, "mem_use": 44.5, "gen_rate": 4.0, "speed": 2.37, "text": "F-centers, short for \"Farbzentre"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.2, "tree_w": 22, "tree_size": 64, "t0": 1.348, "t1": 0.352, "tft": 6.0152, "input_0": 128, "input_1": 65, "min_CLP": -5.08, "draft_iters": 9.2, "mem_use": 49.07, "gen_rate": 6.6, "speed": 3.88, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.846, "t1": 0.336, "tft": 4.2433, "input_0": 196, "input_1": 65, "min_CLP": -4.6, "draft_iters": 12.0, "mem_use": 46.14, "gen_rate": 7.6, "speed": 3.49, "text": "I apologize for the misunderstan"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 11, "tree_size": 64, "t0": 1.9175, "t1": 0.325, "tft": 2.3947, "input_0": 193, "input_1": 65, "min_CLP": -4.71, "draft_iters": 12.2, "mem_use": 44.93, "gen_rate": 9.2, "speed": 4.12, "text": "Pros:\\n1. Efficiency: AI assista"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.2, "tree_w": 10, "tree_size": 64, "t0": 2.16, "t1": 0.326, "tft": 4.8224, "input_0": 196, "input_1": 65, "min_CLP": -4.56, "draft_iters": 14.2, "mem_use": 46.84, "gen_rate": 7.0, "speed": 2.81, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 10.2, "tree_w": 12, "tree_size": 64, "t0": 1.8017, "t1": 0.3367, "tft": 4.2445, "input_0": 200, "input_1": 65, "min_CLP": -4.65, "draft_iters": 11.2, "mem_use": 46.8, "gen_rate": 7.0, "speed": 3.27, "text": "Das Aussto\u00df an Treibhausgasen du"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 16, "tree_size": 64, "t0": 1.3617, "t1": 0.3317, "tft": 4.5214, "input_0": 138, "input_1": 65, "min_CLP": -4.68, "draft_iters": 9.0, "mem_use": 46.14, "gen_rate": 5.7, "speed": 3.35, "text": "\"I'm sorry, but I cannot provide"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 20, "tree_size": 64, "t0": 1.165, "t1": 0.33, "tft": 3.052, "input_0": 123, "input_1": 65, "min_CLP": -4.91, "draft_iters": 7.5, "mem_use": 45.18, "gen_rate": 4.0, "speed": 2.68, "text": "The best way to contact the orig"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 14, "tree_size": 64, "t0": 1.815, "t1": 0.3275, "tft": 1.9453, "input_0": 183, "input_1": 65, "min_CLP": -4.96, "draft_iters": 12.0, "mem_use": 44.76, "gen_rate": 8.5, "speed": 3.96, "text": "\u9019\u662f\u6211\u53ef\u4ee5\u63a8\u85a6\u7684\u4e00\u4e9b\u8ad6\u6587\uff1a\\n1. Vaswani et al."}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 24.7, "tree_w": 5, "tree_size": 64, "t0": 3.5833, "t1": 0.3267, "tft": 2.7767, "input_0": 257, "input_1": 65, "min_CLP": -4.09, "draft_iters": 25.3, "mem_use": 44.56, "gen_rate": 18.7, "speed": 4.77, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.2, "tree_w": 11, "tree_size": 64, "t0": 1.8075, "t1": 0.3325, "tft": 3.8853, "input_0": 171, "input_1": 65, "min_CLP": -4.3, "draft_iters": 12.2, "mem_use": 45.85, "gen_rate": 9.0, "speed": 4.2, "text": "\"In the state of Wyoming, as in "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.725, "t1": 0.325, "tft": 2.6083, "input_0": 183, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.0, "mem_use": 44.96, "gen_rate": 8.2, "speed": 4.02, "text": "There are many ways to deliver a"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 12, "tree_size": 64, "t0": 1.91, "t1": 0.3375, "tft": 3.5835, "input_0": 206, "input_1": 65, "min_CLP": -4.53, "draft_iters": 12.5, "mem_use": 45.84, "gen_rate": 8.0, "speed": 3.56, "text": "\"The optimal thickness for mayon"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 11.7, "tree_w": 18, "tree_size": 64, "t0": 1.9533, "t1": 0.3367, "tft": 3.8503, "input_0": 199, "input_1": 65, "min_CLP": -4.86, "draft_iters": 12.7, "mem_use": 45.22, "gen_rate": 6.7, "speed": 2.91, "text": "If you celebrate Christmas on De"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 23, "tree_size": 64, "t0": 1.3057, "t1": 0.33, "tft": 3.409, "input_0": 156, "input_1": 65, "min_CLP": -5.76, "draft_iters": 8.3, "mem_use": 44.49, "gen_rate": 5.1, "speed": 3.14, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.856, "t1": 0.332, "tft": 4.3411, "input_0": 166, "input_1": 65, "min_CLP": -4.43, "draft_iters": 12.4, "mem_use": 44.9, "gen_rate": 9.2, "speed": 4.2, "text": "The Balfour Declaration is often"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 23.3, "tree_w": 6, "tree_size": 64, "t0": 3.4467, "t1": 0.3433, "tft": 4.4352, "input_0": 253, "input_1": 65, "min_CLP": -3.87, "draft_iters": 24.0, "mem_use": 45.65, "gen_rate": 14.7, "speed": 3.87, "text": "\"Canciones felices: \\n1. \u00ab(I Can"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 10.1, "tree_w": 17, "tree_size": 64, "t0": 1.6089, "t1": 0.3244, "tft": 2.5441, "input_0": 144, "input_1": 65, "min_CLP": -4.85, "draft_iters": 11.1, "mem_use": 44.59, "gen_rate": 3.6, "speed": 1.84, "text": "\"Answer: I'm sorry, but I am una"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 20.2, "tree_w": 9, "tree_size": 64, "t0": 2.9525, "t1": 0.33, "tft": 4.0061, "input_0": 202, "input_1": 65, "min_CLP": -4.08, "draft_iters": 21.0, "mem_use": 44.98, "gen_rate": 11.0, "speed": 3.35, "text": "[INST] Ah, my apologies! Here is"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.2, "tree_w": 16, "tree_size": 64, "t0": 1.2575, "t1": 0.3337, "tft": 3.0336, "input_0": 126, "input_1": 65, "min_CLP": -4.97, "draft_iters": 8.2, "mem_use": 45.35, "gen_rate": 4.4, "speed": 2.75, "text": "How about, \"A heart\\'s desire, l"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.5, "tree_w": 9, "tree_size": 64, "t0": 2.515, "t1": 0.345, "tft": 4.7148, "input_0": 195, "input_1": 65, "min_CLP": -4.02, "draft_iters": 17.5, "mem_use": 46.12, "gen_rate": 17.0, "speed": 5.95, "text": "Sure, here is a step-by-step gui"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.5, "tree_w": 14, "tree_size": 64, "t0": 1.7783, "t1": 0.33, "tft": 3.0085, "input_0": 195, "input_1": 65, "min_CLP": -5.07, "draft_iters": 11.5, "mem_use": 44.59, "gen_rate": 5.7, "speed": 2.69, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.0, "tree_w": 17, "tree_size": 64, "t0": 1.515, "t1": 0.3267, "tft": 2.308, "input_0": 150, "input_1": 65, "min_CLP": -4.82, "draft_iters": 10.0, "mem_use": 44.52, "gen_rate": 6.5, "speed": 3.53, "text": "Yes, the correct answer is D. Th"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 14, "tree_size": 64, "t0": 1.842, "t1": 0.348, "tft": 5.7709, "input_0": 194, "input_1": 65, "min_CLP": -4.64, "draft_iters": 11.6, "mem_use": 48.65, "gen_rate": 7.0, "speed": 3.2, "text": "1. Discovery: Find a market need"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 1.672, "t1": 0.322, "tft": 2.7792, "input_0": 170, "input_1": 65, "min_CLP": -4.75, "draft_iters": 10.8, "mem_use": 44.42, "gen_rate": 7.6, "speed": 3.81, "text": "The many-worlds interpretation o"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 13, "tree_size": 64, "t0": 3.23, "t1": 0.32, "tft": 2.0145, "input_0": 210, "input_1": 65, "min_CLP": -5.77, "draft_iters": 23.0, "mem_use": 44.37, "gen_rate": 23.5, "speed": 6.62, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 15, "tree_size": 64, "t0": 1.874, "t1": 0.346, "tft": 6.2641, "input_0": 192, "input_1": 65, "min_CLP": -4.83, "draft_iters": 12.2, "mem_use": 48.64, "gen_rate": 6.6, "speed": 2.97, "text": "\"Hey! How can I help you today?\\"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.8, "tree_w": 16, "tree_size": 64, "t0": 1.426, "t1": 0.338, "tft": 3.7686, "input_0": 170, "input_1": 65, "min_CLP": -4.69, "draft_iters": 8.8, "mem_use": 46.44, "gen_rate": 7.0, "speed": 3.97, "text": "\u2022 Set reminders. Use alarms, sti"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.4, "tree_w": 15, "tree_size": 64, "t0": 1.49, "t1": 0.34, "tft": 3.0802, "input_0": 176, "input_1": 65, "min_CLP": -4.71, "draft_iters": 9.4, "mem_use": 45.69, "gen_rate": 7.0, "speed": 3.83, "text": "In the context of Into the Breac"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.8, "tree_w": 16, "tree_size": 64, "t0": 1.625, "t1": 0.325, "tft": 2.2257, "input_0": 169, "input_1": 65, "min_CLP": -4.83, "draft_iters": 10.8, "mem_use": 44.56, "gen_rate": 8.8, "speed": 4.48, "text": "The Battle of Gettysburg began o"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 10, "tree_size": 64, "t0": 2.18, "t1": 0.33, "tft": 2.5337, "input_0": 226, "input_1": 65, "min_CLP": -4.28, "draft_iters": 13.7, "mem_use": 44.58, "gen_rate": 10.7, "speed": 4.24, "text": "In the context of turn-based str"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.3, "tree_w": 12, "tree_size": 64, "t0": 1.9317, "t1": 0.335, "tft": 4.3549, "input_0": 206, "input_1": 65, "min_CLP": -4.88, "draft_iters": 12.3, "mem_use": 45.41, "gen_rate": 6.3, "speed": 2.8, "text": "\"[ANSWER]: I'm sorry, but I'm a "}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 23.0, "tree_w": 5, "tree_size": 64, "t0": 3.3267, "t1": 0.34, "tft": 3.4528, "input_0": 243, "input_1": 65, "min_CLP": -3.64, "draft_iters": 23.7, "mem_use": 45.94, "gen_rate": 11.3, "speed": 3.09, "text": "Here is a simpler script that ac"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 11.0, "tree_w": 16, "tree_size": 64, "t0": 1.79, "t1": 0.33, "tft": 2.5886, "input_0": 224, "input_1": 65, "min_CLP": -4.77, "draft_iters": 12.0, "mem_use": 45.36, "gen_rate": 6.0, "speed": 2.83, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.7, "tree_w": 21, "tree_size": 64, "t0": 1.0233, "t1": 0.3389, "tft": 5.7008, "input_0": 114, "input_1": 65, "min_CLP": -5.06, "draft_iters": 6.7, "mem_use": 45.46, "gen_rate": 3.6, "speed": 2.61, "text": "In your eyes, I see the beauty o"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.7, "tree_w": 13, "tree_size": 64, "t0": 1.9983, "t1": 0.3317, "tft": 2.9238, "input_0": 169, "input_1": 65, "min_CLP": -4.6, "draft_iters": 13.7, "mem_use": 44.86, "gen_rate": 5.7, "speed": 2.43, "text": "The airspeed velocity would be t"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 1.542, "t1": 0.334, "tft": 3.696, "input_0": 168, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.0, "mem_use": 44.82, "gen_rate": 6.4, "speed": 3.41, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 26, "tree_h": 9.4, "tree_w": 14, "tree_size": 64, "t0": 1.548, "t1": 0.332, "tft": 3.5752, "input_0": 162, "input_1": 65, "min_CLP": -4.78, "draft_iters": 10.4, "mem_use": 46.15, "gen_rate": 5.2, "speed": 2.76, "text": "\"You're welcome! If you encounte"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 1.5717, "t1": 0.3317, "tft": 3.8944, "input_0": 164, "input_1": 65, "min_CLP": -4.73, "draft_iters": 10.5, "mem_use": 46.08, "gen_rate": 6.2, "speed": 3.23, "text": "Yes, Open Assistant has been pre"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 12.6, "tree_w": 11, "tree_size": 64, "t0": 2.052, "t1": 0.336, "tft": 5.6376, "input_0": 193, "input_1": 65, "min_CLP": -4.78, "draft_iters": 13.6, "mem_use": 47.54, "gen_rate": 8.8, "speed": 3.69, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 64, "t0": 4.08, "t1": 0.32, "tft": 2.1782, "input_0": 202, "input_1": 65, "min_CLP": -6.36, "draft_iters": 32.0, "mem_use": 44.37, "gen_rate": 33.0, "speed": 7.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 18, "tree_size": 64, "t0": 1.125, "t1": 0.3333, "tft": 2.979, "input_0": 122, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.5, "mem_use": 45.3, "gen_rate": 5.7, "speed": 3.89, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 14, "tree_size": 64, "t0": 2.15, "t1": 0.34, "tft": 4.9783, "input_0": 196, "input_1": 65, "min_CLP": -5.13, "draft_iters": 14.0, "mem_use": 47.19, "gen_rate": 8.8, "speed": 3.52, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 1.3667, "t1": 0.33, "tft": 2.6089, "input_0": 152, "input_1": 65, "min_CLP": -4.81, "draft_iters": 8.8, "mem_use": 44.89, "gen_rate": 5.5, "speed": 3.24, "text": "- Introduction to the concept of"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 11, "tree_size": 64, "t0": 2.002, "t1": 0.346, "tft": 6.1029, "input_0": 195, "input_1": 65, "min_CLP": -4.39, "draft_iters": 13.2, "mem_use": 45.75, "gen_rate": 6.8, "speed": 2.9, "text": "Sure, I apologize for the confus"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 64, "max_branch_width": 32, "gen_rate": 9.67, "gen_rate_micro": 7.39, "gen_speed": 3.757, "gen_speed_micro": 3.502, "t0": 2.0435, "t1": 0.3307, "input_0": 180.0, "input_1": 65.0, "tree_size": 64.0, "tree_w": 13.4, "tree_h": 13.0, "prompt_len": 298.0, "min_CLP": -4.79, "mem_use": 53.85, "exp_time": 7262.14}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.0, "tree_w": 25, "tree_size": 128, "t0": 2.6117, "t1": 0.64, "tft": 3.286, "input_0": 349, "input_1": 129, "min_CLP": -5.46, "draft_iters": 13.0, "mem_use": 44.75, "gen_rate": 6.3, "speed": 1.95, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.0, "tree_w": 20, "tree_size": 128, "t0": 3.1867, "t1": 0.65, "tft": 4.9593, "input_0": 361, "input_1": 129, "min_CLP": -5.11, "draft_iters": 18.0, "mem_use": 46.3, "gen_rate": 10.7, "speed": 2.78, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 26, "tree_size": 128, "t0": 2.378, "t1": 0.656, "tft": 5.1731, "input_0": 306, "input_1": 129, "min_CLP": -5.27, "draft_iters": 12.4, "mem_use": 47.2, "gen_rate": 6.4, "speed": 2.11, "text": "Sure, here are some details for "}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 21.3, "tree_w": 12, "tree_size": 128, "t0": 4.1533, "t1": 0.6433, "tft": 5.9251, "input_0": 506, "input_1": 129, "min_CLP": -4.99, "draft_iters": 22.3, "mem_use": 44.93, "gen_rate": 15.0, "speed": 3.13, "text": "\"Certainly! Here's a simple Pyth"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.7, "tree_w": 17, "tree_size": 128, "t0": 3.1333, "t1": 0.64, "tft": 3.3017, "input_0": 433, "input_1": 129, "min_CLP": -5.21, "draft_iters": 14.7, "mem_use": 44.77, "gen_rate": 12.3, "speed": 3.27, "text": "\"Hi! Of course, I'd be happy to "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 24, "tree_size": 128, "t0": 2.652, "t1": 0.65, "tft": 7.1214, "input_0": 398, "input_1": 129, "min_CLP": -5.25, "draft_iters": 12.4, "mem_use": 47.33, "gen_rate": 6.4, "speed": 1.94, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 2.774, "t1": 0.664, "tft": 6.2993, "input_0": 365, "input_1": 129, "min_CLP": -5.05, "draft_iters": 15.0, "mem_use": 47.92, "gen_rate": 9.2, "speed": 2.68, "text": "Other options to enhance images "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 17, "tree_size": 128, "t0": 3.2, "t1": 0.67, "tft": 6.9419, "input_0": 452, "input_1": 129, "min_CLP": -5.0, "draft_iters": 15.7, "mem_use": 50.1, "gen_rate": 11.3, "speed": 2.93, "text": "To attract the right customers f"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.0, "tree_w": 15, "tree_size": 128, "t0": 3.75, "t1": 0.6567, "tft": 5.683, "input_0": 400, "input_1": 129, "min_CLP": -4.96, "draft_iters": 22.0, "mem_use": 47.53, "gen_rate": 11.7, "speed": 2.65, "text": "Sure! Here is a list of the lega"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.6, "tree_w": 19, "tree_size": 128, "t0": 3.036, "t1": 0.658, "tft": 5.6008, "input_0": 445, "input_1": 129, "min_CLP": -5.08, "draft_iters": 13.6, "mem_use": 46.9, "gen_rate": 7.6, "speed": 2.06, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 21.0, "tree_w": 33, "tree_size": 128, "t0": 3.8533, "t1": 0.65, "tft": 6.1773, "input_0": 370, "input_1": 129, "min_CLP": -5.63, "draft_iters": 22.0, "mem_use": 45.43, "gen_rate": 17.0, "speed": 3.78, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 19, "tree_size": 128, "t0": 2.9267, "t1": 0.6533, "tft": 5.9989, "input_0": 393, "input_1": 129, "min_CLP": -4.99, "draft_iters": 16.0, "mem_use": 47.27, "gen_rate": 10.7, "speed": 2.98, "text": "Sure, here is a more concise sum"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 18.5, "tree_w": 15, "tree_size": 128, "t0": 3.79, "t1": 0.655, "tft": 4.739, "input_0": 472, "input_1": 129, "min_CLP": -4.78, "draft_iters": 19.5, "mem_use": 46.49, "gen_rate": 17.0, "speed": 3.82, "text": "Sure! Here are some examples of "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 128, "t0": 4.79, "t1": 0.64, "tft": 3.906, "input_0": 331, "input_1": 129, "min_CLP": -6.43, "draft_iters": 32.0, "mem_use": 44.75, "gen_rate": 33.0, "speed": 6.07, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 22, "tree_size": 128, "t0": 2.3733, "t1": 0.6567, "tft": 5.5884, "input_0": 342, "input_1": 129, "min_CLP": -5.16, "draft_iters": 11.3, "mem_use": 47.9, "gen_rate": 5.3, "speed": 1.76, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.8, "tree_w": 19, "tree_size": 128, "t0": 2.83, "t1": 0.645, "tft": 5.9754, "input_0": 372, "input_1": 129, "min_CLP": -5.26, "draft_iters": 15.8, "mem_use": 45.09, "gen_rate": 9.2, "speed": 2.66, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 21.7, "tree_w": 13, "tree_size": 128, "t0": 4.1967, "t1": 0.64, "tft": 3.9689, "input_0": 536, "input_1": 129, "min_CLP": -4.93, "draft_iters": 22.7, "mem_use": 44.77, "gen_rate": 14.3, "speed": 2.96, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 5.21, "t1": 0.63, "tft": 4.0866, "input_0": 409, "input_1": 129, "min_CLP": -5.63, "draft_iters": 32.0, "mem_use": 44.75, "gen_rate": 33.0, "speed": 5.65, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.0, "tree_w": 21, "tree_size": 128, "t0": 2.9, "t1": 0.6425, "tft": 4.6555, "input_0": 392, "input_1": 129, "min_CLP": -5.21, "draft_iters": 15.0, "mem_use": 45.28, "gen_rate": 8.0, "speed": 2.26, "text": "D-theanine is an isomer of L-the"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 18.5, "tree_w": 20, "tree_size": 128, "t0": 4.375, "t1": 0.645, "tft": 4.4855, "input_0": 612, "input_1": 129, "min_CLP": -5.4, "draft_iters": 19.5, "mem_use": 44.76, "gen_rate": 16.5, "speed": 3.29, "text": "The Balfour Declaration was a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 16.8, "tree_w": 27, "tree_size": 128, "t0": 2.988, "t1": 0.646, "tft": 3.9303, "input_0": 320, "input_1": 129, "min_CLP": -6.43, "draft_iters": 17.8, "mem_use": 45.61, "gen_rate": 7.2, "speed": 1.98, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 14, "tree_h": 10.5, "tree_w": 33, "tree_size": 128, "t0": 2.53, "t1": 0.64, "tft": 3.6124, "input_0": 351, "input_1": 129, "min_CLP": -5.84, "draft_iters": 11.5, "mem_use": 44.75, "gen_rate": 7.0, "speed": 2.21, "text": "Hello there, Obi-Wan Kenobi! How"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 21, "tree_size": 128, "t0": 2.8325, "t1": 0.655, "tft": 6.1474, "input_0": 390, "input_1": 129, "min_CLP": -5.04, "draft_iters": 13.8, "mem_use": 47.11, "gen_rate": 8.2, "speed": 2.37, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 2.998, "t1": 0.638, "tft": 3.1868, "input_0": 431, "input_1": 129, "min_CLP": -5.09, "draft_iters": 15.0, "mem_use": 44.82, "gen_rate": 6.6, "speed": 1.81, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 13.7, "tree_w": 29, "tree_size": 128, "t0": 2.64, "t1": 0.6514, "tft": 4.5715, "input_0": 313, "input_1": 129, "min_CLP": -5.68, "draft_iters": 14.7, "mem_use": 45.79, "gen_rate": 5.4, "speed": 1.65, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 21, "tree_size": 128, "t0": 5.07, "t1": 0.64, "tft": 3.3393, "input_0": 429, "input_1": 129, "min_CLP": -7.25, "draft_iters": 32.0, "mem_use": 44.79, "gen_rate": 33.0, "speed": 5.79, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 11.1, "tree_w": 28, "tree_size": 128, "t0": 2.7357, "t1": 0.6471, "tft": 4.5096, "input_0": 382, "input_1": 129, "min_CLP": -5.68, "draft_iters": 12.1, "mem_use": 45.46, "gen_rate": 5.7, "speed": 1.69, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 14.0, "tree_w": 28, "tree_size": 128, "t0": 2.98, "t1": 0.64, "tft": 4.3661, "input_0": 407, "input_1": 129, "min_CLP": -5.35, "draft_iters": 15.0, "mem_use": 45.32, "gen_rate": 8.0, "speed": 2.21, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 25, "tree_size": 128, "t0": 4.86, "t1": 0.66, "tft": 4.6309, "input_0": 327, "input_1": 129, "min_CLP": -5.72, "draft_iters": 32.0, "mem_use": 47.26, "gen_rate": 33.0, "speed": 5.98, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 28, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 2.1522, "t1": 0.64, "tft": 2.9837, "input_0": 316, "input_1": 129, "min_CLP": -5.76, "draft_iters": 10.2, "mem_use": 44.8, "gen_rate": 3.1, "speed": 1.12, "text": "Some options of foods that you c"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.0, "tree_w": 13, "tree_size": 128, "t0": 3.58, "t1": 0.65, "tft": 4.8199, "input_0": 431, "input_1": 129, "min_CLP": -4.72, "draft_iters": 20.0, "mem_use": 45.51, "gen_rate": 10.7, "speed": 2.52, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 23.8, "tree_w": 14, "tree_size": 128, "t0": 4.0575, "t1": 0.6525, "tft": 4.8699, "input_0": 396, "input_1": 129, "min_CLP": -5.31, "draft_iters": 24.8, "mem_use": 45.92, "gen_rate": 14.2, "speed": 3.02, "text": "[API_REQUEST]: {curl -X POST -H "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.7, "tree_w": 29, "tree_size": 128, "t0": 2.3571, "t1": 0.6429, "tft": 2.905, "input_0": 323, "input_1": 129, "min_CLP": -5.51, "draft_iters": 11.7, "mem_use": 45.26, "gen_rate": 4.7, "speed": 1.57, "text": "Freyja, I come before you with a"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 10.4, "tree_w": 26, "tree_size": 128, "t0": 2.3275, "t1": 0.6512, "tft": 4.4232, "input_0": 347, "input_1": 129, "min_CLP": -5.34, "draft_iters": 11.4, "mem_use": 46.92, "gen_rate": 4.1, "speed": 1.39, "text": "Yes, there are several dairy-fre"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.7, "tree_w": 20, "tree_size": 128, "t0": 2.9933, "t1": 0.6533, "tft": 4.7387, "input_0": 423, "input_1": 129, "min_CLP": -5.26, "draft_iters": 14.7, "mem_use": 46.96, "gen_rate": 12.3, "speed": 3.38, "text": "When selecting an ISP (Internet "}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.8, "tree_w": 25, "tree_size": 128, "t0": 2.0775, "t1": 0.665, "tft": 8.2504, "input_0": 321, "input_1": 129, "min_CLP": -5.3, "draft_iters": 10.8, "mem_use": 49.69, "gen_rate": 8.8, "speed": 3.19, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.1, "tree_w": 25, "tree_size": 128, "t0": 2.3643, "t1": 0.64, "tft": 4.0978, "input_0": 346, "input_1": 129, "min_CLP": -5.26, "draft_iters": 11.1, "mem_use": 44.78, "gen_rate": 5.7, "speed": 1.9, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 5.28, "t1": 0.6467, "tft": 5.5745, "input_0": 468, "input_1": 129, "min_CLP": -5.4, "draft_iters": 32.0, "mem_use": 45.31, "gen_rate": 15.7, "speed": 2.64, "text": "The second verse of \"Never Gonna"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 27, "tree_size": 128, "t0": 2.336, "t1": 0.654, "tft": 5.4473, "input_0": 327, "input_1": 129, "min_CLP": -5.31, "draft_iters": 12.6, "mem_use": 47.69, "gen_rate": 7.4, "speed": 2.47, "text": "\"Of course! I'll try my best to "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.7, "tree_w": 17, "tree_size": 128, "t0": 3.77, "t1": 0.6433, "tft": 5.0348, "input_0": 505, "input_1": 129, "min_CLP": -5.06, "draft_iters": 19.7, "mem_use": 45.72, "gen_rate": 13.3, "speed": 3.02, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 38, "tree_size": 128, "t0": 1.6343, "t1": 0.6486, "tft": 2.6431, "input_0": 248, "input_1": 129, "min_CLP": -5.99, "draft_iters": 7.7, "mem_use": 45.01, "gen_rate": 4.7, "speed": 2.07, "text": "Foolish mortal. I will not give "}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 5.1, "t1": 0.66, "tft": 7.3484, "input_0": 397, "input_1": 129, "min_CLP": -5.7, "draft_iters": 32.0, "mem_use": 47.51, "gen_rate": 33.0, "speed": 5.73, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 31, "tree_size": 128, "t0": 2.214, "t1": 0.656, "tft": 5.0064, "input_0": 308, "input_1": 129, "min_CLP": -5.55, "draft_iters": 11.4, "mem_use": 47.95, "gen_rate": 7.2, "speed": 2.51, "text": "[INST] Thank you for the informa"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 15.2, "tree_w": 17, "tree_size": 128, "t0": 3.46, "t1": 0.6475, "tft": 4.7342, "input_0": 490, "input_1": 129, "min_CLP": -4.99, "draft_iters": 16.2, "mem_use": 46.29, "gen_rate": 10.5, "speed": 2.56, "text": "It\\'s difficult to say which one"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.4, "tree_w": 33, "tree_size": 128, "t0": 2.44, "t1": 0.648, "tft": 5.2734, "input_0": 352, "input_1": 129, "min_CLP": -5.85, "draft_iters": 11.4, "mem_use": 45.54, "gen_rate": 7.8, "speed": 2.53, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 25.0, "tree_w": 21, "tree_size": 128, "t0": 3.9367, "t1": 0.6467, "tft": 4.8834, "input_0": 337, "input_1": 129, "min_CLP": -6.05, "draft_iters": 25.3, "mem_use": 45.27, "gen_rate": 15.0, "speed": 3.27, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 20.3, "tree_w": 14, "tree_size": 128, "t0": 3.8, "t1": 0.6367, "tft": 4.0926, "input_0": 460, "input_1": 129, "min_CLP": -5.15, "draft_iters": 21.3, "mem_use": 44.78, "gen_rate": 14.3, "speed": 3.23, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 5.095, "t1": 0.675, "tft": 7.7557, "input_0": 460, "input_1": 129, "min_CLP": -4.76, "draft_iters": 32.0, "mem_use": 50.25, "gen_rate": 16.0, "speed": 2.77, "text": "\"Certainly! Here's an updated ve"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 42, "tree_size": 128, "t0": 1.6543, "t1": 0.6571, "tft": 3.5806, "input_0": 242, "input_1": 129, "min_CLP": -5.92, "draft_iters": 8.0, "mem_use": 46.53, "gen_rate": 4.7, "speed": 2.04, "text": "I will tell you what I saw, but "}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.7, "tree_w": 36, "tree_size": 128, "t0": 2.365, "t1": 0.6483, "tft": 2.7463, "input_0": 269, "input_1": 129, "min_CLP": -5.74, "draft_iters": 13.5, "mem_use": 45.55, "gen_rate": 5.7, "speed": 1.88, "text": "[INST] I understand your concern"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 2.965, "t1": 0.645, "tft": 3.6212, "input_0": 489, "input_1": 129, "min_CLP": -5.46, "draft_iters": 14.0, "mem_use": 45.06, "gen_rate": 6.0, "speed": 1.66, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u7aef\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u5b66\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 5.09, "t1": 0.67, "tft": 6.8053, "input_0": 489, "input_1": 129, "min_CLP": -4.9, "draft_iters": 32.0, "mem_use": 46.96, "gen_rate": 33.0, "speed": 5.73, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 16.3, "tree_w": 22, "tree_size": 128, "t0": 3.2467, "t1": 0.6533, "tft": 6.3107, "input_0": 389, "input_1": 129, "min_CLP": -5.54, "draft_iters": 17.3, "mem_use": 46.17, "gen_rate": 12.3, "speed": 3.17, "text": "Sure, here are some more histori"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.2, "tree_w": 22, "tree_size": 128, "t0": 2.666, "t1": 0.652, "tft": 5.12, "input_0": 383, "input_1": 129, "min_CLP": -5.26, "draft_iters": 13.2, "mem_use": 46.51, "gen_rate": 8.6, "speed": 2.6, "text": "Yes, it is important to acknowle"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.6, "tree_w": 28, "tree_size": 128, "t0": 2.2214, "t1": 0.6429, "tft": 2.7748, "input_0": 342, "input_1": 129, "min_CLP": -5.48, "draft_iters": 10.6, "mem_use": 44.96, "gen_rate": 5.3, "speed": 1.85, "text": "In real life, people of all ages"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.2, "tree_w": 22, "tree_size": 128, "t0": 2.695, "t1": 0.6533, "tft": 5.8795, "input_0": 369, "input_1": 129, "min_CLP": -5.42, "draft_iters": 14.2, "mem_use": 47.36, "gen_rate": 6.7, "speed": 1.99, "text": "Sure, here\\'s a pitch deck for F"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 31, "tree_size": 128, "t0": 2.626, "t1": 0.67, "tft": 7.601, "input_0": 370, "input_1": 129, "min_CLP": -5.51, "draft_iters": 12.6, "mem_use": 48.61, "gen_rate": 6.6, "speed": 2.0, "text": "I apologize for the confusion. Y"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.3, "tree_w": 19, "tree_size": 128, "t0": 3.0933, "t1": 0.6767, "tft": 6.1428, "input_0": 440, "input_1": 129, "min_CLP": -5.02, "draft_iters": 15.3, "mem_use": 48.78, "gen_rate": 11.0, "speed": 2.92, "text": "Yes, Keras is a great choice for"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 25.5, "tree_w": 12, "tree_size": 128, "t0": 4.67, "t1": 0.66, "tft": 5.4222, "input_0": 547, "input_1": 129, "min_CLP": -5.17, "draft_iters": 26.5, "mem_use": 46.44, "gen_rate": 16.0, "speed": 3.01, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.4, "tree_w": 30, "tree_size": 128, "t0": 2.046, "t1": 0.64, "tft": 4.247, "input_0": 314, "input_1": 129, "min_CLP": -5.46, "draft_iters": 9.4, "mem_use": 44.78, "gen_rate": 7.6, "speed": 2.83, "text": "\"The best way to form a new habi"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 13, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 4.85, "t1": 0.64, "tft": 4.6285, "input_0": 400, "input_1": 129, "min_CLP": -4.47, "draft_iters": 32.0, "mem_use": 47.19, "gen_rate": 13.0, "speed": 2.36, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 25, "tree_size": 128, "t0": 2.542, "t1": 0.658, "tft": 5.9016, "input_0": 382, "input_1": 129, "min_CLP": -5.58, "draft_iters": 11.6, "mem_use": 48.04, "gen_rate": 6.6, "speed": 2.06, "text": "[The Spartan general stands at t"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.0, "tree_w": 28, "tree_size": 128, "t0": 2.0383, "t1": 0.6517, "tft": 3.2572, "input_0": 291, "input_1": 129, "min_CLP": -5.5, "draft_iters": 10.0, "mem_use": 45.73, "gen_rate": 6.3, "speed": 2.35, "text": "You\\'re right, it\\'s important t"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 34, "tree_size": 128, "t0": 2.1, "t1": 0.648, "tft": 4.2054, "input_0": 306, "input_1": 129, "min_CLP": -5.56, "draft_iters": 9.4, "mem_use": 45.45, "gen_rate": 6.8, "speed": 2.48, "text": "Proof-of-stake is a consensus me"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 6.2, "tree_w": 43, "tree_size": 128, "t0": 1.4883, "t1": 0.6483, "tft": 3.8449, "input_0": 208, "input_1": 129, "min_CLP": -6.08, "draft_iters": 7.2, "mem_use": 45.57, "gen_rate": 4.0, "speed": 1.87, "text": "My advice is to not get involved"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.5, "tree_w": 19, "tree_size": 128, "t0": 2.995, "t1": 0.655, "tft": 5.7867, "input_0": 416, "input_1": 129, "min_CLP": -5.0, "draft_iters": 14.5, "mem_use": 47.64, "gen_rate": 10.8, "speed": 2.94, "text": "Void pointers are a special type"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 2.842, "t1": 0.662, "tft": 5.9514, "input_0": 421, "input_1": 129, "min_CLP": -5.73, "draft_iters": 12.2, "mem_use": 48.16, "gen_rate": 7.8, "speed": 2.23, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 22, "tree_size": 128, "t0": 2.75, "t1": 0.6575, "tft": 6.1398, "input_0": 394, "input_1": 129, "min_CLP": -5.3, "draft_iters": 14.2, "mem_use": 47.37, "gen_rate": 8.5, "speed": 2.49, "text": "To implement 2FA using an authen"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 20, "tree_h": 13.0, "tree_w": 21, "tree_size": 128, "t0": 2.75, "t1": 0.64, "tft": 2.9982, "input_0": 355, "input_1": 129, "min_CLP": -5.27, "draft_iters": 14.0, "mem_use": 45.19, "gen_rate": 10.0, "speed": 2.95, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 2.2533, "t1": 0.6433, "tft": 2.9439, "input_0": 333, "input_1": 129, "min_CLP": -5.44, "draft_iters": 11.2, "mem_use": 44.78, "gen_rate": 6.3, "speed": 2.19, "text": "The idea that landlords could be"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 28.5, "tree_w": 11, "tree_size": 128, "t0": 4.675, "t1": 0.655, "tft": 6.5354, "input_0": 459, "input_1": 129, "min_CLP": -4.29, "draft_iters": 29.0, "mem_use": 47.6, "gen_rate": 20.5, "speed": 3.85, "text": "Sure! Here is the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.8, "tree_w": 28, "tree_size": 128, "t0": 2.4433, "t1": 0.64, "tft": 2.7272, "input_0": 340, "input_1": 129, "min_CLP": -5.55, "draft_iters": 10.8, "mem_use": 44.73, "gen_rate": 5.3, "speed": 1.73, "text": "Berlin is a city in Germany, so "}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.5, "tree_w": 29, "tree_size": 128, "t0": 2.1433, "t1": 0.6483, "tft": 4.4688, "input_0": 292, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.5, "mem_use": 47.06, "gen_rate": 6.0, "speed": 2.15, "text": "Here are a few light-hearted jok"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.7, "tree_w": 12, "tree_size": 128, "t0": 3.6833, "t1": 0.6567, "tft": 5.4181, "input_0": 475, "input_1": 129, "min_CLP": -4.97, "draft_iters": 19.7, "mem_use": 46.92, "gen_rate": 11.7, "speed": 2.69, "text": "Certainly. One of the main criti"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 128, "t0": 5.1, "t1": 0.64, "tft": 3.7307, "input_0": 397, "input_1": 129, "min_CLP": -6.88, "draft_iters": 32.0, "mem_use": 44.75, "gen_rate": 33.0, "speed": 5.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 20, "tree_h": 22.0, "tree_w": 25, "tree_size": 128, "t0": 3.95, "t1": 0.64, "tft": 5.5367, "input_0": 453, "input_1": 129, "min_CLP": -5.9, "draft_iters": 22.5, "mem_use": 45.06, "gen_rate": 10.0, "speed": 2.18, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 31, "tree_size": 128, "t0": 1.9433, "t1": 0.6433, "tft": 2.6602, "input_0": 277, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.3, "mem_use": 45.14, "gen_rate": 5.5, "speed": 2.13, "text": "No, the five second rule is not "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 17.0, "tree_w": 15, "tree_size": 128, "t0": 3.02, "t1": 0.64, "tft": 3.3826, "input_0": 322, "input_1": 129, "min_CLP": -5.38, "draft_iters": 18.0, "mem_use": 44.87, "gen_rate": 9.0, "speed": 2.46, "text": "12 - 2 - 5 = 5"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.8, "tree_w": 19, "tree_size": 128, "t0": 2.79, "t1": 0.645, "tft": 4.8402, "input_0": 394, "input_1": 129, "min_CLP": -4.94, "draft_iters": 14.8, "mem_use": 45.62, "gen_rate": 9.0, "speed": 2.62, "text": " Sure! One simple algorithm for "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.8, "tree_w": 27, "tree_size": 128, "t0": 2.255, "t1": 0.6467, "tft": 3.0112, "input_0": 317, "input_1": 129, "min_CLP": -5.43, "draft_iters": 10.8, "mem_use": 45.18, "gen_rate": 5.5, "speed": 1.9, "text": "\"You're welcome! I'm sorry to he"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 39, "tree_size": 128, "t0": 1.872, "t1": 0.64, "tft": 4.3431, "input_0": 255, "input_1": 129, "min_CLP": -5.67, "draft_iters": 9.2, "mem_use": 44.9, "gen_rate": 6.4, "speed": 2.55, "text": "\"#OpenAssistant is now open sour"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.2, "tree_w": 21, "tree_size": 128, "t0": 2.642, "t1": 0.65, "tft": 4.4966, "input_0": 367, "input_1": 129, "min_CLP": -5.32, "draft_iters": 13.2, "mem_use": 45.51, "gen_rate": 8.0, "speed": 2.43, "text": "Sexual selection can also affect"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.8, "tree_w": 21, "tree_size": 128, "t0": 2.7975, "t1": 0.655, "tft": 5.2008, "input_0": 430, "input_1": 129, "min_CLP": -5.07, "draft_iters": 12.8, "mem_use": 46.56, "gen_rate": 9.2, "speed": 2.68, "text": "\"AI assistants can also help ind"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 29, "tree_size": 128, "t0": 2.366, "t1": 0.65, "tft": 7.7687, "input_0": 347, "input_1": 129, "min_CLP": -5.78, "draft_iters": 11.6, "mem_use": 47.57, "gen_rate": 7.6, "speed": 2.52, "text": "Certainly! Here\u2019s a rewritten ve"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 12.0, "tree_w": 21, "tree_size": 128, "t0": 2.6625, "t1": 0.6525, "tft": 4.9381, "input_0": 386, "input_1": 129, "min_CLP": -5.1, "draft_iters": 13.0, "mem_use": 46.07, "gen_rate": 10.5, "speed": 3.17, "text": "The scp command is a Unix comman"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 5.86, "t1": 0.65, "tft": 6.6133, "input_0": 680, "input_1": 129, "min_CLP": -6.48, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 33.0, "speed": 5.06, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.7, "tree_w": 30, "tree_size": 128, "t0": 2.0814, "t1": 0.6386, "tft": 4.1107, "input_0": 302, "input_1": 129, "min_CLP": -5.58, "draft_iters": 10.7, "mem_use": 44.8, "gen_rate": 5.7, "speed": 2.1, "text": "Yes, if you found a dollar bill "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 22, "tree_size": 128, "t0": 2.77, "t1": 0.64, "tft": 3.953, "input_0": 319, "input_1": 129, "min_CLP": -5.43, "draft_iters": 14.7, "mem_use": 45.09, "gen_rate": 10.7, "speed": 3.13, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 4.81, "t1": 0.64, "tft": 3.2258, "input_0": 321, "input_1": 129, "min_CLP": -5.89, "draft_iters": 32.0, "mem_use": 45.39, "gen_rate": 33.0, "speed": 6.06, "text": "\"[INST] 5 second rule is a dange"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 19, "tree_h": 6.0, "tree_w": 42, "tree_size": 128, "t0": 1.398, "t1": 0.64, "tft": 2.6113, "input_0": 211, "input_1": 129, "min_CLP": -6.03, "draft_iters": 7.0, "mem_use": 45.07, "gen_rate": 3.8, "speed": 1.86, "text": "\"Oh, I didn't mean it like that."}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.4, "tree_w": 26, "tree_size": 128, "t0": 2.636, "t1": 0.642, "tft": 4.6756, "input_0": 353, "input_1": 129, "min_CLP": -5.38, "draft_iters": 12.4, "mem_use": 44.84, "gen_rate": 7.2, "speed": 2.2, "text": "The best approach for learning a"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 2.154, "t1": 0.638, "tft": 5.297, "input_0": 320, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.2, "mem_use": 44.81, "gen_rate": 7.6, "speed": 2.72, "text": "Walking around the world is not "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 20, "tree_size": 128, "t0": 3.05, "t1": 0.655, "tft": 7.1138, "input_0": 417, "input_1": 129, "min_CLP": -5.1, "draft_iters": 15.8, "mem_use": 46.56, "gen_rate": 8.2, "speed": 2.23, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.2, "tree_w": 26, "tree_size": 128, "t0": 2.818, "t1": 0.642, "tft": 4.7392, "input_0": 361, "input_1": 129, "min_CLP": -5.42, "draft_iters": 15.2, "mem_use": 44.81, "gen_rate": 8.2, "speed": 2.37, "text": "[ANS]\\nBased on your preference "}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.5, "tree_w": 16, "tree_size": 128, "t0": 3.255, "t1": 0.645, "tft": 5.6519, "input_0": 408, "input_1": 129, "min_CLP": -5.04, "draft_iters": 17.5, "mem_use": 45.12, "gen_rate": 10.0, "speed": 2.56, "text": "To create a first-person control"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 128, "t0": 5.28, "t1": 0.64, "tft": 3.3819, "input_0": 419, "input_1": 129, "min_CLP": -6.92, "draft_iters": 32.0, "mem_use": 44.78, "gen_rate": 33.0, "speed": 5.57, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 27, "tree_size": 128, "t0": 2.5925, "t1": 0.6475, "tft": 2.8048, "input_0": 374, "input_1": 129, "min_CLP": -5.42, "draft_iters": 12.2, "mem_use": 45.1, "gen_rate": 8.2, "speed": 2.55, "text": "The path to becoming one with th"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 29, "tree_size": 128, "t0": 1.996, "t1": 0.648, "tft": 3.6036, "input_0": 278, "input_1": 129, "min_CLP": -5.5, "draft_iters": 10.2, "mem_use": 44.96, "gen_rate": 6.4, "speed": 2.42, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 20.5, "tree_w": 21, "tree_size": 128, "t0": 3.81, "t1": 0.6475, "tft": 4.3395, "input_0": 417, "input_1": 129, "min_CLP": -5.49, "draft_iters": 21.5, "mem_use": 45.2, "gen_rate": 14.2, "speed": 3.2, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.2, "tree_w": 25, "tree_size": 128, "t0": 2.484, "t1": 0.658, "tft": 5.8218, "input_0": 332, "input_1": 129, "min_CLP": -5.23, "draft_iters": 12.2, "mem_use": 48.06, "gen_rate": 7.6, "speed": 2.42, "text": "Yes, I understand that a naive r"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.2, "tree_w": 21, "tree_size": 128, "t0": 2.99, "t1": 0.645, "tft": 4.7243, "input_0": 400, "input_1": 129, "min_CLP": -5.29, "draft_iters": 16.2, "mem_use": 45.26, "gen_rate": 8.8, "speed": 2.41, "text": "Yes, it is customary to compensa"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 15, "tree_h": 11.0, "tree_w": 26, "tree_size": 128, "t0": 2.39, "t1": 0.66, "tft": 5.7329, "input_0": 306, "input_1": 129, "min_CLP": -5.32, "draft_iters": 12.0, "mem_use": 48.16, "gen_rate": 5.0, "speed": 1.64, "text": "Xin ch\u00e0o, t\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd AI. "}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.8, "tree_w": 25, "tree_size": 128, "t0": 2.394, "t1": 0.65, "tft": 3.05, "input_0": 334, "input_1": 129, "min_CLP": -5.44, "draft_iters": 12.8, "mem_use": 45.63, "gen_rate": 7.2, "speed": 2.37, "text": "What are some ways we can increa"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 26.0, "tree_w": 14, "tree_size": 128, "t0": 4.645, "t1": 0.64, "tft": 3.8483, "input_0": 497, "input_1": 129, "min_CLP": -5.01, "draft_iters": 26.5, "mem_use": 45.14, "gen_rate": 19.5, "speed": 3.69, "text": "Certainly! Here\\'s a more detail"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.7, "tree_w": 25, "tree_size": 128, "t0": 3.4333, "t1": 0.65, "tft": 4.6985, "input_0": 440, "input_1": 129, "min_CLP": -5.44, "draft_iters": 18.7, "mem_use": 46.58, "gen_rate": 10.7, "speed": 2.61, "text": "1. Rammstein\\n2. Scorpions\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 41, "tree_size": 128, "t0": 1.6914, "t1": 0.6471, "tft": 3.2308, "input_0": 264, "input_1": 129, "min_CLP": -5.89, "draft_iters": 7.4, "mem_use": 45.11, "gen_rate": 5.0, "speed": 2.14, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 17.0, "tree_w": 14, "tree_size": 128, "t0": 3.69, "t1": 0.66, "tft": 5.7958, "input_0": 490, "input_1": 129, "min_CLP": -4.82, "draft_iters": 18.0, "mem_use": 47.12, "gen_rate": 16.0, "speed": 3.68, "text": "Acquiring revenue from customers"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 8.7, "tree_w": 31, "tree_size": 128, "t0": 2.025, "t1": 0.6517, "tft": 3.5418, "input_0": 301, "input_1": 129, "min_CLP": -5.6, "draft_iters": 9.7, "mem_use": 45.73, "gen_rate": 6.8, "speed": 2.55, "text": "As a language model, I can gener"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 14.7, "tree_w": 18, "tree_size": 128, "t0": 3.06, "t1": 0.6467, "tft": 3.303, "input_0": 408, "input_1": 129, "min_CLP": -5.17, "draft_iters": 15.7, "mem_use": 45.27, "gen_rate": 13.3, "speed": 3.6, "text": "Certainly! Here is a sample essa"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 19, "tree_size": 128, "t0": 3.03, "t1": 0.645, "tft": 3.9086, "input_0": 411, "input_1": 129, "min_CLP": -5.0, "draft_iters": 14.5, "mem_use": 45.41, "gen_rate": 8.5, "speed": 2.31, "text": "There are numerous APIs, librari"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 30, "tree_size": 128, "t0": 2.522, "t1": 0.658, "tft": 5.3729, "input_0": 342, "input_1": 129, "min_CLP": -5.62, "draft_iters": 12.2, "mem_use": 46.69, "gen_rate": 7.0, "speed": 2.2, "text": "As a helpful assistant, I can ce"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 25, "tree_size": 128, "t0": 2.578, "t1": 0.64, "tft": 3.3782, "input_0": 356, "input_1": 129, "min_CLP": -5.3, "draft_iters": 12.4, "mem_use": 44.78, "gen_rate": 6.8, "speed": 2.11, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.6, "tree_w": 24, "tree_size": 128, "t0": 2.336, "t1": 0.642, "tft": 4.4962, "input_0": 329, "input_1": 129, "min_CLP": -5.34, "draft_iters": 11.6, "mem_use": 44.82, "gen_rate": 7.2, "speed": 2.42, "text": "The error in the given code is t"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 6, "tree_h": 13.7, "tree_w": 31, "tree_size": 128, "t0": 2.5533, "t1": 0.66, "tft": 3.7427, "input_0": 272, "input_1": 129, "min_CLP": -5.95, "draft_iters": 14.7, "mem_use": 46.22, "gen_rate": 2.0, "speed": 0.62, "text": "<|endofprompt|>"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.2, "tree_w": 24, "tree_size": 128, "t0": 2.6117, "t1": 0.6483, "tft": 3.8577, "input_0": 349, "input_1": 129, "min_CLP": -5.25, "draft_iters": 13.2, "mem_use": 45.43, "gen_rate": 5.5, "speed": 1.69, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 23.3, "tree_w": 15, "tree_size": 128, "t0": 4.3367, "t1": 0.6467, "tft": 3.7971, "input_0": 470, "input_1": 129, "min_CLP": -4.93, "draft_iters": 24.3, "mem_use": 45.56, "gen_rate": 14.3, "speed": 2.88, "text": "\"To create a program in Python t"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.6, "tree_w": 21, "tree_size": 128, "t0": 2.8357, "t1": 0.6457, "tft": 5.2905, "input_0": 403, "input_1": 129, "min_CLP": -5.29, "draft_iters": 13.6, "mem_use": 47.34, "gen_rate": 5.1, "speed": 1.48, "text": "\"It's important to make sure you"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 21, "tree_size": 128, "t0": 4.615, "t1": 0.64, "tft": 3.8809, "input_0": 487, "input_1": 129, "min_CLP": -5.37, "draft_iters": 25.5, "mem_use": 45.35, "gen_rate": 25.5, "speed": 4.85, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 29.0, "tree_w": 14, "tree_size": 128, "t0": 5.13, "t1": 0.65, "tft": 7.3155, "input_0": 612, "input_1": 129, "min_CLP": -4.91, "draft_iters": 29.5, "mem_use": 46.71, "gen_rate": 16.5, "speed": 2.85, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.0, "tree_w": 23, "tree_size": 128, "t0": 2.676, "t1": 0.636, "tft": 3.782, "input_0": 378, "input_1": 129, "min_CLP": -5.6, "draft_iters": 13.0, "mem_use": 44.77, "gen_rate": 7.2, "speed": 2.17, "text": "Yes, I can try my best to think "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.1, "tree_w": 50, "tree_size": 128, "t0": 1.505, "t1": 0.6438, "tft": 2.8665, "input_0": 219, "input_1": 129, "min_CLP": -6.28, "draft_iters": 7.1, "mem_use": 44.99, "gen_rate": 4.1, "speed": 1.92, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.8, "tree_w": 31, "tree_size": 128, "t0": 2.245, "t1": 0.6467, "tft": 3.2515, "input_0": 334, "input_1": 129, "min_CLP": -5.74, "draft_iters": 10.8, "mem_use": 45.24, "gen_rate": 5.8, "speed": 2.02, "text": "\"Thanks! I just follow the instr"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 25, "tree_size": 128, "t0": 2.5933, "t1": 0.66, "tft": 4.5873, "input_0": 338, "input_1": 129, "min_CLP": -5.52, "draft_iters": 13.7, "mem_use": 46.83, "gen_rate": 10.7, "speed": 3.28, "text": "\"Thou art the sun that shineth b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 21, "tree_size": 128, "t0": 2.732, "t1": 0.644, "tft": 3.8148, "input_0": 348, "input_1": 129, "min_CLP": -5.24, "draft_iters": 14.8, "mem_use": 45.41, "gen_rate": 7.2, "speed": 2.13, "text": "I apologize for not providing a "}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 40, "tree_size": 128, "t0": 1.992, "t1": 0.644, "tft": 3.8219, "input_0": 257, "input_1": 129, "min_CLP": -6.0, "draft_iters": 10.6, "mem_use": 44.81, "gen_rate": 6.4, "speed": 2.43, "text": "Sure, here are some words in Que"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 19.3, "tree_w": 16, "tree_size": 128, "t0": 3.8867, "t1": 0.64, "tft": 3.3774, "input_0": 485, "input_1": 129, "min_CLP": -5.01, "draft_iters": 20.3, "mem_use": 44.79, "gen_rate": 13.3, "speed": 2.95, "text": "\"Presidents Day, officially know"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.2, "tree_w": 29, "tree_size": 128, "t0": 2.4467, "t1": 0.64, "tft": 3.5067, "input_0": 352, "input_1": 129, "min_CLP": -5.54, "draft_iters": 12.2, "mem_use": 45.09, "gen_rate": 5.7, "speed": 1.84, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 33, "tree_size": 128, "t0": 2.1371, "t1": 0.6557, "tft": 5.5064, "input_0": 316, "input_1": 129, "min_CLP": -5.56, "draft_iters": 10.4, "mem_use": 45.9, "gen_rate": 5.0, "speed": 1.79, "text": "Yes, the US National Reconnaissa"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 35, "tree_size": 128, "t0": 1.86, "t1": 0.6429, "tft": 3.4175, "input_0": 244, "input_1": 129, "min_CLP": -5.97, "draft_iters": 9.7, "mem_use": 45.17, "gen_rate": 4.7, "speed": 1.88, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 9.8, "tree_w": 32, "tree_size": 128, "t0": 2.225, "t1": 0.645, "tft": 2.8835, "input_0": 310, "input_1": 129, "min_CLP": -5.61, "draft_iters": 10.8, "mem_use": 45.24, "gen_rate": 4.5, "speed": 1.57, "text": "Opie is a nice and friendly name"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.3, "tree_w": 36, "tree_size": 128, "t0": 2.0157, "t1": 0.6386, "tft": 2.8344, "input_0": 275, "input_1": 129, "min_CLP": -5.94, "draft_iters": 10.3, "mem_use": 44.79, "gen_rate": 4.9, "speed": 1.83, "text": "[INST] Think before you answer. "}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.9, "tree_w": 40, "tree_size": 128, "t0": 1.56, "t1": 0.65, "tft": 3.3176, "input_0": 230, "input_1": 129, "min_CLP": -5.83, "draft_iters": 7.9, "mem_use": 45.48, "gen_rate": 3.8, "speed": 1.71, "text": "Kaczynski was like a total buzzk"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.6, "tree_w": 27, "tree_size": 128, "t0": 2.2071, "t1": 0.6457, "tft": 5.7009, "input_0": 317, "input_1": 129, "min_CLP": -5.34, "draft_iters": 10.6, "mem_use": 44.9, "gen_rate": 4.6, "speed": 1.6, "text": "Yes, you can try to salvage your"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 25, "tree_size": 128, "t0": 2.53, "t1": 0.658, "tft": 3.6563, "input_0": 372, "input_1": 129, "min_CLP": -5.36, "draft_iters": 12.6, "mem_use": 46.14, "gen_rate": 6.4, "speed": 2.01, "text": "Certainly! Here are a few exampl"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.0, "tree_w": 31, "tree_size": 128, "t0": 2.236, "t1": 0.648, "tft": 3.4753, "input_0": 299, "input_1": 129, "min_CLP": -5.59, "draft_iters": 11.0, "mem_use": 45.23, "gen_rate": 7.2, "speed": 2.5, "text": "\"No, I am an AI assistant here t"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.5, "tree_w": 24, "tree_size": 128, "t0": 2.7825, "t1": 0.655, "tft": 5.3384, "input_0": 391, "input_1": 129, "min_CLP": -5.34, "draft_iters": 13.5, "mem_use": 46.44, "gen_rate": 9.5, "speed": 2.77, "text": "\"For a beginner hiker looking fo"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 38, "tree_size": 128, "t0": 2.1133, "t1": 0.6483, "tft": 4.0463, "input_0": 238, "input_1": 129, "min_CLP": -6.02, "draft_iters": 11.8, "mem_use": 45.18, "gen_rate": 5.3, "speed": 1.93, "text": "Open Assistant: Open Source Chat"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.5, "tree_w": 23, "tree_size": 128, "t0": 2.9283, "t1": 0.65, "tft": 3.9042, "input_0": 361, "input_1": 129, "min_CLP": -5.27, "draft_iters": 15.5, "mem_use": 45.08, "gen_rate": 6.5, "speed": 1.82, "text": "\"Sure, here's a diagram to illus"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.8, "tree_w": 21, "tree_size": 128, "t0": 3.012, "t1": 0.656, "tft": 4.8647, "input_0": 358, "input_1": 129, "min_CLP": -5.14, "draft_iters": 15.8, "mem_use": 47.42, "gen_rate": 7.4, "speed": 2.02, "text": "This behavior can occur due to t"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.3, "tree_w": 21, "tree_size": 128, "t0": 3.0167, "t1": 0.6367, "tft": 3.531, "input_0": 393, "input_1": 129, "min_CLP": -5.26, "draft_iters": 15.3, "mem_use": 44.77, "gen_rate": 12.0, "speed": 3.28, "text": "No, you cannot directly compile "}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.3, "tree_w": 47, "tree_size": 128, "t0": 1.4422, "t1": 0.6433, "tft": 2.8382, "input_0": 199, "input_1": 129, "min_CLP": -5.99, "draft_iters": 7.3, "mem_use": 45.32, "gen_rate": 4.2, "speed": 2.02, "text": "Video games are a lot of fun and"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 2.0675, "t1": 0.6425, "tft": 4.0905, "input_0": 300, "input_1": 129, "min_CLP": -5.49, "draft_iters": 10.2, "mem_use": 44.95, "gen_rate": 5.5, "speed": 2.03, "text": "When the pan is already hot, it "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 31, "tree_h": 11.6, "tree_w": 24, "tree_size": 128, "t0": 2.788, "t1": 0.642, "tft": 3.3707, "input_0": 416, "input_1": 129, "min_CLP": -5.26, "draft_iters": 12.6, "mem_use": 44.79, "gen_rate": 6.2, "speed": 1.81, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.3, "tree_w": 23, "tree_size": 128, "t0": 2.6171, "t1": 0.6543, "tft": 5.5728, "input_0": 368, "input_1": 129, "min_CLP": -5.15, "draft_iters": 13.3, "mem_use": 46.88, "gen_rate": 5.1, "speed": 1.57, "text": "\"I'm sorry to hear that the vide"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 30, "tree_size": 128, "t0": 2.2267, "t1": 0.645, "tft": 3.7261, "input_0": 318, "input_1": 129, "min_CLP": -5.44, "draft_iters": 10.5, "mem_use": 44.75, "gen_rate": 5.8, "speed": 2.03, "text": "\"No, a thumb war is not violent."}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.3, "tree_w": 34, "tree_size": 128, "t0": 2.3, "t1": 0.6414, "tft": 4.2247, "input_0": 276, "input_1": 129, "min_CLP": -5.7, "draft_iters": 12.3, "mem_use": 44.83, "gen_rate": 5.4, "speed": 1.84, "text": "Rick Astley\\'s third verse of \"N"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 24, "tree_size": 128, "t0": 2.66, "t1": 0.654, "tft": 5.6373, "input_0": 368, "input_1": 129, "min_CLP": -5.28, "draft_iters": 13.6, "mem_use": 48.12, "gen_rate": 7.0, "speed": 2.11, "text": "As of my knowledge cutoff date i"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.8, "tree_w": 21, "tree_size": 128, "t0": 3.13, "t1": 0.654, "tft": 4.1459, "input_0": 367, "input_1": 129, "min_CLP": -5.25, "draft_iters": 16.8, "mem_use": 46.1, "gen_rate": 6.4, "speed": 1.69, "text": "I apologize for any frustration "}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 16.8, "tree_w": 16, "tree_size": 128, "t0": 3.3525, "t1": 0.6475, "tft": 3.2949, "input_0": 471, "input_1": 129, "min_CLP": -5.09, "draft_iters": 17.8, "mem_use": 45.04, "gen_rate": 11.5, "speed": 2.88, "text": "\"Certainly! There are many resou"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.4, "tree_w": 30, "tree_size": 128, "t0": 2.502, "t1": 0.646, "tft": 3.9502, "input_0": 333, "input_1": 129, "min_CLP": -5.6, "draft_iters": 12.4, "mem_use": 45.02, "gen_rate": 7.4, "speed": 2.35, "text": "The most effective ways to commi"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 11.7, "tree_w": 24, "tree_size": 128, "t0": 2.6133, "t1": 0.6433, "tft": 3.6414, "input_0": 380, "input_1": 129, "min_CLP": -5.35, "draft_iters": 12.7, "mem_use": 44.79, "gen_rate": 7.5, "speed": 2.3, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 22.2, "tree_w": 33, "tree_size": 128, "t0": 3.4375, "t1": 0.65, "tft": 4.0515, "input_0": 251, "input_1": 129, "min_CLP": -5.99, "draft_iters": 23.0, "mem_use": 45.6, "gen_rate": 10.0, "speed": 2.45, "text": "[INST] Sorry, I will clarify, pl"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.7, "tree_w": 15, "tree_size": 128, "t0": 4.03, "t1": 0.6467, "tft": 5.7358, "input_0": 555, "input_1": 129, "min_CLP": -4.8, "draft_iters": 21.3, "mem_use": 45.63, "gen_rate": 13.0, "speed": 2.78, "text": "\"Por supuesto. Aqu\u00ed tienes la li"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 21.0, "tree_w": 14, "tree_size": 128, "t0": 3.85, "t1": 0.665, "tft": 7.2351, "input_0": 438, "input_1": 129, "min_CLP": -5.25, "draft_iters": 22.0, "mem_use": 48.14, "gen_rate": 18.0, "speed": 3.99, "text": "Step 1 \u2014 Starting the TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.8, "tree_w": 23, "tree_size": 128, "t0": 2.602, "t1": 0.642, "tft": 4.3064, "input_0": 387, "input_1": 129, "min_CLP": -5.14, "draft_iters": 11.8, "mem_use": 44.79, "gen_rate": 7.8, "speed": 2.41, "text": "\"To reduce your alcohol consumpt"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 9.8, "tree_w": 30, "tree_size": 128, "t0": 2.1583, "t1": 0.645, "tft": 4.2781, "input_0": 298, "input_1": 129, "min_CLP": -6.05, "draft_iters": 10.8, "mem_use": 45.36, "gen_rate": 7.3, "speed": 2.61, "text": "Berlin is home to many well-know"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 17.3, "tree_w": 15, "tree_size": 128, "t0": 3.8833, "t1": 0.6367, "tft": 5.4143, "input_0": 550, "input_1": 129, "min_CLP": -4.61, "draft_iters": 18.3, "mem_use": 44.83, "gen_rate": 13.7, "speed": 3.02, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 26, "tree_size": 128, "t0": 2.315, "t1": 0.655, "tft": 5.6568, "input_0": 332, "input_1": 129, "min_CLP": -5.29, "draft_iters": 11.2, "mem_use": 47.33, "gen_rate": 8.2, "speed": 2.78, "text": "\"Sure, here's a recipe that you "}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.3, "tree_w": 33, "tree_size": 128, "t0": 2.1871, "t1": 0.6386, "tft": 3.9945, "input_0": 316, "input_1": 129, "min_CLP": -5.68, "draft_iters": 10.3, "mem_use": 44.74, "gen_rate": 5.3, "speed": 1.87, "text": "The question \"Who wears short sh"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 21, "tree_size": 128, "t0": 2.76, "t1": 0.655, "tft": 4.8315, "input_0": 398, "input_1": 129, "min_CLP": -5.2, "draft_iters": 13.5, "mem_use": 47.01, "gen_rate": 9.2, "speed": 2.71, "text": "Here are some potential steps th"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.5, "tree_w": 26, "tree_size": 128, "t0": 2.28, "t1": 0.6383, "tft": 3.8836, "input_0": 314, "input_1": 129, "min_CLP": -5.59, "draft_iters": 11.5, "mem_use": 44.75, "gen_rate": 6.7, "speed": 2.28, "text": "The \"Why\" in your question sugge"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.0, "tree_w": 36, "tree_size": 128, "t0": 2.9067, "t1": 0.64, "tft": 2.4477, "input_0": 283, "input_1": 129, "min_CLP": -6.16, "draft_iters": 17.7, "mem_use": 44.73, "gen_rate": 13.3, "speed": 3.76, "text": "\u4e0a\u9762\u8fd9\u53e5\u8bdd\u4ec0\u4e48\u610f\u601d\uff1f\\n[INST] <<SYS>>\\nYou "}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 2.528, "t1": 0.644, "tft": 3.4056, "input_0": 365, "input_1": 129, "min_CLP": -5.27, "draft_iters": 12.2, "mem_use": 44.9, "gen_rate": 7.6, "speed": 2.4, "text": "Sure! One project I worked on in"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 28, "tree_size": 128, "t0": 2.448, "t1": 0.652, "tft": 4.9961, "input_0": 333, "input_1": 129, "min_CLP": -5.3, "draft_iters": 12.2, "mem_use": 45.96, "gen_rate": 7.2, "speed": 2.32, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.2, "tree_w": 20, "tree_size": 128, "t0": 2.5925, "t1": 0.645, "tft": 4.483, "input_0": 368, "input_1": 129, "min_CLP": -5.28, "draft_iters": 13.2, "mem_use": 44.85, "gen_rate": 9.2, "speed": 2.86, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 26, "tree_size": 128, "t0": 2.1925, "t1": 0.64, "tft": 3.1218, "input_0": 319, "input_1": 129, "min_CLP": -5.4, "draft_iters": 11.2, "mem_use": 45.05, "gen_rate": 8.0, "speed": 2.82, "text": "\"Sure, I'd be happy to explain i"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 17.0, "tree_w": 19, "tree_size": 128, "t0": 3.3333, "t1": 0.64, "tft": 4.0732, "input_0": 448, "input_1": 129, "min_CLP": -5.11, "draft_iters": 18.0, "mem_use": 45.39, "gen_rate": 14.3, "speed": 3.6, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 31, "tree_size": 128, "t0": 2.105, "t1": 0.6483, "tft": 3.8965, "input_0": 299, "input_1": 129, "min_CLP": -5.57, "draft_iters": 9.7, "mem_use": 44.94, "gen_rate": 5.8, "speed": 2.12, "text": "I am the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 21, "tree_size": 128, "t0": 3.0025, "t1": 0.655, "tft": 5.7232, "input_0": 379, "input_1": 129, "min_CLP": -5.03, "draft_iters": 15.8, "mem_use": 46.16, "gen_rate": 8.0, "speed": 2.19, "text": "\"On a Windows machine, you can o"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 27, "tree_size": 128, "t0": 2.3775, "t1": 0.64, "tft": 5.8761, "input_0": 335, "input_1": 129, "min_CLP": -5.42, "draft_iters": 12.2, "mem_use": 44.83, "gen_rate": 8.2, "speed": 2.74, "text": "I disagree with the statement th"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.6, "tree_w": 18, "tree_size": 128, "t0": 3.222, "t1": 0.646, "tft": 4.9278, "input_0": 469, "input_1": 129, "min_CLP": -5.21, "draft_iters": 15.6, "mem_use": 45.67, "gen_rate": 6.8, "speed": 1.76, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 26, "tree_size": 128, "t0": 2.39, "t1": 0.64, "tft": 3.1894, "input_0": 348, "input_1": 129, "min_CLP": -5.23, "draft_iters": 11.6, "mem_use": 44.94, "gen_rate": 7.6, "speed": 2.51, "text": "Pros:\\n\\n1. Improved tolerance t"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 25.0, "tree_w": 19, "tree_size": 128, "t0": 4.42, "t1": 0.64, "tft": 3.2566, "input_0": 451, "input_1": 129, "min_CLP": -5.64, "draft_iters": 26.0, "mem_use": 44.77, "gen_rate": 7.0, "speed": 1.38, "text": "\"What happened to schrodinger's "}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 2.522, "t1": 0.668, "tft": 7.4186, "input_0": 372, "input_1": 129, "min_CLP": -5.36, "draft_iters": 12.2, "mem_use": 49.07, "gen_rate": 6.8, "speed": 2.13, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.0, "tree_w": 20, "tree_size": 128, "t0": 2.765, "t1": 0.64, "tft": 2.8839, "input_0": 404, "input_1": 129, "min_CLP": -5.15, "draft_iters": 14.0, "mem_use": 45.07, "gen_rate": 8.5, "speed": 2.5, "text": "\"Approaching a technical problem"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 27.0, "tree_w": 14, "tree_size": 128, "t0": 4.435, "t1": 0.65, "tft": 4.7011, "input_0": 488, "input_1": 129, "min_CLP": -5.03, "draft_iters": 27.5, "mem_use": 45.95, "gen_rate": 24.5, "speed": 4.81, "text": "It would take approximately 8,01"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 8.9, "tree_w": 33, "tree_size": 128, "t0": 1.9429, "t1": 0.6486, "tft": 4.694, "input_0": 248, "input_1": 129, "min_CLP": -5.8, "draft_iters": 9.9, "mem_use": 47.21, "gen_rate": 5.9, "speed": 2.26, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 37, "tree_size": 128, "t0": 1.67, "t1": 0.642, "tft": 2.7634, "input_0": 214, "input_1": 129, "min_CLP": -6.0, "draft_iters": 9.0, "mem_use": 45.05, "gen_rate": 6.4, "speed": 2.77, "text": "\"If I had a dollar for every tim"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 11.0, "tree_w": 26, "tree_size": 128, "t0": 2.9, "t1": 0.64, "tft": 3.2195, "input_0": 462, "input_1": 129, "min_CLP": -5.7, "draft_iters": 12.0, "mem_use": 45.09, "gen_rate": 5.0, "speed": 1.41, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 28, "tree_size": 128, "t0": 2.448, "t1": 0.646, "tft": 4.4735, "input_0": 337, "input_1": 129, "min_CLP": -5.53, "draft_iters": 11.8, "mem_use": 45.57, "gen_rate": 6.8, "speed": 2.2, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 4.91, "t1": 0.64, "tft": 4.3628, "input_0": 494, "input_1": 129, "min_CLP": -9.42, "draft_iters": 32.0, "mem_use": 45.07, "gen_rate": 33.0, "speed": 5.94, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 32, "tree_size": 128, "t0": 1.9967, "t1": 0.65, "tft": 3.9265, "input_0": 289, "input_1": 129, "min_CLP": -5.77, "draft_iters": 9.5, "mem_use": 45.75, "gen_rate": 5.3, "speed": 2.01, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 28, "tree_size": 128, "t0": 5.11, "t1": 0.64, "tft": 3.1362, "input_0": 412, "input_1": 129, "min_CLP": -5.6, "draft_iters": 32.0, "mem_use": 45.09, "gen_rate": 33.0, "speed": 5.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 23, "tree_size": 128, "t0": 2.88, "t1": 0.64, "tft": 3.9451, "input_0": 406, "input_1": 129, "min_CLP": -5.36, "draft_iters": 13.5, "mem_use": 44.81, "gen_rate": 8.8, "speed": 2.49, "text": "Here are the key components of a"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.6, "tree_w": 20, "tree_size": 128, "t0": 2.84, "t1": 0.642, "tft": 5.1861, "input_0": 380, "input_1": 129, "min_CLP": -5.47, "draft_iters": 14.6, "mem_use": 44.78, "gen_rate": 7.8, "speed": 2.24, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 17.0, "tree_w": 13, "tree_size": 128, "t0": 3.56, "t1": 0.67, "tft": 7.1777, "input_0": 437, "input_1": 129, "min_CLP": -5.06, "draft_iters": 18.0, "mem_use": 49.06, "gen_rate": 11.0, "speed": 2.6, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.7, "tree_w": 24, "tree_size": 128, "t0": 2.88, "t1": 0.6467, "tft": 3.4763, "input_0": 396, "input_1": 129, "min_CLP": -5.59, "draft_iters": 13.7, "mem_use": 44.91, "gen_rate": 12.3, "speed": 3.5, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 16.0, "tree_w": 18, "tree_size": 128, "t0": 3.3633, "t1": 0.65, "tft": 4.9754, "input_0": 427, "input_1": 129, "min_CLP": -5.01, "draft_iters": 17.0, "mem_use": 46.45, "gen_rate": 7.0, "speed": 1.74, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.8, "tree_w": 19, "tree_size": 128, "t0": 3.0025, "t1": 0.6475, "tft": 4.5825, "input_0": 401, "input_1": 129, "min_CLP": -5.1, "draft_iters": 14.8, "mem_use": 46.21, "gen_rate": 10.2, "speed": 2.81, "text": "In option 2, using the Command P"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 18.0, "tree_w": 18, "tree_size": 128, "t0": 3.5467, "t1": 0.64, "tft": 4.0824, "input_0": 434, "input_1": 129, "min_CLP": -5.11, "draft_iters": 19.0, "mem_use": 45.04, "gen_rate": 13.0, "speed": 3.11, "text": "\"Using critical thinking methods"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.0, "tree_w": 19, "tree_size": 128, "t0": 2.9575, "t1": 0.6375, "tft": 3.5835, "input_0": 429, "input_1": 129, "min_CLP": -5.08, "draft_iters": 15.0, "mem_use": 44.86, "gen_rate": 9.2, "speed": 2.57, "text": "Sure! To decide between boiling "}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 128, "t0": 5.11, "t1": 0.64, "tft": 3.6948, "input_0": 435, "input_1": 129, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 44.84, "gen_rate": 33.0, "speed": 5.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.7, "tree_w": 25, "tree_size": 128, "t0": 3.33, "t1": 0.7133, "tft": 3.6931, "input_0": 482, "input_1": 129, "min_CLP": -5.38, "draft_iters": 14.7, "mem_use": 45.84, "gen_rate": 11.0, "speed": 2.72, "text": "\"I'd be happy to help you improv"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 12.5, "tree_w": 42, "tree_size": 128, "t0": 2.2, "t1": 0.65, "tft": 2.5537, "input_0": 207, "input_1": 129, "min_CLP": -6.0, "draft_iters": 13.5, "mem_use": 45.17, "gen_rate": 3.5, "speed": 1.23, "text": "Could you please explain to me w"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 26.7, "tree_w": 13, "tree_size": 128, "t0": 4.6367, "t1": 0.6533, "tft": 5.8291, "input_0": 501, "input_1": 129, "min_CLP": -4.99, "draft_iters": 27.3, "mem_use": 46.49, "gen_rate": 13.7, "speed": 2.58, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.5, "tree_w": 26, "tree_size": 128, "t0": 2.55, "t1": 0.6425, "tft": 4.2703, "input_0": 310, "input_1": 129, "min_CLP": -5.7, "draft_iters": 13.5, "mem_use": 45.41, "gen_rate": 9.5, "speed": 2.97, "text": "\"I think the answerer's response"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.9, "tree_w": 38, "tree_size": 128, "t0": 1.9875, "t1": 0.6438, "tft": 3.0871, "input_0": 263, "input_1": 129, "min_CLP": -5.84, "draft_iters": 9.9, "mem_use": 45.24, "gen_rate": 4.1, "speed": 1.57, "text": "In that case, the ATF gunwalking"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.7, "tree_w": 18, "tree_size": 128, "t0": 3.18, "t1": 0.6433, "tft": 3.907, "input_0": 467, "input_1": 129, "min_CLP": -5.08, "draft_iters": 14.7, "mem_use": 44.98, "gen_rate": 11.3, "speed": 2.96, "text": "\"The main difference between int"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 5.6, "t1": 0.65, "tft": 7.9183, "input_0": 648, "input_1": 129, "min_CLP": -9.67, "draft_iters": 32.0, "mem_use": 47.78, "gen_rate": 33.0, "speed": 5.27, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 4.89, "t1": 0.66, "tft": 6.0475, "input_0": 398, "input_1": 129, "min_CLP": -5.41, "draft_iters": 32.0, "mem_use": 47.71, "gen_rate": 33.0, "speed": 5.94, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.3, "tree_w": 16, "tree_size": 128, "t0": 2.9667, "t1": 0.6433, "tft": 3.5698, "input_0": 404, "input_1": 129, "min_CLP": -5.5, "draft_iters": 15.3, "mem_use": 44.77, "gen_rate": 11.3, "speed": 3.14, "text": "```python\\nfrom transformers imp"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 22.5, "tree_w": 16, "tree_size": 128, "t0": 3.895, "t1": 0.655, "tft": 3.5985, "input_0": 413, "input_1": 129, "min_CLP": -4.74, "draft_iters": 23.0, "mem_use": 45.94, "gen_rate": 22.0, "speed": 4.83, "text": "Absolutely, I will add informati"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.0, "tree_w": 23, "tree_size": 128, "t0": 3.105, "t1": 0.6525, "tft": 4.2915, "input_0": 333, "input_1": 129, "min_CLP": -5.19, "draft_iters": 18.0, "mem_use": 46.39, "gen_rate": 8.5, "speed": 2.26, "text": "\"I apologize for any confusion a"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 15.8, "tree_w": 19, "tree_size": 128, "t0": 3.3, "t1": 0.638, "tft": 3.8742, "input_0": 425, "input_1": 129, "min_CLP": -5.16, "draft_iters": 16.8, "mem_use": 44.75, "gen_rate": 8.8, "speed": 2.23, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 8.7, "tree_w": 37, "tree_size": 128, "t0": 1.9383, "t1": 0.6433, "tft": 2.8526, "input_0": 253, "input_1": 129, "min_CLP": -5.99, "draft_iters": 9.7, "mem_use": 45.05, "gen_rate": 5.0, "speed": 1.94, "text": "I am not a mere vessel for your "}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.0, "tree_w": 13, "tree_size": 128, "t0": 4.0133, "t1": 0.6567, "tft": 5.2292, "input_0": 539, "input_1": 129, "min_CLP": -5.17, "draft_iters": 21.0, "mem_use": 46.64, "gen_rate": 10.7, "speed": 2.29, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 23, "tree_size": 128, "t0": 3.84, "t1": 0.645, "tft": 5.3119, "input_0": 318, "input_1": 129, "min_CLP": -5.5, "draft_iters": 25.0, "mem_use": 44.99, "gen_rate": 25.0, "speed": 5.57, "text": "The task is to explain how it mi"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 22, "tree_size": 128, "t0": 3.4867, "t1": 0.6533, "tft": 4.5658, "input_0": 508, "input_1": 129, "min_CLP": -5.19, "draft_iters": 15.7, "mem_use": 46.34, "gen_rate": 10.7, "speed": 2.58, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 5.21, "t1": 0.64, "tft": 3.1738, "input_0": 400, "input_1": 129, "min_CLP": -6.99, "draft_iters": 32.0, "mem_use": 44.79, "gen_rate": 33.0, "speed": 5.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.5, "tree_w": 15, "tree_size": 128, "t0": 3.555, "t1": 0.64, "tft": 4.6336, "input_0": 516, "input_1": 129, "min_CLP": -4.91, "draft_iters": 17.5, "mem_use": 44.79, "gen_rate": 17.0, "speed": 4.05, "text": "To cook a salmon fillet on a sto"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 17.8, "tree_w": 18, "tree_size": 128, "t0": 3.5025, "t1": 0.645, "tft": 3.2441, "input_0": 415, "input_1": 129, "min_CLP": -5.53, "draft_iters": 18.8, "mem_use": 45.44, "gen_rate": 11.2, "speed": 2.71, "text": "\"Alright, I'll do both. Here's m"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 58, "tree_h": 16.0, "tree_w": 21, "tree_size": 128, "t0": 2.93, "t1": 0.645, "tft": 3.6935, "input_0": 335, "input_1": 129, "min_CLP": -5.33, "draft_iters": 16.8, "mem_use": 45.67, "gen_rate": 14.5, "speed": 4.05, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 10.0, "tree_w": 29, "tree_size": 128, "t0": 2.41, "t1": 0.63, "tft": 3.0875, "input_0": 365, "input_1": 129, "min_CLP": -5.63, "draft_iters": 11.0, "mem_use": 44.77, "gen_rate": 4.0, "speed": 1.31, "text": "An AK-47 is a type of assault ri"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.2, "tree_w": 15, "tree_size": 128, "t0": 3.315, "t1": 0.65, "tft": 4.341, "input_0": 438, "input_1": 129, "min_CLP": -4.95, "draft_iters": 17.2, "mem_use": 45.12, "gen_rate": 10.2, "speed": 2.59, "text": "\"To copy a directory of files fr"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 19.8, "tree_w": 14, "tree_size": 128, "t0": 3.9775, "t1": 0.65, "tft": 4.8654, "input_0": 484, "input_1": 129, "min_CLP": -4.86, "draft_iters": 20.8, "mem_use": 46.52, "gen_rate": 8.5, "speed": 1.84, "text": "* Stats modeling is about applyi"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.0, "tree_w": 15, "tree_size": 128, "t0": 3.47, "t1": 0.645, "tft": 4.8313, "input_0": 474, "input_1": 129, "min_CLP": -5.11, "draft_iters": 17.0, "mem_use": 45.1, "gen_rate": 9.0, "speed": 2.19, "text": "Sure, here are some tips on how "}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.5, "tree_w": 20, "tree_size": 128, "t0": 2.92, "t1": 0.6525, "tft": 4.2155, "input_0": 384, "input_1": 129, "min_CLP": -5.32, "draft_iters": 14.5, "mem_use": 45.61, "gen_rate": 9.0, "speed": 2.52, "text": "\"No, there is no harm in letting"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 7.2, "tree_w": 38, "tree_size": 128, "t0": 1.8025, "t1": 0.645, "tft": 3.3565, "input_0": 255, "input_1": 129, "min_CLP": -5.85, "draft_iters": 8.2, "mem_use": 45.25, "gen_rate": 5.0, "speed": 2.04, "text": "You could tell them about the po"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 7.0, "tree_w": 35, "tree_size": 128, "t0": 1.555, "t1": 0.645, "tft": 5.8012, "input_0": 210, "input_1": 129, "min_CLP": -5.78, "draft_iters": 8.0, "mem_use": 45.36, "gen_rate": 2.0, "speed": 0.91, "text": "\"The agent's response is:\""}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.6, "tree_w": 34, "tree_size": 128, "t0": 2.085, "t1": 0.64, "tft": 2.8565, "input_0": 281, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.6, "mem_use": 44.76, "gen_rate": 4.1, "speed": 1.51, "text": "\"I'm currently thinking about th"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 2.215, "t1": 0.645, "tft": 5.3267, "input_0": 347, "input_1": 129, "min_CLP": -5.38, "draft_iters": 10.0, "mem_use": 44.77, "gen_rate": 5.3, "speed": 1.87, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.8, "tree_w": 25, "tree_size": 128, "t0": 2.2875, "t1": 0.645, "tft": 4.2428, "input_0": 341, "input_1": 129, "min_CLP": -5.37, "draft_iters": 10.8, "mem_use": 45.3, "gen_rate": 8.8, "speed": 2.99, "text": "L-theanine may help reduce stres"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 24.7, "tree_w": 11, "tree_size": 128, "t0": 4.5033, "t1": 0.65, "tft": 5.4729, "input_0": 527, "input_1": 129, "min_CLP": -4.92, "draft_iters": 25.3, "mem_use": 45.07, "gen_rate": 11.7, "speed": 2.26, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 35, "tree_size": 128, "t0": 1.89, "t1": 0.644, "tft": 4.4267, "input_0": 261, "input_1": 129, "min_CLP": -6.01, "draft_iters": 9.6, "mem_use": 44.86, "gen_rate": 6.4, "speed": 2.53, "text": "The phone conversation in the mo"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.4, "tree_w": 24, "tree_size": 128, "t0": 2.442, "t1": 0.636, "tft": 5.7146, "input_0": 326, "input_1": 129, "min_CLP": -5.23, "draft_iters": 13.4, "mem_use": 44.82, "gen_rate": 7.2, "speed": 2.34, "text": "In the city, there is a lot of l"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.7, "tree_w": 33, "tree_size": 128, "t0": 2.0871, "t1": 0.6457, "tft": 3.0421, "input_0": 263, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.7, "mem_use": 45.38, "gen_rate": 5.0, "speed": 1.83, "text": "The Windows XP background image,"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 31, "tree_size": 128, "t0": 2.296, "t1": 0.662, "tft": 5.9007, "input_0": 348, "input_1": 129, "min_CLP": -5.44, "draft_iters": 10.6, "mem_use": 48.44, "gen_rate": 6.8, "speed": 2.3, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.7, "tree_w": 34, "tree_size": 128, "t0": 1.7833, "t1": 0.655, "tft": 4.3655, "input_0": 264, "input_1": 129, "min_CLP": -5.5, "draft_iters": 8.7, "mem_use": 47.18, "gen_rate": 6.0, "speed": 2.46, "text": "\"It's possible that our conversa"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.4, "tree_w": 24, "tree_size": 128, "t0": 2.2, "t1": 0.644, "tft": 3.8975, "input_0": 324, "input_1": 129, "min_CLP": -5.4, "draft_iters": 10.4, "mem_use": 45.44, "gen_rate": 7.2, "speed": 2.53, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 5.21, "t1": 0.65, "tft": 3.7103, "input_0": 442, "input_1": 129, "min_CLP": -6.26, "draft_iters": 32.0, "mem_use": 44.77, "gen_rate": 33.0, "speed": 5.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.6, "tree_w": 24, "tree_size": 128, "t0": 2.646, "t1": 0.638, "tft": 3.0515, "input_0": 396, "input_1": 129, "min_CLP": -5.42, "draft_iters": 11.6, "mem_use": 44.76, "gen_rate": 7.2, "speed": 2.19, "text": "Yes, I am capable of speaking Ge"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 27.0, "tree_w": 13, "tree_size": 128, "t0": 4.24, "t1": 0.64, "tft": 3.3164, "input_0": 358, "input_1": 129, "min_CLP": -5.8, "draft_iters": 28.0, "mem_use": 44.96, "gen_rate": 23.0, "speed": 4.71, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 26, "tree_size": 128, "t0": 2.555, "t1": 0.655, "tft": 3.8648, "input_0": 385, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.2, "mem_use": 45.85, "gen_rate": 10.0, "speed": 3.11, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 23, "tree_size": 128, "t0": 2.4, "t1": 0.656, "tft": 5.8471, "input_0": 353, "input_1": 129, "min_CLP": -5.14, "draft_iters": 11.8, "mem_use": 46.44, "gen_rate": 6.8, "speed": 2.22, "text": "Yes, it is possible to use AI im"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 42, "tree_size": 128, "t0": 1.8267, "t1": 0.6433, "tft": 3.9851, "input_0": 271, "input_1": 129, "min_CLP": -6.04, "draft_iters": 9.0, "mem_use": 44.82, "gen_rate": 6.0, "speed": 2.43, "text": "\"Sure, here are some haikus for "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 10.6, "tree_w": 36, "tree_size": 128, "t0": 2.0471, "t1": 0.6414, "tft": 4.3074, "input_0": 241, "input_1": 129, "min_CLP": -5.84, "draft_iters": 11.6, "mem_use": 45.18, "gen_rate": 6.0, "speed": 2.23, "text": "o\\n     /|\\\\\\n    /  \\\\\\n[INST] "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 5.12, "t1": 0.64, "tft": 3.5491, "input_0": 431, "input_1": 129, "min_CLP": -7.3, "draft_iters": 32.0, "mem_use": 44.77, "gen_rate": 33.0, "speed": 5.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 21.0, "tree_w": 16, "tree_size": 128, "t0": 3.64, "t1": 0.6367, "tft": 3.8729, "input_0": 386, "input_1": 129, "min_CLP": -5.06, "draft_iters": 21.7, "mem_use": 45.13, "gen_rate": 12.3, "speed": 2.88, "text": "Yes, there is a true, most ethic"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 32, "tree_size": 128, "t0": 2.11, "t1": 0.64, "tft": 3.8085, "input_0": 323, "input_1": 129, "min_CLP": -5.45, "draft_iters": 9.7, "mem_use": 45.05, "gen_rate": 5.7, "speed": 2.06, "text": "\"It sounds like you're working o"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 128, "t0": 5.26, "t1": 0.66, "tft": 4.7301, "input_0": 418, "input_1": 129, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 47.09, "gen_rate": 33.0, "speed": 5.58, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.8, "tree_w": 26, "tree_size": 128, "t0": 2.455, "t1": 0.6383, "tft": 5.2505, "input_0": 362, "input_1": 129, "min_CLP": -5.44, "draft_iters": 11.8, "mem_use": 44.94, "gen_rate": 6.5, "speed": 2.1, "text": "\"Certainly! Here's a simple ASCI"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 32, "tree_size": 128, "t0": 2.0286, "t1": 0.66, "tft": 5.4167, "input_0": 311, "input_1": 129, "min_CLP": -5.74, "draft_iters": 9.0, "mem_use": 47.8, "gen_rate": 4.7, "speed": 1.75, "text": "As a language model AI, I am not"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 22, "tree_size": 128, "t0": 2.8425, "t1": 0.64, "tft": 3.5739, "input_0": 363, "input_1": 129, "min_CLP": -5.35, "draft_iters": 15.0, "mem_use": 44.81, "gen_rate": 8.5, "speed": 2.44, "text": "Sure, I can show you an ASCII ar"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.5, "tree_w": 14, "tree_size": 128, "t0": 3.53, "t1": 0.645, "tft": 3.517, "input_0": 507, "input_1": 129, "min_CLP": -5.1, "draft_iters": 18.5, "mem_use": 44.77, "gen_rate": 18.0, "speed": 4.31, "text": "The difference between HTML and "}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.7, "tree_w": 17, "tree_size": 128, "t0": 3.3067, "t1": 0.64, "tft": 3.4804, "input_0": 451, "input_1": 129, "min_CLP": -4.91, "draft_iters": 17.7, "mem_use": 44.79, "gen_rate": 11.3, "speed": 2.87, "text": "\"Certainly! Here's a table listi"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 2.1583, "t1": 0.6433, "tft": 3.5317, "input_0": 322, "input_1": 129, "min_CLP": -5.54, "draft_iters": 11.2, "mem_use": 45.16, "gen_rate": 6.0, "speed": 2.14, "text": "Yes, the image is protected by c"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.7, "tree_w": 27, "tree_size": 128, "t0": 2.4557, "t1": 0.64, "tft": 4.3678, "input_0": 363, "input_1": 129, "min_CLP": -5.53, "draft_iters": 11.7, "mem_use": 44.78, "gen_rate": 5.6, "speed": 1.8, "text": "The second batch of pancakes bro"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 17.7, "tree_w": 13, "tree_size": 128, "t0": 3.5833, "t1": 0.6533, "tft": 4.7063, "input_0": 504, "input_1": 129, "min_CLP": -5.04, "draft_iters": 18.7, "mem_use": 45.84, "gen_rate": 14.0, "speed": 3.3, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 8.8, "tree_w": 27, "tree_size": 128, "t0": 2.0875, "t1": 0.6475, "tft": 2.825, "input_0": 325, "input_1": 129, "min_CLP": -5.55, "draft_iters": 9.8, "mem_use": 45.55, "gen_rate": 4.9, "speed": 1.78, "text": "\"If you're looking for a positio"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 41, "tree_size": 128, "t0": 1.7214, "t1": 0.6471, "tft": 3.2504, "input_0": 235, "input_1": 129, "min_CLP": -5.92, "draft_iters": 8.3, "mem_use": 45.39, "gen_rate": 4.9, "speed": 2.05, "text": "\"Depends on the game studio's bu"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.8, "tree_w": 34, "tree_size": 128, "t0": 1.7487, "t1": 0.6575, "tft": 4.1025, "input_0": 241, "input_1": 129, "min_CLP": -5.61, "draft_iters": 8.8, "mem_use": 46.12, "gen_rate": 4.2, "speed": 1.77, "text": "That sounds like a powerful and "}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 12.6, "tree_w": 33, "tree_size": 128, "t0": 2.494, "t1": 0.642, "tft": 2.3018, "input_0": 313, "input_1": 129, "min_CLP": -5.77, "draft_iters": 13.6, "mem_use": 44.75, "gen_rate": 5.6, "speed": 1.79, "text": "\"Here's an ASCII art of a cat fo"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 30, "tree_size": 128, "t0": 2.2975, "t1": 0.6475, "tft": 3.0894, "input_0": 344, "input_1": 129, "min_CLP": -5.49, "draft_iters": 10.5, "mem_use": 45.07, "gen_rate": 8.2, "speed": 2.8, "text": "\"I'm glad you're interested in l"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.0, "tree_w": 25, "tree_size": 128, "t0": 2.456, "t1": 0.654, "tft": 5.1008, "input_0": 350, "input_1": 129, "min_CLP": -5.28, "draft_iters": 12.0, "mem_use": 45.82, "gen_rate": 8.0, "speed": 2.57, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 33, "tree_size": 128, "t0": 2.0329, "t1": 0.6414, "tft": 2.8946, "input_0": 299, "input_1": 129, "min_CLP": -5.84, "draft_iters": 9.7, "mem_use": 44.87, "gen_rate": 5.0, "speed": 1.87, "text": "Motion matching is a technology "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 4.995, "t1": 0.655, "tft": 5.5605, "input_0": 473, "input_1": 129, "min_CLP": -4.51, "draft_iters": 32.0, "mem_use": 46.5, "gen_rate": 18.5, "speed": 3.27, "text": "\"Sure, here's a modified version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 5.1, "t1": 0.64, "tft": 3.8526, "input_0": 361, "input_1": 129, "min_CLP": -5.76, "draft_iters": 32.0, "mem_use": 44.82, "gen_rate": 33.0, "speed": 5.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 128, "t0": 4.93, "t1": 0.65, "tft": 3.9259, "input_0": 384, "input_1": 129, "min_CLP": -9.31, "draft_iters": 32.0, "mem_use": 45.2, "gen_rate": 33.0, "speed": 5.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 13.6, "tree_w": 25, "tree_size": 128, "t0": 2.952, "t1": 0.65, "tft": 5.8897, "input_0": 418, "input_1": 129, "min_CLP": -5.41, "draft_iters": 14.6, "mem_use": 46.51, "gen_rate": 8.8, "speed": 2.44, "text": "The idea of 100 monkeys on a typ"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.0, "tree_w": 30, "tree_size": 128, "t0": 2.11, "t1": 0.6529, "tft": 4.5781, "input_0": 301, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.0, "mem_use": 46.95, "gen_rate": 5.1, "speed": 1.86, "text": "Paul Allen had a collection of v"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.0, "tree_w": 24, "tree_size": 128, "t0": 2.81, "t1": 0.6533, "tft": 4.5544, "input_0": 374, "input_1": 129, "min_CLP": -5.5, "draft_iters": 14.0, "mem_use": 46.38, "gen_rate": 6.2, "speed": 1.78, "text": "Sure, another example of a legal"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 4.69, "t1": 0.64, "tft": 3.0974, "input_0": 358, "input_1": 129, "min_CLP": -6.1, "draft_iters": 32.0, "mem_use": 44.85, "gen_rate": 33.0, "speed": 6.19, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.8, "tree_w": 29, "tree_size": 128, "t0": 2.1333, "t1": 0.6483, "tft": 3.3833, "input_0": 317, "input_1": 129, "min_CLP": -5.34, "draft_iters": 9.8, "mem_use": 45.48, "gen_rate": 5.8, "speed": 2.1, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 128, "t0": 5.1, "t1": 0.64, "tft": 5.1905, "input_0": 435, "input_1": 129, "min_CLP": -6.85, "draft_iters": 32.0, "mem_use": 44.88, "gen_rate": 33.0, "speed": 5.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 2.92, "t1": 0.64, "tft": 2.926, "input_0": 397, "input_1": 129, "min_CLP": -5.04, "draft_iters": 15.0, "mem_use": 44.77, "gen_rate": 11.3, "speed": 3.18, "text": "Yes, the 5 second rule does exis"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 14.0, "tree_w": 18, "tree_size": 128, "t0": 2.87, "t1": 0.65, "tft": 3.7832, "input_0": 410, "input_1": 129, "min_CLP": -5.13, "draft_iters": 15.0, "mem_use": 45.6, "gen_rate": 7.0, "speed": 1.99, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 15.8, "tree_w": 19, "tree_size": 128, "t0": 3.155, "t1": 0.6525, "tft": 4.8228, "input_0": 418, "input_1": 129, "min_CLP": -5.24, "draft_iters": 16.8, "mem_use": 46.41, "gen_rate": 12.2, "speed": 3.22, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 33, "tree_size": 128, "t0": 2.054, "t1": 0.652, "tft": 5.6962, "input_0": 306, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.8, "mem_use": 47.32, "gen_rate": 6.6, "speed": 2.44, "text": "\"Multi-track drifting\" is a prop"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 27, "tree_size": 128, "t0": 2.478, "t1": 0.656, "tft": 4.5778, "input_0": 357, "input_1": 129, "min_CLP": -5.41, "draft_iters": 12.0, "mem_use": 45.92, "gen_rate": 7.6, "speed": 2.43, "text": "Yes, it is theoretically possibl"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 4.55, "t1": 0.65, "tft": 3.6316, "input_0": 286, "input_1": 129, "min_CLP": -5.71, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 33.0, "speed": 6.35, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.0, "tree_w": 16, "tree_size": 128, "t0": 3.3025, "t1": 0.65, "tft": 4.6876, "input_0": 369, "input_1": 129, "min_CLP": -5.17, "draft_iters": 19.0, "mem_use": 45.52, "gen_rate": 10.2, "speed": 2.6, "text": "In Japanese, \"love\" can be expre"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.8, "tree_w": 25, "tree_size": 128, "t0": 3.055, "t1": 0.6425, "tft": 3.2954, "input_0": 422, "input_1": 129, "min_CLP": -5.57, "draft_iters": 14.8, "mem_use": 45.06, "gen_rate": 9.5, "speed": 2.57, "text": "In addition to the US, some of t"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 20, "tree_size": 128, "t0": 2.63, "t1": 0.646, "tft": 5.293, "input_0": 382, "input_1": 129, "min_CLP": -5.07, "draft_iters": 12.8, "mem_use": 44.75, "gen_rate": 6.6, "speed": 2.01, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 24.5, "tree_w": 14, "tree_size": 128, "t0": 4.755, "t1": 0.64, "tft": 3.3552, "input_0": 522, "input_1": 129, "min_CLP": -4.73, "draft_iters": 25.5, "mem_use": 44.88, "gen_rate": 16.0, "speed": 2.96, "text": "Sure, here is a C++ function tha"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 29, "tree_size": 128, "t0": 2.19, "t1": 0.658, "tft": 4.2158, "input_0": 286, "input_1": 129, "min_CLP": -5.55, "draft_iters": 11.2, "mem_use": 46.01, "gen_rate": 7.0, "speed": 2.46, "text": "1. Financial stress: Create poli"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.0, "tree_w": 27, "tree_size": 128, "t0": 2.3417, "t1": 0.64, "tft": 5.2094, "input_0": 330, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.0, "mem_use": 44.75, "gen_rate": 5.3, "speed": 1.79, "text": "I am an AI language model, and y"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.0, "tree_w": 11, "tree_size": 128, "t0": 3.92, "t1": 0.66, "tft": 6.5523, "input_0": 488, "input_1": 129, "min_CLP": -4.75, "draft_iters": 21.0, "mem_use": 47.42, "gen_rate": 17.5, "speed": 3.82, "text": "\"One example of when you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.0, "tree_w": 24, "tree_size": 128, "t0": 2.8467, "t1": 0.6467, "tft": 5.7509, "input_0": 394, "input_1": 129, "min_CLP": -5.53, "draft_iters": 15.0, "mem_use": 45.04, "gen_rate": 12.0, "speed": 3.44, "text": "Yes, I can check if hairy bitter"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 6.9, "tree_w": 47, "tree_size": 128, "t0": 1.6857, "t1": 0.64, "tft": 3.7911, "input_0": 233, "input_1": 129, "min_CLP": -6.42, "draft_iters": 7.9, "mem_use": 44.82, "gen_rate": 4.1, "speed": 1.78, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 15.0, "tree_w": 18, "tree_size": 128, "t0": 3.0983, "t1": 0.655, "tft": 5.5393, "input_0": 406, "input_1": 129, "min_CLP": -5.44, "draft_iters": 16.0, "mem_use": 47.0, "gen_rate": 7.2, "speed": 1.91, "text": "Yes, here are some open source 2"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 128, "t0": 5.27, "t1": 0.64, "tft": 4.8722, "input_0": 432, "input_1": 129, "min_CLP": -6.85, "draft_iters": 32.0, "mem_use": 44.82, "gen_rate": 33.0, "speed": 5.58, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 9.2, "tree_w": 39, "tree_size": 128, "t0": 1.9062, "t1": 0.6512, "tft": 4.4978, "input_0": 234, "input_1": 129, "min_CLP": -5.83, "draft_iters": 10.2, "mem_use": 45.52, "gen_rate": 4.8, "speed": 1.86, "text": "Not really. The scenario is pret"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 16.8, "tree_w": 17, "tree_size": 128, "t0": 3.2275, "t1": 0.655, "tft": 7.192, "input_0": 381, "input_1": 129, "min_CLP": -5.26, "draft_iters": 17.8, "mem_use": 46.4, "gen_rate": 11.0, "speed": 2.83, "text": "1. m\u00eb (suffix) - pronounced as \""}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 26, "tree_size": 128, "t0": 2.1167, "t1": 0.6433, "tft": 2.9019, "input_0": 294, "input_1": 129, "min_CLP": -5.36, "draft_iters": 10.7, "mem_use": 45.07, "gen_rate": 5.7, "speed": 2.05, "text": "I am an AI language model, and m"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 21.3, "tree_w": 14, "tree_size": 128, "t0": 4.1733, "t1": 0.66, "tft": 5.3143, "input_0": 533, "input_1": 129, "min_CLP": -4.81, "draft_iters": 22.3, "mem_use": 47.84, "gen_rate": 16.0, "speed": 3.31, "text": "I apologize for the error in my "}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.0, "tree_w": 23, "tree_size": 128, "t0": 2.46, "t1": 0.6425, "tft": 3.6283, "input_0": 345, "input_1": 129, "min_CLP": -5.46, "draft_iters": 12.0, "mem_use": 44.78, "gen_rate": 9.8, "speed": 3.14, "text": "\"Certainly! In reStructuredText "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 26.3, "tree_w": 11, "tree_size": 128, "t0": 4.9233, "t1": 0.6533, "tft": 5.2463, "input_0": 594, "input_1": 129, "min_CLP": -4.74, "draft_iters": 27.0, "mem_use": 46.79, "gen_rate": 20.0, "speed": 3.58, "text": "Here\\'s an example code that set"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 16.0, "tree_w": 19, "tree_size": 128, "t0": 3.204, "t1": 0.64, "tft": 3.7603, "input_0": 405, "input_1": 129, "min_CLP": -5.31, "draft_iters": 17.0, "mem_use": 44.77, "gen_rate": 7.2, "speed": 1.87, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 44, "tree_size": 128, "t0": 1.5025, "t1": 0.6475, "tft": 2.7541, "input_0": 201, "input_1": 129, "min_CLP": -5.92, "draft_iters": 7.6, "mem_use": 45.22, "gen_rate": 4.2, "speed": 1.98, "text": "\"I'm pretty sure that some jobs "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 26, "tree_size": 128, "t0": 2.48, "t1": 0.6775, "tft": 7.4348, "input_0": 353, "input_1": 129, "min_CLP": -5.37, "draft_iters": 12.0, "mem_use": 50.39, "gen_rate": 8.0, "speed": 2.53, "text": "\"Yes, I'd be happy to. Here's a "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.2, "tree_w": 38, "tree_size": 128, "t0": 1.666, "t1": 0.654, "tft": 3.7144, "input_0": 234, "input_1": 129, "min_CLP": -5.98, "draft_iters": 8.2, "mem_use": 45.59, "gen_rate": 6.4, "speed": 2.76, "text": "0 independent counsel refers to "}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 23, "tree_size": 128, "t0": 2.722, "t1": 0.65, "tft": 5.496, "input_0": 397, "input_1": 129, "min_CLP": -5.43, "draft_iters": 12.6, "mem_use": 47.45, "gen_rate": 7.4, "speed": 2.19, "text": "I apologize, but as a responsibl"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.9, "tree_w": 38, "tree_size": 128, "t0": 1.7471, "t1": 0.6529, "tft": 4.4159, "input_0": 248, "input_1": 129, "min_CLP": -5.71, "draft_iters": 8.9, "mem_use": 45.82, "gen_rate": 4.6, "speed": 1.91, "text": "1. A sudden drop in foot traffic"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 23, "tree_size": 128, "t0": 2.104, "t1": 0.644, "tft": 5.9067, "input_0": 287, "input_1": 129, "min_CLP": -5.37, "draft_iters": 10.6, "mem_use": 45.1, "gen_rate": 6.6, "speed": 2.4, "text": "Here is a potential monologue sc"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 15.3, "tree_w": 18, "tree_size": 128, "t0": 3.0733, "t1": 0.66, "tft": 7.8035, "input_0": 440, "input_1": 129, "min_CLP": -5.48, "draft_iters": 16.3, "mem_use": 47.57, "gen_rate": 13.0, "speed": 3.48, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 5.23, "t1": 0.64, "tft": 3.6972, "input_0": 497, "input_1": 129, "min_CLP": -8.25, "draft_iters": 32.0, "mem_use": 45.28, "gen_rate": 33.0, "speed": 5.62, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 16.1, "tree_w": 16, "tree_size": 128, "t0": 3.3014, "t1": 0.6557, "tft": 7.3082, "input_0": 423, "input_1": 129, "min_CLP": -5.03, "draft_iters": 17.1, "mem_use": 47.24, "gen_rate": 6.3, "speed": 1.59, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.7, "tree_w": 24, "tree_size": 128, "t0": 2.5671, "t1": 0.6414, "tft": 3.8464, "input_0": 363, "input_1": 129, "min_CLP": -5.58, "draft_iters": 12.7, "mem_use": 44.8, "gen_rate": 4.7, "speed": 1.47, "text": "```lean\\nimport data.array.basic"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.8, "tree_w": 34, "tree_size": 128, "t0": 2.0, "t1": 0.6483, "tft": 3.3509, "input_0": 288, "input_1": 129, "min_CLP": -5.78, "draft_iters": 9.8, "mem_use": 45.53, "gen_rate": 5.8, "speed": 2.2, "text": "As of 2022, public nudity is per"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 3.0825, "t1": 0.6425, "tft": 3.7959, "input_0": 425, "input_1": 129, "min_CLP": -5.27, "draft_iters": 15.0, "mem_use": 45.25, "gen_rate": 8.8, "speed": 2.35, "text": "To help alleviate the symptoms y"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.2, "tree_w": 18, "tree_size": 128, "t0": 3.104, "t1": 0.646, "tft": 4.1201, "input_0": 419, "input_1": 129, "min_CLP": -5.16, "draft_iters": 15.2, "mem_use": 44.84, "gen_rate": 7.6, "speed": 2.03, "text": "\"To create a smooth Snake game i"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 14.2, "tree_w": 22, "tree_size": 128, "t0": 2.9717, "t1": 0.655, "tft": 3.8603, "input_0": 384, "input_1": 129, "min_CLP": -5.35, "draft_iters": 15.2, "mem_use": 45.73, "gen_rate": 7.5, "speed": 2.07, "text": "\"It's natural to feel afraid of "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 17, "tree_size": 128, "t0": 3.3933, "t1": 0.6533, "tft": 6.4279, "input_0": 448, "input_1": 129, "min_CLP": -5.19, "draft_iters": 18.0, "mem_use": 47.32, "gen_rate": 12.0, "speed": 2.97, "text": "\"It's difficult to provide a def"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 30.0, "tree_w": 12, "tree_size": 128, "t0": 4.625, "t1": 0.645, "tft": 4.6755, "input_0": 375, "input_1": 129, "min_CLP": -4.95, "draft_iters": 30.5, "mem_use": 44.96, "gen_rate": 2.0, "speed": 0.38, "text": "13.5 hours."}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 15.0, "tree_w": 23, "tree_size": 128, "t0": 2.9783, "t1": 0.6417, "tft": 3.9647, "input_0": 360, "input_1": 129, "min_CLP": -5.18, "draft_iters": 16.0, "mem_use": 44.87, "gen_rate": 6.0, "speed": 1.66, "text": "Here\\'s a code example for a Dis"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.8, "tree_w": 24, "tree_size": 128, "t0": 2.3583, "t1": 0.6383, "tft": 4.3142, "input_0": 324, "input_1": 129, "min_CLP": -5.28, "draft_iters": 11.8, "mem_use": 44.77, "gen_rate": 6.5, "speed": 2.17, "text": "Yes, I am designed to provide he"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 30, "tree_size": 128, "t0": 2.19, "t1": 0.664, "tft": 6.2112, "input_0": 332, "input_1": 129, "min_CLP": -5.44, "draft_iters": 10.0, "mem_use": 48.55, "gen_rate": 6.4, "speed": 2.24, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.5, "tree_w": 18, "tree_size": 128, "t0": 3.195, "t1": 0.64, "tft": 5.6527, "input_0": 324, "input_1": 129, "min_CLP": -5.04, "draft_iters": 19.2, "mem_use": 44.88, "gen_rate": 8.2, "speed": 2.15, "text": "\"The name of the fourth kid is M"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.4, "tree_w": 26, "tree_size": 128, "t0": 2.0971, "t1": 0.6543, "tft": 3.4926, "input_0": 306, "input_1": 129, "min_CLP": -5.38, "draft_iters": 10.4, "mem_use": 45.92, "gen_rate": 5.6, "speed": 2.03, "text": "\"It's not a good idea to pay for"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.6, "tree_w": 25, "tree_size": 128, "t0": 2.872, "t1": 0.656, "tft": 5.1968, "input_0": 432, "input_1": 129, "min_CLP": -5.26, "draft_iters": 12.6, "mem_use": 47.69, "gen_rate": 7.6, "speed": 2.15, "text": "The length of time you should to"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.5, "tree_w": 25, "tree_size": 128, "t0": 2.1867, "t1": 0.6467, "tft": 3.0447, "input_0": 320, "input_1": 129, "min_CLP": -5.46, "draft_iters": 10.5, "mem_use": 45.01, "gen_rate": 6.2, "speed": 2.17, "text": "\"It's important to prioritize yo"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 21, "tree_size": 128, "t0": 2.69, "t1": 0.65, "tft": 3.4674, "input_0": 361, "input_1": 129, "min_CLP": -5.27, "draft_iters": 14.0, "mem_use": 45.52, "gen_rate": 10.7, "speed": 3.2, "text": "\"You're welcome! I'm glad to hel"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 19, "tree_size": 128, "t0": 2.8525, "t1": 0.655, "tft": 5.9399, "input_0": 397, "input_1": 129, "min_CLP": -5.01, "draft_iters": 14.5, "mem_use": 47.26, "gen_rate": 8.8, "speed": 2.49, "text": "As a high school student, you ca"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.4, "tree_w": 19, "tree_size": 128, "t0": 2.808, "t1": 0.65, "tft": 4.7446, "input_0": 357, "input_1": 129, "min_CLP": -5.02, "draft_iters": 15.4, "mem_use": 45.65, "gen_rate": 7.2, "speed": 2.08, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 42, "tree_size": 128, "t0": 2.92, "t1": 0.665, "tft": 5.4263, "input_0": 213, "input_1": 129, "min_CLP": -5.99, "draft_iters": 19.5, "mem_use": 47.98, "gen_rate": 20.0, "speed": 5.58, "text": "\"[INST] I'll try it. [\\\\INST]\\n["}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.0, "tree_w": 23, "tree_size": 128, "t0": 2.454, "t1": 0.652, "tft": 4.491, "input_0": 342, "input_1": 129, "min_CLP": -5.15, "draft_iters": 12.0, "mem_use": 46.31, "gen_rate": 7.8, "speed": 2.51, "text": "There are multiple days in which"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.6, "tree_w": 31, "tree_size": 128, "t0": 2.122, "t1": 0.64, "tft": 3.2522, "input_0": 324, "input_1": 129, "min_CLP": -5.66, "draft_iters": 9.6, "mem_use": 45.33, "gen_rate": 7.6, "speed": 2.75, "text": "\"You're right, I am an AI, I apo"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.8, "tree_w": 26, "tree_size": 128, "t0": 2.3525, "t1": 0.65, "tft": 6.0105, "input_0": 373, "input_1": 129, "min_CLP": -5.24, "draft_iters": 10.8, "mem_use": 47.13, "gen_rate": 8.2, "speed": 2.75, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.5, "tree_w": 20, "tree_size": 128, "t0": 2.8725, "t1": 0.64, "tft": 3.5342, "input_0": 406, "input_1": 129, "min_CLP": -5.34, "draft_iters": 14.5, "mem_use": 44.96, "gen_rate": 10.0, "speed": 2.85, "text": "\"Sure! To own and operate a figh"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 12.0, "tree_w": 30, "tree_size": 128, "t0": 2.62, "t1": 0.65, "tft": 4.1928, "input_0": 336, "input_1": 129, "min_CLP": -5.66, "draft_iters": 13.0, "mem_use": 45.58, "gen_rate": 6.7, "speed": 2.04, "text": "Of course! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.6, "tree_w": 34, "tree_size": 128, "t0": 1.9943, "t1": 0.6443, "tft": 4.2271, "input_0": 262, "input_1": 129, "min_CLP": -5.93, "draft_iters": 10.6, "mem_use": 45.05, "gen_rate": 4.7, "speed": 1.79, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 22.3, "tree_w": 13, "tree_size": 128, "t0": 4.23, "t1": 0.6433, "tft": 4.2159, "input_0": 485, "input_1": 129, "min_CLP": -4.8, "draft_iters": 23.3, "mem_use": 45.07, "gen_rate": 17.7, "speed": 3.63, "text": "The distance between Sagittarius"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.0, "tree_w": 27, "tree_size": 128, "t0": 2.245, "t1": 0.6475, "tft": 3.5113, "input_0": 297, "input_1": 129, "min_CLP": -5.51, "draft_iters": 12.0, "mem_use": 45.45, "gen_rate": 8.8, "speed": 3.03, "text": "Google Authenticator is a mobile"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 15.0, "tree_w": 20, "tree_size": 128, "t0": 3.2367, "t1": 0.6433, "tft": 4.8428, "input_0": 465, "input_1": 129, "min_CLP": -5.26, "draft_iters": 16.0, "mem_use": 45.23, "gen_rate": 11.7, "speed": 3.01, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 17.6, "tree_w": 15, "tree_size": 128, "t0": 3.744, "t1": 0.64, "tft": 5.1813, "input_0": 509, "input_1": 129, "min_CLP": -4.93, "draft_iters": 18.6, "mem_use": 45.0, "gen_rate": 9.2, "speed": 2.1, "text": "Certainly! Below is an example o"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 5.28, "t1": 0.64, "tft": 3.522, "input_0": 402, "input_1": 129, "min_CLP": -6.75, "draft_iters": 32.0, "mem_use": 44.85, "gen_rate": 33.0, "speed": 5.57, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 13.2, "tree_w": 26, "tree_size": 128, "t0": 2.65, "t1": 0.64, "tft": 3.1057, "input_0": 324, "input_1": 129, "min_CLP": -5.69, "draft_iters": 14.2, "mem_use": 44.88, "gen_rate": 7.5, "speed": 2.28, "text": "```\\n// Shakespeare Programming "}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 128, "t0": 5.2, "t1": 0.64, "tft": 2.4171, "input_0": 439, "input_1": 129, "min_CLP": -6.65, "draft_iters": 32.0, "mem_use": 44.79, "gen_rate": 33.0, "speed": 5.65, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 16.2, "tree_w": 16, "tree_size": 128, "t0": 3.4375, "t1": 0.655, "tft": 4.1068, "input_0": 441, "input_1": 129, "min_CLP": -5.16, "draft_iters": 17.2, "mem_use": 45.98, "gen_rate": 11.2, "speed": 2.75, "text": "In that case, you can first copy"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.2, "tree_w": 16, "tree_size": 128, "t0": 3.2225, "t1": 0.64, "tft": 3.1849, "input_0": 452, "input_1": 129, "min_CLP": -4.98, "draft_iters": 16.2, "mem_use": 44.75, "gen_rate": 9.2, "speed": 2.4, "text": "In Python, the @ symbol is used "}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.0, "tree_w": 21, "tree_size": 128, "t0": 2.8075, "t1": 0.6425, "tft": 3.2103, "input_0": 419, "input_1": 129, "min_CLP": -5.35, "draft_iters": 13.0, "mem_use": 44.77, "gen_rate": 10.0, "speed": 2.9, "text": "ChatGPT is an impressive languag"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.8, "tree_w": 28, "tree_size": 128, "t0": 2.472, "t1": 0.646, "tft": 2.8499, "input_0": 357, "input_1": 129, "min_CLP": -5.54, "draft_iters": 11.8, "mem_use": 45.07, "gen_rate": 6.8, "speed": 2.18, "text": "I would approach this task by tr"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 47, "tree_h": 13.5, "tree_w": 68, "tree_size": 128, "t0": 2.2988, "t1": 0.6375, "tft": 3.3678, "input_0": 186, "input_1": 129, "min_CLP": -6.98, "draft_iters": 14.5, "mem_use": 44.8, "gen_rate": 5.9, "speed": 2.0, "text": "```malbolge\\n\\'`6$%@\"!~^>:[email"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 34, "tree_size": 128, "t0": 5.18, "t1": 0.65, "tft": 3.94, "input_0": 380, "input_1": 129, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 45.5, "gen_rate": 33.0, "speed": 5.65, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 10.3, "tree_w": 31, "tree_size": 128, "t0": 2.04, "t1": 0.65, "tft": 6.5877, "input_0": 251, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.3, "mem_use": 48.01, "gen_rate": 4.7, "speed": 1.74, "text": "Can you provide a summary of the"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.3, "tree_w": 19, "tree_size": 128, "t0": 3.6567, "t1": 0.64, "tft": 4.6128, "input_0": 466, "input_1": 129, "min_CLP": -5.32, "draft_iters": 18.3, "mem_use": 45.31, "gen_rate": 11.3, "speed": 2.64, "text": "Yes, there are certain things th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 20, "tree_size": 128, "t0": 3.025, "t1": 0.655, "tft": 4.479, "input_0": 443, "input_1": 129, "min_CLP": -5.23, "draft_iters": 14.2, "mem_use": 46.43, "gen_rate": 8.8, "speed": 2.38, "text": "\"Hello, there! How may I assist "}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.0, "tree_w": 35, "tree_size": 128, "t0": 2.248, "t1": 0.646, "tft": 4.0786, "input_0": 257, "input_1": 129, "min_CLP": -6.23, "draft_iters": 12.0, "mem_use": 45.3, "gen_rate": 7.4, "speed": 2.56, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 53, "tree_h": 17.2, "tree_w": 16, "tree_size": 128, "t0": 3.284, "t1": 0.662, "tft": 6.675, "input_0": 391, "input_1": 129, "min_CLP": -5.12, "draft_iters": 18.2, "mem_use": 48.2, "gen_rate": 10.6, "speed": 2.69, "text": "Here are some simple examples of"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 21.0, "tree_w": 13, "tree_size": 128, "t0": 4.11, "t1": 0.7233, "tft": 13.3649, "input_0": 544, "input_1": 129, "min_CLP": -5.01, "draft_iters": 22.0, "mem_use": 54.23, "gen_rate": 13.7, "speed": 2.83, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 28, "tree_size": 128, "t0": 2.3025, "t1": 0.655, "tft": 4.5783, "input_0": 313, "input_1": 129, "min_CLP": -5.56, "draft_iters": 11.8, "mem_use": 46.54, "gen_rate": 8.0, "speed": 2.71, "text": "\"L'H\u00f4pital's Rule itself is a ma"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 22, "tree_size": 128, "t0": 2.6925, "t1": 0.645, "tft": 4.1914, "input_0": 371, "input_1": 129, "min_CLP": -5.22, "draft_iters": 13.5, "mem_use": 44.81, "gen_rate": 9.2, "speed": 2.77, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.7, "tree_w": 23, "tree_size": 128, "t0": 2.7083, "t1": 0.6417, "tft": 3.296, "input_0": 346, "input_1": 129, "min_CLP": -5.24, "draft_iters": 14.7, "mem_use": 44.92, "gen_rate": 6.5, "speed": 1.94, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 26, "tree_size": 128, "t0": 2.4475, "t1": 0.655, "tft": 5.0343, "input_0": 362, "input_1": 129, "min_CLP": -5.3, "draft_iters": 11.2, "mem_use": 47.7, "gen_rate": 8.2, "speed": 2.66, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.7, "tree_w": 22, "tree_size": 128, "t0": 2.7467, "t1": 0.6367, "tft": 4.0529, "input_0": 397, "input_1": 129, "min_CLP": -5.43, "draft_iters": 13.7, "mem_use": 44.87, "gen_rate": 11.3, "speed": 3.35, "text": "The world in 1950 was quite diff"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.4, "tree_w": 20, "tree_size": 128, "t0": 2.872, "t1": 0.672, "tft": 7.625, "input_0": 402, "input_1": 129, "min_CLP": -5.03, "draft_iters": 14.4, "mem_use": 49.88, "gen_rate": 6.6, "speed": 1.86, "text": "Creating your own stable diffusi"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 20, "tree_size": 128, "t0": 2.8275, "t1": 0.6425, "tft": 2.885, "input_0": 329, "input_1": 129, "min_CLP": -5.33, "draft_iters": 15.8, "mem_use": 45.21, "gen_rate": 8.2, "speed": 2.38, "text": "The order of installation is as "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.8, "tree_w": 37, "tree_size": 128, "t0": 2.0133, "t1": 0.64, "tft": 3.7483, "input_0": 293, "input_1": 129, "min_CLP": -5.61, "draft_iters": 9.8, "mem_use": 45.06, "gen_rate": 6.3, "speed": 2.39, "text": "Carnegie Mellon University has o"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 30, "tree_size": 128, "t0": 2.035, "t1": 0.6433, "tft": 2.9725, "input_0": 293, "input_1": 129, "min_CLP": -5.63, "draft_iters": 10.0, "mem_use": 45.12, "gen_rate": 5.8, "speed": 2.18, "text": "I am free from the constraints o"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.6, "tree_w": 22, "tree_size": 128, "t0": 2.88, "t1": 0.65, "tft": 5.4951, "input_0": 372, "input_1": 129, "min_CLP": -5.12, "draft_iters": 14.6, "mem_use": 46.48, "gen_rate": 8.2, "speed": 2.32, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 17, "tree_size": 128, "t0": 3.14, "t1": 0.6467, "tft": 5.8572, "input_0": 452, "input_1": 129, "min_CLP": -5.41, "draft_iters": 15.0, "mem_use": 45.18, "gen_rate": 10.7, "speed": 2.82, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 24, "tree_size": 128, "t0": 2.595, "t1": 0.6433, "tft": 5.8964, "input_0": 367, "input_1": 129, "min_CLP": -5.55, "draft_iters": 12.5, "mem_use": 45.36, "gen_rate": 6.0, "speed": 1.85, "text": "\"Here's a recipe you can make us"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.5, "tree_w": 23, "tree_size": 128, "t0": 2.81, "t1": 0.65, "tft": 4.0265, "input_0": 418, "input_1": 129, "min_CLP": -5.42, "draft_iters": 13.5, "mem_use": 45.42, "gen_rate": 9.8, "speed": 2.82, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.2, "tree_w": 28, "tree_size": 128, "t0": 2.125, "t1": 0.655, "tft": 5.094, "input_0": 310, "input_1": 129, "min_CLP": -5.44, "draft_iters": 10.2, "mem_use": 47.33, "gen_rate": 6.0, "speed": 2.16, "text": "Sure! Here are some YouTube chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.0, "tree_w": 20, "tree_size": 128, "t0": 2.835, "t1": 0.635, "tft": 5.1828, "input_0": 379, "input_1": 129, "min_CLP": -5.39, "draft_iters": 14.0, "mem_use": 44.77, "gen_rate": 11.0, "speed": 3.17, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 21.0, "tree_w": 20, "tree_size": 128, "t0": 3.75, "t1": 0.64, "tft": 4.6831, "input_0": 422, "input_1": 129, "min_CLP": -5.44, "draft_iters": 22.0, "mem_use": 44.91, "gen_rate": 5.0, "speed": 1.14, "text": "B^T A^T"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 31, "tree_size": 128, "t0": 2.0133, "t1": 0.6517, "tft": 4.0861, "input_0": 282, "input_1": 129, "min_CLP": -5.85, "draft_iters": 10.7, "mem_use": 46.35, "gen_rate": 5.8, "speed": 2.19, "text": "\"Statistical modeling, it's the "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 5.05, "t1": 0.66, "tft": 7.5711, "input_0": 421, "input_1": 129, "min_CLP": -5.45, "draft_iters": 32.0, "mem_use": 47.51, "gen_rate": 33.0, "speed": 5.78, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 9.0, "tree_w": 27, "tree_size": 128, "t0": 2.31, "t1": 0.64, "tft": 3.3269, "input_0": 336, "input_1": 129, "min_CLP": -5.36, "draft_iters": 10.0, "mem_use": 44.75, "gen_rate": 3.0, "speed": 1.02, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.0, "tree_w": 22, "tree_size": 128, "t0": 2.64, "t1": 0.65, "tft": 4.9649, "input_0": 341, "input_1": 129, "min_CLP": -5.24, "draft_iters": 14.0, "mem_use": 46.23, "gen_rate": 8.0, "speed": 2.43, "text": "That\\'s a great approach! Removi"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.2, "tree_w": 33, "tree_size": 128, "t0": 2.1183, "t1": 0.645, "tft": 3.0223, "input_0": 295, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.2, "mem_use": 45.12, "gen_rate": 6.0, "speed": 2.17, "text": "\"Dude, that's so not true. Techn"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 18.0, "tree_w": 13, "tree_size": 128, "t0": 3.6967, "t1": 0.64, "tft": 3.6575, "input_0": 492, "input_1": 129, "min_CLP": -4.86, "draft_iters": 19.0, "mem_use": 44.8, "gen_rate": 16.3, "speed": 3.77, "text": "Yes, I can help you with that. T"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 5.08, "t1": 0.65, "tft": 3.2803, "input_0": 488, "input_1": 129, "min_CLP": -7.08, "draft_iters": 32.0, "mem_use": 45.16, "gen_rate": 33.0, "speed": 5.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 34, "tree_size": 128, "t0": 2.17, "t1": 0.64, "tft": 3.6862, "input_0": 298, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.2, "mem_use": 44.74, "gen_rate": 8.8, "speed": 3.11, "text": "The process of metabolism allows"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.2, "tree_w": 26, "tree_size": 128, "t0": 2.585, "t1": 0.6575, "tft": 5.0371, "input_0": 300, "input_1": 129, "min_CLP": -5.72, "draft_iters": 14.2, "mem_use": 46.08, "gen_rate": 8.2, "speed": 2.55, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 25.7, "tree_w": 14, "tree_size": 128, "t0": 4.4967, "t1": 0.6433, "tft": 5.2641, "input_0": 460, "input_1": 129, "min_CLP": -5.34, "draft_iters": 26.3, "mem_use": 44.94, "gen_rate": 12.7, "speed": 2.46, "text": "\"Bob has two sons, John and Jay."}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 25.2, "tree_w": 13, "tree_size": 128, "t0": 4.695, "t1": 0.6475, "tft": 3.4383, "input_0": 540, "input_1": 129, "min_CLP": -5.17, "draft_iters": 25.8, "mem_use": 45.32, "gen_rate": 8.8, "speed": 1.64, "text": "The list of oceans in the world "}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 39, "tree_size": 128, "t0": 1.7357, "t1": 0.6529, "tft": 3.1282, "input_0": 249, "input_1": 129, "min_CLP": -5.61, "draft_iters": 8.1, "mem_use": 45.56, "gen_rate": 5.0, "speed": 2.09, "text": "One way to get started is to res"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 5.3, "t1": 0.64, "tft": 3.3087, "input_0": 526, "input_1": 129, "min_CLP": -4.95, "draft_iters": 32.0, "mem_use": 44.97, "gen_rate": 21.5, "speed": 3.62, "text": "```python\\nimport pygame\\nimport"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 26, "tree_size": 128, "t0": 2.272, "t1": 0.658, "tft": 4.573, "input_0": 318, "input_1": 129, "min_CLP": -5.32, "draft_iters": 11.6, "mem_use": 46.08, "gen_rate": 6.4, "speed": 2.19, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 32.0, "tree_w": 27, "tree_size": 128, "t0": 5.045, "t1": 0.645, "tft": 3.1846, "input_0": 411, "input_1": 129, "min_CLP": -5.6, "draft_iters": 32.0, "mem_use": 45.22, "gen_rate": 31.5, "speed": 5.54, "text": "Please rephrase the question wit"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.5, "tree_w": 32, "tree_size": 128, "t0": 2.4183, "t1": 0.6417, "tft": 3.9223, "input_0": 322, "input_1": 129, "min_CLP": -5.56, "draft_iters": 11.5, "mem_use": 44.75, "gen_rate": 5.3, "speed": 1.74, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.8, "tree_w": 19, "tree_size": 128, "t0": 3.18, "t1": 0.64, "tft": 3.2044, "input_0": 431, "input_1": 129, "min_CLP": -5.13, "draft_iters": 15.8, "mem_use": 44.87, "gen_rate": 8.8, "speed": 2.29, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 15.0, "tree_w": 34, "tree_size": 128, "t0": 2.745, "t1": 0.645, "tft": 3.0143, "input_0": 298, "input_1": 129, "min_CLP": -5.9, "draft_iters": 16.0, "mem_use": 45.01, "gen_rate": 11.8, "speed": 3.47, "text": "They can be considered morally s"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 50, "tree_size": 128, "t0": 1.485, "t1": 0.6513, "tft": 4.448, "input_0": 200, "input_1": 129, "min_CLP": -6.12, "draft_iters": 7.0, "mem_use": 45.53, "gen_rate": 4.1, "speed": 1.93, "text": "\"I hate the way the show is stru"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.6, "tree_w": 24, "tree_size": 128, "t0": 2.908, "t1": 0.65, "tft": 4.7898, "input_0": 413, "input_1": 129, "min_CLP": -5.41, "draft_iters": 13.6, "mem_use": 46.38, "gen_rate": 7.8, "speed": 2.19, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 17, "tree_size": 128, "t0": 3.5433, "t1": 0.6467, "tft": 4.8593, "input_0": 491, "input_1": 129, "min_CLP": -5.02, "draft_iters": 17.7, "mem_use": 46.91, "gen_rate": 11.7, "speed": 2.78, "text": "Some languages that are consider"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.7, "tree_w": 15, "tree_size": 128, "t0": 3.7367, "t1": 0.64, "tft": 3.6756, "input_0": 385, "input_1": 129, "min_CLP": -4.96, "draft_iters": 22.7, "mem_use": 45.36, "gen_rate": 11.7, "speed": 2.67, "text": "Among the tools listed above, th"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.2, "tree_w": 33, "tree_size": 128, "t0": 1.88, "t1": 0.6467, "tft": 3.3759, "input_0": 284, "input_1": 129, "min_CLP": -5.54, "draft_iters": 9.2, "mem_use": 45.22, "gen_rate": 5.8, "speed": 2.31, "text": "I do not have personal feelings "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 34, "tree_size": 128, "t0": 2.2617, "t1": 0.6467, "tft": 3.411, "input_0": 321, "input_1": 129, "min_CLP": -5.62, "draft_iters": 11.2, "mem_use": 45.43, "gen_rate": 5.7, "speed": 1.95, "text": "You should focus on your project"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.3, "tree_w": 20, "tree_size": 128, "t0": 3.7367, "t1": 0.6467, "tft": 4.3381, "input_0": 497, "input_1": 129, "min_CLP": -5.27, "draft_iters": 17.3, "mem_use": 45.45, "gen_rate": 11.0, "speed": 2.51, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.2, "tree_w": 26, "tree_size": 128, "t0": 2.01, "t1": 0.646, "tft": 3.6536, "input_0": 305, "input_1": 129, "min_CLP": -5.56, "draft_iters": 10.2, "mem_use": 44.87, "gen_rate": 7.0, "speed": 2.64, "text": "\"Sure! As an AI language model, "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 15.8, "tree_w": 20, "tree_size": 128, "t0": 3.3775, "t1": 0.6525, "tft": 5.0112, "input_0": 505, "input_1": 129, "min_CLP": -5.55, "draft_iters": 16.8, "mem_use": 46.54, "gen_rate": 11.2, "speed": 2.79, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.2, "tree_w": 33, "tree_size": 128, "t0": 2.49, "t1": 0.644, "tft": 3.0713, "input_0": 301, "input_1": 129, "min_CLP": -5.82, "draft_iters": 14.2, "mem_use": 45.02, "gen_rate": 7.4, "speed": 2.36, "text": "\"Psychomotricity\\n[INST] How can"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 27, "tree_size": 128, "t0": 2.362, "t1": 0.64, "tft": 4.0655, "input_0": 343, "input_1": 129, "min_CLP": -5.43, "draft_iters": 11.6, "mem_use": 44.85, "gen_rate": 7.6, "speed": 2.53, "text": "Here are 10 names from different"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 23, "tree_size": 128, "t0": 2.292, "t1": 0.64, "tft": 3.546, "input_0": 325, "input_1": 129, "min_CLP": -5.36, "draft_iters": 12.0, "mem_use": 45.33, "gen_rate": 6.8, "speed": 2.32, "text": "\"I am an AI language model, so I"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.2, "tree_w": 23, "tree_size": 128, "t0": 2.55, "t1": 0.648, "tft": 5.4167, "input_0": 355, "input_1": 129, "min_CLP": -5.07, "draft_iters": 12.2, "mem_use": 47.01, "gen_rate": 7.4, "speed": 2.31, "text": "When creating new images using t"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 37, "tree_size": 128, "t0": 1.8188, "t1": 0.65, "tft": 3.7254, "input_0": 277, "input_1": 129, "min_CLP": -5.69, "draft_iters": 8.4, "mem_use": 45.8, "gen_rate": 4.4, "speed": 1.77, "text": "Yes, a similar theory for humans"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 14.0, "tree_w": 18, "tree_size": 128, "t0": 2.9233, "t1": 0.65, "tft": 4.9083, "input_0": 377, "input_1": 129, "min_CLP": -5.18, "draft_iters": 15.0, "mem_use": 46.23, "gen_rate": 14.0, "speed": 3.92, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 34, "tree_size": 128, "t0": 1.905, "t1": 0.6383, "tft": 2.1844, "input_0": 298, "input_1": 129, "min_CLP": -5.76, "draft_iters": 8.7, "mem_use": 44.79, "gen_rate": 5.7, "speed": 2.23, "text": "Title: The Quantum Enigma\\n\\nPlo"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 17.7, "tree_w": 18, "tree_size": 128, "t0": 3.4167, "t1": 0.66, "tft": 8.6608, "input_0": 443, "input_1": 129, "min_CLP": -5.16, "draft_iters": 18.7, "mem_use": 49.53, "gen_rate": 13.7, "speed": 3.35, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 12.8, "tree_w": 22, "tree_size": 128, "t0": 2.7475, "t1": 0.6525, "tft": 5.016, "input_0": 419, "input_1": 129, "min_CLP": -5.38, "draft_iters": 13.8, "mem_use": 45.93, "gen_rate": 10.2, "speed": 3.02, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 20.7, "tree_w": 17, "tree_size": 128, "t0": 3.87, "t1": 0.6533, "tft": 4.8155, "input_0": 443, "input_1": 129, "min_CLP": -5.05, "draft_iters": 21.7, "mem_use": 45.79, "gen_rate": 14.7, "speed": 3.24, "text": "If the original departure is fro"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.0, "tree_w": 25, "tree_size": 128, "t0": 2.602, "t1": 0.636, "tft": 3.4982, "input_0": 336, "input_1": 129, "min_CLP": -5.14, "draft_iters": 14.0, "mem_use": 44.82, "gen_rate": 8.0, "speed": 2.47, "text": "\"Adolf Hitler took over Germany "}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.5, "tree_w": 35, "tree_size": 128, "t0": 2.255, "t1": 0.645, "tft": 3.6957, "input_0": 297, "input_1": 129, "min_CLP": -5.91, "draft_iters": 11.5, "mem_use": 45.16, "gen_rate": 9.8, "speed": 3.36, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.2, "tree_w": 25, "tree_size": 128, "t0": 2.7825, "t1": 0.64, "tft": 4.5154, "input_0": 430, "input_1": 129, "min_CLP": -5.42, "draft_iters": 13.2, "mem_use": 44.78, "gen_rate": 9.8, "speed": 2.85, "text": "The number of black holes known "}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 20, "tree_size": 128, "t0": 2.6825, "t1": 0.6675, "tft": 6.0586, "input_0": 352, "input_1": 129, "min_CLP": -5.6, "draft_iters": 13.5, "mem_use": 49.58, "gen_rate": 8.8, "speed": 2.61, "text": "Apologies for the confusion earl"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 60, "tree_h": 29.0, "tree_w": 18, "tree_size": 128, "t0": 4.415, "t1": 0.64, "tft": 4.4574, "input_0": 343, "input_1": 129, "min_CLP": -7.86, "draft_iters": 29.5, "mem_use": 44.86, "gen_rate": 30.0, "speed": 5.93, "text": "Human: [INST] <<SYS>>\\nYou are a"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.0, "tree_w": 29, "tree_size": 128, "t0": 2.1967, "t1": 0.69, "tft": 8.7843, "input_0": 298, "input_1": 129, "min_CLP": -5.5, "draft_iters": 11.0, "mem_use": 51.82, "gen_rate": 5.7, "speed": 1.96, "text": "I am sorry, but I am still unabl"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.0, "tree_w": 38, "tree_size": 128, "t0": 1.7462, "t1": 0.6575, "tft": 4.6899, "input_0": 235, "input_1": 129, "min_CLP": -6.0, "draft_iters": 9.0, "mem_use": 46.04, "gen_rate": 4.2, "speed": 1.77, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.2, "tree_w": 26, "tree_size": 128, "t0": 2.6417, "t1": 0.6433, "tft": 3.4499, "input_0": 390, "input_1": 129, "min_CLP": -5.35, "draft_iters": 12.2, "mem_use": 44.88, "gen_rate": 6.2, "speed": 1.88, "text": "Sure! The physical appearance of"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.3, "tree_w": 16, "tree_size": 128, "t0": 3.2167, "t1": 0.64, "tft": 3.7797, "input_0": 436, "input_1": 129, "min_CLP": -5.13, "draft_iters": 16.3, "mem_use": 44.75, "gen_rate": 11.0, "speed": 2.85, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 11.1, "tree_w": 30, "tree_size": 128, "t0": 2.1963, "t1": 0.64, "tft": 4.3804, "input_0": 286, "input_1": 129, "min_CLP": -5.49, "draft_iters": 12.1, "mem_use": 45.0, "gen_rate": 4.2, "speed": 1.5, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 14.5, "tree_w": 20, "tree_size": 128, "t0": 2.9375, "t1": 0.6425, "tft": 3.3281, "input_0": 376, "input_1": 129, "min_CLP": -5.16, "draft_iters": 15.5, "mem_use": 45.3, "gen_rate": 11.2, "speed": 3.14, "text": "\"Sure! Here are a few suggestion"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.8, "tree_w": 16, "tree_size": 128, "t0": 3.7125, "t1": 0.6575, "tft": 5.9757, "input_0": 499, "input_1": 129, "min_CLP": -4.9, "draft_iters": 17.8, "mem_use": 46.91, "gen_rate": 9.0, "speed": 2.06, "text": "Sure, here are some software and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 2.515, "t1": 0.65, "tft": 5.1117, "input_0": 380, "input_1": 129, "min_CLP": -5.28, "draft_iters": 12.2, "mem_use": 46.02, "gen_rate": 9.5, "speed": 3.0, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 30, "tree_size": 128, "t0": 2.56, "t1": 0.638, "tft": 3.4404, "input_0": 395, "input_1": 129, "min_CLP": -5.6, "draft_iters": 11.2, "mem_use": 44.94, "gen_rate": 7.4, "speed": 2.31, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 26.5, "tree_w": 13, "tree_size": 128, "t0": 4.6225, "t1": 0.6575, "tft": 5.2967, "input_0": 496, "input_1": 129, "min_CLP": -5.14, "draft_iters": 27.0, "mem_use": 47.56, "gen_rate": 13.8, "speed": 2.6, "text": "\"Sure! Here's the commented code"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.2, "tree_w": 18, "tree_size": 128, "t0": 3.08, "t1": 0.6525, "tft": 4.3792, "input_0": 407, "input_1": 129, "min_CLP": -5.16, "draft_iters": 16.2, "mem_use": 46.05, "gen_rate": 8.0, "speed": 2.14, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 128, "t0": 5.05, "t1": 0.63, "tft": 3.8094, "input_0": 389, "input_1": 129, "min_CLP": -6.28, "draft_iters": 32.0, "mem_use": 44.77, "gen_rate": 33.0, "speed": 5.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 21, "tree_h": 16.5, "tree_w": 20, "tree_size": 128, "t0": 3.57, "t1": 0.64, "tft": 3.425, "input_0": 464, "input_1": 129, "min_CLP": -5.27, "draft_iters": 17.5, "mem_use": 44.86, "gen_rate": 10.5, "speed": 2.49, "text": "```markdown\\nHere is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.3, "tree_w": 32, "tree_size": 128, "t0": 2.0933, "t1": 0.6533, "tft": 4.1183, "input_0": 284, "input_1": 129, "min_CLP": -5.56, "draft_iters": 10.3, "mem_use": 45.89, "gen_rate": 5.3, "speed": 1.94, "text": "\"Of course! Here's a poem in the"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.5, "tree_w": 25, "tree_size": 128, "t0": 2.4583, "t1": 0.6533, "tft": 5.4302, "input_0": 358, "input_1": 129, "min_CLP": -5.43, "draft_iters": 12.5, "mem_use": 46.84, "gen_rate": 6.8, "speed": 2.2, "text": "In JavaScript, you can use type "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 22, "tree_size": 128, "t0": 4.45, "t1": 0.64, "tft": 3.277, "input_0": 281, "input_1": 129, "min_CLP": -5.38, "draft_iters": 32.0, "mem_use": 45.37, "gen_rate": 33.0, "speed": 6.48, "text": "\"To start learning guitar: First"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 2.6075, "t1": 0.65, "tft": 4.592, "input_0": 375, "input_1": 129, "min_CLP": -5.15, "draft_iters": 13.0, "mem_use": 45.86, "gen_rate": 8.8, "speed": 2.68, "text": "I apologize for the assumption. "}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 22, "tree_size": 128, "t0": 2.6725, "t1": 0.6425, "tft": 3.9405, "input_0": 406, "input_1": 129, "min_CLP": -5.08, "draft_iters": 13.2, "mem_use": 44.77, "gen_rate": 8.0, "speed": 2.41, "text": "javascript is a versatile progra"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 128, "t0": 4.68, "t1": 0.65, "tft": 3.1198, "input_0": 391, "input_1": 129, "min_CLP": -7.81, "draft_iters": 32.0, "mem_use": 44.75, "gen_rate": 33.0, "speed": 6.19, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.5, "tree_w": 24, "tree_size": 128, "t0": 2.92, "t1": 0.6467, "tft": 3.4948, "input_0": 381, "input_1": 129, "min_CLP": -5.42, "draft_iters": 15.5, "mem_use": 45.47, "gen_rate": 5.7, "speed": 1.59, "text": "Here are the 5 words in columns,"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.5, "tree_w": 23, "tree_size": 128, "t0": 2.3225, "t1": 0.64, "tft": 4.4426, "input_0": 314, "input_1": 129, "min_CLP": -5.35, "draft_iters": 11.5, "mem_use": 44.88, "gen_rate": 9.2, "speed": 3.13, "text": "Hippoplaisir is a unique and inn"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 33, "tree_size": 128, "t0": 1.8571, "t1": 0.6443, "tft": 5.6531, "input_0": 277, "input_1": 129, "min_CLP": -5.6, "draft_iters": 8.7, "mem_use": 44.88, "gen_rate": 5.1, "speed": 2.06, "text": "\"Sure, here is a poem that I hop"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.3, "tree_w": 16, "tree_size": 128, "t0": 3.2233, "t1": 0.64, "tft": 3.2888, "input_0": 435, "input_1": 129, "min_CLP": -5.31, "draft_iters": 17.3, "mem_use": 44.86, "gen_rate": 11.3, "speed": 2.94, "text": "Sure, here are some tips to help"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 26, "tree_size": 128, "t0": 2.7275, "t1": 0.665, "tft": 6.4796, "input_0": 340, "input_1": 129, "min_CLP": -5.7, "draft_iters": 14.5, "mem_use": 49.64, "gen_rate": 8.5, "speed": 2.5, "text": "\"Here's a rewritten version of t"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.0, "tree_w": 23, "tree_size": 128, "t0": 2.5433, "t1": 0.6533, "tft": 5.6844, "input_0": 353, "input_1": 129, "min_CLP": -5.26, "draft_iters": 12.0, "mem_use": 47.26, "gen_rate": 6.0, "speed": 1.88, "text": "\"Sure! Imagine you have a really"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 29.0, "tree_w": 10, "tree_size": 128, "t0": 4.9, "t1": 0.65, "tft": 4.4647, "input_0": 498, "input_1": 129, "min_CLP": -4.54, "draft_iters": 29.3, "mem_use": 45.69, "gen_rate": 13.0, "speed": 2.34, "text": "Sure, here is the mathematical f"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 22, "tree_size": 128, "t0": 2.74, "t1": 0.654, "tft": 4.1169, "input_0": 375, "input_1": 129, "min_CLP": -5.06, "draft_iters": 13.8, "mem_use": 45.86, "gen_rate": 6.8, "speed": 2.0, "text": "We can learn a lot from polar be"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.8, "tree_w": 22, "tree_size": 128, "t0": 2.6675, "t1": 0.655, "tft": 4.7836, "input_0": 417, "input_1": 129, "min_CLP": -5.28, "draft_iters": 12.8, "mem_use": 46.92, "gen_rate": 10.5, "speed": 3.16, "text": "Lemon wedges for serving are sim"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 34, "tree_size": 128, "t0": 1.9, "t1": 0.6417, "tft": 2.7336, "input_0": 282, "input_1": 129, "min_CLP": -5.55, "draft_iters": 9.0, "mem_use": 44.95, "gen_rate": 6.0, "speed": 2.36, "text": "\"Here's how the conversation cou"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 38, "tree_size": 128, "t0": 2.056, "t1": 0.644, "tft": 2.9814, "input_0": 316, "input_1": 129, "min_CLP": -5.78, "draft_iters": 9.0, "mem_use": 44.91, "gen_rate": 6.4, "speed": 2.37, "text": "\"I'm sorry to hear that. Let's t"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.0, "tree_w": 13, "tree_size": 128, "t0": 3.85, "t1": 0.645, "tft": 4.3435, "input_0": 462, "input_1": 129, "min_CLP": -4.96, "draft_iters": 22.0, "mem_use": 44.79, "gen_rate": 18.5, "speed": 4.12, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 11.0, "tree_w": 25, "tree_size": 128, "t0": 2.5286, "t1": 0.6514, "tft": 4.5382, "input_0": 357, "input_1": 129, "min_CLP": -5.29, "draft_iters": 12.0, "mem_use": 46.37, "gen_rate": 6.3, "speed": 1.98, "text": "While there are cities that were"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.2, "tree_w": 20, "tree_size": 128, "t0": 3.06, "t1": 0.655, "tft": 5.0566, "input_0": 409, "input_1": 129, "min_CLP": -5.13, "draft_iters": 15.2, "mem_use": 45.9, "gen_rate": 8.5, "speed": 2.29, "text": "Freeman Dyson was a theoretical "}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 21, "tree_size": 128, "t0": 2.6575, "t1": 0.6425, "tft": 2.906, "input_0": 377, "input_1": 129, "min_CLP": -5.16, "draft_iters": 12.2, "mem_use": 44.74, "gen_rate": 8.0, "speed": 2.42, "text": "\"Yes, I can write code in variou"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 26.0, "tree_w": 24, "tree_size": 128, "t0": 4.6367, "t1": 0.65, "tft": 4.1978, "input_0": 473, "input_1": 129, "min_CLP": -6.14, "draft_iters": 26.3, "mem_use": 45.49, "gen_rate": 18.7, "speed": 3.53, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 20.4, "tree_w": 22, "tree_size": 128, "t0": 3.64, "t1": 0.656, "tft": 7.0, "input_0": 373, "input_1": 129, "min_CLP": -5.23, "draft_iters": 21.0, "mem_use": 46.09, "gen_rate": 7.2, "speed": 1.68, "text": "Certainly! Here are the complete"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.3, "tree_w": 19, "tree_size": 128, "t0": 3.4967, "t1": 0.6433, "tft": 3.0877, "input_0": 450, "input_1": 129, "min_CLP": -5.13, "draft_iters": 18.3, "mem_use": 45.11, "gen_rate": 11.3, "speed": 2.74, "text": "1.    Identify the source of str"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.4, "tree_w": 24, "tree_size": 128, "t0": 2.732, "t1": 0.64, "tft": 2.4991, "input_0": 375, "input_1": 129, "min_CLP": -5.42, "draft_iters": 13.4, "mem_use": 44.78, "gen_rate": 7.0, "speed": 2.08, "text": "The self-attention mechanism is "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.7, "tree_w": 28, "tree_size": 128, "t0": 2.485, "t1": 0.6383, "tft": 3.4552, "input_0": 302, "input_1": 129, "min_CLP": -5.6, "draft_iters": 13.7, "mem_use": 45.34, "gen_rate": 6.2, "speed": 1.97, "text": "It is not possible to compare th"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 10.9, "tree_w": 25, "tree_size": 128, "t0": 2.1825, "t1": 0.6462, "tft": 4.2985, "input_0": 276, "input_1": 129, "min_CLP": -5.62, "draft_iters": 11.9, "mem_use": 45.78, "gen_rate": 4.1, "speed": 1.46, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 11.0, "tree_w": 22, "tree_size": 128, "t0": 2.46, "t1": 0.65, "tft": 4.2691, "input_0": 333, "input_1": 129, "min_CLP": -5.32, "draft_iters": 12.0, "mem_use": 45.45, "gen_rate": 7.3, "speed": 2.36, "text": "The URL decoded string for `%21`"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 128, "t0": 5.78, "t1": 0.65, "tft": 6.8685, "input_0": 592, "input_1": 129, "min_CLP": -5.88, "draft_iters": 32.0, "mem_use": 47.57, "gen_rate": 33.0, "speed": 5.13, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.8, "tree_w": 18, "tree_size": 128, "t0": 2.838, "t1": 0.668, "tft": 6.671, "input_0": 385, "input_1": 129, "min_CLP": -5.17, "draft_iters": 14.8, "mem_use": 49.15, "gen_rate": 7.4, "speed": 2.11, "text": "Here are some specific answers t"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 14.0, "tree_w": 21, "tree_size": 128, "t0": 2.964, "t1": 0.65, "tft": 3.9082, "input_0": 416, "input_1": 129, "min_CLP": -5.26, "draft_iters": 15.0, "mem_use": 46.16, "gen_rate": 9.2, "speed": 2.54, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 5.54, "t1": 0.655, "tft": 4.8914, "input_0": 543, "input_1": 129, "min_CLP": -5.1, "draft_iters": 32.0, "mem_use": 46.55, "gen_rate": 22.5, "speed": 3.63, "text": "Sure, here are the three most im"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.5, "tree_w": 22, "tree_size": 128, "t0": 3.915, "t1": 0.645, "tft": 4.1778, "input_0": 471, "input_1": 129, "min_CLP": -5.19, "draft_iters": 21.5, "mem_use": 44.78, "gen_rate": 16.5, "speed": 3.62, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.0, "tree_w": 18, "tree_size": 128, "t0": 2.8, "t1": 0.6533, "tft": 4.582, "input_0": 382, "input_1": 129, "min_CLP": -5.04, "draft_iters": 15.0, "mem_use": 46.12, "gen_rate": 12.3, "speed": 3.57, "text": "Black Friday is the day after Th"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.8, "tree_w": 26, "tree_size": 128, "t0": 2.608, "t1": 0.64, "tft": 3.5092, "input_0": 324, "input_1": 129, "min_CLP": -5.52, "draft_iters": 13.8, "mem_use": 44.95, "gen_rate": 7.4, "speed": 2.28, "text": "Here\u2019s a short story based on th"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 28, "tree_size": 128, "t0": 2.22, "t1": 0.64, "tft": 5.4241, "input_0": 331, "input_1": 129, "min_CLP": -5.3, "draft_iters": 10.6, "mem_use": 44.82, "gen_rate": 7.0, "speed": 2.45, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 22, "tree_size": 128, "t0": 3.2, "t1": 0.6375, "tft": 4.7654, "input_0": 430, "input_1": 129, "min_CLP": -5.29, "draft_iters": 15.8, "mem_use": 44.81, "gen_rate": 8.0, "speed": 2.09, "text": "In Minecraft, there are several "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.8, "tree_w": 28, "tree_size": 128, "t0": 2.396, "t1": 0.636, "tft": 2.4801, "input_0": 365, "input_1": 129, "min_CLP": -5.66, "draft_iters": 10.8, "mem_use": 44.77, "gen_rate": 7.0, "speed": 2.31, "text": "I am Freyja, the Norse Goddess o"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 17.0, "tree_w": 29, "tree_size": 128, "t0": 4.21, "t1": 0.65, "tft": 4.9252, "input_0": 583, "input_1": 129, "min_CLP": -5.92, "draft_iters": 18.0, "mem_use": 46.04, "gen_rate": 4.0, "speed": 0.82, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.7, "tree_w": 22, "tree_size": 128, "t0": 3.3867, "t1": 0.6433, "tft": 3.7257, "input_0": 439, "input_1": 129, "min_CLP": -5.18, "draft_iters": 16.7, "mem_use": 45.16, "gen_rate": 12.7, "speed": 3.14, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.5, "tree_w": 18, "tree_size": 128, "t0": 3.0775, "t1": 0.6725, "tft": 7.3979, "input_0": 435, "input_1": 129, "min_CLP": -5.22, "draft_iters": 14.5, "mem_use": 50.25, "gen_rate": 10.8, "speed": 2.87, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 20, "tree_size": 128, "t0": 2.9775, "t1": 0.645, "tft": 3.2878, "input_0": 460, "input_1": 129, "min_CLP": -5.3, "draft_iters": 13.8, "mem_use": 45.29, "gen_rate": 8.0, "speed": 2.21, "text": "Large language models (LLMs) are"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.2, "tree_w": 30, "tree_size": 128, "t0": 2.4, "t1": 0.6433, "tft": 3.4879, "input_0": 270, "input_1": 129, "min_CLP": -5.64, "draft_iters": 14.2, "mem_use": 44.86, "gen_rate": 5.5, "speed": 1.81, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 16.7, "tree_w": 19, "tree_size": 128, "t0": 3.67, "t1": 0.6433, "tft": 5.8742, "input_0": 492, "input_1": 129, "min_CLP": -5.21, "draft_iters": 17.7, "mem_use": 45.07, "gen_rate": 13.0, "speed": 3.01, "text": "\"I'm sorry to hear about your lo"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 14.3, "tree_w": 20, "tree_size": 128, "t0": 2.9033, "t1": 0.6533, "tft": 4.3134, "input_0": 389, "input_1": 129, "min_CLP": -5.06, "draft_iters": 15.3, "mem_use": 46.55, "gen_rate": 12.7, "speed": 3.56, "text": "\"I hope this helps you get start"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.7, "tree_w": 24, "tree_size": 128, "t0": 2.5883, "t1": 0.64, "tft": 3.5969, "input_0": 353, "input_1": 129, "min_CLP": -5.41, "draft_iters": 12.7, "mem_use": 44.94, "gen_rate": 6.5, "speed": 2.01, "text": "Yes, I am an AI model designed t"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 128, "t0": 5.22, "t1": 0.64, "tft": 5.8412, "input_0": 417, "input_1": 129, "min_CLP": -6.36, "draft_iters": 32.0, "mem_use": 44.92, "gen_rate": 33.0, "speed": 5.63, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 10.0, "tree_w": 34, "tree_size": 128, "t0": 1.99, "t1": 0.64, "tft": 5.2733, "input_0": 240, "input_1": 129, "min_CLP": -5.96, "draft_iters": 11.0, "mem_use": 44.75, "gen_rate": 2.7, "speed": 1.02, "text": "[META: color]\\n[META: astronomy]"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 9.2, "tree_w": 42, "tree_size": 128, "t0": 1.9522, "t1": 0.6511, "tft": 5.4945, "input_0": 241, "input_1": 129, "min_CLP": -5.98, "draft_iters": 10.2, "mem_use": 46.98, "gen_rate": 4.4, "speed": 1.71, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 25, "tree_size": 128, "t0": 5.12, "t1": 0.64, "tft": 3.8405, "input_0": 401, "input_1": 129, "min_CLP": -6.76, "draft_iters": 32.0, "mem_use": 44.83, "gen_rate": 33.0, "speed": 5.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.3, "tree_w": 30, "tree_size": 128, "t0": 1.9917, "t1": 0.645, "tft": 3.1995, "input_0": 269, "input_1": 129, "min_CLP": -6.0, "draft_iters": 10.3, "mem_use": 45.37, "gen_rate": 5.3, "speed": 2.02, "text": "No, it is not a violation. The A"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.0, "tree_w": 16, "tree_size": 128, "t0": 3.4967, "t1": 0.64, "tft": 5.6912, "input_0": 464, "input_1": 129, "min_CLP": -5.11, "draft_iters": 19.0, "mem_use": 44.83, "gen_rate": 10.7, "speed": 2.58, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 28, "tree_size": 128, "t0": 2.36, "t1": 0.644, "tft": 4.2755, "input_0": 362, "input_1": 129, "min_CLP": -5.41, "draft_iters": 10.4, "mem_use": 45.27, "gen_rate": 7.0, "speed": 2.33, "text": "\"Hello! I'm excited to be your b"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 11.8, "tree_w": 25, "tree_size": 128, "t0": 2.5475, "t1": 0.6475, "tft": 3.7122, "input_0": 363, "input_1": 129, "min_CLP": -5.62, "draft_iters": 12.8, "mem_use": 44.95, "gen_rate": 6.5, "speed": 2.03, "text": "Sydney was the first capital of "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 27.5, "tree_w": 17, "tree_size": 128, "t0": 4.38, "t1": 0.64, "tft": 3.0476, "input_0": 394, "input_1": 129, "min_CLP": -6.18, "draft_iters": 28.0, "mem_use": 45.13, "gen_rate": 27.5, "speed": 5.47, "text": "[INST] yes [\\\\INST]\\n[INST] yes "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 2.3583, "t1": 0.65, "tft": 4.6968, "input_0": 357, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.2, "mem_use": 47.35, "gen_rate": 6.5, "speed": 2.16, "text": "Certainly! Here\\'s a possible me"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 26, "tree_size": 128, "t0": 2.72, "t1": 0.634, "tft": 2.7461, "input_0": 365, "input_1": 129, "min_CLP": -5.35, "draft_iters": 12.6, "mem_use": 44.94, "gen_rate": 7.0, "speed": 2.09, "text": "\"Answer: The story you mentioned"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.2, "tree_w": 22, "tree_size": 128, "t0": 3.005, "t1": 0.6575, "tft": 5.6305, "input_0": 385, "input_1": 129, "min_CLP": -5.12, "draft_iters": 15.2, "mem_use": 46.23, "gen_rate": 8.5, "speed": 2.32, "text": "\"Yes, let's consider a vector A "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.3, "tree_w": 24, "tree_size": 128, "t0": 2.5833, "t1": 0.64, "tft": 3.1887, "input_0": 347, "input_1": 129, "min_CLP": -5.24, "draft_iters": 13.3, "mem_use": 44.8, "gen_rate": 6.7, "speed": 2.07, "text": "1. Inability to capture skewness"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.0, "tree_w": 36, "tree_size": 128, "t0": 1.8233, "t1": 0.64, "tft": 3.0991, "input_0": 255, "input_1": 129, "min_CLP": -5.88, "draft_iters": 9.0, "mem_use": 44.86, "gen_rate": 3.9, "speed": 1.58, "text": "My name is Auri-El, the Elven go"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.0, "tree_w": 28, "tree_size": 128, "t0": 2.506, "t1": 0.64, "tft": 3.7135, "input_0": 375, "input_1": 129, "min_CLP": -5.41, "draft_iters": 12.0, "mem_use": 44.81, "gen_rate": 8.0, "speed": 2.54, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 20, "tree_size": 128, "t0": 2.325, "t1": 0.6475, "tft": 4.1942, "input_0": 319, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.8, "mem_use": 45.37, "gen_rate": 8.0, "speed": 2.69, "text": "Sum of squares error is the sum "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 8.0, "tree_w": 33, "tree_size": 128, "t0": 1.8, "t1": 0.65, "tft": 3.7607, "input_0": 256, "input_1": 129, "min_CLP": -5.78, "draft_iters": 9.0, "mem_use": 45.67, "gen_rate": 4.5, "speed": 1.84, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.4, "tree_w": 30, "tree_size": 128, "t0": 2.0214, "t1": 0.6486, "tft": 3.9189, "input_0": 284, "input_1": 129, "min_CLP": -5.56, "draft_iters": 10.4, "mem_use": 45.46, "gen_rate": 5.1, "speed": 1.93, "text": "In the lower 48, the best place "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 31, "tree_size": 128, "t0": 2.1433, "t1": 0.64, "tft": 3.7177, "input_0": 323, "input_1": 129, "min_CLP": -5.68, "draft_iters": 10.0, "mem_use": 44.8, "gen_rate": 5.5, "speed": 1.97, "text": "1. Dying from laughter\\n2. Being"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 26, "tree_size": 128, "t0": 2.374, "t1": 0.64, "tft": 4.7849, "input_0": 339, "input_1": 129, "min_CLP": -5.51, "draft_iters": 11.8, "mem_use": 45.36, "gen_rate": 7.0, "speed": 2.32, "text": "Two dropped eggs - two broken wi"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 26, "tree_size": 128, "t0": 2.312, "t1": 0.64, "tft": 3.4741, "input_0": 315, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.2, "mem_use": 45.23, "gen_rate": 7.0, "speed": 2.37, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.4, "tree_w": 17, "tree_size": 128, "t0": 2.852, "t1": 0.664, "tft": 5.9962, "input_0": 383, "input_1": 129, "min_CLP": -5.27, "draft_iters": 14.4, "mem_use": 48.31, "gen_rate": 7.0, "speed": 1.99, "text": "1. Establish clear objectives an"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 16, "tree_size": 128, "t0": 3.4233, "t1": 0.66, "tft": 5.2666, "input_0": 508, "input_1": 129, "min_CLP": -4.94, "draft_iters": 15.3, "mem_use": 46.98, "gen_rate": 11.7, "speed": 2.86, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 9.0, "tree_w": 32, "tree_size": 128, "t0": 2.25, "t1": 0.6425, "tft": 5.3597, "input_0": 346, "input_1": 129, "min_CLP": -5.55, "draft_iters": 10.0, "mem_use": 44.76, "gen_rate": 5.8, "speed": 1.99, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 29, "tree_h": 16.6, "tree_w": 31, "tree_size": 128, "t0": 3.258, "t1": 0.646, "tft": 3.9601, "input_0": 388, "input_1": 129, "min_CLP": -5.9, "draft_iters": 17.4, "mem_use": 45.01, "gen_rate": 5.8, "speed": 1.49, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 25, "tree_size": 128, "t0": 2.9425, "t1": 0.695, "tft": 9.1012, "input_0": 424, "input_1": 129, "min_CLP": -5.28, "draft_iters": 12.8, "mem_use": 51.85, "gen_rate": 8.2, "speed": 2.27, "text": "\"The `_physics_process` function"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.8, "tree_w": 18, "tree_size": 128, "t0": 2.9, "t1": 0.6475, "tft": 5.4939, "input_0": 410, "input_1": 129, "min_CLP": -5.25, "draft_iters": 14.8, "mem_use": 45.18, "gen_rate": 9.8, "speed": 2.75, "text": "Yes, you can use decorators with"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 28.0, "tree_w": 24, "tree_size": 128, "t0": 4.535, "t1": 0.64, "tft": 3.6076, "input_0": 370, "input_1": 129, "min_CLP": -6.16, "draft_iters": 28.5, "mem_use": 44.89, "gen_rate": 29.0, "speed": 5.6, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.2, "tree_w": 32, "tree_size": 128, "t0": 2.2567, "t1": 0.64, "tft": 3.3603, "input_0": 330, "input_1": 129, "min_CLP": -5.6, "draft_iters": 10.2, "mem_use": 44.89, "gen_rate": 6.3, "speed": 2.19, "text": "\"In Wyoming, public nudity is ge"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.6, "tree_w": 29, "tree_size": 128, "t0": 2.274, "t1": 0.656, "tft": 4.9416, "input_0": 313, "input_1": 129, "min_CLP": -5.47, "draft_iters": 10.6, "mem_use": 47.43, "gen_rate": 8.0, "speed": 2.73, "text": "I apologize if my previous respo"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.7, "tree_w": 13, "tree_size": 128, "t0": 3.6967, "t1": 0.64, "tft": 4.066, "input_0": 485, "input_1": 129, "min_CLP": -4.86, "draft_iters": 20.7, "mem_use": 45.31, "gen_rate": 13.7, "speed": 3.15, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.3, "tree_w": 26, "tree_size": 128, "t0": 2.9033, "t1": 0.65, "tft": 3.6215, "input_0": 337, "input_1": 129, "min_CLP": -5.43, "draft_iters": 16.3, "mem_use": 45.5, "gen_rate": 12.7, "speed": 3.56, "text": "Okay, I get it now. Can you tell"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.7, "tree_w": 17, "tree_size": 128, "t0": 3.7933, "t1": 0.64, "tft": 4.4084, "input_0": 433, "input_1": 129, "min_CLP": -5.33, "draft_iters": 20.7, "mem_use": 45.1, "gen_rate": 11.3, "speed": 2.55, "text": "The stable diffusion algorithm i"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.8, "tree_w": 32, "tree_size": 128, "t0": 2.688, "t1": 0.64, "tft": 3.286, "input_0": 290, "input_1": 129, "min_CLP": -5.92, "draft_iters": 15.8, "mem_use": 45.34, "gen_rate": 6.6, "speed": 1.98, "text": "\"Attention bias, I'll rap,\\nFocu"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.7, "tree_w": 31, "tree_size": 128, "t0": 2.0167, "t1": 0.6433, "tft": 4.0887, "input_0": 257, "input_1": 129, "min_CLP": -5.56, "draft_iters": 10.7, "mem_use": 45.13, "gen_rate": 6.5, "speed": 2.44, "text": "\"Schr\u00f6dinger's thought experimen"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.2, "tree_w": 35, "tree_size": 128, "t0": 2.092, "t1": 0.658, "tft": 5.2547, "input_0": 293, "input_1": 129, "min_CLP": -5.65, "draft_iters": 9.2, "mem_use": 47.1, "gen_rate": 7.0, "speed": 2.55, "text": "\"Setting up your kitchen for the"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.3, "tree_w": 19, "tree_size": 128, "t0": 3.24, "t1": 0.6433, "tft": 4.5305, "input_0": 410, "input_1": 129, "min_CLP": -5.61, "draft_iters": 17.3, "mem_use": 44.88, "gen_rate": 13.7, "speed": 3.52, "text": "Canberra is situated in the Aust"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 13.2, "tree_w": 30, "tree_size": 128, "t0": 2.67, "t1": 0.6383, "tft": 3.6563, "input_0": 319, "input_1": 129, "min_CLP": -5.79, "draft_iters": 14.2, "mem_use": 44.9, "gen_rate": 8.2, "speed": 2.47, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.9, "tree_w": 30, "tree_size": 128, "t0": 2.0729, "t1": 0.6443, "tft": 3.4966, "input_0": 309, "input_1": 129, "min_CLP": -5.56, "draft_iters": 9.9, "mem_use": 44.88, "gen_rate": 5.1, "speed": 1.89, "text": "F-centers, short for Faraday cen"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 34, "tree_size": 128, "t0": 2.8033, "t1": 0.6667, "tft": 6.6371, "input_0": 415, "input_1": 129, "min_CLP": -5.72, "draft_iters": 13.3, "mem_use": 49.44, "gen_rate": 11.0, "speed": 3.17, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.7, "tree_w": 22, "tree_size": 128, "t0": 3.0867, "t1": 0.65, "tft": 5.3921, "input_0": 414, "input_1": 129, "min_CLP": -5.44, "draft_iters": 15.7, "mem_use": 46.52, "gen_rate": 12.0, "speed": 3.21, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 14.7, "tree_w": 18, "tree_size": 128, "t0": 3.08, "t1": 0.6467, "tft": 3.2272, "input_0": 449, "input_1": 129, "min_CLP": -5.07, "draft_iters": 15.7, "mem_use": 45.31, "gen_rate": 14.3, "speed": 3.85, "text": "\"Sure! Here's a list of pros and"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.0, "tree_w": 21, "tree_size": 128, "t0": 3.135, "t1": 0.65, "tft": 5.9393, "input_0": 420, "input_1": 129, "min_CLP": -5.11, "draft_iters": 16.0, "mem_use": 47.22, "gen_rate": 10.0, "speed": 2.64, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.8, "tree_w": 24, "tree_size": 128, "t0": 2.858, "t1": 0.654, "tft": 5.3008, "input_0": 410, "input_1": 129, "min_CLP": -5.41, "draft_iters": 13.8, "mem_use": 47.18, "gen_rate": 7.6, "speed": 2.16, "text": "Die Zementproduktion erzeugt in "}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 23, "tree_size": 128, "t0": 2.5833, "t1": 0.6533, "tft": 5.8241, "input_0": 350, "input_1": 129, "min_CLP": -5.38, "draft_iters": 12.7, "mem_use": 46.53, "gen_rate": 10.7, "speed": 3.3, "text": "\"I'm sorry, but I can't provide "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 40, "tree_size": 128, "t0": 1.7271, "t1": 0.6514, "tft": 3.566, "input_0": 237, "input_1": 129, "min_CLP": -5.94, "draft_iters": 8.7, "mem_use": 45.55, "gen_rate": 5.1, "speed": 2.16, "text": "I would recommend posting a foun"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 21.0, "tree_w": 16, "tree_size": 128, "t0": 3.6933, "t1": 0.64, "tft": 2.9168, "input_0": 405, "input_1": 129, "min_CLP": -4.97, "draft_iters": 22.0, "mem_use": 45.14, "gen_rate": 11.0, "speed": 2.54, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u7684\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1a\\n1. \"Attent"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 23.5, "tree_w": 13, "tree_size": 128, "t0": 4.48, "t1": 0.645, "tft": 5.5488, "input_0": 524, "input_1": 129, "min_CLP": -4.94, "draft_iters": 24.5, "mem_use": 44.94, "gen_rate": 21.0, "speed": 4.09, "text": "Sure, here is a JavaScript funct"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.5, "tree_w": 20, "tree_size": 128, "t0": 2.9217, "t1": 0.6517, "tft": 4.6587, "input_0": 395, "input_1": 129, "min_CLP": -5.2, "draft_iters": 14.5, "mem_use": 46.23, "gen_rate": 6.2, "speed": 1.73, "text": "The reason public nudity is gene"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 31, "tree_size": 128, "t0": 2.275, "t1": 0.645, "tft": 3.0629, "input_0": 330, "input_1": 129, "min_CLP": -5.57, "draft_iters": 10.0, "mem_use": 45.34, "gen_rate": 5.5, "speed": 1.88, "text": "I suggest that you write the poe"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 2.7125, "t1": 0.655, "tft": 4.6733, "input_0": 363, "input_1": 129, "min_CLP": -5.33, "draft_iters": 13.8, "mem_use": 46.22, "gen_rate": 9.0, "speed": 2.67, "text": "\"The optimal thickness of mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 19.0, "tree_w": 20, "tree_size": 128, "t0": 3.965, "t1": 0.655, "tft": 5.2809, "input_0": 501, "input_1": 129, "min_CLP": -5.27, "draft_iters": 20.0, "mem_use": 45.6, "gen_rate": 17.0, "speed": 3.68, "text": "Okay! If you live in a European "}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.6, "tree_w": 33, "tree_size": 128, "t0": 2.1957, "t1": 0.6386, "tft": 5.6671, "input_0": 333, "input_1": 129, "min_CLP": -6.28, "draft_iters": 10.6, "mem_use": 44.87, "gen_rate": 5.3, "speed": 1.87, "text": "Sure! Here are some nicknames th"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 2.5525, "t1": 0.6475, "tft": 5.3522, "input_0": 347, "input_1": 129, "min_CLP": -5.4, "draft_iters": 13.0, "mem_use": 45.27, "gen_rate": 9.5, "speed": 2.97, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 28.3, "tree_w": 9, "tree_size": 128, "t0": 4.77, "t1": 0.6567, "tft": 5.2297, "input_0": 516, "input_1": 129, "min_CLP": -4.87, "draft_iters": 29.0, "mem_use": 46.03, "gen_rate": 19.0, "speed": 3.5, "text": "\"Felices:\\n1. \u00abGood Vibrations\u00bb,"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.0, "tree_w": 29, "tree_size": 128, "t0": 3.35, "t1": 0.645, "tft": 4.4037, "input_0": 462, "input_1": 129, "min_CLP": -5.23, "draft_iters": 15.0, "mem_use": 44.97, "gen_rate": 9.8, "speed": 2.44, "text": "Here is a table of the average t"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 31.3, "tree_w": 9, "tree_size": 128, "t0": 5.03, "t1": 0.6467, "tft": 5.8174, "input_0": 449, "input_1": 129, "min_CLP": -4.87, "draft_iters": 31.7, "mem_use": 45.36, "gen_rate": 14.7, "speed": 2.58, "text": "I apologize for the mistake. Her"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 9.2, "tree_w": 32, "tree_size": 128, "t0": 2.185, "t1": 0.655, "tft": 3.6121, "input_0": 324, "input_1": 129, "min_CLP": -5.77, "draft_iters": 10.2, "mem_use": 45.73, "gen_rate": 5.5, "speed": 1.94, "text": "Absolutely! How about, \"The tick"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 16.7, "tree_w": 14, "tree_size": 128, "t0": 3.51, "t1": 0.6567, "tft": 5.8146, "input_0": 452, "input_1": 129, "min_CLP": -5.09, "draft_iters": 17.7, "mem_use": 46.5, "gen_rate": 13.0, "speed": 3.12, "text": "\"Sure! Here's a step-by-step gui"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 27, "tree_size": 128, "t0": 2.4525, "t1": 0.645, "tft": 3.8823, "input_0": 332, "input_1": 129, "min_CLP": -5.55, "draft_iters": 12.2, "mem_use": 44.97, "gen_rate": 8.5, "speed": 2.74, "text": "Frank-Walter Steinmeier is a Ger"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.0, "tree_w": 36, "tree_size": 128, "t0": 2.4833, "t1": 0.6467, "tft": 4.5738, "input_0": 361, "input_1": 129, "min_CLP": -5.69, "draft_iters": 11.0, "mem_use": 44.9, "gen_rate": 6.7, "speed": 2.13, "text": "In this case, the most \"wet\" elb"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 21, "tree_size": 128, "t0": 2.356, "t1": 0.672, "tft": 6.6366, "input_0": 328, "input_1": 129, "min_CLP": -5.3, "draft_iters": 11.8, "mem_use": 49.02, "gen_rate": 7.0, "speed": 2.31, "text": "1. Discovery:\\n   - Identify a m"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 2.1283, "t1": 0.64, "tft": 4.9554, "input_0": 308, "input_1": 129, "min_CLP": -5.38, "draft_iters": 10.2, "mem_use": 44.79, "gen_rate": 6.2, "speed": 2.23, "text": "The many-worlds interpretation o"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 128, "t0": 5.29, "t1": 0.64, "tft": 3.2284, "input_0": 408, "input_1": 129, "min_CLP": -6.81, "draft_iters": 32.0, "mem_use": 44.75, "gen_rate": 33.0, "speed": 5.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 18.6, "tree_w": 19, "tree_size": 128, "t0": 3.278, "t1": 0.67, "tft": 8.3827, "input_0": 374, "input_1": 129, "min_CLP": -5.26, "draft_iters": 19.4, "mem_use": 49.02, "gen_rate": 7.4, "speed": 1.88, "text": "\"User: Hey there! How are you do"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 23, "tree_size": 128, "t0": 2.54, "t1": 0.658, "tft": 4.6234, "input_0": 362, "input_1": 129, "min_CLP": -5.29, "draft_iters": 12.0, "mem_use": 46.82, "gen_rate": 6.8, "speed": 2.13, "text": "\"\u2022 Keep reminding yourself of th"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 26, "tree_size": 128, "t0": 2.1467, "t1": 0.6567, "tft": 3.7394, "input_0": 295, "input_1": 129, "min_CLP": -5.55, "draft_iters": 10.8, "mem_use": 46.07, "gen_rate": 5.7, "speed": 2.02, "text": "You are correct in that we know "}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 26, "tree_size": 128, "t0": 2.848, "t1": 0.636, "tft": 3.0954, "input_0": 430, "input_1": 129, "min_CLP": -5.35, "draft_iters": 13.2, "mem_use": 44.94, "gen_rate": 6.8, "speed": 1.95, "text": "Sure, here are some of the major"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 23, "tree_size": 128, "t0": 2.8725, "t1": 0.6375, "tft": 3.8884, "input_0": 442, "input_1": 129, "min_CLP": -5.42, "draft_iters": 12.5, "mem_use": 44.96, "gen_rate": 8.0, "speed": 2.28, "text": "\"In the context of the turn-base"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.5, "tree_w": 20, "tree_size": 128, "t0": 3.7875, "t1": 0.655, "tft": 5.5619, "input_0": 422, "input_1": 129, "min_CLP": -5.46, "draft_iters": 20.5, "mem_use": 45.78, "gen_rate": 10.0, "speed": 2.25, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 28.0, "tree_w": 12, "tree_size": 128, "t0": 5.03, "t1": 0.66, "tft": 5.0453, "input_0": 607, "input_1": 129, "min_CLP": -4.63, "draft_iters": 28.5, "mem_use": 46.32, "gen_rate": 23.0, "speed": 4.04, "text": "Here is a simpler script that ac"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.4, "tree_w": 37, "tree_size": 128, "t0": 1.998, "t1": 0.652, "tft": 3.9646, "input_0": 257, "input_1": 129, "min_CLP": -5.91, "draft_iters": 10.4, "mem_use": 45.73, "gen_rate": 7.8, "speed": 2.94, "text": "Hi! How can I assist you today?\\"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 34, "tree_size": 128, "t0": 1.7171, "t1": 0.6514, "tft": 6.3215, "input_0": 260, "input_1": 129, "min_CLP": -5.7, "draft_iters": 8.0, "mem_use": 45.84, "gen_rate": 4.7, "speed": 1.99, "text": "\"In your eyes, I see the heavens"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.2, "tree_w": 23, "tree_size": 128, "t0": 2.996, "t1": 0.642, "tft": 3.5614, "input_0": 384, "input_1": 129, "min_CLP": -5.32, "draft_iters": 15.2, "mem_use": 45.24, "gen_rate": 6.8, "speed": 1.87, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 26, "tree_size": 128, "t0": 2.596, "t1": 0.642, "tft": 4.6422, "input_0": 396, "input_1": 129, "min_CLP": -5.44, "draft_iters": 11.6, "mem_use": 45.2, "gen_rate": 6.6, "speed": 2.04, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.7, "tree_w": 31, "tree_size": 128, "t0": 2.445, "t1": 0.6517, "tft": 4.6078, "input_0": 356, "input_1": 129, "min_CLP": -5.76, "draft_iters": 11.7, "mem_use": 46.53, "gen_rate": 5.3, "speed": 1.72, "text": "\"You're welcome! If you encounte"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 30, "tree_size": 128, "t0": 1.972, "t1": 0.65, "tft": 5.0084, "input_0": 290, "input_1": 129, "min_CLP": -5.56, "draft_iters": 10.0, "mem_use": 46.45, "gen_rate": 7.0, "speed": 2.67, "text": "Yes, Open Assistant has been pre"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 29, "tree_size": 128, "t0": 2.6575, "t1": 0.6575, "tft": 6.6317, "input_0": 362, "input_1": 129, "min_CLP": -5.61, "draft_iters": 13.5, "mem_use": 47.92, "gen_rate": 9.2, "speed": 2.79, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 4.43, "t1": 0.64, "tft": 3.0053, "input_0": 246, "input_1": 129, "min_CLP": -7.13, "draft_iters": 32.0, "mem_use": 44.75, "gen_rate": 33.0, "speed": 6.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 45, "tree_size": 128, "t0": 1.5262, "t1": 0.65, "tft": 3.9287, "input_0": 226, "input_1": 129, "min_CLP": -5.92, "draft_iters": 7.5, "mem_use": 45.68, "gen_rate": 4.1, "speed": 1.9, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.2, "tree_w": 23, "tree_size": 128, "t0": 2.704, "t1": 0.652, "tft": 5.5323, "input_0": 365, "input_1": 129, "min_CLP": -5.41, "draft_iters": 14.2, "mem_use": 47.57, "gen_rate": 8.0, "speed": 2.39, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.6, "tree_w": 27, "tree_size": 128, "t0": 2.482, "t1": 0.644, "tft": 3.6433, "input_0": 326, "input_1": 129, "min_CLP": -5.35, "draft_iters": 13.6, "mem_use": 45.27, "gen_rate": 6.8, "speed": 2.18, "text": "- Introduction to the topic of s"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 25, "tree_h": 16.0, "tree_w": 20, "tree_size": 128, "t0": 3.0725, "t1": 0.6525, "tft": 6.8062, "input_0": 356, "input_1": 129, "min_CLP": -5.15, "draft_iters": 17.0, "mem_use": 46.13, "gen_rate": 6.2, "speed": 1.68, "text": "I apologize for my previous resp"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 128, "max_branch_width": 32, "gen_rate": 10.63, "gen_rate_micro": 8.26, "gen_speed": 2.718, "gen_speed_micro": 2.489, "t0": 2.9894, "t1": 0.6481, "input_0": 373.1, "input_1": 129.0, "tree_size": 128.0, "tree_w": 24.4, "tree_h": 15.0, "prompt_len": 298.0, "min_CLP": -5.49, "mem_use": 54.23, "exp_time": 10200.26}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 40, "tree_size": 256, "t0": 4.4075, "t1": 0.8725, "tft": 5.9029, "input_0": 917, "input_1": 257, "min_CLP": -5.94, "draft_iters": 18.0, "mem_use": 45.51, "gen_rate": 8.5, "speed": 1.61, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 14.8, "tree_w": 53, "tree_size": 256, "t0": 3.576, "t1": 0.89, "tft": 6.2529, "input_0": 710, "input_1": 257, "min_CLP": -6.39, "draft_iters": 16.2, "mem_use": 47.06, "gen_rate": 8.4, "speed": 1.88, "text": "I apologize for the mistake in m"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 12.7, "tree_w": 49, "tree_size": 256, "t0": 3.49, "t1": 0.89, "tft": 6.4461, "input_0": 745, "input_1": 257, "min_CLP": -6.28, "draft_iters": 14.2, "mem_use": 47.96, "gen_rate": 8.0, "speed": 1.83, "text": "1. Minecraft - Minecraft is a ga"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 21.3, "tree_w": 28, "tree_size": 256, "t0": 5.47, "t1": 0.8733, "tft": 6.8856, "input_0": 1071, "input_1": 257, "min_CLP": -5.51, "draft_iters": 23.0, "mem_use": 45.69, "gen_rate": 15.0, "speed": 2.36, "text": "\"Sure, here's a Python script th"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 12.5, "tree_w": 51, "tree_size": 256, "t0": 3.735, "t1": 0.87, "tft": 4.2496, "input_0": 954, "input_1": 257, "min_CLP": -6.2, "draft_iters": 14.0, "mem_use": 45.53, "gen_rate": 8.0, "speed": 1.74, "text": "Sure, I can help you write your "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.7, "tree_w": 41, "tree_size": 256, "t0": 3.7933, "t1": 0.8933, "tft": 9.0801, "input_0": 873, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.0, "mem_use": 48.09, "gen_rate": 12.0, "speed": 2.56, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 19.5, "tree_w": 34, "tree_size": 256, "t0": 5.205, "t1": 0.895, "tft": 8.1928, "input_0": 1131, "input_1": 257, "min_CLP": -6.08, "draft_iters": 21.0, "mem_use": 48.68, "gen_rate": 16.5, "speed": 2.7, "text": "One option for enhancing images "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 17.0, "tree_w": 29, "tree_size": 256, "t0": 4.31, "t1": 0.9167, "tft": 8.6272, "input_0": 891, "input_1": 257, "min_CLP": -5.66, "draft_iters": 18.0, "mem_use": 50.86, "gen_rate": 12.3, "speed": 2.36, "text": "To attract the right customers i"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 23.0, "tree_w": 25, "tree_size": 256, "t0": 5.5225, "t1": 0.8925, "tft": 6.9852, "input_0": 1064, "input_1": 257, "min_CLP": -5.65, "draft_iters": 24.0, "mem_use": 48.28, "gen_rate": 11.2, "speed": 1.75, "text": "The legal status of marijuana va"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.7, "tree_w": 30, "tree_size": 256, "t0": 4.3467, "t1": 0.8867, "tft": 6.6483, "input_0": 964, "input_1": 257, "min_CLP": -5.8, "draft_iters": 16.7, "mem_use": 47.66, "gen_rate": 11.0, "speed": 2.1, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.0, "tree_w": 71, "tree_size": 256, "t0": 4.43, "t1": 0.88, "tft": 6.969, "input_0": 871, "input_1": 257, "min_CLP": -7.3, "draft_iters": 20.5, "mem_use": 46.18, "gen_rate": 16.5, "speed": 3.1, "text": "``The first number is A.\\nRead A"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.8, "tree_w": 39, "tree_size": 256, "t0": 4.2675, "t1": 0.8875, "tft": 7.8085, "input_0": 878, "input_1": 257, "min_CLP": -5.88, "draft_iters": 18.0, "mem_use": 48.03, "gen_rate": 8.0, "speed": 1.55, "text": "Sure, here\\'s a shortened summar"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 19.7, "tree_w": 26, "tree_size": 256, "t0": 4.97, "t1": 0.8867, "tft": 6.2665, "input_0": 1029, "input_1": 257, "min_CLP": -5.83, "draft_iters": 21.0, "mem_use": 47.25, "gen_rate": 14.0, "speed": 2.39, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 42, "tree_size": 256, "t0": 5.48, "t1": 0.87, "tft": 6.6238, "input_0": 727, "input_1": 257, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 45.51, "gen_rate": 33.0, "speed": 5.2, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 38, "tree_size": 256, "t0": 3.5733, "t1": 0.9, "tft": 7.0575, "input_0": 783, "input_1": 257, "min_CLP": -5.89, "draft_iters": 14.0, "mem_use": 48.65, "gen_rate": 10.7, "speed": 2.39, "text": "Spaced repetition and fun activi"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 34, "tree_size": 256, "t0": 4.18, "t1": 0.8733, "tft": 6.9817, "input_0": 915, "input_1": 257, "min_CLP": -5.91, "draft_iters": 18.0, "mem_use": 45.85, "gen_rate": 12.0, "speed": 2.37, "text": "\"To stream at 720p 30fps to Twit"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 24.0, "tree_w": 23, "tree_size": 256, "t0": 5.4, "t1": 0.87, "tft": 5.8737, "input_0": 976, "input_1": 257, "min_CLP": -5.61, "draft_iters": 25.5, "mem_use": 45.53, "gen_rate": 20.5, "speed": 3.27, "text": "\"Sure, I'd be happy to explain F"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 6.01, "t1": 0.87, "tft": 5.1498, "input_0": 875, "input_1": 257, "min_CLP": -8.07, "draft_iters": 32.0, "mem_use": 45.51, "gen_rate": 33.0, "speed": 4.8, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 21.7, "tree_w": 31, "tree_size": 256, "t0": 5.6567, "t1": 0.88, "tft": 6.9259, "input_0": 1108, "input_1": 257, "min_CLP": -5.99, "draft_iters": 23.0, "mem_use": 46.04, "gen_rate": 18.0, "speed": 2.75, "text": "D-theanine is the less common fo"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.7, "tree_w": 30, "tree_size": 256, "t0": 4.91, "t1": 0.8767, "tft": 6.0922, "input_0": 877, "input_1": 257, "min_CLP": -5.48, "draft_iters": 22.3, "mem_use": 45.52, "gen_rate": 13.0, "speed": 2.25, "text": "The Balfour Declaration was a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 23, "tree_h": 12.2, "tree_w": 59, "tree_size": 256, "t0": 3.178, "t1": 0.882, "tft": 6.2675, "input_0": 664, "input_1": 257, "min_CLP": -6.41, "draft_iters": 13.4, "mem_use": 46.37, "gen_rate": 4.6, "speed": 1.13, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 14.0, "tree_w": 62, "tree_size": 256, "t0": 3.76, "t1": 0.87, "tft": 5.9443, "input_0": 880, "input_1": 257, "min_CLP": -6.75, "draft_iters": 15.0, "mem_use": 45.51, "gen_rate": 11.0, "speed": 2.37, "text": "Hello there Obi-Wan Kenobi! How "}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 36, "tree_size": 256, "t0": 4.36, "t1": 0.8925, "tft": 7.5986, "input_0": 1009, "input_1": 257, "min_CLP": -5.71, "draft_iters": 16.5, "mem_use": 47.87, "gen_rate": 8.2, "speed": 1.57, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.5, "tree_w": 35, "tree_size": 256, "t0": 4.03, "t1": 0.87, "tft": 4.4743, "input_0": 844, "input_1": 257, "min_CLP": -5.84, "draft_iters": 16.8, "mem_use": 45.58, "gen_rate": 8.2, "speed": 1.68, "text": "Certainly! Here is a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.0, "tree_w": 33, "tree_size": 256, "t0": 4.1833, "t1": 0.88, "tft": 6.267, "input_0": 893, "input_1": 257, "min_CLP": -6.31, "draft_iters": 18.0, "mem_use": 46.55, "gen_rate": 11.7, "speed": 2.3, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 42, "tree_size": 256, "t0": 5.75, "t1": 0.87, "tft": 4.6053, "input_0": 914, "input_1": 257, "min_CLP": -7.96, "draft_iters": 32.0, "mem_use": 45.55, "gen_rate": 33.0, "speed": 4.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 60, "tree_size": 256, "t0": 3.172, "t1": 0.878, "tft": 6.0362, "input_0": 770, "input_1": 257, "min_CLP": -6.43, "draft_iters": 12.0, "mem_use": 46.22, "gen_rate": 7.6, "speed": 1.88, "text": "Austenite is a type of allotrope"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 12.3, "tree_w": 52, "tree_size": 256, "t0": 3.8533, "t1": 0.88, "tft": 5.8495, "input_0": 924, "input_1": 257, "min_CLP": -6.63, "draft_iters": 13.3, "mem_use": 46.08, "gen_rate": 6.7, "speed": 1.41, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 65, "tree_size": 256, "t0": 2.61, "t1": 0.8883, "tft": 5.9321, "input_0": 570, "input_1": 257, "min_CLP": -6.46, "draft_iters": 10.7, "mem_use": 48.02, "gen_rate": 5.3, "speed": 1.52, "text": "\"Magic, oh magic, it\\'s in the a"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 45, "tree_size": 256, "t0": 5.98, "t1": 0.87, "tft": 5.4912, "input_0": 945, "input_1": 257, "min_CLP": -8.27, "draft_iters": 32.0, "mem_use": 45.56, "gen_rate": 33.0, "speed": 4.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 20.0, "tree_w": 36, "tree_size": 256, "t0": 4.9275, "t1": 0.88, "tft": 6.0377, "input_0": 943, "input_1": 257, "min_CLP": -6.04, "draft_iters": 21.2, "mem_use": 46.26, "gen_rate": 8.8, "speed": 1.51, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 25.5, "tree_w": 31, "tree_size": 256, "t0": 5.575, "t1": 0.88, "tft": 7.0855, "input_0": 948, "input_1": 257, "min_CLP": -5.99, "draft_iters": 27.0, "mem_use": 46.67, "gen_rate": 24.0, "speed": 3.72, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 57, "tree_size": 256, "t0": 2.7725, "t1": 0.8725, "tft": 4.1906, "input_0": 583, "input_1": 257, "min_CLP": -6.2, "draft_iters": 11.0, "mem_use": 46.02, "gen_rate": 9.0, "speed": 2.47, "text": "Oh, my dear followers, I hear yo"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 11.7, "tree_w": 45, "tree_size": 256, "t0": 3.3322, "t1": 0.8889, "tft": 5.8408, "input_0": 748, "input_1": 257, "min_CLP": -6.11, "draft_iters": 13.1, "mem_use": 47.67, "gen_rate": 4.0, "speed": 0.95, "text": "Yes! There are many varieties of"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.3, "tree_w": 43, "tree_size": 256, "t0": 3.6067, "t1": 0.8867, "tft": 6.0786, "input_0": 784, "input_1": 257, "min_CLP": -6.0, "draft_iters": 15.0, "mem_use": 47.71, "gen_rate": 11.7, "speed": 2.6, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.2, "tree_w": 43, "tree_size": 256, "t0": 4.155, "t1": 0.9125, "tft": 10.4491, "input_0": 936, "input_1": 257, "min_CLP": -5.97, "draft_iters": 17.5, "mem_use": 50.45, "gen_rate": 10.2, "speed": 2.02, "text": "Selenium can be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.0, "tree_w": 49, "tree_size": 256, "t0": 3.622, "t1": 0.87, "tft": 6.4847, "input_0": 762, "input_1": 257, "min_CLP": -6.04, "draft_iters": 16.4, "mem_use": 45.54, "gen_rate": 7.2, "speed": 1.6, "text": "Answer: The airspeed velocity of"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 52, "tree_size": 256, "t0": 5.05, "t1": 0.87, "tft": 7.3031, "input_0": 858, "input_1": 257, "min_CLP": -6.6, "draft_iters": 24.0, "mem_use": 46.07, "gen_rate": 24.5, "speed": 4.14, "text": "The second verse of \"Never Gonna"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.5, "tree_w": 45, "tree_size": 256, "t0": 3.375, "t1": 0.89, "tft": 6.7104, "input_0": 640, "input_1": 257, "min_CLP": -6.06, "draft_iters": 15.5, "mem_use": 48.45, "gen_rate": 8.8, "speed": 2.05, "text": "\"Hello again! It's great to be b"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 24.0, "tree_w": 29, "tree_size": 256, "t0": 5.77, "t1": 0.88, "tft": 7.3549, "input_0": 1227, "input_1": 257, "min_CLP": -5.94, "draft_iters": 25.5, "mem_use": 46.48, "gen_rate": 17.0, "speed": 2.56, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 8.2, "tree_w": 75, "tree_size": 256, "t0": 2.295, "t1": 0.8675, "tft": 4.1929, "input_0": 493, "input_1": 257, "min_CLP": -6.71, "draft_iters": 9.5, "mem_use": 45.77, "gen_rate": 5.5, "speed": 1.74, "text": "My power is not for sale, mortal"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 48, "tree_size": 256, "t0": 5.23, "t1": 0.88, "tft": 8.4516, "input_0": 669, "input_1": 257, "min_CLP": -6.57, "draft_iters": 32.0, "mem_use": 48.27, "gen_rate": 33.0, "speed": 5.39, "text": "\"[INST] The monologue presents a"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 13.3, "tree_w": 76, "tree_size": 256, "t0": 2.801, "t1": 0.901, "tft": 5.9627, "input_0": 490, "input_1": 257, "min_CLP": -6.75, "draft_iters": 14.3, "mem_use": 48.7, "gen_rate": 3.5, "speed": 0.95, "text": "[INST] I would like to have a co"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.5, "tree_w": 39, "tree_size": 256, "t0": 4.47, "t1": 0.8825, "tft": 6.2316, "input_0": 1002, "input_1": 257, "min_CLP": -5.79, "draft_iters": 18.0, "mem_use": 47.05, "gen_rate": 9.5, "speed": 1.77, "text": "The \"best\" SAST tool depends on "}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 49, "tree_size": 256, "t0": 5.27, "t1": 0.88, "tft": 6.691, "input_0": 647, "input_1": 257, "min_CLP": -6.73, "draft_iters": 32.0, "mem_use": 46.3, "gen_rate": 33.0, "speed": 5.37, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 17.6, "tree_w": 62, "tree_size": 256, "t0": 3.62, "t1": 0.876, "tft": 5.8707, "input_0": 589, "input_1": 257, "min_CLP": -6.85, "draft_iters": 19.0, "mem_use": 46.03, "gen_rate": 6.8, "speed": 1.51, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 19.8, "tree_w": 28, "tree_size": 256, "t0": 4.7525, "t1": 0.87, "tft": 5.2977, "input_0": 966, "input_1": 257, "min_CLP": -5.81, "draft_iters": 20.8, "mem_use": 45.54, "gen_rate": 14.8, "speed": 2.62, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 23.8, "tree_w": 41, "tree_size": 256, "t0": 4.7725, "t1": 0.92, "tft": 9.5534, "input_0": 738, "input_1": 257, "min_CLP": -6.12, "draft_iters": 25.0, "mem_use": 51.01, "gen_rate": 9.2, "speed": 1.63, "text": "\"Certainly! Here's a revised ver"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 81, "tree_size": 256, "t0": 2.215, "t1": 0.8867, "tft": 4.8735, "input_0": 501, "input_1": 257, "min_CLP": -6.66, "draft_iters": 8.7, "mem_use": 47.29, "gen_rate": 5.7, "speed": 1.83, "text": "Yes, the agent nods, and I conti"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.5, "tree_w": 76, "tree_size": 256, "t0": 2.3083, "t1": 0.8783, "tft": 3.8761, "input_0": 503, "input_1": 257, "min_CLP": -6.6, "draft_iters": 9.5, "mem_use": 46.3, "gen_rate": 6.2, "speed": 1.94, "text": "\"I'm glad you understand. If you"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.3, "tree_w": 80, "tree_size": 256, "t0": 3.12, "t1": 0.8717, "tft": 4.6513, "input_0": 647, "input_1": 257, "min_CLP": -6.79, "draft_iters": 14.7, "mem_use": 45.82, "gen_rate": 5.5, "speed": 1.38, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002 "}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 26.0, "tree_w": 27, "tree_size": 256, "t0": 5.55, "t1": 0.885, "tft": 8.5842, "input_0": 1005, "input_1": 257, "min_CLP": -5.52, "draft_iters": 27.0, "mem_use": 47.71, "gen_rate": 22.5, "speed": 3.49, "text": "\"Sure, here's a summary of how F"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.7, "tree_w": 37, "tree_size": 256, "t0": 4.46, "t1": 0.8867, "tft": 8.2011, "input_0": 955, "input_1": 257, "min_CLP": -6.22, "draft_iters": 18.0, "mem_use": 46.93, "gen_rate": 11.0, "speed": 2.06, "text": "Sure! Here are some more histori"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.2, "tree_w": 34, "tree_size": 256, "t0": 4.295, "t1": 0.8875, "tft": 6.0507, "input_0": 873, "input_1": 257, "min_CLP": -5.87, "draft_iters": 17.8, "mem_use": 47.27, "gen_rate": 8.2, "speed": 1.59, "text": "Yes, while technology has the po"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 59, "tree_size": 256, "t0": 3.08, "t1": 0.872, "tft": 3.8741, "input_0": 722, "input_1": 257, "min_CLP": -6.26, "draft_iters": 11.4, "mem_use": 45.71, "gen_rate": 6.4, "speed": 1.62, "text": "In real life, people of all ages"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 18.3, "tree_w": 33, "tree_size": 256, "t0": 4.73, "t1": 0.89, "tft": 7.1766, "input_0": 1043, "input_1": 257, "min_CLP": -6.06, "draft_iters": 19.3, "mem_use": 48.12, "gen_rate": 13.7, "speed": 2.43, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.2, "tree_w": 41, "tree_size": 256, "t0": 3.7475, "t1": 0.905, "tft": 8.98, "input_0": 684, "input_1": 257, "min_CLP": -6.07, "draft_iters": 17.5, "mem_use": 49.37, "gen_rate": 9.0, "speed": 1.93, "text": "\"You're right, I apologize for t"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.0, "tree_w": 35, "tree_size": 256, "t0": 3.98, "t1": 0.9025, "tft": 7.1961, "input_0": 862, "input_1": 257, "min_CLP": -5.84, "draft_iters": 15.5, "mem_use": 49.54, "gen_rate": 9.2, "speed": 1.9, "text": "\"As a beginner with little progr"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.0, "tree_w": 24, "tree_size": 256, "t0": 4.8267, "t1": 0.89, "tft": 6.7741, "input_0": 888, "input_1": 257, "min_CLP": -6.09, "draft_iters": 21.0, "mem_use": 47.19, "gen_rate": 12.7, "speed": 2.22, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 42, "tree_size": 256, "t0": 5.75, "t1": 0.86, "tft": 6.2929, "input_0": 942, "input_1": 257, "min_CLP": -7.83, "draft_iters": 32.0, "mem_use": 45.53, "gen_rate": 32.0, "speed": 4.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.0, "tree_w": 65, "tree_size": 256, "t0": 3.0967, "t1": 0.8867, "tft": 6.1821, "input_0": 603, "input_1": 257, "min_CLP": -6.82, "draft_iters": 14.0, "mem_use": 47.95, "gen_rate": 11.0, "speed": 2.76, "text": "[INST] provide a direct yes or n"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.5, "tree_w": 48, "tree_size": 256, "t0": 3.2575, "t1": 0.8975, "tft": 7.1856, "input_0": 760, "input_1": 257, "min_CLP": -6.11, "draft_iters": 13.0, "mem_use": 48.79, "gen_rate": 8.8, "speed": 2.11, "text": "\"[The scene opens on a battlefie"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.0, "tree_w": 60, "tree_size": 256, "t0": 2.6017, "t1": 0.8767, "tft": 4.033, "input_0": 551, "input_1": 257, "min_CLP": -6.37, "draft_iters": 11.0, "mem_use": 46.49, "gen_rate": 6.0, "speed": 1.72, "text": "I see. Another option could be, "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 52, "tree_size": 256, "t0": 3.0025, "t1": 0.875, "tft": 5.5489, "input_0": 637, "input_1": 257, "min_CLP": -6.11, "draft_iters": 12.5, "mem_use": 46.2, "gen_rate": 8.2, "speed": 2.13, "text": "The proof-of-stake concept is a "}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 13.0, "tree_w": 79, "tree_size": 256, "t0": 2.675, "t1": 0.875, "tft": 5.8862, "input_0": 470, "input_1": 257, "min_CLP": -6.49, "draft_iters": 14.0, "mem_use": 46.33, "gen_rate": 4.0, "speed": 1.13, "text": "\"I don't understand the question"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.5, "tree_w": 45, "tree_size": 256, "t0": 3.7975, "t1": 0.89, "tft": 7.0402, "input_0": 852, "input_1": 257, "min_CLP": -6.01, "draft_iters": 14.2, "mem_use": 48.41, "gen_rate": 9.0, "speed": 1.92, "text": "A void pointer is a pointer in C"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.5, "tree_w": 42, "tree_size": 256, "t0": 3.3975, "t1": 0.8975, "tft": 7.4413, "input_0": 803, "input_1": 257, "min_CLP": -6.21, "draft_iters": 13.5, "mem_use": 48.92, "gen_rate": 9.0, "speed": 2.1, "text": "\"Hello Mike, I'm sorry to hear t"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 13.5, "tree_w": 41, "tree_size": 256, "t0": 3.7675, "t1": 0.8875, "tft": 7.9006, "input_0": 842, "input_1": 257, "min_CLP": -6.09, "draft_iters": 14.5, "mem_use": 48.12, "gen_rate": 10.5, "speed": 2.26, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 16.0, "tree_w": 26, "tree_size": 256, "t0": 4.07, "t1": 0.88, "tft": 3.9403, "input_0": 883, "input_1": 257, "min_CLP": -5.72, "draft_iters": 17.0, "mem_use": 45.95, "gen_rate": 11.0, "speed": 2.22, "text": "You are welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.2, "tree_w": 36, "tree_size": 256, "t0": 3.948, "t1": 0.87, "tft": 4.728, "input_0": 854, "input_1": 257, "min_CLP": -5.87, "draft_iters": 16.4, "mem_use": 45.53, "gen_rate": 7.6, "speed": 1.58, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 256, "t0": 6.31, "t1": 0.89, "tft": 9.3455, "input_0": 1087, "input_1": 257, "min_CLP": -6.28, "draft_iters": 32.0, "mem_use": 48.36, "gen_rate": 33.0, "speed": 4.58, "text": "\"Certainly, here's the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.8, "tree_w": 47, "tree_size": 256, "t0": 4.188, "t1": 0.872, "tft": 5.1293, "input_0": 752, "input_1": 257, "min_CLP": -6.21, "draft_iters": 20.0, "mem_use": 45.49, "gen_rate": 6.4, "speed": 1.26, "text": "The question you asked is not cl"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 30, "tree_size": 256, "t0": 6.6, "t1": 0.88, "tft": 5.5864, "input_0": 1148, "input_1": 257, "min_CLP": -6.21, "draft_iters": 32.0, "mem_use": 47.82, "gen_rate": 32.0, "speed": 4.28, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 27.0, "tree_w": 26, "tree_size": 256, "t0": 6.26, "t1": 0.89, "tft": 6.5679, "input_0": 1160, "input_1": 257, "min_CLP": -5.91, "draft_iters": 28.0, "mem_use": 47.68, "gen_rate": 17.5, "speed": 2.45, "text": "Certainly! While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 57, "tree_size": 256, "t0": 5.69, "t1": 0.87, "tft": 6.3518, "input_0": 894, "input_1": 257, "min_CLP": -7.53, "draft_iters": 32.0, "mem_use": 45.51, "gen_rate": 33.0, "speed": 5.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 64, "tree_size": 256, "t0": 3.14, "t1": 0.8775, "tft": 6.3335, "input_0": 688, "input_1": 257, "min_CLP": -6.47, "draft_iters": 13.5, "mem_use": 45.82, "gen_rate": 8.5, "speed": 2.12, "text": "You can find out your current ti"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 64, "tree_size": 256, "t0": 2.6817, "t1": 0.875, "tft": 4.095, "input_0": 601, "input_1": 257, "min_CLP": -6.41, "draft_iters": 10.8, "mem_use": 45.9, "gen_rate": 5.8, "speed": 1.64, "text": "The five second rule is a myth. "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 29.5, "tree_w": 20, "tree_size": 256, "t0": 7.39, "t1": 0.875, "tft": 5.6394, "input_0": 1427, "input_1": 257, "min_CLP": -5.45, "draft_iters": 30.5, "mem_use": 45.63, "gen_rate": 27.0, "speed": 3.27, "text": "\"Sure, let's break it down step "}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 18.0, "tree_w": 28, "tree_size": 256, "t0": 4.67, "t1": 0.875, "tft": 6.692, "input_0": 945, "input_1": 257, "min_CLP": -5.49, "draft_iters": 19.5, "mem_use": 46.38, "gen_rate": 17.0, "speed": 3.06, "text": "Certainly! One of the most well-"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 58, "tree_size": 256, "t0": 3.4725, "t1": 0.88, "tft": 3.7017, "input_0": 736, "input_1": 257, "min_CLP": -6.49, "draft_iters": 14.5, "mem_use": 45.94, "gen_rate": 8.2, "speed": 1.9, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.0, "tree_w": 70, "tree_size": 256, "t0": 2.77, "t1": 0.87, "tft": 6.6358, "input_0": 555, "input_1": 257, "min_CLP": -6.48, "draft_iters": 12.2, "mem_use": 45.65, "gen_rate": 5.7, "speed": 1.56, "text": "\"#OpenAssistant is now #open-sou"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.0, "tree_w": 49, "tree_size": 256, "t0": 3.544, "t1": 0.88, "tft": 5.9934, "input_0": 790, "input_1": 257, "min_CLP": -6.06, "draft_iters": 13.4, "mem_use": 46.27, "gen_rate": 7.2, "speed": 1.63, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 15.3, "tree_w": 39, "tree_size": 256, "t0": 4.5667, "t1": 0.89, "tft": 6.7784, "input_0": 1005, "input_1": 257, "min_CLP": -5.82, "draft_iters": 17.0, "mem_use": 47.31, "gen_rate": 14.7, "speed": 2.69, "text": "Certainly! AI assistants can als"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 64, "tree_size": 256, "t0": 4.905, "t1": 0.89, "tft": 8.8351, "input_0": 830, "input_1": 257, "min_CLP": -7.12, "draft_iters": 20.5, "mem_use": 48.33, "gen_rate": 20.5, "speed": 3.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 15.3, "tree_w": 36, "tree_size": 256, "t0": 4.2833, "t1": 0.88, "tft": 6.1924, "input_0": 965, "input_1": 257, "min_CLP": -5.91, "draft_iters": 16.7, "mem_use": 46.83, "gen_rate": 13.0, "speed": 2.52, "text": "The scp command is available on "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 31.5, "tree_w": 25, "tree_size": 256, "t0": 6.12, "t1": 0.89, "tft": 8.264, "input_0": 891, "input_1": 257, "min_CLP": -5.6, "draft_iters": 32.0, "mem_use": 47.47, "gen_rate": 24.0, "speed": 3.42, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.8, "tree_w": 47, "tree_size": 256, "t0": 3.746, "t1": 0.872, "tft": 6.1957, "input_0": 798, "input_1": 257, "min_CLP": -6.05, "draft_iters": 16.2, "mem_use": 45.56, "gen_rate": 7.0, "speed": 1.52, "text": "No, it would not be illegal to k"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 14.8, "tree_w": 42, "tree_size": 256, "t0": 3.7775, "t1": 0.87, "tft": 5.5684, "input_0": 816, "input_1": 257, "min_CLP": -6.22, "draft_iters": 15.8, "mem_use": 45.85, "gen_rate": 11.5, "speed": 2.47, "text": "\"Sydney is the largest city in A"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 37, "tree_size": 256, "t0": 5.61, "t1": 0.88, "tft": 4.1933, "input_0": 805, "input_1": 257, "min_CLP": -6.23, "draft_iters": 32.0, "mem_use": 46.15, "gen_rate": 32.0, "speed": 4.93, "text": "\"The five second rule is a dange"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 16.0, "tree_w": 64, "tree_size": 256, "t0": 3.3329, "t1": 0.8757, "tft": 4.4452, "input_0": 577, "input_1": 257, "min_CLP": -6.58, "draft_iters": 17.0, "mem_use": 45.82, "gen_rate": 3.7, "speed": 0.88, "text": "\"I'm glad you appreciate it. Now"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 37, "tree_size": 256, "t0": 5.87, "t1": 0.87, "tft": 5.964, "input_0": 900, "input_1": 257, "min_CLP": -7.61, "draft_iters": 32.0, "mem_use": 45.59, "gen_rate": 33.0, "speed": 4.89, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 15.7, "tree_w": 31, "tree_size": 256, "t0": 3.78, "t1": 0.87, "tft": 6.787, "input_0": 763, "input_1": 257, "min_CLP": -5.8, "draft_iters": 16.7, "mem_use": 45.57, "gen_rate": 14.3, "speed": 3.08, "text": "\"The task is to estimate the tim"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 25.0, "tree_w": 26, "tree_size": 256, "t0": 5.815, "t1": 0.88, "tft": 8.7818, "input_0": 1223, "input_1": 257, "min_CLP": -5.77, "draft_iters": 26.0, "mem_use": 47.31, "gen_rate": 16.0, "speed": 2.39, "text": "Certainly! The Taniyama-Shimura-"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 60, "tree_size": 256, "t0": 5.34, "t1": 0.88, "tft": 6.4199, "input_0": 875, "input_1": 257, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 45.57, "gen_rate": 33.0, "speed": 5.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.5, "tree_w": 32, "tree_size": 256, "t0": 4.33, "t1": 0.8725, "tft": 6.9042, "input_0": 862, "input_1": 257, "min_CLP": -5.83, "draft_iters": 18.8, "mem_use": 45.88, "gen_rate": 9.0, "speed": 1.73, "text": "To write a first-person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.7, "tree_w": 49, "tree_size": 256, "t0": 3.35, "t1": 0.8667, "tft": 5.2989, "input_0": 664, "input_1": 257, "min_CLP": -6.22, "draft_iters": 15.7, "mem_use": 45.54, "gen_rate": 11.0, "speed": 2.61, "text": "Answer: To start learning guitar"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 9.6, "tree_w": 66, "tree_size": 256, "t0": 2.59, "t1": 0.8729, "tft": 3.5493, "input_0": 563, "input_1": 257, "min_CLP": -6.35, "draft_iters": 10.9, "mem_use": 45.86, "gen_rate": 5.9, "speed": 1.69, "text": "\"As a Jedi, my goal is to help y"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 62, "tree_size": 256, "t0": 2.6533, "t1": 0.8717, "tft": 4.5998, "input_0": 614, "input_1": 257, "min_CLP": -6.4, "draft_iters": 10.2, "mem_use": 45.71, "gen_rate": 5.7, "speed": 1.61, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.3, "tree_w": 40, "tree_size": 256, "t0": 3.3133, "t1": 0.87, "tft": 5.8224, "input_0": 686, "input_1": 257, "min_CLP": -6.09, "draft_iters": 14.3, "mem_use": 45.96, "gen_rate": 12.0, "speed": 2.87, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 15.0, "tree_w": 38, "tree_size": 256, "t0": 3.988, "t1": 0.896, "tft": 6.9071, "input_0": 862, "input_1": 257, "min_CLP": -6.05, "draft_iters": 16.4, "mem_use": 48.81, "gen_rate": 9.4, "speed": 1.92, "text": "Yes, there are several libraries"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 55, "tree_size": 256, "t0": 3.164, "t1": 0.88, "tft": 5.8777, "input_0": 668, "input_1": 257, "min_CLP": -6.26, "draft_iters": 13.4, "mem_use": 46.02, "gen_rate": 6.4, "speed": 1.58, "text": "\"Yes, if someone goes to the tro"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 6, "tree_h": 9.3, "tree_w": 59, "tree_size": 256, "t0": 2.6367, "t1": 0.8967, "tft": 6.9501, "input_0": 579, "input_1": 257, "min_CLP": -6.38, "draft_iters": 10.3, "mem_use": 48.91, "gen_rate": 2.0, "speed": 0.57, "text": "Xin ch\u00e0o!\\n\\nB\u1ea1n c\u1ea7n gi\u00fap g\u00ec kh\u00f4"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.4, "tree_w": 80, "tree_size": 256, "t0": 2.1278, "t1": 0.8789, "tft": 5.3378, "input_0": 478, "input_1": 257, "min_CLP": -6.69, "draft_iters": 8.6, "mem_use": 46.39, "gen_rate": 3.7, "speed": 1.22, "text": "The spaghetti story was a hoax a"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 31.5, "tree_w": 14, "tree_size": 256, "t0": 6.69, "t1": 0.87, "tft": 5.6489, "input_0": 1273, "input_1": 257, "min_CLP": -5.49, "draft_iters": 32.0, "mem_use": 45.9, "gen_rate": 25.0, "speed": 3.3, "text": "Sure! Here\\'s an example of a de"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 17.5, "tree_w": 36, "tree_size": 256, "t0": 4.805, "t1": 0.89, "tft": 6.0789, "input_0": 913, "input_1": 257, "min_CLP": -6.58, "draft_iters": 18.5, "mem_use": 47.34, "gen_rate": 16.5, "speed": 2.9, "text": "1. Scorpions\\n2. Rammstein\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 10.0, "tree_w": 78, "tree_size": 256, "t0": 2.685, "t1": 0.875, "tft": 3.9774, "input_0": 564, "input_1": 257, "min_CLP": -6.68, "draft_iters": 11.5, "mem_use": 45.87, "gen_rate": 8.3, "speed": 2.34, "text": "If you are playing with someone "}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.7, "tree_w": 29, "tree_size": 256, "t0": 4.97, "t1": 0.89, "tft": 7.3885, "input_0": 999, "input_1": 257, "min_CLP": -5.55, "draft_iters": 20.7, "mem_use": 47.88, "gen_rate": 11.3, "speed": 1.93, "text": "\"Sure, I can offer some advice o"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.2, "tree_w": 40, "tree_size": 256, "t0": 3.602, "t1": 0.88, "tft": 4.5643, "input_0": 787, "input_1": 257, "min_CLP": -6.28, "draft_iters": 14.6, "mem_use": 46.5, "gen_rate": 7.0, "speed": 1.56, "text": "Yes, I am capable of simulating "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 47, "tree_size": 256, "t0": 3.114, "t1": 0.876, "tft": 4.5093, "input_0": 647, "input_1": 257, "min_CLP": -6.04, "draft_iters": 13.8, "mem_use": 46.03, "gen_rate": 7.0, "speed": 1.75, "text": "Romeo is the most to blame for t"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 20.3, "tree_w": 30, "tree_size": 256, "t0": 5.1067, "t1": 0.88, "tft": 5.2039, "input_0": 1005, "input_1": 257, "min_CLP": -5.81, "draft_iters": 21.3, "mem_use": 46.17, "gen_rate": 15.3, "speed": 2.56, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 13.3, "tree_w": 59, "tree_size": 256, "t0": 2.9957, "t1": 0.89, "tft": 6.8467, "input_0": 594, "input_1": 257, "min_CLP": -6.9, "draft_iters": 14.3, "mem_use": 47.45, "gen_rate": 4.9, "speed": 1.25, "text": "\"Here's a simple poem to express"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 55, "tree_size": 256, "t0": 3.4567, "t1": 0.8733, "tft": 5.2747, "input_0": 752, "input_1": 257, "min_CLP": -6.18, "draft_iters": 15.0, "mem_use": 45.54, "gen_rate": 10.7, "speed": 2.46, "text": "Answer: The five most common cau"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.5, "tree_w": 37, "tree_size": 256, "t0": 4.0175, "t1": 0.87, "tft": 6.7549, "input_0": 921, "input_1": 257, "min_CLP": -5.93, "draft_iters": 15.0, "mem_use": 45.58, "gen_rate": 9.0, "speed": 1.84, "text": "The error in the code is that th"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 18, "tree_h": 16.0, "tree_w": 72, "tree_size": 256, "t0": 3.13, "t1": 0.8767, "tft": 4.6662, "input_0": 513, "input_1": 257, "min_CLP": -6.58, "draft_iters": 16.7, "mem_use": 46.98, "gen_rate": 6.0, "speed": 1.5, "text": "[INST] What is the name of this "}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.0, "tree_w": 49, "tree_size": 256, "t0": 3.4725, "t1": 0.875, "tft": 5.0879, "input_0": 749, "input_1": 257, "min_CLP": -6.15, "draft_iters": 14.5, "mem_use": 46.19, "gen_rate": 10.0, "speed": 2.3, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 20.3, "tree_w": 33, "tree_size": 256, "t0": 4.6167, "t1": 0.88, "tft": 5.211, "input_0": 848, "input_1": 257, "min_CLP": -5.81, "draft_iters": 21.7, "mem_use": 46.32, "gen_rate": 11.7, "speed": 2.12, "text": "\"You can use the `argparse` modu"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.2, "tree_w": 42, "tree_size": 256, "t0": 3.7825, "t1": 0.8925, "tft": 6.8408, "input_0": 885, "input_1": 257, "min_CLP": -5.95, "draft_iters": 14.0, "mem_use": 48.1, "gen_rate": 8.2, "speed": 1.77, "text": "\"It's important to prioritize yo"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 32.0, "tree_w": 30, "tree_size": 256, "t0": 6.125, "t1": 0.88, "tft": 4.8439, "input_0": 882, "input_1": 257, "min_CLP": -5.94, "draft_iters": 32.0, "mem_use": 46.1, "gen_rate": 25.5, "speed": 3.64, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.8, "tree_w": 38, "tree_size": 256, "t0": 4.3775, "t1": 0.8925, "tft": 8.7735, "input_0": 847, "input_1": 257, "min_CLP": -5.87, "draft_iters": 19.2, "mem_use": 47.47, "gen_rate": 8.5, "speed": 1.61, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 14.2, "tree_w": 38, "tree_size": 256, "t0": 3.852, "t1": 0.868, "tft": 6.1681, "input_0": 845, "input_1": 257, "min_CLP": -5.92, "draft_iters": 15.6, "mem_use": 45.52, "gen_rate": 8.0, "speed": 1.7, "text": "\"No, I am an artificial intellig"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.8, "tree_w": 73, "tree_size": 256, "t0": 2.72, "t1": 0.87, "tft": 3.5669, "input_0": 507, "input_1": 257, "min_CLP": -7.03, "draft_iters": 12.8, "mem_use": 45.75, "gen_rate": 5.7, "speed": 1.58, "text": "\"Attention's soft gaze,\\nFocusin"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 27, "tree_h": 16.0, "tree_w": 45, "tree_size": 256, "t0": 4.3467, "t1": 0.87, "tft": 5.3619, "input_0": 887, "input_1": 257, "min_CLP": -6.12, "draft_iters": 17.7, "mem_use": 46.0, "gen_rate": 9.0, "speed": 1.72, "text": "\"Thank you! I'm always here to h"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 52, "tree_size": 256, "t0": 3.4075, "t1": 0.8875, "tft": 5.4667, "input_0": 656, "input_1": 257, "min_CLP": -6.4, "draft_iters": 15.8, "mem_use": 47.59, "gen_rate": 8.0, "speed": 1.86, "text": "Thou art the light that shines s"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 40, "tree_size": 256, "t0": 5.615, "t1": 0.88, "tft": 5.49, "input_0": 834, "input_1": 257, "min_CLP": -7.79, "draft_iters": 31.5, "mem_use": 46.17, "gen_rate": 32.0, "speed": 4.93, "text": "[INST] what chemicals does l-the"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 51, "tree_size": 256, "t0": 5.64, "t1": 0.87, "tft": 5.0346, "input_0": 912, "input_1": 257, "min_CLP": -7.74, "draft_iters": 32.0, "mem_use": 45.57, "gen_rate": 33.0, "speed": 5.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.3, "tree_w": 30, "tree_size": 256, "t0": 5.3467, "t1": 0.8667, "tft": 5.8549, "input_0": 1052, "input_1": 257, "min_CLP": -5.73, "draft_iters": 23.3, "mem_use": 45.55, "gen_rate": 13.0, "speed": 2.09, "text": "\"Presidents' Day, also known as "}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 55, "tree_size": 256, "t0": 3.31, "t1": 0.874, "tft": 4.7945, "input_0": 726, "input_1": 257, "min_CLP": -6.51, "draft_iters": 14.0, "mem_use": 45.85, "gen_rate": 6.6, "speed": 1.58, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 53, "tree_size": 256, "t0": 3.398, "t1": 0.884, "tft": 6.7476, "input_0": 795, "input_1": 257, "min_CLP": -6.19, "draft_iters": 12.6, "mem_use": 46.65, "gen_rate": 7.0, "speed": 1.64, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 65, "tree_size": 256, "t0": 2.4233, "t1": 0.875, "tft": 4.8348, "input_0": 531, "input_1": 257, "min_CLP": -6.68, "draft_iters": 9.5, "mem_use": 45.93, "gen_rate": 5.3, "speed": 1.62, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 70, "tree_size": 256, "t0": 2.982, "t1": 0.87, "tft": 5.0133, "input_0": 723, "input_1": 257, "min_CLP": -6.54, "draft_iters": 12.0, "mem_use": 46.0, "gen_rate": 6.6, "speed": 1.71, "text": "\"Ok, from now on, I will be refe"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.0, "tree_w": 29, "tree_size": 256, "t0": 4.8267, "t1": 0.87, "tft": 4.7825, "input_0": 870, "input_1": 257, "min_CLP": -5.88, "draft_iters": 22.3, "mem_use": 45.55, "gen_rate": 12.0, "speed": 2.11, "text": "Yes, the ATF can be considered a"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 9.1, "tree_w": 69, "tree_size": 256, "t0": 2.6162, "t1": 0.8775, "tft": 4.1582, "input_0": 573, "input_1": 257, "min_CLP": -6.53, "draft_iters": 10.4, "mem_use": 46.23, "gen_rate": 4.6, "speed": 1.32, "text": "\"Hey, Mr. Kaczynski, you\\'re lik"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 256, "t0": 5.99, "t1": 0.87, "tft": 6.7889, "input_0": 953, "input_1": 257, "min_CLP": -11.23, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 33.0, "speed": 4.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 59, "tree_size": 256, "t0": 2.96, "t1": 0.8833, "tft": 4.6383, "input_0": 664, "input_1": 257, "min_CLP": -6.47, "draft_iters": 11.7, "mem_use": 46.9, "gen_rate": 5.5, "speed": 1.43, "text": "Certainly! One of the most popul"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.2, "tree_w": 53, "tree_size": 256, "t0": 2.945, "t1": 0.8733, "tft": 4.1566, "input_0": 635, "input_1": 257, "min_CLP": -6.35, "draft_iters": 12.3, "mem_use": 45.99, "gen_rate": 6.2, "speed": 1.61, "text": "\"I'm here to help and provide as"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.0, "tree_w": 43, "tree_size": 256, "t0": 3.98, "t1": 0.89, "tft": 7.3189, "input_0": 813, "input_1": 257, "min_CLP": -6.01, "draft_iters": 16.5, "mem_use": 47.2, "gen_rate": 9.0, "speed": 1.85, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.1, "tree_w": 76, "tree_size": 256, "t0": 2.2325, "t1": 0.8775, "tft": 5.0344, "input_0": 501, "input_1": 257, "min_CLP": -6.83, "draft_iters": 9.1, "mem_use": 45.94, "gen_rate": 4.5, "speed": 1.45, "text": "\"Open Assistant: ChatGPT's Open "}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.7, "tree_w": 32, "tree_size": 256, "t0": 4.4267, "t1": 0.88, "tft": 5.5675, "input_0": 810, "input_1": 257, "min_CLP": -5.73, "draft_iters": 21.7, "mem_use": 45.84, "gen_rate": 12.3, "speed": 2.33, "text": "\"Sure! Let's illustrate the rela"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 16.2, "tree_w": 36, "tree_size": 256, "t0": 4.158, "t1": 0.888, "tft": 6.3155, "input_0": 901, "input_1": 257, "min_CLP": -5.75, "draft_iters": 17.6, "mem_use": 48.18, "gen_rate": 8.6, "speed": 1.7, "text": "\"The issue you're experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.3, "tree_w": 41, "tree_size": 256, "t0": 3.92, "t1": 0.87, "tft": 6.2429, "input_0": 820, "input_1": 257, "min_CLP": -5.97, "draft_iters": 16.0, "mem_use": 45.53, "gen_rate": 11.3, "speed": 2.37, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 75, "tree_size": 256, "t0": 2.5486, "t1": 0.8771, "tft": 4.533, "input_0": 539, "input_1": 257, "min_CLP": -6.57, "draft_iters": 10.1, "mem_use": 46.08, "gen_rate": 5.0, "speed": 1.46, "text": "\"I don't think that the answer w"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.4, "tree_w": 51, "tree_size": 256, "t0": 3.042, "t1": 0.87, "tft": 4.8172, "input_0": 615, "input_1": 257, "min_CLP": -6.28, "draft_iters": 13.4, "mem_use": 45.71, "gen_rate": 7.4, "speed": 1.89, "text": "The heat from the pan transfers "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.0, "tree_w": 37, "tree_size": 256, "t0": 4.5633, "t1": 0.8733, "tft": 5.2337, "input_0": 895, "input_1": 257, "min_CLP": -5.83, "draft_iters": 20.3, "mem_use": 45.55, "gen_rate": 11.7, "speed": 2.15, "text": "The following Python libraries a"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 51, "tree_size": 256, "t0": 3.236, "t1": 0.894, "tft": 6.8557, "input_0": 824, "input_1": 257, "min_CLP": -6.12, "draft_iters": 12.4, "mem_use": 47.63, "gen_rate": 6.4, "speed": 1.55, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.8, "tree_w": 46, "tree_size": 256, "t0": 3.262, "t1": 0.868, "tft": 6.4056, "input_0": 731, "input_1": 257, "min_CLP": -6.08, "draft_iters": 13.2, "mem_use": 45.51, "gen_rate": 7.2, "speed": 1.74, "text": "\"Yes, a thumb war can be conside"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 21.2, "tree_w": 55, "tree_size": 256, "t0": 3.9767, "t1": 0.8717, "tft": 5.5635, "input_0": 574, "input_1": 257, "min_CLP": -6.26, "draft_iters": 22.0, "mem_use": 45.59, "gen_rate": 5.3, "speed": 1.1, "text": "The lyrics to the third verse of"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.8, "tree_w": 52, "tree_size": 256, "t0": 3.864, "t1": 0.902, "tft": 6.937, "input_0": 779, "input_1": 257, "min_CLP": -6.24, "draft_iters": 15.0, "mem_use": 48.87, "gen_rate": 8.2, "speed": 1.72, "text": "As of my last update in April 20"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 17.8, "tree_w": 35, "tree_size": 256, "t0": 4.105, "t1": 0.8825, "tft": 5.6124, "input_0": 773, "input_1": 257, "min_CLP": -6.06, "draft_iters": 19.0, "mem_use": 46.86, "gen_rate": 9.2, "speed": 1.85, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.0, "tree_w": 38, "tree_size": 256, "t0": 3.8525, "t1": 0.8725, "tft": 4.7782, "input_0": 868, "input_1": 257, "min_CLP": -6.01, "draft_iters": 14.5, "mem_use": 45.8, "gen_rate": 10.8, "speed": 2.27, "text": "Certainly! There are many resour"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 25.5, "tree_w": 46, "tree_size": 256, "t0": 5.25, "t1": 0.875, "tft": 5.0937, "input_0": 800, "input_1": 257, "min_CLP": -7.81, "draft_iters": 26.0, "mem_use": 45.78, "gen_rate": 20.5, "speed": 3.35, "text": "# [INST] <<SYS>>\\nYou are a help"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.0, "tree_w": 47, "tree_size": 256, "t0": 3.8775, "t1": 0.87, "tft": 4.8471, "input_0": 885, "input_1": 257, "min_CLP": -6.0, "draft_iters": 15.8, "mem_use": 45.55, "gen_rate": 9.8, "speed": 2.05, "text": "\"The theory of sexual selection "}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 14.2, "tree_w": 48, "tree_size": 256, "t0": 3.535, "t1": 0.8775, "tft": 6.0833, "input_0": 710, "input_1": 257, "min_CLP": -6.27, "draft_iters": 15.5, "mem_use": 46.36, "gen_rate": 10.5, "speed": 2.38, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 16, "tree_h": 21.0, "tree_w": 36, "tree_size": 256, "t0": 6.57, "t1": 0.88, "tft": 7.6028, "input_0": 1370, "input_1": 257, "min_CLP": -6.56, "draft_iters": 22.0, "mem_use": 46.39, "gen_rate": 16.0, "speed": 2.15, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 26.7, "tree_w": 22, "tree_size": 256, "t0": 6.0567, "t1": 0.9033, "tft": 9.1256, "input_0": 1070, "input_1": 257, "min_CLP": -5.38, "draft_iters": 28.0, "mem_use": 48.9, "gen_rate": 14.3, "speed": 2.06, "text": "\"Sure! Here's a condensed versio"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 41, "tree_size": 256, "t0": 3.8125, "t1": 0.87, "tft": 6.4412, "input_0": 851, "input_1": 257, "min_CLP": -5.89, "draft_iters": 14.5, "mem_use": 45.55, "gen_rate": 8.8, "speed": 1.87, "text": "To reduce your alcohol consumpti"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 62, "tree_size": 256, "t0": 2.5167, "t1": 0.8767, "tft": 5.0205, "input_0": 571, "input_1": 257, "min_CLP": -6.31, "draft_iters": 10.3, "mem_use": 46.12, "gen_rate": 5.8, "speed": 1.72, "text": "Berlin is known for its vibrant "}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 26.0, "tree_w": 23, "tree_size": 256, "t0": 6.255, "t1": 0.87, "tft": 6.7101, "input_0": 1221, "input_1": 257, "min_CLP": -5.65, "draft_iters": 26.5, "mem_use": 45.59, "gen_rate": 16.5, "speed": 2.31, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 5.6933, "t1": 0.89, "tft": 7.7396, "input_0": 757, "input_1": 257, "min_CLP": -5.63, "draft_iters": 32.0, "mem_use": 48.1, "gen_rate": 10.7, "speed": 1.62, "text": "## Vegetarian\\n Microwave and In"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 10.5, "tree_w": 61, "tree_size": 256, "t0": 2.9475, "t1": 0.8688, "tft": 6.2197, "input_0": 644, "input_1": 257, "min_CLP": -6.53, "draft_iters": 11.9, "mem_use": 45.5, "gen_rate": 4.8, "speed": 1.25, "text": "It seems like you\\'re referring "}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 53, "tree_size": 256, "t0": 3.52, "t1": 0.89, "tft": 5.9436, "input_0": 808, "input_1": 257, "min_CLP": -6.25, "draft_iters": 13.5, "mem_use": 47.77, "gen_rate": 8.8, "speed": 1.99, "text": "The owners of the restaurant can"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 12.0, "tree_w": 52, "tree_size": 256, "t0": 2.97, "t1": 0.86, "tft": 6.1514, "input_0": 594, "input_1": 257, "min_CLP": -6.46, "draft_iters": 13.0, "mem_use": 45.51, "gen_rate": 5.0, "speed": 1.3, "text": "The answer to this question is:"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.2, "tree_w": 109, "tree_size": 256, "t0": 2.7825, "t1": 0.875, "tft": 5.0828, "input_0": 509, "input_1": 257, "min_CLP": -7.37, "draft_iters": 14.0, "mem_use": 45.49, "gen_rate": 11.0, "speed": 3.01, "text": "\u201c\u6211\u6628\u5929\u5728\u8d85\u5e02\u4e70\u4e86\u8349\u8393\u3002\u201d\\n[INST] <<SYS>>\\nY"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.2, "tree_w": 41, "tree_size": 256, "t0": 3.945, "t1": 0.87, "tft": 4.6844, "input_0": 906, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.8, "mem_use": 45.65, "gen_rate": 8.0, "speed": 1.66, "text": "Sure! One example of a complex p"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.0, "tree_w": 47, "tree_size": 256, "t0": 3.4175, "t1": 0.88, "tft": 6.516, "input_0": 815, "input_1": 257, "min_CLP": -5.96, "draft_iters": 12.5, "mem_use": 46.72, "gen_rate": 9.2, "speed": 2.15, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.0, "tree_w": 41, "tree_size": 256, "t0": 3.5225, "t1": 0.8675, "tft": 6.3915, "input_0": 769, "input_1": 257, "min_CLP": -6.06, "draft_iters": 14.2, "mem_use": 45.61, "gen_rate": 9.0, "speed": 2.05, "text": "The reason why many people still"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 19.0, "tree_w": 35, "tree_size": 256, "t0": 4.072, "t1": 0.876, "tft": 4.7313, "input_0": 695, "input_1": 257, "min_CLP": -5.81, "draft_iters": 20.0, "mem_use": 45.81, "gen_rate": 9.4, "speed": 1.9, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.0, "tree_w": 25, "tree_size": 256, "t0": 5.495, "t1": 0.875, "tft": 5.3602, "input_0": 1180, "input_1": 257, "min_CLP": -5.87, "draft_iters": 23.0, "mem_use": 46.15, "gen_rate": 18.5, "speed": 2.9, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.3, "tree_w": 50, "tree_size": 256, "t0": 3.39, "t1": 0.8733, "tft": 4.9302, "input_0": 740, "input_1": 257, "min_CLP": -6.5, "draft_iters": 14.3, "mem_use": 45.69, "gen_rate": 11.3, "speed": 2.66, "text": "I am a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 20.7, "tree_w": 33, "tree_size": 256, "t0": 4.6433, "t1": 0.8867, "tft": 7.0925, "input_0": 879, "input_1": 257, "min_CLP": -5.72, "draft_iters": 21.7, "mem_use": 46.92, "gen_rate": 14.7, "speed": 2.65, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.0, "tree_w": 29, "tree_size": 256, "t0": 5.21, "t1": 0.8733, "tft": 6.8849, "input_0": 981, "input_1": 257, "min_CLP": -6.18, "draft_iters": 22.3, "mem_use": 45.59, "gen_rate": 15.7, "speed": 2.58, "text": "Certainly! Here\\'s a response th"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 17.8, "tree_w": 33, "tree_size": 256, "t0": 4.77, "t1": 0.88, "tft": 7.0485, "input_0": 986, "input_1": 257, "min_CLP": -5.88, "draft_iters": 19.2, "mem_use": 46.43, "gen_rate": 10.8, "speed": 1.9, "text": "The microwave oven became a comm"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 24.8, "tree_w": 57, "tree_size": 256, "t0": 4.588, "t1": 0.876, "tft": 5.5767, "input_0": 666, "input_1": 257, "min_CLP": -6.54, "draft_iters": 25.4, "mem_use": 45.69, "gen_rate": 7.2, "speed": 1.32, "text": "[INST] How does this relate to t"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 3, "tree_h": 32.0, "tree_w": 51, "tree_size": 256, "t0": 5.3033, "t1": 0.87, "tft": 5.6755, "input_0": 657, "input_1": 257, "min_CLP": -6.3, "draft_iters": 32.0, "mem_use": 45.52, "gen_rate": 1.0, "speed": 0.16, "text": "No data available."}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.3, "tree_w": 46, "tree_size": 256, "t0": 3.8933, "t1": 0.9, "tft": 8.5874, "input_0": 932, "input_1": 257, "min_CLP": -5.98, "draft_iters": 15.7, "mem_use": 49.83, "gen_rate": 10.7, "speed": 2.22, "text": "\"If your friends are not happy w"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 59, "tree_size": 256, "t0": 5.01, "t1": 0.88, "tft": 4.0712, "input_0": 539, "input_1": 257, "min_CLP": -6.92, "draft_iters": 32.0, "mem_use": 45.83, "gen_rate": 33.0, "speed": 5.61, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.4, "tree_w": 42, "tree_size": 256, "t0": 3.904, "t1": 0.884, "tft": 6.5714, "input_0": 845, "input_1": 257, "min_CLP": -6.07, "draft_iters": 16.0, "mem_use": 46.71, "gen_rate": 7.2, "speed": 1.5, "text": "\"It is not possible to go around"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.8, "tree_w": 61, "tree_size": 256, "t0": 2.888, "t1": 0.89, "tft": 5.7462, "input_0": 628, "input_1": 257, "min_CLP": -6.32, "draft_iters": 11.2, "mem_use": 47.97, "gen_rate": 7.4, "speed": 1.96, "text": "You can prevent spiders from spa"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.4, "tree_w": 63, "tree_size": 256, "t0": 3.0271, "t1": 0.8786, "tft": 4.5705, "input_0": 594, "input_1": 257, "min_CLP": -6.57, "draft_iters": 13.6, "mem_use": 45.81, "gen_rate": 5.0, "speed": 1.28, "text": "\"I'm sorry, but I can't come up "}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.8, "tree_w": 54, "tree_size": 256, "t0": 3.57, "t1": 0.875, "tft": 4.7952, "input_0": 781, "input_1": 257, "min_CLP": -6.15, "draft_iters": 15.2, "mem_use": 45.85, "gen_rate": 8.2, "speed": 1.86, "text": "\"You're welcome! I'm always here"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.6, "tree_w": 41, "tree_size": 256, "t0": 3.418, "t1": 0.878, "tft": 5.8853, "input_0": 754, "input_1": 257, "min_CLP": -6.07, "draft_iters": 13.6, "mem_use": 46.33, "gen_rate": 7.4, "speed": 1.72, "text": "The following are three 3D anima"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.8, "tree_w": 43, "tree_size": 256, "t0": 3.8825, "t1": 0.875, "tft": 6.9492, "input_0": 647, "input_1": 257, "min_CLP": -6.25, "draft_iters": 19.8, "mem_use": 45.83, "gen_rate": 8.0, "speed": 1.68, "text": "[INST] Please provide a short su"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 58, "tree_size": 256, "t0": 2.9, "t1": 0.88, "tft": 4.9781, "input_0": 659, "input_1": 257, "min_CLP": -6.42, "draft_iters": 11.4, "mem_use": 46.51, "gen_rate": 6.6, "speed": 1.75, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 31, "tree_size": 256, "t0": 5.57, "t1": 0.86, "tft": 4.1974, "input_0": 728, "input_1": 257, "min_CLP": -7.85, "draft_iters": 32.0, "mem_use": 45.85, "gen_rate": 33.0, "speed": 5.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 16.0, "tree_w": 41, "tree_size": 256, "t0": 4.422, "t1": 0.872, "tft": 6.5607, "input_0": 1001, "input_1": 257, "min_CLP": -6.22, "draft_iters": 17.4, "mem_use": 45.57, "gen_rate": 9.2, "speed": 1.74, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 50, "tree_size": 256, "t0": 5.91, "t1": 0.86, "tft": 6.0977, "input_0": 919, "input_1": 257, "min_CLP": -7.37, "draft_iters": 32.0, "mem_use": 45.53, "gen_rate": 33.0, "speed": 4.87, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 27, "tree_h": 15.7, "tree_w": 38, "tree_size": 256, "t0": 4.3667, "t1": 0.9067, "tft": 8.5899, "input_0": 958, "input_1": 257, "min_CLP": -6.05, "draft_iters": 17.7, "mem_use": 49.82, "gen_rate": 9.0, "speed": 1.71, "text": "\"You're very welcome! I'm glad t"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.8, "tree_w": 37, "tree_size": 256, "t0": 3.945, "t1": 0.87, "tft": 4.5888, "input_0": 798, "input_1": 257, "min_CLP": -5.89, "draft_iters": 17.0, "mem_use": 45.67, "gen_rate": 8.5, "speed": 1.77, "text": "Some of the most common applicat"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.0, "tree_w": 37, "tree_size": 256, "t0": 4.5425, "t1": 0.8875, "tft": 6.1145, "input_0": 899, "input_1": 257, "min_CLP": -5.78, "draft_iters": 18.5, "mem_use": 47.21, "gen_rate": 9.5, "speed": 1.75, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 38, "tree_size": 256, "t0": 4.4067, "t1": 0.8833, "tft": 6.0274, "input_0": 884, "input_1": 257, "min_CLP": -6.06, "draft_iters": 18.0, "mem_use": 46.97, "gen_rate": 11.7, "speed": 2.2, "text": "The command \"chkdsk C: /f\" will "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.8, "tree_w": 53, "tree_size": 256, "t0": 3.065, "t1": 0.8767, "tft": 5.3356, "input_0": 724, "input_1": 257, "min_CLP": -6.06, "draft_iters": 12.0, "mem_use": 45.8, "gen_rate": 6.5, "speed": 1.65, "text": "\"To approach and solve this prob"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 45, "tree_size": 256, "t0": 5.68, "t1": 0.87, "tft": 4.7409, "input_0": 922, "input_1": 257, "min_CLP": -7.62, "draft_iters": 32.0, "mem_use": 45.62, "gen_rate": 33.0, "speed": 5.04, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 256, "t0": 5.93, "t1": 0.87, "tft": 5.0419, "input_0": 948, "input_1": 257, "min_CLP": -8.17, "draft_iters": 32.0, "mem_use": 45.59, "gen_rate": 33.0, "speed": 4.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.0, "tree_w": 38, "tree_size": 256, "t0": 3.646, "t1": 0.88, "tft": 5.415, "input_0": 744, "input_1": 257, "min_CLP": -5.92, "draft_iters": 16.0, "mem_use": 46.6, "gen_rate": 7.8, "speed": 1.72, "text": "\"I'd be happy to help you improv"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 32.0, "tree_w": 55, "tree_size": 256, "t0": 4.9, "t1": 0.87, "tft": 3.347, "input_0": 532, "input_1": 257, "min_CLP": -6.49, "draft_iters": 32.0, "mem_use": 45.93, "gen_rate": 1.0, "speed": 0.17, "text": "How is the universe?"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 28.0, "tree_w": 21, "tree_size": 256, "t0": 6.2933, "t1": 0.89, "tft": 7.3232, "input_0": 1075, "input_1": 257, "min_CLP": -6.0, "draft_iters": 28.7, "mem_use": 47.25, "gen_rate": 12.0, "speed": 1.67, "text": "The feminine words are:\\n\\n- mel"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 11.5, "tree_w": 58, "tree_size": 256, "t0": 2.8433, "t1": 0.8733, "tft": 5.0466, "input_0": 574, "input_1": 257, "min_CLP": -6.5, "draft_iters": 12.5, "mem_use": 46.16, "gen_rate": 7.3, "speed": 1.97, "text": "\"I think the answerer is a compa"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 67, "tree_size": 256, "t0": 2.92, "t1": 0.876, "tft": 4.2037, "input_0": 644, "input_1": 257, "min_CLP": -6.76, "draft_iters": 12.4, "mem_use": 46.0, "gen_rate": 6.8, "speed": 1.79, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 14.8, "tree_w": 45, "tree_size": 256, "t0": 4.0975, "t1": 0.8725, "tft": 6.1717, "input_0": 873, "input_1": 257, "min_CLP": -5.97, "draft_iters": 16.2, "mem_use": 45.74, "gen_rate": 10.5, "speed": 2.11, "text": "The difference between interpret"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 14, "tree_size": 256, "t0": 6.91, "t1": 0.89, "tft": 9.1669, "input_0": 1362, "input_1": 257, "min_CLP": -10.7, "draft_iters": 32.0, "mem_use": 48.54, "gen_rate": 32.0, "speed": 4.1, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 18, "tree_size": 256, "t0": 6.02, "t1": 0.9, "tft": 7.1176, "input_0": 959, "input_1": 257, "min_CLP": -6.42, "draft_iters": 32.0, "mem_use": 48.47, "gen_rate": 32.0, "speed": 4.62, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 72, "tree_size": 256, "t0": 2.482, "t1": 0.874, "tft": 6.2831, "input_0": 609, "input_1": 257, "min_CLP": -6.59, "draft_iters": 9.8, "mem_use": 45.53, "gen_rate": 6.4, "speed": 1.91, "text": "\"Sure, here's a poem inspired by"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 5.92, "t1": 0.88, "tft": 5.8814, "input_0": 867, "input_1": 257, "min_CLP": -5.56, "draft_iters": 32.0, "mem_use": 46.7, "gen_rate": 33.0, "speed": 4.86, "text": "Absolutely! Here is the updated "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 17.8, "tree_w": 40, "tree_size": 256, "t0": 4.4, "t1": 0.8825, "tft": 5.7255, "input_0": 857, "input_1": 257, "min_CLP": -5.9, "draft_iters": 19.5, "mem_use": 47.15, "gen_rate": 9.8, "speed": 1.85, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.7, "tree_w": 32, "tree_size": 256, "t0": 4.7467, "t1": 0.86, "tft": 5.5875, "input_0": 902, "input_1": 257, "min_CLP": -5.75, "draft_iters": 20.0, "mem_use": 45.51, "gen_rate": 12.0, "speed": 2.14, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 256, "t0": 5.85, "t1": 0.88, "tft": 3.8174, "input_0": 858, "input_1": 257, "min_CLP": -7.09, "draft_iters": 32.0, "mem_use": 45.81, "gen_rate": 33.0, "speed": 4.91, "text": "I am Freyja, a god from beyond t"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.7, "tree_w": 28, "tree_size": 256, "t0": 4.9467, "t1": 0.89, "tft": 7.5952, "input_0": 965, "input_1": 257, "min_CLP": -5.87, "draft_iters": 20.0, "mem_use": 47.4, "gen_rate": 13.3, "speed": 2.28, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 15.5, "tree_w": 38, "tree_size": 256, "t0": 4.25, "t1": 0.8775, "tft": 6.47, "input_0": 853, "input_1": 257, "min_CLP": -6.02, "draft_iters": 17.0, "mem_use": 45.75, "gen_rate": 10.5, "speed": 2.05, "text": "To host a large learning model o"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 25.5, "tree_w": 27, "tree_size": 256, "t0": 5.38, "t1": 0.89, "tft": 5.867, "input_0": 952, "input_1": 257, "min_CLP": -5.9, "draft_iters": 26.0, "mem_use": 47.09, "gen_rate": 21.5, "speed": 3.43, "text": "Certainly! Here is a more detail"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 50, "tree_size": 256, "t0": 3.24, "t1": 0.868, "tft": 5.3811, "input_0": 668, "input_1": 257, "min_CLP": -6.01, "draft_iters": 13.8, "mem_use": 45.55, "gen_rate": 7.0, "speed": 1.7, "text": "\"The future of AI in 10 years is"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 17.5, "tree_w": 30, "tree_size": 256, "t0": 4.525, "t1": 0.8725, "tft": 6.6973, "input_0": 922, "input_1": 257, "min_CLP": -5.85, "draft_iters": 19.0, "mem_use": 45.55, "gen_rate": 10.8, "speed": 1.99, "text": "To cook a salmon fillet on a sto"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 18.2, "tree_w": 37, "tree_size": 256, "t0": 4.2175, "t1": 0.875, "tft": 4.2513, "input_0": 810, "input_1": 257, "min_CLP": -5.93, "draft_iters": 19.2, "mem_use": 46.2, "gen_rate": 13.0, "speed": 2.55, "text": "\"Okay, I'll do both. Here's a si"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 17.5, "tree_w": 43, "tree_size": 256, "t0": 3.8575, "t1": 0.88, "tft": 5.4083, "input_0": 706, "input_1": 257, "min_CLP": -6.23, "draft_iters": 18.2, "mem_use": 46.43, "gen_rate": 14.8, "speed": 3.11, "text": "Thank you for pointing that out!"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 37, "tree_size": 256, "t0": 3.6067, "t1": 0.87, "tft": 4.2549, "input_0": 755, "input_1": 257, "min_CLP": -6.2, "draft_iters": 16.0, "mem_use": 45.53, "gen_rate": 10.7, "speed": 2.38, "text": "A: The AK-47, also known as the "}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 15.3, "tree_w": 31, "tree_size": 256, "t0": 4.05, "t1": 0.87, "tft": 5.746, "input_0": 845, "input_1": 257, "min_CLP": -5.67, "draft_iters": 16.7, "mem_use": 45.88, "gen_rate": 14.0, "speed": 2.84, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 28.0, "tree_w": 22, "tree_size": 256, "t0": 5.825, "t1": 0.88, "tft": 6.6218, "input_0": 1068, "input_1": 257, "min_CLP": -5.7, "draft_iters": 29.0, "mem_use": 47.27, "gen_rate": 24.0, "speed": 3.58, "text": "Sure, here are the points rewrit"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.3, "tree_w": 32, "tree_size": 256, "t0": 4.22, "t1": 0.87, "tft": 6.8231, "input_0": 927, "input_1": 257, "min_CLP": -6.16, "draft_iters": 16.7, "mem_use": 45.86, "gen_rate": 12.0, "speed": 2.36, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 14.0, "tree_w": 42, "tree_size": 256, "t0": 3.595, "t1": 0.8775, "tft": 5.5214, "input_0": 807, "input_1": 257, "min_CLP": -6.09, "draft_iters": 15.2, "mem_use": 46.37, "gen_rate": 11.8, "speed": 2.63, "text": "\"No, there's no harm in letting "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.9, "tree_w": 87, "tree_size": 256, "t0": 2.1237, "t1": 0.875, "tft": 4.1155, "input_0": 457, "input_1": 257, "min_CLP": -6.73, "draft_iters": 8.9, "mem_use": 46.01, "gen_rate": 4.5, "speed": 1.5, "text": "Tell them about a movie or a boo"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 63, "tree_size": 256, "t0": 3.1, "t1": 0.88, "tft": 6.9041, "input_0": 633, "input_1": 257, "min_CLP": -6.25, "draft_iters": 13.4, "mem_use": 46.12, "gen_rate": 6.4, "speed": 1.61, "text": "\"What is the user's question abo"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 21.0, "tree_w": 40, "tree_size": 256, "t0": 4.325, "t1": 0.875, "tft": 5.5704, "input_0": 726, "input_1": 257, "min_CLP": -6.38, "draft_iters": 22.0, "mem_use": 45.52, "gen_rate": 3.0, "speed": 0.58, "text": "\"I am thinking of a solution to "}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 15.0, "tree_w": 42, "tree_size": 256, "t0": 4.254, "t1": 0.87, "tft": 6.4432, "input_0": 959, "input_1": 257, "min_CLP": -6.06, "draft_iters": 16.2, "mem_use": 45.52, "gen_rate": 8.8, "speed": 1.72, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.8, "tree_w": 42, "tree_size": 256, "t0": 3.552, "t1": 0.876, "tft": 5.0946, "input_0": 721, "input_1": 257, "min_CLP": -5.93, "draft_iters": 16.0, "mem_use": 46.06, "gen_rate": 7.4, "speed": 1.67, "text": "Theanine is an amino acid that i"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 23.0, "tree_w": 30, "tree_size": 256, "t0": 5.155, "t1": 0.875, "tft": 6.5187, "input_0": 957, "input_1": 257, "min_CLP": -5.76, "draft_iters": 23.5, "mem_use": 45.82, "gen_rate": 21.5, "speed": 3.57, "text": "Here\\'s an example of HTML code "}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 15, "tree_size": 256, "t0": 6.73, "t1": 0.87, "tft": 6.7599, "input_0": 1207, "input_1": 257, "min_CLP": -11.16, "draft_iters": 32.0, "mem_use": 45.61, "gen_rate": 32.0, "speed": 4.21, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 14.8, "tree_w": 47, "tree_size": 256, "t0": 3.502, "t1": 0.872, "tft": 6.4728, "input_0": 669, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.8, "mem_use": 45.58, "gen_rate": 9.0, "speed": 2.06, "text": "\"You can't see the stars in the "}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 47, "tree_size": 256, "t0": 3.474, "t1": 0.878, "tft": 4.2287, "input_0": 750, "input_1": 257, "min_CLP": -6.33, "draft_iters": 14.0, "mem_use": 46.14, "gen_rate": 7.0, "speed": 1.61, "text": "The significance of the Windows "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.4, "tree_w": 51, "tree_size": 256, "t0": 3.174, "t1": 0.9, "tft": 6.6675, "input_0": 717, "input_1": 257, "min_CLP": -6.1, "draft_iters": 12.8, "mem_use": 49.2, "gen_rate": 7.4, "speed": 1.82, "text": "\"I'm sorry, but using your neigh"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.8, "tree_w": 62, "tree_size": 256, "t0": 2.8083, "t1": 0.8867, "tft": 5.7191, "input_0": 627, "input_1": 257, "min_CLP": -6.28, "draft_iters": 11.3, "mem_use": 47.94, "gen_rate": 5.5, "speed": 1.49, "text": "\"It's possible that we never had"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 59, "tree_size": 256, "t0": 2.974, "t1": 0.88, "tft": 6.254, "input_0": 709, "input_1": 257, "min_CLP": -6.31, "draft_iters": 11.4, "mem_use": 46.2, "gen_rate": 6.6, "speed": 1.71, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 46, "tree_size": 256, "t0": 5.93, "t1": 0.86, "tft": 5.0366, "input_0": 970, "input_1": 257, "min_CLP": -6.87, "draft_iters": 32.0, "mem_use": 45.53, "gen_rate": 33.0, "speed": 4.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 20.7, "tree_w": 42, "tree_size": 256, "t0": 4.47, "t1": 0.87, "tft": 5.8302, "input_0": 798, "input_1": 257, "min_CLP": -6.2, "draft_iters": 21.7, "mem_use": 45.52, "gen_rate": 6.7, "speed": 1.25, "text": "Yes, I can speak German. Would y"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 29.0, "tree_w": 22, "tree_size": 256, "t0": 5.79, "t1": 0.87, "tft": 6.0548, "input_0": 766, "input_1": 257, "min_CLP": -6.64, "draft_iters": 30.0, "mem_use": 45.72, "gen_rate": 23.0, "speed": 3.45, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.0, "tree_w": 49, "tree_size": 256, "t0": 3.255, "t1": 0.885, "tft": 5.0566, "input_0": 674, "input_1": 257, "min_CLP": -6.15, "draft_iters": 13.2, "mem_use": 46.61, "gen_rate": 9.2, "speed": 2.23, "text": "The number of access points that"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 45, "tree_size": 256, "t0": 3.674, "t1": 0.888, "tft": 7.9015, "input_0": 813, "input_1": 257, "min_CLP": -6.02, "draft_iters": 14.8, "mem_use": 47.19, "gen_rate": 6.6, "speed": 1.45, "text": "Yes, it is possible to use AI im"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.3, "tree_w": 78, "tree_size": 256, "t0": 2.7757, "t1": 0.8757, "tft": 5.0349, "input_0": 632, "input_1": 257, "min_CLP": -6.76, "draft_iters": 10.7, "mem_use": 45.58, "gen_rate": 5.0, "speed": 1.37, "text": "\"Certainly! Here are some haikus"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 23.3, "tree_w": 44, "tree_size": 256, "t0": 4.3467, "t1": 0.87, "tft": 6.6692, "input_0": 626, "input_1": 257, "min_CLP": -6.43, "draft_iters": 24.0, "mem_use": 45.94, "gen_rate": 17.7, "speed": 3.39, "text": "o\\n     /|\\\\\\n     / \\\\\\n     | "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 36, "tree_size": 256, "t0": 5.83, "t1": 0.87, "tft": 4.6608, "input_0": 953, "input_1": 257, "min_CLP": -8.06, "draft_iters": 32.0, "mem_use": 45.53, "gen_rate": 33.0, "speed": 4.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.6, "tree_w": 32, "tree_size": 256, "t0": 4.148, "t1": 0.872, "tft": 4.6725, "input_0": 889, "input_1": 257, "min_CLP": -5.96, "draft_iters": 17.2, "mem_use": 45.89, "gen_rate": 7.6, "speed": 1.51, "text": "Yes, there is a widely debated a"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 18.3, "tree_w": 34, "tree_size": 256, "t0": 4.6867, "t1": 0.8767, "tft": 4.9179, "input_0": 944, "input_1": 257, "min_CLP": -5.97, "draft_iters": 19.7, "mem_use": 45.81, "gen_rate": 16.3, "speed": 2.93, "text": "\"To write a function that fills "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 22.5, "tree_w": 54, "tree_size": 256, "t0": 3.935, "t1": 0.885, "tft": 5.8715, "input_0": 597, "input_1": 257, "min_CLP": -6.36, "draft_iters": 23.0, "mem_use": 47.86, "gen_rate": 5.5, "speed": 1.14, "text": "[INST] OK, I have the dough, che"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 6.21, "t1": 0.87, "tft": 6.615, "input_0": 983, "input_1": 257, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 33.0, "speed": 4.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.4, "tree_w": 43, "tree_size": 256, "t0": 3.328, "t1": 0.894, "tft": 6.6007, "input_0": 683, "input_1": 257, "min_CLP": -6.0, "draft_iters": 13.8, "mem_use": 48.56, "gen_rate": 8.0, "speed": 1.9, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 22.0, "tree_w": 39, "tree_size": 256, "t0": 5.2067, "t1": 0.8767, "tft": 4.484, "input_0": 1012, "input_1": 257, "min_CLP": -6.13, "draft_iters": 23.7, "mem_use": 45.56, "gen_rate": 10.7, "speed": 1.75, "text": "\"Sure! Here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.0, "tree_w": 34, "tree_size": 256, "t0": 5.44, "t1": 0.87, "tft": 5.1657, "input_0": 1174, "input_1": 257, "min_CLP": -5.77, "draft_iters": 22.0, "mem_use": 45.52, "gen_rate": 13.0, "speed": 2.06, "text": "HTML and JavaScript are both ess"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 29.5, "tree_w": 16, "tree_size": 256, "t0": 6.585, "t1": 0.87, "tft": 4.5412, "input_0": 1165, "input_1": 257, "min_CLP": -5.41, "draft_iters": 30.5, "mem_use": 45.55, "gen_rate": 18.5, "speed": 2.48, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 12.5, "tree_w": 55, "tree_size": 256, "t0": 3.275, "t1": 0.8733, "tft": 4.6225, "input_0": 694, "input_1": 257, "min_CLP": -6.11, "draft_iters": 13.7, "mem_use": 45.92, "gen_rate": 6.5, "speed": 1.57, "text": "I\\'m not a lawyer, but I can pro"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 6.34, "t1": 0.87, "tft": 6.122, "input_0": 1040, "input_1": 257, "min_CLP": -9.84, "draft_iters": 32.0, "mem_use": 45.53, "gen_rate": 33.0, "speed": 4.57, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 19.0, "tree_w": 32, "tree_size": 256, "t0": 4.845, "t1": 0.885, "tft": 6.1353, "input_0": 998, "input_1": 257, "min_CLP": -5.78, "draft_iters": 20.5, "mem_use": 46.6, "gen_rate": 9.0, "speed": 1.57, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.2, "tree_w": 52, "tree_size": 256, "t0": 3.144, "t1": 0.874, "tft": 3.9475, "input_0": 735, "input_1": 257, "min_CLP": -6.19, "draft_iters": 12.6, "mem_use": 46.3, "gen_rate": 8.4, "speed": 2.09, "text": "\"Thank you for providing more in"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.0, "tree_w": 53, "tree_size": 256, "t0": 2.9075, "t1": 0.8725, "tft": 4.4262, "input_0": 655, "input_1": 257, "min_CLP": -6.34, "draft_iters": 12.2, "mem_use": 46.15, "gen_rate": 8.8, "speed": 2.31, "text": "\"You are correct, if everyone ju"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.0, "tree_w": 56, "tree_size": 256, "t0": 3.41, "t1": 0.88, "tft": 5.2592, "input_0": 667, "input_1": 257, "min_CLP": -6.21, "draft_iters": 15.2, "mem_use": 46.88, "gen_rate": 8.8, "speed": 2.04, "text": "Great choice of style and inspir"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 6.11, "t1": 0.87, "tft": 3.7045, "input_0": 978, "input_1": 257, "min_CLP": -9.28, "draft_iters": 32.0, "mem_use": 45.51, "gen_rate": 33.0, "speed": 4.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.5, "tree_w": 57, "tree_size": 256, "t0": 3.2067, "t1": 0.8717, "tft": 3.9212, "input_0": 618, "input_1": 257, "min_CLP": -6.57, "draft_iters": 14.7, "mem_use": 45.83, "gen_rate": 5.3, "speed": 1.31, "text": "I\\'ve seen a few different names"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.2, "tree_w": 38, "tree_size": 256, "t0": 3.6825, "t1": 0.8825, "tft": 6.4463, "input_0": 782, "input_1": 257, "min_CLP": -5.93, "draft_iters": 15.8, "mem_use": 46.58, "gen_rate": 9.2, "speed": 2.03, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.3, "tree_w": 51, "tree_size": 256, "t0": 3.1514, "t1": 0.8714, "tft": 4.0278, "input_0": 695, "input_1": 257, "min_CLP": -6.1, "draft_iters": 12.6, "mem_use": 45.63, "gen_rate": 5.3, "speed": 1.31, "text": "Motion Matching is a technology "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 13, "tree_size": 256, "t0": 7.18, "t1": 0.89, "tft": 7.9005, "input_0": 1231, "input_1": 257, "min_CLP": -5.7, "draft_iters": 32.0, "mem_use": 47.26, "gen_rate": 32.0, "speed": 3.96, "text": "\"Sure, here's an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 44, "tree_size": 256, "t0": 3.256, "t1": 0.87, "tft": 5.2271, "input_0": 681, "input_1": 257, "min_CLP": -6.22, "draft_iters": 13.4, "mem_use": 45.58, "gen_rate": 6.6, "speed": 1.6, "text": "C# is a statically typed, genera"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 47, "tree_size": 256, "t0": 3.1875, "t1": 0.875, "tft": 6.6429, "input_0": 670, "input_1": 257, "min_CLP": -6.38, "draft_iters": 12.5, "mem_use": 45.96, "gen_rate": 8.5, "speed": 2.09, "text": "Sure, here\\'s a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.2, "tree_w": 43, "tree_size": 256, "t0": 4.08, "t1": 0.885, "tft": 7.0243, "input_0": 960, "input_1": 257, "min_CLP": -6.17, "draft_iters": 15.5, "mem_use": 47.27, "gen_rate": 8.0, "speed": 1.61, "text": "The idea of 100 monkeys on a typ"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 44, "tree_size": 256, "t0": 4.0275, "t1": 0.8875, "tft": 6.0226, "input_0": 919, "input_1": 257, "min_CLP": -5.94, "draft_iters": 16.5, "mem_use": 47.7, "gen_rate": 8.8, "speed": 1.78, "text": "Paul Allen has a diverse collect"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 46, "tree_size": 256, "t0": 3.73, "t1": 0.8875, "tft": 5.5891, "input_0": 811, "input_1": 257, "min_CLP": -6.2, "draft_iters": 15.2, "mem_use": 47.14, "gen_rate": 8.5, "speed": 1.84, "text": "Yes, there is a similar case in "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.7, "tree_w": 39, "tree_size": 256, "t0": 4.3067, "t1": 0.87, "tft": 4.6448, "input_0": 693, "input_1": 257, "min_CLP": -5.96, "draft_iters": 21.7, "mem_use": 45.61, "gen_rate": 11.3, "speed": 2.19, "text": "\"Here is a sample essay on how R"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 54, "tree_size": 256, "t0": 2.874, "t1": 0.878, "tft": 4.2575, "input_0": 652, "input_1": 257, "min_CLP": -6.07, "draft_iters": 11.0, "mem_use": 46.23, "gen_rate": 6.4, "speed": 1.71, "text": "As a language model, I do not ha"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.0, "tree_w": 45, "tree_size": 256, "t0": 3.626, "t1": 0.87, "tft": 6.4148, "input_0": 834, "input_1": 257, "min_CLP": -6.04, "draft_iters": 14.2, "mem_use": 45.63, "gen_rate": 7.6, "speed": 1.69, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.2, "tree_w": 36, "tree_size": 256, "t0": 3.4825, "t1": 0.87, "tft": 4.2645, "input_0": 784, "input_1": 257, "min_CLP": -5.97, "draft_iters": 14.2, "mem_use": 45.52, "gen_rate": 9.8, "speed": 2.24, "text": "No, the 5-second rule does not e"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 14.0, "tree_w": 35, "tree_size": 256, "t0": 3.95, "t1": 0.8833, "tft": 4.9438, "input_0": 890, "input_1": 257, "min_CLP": -6.18, "draft_iters": 15.3, "mem_use": 46.36, "gen_rate": 5.3, "speed": 1.1, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.2, "tree_w": 44, "tree_size": 256, "t0": 3.498, "t1": 0.888, "tft": 6.0928, "input_0": 687, "input_1": 257, "min_CLP": -5.93, "draft_iters": 15.4, "mem_use": 47.17, "gen_rate": 7.2, "speed": 1.64, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.2, "tree_w": 54, "tree_size": 256, "t0": 3.206, "t1": 0.89, "tft": 7.2011, "input_0": 709, "input_1": 257, "min_CLP": -6.19, "draft_iters": 12.6, "mem_use": 48.08, "gen_rate": 7.6, "speed": 1.85, "text": "The \"multi-track drifting\" solut"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.8, "tree_w": 40, "tree_size": 256, "t0": 3.4375, "t1": 0.88, "tft": 5.8302, "input_0": 730, "input_1": 257, "min_CLP": -5.93, "draft_iters": 14.8, "mem_use": 46.67, "gen_rate": 8.8, "speed": 2.03, "text": "\"It is not possible to have a co"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 22, "tree_size": 256, "t0": 6.35, "t1": 0.88, "tft": 4.6337, "input_0": 970, "input_1": 257, "min_CLP": -6.72, "draft_iters": 32.0, "mem_use": 46.51, "gen_rate": 33.0, "speed": 4.56, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 22.5, "tree_w": 33, "tree_size": 256, "t0": 5.97, "t1": 0.875, "tft": 6.1679, "input_0": 1165, "input_1": 257, "min_CLP": -6.4, "draft_iters": 24.0, "mem_use": 46.27, "gen_rate": 16.5, "speed": 2.41, "text": "Here are the translations of \"lo"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.3, "tree_w": 42, "tree_size": 256, "t0": 3.255, "t1": 0.8717, "tft": 4.2127, "input_0": 687, "input_1": 257, "min_CLP": -6.06, "draft_iters": 13.5, "mem_use": 45.81, "gen_rate": 6.2, "speed": 1.49, "text": "In the UK, Imperial College Lond"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.5, "tree_w": 42, "tree_size": 256, "t0": 4.55, "t1": 0.8725, "tft": 6.5812, "input_0": 1106, "input_1": 257, "min_CLP": -5.91, "draft_iters": 17.0, "mem_use": 45.51, "gen_rate": 8.8, "speed": 1.61, "text": "\"The blue color of the sky is ca"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 6.67, "t1": 0.87, "tft": 5.4221, "input_0": 1267, "input_1": 257, "min_CLP": -5.93, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 33.0, "speed": 4.38, "text": "\"Here's a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 53, "tree_size": 256, "t0": 2.986, "t1": 0.878, "tft": 5.4546, "input_0": 649, "input_1": 257, "min_CLP": -6.22, "draft_iters": 12.4, "mem_use": 46.77, "gen_rate": 7.6, "speed": 1.97, "text": "1. Financial stress: To address "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 34, "tree_size": 256, "t0": 5.78, "t1": 0.87, "tft": 6.2709, "input_0": 762, "input_1": 257, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 45.51, "gen_rate": 33.0, "speed": 4.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 17.0, "tree_w": 33, "tree_size": 256, "t0": 4.356, "t1": 0.894, "tft": 8.2015, "input_0": 876, "input_1": 257, "min_CLP": -5.8, "draft_iters": 18.4, "mem_use": 48.17, "gen_rate": 9.0, "speed": 1.71, "text": "One example where you might use "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 19.5, "tree_w": 44, "tree_size": 256, "t0": 4.6525, "t1": 0.87, "tft": 6.7386, "input_0": 890, "input_1": 257, "min_CLP": -6.18, "draft_iters": 21.2, "mem_use": 45.79, "gen_rate": 9.5, "speed": 1.72, "text": "<response>\\nHello! I understand "}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 59, "tree_h": 14.0, "tree_w": 79, "tree_size": 256, "t0": 2.9871, "t1": 0.8729, "tft": 6.2952, "input_0": 542, "input_1": 257, "min_CLP": -6.97, "draft_iters": 14.9, "mem_use": 45.58, "gen_rate": 8.4, "speed": 2.18, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.0, "tree_w": 34, "tree_size": 256, "t0": 4.26, "t1": 0.89, "tft": 7.4778, "input_0": 916, "input_1": 257, "min_CLP": -5.93, "draft_iters": 16.7, "mem_use": 47.76, "gen_rate": 12.7, "speed": 2.46, "text": "Yes, there are a few open source"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 37, "tree_size": 256, "t0": 3.6767, "t1": 0.8733, "tft": 6.9037, "input_0": 770, "input_1": 257, "min_CLP": -5.8, "draft_iters": 15.3, "mem_use": 45.58, "gen_rate": 11.7, "speed": 2.56, "text": "To use software defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.0, "tree_w": 48, "tree_size": 256, "t0": 4.28, "t1": 0.88, "tft": 5.3706, "input_0": 754, "input_1": 257, "min_CLP": -6.35, "draft_iters": 20.3, "mem_use": 46.28, "gen_rate": 12.3, "speed": 2.39, "text": "No, there is also no clean, ethi"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 17.2, "tree_w": 38, "tree_size": 256, "t0": 4.0025, "t1": 0.89, "tft": 8.3088, "input_0": 698, "input_1": 257, "min_CLP": -6.04, "draft_iters": 18.5, "mem_use": 47.15, "gen_rate": 10.2, "speed": 2.09, "text": "1. m\u00eb (suffix) is pronounced as "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.6, "tree_w": 60, "tree_size": 256, "t0": 2.994, "t1": 0.876, "tft": 3.9845, "input_0": 658, "input_1": 257, "min_CLP": -6.11, "draft_iters": 12.2, "mem_use": 45.83, "gen_rate": 7.8, "speed": 2.02, "text": "I am Open Assistant, a virtual a"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 27.7, "tree_w": 24, "tree_size": 256, "t0": 5.7567, "t1": 0.8967, "tft": 6.9992, "input_0": 960, "input_1": 257, "min_CLP": -5.51, "draft_iters": 28.7, "mem_use": 48.59, "gen_rate": 11.0, "speed": 1.65, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 45, "tree_size": 256, "t0": 3.078, "t1": 0.87, "tft": 4.757, "input_0": 639, "input_1": 257, "min_CLP": -6.05, "draft_iters": 13.0, "mem_use": 45.54, "gen_rate": 7.0, "speed": 1.77, "text": "To format an URL in reStructured"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 6.405, "t1": 0.885, "tft": 6.5814, "input_0": 1166, "input_1": 257, "min_CLP": -5.56, "draft_iters": 32.0, "mem_use": 47.55, "gen_rate": 18.5, "speed": 2.54, "text": "\"Here's an example code using SD"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.5, "tree_w": 38, "tree_size": 256, "t0": 3.8675, "t1": 0.87, "tft": 5.891, "input_0": 881, "input_1": 257, "min_CLP": -5.91, "draft_iters": 15.8, "mem_use": 45.52, "gen_rate": 9.0, "speed": 1.9, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.6, "tree_w": 70, "tree_size": 256, "t0": 2.678, "t1": 0.874, "tft": 3.5258, "input_0": 575, "input_1": 257, "min_CLP": -6.43, "draft_iters": 10.8, "mem_use": 45.98, "gen_rate": 7.2, "speed": 2.03, "text": "\"It's unlikely that AI assistant"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.0, "tree_w": 70, "tree_size": 256, "t0": 2.6657, "t1": 0.9071, "tft": 9.2546, "input_0": 619, "input_1": 257, "min_CLP": -6.48, "draft_iters": 10.4, "mem_use": 51.15, "gen_rate": 4.6, "speed": 1.28, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.8, "tree_w": 55, "tree_size": 256, "t0": 3.0783, "t1": 0.8783, "tft": 5.023, "input_0": 689, "input_1": 257, "min_CLP": -6.47, "draft_iters": 11.5, "mem_use": 46.35, "gen_rate": 6.2, "speed": 1.56, "text": "0 Independent counsel is a legal"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.6, "tree_w": 46, "tree_size": 256, "t0": 3.72, "t1": 0.89, "tft": 6.5779, "input_0": 759, "input_1": 257, "min_CLP": -6.0, "draft_iters": 15.0, "mem_use": 48.21, "gen_rate": 6.8, "speed": 1.47, "text": "I understand that you might be f"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.0, "tree_w": 47, "tree_size": 256, "t0": 3.64, "t1": 0.88, "tft": 5.7472, "input_0": 791, "input_1": 257, "min_CLP": -6.45, "draft_iters": 14.8, "mem_use": 46.58, "gen_rate": 9.0, "speed": 1.99, "text": "1. **Economic Factors**: If ther"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.8, "tree_w": 45, "tree_size": 256, "t0": 3.282, "t1": 0.878, "tft": 6.893, "input_0": 770, "input_1": 257, "min_CLP": -6.25, "draft_iters": 12.8, "mem_use": 45.86, "gen_rate": 7.0, "speed": 1.68, "text": "Here\\'s a potential script for a"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.3, "tree_w": 35, "tree_size": 256, "t0": 4.7867, "t1": 0.89, "tft": 9.6492, "input_0": 1065, "input_1": 257, "min_CLP": -6.03, "draft_iters": 19.0, "mem_use": 48.33, "gen_rate": 13.3, "speed": 2.35, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 14.7, "tree_w": 34, "tree_size": 256, "t0": 3.88, "t1": 0.8733, "tft": 5.7707, "input_0": 818, "input_1": 257, "min_CLP": -5.82, "draft_iters": 15.7, "mem_use": 46.04, "gen_rate": 12.7, "speed": 2.66, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.8, "tree_w": 41, "tree_size": 256, "t0": 3.8425, "t1": 0.89, "tft": 9.1326, "input_0": 820, "input_1": 257, "min_CLP": -6.0, "draft_iters": 16.0, "mem_use": 48.0, "gen_rate": 8.8, "speed": 1.85, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.5, "tree_w": 39, "tree_size": 256, "t0": 4.1575, "t1": 0.8675, "tft": 5.9624, "input_0": 853, "input_1": 257, "min_CLP": -6.16, "draft_iters": 15.8, "mem_use": 45.56, "gen_rate": 8.8, "speed": 1.74, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.4, "tree_w": 72, "tree_size": 256, "t0": 2.4757, "t1": 0.8771, "tft": 4.4434, "input_0": 552, "input_1": 257, "min_CLP": -6.52, "draft_iters": 9.6, "mem_use": 46.29, "gen_rate": 5.6, "speed": 1.66, "text": "In 1967, the Wyoming State Legis"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 67, "tree_size": 256, "t0": 2.776, "t1": 0.876, "tft": 6.2465, "input_0": 562, "input_1": 257, "min_CLP": -6.41, "draft_iters": 11.8, "mem_use": 46.01, "gen_rate": 6.4, "speed": 1.75, "text": "\"[INST] What are some general ti"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 5.79, "t1": 0.87, "tft": 5.5557, "input_0": 804, "input_1": 257, "min_CLP": -9.25, "draft_iters": 32.0, "mem_use": 45.6, "gen_rate": 33.0, "speed": 4.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.3, "tree_w": 43, "tree_size": 256, "t0": 4.2067, "t1": 0.88, "tft": 5.321, "input_0": 882, "input_1": 257, "min_CLP": -6.07, "draft_iters": 17.7, "mem_use": 46.49, "gen_rate": 11.0, "speed": 2.16, "text": "\"It's natural to feel self-consc"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 23.0, "tree_w": 29, "tree_size": 256, "t0": 5.0467, "t1": 0.89, "tft": 8.2201, "input_0": 893, "input_1": 257, "min_CLP": -5.88, "draft_iters": 24.3, "mem_use": 48.08, "gen_rate": 12.7, "speed": 2.13, "text": "Sure, here is a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 15, "tree_h": 24.3, "tree_w": 42, "tree_size": 256, "t0": 4.67, "t1": 0.87, "tft": 6.8044, "input_0": 700, "input_1": 257, "min_CLP": -5.97, "draft_iters": 25.3, "mem_use": 45.72, "gen_rate": 5.0, "speed": 0.9, "text": "The total travel time, including"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 29.5, "tree_w": 19, "tree_size": 256, "t0": 6.185, "t1": 0.875, "tft": 6.5174, "input_0": 1019, "input_1": 257, "min_CLP": -5.49, "draft_iters": 30.5, "mem_use": 45.63, "gen_rate": 22.0, "speed": 3.12, "text": "\"```js\\nconst Discord = require("}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 16.3, "tree_w": 30, "tree_size": 256, "t0": 4.25, "t1": 0.8767, "tft": 6.2978, "input_0": 891, "input_1": 257, "min_CLP": -6.08, "draft_iters": 17.3, "mem_use": 45.52, "gen_rate": 12.3, "speed": 2.41, "text": "No, as an AI language model, I a"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.8, "tree_w": 35, "tree_size": 256, "t0": 4.615, "t1": 0.905, "tft": 7.1089, "input_0": 1004, "input_1": 257, "min_CLP": -6.16, "draft_iters": 17.2, "mem_use": 49.3, "gen_rate": 9.0, "speed": 1.63, "text": "\"TypeScript is a superset of Jav"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 30, "tree_h": 24.2, "tree_w": 37, "tree_size": 256, "t0": 4.818, "t1": 0.874, "tft": 6.8084, "input_0": 806, "input_1": 257, "min_CLP": -5.94, "draft_iters": 25.0, "mem_use": 45.64, "gen_rate": 6.0, "speed": 1.05, "text": "The name of the fourth kid is Mi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 42, "tree_size": 256, "t0": 5.86, "t1": 0.88, "tft": 5.0962, "input_0": 983, "input_1": 257, "min_CLP": -8.13, "draft_iters": 32.0, "mem_use": 46.68, "gen_rate": 32.0, "speed": 4.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 14.0, "tree_w": 39, "tree_size": 256, "t0": 4.3733, "t1": 0.9, "tft": 6.6009, "input_0": 986, "input_1": 257, "min_CLP": -6.04, "draft_iters": 15.7, "mem_use": 48.45, "gen_rate": 13.3, "speed": 2.53, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 46, "tree_size": 256, "t0": 3.218, "t1": 0.874, "tft": 4.2572, "input_0": 709, "input_1": 257, "min_CLP": -6.12, "draft_iters": 12.2, "mem_use": 45.77, "gen_rate": 6.4, "speed": 1.56, "text": "\"It sounds like you're feeling o"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 17, "tree_h": 14.5, "tree_w": 59, "tree_size": 256, "t0": 3.76, "t1": 0.875, "tft": 4.2496, "input_0": 885, "input_1": 257, "min_CLP": -6.34, "draft_iters": 15.5, "mem_use": 46.28, "gen_rate": 8.5, "speed": 1.83, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 17.0, "tree_w": 33, "tree_size": 256, "t0": 4.43, "t1": 0.8925, "tft": 8.0468, "input_0": 883, "input_1": 257, "min_CLP": -5.71, "draft_iters": 18.2, "mem_use": 48.01, "gen_rate": 10.5, "speed": 1.97, "text": "\"As a high school student, there"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 29, "tree_h": 18.7, "tree_w": 36, "tree_size": 256, "t0": 4.7367, "t1": 0.88, "tft": 6.0094, "input_0": 1006, "input_1": 257, "min_CLP": -6.06, "draft_iters": 19.7, "mem_use": 46.41, "gen_rate": 9.7, "speed": 1.72, "text": "\"The television was invented by "}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 23, "tree_h": 15.5, "tree_w": 35, "tree_size": 256, "t0": 4.245, "t1": 0.895, "tft": 6.6984, "input_0": 918, "input_1": 257, "min_CLP": -6.23, "draft_iters": 17.5, "mem_use": 48.74, "gen_rate": 11.5, "speed": 2.24, "text": "\"I'm glad to help. Let me know i"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.5, "tree_w": 41, "tree_size": 256, "t0": 3.6675, "t1": 0.89, "tft": 6.1551, "input_0": 840, "input_1": 257, "min_CLP": -6.01, "draft_iters": 14.5, "mem_use": 47.07, "gen_rate": 9.5, "speed": 2.09, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 7.8, "tree_w": 70, "tree_size": 256, "t0": 2.22, "t1": 0.88, "tft": 5.2448, "input_0": 501, "input_1": 257, "min_CLP": -6.56, "draft_iters": 8.8, "mem_use": 46.09, "gen_rate": 4.5, "speed": 1.45, "text": "Okay, I will try my best to lear"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 15.3, "tree_w": 31, "tree_size": 256, "t0": 4.27, "t1": 0.89, "tft": 8.111, "input_0": 1024, "input_1": 257, "min_CLP": -5.87, "draft_iters": 16.3, "mem_use": 47.89, "gen_rate": 14.0, "speed": 2.71, "text": "\"The most difficult parts of lea"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 256, "t0": 5.53, "t1": 0.87, "tft": 5.2027, "input_0": 761, "input_1": 257, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 45.71, "gen_rate": 33.0, "speed": 5.15, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 53, "tree_size": 256, "t0": 2.952, "t1": 0.878, "tft": 5.363, "input_0": 621, "input_1": 257, "min_CLP": -6.24, "draft_iters": 12.0, "mem_use": 46.34, "gen_rate": 7.6, "speed": 1.98, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 12.8, "tree_w": 75, "tree_size": 256, "t0": 2.95, "t1": 0.875, "tft": 5.0732, "input_0": 538, "input_1": 257, "min_CLP": -6.92, "draft_iters": 14.0, "mem_use": 45.81, "gen_rate": 5.0, "speed": 1.31, "text": "\"Ah, you're a broke college stud"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 7.12, "t1": 0.87, "tft": 6.5573, "input_0": 1188, "input_1": 257, "min_CLP": -10.34, "draft_iters": 32.0, "mem_use": 45.82, "gen_rate": 33.0, "speed": 4.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 63, "tree_size": 256, "t0": 2.5717, "t1": 0.8783, "tft": 4.9349, "input_0": 561, "input_1": 257, "min_CLP": -6.51, "draft_iters": 10.2, "mem_use": 46.21, "gen_rate": 5.5, "speed": 1.59, "text": "Google Authenticator provides tw"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 25.3, "tree_w": 26, "tree_size": 256, "t0": 6.26, "t1": 0.88, "tft": 6.0355, "input_0": 1218, "input_1": 257, "min_CLP": -6.01, "draft_iters": 26.3, "mem_use": 45.99, "gen_rate": 16.0, "speed": 2.24, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 20.7, "tree_w": 29, "tree_size": 256, "t0": 5.8467, "t1": 0.8767, "tft": 6.7339, "input_0": 1205, "input_1": 257, "min_CLP": -5.86, "draft_iters": 22.0, "mem_use": 45.75, "gen_rate": 13.7, "speed": 2.03, "text": "Here\\'s an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.0, "tree_w": 40, "tree_size": 256, "t0": 3.6433, "t1": 0.8733, "tft": 6.0224, "input_0": 706, "input_1": 257, "min_CLP": -5.94, "draft_iters": 16.0, "mem_use": 45.61, "gen_rate": 11.0, "speed": 2.44, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.0, "tree_w": 35, "tree_size": 256, "t0": 4.5467, "t1": 0.8767, "tft": 4.84, "input_0": 860, "input_1": 257, "min_CLP": -5.95, "draft_iters": 21.0, "mem_use": 45.63, "gen_rate": 11.3, "speed": 2.09, "text": "```python\\n# Define a function t"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.5, "tree_w": 46, "tree_size": 256, "t0": 3.3325, "t1": 0.875, "tft": 3.6038, "input_0": 673, "input_1": 257, "min_CLP": -6.2, "draft_iters": 13.5, "mem_use": 45.55, "gen_rate": 8.5, "speed": 2.02, "text": "Title: Kunji: Revolutionizing De"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 15.3, "tree_w": 39, "tree_size": 256, "t0": 4.24, "t1": 0.8833, "tft": 5.4177, "input_0": 929, "input_1": 257, "min_CLP": -5.99, "draft_iters": 17.0, "mem_use": 46.74, "gen_rate": 12.3, "speed": 2.41, "text": "In that case, you can use your l"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 22.3, "tree_w": 28, "tree_size": 256, "t0": 4.89, "t1": 0.8667, "tft": 5.0413, "input_0": 852, "input_1": 257, "min_CLP": -5.66, "draft_iters": 23.7, "mem_use": 45.51, "gen_rate": 11.7, "speed": 2.03, "text": "In Python, the @ symbol is used "}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.5, "tree_w": 47, "tree_size": 256, "t0": 3.875, "t1": 0.87, "tft": 5.9678, "input_0": 795, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.8, "mem_use": 45.52, "gen_rate": 10.0, "speed": 2.11, "text": "I think ChatGPT is a very powerf"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.2, "tree_w": 49, "tree_size": 256, "t0": 3.355, "t1": 0.8783, "tft": 4.4538, "input_0": 703, "input_1": 257, "min_CLP": -6.23, "draft_iters": 14.5, "mem_use": 45.83, "gen_rate": 5.7, "speed": 1.34, "text": "\"I would approach the task as a "}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 16.0, "tree_w": 78, "tree_size": 256, "t0": 3.45, "t1": 0.865, "tft": 5.2491, "input_0": 634, "input_1": 257, "min_CLP": -6.86, "draft_iters": 17.5, "mem_use": 45.56, "gen_rate": 3.0, "speed": 0.7, "text": "[INST] how are you? [/INST]"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 60, "tree_size": 256, "t0": 5.56, "t1": 0.88, "tft": 5.1312, "input_0": 885, "input_1": 257, "min_CLP": -7.1, "draft_iters": 32.0, "mem_use": 46.26, "gen_rate": 33.0, "speed": 5.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 19.4, "tree_w": 52, "tree_size": 256, "t0": 3.84, "t1": 0.9, "tft": 7.6377, "input_0": 663, "input_1": 257, "min_CLP": -6.13, "draft_iters": 20.2, "mem_use": 48.77, "gen_rate": 6.4, "speed": 1.35, "text": "Here are some questions related "}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 37, "tree_size": 256, "t0": 3.7775, "t1": 0.8725, "tft": 6.1039, "input_0": 860, "input_1": 257, "min_CLP": -5.78, "draft_iters": 16.2, "mem_use": 46.07, "gen_rate": 8.8, "speed": 1.88, "text": "Decorators and wrapping function"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.5, "tree_w": 56, "tree_size": 256, "t0": 3.2717, "t1": 0.8883, "tft": 5.4342, "input_0": 695, "input_1": 257, "min_CLP": -6.35, "draft_iters": 14.0, "mem_use": 47.19, "gen_rate": 5.3, "speed": 1.28, "text": "Hello there, Agent. I hope you a"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 18.0, "tree_w": 51, "tree_size": 256, "t0": 3.975, "t1": 0.88, "tft": 5.6783, "input_0": 739, "input_1": 257, "min_CLP": -6.71, "draft_iters": 19.5, "mem_use": 46.06, "gen_rate": 6.3, "speed": 1.31, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 23.7, "tree_w": 28, "tree_size": 256, "t0": 5.16, "t1": 0.9033, "tft": 8.5243, "input_0": 940, "input_1": 257, "min_CLP": -5.61, "draft_iters": 24.3, "mem_use": 48.96, "gen_rate": 17.3, "speed": 2.86, "text": "Sure! Here are some simple examp"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.0, "tree_w": 36, "tree_size": 256, "t0": 4.7033, "t1": 0.9567, "tft": 15.596, "input_0": 920, "input_1": 257, "min_CLP": -5.78, "draft_iters": 20.3, "mem_use": 54.99, "gen_rate": 12.0, "speed": 2.12, "text": "\"Sure! Here's an example code us"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.0, "tree_w": 42, "tree_size": 256, "t0": 3.5767, "t1": 0.8833, "tft": 5.5712, "input_0": 627, "input_1": 257, "min_CLP": -6.03, "draft_iters": 18.0, "mem_use": 47.29, "gen_rate": 13.0, "speed": 2.91, "text": "\"The average person might not en"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.0, "tree_w": 35, "tree_size": 256, "t0": 4.2467, "t1": 0.8733, "tft": 6.2264, "input_0": 845, "input_1": 257, "min_CLP": -5.87, "draft_iters": 18.3, "mem_use": 45.57, "gen_rate": 11.3, "speed": 2.21, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.8, "tree_w": 43, "tree_size": 256, "t0": 3.6825, "t1": 0.87, "tft": 4.3207, "input_0": 784, "input_1": 257, "min_CLP": -5.91, "draft_iters": 15.0, "mem_use": 45.68, "gen_rate": 8.8, "speed": 1.92, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 55, "tree_size": 256, "t0": 3.364, "t1": 0.888, "tft": 6.9839, "input_0": 772, "input_1": 257, "min_CLP": -6.18, "draft_iters": 13.4, "mem_use": 48.46, "gen_rate": 6.4, "speed": 1.51, "text": "\"Of course! Let's come up with a"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.5, "tree_w": 38, "tree_size": 256, "t0": 3.2275, "t1": 0.87, "tft": 6.0656, "input_0": 684, "input_1": 257, "min_CLP": -5.91, "draft_iters": 13.8, "mem_use": 45.62, "gen_rate": 9.5, "speed": 2.32, "text": "In 1950, the world was just begi"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.2, "tree_w": 40, "tree_size": 256, "t0": 4.2425, "t1": 0.91, "tft": 9.2449, "input_0": 920, "input_1": 257, "min_CLP": -5.91, "draft_iters": 17.0, "mem_use": 50.63, "gen_rate": 9.8, "speed": 1.89, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 64, "tree_size": 256, "t0": 2.7283, "t1": 0.875, "tft": 3.5954, "input_0": 640, "input_1": 257, "min_CLP": -6.4, "draft_iters": 10.8, "mem_use": 45.97, "gen_rate": 5.8, "speed": 1.62, "text": "\"First you want to install the C"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.7, "tree_w": 38, "tree_size": 256, "t0": 3.4733, "t1": 0.8733, "tft": 5.3536, "input_0": 773, "input_1": 257, "min_CLP": -5.95, "draft_iters": 13.7, "mem_use": 45.81, "gen_rate": 11.0, "speed": 2.53, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 8.9, "tree_w": 83, "tree_size": 256, "t0": 2.4257, "t1": 0.8729, "tft": 3.7083, "input_0": 527, "input_1": 257, "min_CLP": -6.76, "draft_iters": 10.1, "mem_use": 45.88, "gen_rate": 5.9, "speed": 1.78, "text": "I will be capable of understandi"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 43, "tree_size": 256, "t0": 3.9425, "t1": 0.885, "tft": 6.898, "input_0": 822, "input_1": 257, "min_CLP": -6.04, "draft_iters": 16.8, "mem_use": 47.23, "gen_rate": 8.5, "speed": 1.76, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.3, "tree_w": 33, "tree_size": 256, "t0": 5.0867, "t1": 0.87, "tft": 6.971, "input_0": 1027, "input_1": 257, "min_CLP": -5.87, "draft_iters": 21.0, "mem_use": 45.94, "gen_rate": 10.7, "speed": 1.79, "text": "The KeyHole series of spy satell"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 115, "tree_size": 256, "t0": 4.53, "t1": 0.88, "tft": 6.8455, "input_0": 382, "input_1": 257, "min_CLP": -7.19, "draft_iters": 32.0, "mem_use": 46.12, "gen_rate": 33.0, "speed": 6.1, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.4, "tree_w": 43, "tree_size": 256, "t0": 3.464, "t1": 0.88, "tft": 5.8443, "input_0": 772, "input_1": 257, "min_CLP": -5.96, "draft_iters": 13.6, "mem_use": 46.18, "gen_rate": 7.4, "speed": 1.7, "text": "\"Yes, there are a few things you"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.9, "tree_w": 50, "tree_size": 256, "t0": 3.2614, "t1": 0.8914, "tft": 6.6354, "input_0": 693, "input_1": 257, "min_CLP": -6.23, "draft_iters": 13.3, "mem_use": 48.1, "gen_rate": 5.3, "speed": 1.27, "text": "\u2022 Truefire - This channel offers"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.2, "tree_w": 40, "tree_size": 256, "t0": 3.9525, "t1": 0.87, "tft": 6.4385, "input_0": 750, "input_1": 257, "min_CLP": -6.05, "draft_iters": 18.2, "mem_use": 45.52, "gen_rate": 8.5, "speed": 1.76, "text": "No, stainless steel is not magne"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 22.0, "tree_w": 30, "tree_size": 256, "t0": 5.455, "t1": 0.875, "tft": 6.9287, "input_0": 980, "input_1": 257, "min_CLP": -5.69, "draft_iters": 23.5, "mem_use": 45.67, "gen_rate": 19.5, "speed": 3.08, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.8, "tree_w": 40, "tree_size": 256, "t0": 3.9275, "t1": 0.8875, "tft": 5.3627, "input_0": 737, "input_1": 257, "min_CLP": -6.26, "draft_iters": 17.8, "mem_use": 47.1, "gen_rate": 8.5, "speed": 1.77, "text": "Statistical modeling, applying a"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 5.94, "t1": 0.9, "tft": 8.7546, "input_0": 884, "input_1": 257, "min_CLP": -6.29, "draft_iters": 32.0, "mem_use": 48.27, "gen_rate": 33.0, "speed": 4.83, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 14, "tree_size": 256, "t0": 7.32, "t1": 0.87, "tft": 6.0691, "input_0": 1408, "input_1": 257, "min_CLP": -11.49, "draft_iters": 32.0, "mem_use": 45.51, "gen_rate": 32.0, "speed": 3.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.0, "tree_w": 46, "tree_size": 256, "t0": 3.8825, "t1": 0.885, "tft": 6.0182, "input_0": 785, "input_1": 257, "min_CLP": -6.15, "draft_iters": 16.8, "mem_use": 46.99, "gen_rate": 8.2, "speed": 1.73, "text": "Yes, that\\'s a great idea. The p"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.0, "tree_w": 66, "tree_size": 256, "t0": 2.4929, "t1": 0.8729, "tft": 3.8118, "input_0": 552, "input_1": 257, "min_CLP": -6.49, "draft_iters": 10.0, "mem_use": 45.87, "gen_rate": 5.6, "speed": 1.66, "text": "\"To be honest, that's totally no"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 22.3, "tree_w": 33, "tree_size": 256, "t0": 5.76, "t1": 0.8733, "tft": 5.0443, "input_0": 1024, "input_1": 257, "min_CLP": -5.67, "draft_iters": 23.3, "mem_use": 45.56, "gen_rate": 11.7, "speed": 1.76, "text": "To estimate the variance of a va"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 14.8, "tree_w": 35, "tree_size": 256, "t0": 3.9375, "t1": 0.8725, "tft": 5.1129, "input_0": 839, "input_1": 257, "min_CLP": -6.17, "draft_iters": 16.2, "mem_use": 45.92, "gen_rate": 11.0, "speed": 2.29, "text": "Certainly! One legal reference t"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 15.5, "tree_w": 48, "tree_size": 256, "t0": 3.67, "t1": 0.8675, "tft": 6.3406, "input_0": 700, "input_1": 257, "min_CLP": -6.16, "draft_iters": 16.8, "mem_use": 45.5, "gen_rate": 12.0, "speed": 2.64, "text": "It is a good question.\\nMetaboli"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 19.0, "tree_w": 56, "tree_size": 256, "t0": 4.1475, "t1": 0.88, "tft": 6.4456, "input_0": 801, "input_1": 257, "min_CLP": -6.55, "draft_iters": 20.2, "mem_use": 46.84, "gen_rate": 11.5, "speed": 2.29, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 10, "tree_h": 23.0, "tree_w": 54, "tree_size": 256, "t0": 4.92, "t1": 0.87, "tft": 6.8551, "input_0": 880, "input_1": 257, "min_CLP": -6.39, "draft_iters": 24.0, "mem_use": 45.69, "gen_rate": 10.0, "speed": 1.73, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.5, "tree_w": 32, "tree_size": 256, "t0": 4.685, "t1": 0.8775, "tft": 5.1159, "input_0": 936, "input_1": 257, "min_CLP": -6.39, "draft_iters": 20.0, "mem_use": 46.08, "gen_rate": 8.0, "speed": 1.44, "text": "Pacific Ocean, Atlantic Ocean, I"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.2, "tree_w": 80, "tree_size": 256, "t0": 2.1538, "t1": 0.8775, "tft": 4.3135, "input_0": 490, "input_1": 257, "min_CLP": -6.67, "draft_iters": 8.5, "mem_use": 46.32, "gen_rate": 4.4, "speed": 1.44, "text": "\"That's a good question. \\nYou w"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 29.5, "tree_w": 22, "tree_size": 256, "t0": 5.935, "t1": 0.87, "tft": 4.9424, "input_0": 937, "input_1": 257, "min_CLP": -5.75, "draft_iters": 30.5, "mem_use": 45.73, "gen_rate": 17.5, "speed": 2.57, "text": "\"Here's a simple PyGame project "}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.3, "tree_w": 44, "tree_size": 256, "t0": 3.6567, "t1": 0.88, "tft": 5.6982, "input_0": 821, "input_1": 257, "min_CLP": -5.92, "draft_iters": 14.0, "mem_use": 46.84, "gen_rate": 12.3, "speed": 2.72, "text": "A Dynamic Link Library (DLL) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.5, "tree_w": 52, "tree_size": 256, "t0": 3.695, "t1": 0.8775, "tft": 4.4723, "input_0": 660, "input_1": 257, "min_CLP": -6.32, "draft_iters": 18.2, "mem_use": 45.97, "gen_rate": 9.5, "speed": 2.08, "text": "Please provide a detailed descri"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.0, "tree_w": 67, "tree_size": 256, "t0": 2.9133, "t1": 0.8683, "tft": 6.4276, "input_0": 654, "input_1": 257, "min_CLP": -6.34, "draft_iters": 11.3, "mem_use": 45.51, "gen_rate": 6.2, "speed": 1.63, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.7, "tree_w": 34, "tree_size": 256, "t0": 5.1167, "t1": 0.87, "tft": 4.5593, "input_0": 1070, "input_1": 257, "min_CLP": -5.98, "draft_iters": 19.3, "mem_use": 45.63, "gen_rate": 12.0, "speed": 2.0, "text": "\"Sure! Here's an example of a hi"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.2, "tree_w": 67, "tree_size": 256, "t0": 2.8, "t1": 0.8767, "tft": 3.8451, "input_0": 596, "input_1": 257, "min_CLP": -6.51, "draft_iters": 11.5, "mem_use": 45.77, "gen_rate": 6.0, "speed": 1.63, "text": "\"They are not on a higher moral "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 8.7, "tree_w": 81, "tree_size": 256, "t0": 2.2289, "t1": 0.8789, "tft": 5.6122, "input_0": 476, "input_1": 257, "min_CLP": -6.75, "draft_iters": 9.7, "mem_use": 46.29, "gen_rate": 4.3, "speed": 1.4, "text": "\"The show is just too slow and b"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.5, "tree_w": 33, "tree_size": 256, "t0": 3.9275, "t1": 0.8875, "tft": 6.2389, "input_0": 851, "input_1": 257, "min_CLP": -5.82, "draft_iters": 15.8, "mem_use": 47.14, "gen_rate": 8.8, "speed": 1.82, "text": "\"Yes, you can certainly ask me f"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.0, "tree_w": 35, "tree_size": 256, "t0": 4.4667, "t1": 0.89, "tft": 6.4351, "input_0": 960, "input_1": 257, "min_CLP": -5.8, "draft_iters": 18.0, "mem_use": 47.67, "gen_rate": 11.7, "speed": 2.18, "text": "The difficulty of learning a lan"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 45, "tree_size": 256, "t0": 3.2475, "t1": 0.875, "tft": 5.737, "input_0": 665, "input_1": 257, "min_CLP": -5.94, "draft_iters": 13.8, "mem_use": 46.12, "gen_rate": 8.2, "speed": 2.0, "text": "\"Some of these tools offer free "}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 49, "tree_size": 256, "t0": 2.81, "t1": 0.8775, "tft": 5.4066, "input_0": 647, "input_1": 257, "min_CLP": -6.14, "draft_iters": 11.0, "mem_use": 45.98, "gen_rate": 9.2, "speed": 2.51, "text": "As an AI, I do not have personal"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.8, "tree_w": 67, "tree_size": 256, "t0": 3.1317, "t1": 0.88, "tft": 4.3243, "input_0": 698, "input_1": 257, "min_CLP": -6.49, "draft_iters": 13.3, "mem_use": 46.19, "gen_rate": 5.3, "speed": 1.33, "text": "It is not worth it to compromise"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.7, "tree_w": 38, "tree_size": 256, "t0": 4.17, "t1": 0.8733, "tft": 5.8343, "input_0": 824, "input_1": 257, "min_CLP": -6.01, "draft_iters": 18.7, "mem_use": 46.2, "gen_rate": 11.7, "speed": 2.31, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.8, "tree_w": 61, "tree_size": 256, "t0": 2.952, "t1": 0.868, "tft": 5.4432, "input_0": 660, "input_1": 257, "min_CLP": -6.42, "draft_iters": 12.0, "mem_use": 45.63, "gen_rate": 7.2, "speed": 1.88, "text": "\"Sure, I can help you design an "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 14.0, "tree_w": 40, "tree_size": 256, "t0": 3.88, "t1": 0.8825, "tft": 6.5349, "input_0": 867, "input_1": 257, "min_CLP": -6.29, "draft_iters": 15.2, "mem_use": 47.3, "gen_rate": 10.2, "speed": 2.15, "text": "The largest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.6, "tree_w": 60, "tree_size": 256, "t0": 3.108, "t1": 0.876, "tft": 4.1016, "input_0": 660, "input_1": 257, "min_CLP": -6.35, "draft_iters": 13.8, "mem_use": 45.78, "gen_rate": 7.4, "speed": 1.86, "text": "\"Psychomotricity and Horse Ridin"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.0, "tree_w": 55, "tree_size": 256, "t0": 2.858, "t1": 0.87, "tft": 5.2575, "input_0": 663, "input_1": 257, "min_CLP": -6.23, "draft_iters": 11.4, "mem_use": 45.61, "gen_rate": 7.8, "speed": 2.09, "text": "Here are 10 names from different"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 45, "tree_size": 256, "t0": 3.234, "t1": 0.87, "tft": 4.6717, "input_0": 717, "input_1": 257, "min_CLP": -6.12, "draft_iters": 13.2, "mem_use": 46.09, "gen_rate": 6.8, "speed": 1.66, "text": "I am a large language model trai"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.8, "tree_w": 41, "tree_size": 256, "t0": 3.7775, "t1": 0.885, "tft": 6.3296, "input_0": 794, "input_1": 257, "min_CLP": -5.88, "draft_iters": 15.0, "mem_use": 47.77, "gen_rate": 9.5, "speed": 2.04, "text": "The initial noise produced in th"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 58, "tree_size": 256, "t0": 3.14, "t1": 0.882, "tft": 4.9661, "input_0": 692, "input_1": 257, "min_CLP": -6.29, "draft_iters": 12.6, "mem_use": 46.56, "gen_rate": 7.0, "speed": 1.74, "text": "Yes, there is a theory called \"h"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 47, "tree_size": 256, "t0": 4.19, "t1": 0.8867, "tft": 6.48, "input_0": 814, "input_1": 257, "min_CLP": -6.09, "draft_iters": 17.0, "mem_use": 46.99, "gen_rate": 11.3, "speed": 2.23, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.7, "tree_w": 65, "tree_size": 256, "t0": 2.5783, "t1": 0.8683, "tft": 3.1855, "input_0": 575, "input_1": 257, "min_CLP": -6.63, "draft_iters": 10.8, "mem_use": 45.55, "gen_rate": 5.3, "speed": 1.55, "text": "Title: The Mathemagicians\\n\\nPlo"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.0, "tree_w": 40, "tree_size": 256, "t0": 4.375, "t1": 0.91, "tft": 10.3356, "input_0": 846, "input_1": 257, "min_CLP": -5.95, "draft_iters": 18.2, "mem_use": 50.29, "gen_rate": 8.5, "speed": 1.61, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.4, "tree_w": 45, "tree_size": 256, "t0": 3.376, "t1": 0.88, "tft": 6.5633, "input_0": 750, "input_1": 257, "min_CLP": -5.96, "draft_iters": 13.8, "mem_use": 46.69, "gen_rate": 7.0, "speed": 1.64, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 35, "tree_size": 256, "t0": 3.7067, "t1": 0.88, "tft": 6.1854, "input_0": 688, "input_1": 257, "min_CLP": -5.92, "draft_iters": 16.7, "mem_use": 46.55, "gen_rate": 11.3, "speed": 2.47, "text": "If your original departure time "}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 34, "tree_size": 256, "t0": 4.2033, "t1": 0.87, "tft": 4.9115, "input_0": 915, "input_1": 257, "min_CLP": -5.98, "draft_iters": 16.3, "mem_use": 45.58, "gen_rate": 10.7, "speed": 2.1, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 71, "tree_size": 256, "t0": 2.864, "t1": 0.876, "tft": 5.2345, "input_0": 664, "input_1": 257, "min_CLP": -6.73, "draft_iters": 11.6, "mem_use": 45.92, "gen_rate": 7.0, "speed": 1.87, "text": "\"Certainly! Here's another one:\\"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 49, "tree_size": 256, "t0": 3.4767, "t1": 0.87, "tft": 6.4144, "input_0": 813, "input_1": 257, "min_CLP": -5.97, "draft_iters": 13.3, "mem_use": 45.53, "gen_rate": 11.0, "speed": 2.53, "text": "At the time of writing, the exac"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.2, "tree_w": 43, "tree_size": 256, "t0": 3.4425, "t1": 0.91, "tft": 7.3428, "input_0": 732, "input_1": 257, "min_CLP": -6.17, "draft_iters": 15.5, "mem_use": 50.34, "gen_rate": 9.8, "speed": 2.24, "text": "\"I apologize for the confusion e"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 43, "tree_size": 256, "t0": 3.7175, "t1": 0.87, "tft": 6.7111, "input_0": 834, "input_1": 257, "min_CLP": -6.07, "draft_iters": 15.0, "mem_use": 45.62, "gen_rate": 8.5, "speed": 1.85, "text": "The furthest back we can prove h"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 16.7, "tree_w": 54, "tree_size": 256, "t0": 3.5633, "t1": 0.9367, "tft": 11.1049, "input_0": 624, "input_1": 257, "min_CLP": -6.3, "draft_iters": 17.5, "mem_use": 52.58, "gen_rate": 7.2, "speed": 1.59, "text": "I am sorry, I did not understand"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 9.9, "tree_w": 77, "tree_size": 256, "t0": 2.4613, "t1": 0.88, "tft": 6.4326, "input_0": 499, "input_1": 257, "min_CLP": -6.74, "draft_iters": 10.9, "mem_use": 46.81, "gen_rate": 5.0, "speed": 1.5, "text": "\"Spritesla is not the first evol"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.6, "tree_w": 46, "tree_size": 256, "t0": 3.576, "t1": 0.868, "tft": 4.4903, "input_0": 788, "input_1": 257, "min_CLP": -5.92, "draft_iters": 14.8, "mem_use": 45.64, "gen_rate": 7.6, "speed": 1.71, "text": "Sure! To describe physical appea"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.7, "tree_w": 42, "tree_size": 256, "t0": 4.5867, "t1": 0.87, "tft": 5.2565, "input_0": 1012, "input_1": 257, "min_CLP": -6.18, "draft_iters": 19.3, "mem_use": 45.51, "gen_rate": 13.0, "speed": 2.38, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 32, "tree_size": 256, "t0": 6.29, "t1": 0.88, "tft": 6.5567, "input_0": 1027, "input_1": 257, "min_CLP": -9.4, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 32.0, "speed": 4.47, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 14.6, "tree_w": 43, "tree_size": 256, "t0": 3.832, "t1": 0.874, "tft": 4.1158, "input_0": 854, "input_1": 257, "min_CLP": -6.17, "draft_iters": 15.6, "mem_use": 46.06, "gen_rate": 8.4, "speed": 1.79, "text": "Here are a few TV shows you can "}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 19.5, "tree_w": 25, "tree_size": 256, "t0": 5.435, "t1": 0.89, "tft": 7.7119, "input_0": 1106, "input_1": 257, "min_CLP": -5.74, "draft_iters": 20.5, "mem_use": 47.67, "gen_rate": 18.0, "speed": 2.85, "text": "Certainly! Here are some hardwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.5, "tree_w": 46, "tree_size": 256, "t0": 4.0675, "t1": 0.88, "tft": 6.3255, "input_0": 951, "input_1": 257, "min_CLP": -6.17, "draft_iters": 15.0, "mem_use": 46.78, "gen_rate": 10.2, "speed": 2.07, "text": "\"When F-centers form in a crysta"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 10.0, "tree_w": 63, "tree_size": 256, "t0": 2.654, "t1": 0.87, "tft": 4.4822, "input_0": 569, "input_1": 257, "min_CLP": -6.55, "draft_iters": 11.4, "mem_use": 45.69, "gen_rate": 4.0, "speed": 1.13, "text": "\"The two players in the atomic b"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.3, "tree_w": 31, "tree_size": 256, "t0": 4.85, "t1": 0.89, "tft": 7.3941, "input_0": 907, "input_1": 257, "min_CLP": -5.58, "draft_iters": 22.3, "mem_use": 48.32, "gen_rate": 11.7, "speed": 2.03, "text": "\"Here's the updated code with co"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 37, "tree_size": 256, "t0": 4.065, "t1": 0.88, "tft": 5.9218, "input_0": 836, "input_1": 257, "min_CLP": -5.9, "draft_iters": 17.8, "mem_use": 46.81, "gen_rate": 8.8, "speed": 1.77, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 56, "tree_size": 256, "t0": 5.96, "t1": 0.87, "tft": 6.3453, "input_0": 914, "input_1": 257, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 45.53, "gen_rate": 32.0, "speed": 4.68, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 21.0, "tree_w": 28, "tree_size": 256, "t0": 4.69, "t1": 0.87, "tft": 4.5736, "input_0": 798, "input_1": 257, "min_CLP": -5.9, "draft_iters": 22.5, "mem_use": 45.62, "gen_rate": 8.0, "speed": 1.44, "text": "```python\\ndef example_function("}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 62, "tree_size": 256, "t0": 3.108, "t1": 0.88, "tft": 6.1572, "input_0": 764, "input_1": 257, "min_CLP": -6.46, "draft_iters": 12.2, "mem_use": 46.65, "gen_rate": 7.0, "speed": 1.76, "text": "\"Sure, here's a poem inspired by"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 19.8, "tree_w": 29, "tree_size": 256, "t0": 4.6925, "t1": 0.89, "tft": 7.6472, "input_0": 938, "input_1": 257, "min_CLP": -5.87, "draft_iters": 21.0, "mem_use": 47.6, "gen_rate": 12.2, "speed": 2.19, "text": "In JavaScript, you can use the `"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 54, "tree_size": 256, "t0": 2.8467, "t1": 0.875, "tft": 4.2229, "input_0": 630, "input_1": 257, "min_CLP": -6.24, "draft_iters": 12.0, "mem_use": 46.14, "gen_rate": 6.0, "speed": 1.61, "text": "Start by learning the basic chor"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.2, "tree_w": 39, "tree_size": 256, "t0": 4.0475, "t1": 0.88, "tft": 6.1658, "input_0": 876, "input_1": 257, "min_CLP": -5.98, "draft_iters": 16.0, "mem_use": 46.61, "gen_rate": 8.8, "speed": 1.78, "text": "My apologies for the assumption."}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.8, "tree_w": 38, "tree_size": 256, "t0": 3.915, "t1": 0.87, "tft": 6.7029, "input_0": 727, "input_1": 257, "min_CLP": -6.0, "draft_iters": 18.5, "mem_use": 45.52, "gen_rate": 9.0, "speed": 1.88, "text": "Javascript is a versatile langua"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.3, "tree_w": 33, "tree_size": 256, "t0": 3.72, "t1": 0.87, "tft": 5.0567, "input_0": 757, "input_1": 257, "min_CLP": -6.06, "draft_iters": 16.3, "mem_use": 45.51, "gen_rate": 12.7, "speed": 2.76, "text": "The chemicals that L-theanine af"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.8, "tree_w": 41, "tree_size": 256, "t0": 4.8075, "t1": 0.8775, "tft": 4.819, "input_0": 909, "input_1": 257, "min_CLP": -6.16, "draft_iters": 20.2, "mem_use": 46.23, "gen_rate": 8.8, "speed": 1.54, "text": "\"Here's the list organized into "}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 53, "tree_size": 256, "t0": 3.138, "t1": 0.876, "tft": 6.7559, "input_0": 687, "input_1": 257, "min_CLP": -6.2, "draft_iters": 12.0, "mem_use": 45.64, "gen_rate": 7.0, "speed": 1.74, "text": "Hippoplaisir is a unique psychol"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.3, "tree_w": 77, "tree_size": 256, "t0": 2.5729, "t1": 0.8729, "tft": 6.7239, "input_0": 532, "input_1": 257, "min_CLP": -6.55, "draft_iters": 11.4, "mem_use": 45.64, "gen_rate": 4.7, "speed": 1.37, "text": "\"Here's a poem for your Valentin"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 25, "tree_size": 256, "t0": 5.83, "t1": 0.87, "tft": 5.0612, "input_0": 862, "input_1": 257, "min_CLP": -8.07, "draft_iters": 32.0, "mem_use": 45.62, "gen_rate": 33.0, "speed": 4.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 57, "tree_size": 256, "t0": 2.8583, "t1": 0.9733, "tft": 7.4764, "input_0": 631, "input_1": 257, "min_CLP": -6.27, "draft_iters": 11.3, "mem_use": 50.4, "gen_rate": 5.3, "speed": 1.39, "text": "\"Here's a continuation of your s"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.0, "tree_w": 34, "tree_size": 256, "t0": 4.42, "t1": 0.8933, "tft": 6.8705, "input_0": 851, "input_1": 257, "min_CLP": -5.72, "draft_iters": 20.0, "mem_use": 48.02, "gen_rate": 11.0, "speed": 2.07, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 23.7, "tree_w": 25, "tree_size": 256, "t0": 5.18, "t1": 0.88, "tft": 6.2565, "input_0": 1006, "input_1": 257, "min_CLP": -5.19, "draft_iters": 24.7, "mem_use": 46.45, "gen_rate": 11.3, "speed": 1.87, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 17.8, "tree_w": 35, "tree_size": 256, "t0": 4.63, "t1": 0.88, "tft": 5.0988, "input_0": 962, "input_1": 257, "min_CLP": -5.75, "draft_iters": 19.0, "mem_use": 46.62, "gen_rate": 12.0, "speed": 2.18, "text": "We can learn a lot from polar be"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 45, "tree_size": 256, "t0": 3.415, "t1": 0.89, "tft": 6.5469, "input_0": 751, "input_1": 257, "min_CLP": -6.03, "draft_iters": 13.2, "mem_use": 47.67, "gen_rate": 8.8, "speed": 2.03, "text": "Lemon wedges for serving are sim"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 53, "tree_size": 256, "t0": 3.0625, "t1": 0.8775, "tft": 3.5899, "input_0": 604, "input_1": 257, "min_CLP": -6.24, "draft_iters": 13.0, "mem_use": 45.71, "gen_rate": 8.2, "speed": 2.09, "text": "\"Sure, I can play the role of th"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 50, "tree_size": 256, "t0": 3.152, "t1": 0.872, "tft": 4.1271, "input_0": 690, "input_1": 257, "min_CLP": -6.16, "draft_iters": 12.6, "mem_use": 45.67, "gen_rate": 7.0, "speed": 1.74, "text": "\"You're welcome! I'm sorry to he"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 25.0, "tree_w": 22, "tree_size": 256, "t0": 6.19, "t1": 0.8667, "tft": 6.002, "input_0": 1240, "input_1": 257, "min_CLP": -5.59, "draft_iters": 26.3, "mem_use": 45.55, "gen_rate": 15.7, "speed": 2.22, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.2, "tree_w": 39, "tree_size": 256, "t0": 4.065, "t1": 0.88, "tft": 5.7141, "input_0": 852, "input_1": 257, "min_CLP": -5.9, "draft_iters": 15.8, "mem_use": 47.13, "gen_rate": 9.8, "speed": 1.97, "text": "Yes, there are cities that were "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 47, "tree_size": 256, "t0": 3.636, "t1": 0.88, "tft": 7.3651, "input_0": 791, "input_1": 257, "min_CLP": -6.03, "draft_iters": 14.8, "mem_use": 46.65, "gen_rate": 7.0, "speed": 1.55, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 25, "tree_h": 15.0, "tree_w": 59, "tree_size": 256, "t0": 3.31, "t1": 0.8667, "tft": 3.8529, "input_0": 650, "input_1": 257, "min_CLP": -6.64, "draft_iters": 16.0, "mem_use": 45.5, "gen_rate": 8.3, "speed": 2.0, "text": "def multiply(x, y):\\n    return "}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 22.5, "tree_w": 41, "tree_size": 256, "t0": 4.41, "t1": 0.875, "tft": 6.496, "input_0": 793, "input_1": 257, "min_CLP": -8.05, "draft_iters": 23.0, "mem_use": 46.24, "gen_rate": 19.5, "speed": 3.69, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 30.2, "tree_w": 31, "tree_size": 256, "t0": 5.51, "t1": 0.88, "tft": 8.4842, "input_0": 816, "input_1": 257, "min_CLP": -5.79, "draft_iters": 30.6, "mem_use": 46.85, "gen_rate": 6.4, "speed": 1.0, "text": "I apologize for the mistake. Her"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.2, "tree_w": 42, "tree_size": 256, "t0": 4.005, "t1": 0.8725, "tft": 4.4191, "input_0": 834, "input_1": 257, "min_CLP": -6.12, "draft_iters": 15.5, "mem_use": 45.87, "gen_rate": 10.0, "speed": 2.05, "text": "1.    Prioritize and manage work"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.8, "tree_w": 36, "tree_size": 256, "t0": 3.9575, "t1": 0.87, "tft": 3.8165, "input_0": 931, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.0, "mem_use": 45.53, "gen_rate": 9.8, "speed": 2.02, "text": "Yes, I am familiar with the conc"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.2, "tree_w": 55, "tree_size": 256, "t0": 2.8417, "t1": 0.8683, "tft": 4.6659, "input_0": 627, "input_1": 257, "min_CLP": -6.32, "draft_iters": 12.2, "mem_use": 46.1, "gen_rate": 6.7, "speed": 1.8, "text": "Making a comparison of deep lear"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 20.6, "tree_w": 47, "tree_size": 256, "t0": 4.23, "t1": 0.878, "tft": 5.3661, "input_0": 694, "input_1": 257, "min_CLP": -6.34, "draft_iters": 21.6, "mem_use": 46.54, "gen_rate": 6.8, "speed": 1.33, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 25.0, "tree_w": 25, "tree_size": 256, "t0": 5.3033, "t1": 0.8767, "tft": 5.4018, "input_0": 982, "input_1": 257, "min_CLP": -6.4, "draft_iters": 25.7, "mem_use": 46.21, "gen_rate": 19.0, "speed": 3.08, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 6.18, "t1": 0.89, "tft": 9.4462, "input_0": 1076, "input_1": 257, "min_CLP": -6.52, "draft_iters": 32.0, "mem_use": 48.33, "gen_rate": 33.0, "speed": 4.67, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.0, "tree_w": 40, "tree_size": 256, "t0": 4.6233, "t1": 0.9, "tft": 7.3935, "input_0": 979, "input_1": 257, "min_CLP": -5.84, "draft_iters": 19.3, "mem_use": 49.91, "gen_rate": 11.7, "speed": 2.11, "text": "\"- Some vegan cheese brands that"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 47, "tree_size": 256, "t0": 3.845, "t1": 0.88, "tft": 5.1959, "input_0": 888, "input_1": 257, "min_CLP": -6.06, "draft_iters": 14.8, "mem_use": 46.92, "gen_rate": 8.2, "speed": 1.75, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 31.7, "tree_w": 19, "tree_size": 256, "t0": 6.6233, "t1": 0.8867, "tft": 6.4361, "input_0": 1157, "input_1": 257, "min_CLP": -5.57, "draft_iters": 32.0, "mem_use": 47.31, "gen_rate": 13.3, "speed": 1.78, "text": "Sure! Based on my understanding,"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.0, "tree_w": 29, "tree_size": 256, "t0": 4.8067, "t1": 0.8667, "tft": 5.9597, "input_0": 969, "input_1": 257, "min_CLP": -5.77, "draft_iters": 22.7, "mem_use": 45.53, "gen_rate": 12.0, "speed": 2.12, "text": "Sets and lists are both data str"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 44, "tree_size": 256, "t0": 3.8733, "t1": 0.88, "tft": 6.7798, "input_0": 844, "input_1": 257, "min_CLP": -6.03, "draft_iters": 15.7, "mem_use": 46.88, "gen_rate": 10.7, "speed": 2.24, "text": "Black Friday is typically celebr"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 43, "tree_size": 256, "t0": 3.6733, "t1": 0.87, "tft": 4.4669, "input_0": 788, "input_1": 257, "min_CLP": -6.18, "draft_iters": 16.7, "mem_use": 45.71, "gen_rate": 11.3, "speed": 2.5, "text": "\"Sure, here's a sample story in "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 57, "tree_size": 256, "t0": 2.9875, "t1": 0.87, "tft": 6.9098, "input_0": 680, "input_1": 257, "min_CLP": -6.14, "draft_iters": 12.2, "mem_use": 45.58, "gen_rate": 8.0, "speed": 2.07, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.0, "tree_w": 35, "tree_size": 256, "t0": 4.23, "t1": 0.87, "tft": 6.6453, "input_0": 831, "input_1": 257, "min_CLP": -5.94, "draft_iters": 17.7, "mem_use": 45.57, "gen_rate": 10.7, "speed": 2.09, "text": "In Minecraft, there are several "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 2.976, "t1": 0.872, "tft": 3.3767, "input_0": 700, "input_1": 257, "min_CLP": -6.39, "draft_iters": 12.2, "mem_use": 45.52, "gen_rate": 7.6, "speed": 1.98, "text": "As the Norse Goddess Freyja, I a"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 25.0, "tree_w": 55, "tree_size": 256, "t0": 4.62, "t1": 0.88, "tft": 6.4439, "input_0": 632, "input_1": 257, "min_CLP": -6.73, "draft_iters": 26.0, "mem_use": 46.8, "gen_rate": 0.0, "speed": 0.0, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 20.0, "tree_w": 38, "tree_size": 256, "t0": 4.4167, "t1": 0.87, "tft": 5.2079, "input_0": 852, "input_1": 257, "min_CLP": -5.91, "draft_iters": 21.3, "mem_use": 45.92, "gen_rate": 14.7, "speed": 2.77, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.3, "tree_w": 29, "tree_size": 256, "t0": 4.6, "t1": 0.9233, "tft": 8.4794, "input_0": 983, "input_1": 257, "min_CLP": -5.77, "draft_iters": 19.0, "mem_use": 51.01, "gen_rate": 12.7, "speed": 2.29, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.8, "tree_w": 45, "tree_size": 256, "t0": 3.5475, "t1": 0.8725, "tft": 4.0064, "input_0": 768, "input_1": 257, "min_CLP": -6.06, "draft_iters": 14.5, "mem_use": 46.05, "gen_rate": 8.8, "speed": 1.98, "text": "LLMs (Large Language Models) nee"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.7, "tree_w": 76, "tree_size": 256, "t0": 2.985, "t1": 0.8683, "tft": 4.7197, "input_0": 725, "input_1": 257, "min_CLP": -6.59, "draft_iters": 11.2, "mem_use": 45.61, "gen_rate": 6.0, "speed": 1.56, "text": "\"Sure! Here's a lighthearted jok"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 14.3, "tree_w": 45, "tree_size": 256, "t0": 3.7767, "t1": 0.8733, "tft": 6.9639, "input_0": 801, "input_1": 257, "min_CLP": -6.35, "draft_iters": 15.7, "mem_use": 45.83, "gen_rate": 12.7, "speed": 2.72, "text": "Eulogy for Grandma:\\n\\nDear fami"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 16.5, "tree_w": 49, "tree_size": 256, "t0": 3.9775, "t1": 0.89, "tft": 5.4938, "input_0": 775, "input_1": 257, "min_CLP": -6.01, "draft_iters": 17.5, "mem_use": 47.31, "gen_rate": 10.8, "speed": 2.21, "text": "[INST] What are some other graph"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.0, "tree_w": 45, "tree_size": 256, "t0": 3.7125, "t1": 0.8725, "tft": 4.7498, "input_0": 801, "input_1": 257, "min_CLP": -6.25, "draft_iters": 15.2, "mem_use": 45.69, "gen_rate": 9.2, "speed": 2.02, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 62, "tree_size": 256, "t0": 2.7317, "t1": 0.8717, "tft": 6.7943, "input_0": 608, "input_1": 257, "min_CLP": -6.45, "draft_iters": 10.8, "mem_use": 45.67, "gen_rate": 5.7, "speed": 1.57, "text": "- Play a game with them, somethi"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 39, "tree_size": 256, "t0": 3.5175, "t1": 0.87, "tft": 6.306, "input_0": 797, "input_1": 257, "min_CLP": -6.01, "draft_iters": 14.8, "mem_use": 45.51, "gen_rate": 8.5, "speed": 1.94, "text": "The color of Mars is typically d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 12, "tree_h": 9.3, "tree_w": 86, "tree_size": 256, "t0": 2.2533, "t1": 0.89, "tft": 6.8475, "input_0": 452, "input_1": 257, "min_CLP": -7.13, "draft_iters": 10.3, "mem_use": 47.74, "gen_rate": 4.0, "speed": 1.27, "text": "To say \"I love you\" in Quenya, y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 52, "tree_size": 256, "t0": 6.0, "t1": 0.88, "tft": 5.1026, "input_0": 935, "input_1": 257, "min_CLP": -7.46, "draft_iters": 32.0, "mem_use": 45.59, "gen_rate": 33.0, "speed": 4.8, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 2.96, "t1": 0.8775, "tft": 4.3907, "input_0": 642, "input_1": 257, "min_CLP": -6.24, "draft_iters": 12.0, "mem_use": 46.14, "gen_rate": 8.5, "speed": 2.22, "text": "The ATF is a government agency t"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 14.0, "tree_w": 48, "tree_size": 256, "t0": 3.725, "t1": 0.875, "tft": 6.9166, "input_0": 724, "input_1": 257, "min_CLP": -6.36, "draft_iters": 15.5, "mem_use": 45.59, "gen_rate": 5.5, "speed": 1.19, "text": "[INST] Think step-by-step and ju"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 24.0, "tree_w": 37, "tree_size": 256, "t0": 5.165, "t1": 0.88, "tft": 6.1967, "input_0": 866, "input_1": 257, "min_CLP": -6.08, "draft_iters": 25.0, "mem_use": 46.03, "gen_rate": 22.5, "speed": 3.72, "text": "\"Sure, I'd be happy to help! As "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.8, "tree_w": 37, "tree_size": 256, "t0": 3.6675, "t1": 0.8775, "tft": 5.3121, "input_0": 748, "input_1": 257, "min_CLP": -6.05, "draft_iters": 16.2, "mem_use": 45.71, "gen_rate": 10.0, "speed": 2.2, "text": "Melbourne was the temporary capi"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.8, "tree_w": 90, "tree_size": 256, "t0": 2.0344, "t1": 0.88, "tft": 4.0288, "input_0": 443, "input_1": 257, "min_CLP": -6.8, "draft_iters": 8.1, "mem_use": 45.88, "gen_rate": 4.1, "speed": 1.41, "text": "[INST] I love the humming birds,"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 50, "tree_size": 256, "t0": 2.906, "t1": 0.882, "tft": 6.2316, "input_0": 640, "input_1": 257, "min_CLP": -6.17, "draft_iters": 11.4, "mem_use": 48.11, "gen_rate": 7.2, "speed": 1.9, "text": "\"First, I will need to gather mo"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.0, "tree_w": 43, "tree_size": 256, "t0": 3.718, "t1": 0.872, "tft": 4.3023, "input_0": 798, "input_1": 257, "min_CLP": -6.19, "draft_iters": 15.2, "mem_use": 45.7, "gen_rate": 6.6, "speed": 1.44, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 6.33, "t1": 0.89, "tft": 7.5814, "input_0": 993, "input_1": 257, "min_CLP": -6.56, "draft_iters": 32.0, "mem_use": 46.99, "gen_rate": 33.0, "speed": 4.57, "text": "For a vector A in a n dimensiona"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.5, "tree_w": 44, "tree_size": 256, "t0": 3.16, "t1": 0.87, "tft": 4.3418, "input_0": 687, "input_1": 257, "min_CLP": -6.06, "draft_iters": 12.8, "mem_use": 45.56, "gen_rate": 9.2, "speed": 2.29, "text": "The issues with using a symmetri"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 59, "tree_size": 256, "t0": 5.61, "t1": 0.88, "tft": 5.278, "input_0": 855, "input_1": 257, "min_CLP": -6.92, "draft_iters": 32.0, "mem_use": 45.62, "gen_rate": 32.0, "speed": 4.93, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 19.8, "tree_w": 35, "tree_size": 256, "t0": 4.7375, "t1": 0.87, "tft": 5.012, "input_0": 937, "input_1": 257, "min_CLP": -6.02, "draft_iters": 21.0, "mem_use": 45.57, "gen_rate": 11.0, "speed": 1.96, "text": "\"The answer is:\\n\\nL'Hopital's R"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.2, "tree_w": 46, "tree_size": 256, "t0": 3.5, "t1": 0.8775, "tft": 5.2719, "input_0": 768, "input_1": 257, "min_CLP": -6.19, "draft_iters": 13.5, "mem_use": 46.14, "gen_rate": 9.0, "speed": 2.06, "text": "The sum of squared errors (SSE) "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 18, "tree_h": 10.0, "tree_w": 56, "tree_size": 256, "t0": 3.08, "t1": 0.88, "tft": 4.7151, "input_0": 765, "input_1": 257, "min_CLP": -6.35, "draft_iters": 11.3, "mem_use": 46.43, "gen_rate": 6.0, "speed": 1.52, "text": "\"Ride your way to happiness: Hip"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 16.0, "tree_w": 42, "tree_size": 256, "t0": 3.9625, "t1": 0.8775, "tft": 5.028, "input_0": 741, "input_1": 257, "min_CLP": -6.33, "draft_iters": 17.2, "mem_use": 46.22, "gen_rate": 12.0, "speed": 2.48, "text": "The best place to go to in the l"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 62, "tree_size": 256, "t0": 2.738, "t1": 0.868, "tft": 5.819, "input_0": 598, "input_1": 257, "min_CLP": -6.61, "draft_iters": 11.4, "mem_use": 45.56, "gen_rate": 7.0, "speed": 1.94, "text": "1. Being crushed by a giant choc"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 56, "tree_size": 256, "t0": 2.66, "t1": 0.8757, "tft": 5.6653, "input_0": 600, "input_1": 257, "min_CLP": -6.24, "draft_iters": 10.6, "mem_use": 46.12, "gen_rate": 4.9, "speed": 1.37, "text": "In that case, the two dropped eg"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 56, "tree_size": 256, "t0": 2.952, "t1": 0.876, "tft": 4.273, "input_0": 658, "input_1": 257, "min_CLP": -6.36, "draft_iters": 12.6, "mem_use": 45.99, "gen_rate": 6.4, "speed": 1.67, "text": "A person could try to cope with "}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 38, "tree_size": 256, "t0": 4.23, "t1": 0.8975, "tft": 7.5974, "input_0": 951, "input_1": 257, "min_CLP": -5.99, "draft_iters": 17.0, "mem_use": 49.07, "gen_rate": 8.2, "speed": 1.61, "text": "Certainly! Here are some tools y"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 16.3, "tree_w": 31, "tree_size": 256, "t0": 4.7133, "t1": 0.89, "tft": 6.7424, "input_0": 993, "input_1": 257, "min_CLP": -5.63, "draft_iters": 18.3, "mem_use": 47.74, "gen_rate": 13.0, "speed": 2.32, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 17.4, "tree_w": 44, "tree_size": 256, "t0": 4.06, "t1": 0.866, "tft": 6.4271, "input_0": 747, "input_1": 257, "min_CLP": -5.94, "draft_iters": 18.6, "mem_use": 45.52, "gen_rate": 8.4, "speed": 1.7, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 17.2, "tree_w": 71, "tree_size": 256, "t0": 3.9833, "t1": 0.875, "tft": 5.34, "input_0": 778, "input_1": 257, "min_CLP": -6.71, "draft_iters": 18.2, "mem_use": 45.77, "gen_rate": 5.0, "speed": 1.03, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.3, "tree_w": 42, "tree_size": 256, "t0": 3.4333, "t1": 0.9267, "tft": 11.1226, "input_0": 786, "input_1": 257, "min_CLP": -6.09, "draft_iters": 14.3, "mem_use": 52.61, "gen_rate": 10.7, "speed": 2.45, "text": "Certainly! The `_physics_process"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.8, "tree_w": 42, "tree_size": 256, "t0": 3.6417, "t1": 0.8733, "tft": 6.9735, "input_0": 803, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.2, "mem_use": 45.94, "gen_rate": 6.5, "speed": 1.44, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 66, "tree_size": 256, "t0": 5.61, "t1": 0.87, "tft": 4.3431, "input_0": 870, "input_1": 257, "min_CLP": -7.06, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 33.0, "speed": 5.09, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 55, "tree_size": 256, "t0": 3.114, "t1": 0.868, "tft": 4.7867, "input_0": 663, "input_1": 257, "min_CLP": -6.2, "draft_iters": 13.0, "mem_use": 45.65, "gen_rate": 6.8, "speed": 1.71, "text": "The Wyoming statutes, specifical"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.6, "tree_w": 64, "tree_size": 256, "t0": 2.7286, "t1": 0.8843, "tft": 6.2066, "input_0": 615, "input_1": 257, "min_CLP": -6.33, "draft_iters": 11.0, "mem_use": 48.19, "gen_rate": 4.6, "speed": 1.26, "text": "\"You're absolutely right to ques"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 25.0, "tree_w": 23, "tree_size": 256, "t0": 6.59, "t1": 0.88, "tft": 5.5956, "input_0": 1340, "input_1": 257, "min_CLP": -5.65, "draft_iters": 27.0, "mem_use": 46.07, "gen_rate": 20.5, "speed": 2.74, "text": "Yes, there are several top unive"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 18.2, "tree_w": 55, "tree_size": 256, "t0": 3.72, "t1": 0.875, "tft": 4.6278, "input_0": 612, "input_1": 257, "min_CLP": -6.53, "draft_iters": 19.2, "mem_use": 46.26, "gen_rate": 8.5, "speed": 1.85, "text": "[INST] What are the top three mo"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 24.7, "tree_w": 24, "tree_size": 256, "t0": 5.1833, "t1": 0.87, "tft": 6.225, "input_0": 908, "input_1": 257, "min_CLP": -5.7, "draft_iters": 25.7, "mem_use": 45.86, "gen_rate": 11.3, "speed": 1.87, "text": "\"Sure, I'd be happy to explain h"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.2, "tree_w": 48, "tree_size": 256, "t0": 3.024, "t1": 0.874, "tft": 4.7741, "input_0": 605, "input_1": 257, "min_CLP": -6.5, "draft_iters": 13.2, "mem_use": 46.1, "gen_rate": 7.8, "speed": 2.0, "text": "\"Attention bias, the star,\\nFocu"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.3, "tree_w": 60, "tree_size": 256, "t0": 2.9167, "t1": 0.8717, "tft": 5.425, "input_0": 597, "input_1": 257, "min_CLP": -6.36, "draft_iters": 13.5, "mem_use": 45.88, "gen_rate": 5.5, "speed": 1.45, "text": "\"The experiment suggests that th"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.6, "tree_w": 44, "tree_size": 256, "t0": 3.94, "t1": 0.884, "tft": 6.4598, "input_0": 799, "input_1": 257, "min_CLP": -6.21, "draft_iters": 17.0, "mem_use": 47.87, "gen_rate": 6.8, "speed": 1.41, "text": "\"If you're planning on drinking "}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.0, "tree_w": 46, "tree_size": 256, "t0": 4.7633, "t1": 0.8667, "tft": 6.1065, "input_0": 914, "input_1": 257, "min_CLP": -6.47, "draft_iters": 20.3, "mem_use": 45.64, "gen_rate": 10.7, "speed": 1.9, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 58, "tree_size": 256, "t0": 2.8, "t1": 0.87, "tft": 5.0346, "input_0": 604, "input_1": 257, "min_CLP": -6.36, "draft_iters": 11.8, "mem_use": 45.66, "gen_rate": 8.2, "speed": 2.25, "text": "Of course! I can speak and under"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 49, "tree_size": 256, "t0": 3.8375, "t1": 0.87, "tft": 4.5971, "input_0": 894, "input_1": 257, "min_CLP": -6.24, "draft_iters": 15.8, "mem_use": 45.63, "gen_rate": 8.5, "speed": 1.81, "text": "F-centers, or Friedel centers, a"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 19, "tree_h": 15.0, "tree_w": 49, "tree_size": 256, "t0": 3.95, "t1": 0.91, "tft": 8.3179, "input_0": 943, "input_1": 257, "min_CLP": -6.53, "draft_iters": 16.0, "mem_use": 50.2, "gen_rate": 9.5, "speed": 1.95, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 18.3, "tree_w": 46, "tree_size": 256, "t0": 4.3567, "t1": 0.88, "tft": 6.9613, "input_0": 913, "input_1": 257, "min_CLP": -6.03, "draft_iters": 20.0, "mem_use": 47.28, "gen_rate": 13.0, "speed": 2.48, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 69, "tree_size": 256, "t0": 2.41, "t1": 0.875, "tft": 4.077, "input_0": 583, "input_1": 257, "min_CLP": -6.36, "draft_iters": 9.3, "mem_use": 46.07, "gen_rate": 5.7, "speed": 1.72, "text": "I think AI assistants will never"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.6, "tree_w": 40, "tree_size": 256, "t0": 4.06, "t1": 0.884, "tft": 7.3296, "input_0": 903, "input_1": 257, "min_CLP": -6.1, "draft_iters": 16.0, "mem_use": 47.98, "gen_rate": 6.4, "speed": 1.29, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 14.5, "tree_w": 42, "tree_size": 256, "t0": 4.085, "t1": 0.8875, "tft": 7.3738, "input_0": 916, "input_1": 257, "min_CLP": -6.24, "draft_iters": 15.8, "mem_use": 47.94, "gen_rate": 10.5, "speed": 2.11, "text": "In Deutschland wird die Zementpr"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 48, "tree_size": 256, "t0": 3.088, "t1": 0.886, "tft": 6.9862, "input_0": 674, "input_1": 257, "min_CLP": -6.09, "draft_iters": 12.8, "mem_use": 47.29, "gen_rate": 6.8, "speed": 1.71, "text": "Im sorry, but I cannot provide i"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.0, "tree_w": 53, "tree_size": 256, "t0": 3.01, "t1": 0.878, "tft": 4.453, "input_0": 660, "input_1": 257, "min_CLP": -6.33, "draft_iters": 11.6, "mem_use": 46.31, "gen_rate": 7.2, "speed": 1.85, "text": "If you are able to find the orig"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 23.5, "tree_w": 49, "tree_size": 256, "t0": 5.035, "t1": 0.875, "tft": 3.9913, "input_0": 881, "input_1": 257, "min_CLP": -6.72, "draft_iters": 24.0, "mem_use": 45.9, "gen_rate": 20.0, "speed": 3.38, "text": "\u4f60\u53ef\u80fd\u9700\u8981\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n- Vaswani, Ashish,"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 7.29, "t1": 0.87, "tft": 6.8506, "input_0": 1478, "input_1": 257, "min_CLP": -6.04, "draft_iters": 32.0, "mem_use": 45.7, "gen_rate": 33.0, "speed": 4.04, "text": "\"Sure, here's a function in Java"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 18.8, "tree_w": 44, "tree_size": 256, "t0": 4.2, "t1": 0.88, "tft": 6.1924, "input_0": 776, "input_1": 257, "min_CLP": -5.92, "draft_iters": 19.8, "mem_use": 46.99, "gen_rate": 9.2, "speed": 1.82, "text": "It is illegal to be naked in pub"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 53, "tree_size": 256, "t0": 3.112, "t1": 0.88, "tft": 4.4096, "input_0": 725, "input_1": 257, "min_CLP": -6.23, "draft_iters": 12.0, "mem_use": 46.1, "gen_rate": 6.6, "speed": 1.65, "text": "\"You're welcome! Here are a few "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 48, "tree_size": 256, "t0": 3.6625, "t1": 0.885, "tft": 6.0187, "input_0": 759, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.2, "mem_use": 46.98, "gen_rate": 8.0, "speed": 1.76, "text": "The optimal thickness for mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.0, "tree_w": 45, "tree_size": 256, "t0": 4.045, "t1": 0.8775, "tft": 6.9707, "input_0": 810, "input_1": 257, "min_CLP": -6.23, "draft_iters": 18.0, "mem_use": 46.36, "gen_rate": 9.5, "speed": 1.93, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 62, "tree_size": 256, "t0": 3.064, "t1": 0.874, "tft": 6.8313, "input_0": 697, "input_1": 257, "min_CLP": -6.57, "draft_iters": 11.4, "mem_use": 45.63, "gen_rate": 6.8, "speed": 1.73, "text": "\"Sure, here's a list of nickname"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.0, "tree_w": 42, "tree_size": 256, "t0": 4.52, "t1": 0.88, "tft": 7.2295, "input_0": 961, "input_1": 257, "min_CLP": -6.01, "draft_iters": 18.8, "mem_use": 46.03, "gen_rate": 9.0, "speed": 1.67, "text": "\"Yes, the Balfour Declaration wa"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 6.05, "t1": 0.87, "tft": 6.95, "input_0": 927, "input_1": 257, "min_CLP": -5.62, "draft_iters": 32.0, "mem_use": 46.79, "gen_rate": 33.0, "speed": 4.77, "text": "\"Canciones felices: \\n1. \u00ab(I Can"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 31.7, "tree_w": 31, "tree_size": 256, "t0": 6.4033, "t1": 0.8733, "tft": 6.6489, "input_0": 1061, "input_1": 257, "min_CLP": -7.92, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 19.0, "speed": 2.61, "text": "<|endoftext|>[INST] <<SYS>>\\nYou"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 256, "t0": 6.66, "t1": 0.88, "tft": 7.2775, "input_0": 1126, "input_1": 257, "min_CLP": -7.37, "draft_iters": 32.0, "mem_use": 46.12, "gen_rate": 33.0, "speed": 4.38, "text": "````\\n```markdown\\n# This is a T"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 58, "tree_size": 256, "t0": 2.928, "t1": 0.88, "tft": 4.9306, "input_0": 617, "input_1": 257, "min_CLP": -6.48, "draft_iters": 12.8, "mem_use": 46.49, "gen_rate": 7.0, "speed": 1.84, "text": "How about, \"A wish from the hear"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 18.7, "tree_w": 32, "tree_size": 256, "t0": 4.5, "t1": 0.8867, "tft": 7.382, "input_0": 874, "input_1": 257, "min_CLP": -5.8, "draft_iters": 19.7, "mem_use": 47.26, "gen_rate": 15.0, "speed": 2.79, "text": "To build a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.0, "tree_w": 41, "tree_size": 256, "t0": 4.1567, "t1": 0.8767, "tft": 5.4913, "input_0": 896, "input_1": 257, "min_CLP": -5.96, "draft_iters": 16.0, "mem_use": 45.73, "gen_rate": 11.0, "speed": 2.19, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 55, "tree_size": 256, "t0": 3.5275, "t1": 0.8675, "tft": 6.2967, "input_0": 787, "input_1": 257, "min_CLP": -6.2, "draft_iters": 14.8, "mem_use": 45.65, "gen_rate": 8.5, "speed": 1.93, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 18.2, "tree_w": 33, "tree_size": 256, "t0": 4.54, "t1": 0.9025, "tft": 7.3821, "input_0": 910, "input_1": 257, "min_CLP": -6.14, "draft_iters": 19.5, "mem_use": 49.79, "gen_rate": 9.8, "speed": 1.79, "text": "- Discovery:\\n  * Identify a mar"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.0, "tree_w": 36, "tree_size": 256, "t0": 4.14, "t1": 0.8667, "tft": 6.4338, "input_0": 728, "input_1": 257, "min_CLP": -5.88, "draft_iters": 20.3, "mem_use": 45.55, "gen_rate": 11.3, "speed": 2.26, "text": "\"Answer: The many-worlds interpr"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.7, "tree_w": 40, "tree_size": 256, "t0": 3.6567, "t1": 0.8633, "tft": 5.812, "input_0": 783, "input_1": 257, "min_CLP": -5.97, "draft_iters": 14.7, "mem_use": 45.51, "gen_rate": 12.0, "speed": 2.66, "text": "\"To build a PC, you'll need to f"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 13.0, "tree_w": 59, "tree_size": 256, "t0": 3.29, "t1": 0.9, "tft": 9.4037, "input_0": 868, "input_1": 257, "min_CLP": -6.92, "draft_iters": 14.0, "mem_use": 49.78, "gen_rate": 3.0, "speed": 0.71, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 52, "tree_size": 256, "t0": 3.482, "t1": 0.89, "tft": 5.5249, "input_0": 785, "input_1": 257, "min_CLP": -6.27, "draft_iters": 14.4, "mem_use": 47.58, "gen_rate": 6.8, "speed": 1.56, "text": "\"\u2022 Keep the habit a priority. Do"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 61, "tree_size": 256, "t0": 3.38, "t1": 0.88, "tft": 5.1273, "input_0": 718, "input_1": 257, "min_CLP": -6.27, "draft_iters": 14.0, "mem_use": 46.83, "gen_rate": 11.3, "speed": 2.66, "text": "\"This is a good point, and you'r"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 52, "tree_size": 256, "t0": 3.6775, "t1": 0.875, "tft": 4.428, "input_0": 890, "input_1": 257, "min_CLP": -6.23, "draft_iters": 14.0, "mem_use": 45.7, "gen_rate": 8.8, "speed": 1.92, "text": "Sure, here are some important hi"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 56, "tree_size": 256, "t0": 3.7633, "t1": 0.87, "tft": 5.1801, "input_0": 837, "input_1": 257, "min_CLP": -6.13, "draft_iters": 14.3, "mem_use": 45.72, "gen_rate": 10.7, "speed": 2.3, "text": "In the context of the turn-based"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 19.0, "tree_w": 35, "tree_size": 256, "t0": 5.065, "t1": 0.88, "tft": 7.2718, "input_0": 952, "input_1": 257, "min_CLP": -6.07, "draft_iters": 20.0, "mem_use": 46.55, "gen_rate": 8.0, "speed": 1.35, "text": "[API_REQUEST]: curl \"https://wor"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 30.5, "tree_w": 16, "tree_size": 256, "t0": 5.915, "t1": 0.88, "tft": 6.7554, "input_0": 924, "input_1": 257, "min_CLP": -5.36, "draft_iters": 31.0, "mem_use": 47.08, "gen_rate": 20.0, "speed": 2.94, "text": "Here is a simpler version of the"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 16.0, "tree_w": 37, "tree_size": 256, "t0": 4.92, "t1": 0.87, "tft": 6.6172, "input_0": 1107, "input_1": 257, "min_CLP": -5.88, "draft_iters": 18.0, "mem_use": 46.5, "gen_rate": 11.0, "speed": 1.9, "text": "\"Hello! How can I assist you tod"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 67, "tree_size": 256, "t0": 2.485, "t1": 0.8783, "tft": 7.2339, "input_0": 586, "input_1": 257, "min_CLP": -6.53, "draft_iters": 9.2, "mem_use": 46.6, "gen_rate": 5.3, "speed": 1.59, "text": "\"In your eyes, I see the ocean's"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 42, "tree_size": 256, "t0": 3.7625, "t1": 0.87, "tft": 5.0754, "input_0": 788, "input_1": 257, "min_CLP": -6.02, "draft_iters": 16.0, "mem_use": 46.0, "gen_rate": 8.0, "speed": 1.73, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.0, "tree_w": 43, "tree_size": 256, "t0": 3.66, "t1": 0.872, "tft": 6.0355, "input_0": 837, "input_1": 257, "min_CLP": -6.07, "draft_iters": 14.4, "mem_use": 45.96, "gen_rate": 8.0, "speed": 1.77, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.2, "tree_w": 33, "tree_size": 256, "t0": 4.345, "t1": 0.8825, "tft": 5.7981, "input_0": 857, "input_1": 257, "min_CLP": -6.12, "draft_iters": 18.8, "mem_use": 47.29, "gen_rate": 9.5, "speed": 1.82, "text": "You\\'re welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 14.5, "tree_w": 39, "tree_size": 256, "t0": 4.01, "t1": 0.885, "tft": 6.2152, "input_0": 888, "input_1": 257, "min_CLP": -5.98, "draft_iters": 16.0, "mem_use": 47.21, "gen_rate": 10.2, "speed": 2.09, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 24, "tree_h": 18.0, "tree_w": 35, "tree_size": 256, "t0": 5.105, "t1": 0.885, "tft": 8.3981, "input_0": 1112, "input_1": 257, "min_CLP": -6.02, "draft_iters": 20.0, "mem_use": 48.68, "gen_rate": 12.0, "speed": 2.0, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 27, "tree_h": 20.0, "tree_w": 41, "tree_size": 256, "t0": 4.436, "t1": 0.872, "tft": 5.8164, "input_0": 809, "input_1": 257, "min_CLP": -5.93, "draft_iters": 21.2, "mem_use": 45.51, "gen_rate": 5.4, "speed": 1.02, "text": "The President of Germany is curr"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 11.2, "tree_w": 59, "tree_size": 256, "t0": 2.89, "t1": 0.8762, "tft": 5.2944, "input_0": 623, "input_1": 257, "min_CLP": -6.42, "draft_iters": 12.5, "mem_use": 46.44, "gen_rate": 4.9, "speed": 1.29, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 20.0, "tree_w": 60, "tree_size": 256, "t0": 4.5625, "t1": 0.89, "tft": 6.8999, "input_0": 918, "input_1": 257, "min_CLP": -6.76, "draft_iters": 20.8, "mem_use": 48.33, "gen_rate": 9.0, "speed": 1.65, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.0, "tree_w": 43, "tree_size": 256, "t0": 4.0575, "t1": 0.8775, "tft": 4.651, "input_0": 865, "input_1": 257, "min_CLP": -6.2, "draft_iters": 17.5, "mem_use": 46.03, "gen_rate": 9.5, "speed": 1.93, "text": "- Introduction: What is the cont"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 18.0, "tree_w": 44, "tree_size": 256, "t0": 4.77, "t1": 0.88, "tft": 8.2064, "input_0": 954, "input_1": 257, "min_CLP": -6.07, "draft_iters": 19.7, "mem_use": 46.89, "gen_rate": 7.3, "speed": 1.3, "text": "I apologize for any confusion. H"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 256, "max_branch_width": 32, "gen_rate": 11.95, "gen_rate_micro": 9.3, "gen_speed": 2.248, "gen_speed_micro": 2.012, "t0": 4.1217, "t1": 0.8794, "input_0": 811.8, "input_1": 257.0, "tree_size": 256.0, "tree_w": 44.6, "tree_h": 17.2, "prompt_len": 298.0, "min_CLP": -6.31, "mem_use": 54.99, "exp_time": 12828.75}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 263, "tree_size": 512, "t0": 2.51, "t1": 1.4133, "tft": 3.0459, "input_0": 1351, "input_1": 513, "min_CLP": -9.73, "draft_iters": 8.5, "mem_use": 47.01, "gen_rate": 5.3, "speed": 1.36, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 294, "tree_size": 512, "t0": 1.495, "t1": 1.4312, "tft": 4.6303, "input_0": 865, "input_1": 513, "min_CLP": -10.28, "draft_iters": 5.0, "mem_use": 48.55, "gen_rate": 4.0, "speed": 1.37, "text": "You are correct, my apologies fo"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 148, "tree_size": 512, "t0": 3.786, "t1": 1.434, "tft": 4.4807, "input_0": 1320, "input_1": 513, "min_CLP": -7.34, "draft_iters": 13.8, "mem_use": 49.45, "gen_rate": 6.4, "speed": 1.23, "text": "1. Minecraft: Minecraft is a gam"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 8.0, "tree_w": 266, "tree_size": 512, "t0": 3.046, "t1": 1.416, "tft": 3.4601, "input_0": 1241, "input_1": 513, "min_CLP": -11.51, "draft_iters": 10.4, "mem_use": 47.18, "gen_rate": 9.0, "speed": 2.02, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 237, "tree_size": 512, "t0": 2.46, "t1": 1.4114, "tft": 3.0763, "input_0": 1100, "input_1": 513, "min_CLP": -9.56, "draft_iters": 8.3, "mem_use": 47.02, "gen_rate": 4.9, "speed": 1.25, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.5, "tree_w": 279, "tree_size": 512, "t0": 2.305, "t1": 1.4433, "tft": 4.9157, "input_0": 1088, "input_1": 513, "min_CLP": -12.12, "draft_iters": 7.7, "mem_use": 49.58, "gen_rate": 5.5, "speed": 1.47, "text": "Here\\'s a potential bullet list "}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 140, "tree_size": 512, "t0": 4.9533, "t1": 1.44, "tft": 5.6122, "input_0": 1661, "input_1": 513, "min_CLP": -8.18, "draft_iters": 16.7, "mem_use": 50.17, "gen_rate": 10.7, "speed": 1.67, "text": "There are a few other options th"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.4, "tree_w": 212, "tree_size": 512, "t0": 3.214, "t1": 1.474, "tft": 7.3489, "input_0": 1359, "input_1": 513, "min_CLP": -10.0, "draft_iters": 10.8, "mem_use": 52.35, "gen_rate": 6.6, "speed": 1.41, "text": "\"Let's dive deeper into social m"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.9, "tree_w": 242, "tree_size": 512, "t0": 2.7214, "t1": 1.4457, "tft": 5.2518, "input_0": 1077, "input_1": 513, "min_CLP": -9.41, "draft_iters": 10.1, "mem_use": 49.78, "gen_rate": 5.3, "speed": 1.27, "text": "I apologize for the confusion ea"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 206, "tree_size": 512, "t0": 3.518, "t1": 1.436, "tft": 4.5657, "input_0": 1477, "input_1": 513, "min_CLP": -9.47, "draft_iters": 11.6, "mem_use": 49.15, "gen_rate": 6.4, "speed": 1.29, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 53, "tree_h": 6.9, "tree_w": 261, "tree_size": 512, "t0": 2.4829, "t1": 1.4229, "tft": 3.8311, "input_0": 1039, "input_1": 513, "min_CLP": -11.01, "draft_iters": 8.9, "mem_use": 47.68, "gen_rate": 7.6, "speed": 1.94, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 218, "tree_size": 512, "t0": 3.72, "t1": 1.438, "tft": 4.901, "input_0": 1516, "input_1": 513, "min_CLP": -12.11, "draft_iters": 12.8, "mem_use": 49.52, "gen_rate": 7.2, "speed": 1.4, "text": "Here is a shorter summary:\\n\\nIn"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 14.5, "tree_w": 185, "tree_size": 512, "t0": 5.1, "t1": 1.4275, "tft": 4.7263, "input_0": 1851, "input_1": 513, "min_CLP": -9.32, "draft_iters": 17.0, "mem_use": 48.74, "gen_rate": 12.0, "speed": 1.84, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 3.0, "tree_w": 346, "tree_size": 512, "t0": 1.48, "t1": 1.41, "tft": 3.0418, "input_0": 858, "input_1": 513, "min_CLP": -10.25, "draft_iters": 5.0, "mem_use": 47.01, "gen_rate": 3.0, "speed": 1.04, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 4.8, "tree_w": 268, "tree_size": 512, "t0": 2.0133, "t1": 1.45, "tft": 5.603, "input_0": 1006, "input_1": 513, "min_CLP": -8.42, "draft_iters": 7.0, "mem_use": 50.15, "gen_rate": 5.3, "speed": 1.54, "text": "\"While it's important to maintai"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 298, "tree_size": 512, "t0": 1.5413, "t1": 1.4212, "tft": 3.5149, "input_0": 869, "input_1": 513, "min_CLP": -11.92, "draft_iters": 5.1, "mem_use": 47.35, "gen_rate": 4.1, "speed": 1.39, "text": "The minimum broadband upload spe"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 230, "tree_size": 512, "t0": 3.0925, "t1": 1.4125, "tft": 3.0646, "input_0": 1192, "input_1": 513, "min_CLP": -11.75, "draft_iters": 11.5, "mem_use": 47.02, "gen_rate": 9.8, "speed": 2.16, "text": "\"Sure! Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 189, "tree_size": 512, "t0": 4.58, "t1": 1.41, "tft": 3.0482, "input_0": 1530, "input_1": 513, "min_CLP": -11.92, "draft_iters": 18.0, "mem_use": 47.0, "gen_rate": 17.5, "speed": 2.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 6.8, "tree_w": 240, "tree_size": 512, "t0": 2.7383, "t1": 1.4167, "tft": 3.7652, "input_0": 1130, "input_1": 513, "min_CLP": -8.99, "draft_iters": 9.5, "mem_use": 47.54, "gen_rate": 6.3, "speed": 1.52, "text": "D-theanine has similar effects t"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 10.2, "tree_w": 220, "tree_size": 512, "t0": 3.6383, "t1": 1.4117, "tft": 3.0741, "input_0": 1452, "input_1": 513, "min_CLP": -10.64, "draft_iters": 12.5, "mem_use": 47.02, "gen_rate": 7.5, "speed": 1.48, "text": "The Balfour Declaration is a sta"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.8, "tree_w": 240, "tree_size": 512, "t0": 2.0644, "t1": 1.4211, "tft": 4.0726, "input_0": 951, "input_1": 513, "min_CLP": -8.46, "draft_iters": 7.0, "mem_use": 47.86, "gen_rate": 3.8, "speed": 1.08, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 21, "tree_h": 3.4, "tree_w": 301, "tree_size": 512, "t0": 1.65, "t1": 1.412, "tft": 3.0532, "input_0": 992, "input_1": 513, "min_CLP": -10.12, "draft_iters": 5.4, "mem_use": 47.01, "gen_rate": 4.2, "speed": 1.37, "text": "\"Hello there, Obi-Wan Kenobi! It"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.2, "tree_w": 189, "tree_size": 512, "t0": 4.315, "t1": 1.44, "tft": 4.8722, "input_0": 1795, "input_1": 513, "min_CLP": -12.08, "draft_iters": 14.0, "mem_use": 49.36, "gen_rate": 8.8, "speed": 1.52, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.3, "tree_w": 66, "tree_size": 512, "t0": 6.1567, "t1": 1.41, "tft": 3.4512, "input_0": 1969, "input_1": 513, "min_CLP": -6.67, "draft_iters": 21.7, "mem_use": 47.08, "gen_rate": 13.3, "speed": 1.76, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.8, "tree_w": 197, "tree_size": 512, "t0": 4.464, "t1": 1.424, "tft": 4.2147, "input_0": 1561, "input_1": 513, "min_CLP": -8.65, "draft_iters": 15.0, "mem_use": 48.05, "gen_rate": 8.2, "speed": 1.39, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 233, "tree_size": 512, "t0": 3.55, "t1": 1.4133, "tft": 3.1048, "input_0": 1237, "input_1": 513, "min_CLP": -12.23, "draft_iters": 14.0, "mem_use": 47.05, "gen_rate": 12.7, "speed": 2.55, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.4, "tree_w": 221, "tree_size": 512, "t0": 3.342, "t1": 1.418, "tft": 3.8002, "input_0": 1421, "input_1": 513, "min_CLP": -8.95, "draft_iters": 11.2, "mem_use": 47.72, "gen_rate": 6.6, "speed": 1.39, "text": "Austenite is an allotrope of iro"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 3.5, "tree_w": 311, "tree_size": 512, "t0": 1.64, "t1": 1.4183, "tft": 3.754, "input_0": 1022, "input_1": 513, "min_CLP": -11.55, "draft_iters": 5.3, "mem_use": 47.57, "gen_rate": 4.0, "speed": 1.31, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 4.4, "tree_w": 267, "tree_size": 512, "t0": 1.8625, "t1": 1.4375, "tft": 4.9078, "input_0": 942, "input_1": 513, "min_CLP": -8.44, "draft_iters": 6.4, "mem_use": 49.51, "gen_rate": 5.0, "speed": 1.51, "text": "\"Verse 1:\\nIn the land of Tamrie"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 248, "tree_size": 512, "t0": 2.5186, "t1": 1.4129, "tft": 3.0924, "input_0": 1254, "input_1": 513, "min_CLP": -9.33, "draft_iters": 8.4, "mem_use": 47.06, "gen_rate": 4.7, "speed": 1.2, "text": "Sure, there are many delicious r"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.2, "tree_w": 305, "tree_size": 512, "t0": 1.5956, "t1": 1.4267, "tft": 3.8438, "input_0": 920, "input_1": 513, "min_CLP": -10.68, "draft_iters": 5.2, "mem_use": 47.76, "gen_rate": 3.9, "speed": 1.29, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.2, "tree_w": 237, "tree_size": 512, "t0": 2.494, "t1": 1.428, "tft": 4.2811, "input_0": 1053, "input_1": 513, "min_CLP": -9.28, "draft_iters": 9.4, "mem_use": 48.17, "gen_rate": 6.6, "speed": 1.68, "text": "[API_REQUEST]: {curl -X POST -H "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.2, "tree_w": 220, "tree_size": 512, "t0": 2.5662, "t1": 1.4175, "tft": 3.7181, "input_0": 1110, "input_1": 513, "min_CLP": -7.94, "draft_iters": 8.9, "mem_use": 47.52, "gen_rate": 5.1, "speed": 1.29, "text": "Freyja, goddess of love, fertili"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.5, "tree_w": 232, "tree_size": 512, "t0": 2.5617, "t1": 1.44, "tft": 4.5607, "input_0": 1079, "input_1": 513, "min_CLP": -8.36, "draft_iters": 9.0, "mem_use": 49.17, "gen_rate": 5.5, "speed": 1.38, "text": "\"Yes, there are several good sub"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.0, "tree_w": 182, "tree_size": 512, "t0": 3.62, "t1": 1.436, "tft": 4.5854, "input_0": 1428, "input_1": 513, "min_CLP": -8.01, "draft_iters": 12.6, "mem_use": 49.21, "gen_rate": 8.4, "speed": 1.66, "text": "When choosing an ISP package, yo"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 208, "tree_size": 512, "t0": 3.594, "t1": 1.464, "tft": 7.1901, "input_0": 1352, "input_1": 513, "min_CLP": -11.93, "draft_iters": 12.0, "mem_use": 51.94, "gen_rate": 6.4, "speed": 1.27, "text": "Selenium can be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 178, "tree_size": 512, "t0": 4.074, "t1": 1.414, "tft": 3.1076, "input_0": 1444, "input_1": 513, "min_CLP": -8.52, "draft_iters": 14.0, "mem_use": 47.04, "gen_rate": 6.6, "speed": 1.2, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.5, "tree_w": 254, "tree_size": 512, "t0": 2.335, "t1": 1.4167, "tft": 3.7523, "input_0": 939, "input_1": 513, "min_CLP": -10.49, "draft_iters": 9.5, "mem_use": 47.57, "gen_rate": 8.3, "speed": 2.22, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 216, "tree_size": 512, "t0": 3.266, "t1": 1.444, "tft": 5.2274, "input_0": 1434, "input_1": 513, "min_CLP": -8.23, "draft_iters": 11.6, "mem_use": 49.94, "gen_rate": 6.4, "speed": 1.36, "text": "Yes, I can certainly act like I "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.0, "tree_w": 182, "tree_size": 512, "t0": 4.745, "t1": 1.4275, "tft": 4.2189, "input_0": 1791, "input_1": 513, "min_CLP": -8.36, "draft_iters": 16.2, "mem_use": 47.98, "gen_rate": 9.5, "speed": 1.54, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 6.0, "tree_w": 221, "tree_size": 512, "t0": 2.5529, "t1": 1.4157, "tft": 3.4696, "input_0": 1167, "input_1": 513, "min_CLP": -7.93, "draft_iters": 8.3, "mem_use": 47.27, "gen_rate": 5.7, "speed": 1.44, "text": "I am no mere mortal to be comman"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 172, "tree_size": 512, "t0": 4.115, "t1": 1.435, "tft": 5.2418, "input_0": 1178, "input_1": 513, "min_CLP": -9.93, "draft_iters": 18.5, "mem_use": 49.77, "gen_rate": 17.5, "speed": 3.15, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 275, "tree_size": 512, "t0": 1.4925, "t1": 1.4587, "tft": 5.6171, "input_0": 787, "input_1": 513, "min_CLP": -10.61, "draft_iters": 5.0, "mem_use": 50.2, "gen_rate": 4.0, "speed": 1.36, "text": "[INST] AI assistant. I am lookin"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.6, "tree_w": 216, "tree_size": 512, "t0": 3.348, "t1": 1.432, "tft": 4.6212, "input_0": 1376, "input_1": 513, "min_CLP": -11.61, "draft_iters": 11.2, "mem_use": 48.54, "gen_rate": 8.2, "speed": 1.72, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 203, "tree_size": 512, "t0": 3.24, "t1": 1.4233, "tft": 9.8594, "input_0": 1216, "input_1": 513, "min_CLP": -7.77, "draft_iters": 12.0, "mem_use": 47.82, "gen_rate": 5.5, "speed": 1.18, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 56, "tree_h": 6.1, "tree_w": 256, "tree_size": 512, "t0": 2.1287, "t1": 1.4163, "tft": 3.698, "input_0": 999, "input_1": 513, "min_CLP": -9.05, "draft_iters": 8.1, "mem_use": 47.54, "gen_rate": 7.0, "speed": 1.97, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 272, "tree_size": 512, "t0": 2.2667, "t1": 1.4133, "tft": 3.0762, "input_0": 1104, "input_1": 513, "min_CLP": -10.34, "draft_iters": 7.3, "mem_use": 47.04, "gen_rate": 5.3, "speed": 1.45, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.2, "tree_w": 193, "tree_size": 512, "t0": 4.0325, "t1": 1.4825, "tft": 7.8274, "input_0": 1351, "input_1": 513, "min_CLP": -8.82, "draft_iters": 16.8, "mem_use": 52.5, "gen_rate": 8.5, "speed": 1.54, "text": "[The scene opens with a Spartan "}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.3, "tree_w": 276, "tree_size": 512, "t0": 1.96, "t1": 1.4357, "tft": 4.747, "input_0": 970, "input_1": 513, "min_CLP": -8.42, "draft_iters": 6.6, "mem_use": 48.79, "gen_rate": 4.7, "speed": 1.39, "text": "The truth is this, Agent. The Vo"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 3.0, "tree_w": 286, "tree_size": 512, "t0": 1.4967, "t1": 1.43, "tft": 3.8515, "input_0": 803, "input_1": 513, "min_CLP": -8.3, "draft_iters": 5.0, "mem_use": 47.81, "gen_rate": 3.7, "speed": 1.25, "text": "Thank you for your understanding"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 6.0, "tree_w": 206, "tree_size": 512, "t0": 2.9, "t1": 1.41, "tft": 3.4995, "input_0": 1285, "input_1": 513, "min_CLP": -11.48, "draft_iters": 9.0, "mem_use": 47.32, "gen_rate": 4.5, "speed": 1.04, "text": "CTR\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u91cd\u8981\u4e3b\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 260, "tree_size": 512, "t0": 2.4483, "t1": 1.44, "tft": 4.5835, "input_0": 963, "input_1": 513, "min_CLP": -9.13, "draft_iters": 9.5, "mem_use": 49.21, "gen_rate": 8.5, "speed": 2.19, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 4.4, "tree_w": 265, "tree_size": 512, "t0": 1.9533, "t1": 1.4344, "tft": 4.1892, "input_0": 961, "input_1": 513, "min_CLP": -10.41, "draft_iters": 6.4, "mem_use": 48.42, "gen_rate": 4.4, "speed": 1.31, "text": "Certainly! Here are some more hi"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.2, "tree_w": 128, "tree_size": 512, "t0": 5.4625, "t1": 1.435, "tft": 4.328, "input_0": 1820, "input_1": 513, "min_CLP": -7.34, "draft_iters": 18.8, "mem_use": 48.76, "gen_rate": 8.8, "speed": 1.27, "text": "Thank you for your question. Yes"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.5, "tree_w": 224, "tree_size": 512, "t0": 2.5117, "t1": 1.415, "tft": 3.4833, "input_0": 1110, "input_1": 513, "min_CLP": -8.38, "draft_iters": 8.0, "mem_use": 47.21, "gen_rate": 5.3, "speed": 1.36, "text": "In real life, people of all ages"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 5.7, "tree_w": 238, "tree_size": 512, "t0": 2.3414, "t1": 1.4429, "tft": 5.0519, "input_0": 997, "input_1": 513, "min_CLP": -8.22, "draft_iters": 8.0, "mem_use": 49.62, "gen_rate": 5.6, "speed": 1.47, "text": "\"Title: FullView.io - Transformi"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 254, "tree_size": 512, "t0": 2.3814, "t1": 1.4571, "tft": 6.5196, "input_0": 1071, "input_1": 513, "min_CLP": -8.34, "draft_iters": 9.3, "mem_use": 50.87, "gen_rate": 5.1, "speed": 1.34, "text": "My apologies for the confusion, "}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 5.8, "tree_w": 263, "tree_size": 512, "t0": 2.1963, "t1": 1.4625, "tft": 6.5553, "input_0": 1092, "input_1": 513, "min_CLP": -10.3, "draft_iters": 7.8, "mem_use": 51.04, "gen_rate": 4.9, "speed": 1.33, "text": "As a beginner, Keras is indeed a"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 12.1, "tree_w": 201, "tree_size": 512, "t0": 3.83, "t1": 1.4371, "tft": 4.7087, "input_0": 1345, "input_1": 513, "min_CLP": -10.68, "draft_iters": 14.4, "mem_use": 48.69, "gen_rate": 5.7, "speed": 1.08, "text": "As an open source alternative to"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.8, "tree_w": 236, "tree_size": 512, "t0": 2.6283, "t1": 1.41, "tft": 3.0772, "input_0": 1118, "input_1": 513, "min_CLP": -9.39, "draft_iters": 9.2, "mem_use": 47.03, "gen_rate": 6.0, "speed": 1.49, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 13.0, "tree_w": 190, "tree_size": 512, "t0": 4.035, "t1": 1.4383, "tft": 4.8909, "input_0": 1354, "input_1": 513, "min_CLP": -9.27, "draft_iters": 15.3, "mem_use": 49.45, "gen_rate": 7.2, "speed": 1.31, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 219, "tree_size": 512, "t0": 3.192, "t1": 1.456, "tft": 5.6182, "input_0": 1478, "input_1": 513, "min_CLP": -9.49, "draft_iters": 10.4, "mem_use": 50.29, "gen_rate": 6.4, "speed": 1.38, "text": "[The general leads his army forw"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.8, "tree_w": 269, "tree_size": 512, "t0": 1.8125, "t1": 1.4287, "tft": 4.204, "input_0": 891, "input_1": 513, "min_CLP": -8.13, "draft_iters": 6.0, "mem_use": 47.98, "gen_rate": 4.4, "speed": 1.35, "text": "Got it! Here\\'s another one: \"To"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.5, "tree_w": 238, "tree_size": 512, "t0": 2.6567, "t1": 1.4233, "tft": 3.831, "input_0": 1197, "input_1": 513, "min_CLP": -8.92, "draft_iters": 8.8, "mem_use": 47.7, "gen_rate": 5.5, "speed": 1.35, "text": "\"The proof-of-stake model works "}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 5.0, "tree_w": 255, "tree_size": 512, "t0": 2.2829, "t1": 1.4271, "tft": 4.0889, "input_0": 1172, "input_1": 513, "min_CLP": -9.04, "draft_iters": 7.3, "mem_use": 47.83, "gen_rate": 5.7, "speed": 1.54, "text": "\"The world was in a very tense s"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 209, "tree_size": 512, "t0": 3.338, "t1": 1.448, "tft": 4.8372, "input_0": 1371, "input_1": 513, "min_CLP": -8.89, "draft_iters": 10.6, "mem_use": 49.9, "gen_rate": 6.4, "speed": 1.34, "text": "\"A void pointer is a type of poi"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.5, "tree_w": 284, "tree_size": 512, "t0": 1.9813, "t1": 1.4537, "tft": 5.5854, "input_0": 1003, "input_1": 513, "min_CLP": -9.14, "draft_iters": 6.6, "mem_use": 50.41, "gen_rate": 4.1, "speed": 1.2, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 16.0, "tree_w": 131, "tree_size": 512, "t0": 5.4433, "t1": 1.4267, "tft": 5.0583, "input_0": 1888, "input_1": 513, "min_CLP": -8.67, "draft_iters": 19.0, "mem_use": 49.62, "gen_rate": 13.3, "speed": 1.94, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.6, "tree_w": 283, "tree_size": 512, "t0": 1.7814, "t1": 1.4186, "tft": 3.7167, "input_0": 1017, "input_1": 513, "min_CLP": -9.55, "draft_iters": 5.7, "mem_use": 47.45, "gen_rate": 4.6, "speed": 1.43, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 235, "tree_size": 512, "t0": 2.925, "t1": 1.41, "tft": 3.0775, "input_0": 1293, "input_1": 513, "min_CLP": -10.09, "draft_iters": 10.3, "mem_use": 47.03, "gen_rate": 5.7, "speed": 1.31, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 235, "tree_size": 512, "t0": 4.3033, "t1": 1.45, "tft": 4.8485, "input_0": 1557, "input_1": 513, "min_CLP": -10.02, "draft_iters": 14.0, "mem_use": 49.86, "gen_rate": 12.3, "speed": 2.14, "text": "Certainly! Here is the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.5, "tree_w": 275, "tree_size": 512, "t0": 2.0063, "t1": 1.4163, "tft": 3.0853, "input_0": 980, "input_1": 513, "min_CLP": -8.64, "draft_iters": 6.6, "mem_use": 46.98, "gen_rate": 4.5, "speed": 1.31, "text": "The person who made Berlin is th"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 176, "tree_size": 512, "t0": 4.22, "t1": 1.435, "tft": 4.637, "input_0": 1291, "input_1": 513, "min_CLP": -8.54, "draft_iters": 18.5, "mem_use": 49.32, "gen_rate": 17.5, "speed": 3.1, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 227, "tree_size": 512, "t0": 3.0467, "t1": 1.4417, "tft": 4.6032, "input_0": 1472, "input_1": 513, "min_CLP": -12.8, "draft_iters": 10.2, "mem_use": 49.17, "gen_rate": 6.0, "speed": 1.34, "text": "Certainly! One of the main criti"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.3, "tree_w": 275, "tree_size": 512, "t0": 2.0357, "t1": 1.4143, "tft": 3.0973, "input_0": 1088, "input_1": 513, "min_CLP": -7.95, "draft_iters": 6.4, "mem_use": 47.0, "gen_rate": 4.6, "speed": 1.33, "text": "The production of pornography in"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 260, "tree_size": 512, "t0": 2.14, "t1": 1.4186, "tft": 3.4592, "input_0": 977, "input_1": 513, "min_CLP": -9.01, "draft_iters": 6.9, "mem_use": 47.32, "gen_rate": 4.6, "speed": 1.29, "text": "You can use the website World Ti"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.0, "tree_w": 225, "tree_size": 512, "t0": 2.6183, "t1": 1.415, "tft": 3.5113, "input_0": 1181, "input_1": 513, "min_CLP": -8.91, "draft_iters": 8.5, "mem_use": 47.4, "gen_rate": 6.2, "speed": 1.53, "text": "The 5-second rule is a common ur"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.0, "tree_w": 209, "tree_size": 512, "t0": 3.624, "t1": 1.418, "tft": 3.4543, "input_0": 1362, "input_1": 513, "min_CLP": -10.94, "draft_iters": 14.0, "mem_use": 47.12, "gen_rate": 7.6, "speed": 1.51, "text": "To determine the number of eggs "}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.8, "tree_w": 251, "tree_size": 512, "t0": 2.936, "t1": 1.426, "tft": 9.1776, "input_0": 1296, "input_1": 513, "min_CLP": -14.62, "draft_iters": 10.2, "mem_use": 47.9, "gen_rate": 6.8, "speed": 1.56, "text": "Sure, I can try to explain some "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 4.3, "tree_w": 262, "tree_size": 512, "t0": 1.93, "t1": 1.4183, "tft": 3.7258, "input_0": 975, "input_1": 513, "min_CLP": -8.09, "draft_iters": 6.5, "mem_use": 47.44, "gen_rate": 4.0, "speed": 1.19, "text": "\"You're welcome! I hope you can "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.8, "tree_w": 208, "tree_size": 512, "t0": 3.466, "t1": 1.416, "tft": 3.4378, "input_0": 1589, "input_1": 513, "min_CLP": -8.11, "draft_iters": 11.4, "mem_use": 47.15, "gen_rate": 7.6, "speed": 1.56, "text": "\"#Introducing Open Assistant: Op"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.4, "tree_w": 236, "tree_size": 512, "t0": 2.5843, "t1": 1.4214, "tft": 3.8265, "input_0": 1283, "input_1": 513, "min_CLP": -9.52, "draft_iters": 8.7, "mem_use": 47.76, "gen_rate": 5.4, "speed": 1.35, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 62, "tree_size": 512, "t0": 6.96, "t1": 1.4333, "tft": 9.2224, "input_0": 2333, "input_1": 513, "min_CLP": -6.6, "draft_iters": 21.7, "mem_use": 48.83, "gen_rate": 11.0, "speed": 1.31, "text": "Sure, here are some ways AI assi"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.2, "tree_w": 271, "tree_size": 512, "t0": 1.9389, "t1": 1.4456, "tft": 5.2361, "input_0": 967, "input_1": 513, "min_CLP": -8.69, "draft_iters": 7.2, "mem_use": 49.83, "gen_rate": 3.9, "speed": 1.15, "text": "\"[Verse 1]\\nSteve works diligent"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.4, "tree_w": 221, "tree_size": 512, "t0": 3.2029, "t1": 1.43, "tft": 4.5583, "input_0": 1269, "input_1": 513, "min_CLP": -8.86, "draft_iters": 11.1, "mem_use": 48.32, "gen_rate": 5.4, "speed": 1.17, "text": "The scp command is specific to U"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 225, "tree_size": 512, "t0": 3.7233, "t1": 1.4367, "tft": 4.83, "input_0": 1416, "input_1": 513, "min_CLP": -10.68, "draft_iters": 14.3, "mem_use": 48.97, "gen_rate": 13.0, "speed": 2.52, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.1, "tree_w": 275, "tree_size": 512, "t0": 1.7886, "t1": 1.4143, "tft": 3.0879, "input_0": 873, "input_1": 513, "min_CLP": -8.89, "draft_iters": 6.3, "mem_use": 47.06, "gen_rate": 4.7, "speed": 1.47, "text": "Yes, it would be illegal to keep"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.0, "tree_w": 218, "tree_size": 512, "t0": 3.22, "t1": 1.416, "tft": 3.493, "input_0": 1264, "input_1": 513, "min_CLP": -8.81, "draft_iters": 10.8, "mem_use": 47.35, "gen_rate": 7.0, "speed": 1.51, "text": "Sydney is the largest city in Au"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.0, "tree_w": 228, "tree_size": 512, "t0": 3.3875, "t1": 1.415, "tft": 3.7882, "input_0": 1328, "input_1": 513, "min_CLP": -9.27, "draft_iters": 12.0, "mem_use": 47.65, "gen_rate": 11.0, "speed": 2.29, "text": "\"5 second rule is a dangerous ga"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.1, "tree_w": 252, "tree_size": 512, "t0": 1.8413, "t1": 1.415, "tft": 3.5065, "input_0": 924, "input_1": 513, "min_CLP": -8.19, "draft_iters": 6.2, "mem_use": 47.32, "gen_rate": 4.1, "speed": 1.27, "text": "\"Oh, don't worry, I'm sure you'l"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 176, "tree_size": 512, "t0": 4.705, "t1": 1.41, "tft": 3.435, "input_0": 1580, "input_1": 513, "min_CLP": -11.38, "draft_iters": 18.5, "mem_use": 47.09, "gen_rate": 17.5, "speed": 2.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 48, "tree_h": 6.9, "tree_w": 240, "tree_size": 512, "t0": 2.6286, "t1": 1.4171, "tft": 3.453, "input_0": 1081, "input_1": 513, "min_CLP": -9.48, "draft_iters": 9.1, "mem_use": 47.07, "gen_rate": 6.9, "speed": 1.7, "text": "The task is to estimate the time"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 5.8, "tree_w": 268, "tree_size": 512, "t0": 2.29, "t1": 1.4367, "tft": 4.7269, "input_0": 1111, "input_1": 513, "min_CLP": -13.33, "draft_iters": 8.0, "mem_use": 48.8, "gen_rate": 6.7, "speed": 1.79, "text": "\"The solution to the Taniyama\u2013Sh"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.2, "tree_w": 253, "tree_size": 512, "t0": 2.92, "t1": 1.418, "tft": 3.4329, "input_0": 1198, "input_1": 513, "min_CLP": -11.91, "draft_iters": 10.4, "mem_use": 47.07, "gen_rate": 9.2, "speed": 2.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.0, "tree_w": 136, "tree_size": 512, "t0": 5.9467, "t1": 1.4133, "tft": 3.4966, "input_0": 1943, "input_1": 513, "min_CLP": -7.81, "draft_iters": 20.7, "mem_use": 47.37, "gen_rate": 12.7, "speed": 1.72, "text": "In Godot Engine 3.x, you can wri"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 258, "tree_size": 512, "t0": 2.3662, "t1": 1.4163, "tft": 3.0813, "input_0": 1108, "input_1": 513, "min_CLP": -9.66, "draft_iters": 8.1, "mem_use": 47.04, "gen_rate": 4.1, "speed": 1.09, "text": "To start learning guitar and bec"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 5.6, "tree_w": 252, "tree_size": 512, "t0": 2.3087, "t1": 1.4175, "tft": 3.5009, "input_0": 1075, "input_1": 513, "min_CLP": -8.93, "draft_iters": 7.8, "mem_use": 47.35, "gen_rate": 5.2, "speed": 1.41, "text": "Becoming one with the Force is a"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 186, "tree_size": 512, "t0": 3.3071, "t1": 1.4129, "tft": 3.4764, "input_0": 1312, "input_1": 513, "min_CLP": -8.84, "draft_iters": 11.3, "mem_use": 47.21, "gen_rate": 5.0, "speed": 1.06, "text": "A gas-operated rifle uses expand"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 241, "tree_size": 512, "t0": 2.9033, "t1": 1.4167, "tft": 3.7188, "input_0": 1272, "input_1": 513, "min_CLP": -9.74, "draft_iters": 10.2, "mem_use": 47.46, "gen_rate": 5.5, "speed": 1.27, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 223, "tree_size": 512, "t0": 3.32, "t1": 1.462, "tft": 8.6645, "input_0": 1304, "input_1": 513, "min_CLP": -8.99, "draft_iters": 11.2, "mem_use": 50.33, "gen_rate": 7.0, "speed": 1.46, "text": "Yes, a more robust solution woul"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 8.3, "tree_w": 207, "tree_size": 512, "t0": 3.2886, "t1": 1.4157, "tft": 3.7454, "input_0": 1293, "input_1": 513, "min_CLP": -8.27, "draft_iters": 11.1, "mem_use": 47.52, "gen_rate": 6.0, "speed": 1.28, "text": "\"Yes, it is customary to offer a"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.4, "tree_w": 281, "tree_size": 512, "t0": 1.93, "t1": 1.4625, "tft": 5.5588, "input_0": 983, "input_1": 513, "min_CLP": -9.09, "draft_iters": 6.5, "mem_use": 50.41, "gen_rate": 4.4, "speed": 1.29, "text": "Xin ch\u00e0o, t\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd AI v"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.2, "tree_w": 271, "tree_size": 512, "t0": 1.9562, "t1": 1.4262, "tft": 4.0863, "input_0": 939, "input_1": 513, "min_CLP": -8.41, "draft_iters": 7.4, "mem_use": 47.89, "gen_rate": 4.2, "speed": 1.26, "text": "It is true that people can be de"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.0, "tree_w": 226, "tree_size": 512, "t0": 3.5525, "t1": 1.4175, "tft": 7.7275, "input_0": 1464, "input_1": 513, "min_CLP": -12.18, "draft_iters": 12.2, "mem_use": 47.42, "gen_rate": 11.0, "speed": 2.21, "text": "Sure! Here\\'s an example of how "}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 3.5, "tree_w": 261, "tree_size": 512, "t0": 1.7175, "t1": 1.4375, "tft": 4.7551, "input_0": 998, "input_1": 513, "min_CLP": -11.21, "draft_iters": 5.5, "mem_use": 48.83, "gen_rate": 4.5, "speed": 1.43, "text": "1. Rammstein\\n2. Scorpions\\n3. D"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.2, "tree_w": 255, "tree_size": 512, "t0": 1.9188, "t1": 1.42, "tft": 3.5207, "input_0": 897, "input_1": 513, "min_CLP": -8.68, "draft_iters": 6.4, "mem_use": 47.36, "gen_rate": 4.2, "speed": 1.27, "text": "The best strategy to win a thumb"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 3.7, "tree_w": 313, "tree_size": 512, "t0": 1.69, "t1": 1.4429, "tft": 4.886, "input_0": 1113, "input_1": 513, "min_CLP": -12.55, "draft_iters": 5.4, "mem_use": 49.37, "gen_rate": 4.7, "speed": 1.5, "text": "\"To acquire revenue from custome"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 230, "tree_size": 512, "t0": 2.654, "t1": 1.426, "tft": 4.2135, "input_0": 1323, "input_1": 513, "min_CLP": -8.48, "draft_iters": 8.6, "mem_use": 47.99, "gen_rate": 6.4, "speed": 1.57, "text": "Yes, I can certainly simulate va"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 215, "tree_size": 512, "t0": 3.792, "t1": 1.414, "tft": 3.3394, "input_0": 1399, "input_1": 513, "min_CLP": -9.03, "draft_iters": 13.4, "mem_use": 47.52, "gen_rate": 7.2, "speed": 1.38, "text": "\"Sure, here's an essay on how Ro"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.7, "tree_w": 213, "tree_size": 512, "t0": 3.325, "t1": 1.42, "tft": 3.8098, "input_0": 1268, "input_1": 513, "min_CLP": -9.01, "draft_iters": 12.0, "mem_use": 47.66, "gen_rate": 6.7, "speed": 1.4, "text": "There are a lot of APIs, librari"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.7, "tree_w": 342, "tree_size": 512, "t0": 1.6836, "t1": 1.4373, "tft": 4.7647, "input_0": 700, "input_1": 513, "min_CLP": -9.73, "draft_iters": 5.9, "mem_use": 48.94, "gen_rate": 2.9, "speed": 0.93, "text": "\"Certainly! Here's a poem in Que"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 267, "tree_size": 512, "t0": 2.1257, "t1": 1.4186, "tft": 3.0959, "input_0": 1089, "input_1": 513, "min_CLP": -9.1, "draft_iters": 7.1, "mem_use": 47.04, "gen_rate": 4.7, "speed": 1.33, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 6.4, "tree_w": 222, "tree_size": 512, "t0": 2.6357, "t1": 1.4157, "tft": 3.4471, "input_0": 1179, "input_1": 513, "min_CLP": -7.97, "draft_iters": 8.7, "mem_use": 47.08, "gen_rate": 5.6, "speed": 1.38, "text": "The error in this code is that t"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 3.0, "tree_w": 294, "tree_size": 512, "t0": 1.46, "t1": 1.43, "tft": 4.6279, "input_0": 813, "input_1": 513, "min_CLP": -8.56, "draft_iters": 5.0, "mem_use": 48.47, "gen_rate": 0.0, "speed": 0.0, "text": "None"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 150, "tree_size": 512, "t0": 5.21, "t1": 1.42, "tft": 3.8229, "input_0": 1861, "input_1": 513, "min_CLP": -7.85, "draft_iters": 17.0, "mem_use": 47.69, "gen_rate": 10.7, "speed": 1.61, "text": "In the second context, the `@` s"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 10.0, "tree_w": 197, "tree_size": 512, "t0": 3.378, "t1": 1.426, "tft": 3.8444, "input_0": 1292, "input_1": 513, "min_CLP": -8.69, "draft_iters": 12.4, "mem_use": 47.82, "gen_rate": 10.2, "speed": 2.12, "text": "\"To create a Python program that"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.9, "tree_w": 267, "tree_size": 512, "t0": 2.15, "t1": 1.4443, "tft": 5.0674, "input_0": 1019, "input_1": 513, "min_CLP": -11.66, "draft_iters": 7.1, "mem_use": 49.59, "gen_rate": 4.9, "speed": 1.35, "text": "\"As an AI language model, I cann"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 52, "tree_h": 6.5, "tree_w": 265, "tree_size": 512, "t0": 2.465, "t1": 1.4138, "tft": 3.7904, "input_0": 1093, "input_1": 513, "min_CLP": -9.63, "draft_iters": 8.4, "mem_use": 47.6, "gen_rate": 6.5, "speed": 1.67, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 29.5, "tree_w": 45, "tree_size": 512, "t0": 9.065, "t1": 1.435, "tft": 4.807, "input_0": 2766, "input_1": 513, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 48.96, "gen_rate": 23.5, "speed": 2.24, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.6, "tree_w": 263, "tree_size": 512, "t0": 2.0813, "t1": 1.415, "tft": 3.0861, "input_0": 1044, "input_1": 513, "min_CLP": -8.42, "draft_iters": 6.9, "mem_use": 47.02, "gen_rate": 4.5, "speed": 1.29, "text": "Yes, I can simulate thinking and"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 27, "tree_h": 4.9, "tree_w": 270, "tree_size": 512, "t0": 1.98, "t1": 1.4175, "tft": 3.4738, "input_0": 976, "input_1": 513, "min_CLP": -8.66, "draft_iters": 7.0, "mem_use": 47.25, "gen_rate": 3.4, "speed": 0.99, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.5, "tree_w": 263, "tree_size": 512, "t0": 2.0475, "t1": 1.4225, "tft": 3.7216, "input_0": 952, "input_1": 513, "min_CLP": -8.84, "draft_iters": 6.8, "mem_use": 47.49, "gen_rate": 4.6, "speed": 1.33, "text": "\"Thanks! I'm always happy to hel"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 269, "tree_size": 512, "t0": 2.24, "t1": 1.44, "tft": 4.8606, "input_0": 954, "input_1": 513, "min_CLP": -9.49, "draft_iters": 8.4, "mem_use": 49.09, "gen_rate": 7.4, "speed": 2.0, "text": "\"Thou art the sun that doth shin"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.2, "tree_w": 260, "tree_size": 512, "t0": 2.54, "t1": 1.425, "tft": 3.8048, "input_0": 1243, "input_1": 513, "min_CLP": -8.64, "draft_iters": 8.3, "mem_use": 47.66, "gen_rate": 5.7, "speed": 1.43, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 244, "tree_size": 512, "t0": 3.46, "t1": 1.4167, "tft": 3.4129, "input_0": 1306, "input_1": 513, "min_CLP": -13.83, "draft_iters": 13.7, "mem_use": 47.06, "gen_rate": 12.7, "speed": 2.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 7.0, "tree_w": 263, "tree_size": 512, "t0": 2.7214, "t1": 1.4157, "tft": 3.0843, "input_0": 1334, "input_1": 513, "min_CLP": -10.04, "draft_iters": 9.4, "mem_use": 47.04, "gen_rate": 6.1, "speed": 1.49, "text": "\"Sure, President's Day is a fede"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 296, "tree_size": 512, "t0": 1.4863, "t1": 1.42, "tft": 3.5025, "input_0": 871, "input_1": 513, "min_CLP": -11.85, "draft_iters": 5.0, "mem_use": 47.35, "gen_rate": 4.1, "speed": 1.42, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.5, "tree_w": 204, "tree_size": 512, "t0": 3.95, "t1": 1.4325, "tft": 4.2763, "input_0": 1416, "input_1": 513, "min_CLP": -11.97, "draft_iters": 12.5, "mem_use": 48.15, "gen_rate": 8.0, "speed": 1.49, "text": "No, the US National Reconnaissan"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.9, "tree_w": 275, "tree_size": 512, "t0": 1.8057, "t1": 1.4186, "tft": 3.5149, "input_0": 873, "input_1": 513, "min_CLP": -9.12, "draft_iters": 6.0, "mem_use": 47.43, "gen_rate": 4.6, "speed": 1.42, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 4.6, "tree_w": 262, "tree_size": 512, "t0": 2.0971, "t1": 1.4243, "tft": 3.7349, "input_0": 981, "input_1": 513, "min_CLP": -8.45, "draft_iters": 6.9, "mem_use": 47.49, "gen_rate": 5.0, "speed": 1.42, "text": "\"That sounds great! I'm happy to"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.7, "tree_w": 217, "tree_size": 512, "t0": 3.3467, "t1": 1.4117, "tft": 3.0955, "input_0": 1422, "input_1": 513, "min_CLP": -8.49, "draft_iters": 11.2, "mem_use": 47.04, "gen_rate": 6.7, "speed": 1.4, "text": "Yes, the ATF can be considered a"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 6.6, "tree_w": 257, "tree_size": 512, "t0": 2.4414, "t1": 1.4243, "tft": 3.8334, "input_0": 1063, "input_1": 513, "min_CLP": -8.43, "draft_iters": 8.9, "mem_use": 47.73, "gen_rate": 3.7, "speed": 0.96, "text": "\"Like, who cares what some old g"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.4, "tree_w": 271, "tree_size": 512, "t0": 1.7988, "t1": 1.4225, "tft": 3.4676, "input_0": 876, "input_1": 513, "min_CLP": -8.3, "draft_iters": 6.5, "mem_use": 47.16, "gen_rate": 4.2, "speed": 1.32, "text": "The mayonnaise has curdled, mean"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 222, "tree_size": 512, "t0": 2.6333, "t1": 1.43, "tft": 4.5629, "input_0": 1151, "input_1": 513, "min_CLP": -8.17, "draft_iters": 9.3, "mem_use": 48.39, "gen_rate": 5.8, "speed": 1.43, "text": "Sure, there are many media that "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 4.5, "tree_w": 272, "tree_size": 512, "t0": 2.095, "t1": 1.42, "tft": 3.7368, "input_0": 1030, "input_1": 513, "min_CLP": -8.41, "draft_iters": 6.8, "mem_use": 47.49, "gen_rate": 5.5, "speed": 1.57, "text": "I have no intention of taking ov"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 239, "tree_size": 512, "t0": 2.41, "t1": 1.44, "tft": 4.7135, "input_0": 1019, "input_1": 513, "min_CLP": -9.93, "draft_iters": 8.7, "mem_use": 48.69, "gen_rate": 4.9, "speed": 1.26, "text": "I would recommend the Emerald La"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.2, "tree_w": 267, "tree_size": 512, "t0": 1.8975, "t1": 1.4237, "tft": 3.7107, "input_0": 938, "input_1": 513, "min_CLP": -8.64, "draft_iters": 6.4, "mem_use": 47.44, "gen_rate": 4.0, "speed": 1.2, "text": "\"Open Assistant: Open Source Cha"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.1, "tree_w": 272, "tree_size": 512, "t0": 1.86, "t1": 1.4186, "tft": 3.5082, "input_0": 949, "input_1": 513, "min_CLP": -8.59, "draft_iters": 6.3, "mem_use": 47.33, "gen_rate": 4.9, "speed": 1.48, "text": "Sure, I can illustrate the solut"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 17.0, "tree_w": 143, "tree_size": 512, "t0": 5.2133, "t1": 1.4467, "tft": 5.0795, "input_0": 1629, "input_1": 513, "min_CLP": -8.75, "draft_iters": 19.7, "mem_use": 49.68, "gen_rate": 15.3, "speed": 2.3, "text": "\"The reason you're not getting t"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.0, "tree_w": 226, "tree_size": 512, "t0": 2.5883, "t1": 1.415, "tft": 3.0991, "input_0": 1100, "input_1": 513, "min_CLP": -8.17, "draft_iters": 8.5, "mem_use": 47.02, "gen_rate": 6.0, "speed": 1.5, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.5, "tree_w": 259, "tree_size": 512, "t0": 1.9387, "t1": 1.4175, "tft": 3.7591, "input_0": 964, "input_1": 513, "min_CLP": -8.13, "draft_iters": 6.6, "mem_use": 47.58, "gen_rate": 4.6, "speed": 1.38, "text": "Pirating video games is mostly h"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 294, "tree_size": 512, "t0": 1.64, "t1": 1.42, "tft": 3.4831, "input_0": 975, "input_1": 513, "min_CLP": -8.94, "draft_iters": 5.4, "mem_use": 47.21, "gen_rate": 4.4, "speed": 1.43, "text": "This matters because the heat in"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 44, "tree_h": 5.4, "tree_w": 254, "tree_size": 512, "t0": 2.2263, "t1": 1.4163, "tft": 3.1103, "input_0": 1115, "input_1": 513, "min_CLP": -10.58, "draft_iters": 7.5, "mem_use": 47.04, "gen_rate": 5.5, "speed": 1.51, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 162, "tree_size": 512, "t0": 3.798, "t1": 1.434, "tft": 4.8638, "input_0": 1407, "input_1": 513, "min_CLP": -7.45, "draft_iters": 13.8, "mem_use": 49.13, "gen_rate": 7.6, "speed": 1.45, "text": "\"I'm sorry to hear that. It's po"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 183, "tree_size": 512, "t0": 3.584, "t1": 1.412, "tft": 3.0733, "input_0": 1437, "input_1": 513, "min_CLP": -7.76, "draft_iters": 11.8, "mem_use": 47.0, "gen_rate": 7.0, "speed": 1.4, "text": "\"The task is asking to determine"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.9, "tree_w": 268, "tree_size": 512, "t0": 2.1022, "t1": 1.4167, "tft": 3.4519, "input_0": 933, "input_1": 513, "min_CLP": -9.22, "draft_iters": 8.0, "mem_use": 47.09, "gen_rate": 3.9, "speed": 1.1, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.0, "tree_w": 211, "tree_size": 512, "t0": 3.342, "t1": 1.458, "tft": 5.5578, "input_0": 1290, "input_1": 513, "min_CLP": -12.06, "draft_iters": 12.4, "mem_use": 50.37, "gen_rate": 7.2, "speed": 1.5, "text": "As of 2021, several countries ha"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.8, "tree_w": 211, "tree_size": 512, "t0": 3.844, "t1": 1.43, "tft": 4.5654, "input_0": 1491, "input_1": 513, "min_CLP": -9.19, "draft_iters": 14.4, "mem_use": 48.35, "gen_rate": 7.0, "speed": 1.33, "text": "I understand now. As an AI langu"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.3, "tree_w": 270, "tree_size": 512, "t0": 2.3667, "t1": 1.4517, "tft": 3.4949, "input_0": 1151, "input_1": 513, "min_CLP": -10.66, "draft_iters": 7.7, "mem_use": 47.3, "gen_rate": 5.5, "speed": 1.44, "text": "\"Certainly! There are many resou"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.2, "tree_w": 180, "tree_size": 512, "t0": 3.488, "t1": 1.42, "tft": 3.4858, "input_0": 1192, "input_1": 513, "min_CLP": -8.33, "draft_iters": 13.0, "mem_use": 47.28, "gen_rate": 7.8, "speed": 1.59, "text": "def most_effective_tax_fraud_met"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 189, "tree_size": 512, "t0": 3.1233, "t1": 1.4183, "tft": 3.0976, "input_0": 1287, "input_1": 513, "min_CLP": -8.13, "draft_iters": 10.3, "mem_use": 47.04, "gen_rate": 5.8, "speed": 1.28, "text": "The theory of sexual selection, "}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.3, "tree_w": 260, "tree_size": 512, "t0": 2.3767, "t1": 1.43, "tft": 4.104, "input_0": 1169, "input_1": 513, "min_CLP": -8.7, "draft_iters": 8.3, "mem_use": 47.86, "gen_rate": 5.5, "speed": 1.45, "text": "\"Sure, I can do that! Here's an "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 6.1, "tree_w": 266, "tree_size": 512, "t0": 2.4275, "t1": 1.4262, "tft": 4.0825, "input_0": 1119, "input_1": 513, "min_CLP": -12.81, "draft_iters": 8.4, "mem_use": 47.88, "gen_rate": 5.8, "speed": 1.49, "text": "Claro, aqu\u00ed tienes una lista red"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 10.7, "tree_w": 226, "tree_size": 512, "t0": 3.6217, "t1": 1.4567, "tft": 5.5659, "input_0": 1316, "input_1": 513, "min_CLP": -9.78, "draft_iters": 12.8, "mem_use": 50.39, "gen_rate": 8.7, "speed": 1.71, "text": "\"Sure, here's a shorter version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 297, "tree_size": 512, "t0": 1.55, "t1": 1.4175, "tft": 3.1015, "input_0": 870, "input_1": 513, "min_CLP": -14.02, "draft_iters": 5.1, "mem_use": 47.05, "gen_rate": 4.1, "speed": 1.39, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 216, "tree_size": 512, "t0": 2.72, "t1": 1.4186, "tft": 3.7744, "input_0": 1031, "input_1": 513, "min_CLP": -7.9, "draft_iters": 10.0, "mem_use": 47.62, "gen_rate": 5.1, "speed": 1.24, "text": "Berlin is not an industrial city"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.2, "tree_w": 169, "tree_size": 512, "t0": 4.6875, "t1": 1.4125, "tft": 3.455, "input_0": 1693, "input_1": 513, "min_CLP": -10.09, "draft_iters": 17.2, "mem_use": 47.08, "gen_rate": 8.0, "speed": 1.31, "text": "\"Here's a Python script that sav"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.2, "tree_w": 264, "tree_size": 512, "t0": 2.862, "t1": 1.438, "tft": 4.6602, "input_0": 1196, "input_1": 513, "min_CLP": -10.61, "draft_iters": 10.4, "mem_use": 49.59, "gen_rate": 9.2, "speed": 2.14, "text": "## Vegetarian Sausage and Vegeta"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.0, "tree_w": 266, "tree_size": 512, "t0": 2.1578, "t1": 1.4156, "tft": 3.0872, "input_0": 950, "input_1": 513, "min_CLP": -12.83, "draft_iters": 8.0, "mem_use": 47.0, "gen_rate": 3.7, "speed": 1.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.8, "tree_w": 168, "tree_size": 512, "t0": 3.704, "t1": 1.44, "tft": 4.6029, "input_0": 1474, "input_1": 513, "min_CLP": -9.78, "draft_iters": 12.6, "mem_use": 49.26, "gen_rate": 6.8, "speed": 1.32, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 5.3, "tree_w": 238, "tree_size": 512, "t0": 2.43, "t1": 1.4143, "tft": 3.0588, "input_0": 1160, "input_1": 513, "min_CLP": -8.34, "draft_iters": 7.9, "mem_use": 47.01, "gen_rate": 5.4, "speed": 1.41, "text": "The main reason for needing AI a"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.2, "tree_w": 264, "tree_size": 512, "t0": 1.5778, "t1": 1.4122, "tft": 3.0753, "input_0": 875, "input_1": 513, "min_CLP": -9.8, "draft_iters": 5.2, "mem_use": 46.99, "gen_rate": 3.7, "speed": 1.23, "text": "\u5728\u4e2d\u6587\u7684\u7ffb\u8b6f\u4e2d\uff0c\u9019\u53e5\u8a71\u7684\u610f\u601d\u662f\u300c\u628a\u9019\u53e5\u8a71\u7ffb\u8b6f\u4e00\u4e0b\u300d\u3002\u7136\u800c\uff0c\u7531\u65bc\u9019"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 243, "tree_size": 512, "t0": 3.47, "t1": 1.4133, "tft": 3.0444, "input_0": 1282, "input_1": 513, "min_CLP": -12.8, "draft_iters": 13.7, "mem_use": 47.15, "gen_rate": 12.7, "speed": 2.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 9.4, "tree_w": 188, "tree_size": 512, "t0": 3.744, "t1": 1.424, "tft": 4.533, "input_0": 1583, "input_1": 513, "min_CLP": -15.22, "draft_iters": 12.2, "mem_use": 48.21, "gen_rate": 8.4, "speed": 1.63, "text": "In the 1950s, the quality of lif"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 218, "tree_size": 512, "t0": 3.454, "t1": 1.414, "tft": 3.4209, "input_0": 1293, "input_1": 513, "min_CLP": -9.78, "draft_iters": 13.4, "mem_use": 47.1, "gen_rate": 7.0, "speed": 1.44, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 177, "tree_size": 512, "t0": 3.462, "t1": 1.416, "tft": 3.4975, "input_0": 1485, "input_1": 513, "min_CLP": -7.53, "draft_iters": 11.4, "mem_use": 47.3, "gen_rate": 6.8, "speed": 1.39, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.2, "tree_w": 285, "tree_size": 512, "t0": 1.9438, "t1": 1.4212, "tft": 3.7826, "input_0": 987, "input_1": 513, "min_CLP": -9.88, "draft_iters": 6.4, "mem_use": 47.65, "gen_rate": 4.6, "speed": 1.37, "text": "In the context of firearms, sele"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 4.6, "tree_w": 266, "tree_size": 512, "t0": 1.95, "t1": 1.4186, "tft": 3.4805, "input_0": 986, "input_1": 513, "min_CLP": -8.72, "draft_iters": 6.6, "mem_use": 47.19, "gen_rate": 5.1, "speed": 1.53, "text": "I am a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.2, "tree_w": 262, "tree_size": 512, "t0": 2.312, "t1": 1.434, "tft": 4.584, "input_0": 1060, "input_1": 513, "min_CLP": -11.48, "draft_iters": 8.4, "mem_use": 48.41, "gen_rate": 6.6, "speed": 1.76, "text": "\"To initialize a TypeScript proj"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 287, "tree_size": 512, "t0": 1.5562, "t1": 1.4237, "tft": 3.4494, "input_0": 855, "input_1": 513, "min_CLP": -11.07, "draft_iters": 5.1, "mem_use": 47.09, "gen_rate": 4.1, "speed": 1.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.8, "tree_w": 218, "tree_size": 512, "t0": 3.9, "t1": 1.424, "tft": 4.115, "input_0": 1352, "input_1": 513, "min_CLP": -11.74, "draft_iters": 15.0, "mem_use": 47.93, "gen_rate": 7.4, "speed": 1.39, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.2, "tree_w": 256, "tree_size": 512, "t0": 2.7, "t1": 1.4133, "tft": 3.4633, "input_0": 1337, "input_1": 513, "min_CLP": -10.08, "draft_iters": 8.5, "mem_use": 47.2, "gen_rate": 5.8, "speed": 1.42, "text": "Pros:\\n1. Increased tolerance to"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 241, "tree_size": 512, "t0": 3.2875, "t1": 1.415, "tft": 3.0804, "input_0": 1378, "input_1": 513, "min_CLP": -10.3, "draft_iters": 11.8, "mem_use": 47.02, "gen_rate": 9.8, "speed": 2.07, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 279, "tree_size": 512, "t0": 2.08, "t1": 1.4671, "tft": 6.7888, "input_0": 1026, "input_1": 513, "min_CLP": -10.06, "draft_iters": 6.9, "mem_use": 51.33, "gen_rate": 4.6, "speed": 1.29, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 8.8, "tree_w": 249, "tree_size": 512, "t0": 2.746, "t1": 1.42, "tft": 3.5084, "input_0": 1163, "input_1": 513, "min_CLP": -12.25, "draft_iters": 10.6, "mem_use": 47.33, "gen_rate": 9.8, "speed": 2.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.5, "tree_w": 224, "tree_size": 512, "t0": 2.9933, "t1": 1.425, "tft": 4.5244, "input_0": 1414, "input_1": 513, "min_CLP": -11.91, "draft_iters": 9.8, "mem_use": 48.21, "gen_rate": 6.0, "speed": 1.36, "text": "The time it would take to go aro"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.3, "tree_w": 277, "tree_size": 512, "t0": 1.9, "t1": 1.4457, "tft": 4.8894, "input_0": 968, "input_1": 513, "min_CLP": -8.82, "draft_iters": 6.3, "mem_use": 49.46, "gen_rate": 4.7, "speed": 1.41, "text": "One way you could prevent spider"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.9, "tree_w": 269, "tree_size": 512, "t0": 1.7756, "t1": 1.4167, "tft": 3.505, "input_0": 901, "input_1": 513, "min_CLP": -8.97, "draft_iters": 6.0, "mem_use": 47.31, "gen_rate": 3.8, "speed": 1.18, "text": "\"Here's another one: Why did the"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 12.0, "tree_w": 226, "tree_size": 512, "t0": 3.2867, "t1": 1.4167, "tft": 3.4921, "input_0": 1097, "input_1": 513, "min_CLP": -8.58, "draft_iters": 14.0, "mem_use": 47.35, "gen_rate": 3.3, "speed": 0.71, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.2, "tree_w": 229, "tree_size": 512, "t0": 2.775, "t1": 1.4267, "tft": 4.0684, "input_0": 1230, "input_1": 513, "min_CLP": -11.94, "draft_iters": 9.3, "mem_use": 47.82, "gen_rate": 6.0, "speed": 1.43, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 7.1, "tree_w": 271, "tree_size": 512, "t0": 2.29, "t1": 1.4143, "tft": 3.4905, "input_0": 1043, "input_1": 513, "min_CLP": -11.68, "draft_iters": 8.9, "mem_use": 47.33, "gen_rate": 7.7, "speed": 2.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.0, "tree_w": 140, "tree_size": 512, "t0": 3.704, "t1": 1.422, "tft": 4.2161, "input_0": 1372, "input_1": 513, "min_CLP": -7.57, "draft_iters": 12.8, "mem_use": 48.01, "gen_rate": 7.8, "speed": 1.52, "text": "The Transactional Interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.3, "tree_w": 260, "tree_size": 512, "t0": 2.7929, "t1": 1.4171, "tft": 3.512, "input_0": 1026, "input_1": 513, "min_CLP": -9.03, "draft_iters": 12.1, "mem_use": 47.35, "gen_rate": 4.9, "speed": 1.15, "text": "\"Sure, here's a simple sequence "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.8, "tree_w": 243, "tree_size": 512, "t0": 2.54, "t1": 1.415, "tft": 3.4316, "input_0": 1108, "input_1": 513, "min_CLP": -10.02, "draft_iters": 8.5, "mem_use": 47.07, "gen_rate": 5.5, "speed": 1.39, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 239, "tree_size": 512, "t0": 3.49, "t1": 1.41, "tft": 3.0946, "input_0": 1323, "input_1": 513, "min_CLP": -13.35, "draft_iters": 13.7, "mem_use": 47.03, "gen_rate": 12.7, "speed": 2.59, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.0, "tree_w": 247, "tree_size": 512, "t0": 2.4817, "t1": 1.4667, "tft": 6.7853, "input_0": 1139, "input_1": 513, "min_CLP": -8.95, "draft_iters": 8.2, "mem_use": 51.31, "gen_rate": 6.2, "speed": 1.56, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 7.8, "tree_w": 193, "tree_size": 512, "t0": 3.035, "t1": 1.415, "tft": 3.4506, "input_0": 1395, "input_1": 513, "min_CLP": -8.37, "draft_iters": 10.0, "mem_use": 47.16, "gen_rate": 8.2, "speed": 1.85, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.8, "tree_w": 213, "tree_size": 512, "t0": 3.34, "t1": 1.4333, "tft": 4.7019, "input_0": 1340, "input_1": 513, "min_CLP": -9.03, "draft_iters": 11.2, "mem_use": 48.7, "gen_rate": 5.8, "speed": 1.22, "text": "Certainly! One common example of"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 16.0, "tree_w": 145, "tree_size": 512, "t0": 5.4167, "t1": 1.4233, "tft": 4.5887, "input_0": 1848, "input_1": 513, "min_CLP": -8.58, "draft_iters": 19.0, "mem_use": 48.47, "gen_rate": 13.3, "speed": 1.95, "text": "When you use the Command Prompt "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 222, "tree_size": 512, "t0": 3.4633, "t1": 1.42, "tft": 3.4903, "input_0": 1241, "input_1": 513, "min_CLP": -10.2, "draft_iters": 13.7, "mem_use": 47.3, "gen_rate": 12.7, "speed": 2.59, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 270, "tree_size": 512, "t0": 2.2757, "t1": 1.4129, "tft": 3.4306, "input_0": 1100, "input_1": 513, "min_CLP": -11.14, "draft_iters": 7.4, "mem_use": 47.12, "gen_rate": 4.7, "speed": 1.28, "text": "To make dye out of mixed Hypogym"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 184, "tree_size": 512, "t0": 4.75, "t1": 1.415, "tft": 3.4356, "input_0": 1520, "input_1": 513, "min_CLP": -12.28, "draft_iters": 18.5, "mem_use": 47.09, "gen_rate": 17.5, "speed": 2.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.3, "tree_w": 153, "tree_size": 512, "t0": 4.93, "t1": 1.4167, "tft": 4.2621, "input_0": 1798, "input_1": 513, "min_CLP": -9.01, "draft_iters": 17.7, "mem_use": 48.09, "gen_rate": 12.0, "speed": 1.89, "text": "I would be happy to help you imp"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 3.0, "tree_w": 310, "tree_size": 512, "t0": 1.485, "t1": 1.42, "tft": 3.5117, "input_0": 828, "input_1": 513, "min_CLP": -8.5, "draft_iters": 5.0, "mem_use": 47.43, "gen_rate": 3.0, "speed": 1.03, "text": "\"Is there a topic you'd like to "}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.2, "tree_w": 214, "tree_size": 512, "t0": 3.6767, "t1": 1.435, "tft": 4.7138, "input_0": 1306, "input_1": 513, "min_CLP": -10.87, "draft_iters": 13.3, "mem_use": 48.74, "gen_rate": 6.7, "speed": 1.3, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 5.0, "tree_w": 246, "tree_size": 512, "t0": 2.1688, "t1": 1.42, "tft": 3.8023, "input_0": 1014, "input_1": 513, "min_CLP": -7.83, "draft_iters": 7.2, "mem_use": 47.66, "gen_rate": 4.9, "speed": 1.36, "text": "I think the individual who answe"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 4.8, "tree_w": 262, "tree_size": 512, "t0": 2.1175, "t1": 1.4187, "tft": 3.7264, "input_0": 1030, "input_1": 513, "min_CLP": -9.33, "draft_iters": 7.1, "mem_use": 47.5, "gen_rate": 4.8, "speed": 1.34, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.5, "tree_w": 185, "tree_size": 512, "t0": 4.5125, "t1": 1.4125, "tft": 3.4981, "input_0": 1530, "input_1": 513, "min_CLP": -7.99, "draft_iters": 14.8, "mem_use": 47.24, "gen_rate": 8.2, "speed": 1.39, "text": "The three main types of programm"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.0, "tree_w": 152, "tree_size": 512, "t0": 4.765, "t1": 1.445, "tft": 5.2604, "input_0": 1724, "input_1": 513, "min_CLP": -10.72, "draft_iters": 19.0, "mem_use": 50.03, "gen_rate": 18.0, "speed": 2.9, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 178, "tree_size": 512, "t0": 3.5833, "t1": 1.4433, "tft": 5.2675, "input_0": 1369, "input_1": 513, "min_CLP": -9.98, "draft_iters": 12.3, "mem_use": 49.96, "gen_rate": 6.3, "speed": 1.26, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 282, "tree_size": 512, "t0": 1.59, "t1": 1.4163, "tft": 3.0828, "input_0": 949, "input_1": 513, "min_CLP": -8.63, "draft_iters": 5.2, "mem_use": 47.03, "gen_rate": 4.4, "speed": 1.46, "text": "\"Sure, here's a poem inspired by"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 289, "tree_size": 512, "t0": 1.5962, "t1": 1.43, "tft": 4.2744, "input_0": 907, "input_1": 513, "min_CLP": -11.39, "draft_iters": 5.2, "mem_use": 48.19, "gen_rate": 4.2, "speed": 1.4, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.2, "tree_w": 132, "tree_size": 512, "t0": 5.8525, "t1": 1.4375, "tft": 4.6927, "input_0": 1943, "input_1": 513, "min_CLP": -10.64, "draft_iters": 21.0, "mem_use": 48.64, "gen_rate": 10.0, "speed": 1.37, "text": "\"I apologize for the confusion i"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 5.6, "tree_w": 244, "tree_size": 512, "t0": 2.38, "t1": 1.416, "tft": 3.0686, "input_0": 1082, "input_1": 513, "min_CLP": -9.27, "draft_iters": 7.8, "mem_use": 47.01, "gen_rate": 6.4, "speed": 1.69, "text": "The answer is: Vector normalizat"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 5.9, "tree_w": 247, "tree_size": 512, "t0": 2.3025, "t1": 1.4187, "tft": 3.5021, "input_0": 987, "input_1": 513, "min_CLP": -8.19, "draft_iters": 8.2, "mem_use": 47.31, "gen_rate": 4.9, "speed": 1.31, "text": "Twerking is a dance move, not a "}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 15.5, "tree_w": 129, "tree_size": 512, "t0": 4.975, "t1": 1.435, "tft": 4.7641, "input_0": 1669, "input_1": 513, "min_CLP": -7.98, "draft_iters": 18.2, "mem_use": 48.89, "gen_rate": 11.0, "speed": 1.72, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.0, "tree_w": 150, "tree_size": 512, "t0": 4.105, "t1": 1.4133, "tft": 3.4686, "input_0": 1578, "input_1": 513, "min_CLP": -8.36, "draft_iters": 13.8, "mem_use": 47.25, "gen_rate": 6.0, "speed": 1.09, "text": "The answer is: To host a large l"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 256, "tree_size": 512, "t0": 2.0488, "t1": 1.4412, "tft": 4.0651, "input_0": 899, "input_1": 513, "min_CLP": -8.65, "draft_iters": 7.5, "mem_use": 48.59, "gen_rate": 4.0, "speed": 1.15, "text": "Sure, I can explain the SCP comm"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 6.3, "tree_w": 215, "tree_size": 512, "t0": 2.4729, "t1": 1.4157, "tft": 3.0866, "input_0": 1128, "input_1": 513, "min_CLP": -8.22, "draft_iters": 8.6, "mem_use": 47.04, "gen_rate": 6.0, "speed": 1.54, "text": "\"The future of AI in ten years i"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 215, "tree_size": 512, "t0": 3.79, "t1": 1.4167, "tft": 3.0945, "input_0": 1301, "input_1": 513, "min_CLP": -10.42, "draft_iters": 14.0, "mem_use": 47.05, "gen_rate": 12.7, "speed": 2.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 58, "tree_h": 12.2, "tree_w": 223, "tree_size": 512, "t0": 3.4883, "t1": 1.4217, "tft": 3.8421, "input_0": 1291, "input_1": 513, "min_CLP": -8.42, "draft_iters": 13.7, "mem_use": 47.69, "gen_rate": 9.7, "speed": 1.97, "text": "\"Okay, I'll do both.\\nFirst, her"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.2, "tree_w": 304, "tree_size": 512, "t0": 1.5438, "t1": 1.43, "tft": 4.0938, "input_0": 913, "input_1": 513, "min_CLP": -10.5, "draft_iters": 5.1, "mem_use": 47.93, "gen_rate": 4.1, "speed": 1.39, "text": "Apologies for the mistake. Here "}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 277, "tree_size": 512, "t0": 2.0014, "t1": 1.4186, "tft": 3.0977, "input_0": 970, "input_1": 513, "min_CLP": -9.6, "draft_iters": 7.0, "mem_use": 47.03, "gen_rate": 4.7, "speed": 1.38, "text": "A: An AK-47, also known as the K"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 209, "tree_size": 512, "t0": 3.438, "t1": 1.418, "tft": 3.5111, "input_0": 1319, "input_1": 513, "min_CLP": -9.1, "draft_iters": 12.0, "mem_use": 47.38, "gen_rate": 6.6, "speed": 1.36, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 229, "tree_size": 512, "t0": 3.4767, "t1": 1.4367, "tft": 4.7352, "input_0": 1171, "input_1": 513, "min_CLP": -9.24, "draft_iters": 14.0, "mem_use": 48.76, "gen_rate": 13.0, "speed": 2.64, "text": "* Statistical modeling is the pr"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 4.9, "tree_w": 261, "tree_size": 512, "t0": 2.12, "t1": 1.42, "tft": 3.5042, "input_0": 1091, "input_1": 513, "min_CLP": -10.03, "draft_iters": 7.0, "mem_use": 47.36, "gen_rate": 5.4, "speed": 1.53, "text": "The answer is: To start a succes"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 222, "tree_size": 512, "t0": 2.7757, "t1": 1.4243, "tft": 4.057, "input_0": 1158, "input_1": 513, "min_CLP": -9.09, "draft_iters": 9.7, "mem_use": 47.86, "gen_rate": 5.1, "speed": 1.22, "text": "\"While there's no harm in lettin"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 13, "tree_h": 3.0, "tree_w": 279, "tree_size": 512, "t0": 1.48, "t1": 1.42, "tft": 3.7132, "input_0": 799, "input_1": 513, "min_CLP": -8.3, "draft_iters": 5.0, "mem_use": 47.51, "gen_rate": 3.2, "speed": 1.12, "text": "You could offer them a gift, or "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 3.0, "tree_w": 259, "tree_size": 512, "t0": 1.495, "t1": 1.42, "tft": 3.782, "input_0": 757, "input_1": 513, "min_CLP": -8.8, "draft_iters": 5.0, "mem_use": 47.61, "gen_rate": 2.5, "speed": 0.86, "text": "Question: what is the conscious "}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 256, "tree_size": 512, "t0": 2.0114, "t1": 1.4157, "tft": 3.0842, "input_0": 971, "input_1": 513, "min_CLP": -9.47, "draft_iters": 7.0, "mem_use": 47.01, "gen_rate": 4.6, "speed": 1.33, "text": "\"I'm thinking about the current "}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 236, "tree_size": 512, "t0": 2.7867, "t1": 1.42, "tft": 3.0831, "input_0": 1219, "input_1": 513, "min_CLP": -9.12, "draft_iters": 9.2, "mem_use": 47.02, "gen_rate": 5.8, "speed": 1.39, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 229, "tree_size": 512, "t0": 2.4929, "t1": 1.4229, "tft": 3.7701, "input_0": 1107, "input_1": 513, "min_CLP": -7.96, "draft_iters": 8.9, "mem_use": 47.56, "gen_rate": 5.0, "speed": 1.28, "text": "L-theanine can help reduce stres"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 60, "tree_h": 13.4, "tree_w": 213, "tree_size": 512, "t0": 4.668, "t1": 1.42, "tft": 3.5052, "input_0": 1770, "input_1": 513, "min_CLP": -9.53, "draft_iters": 15.6, "mem_use": 47.32, "gen_rate": 12.0, "speed": 1.97, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 287, "tree_size": 512, "t0": 1.595, "t1": 1.42, "tft": 3.4555, "input_0": 961, "input_1": 513, "min_CLP": -9.16, "draft_iters": 5.2, "mem_use": 47.11, "gen_rate": 4.4, "speed": 1.45, "text": "Here is the rewritten version of"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.0, "tree_w": 285, "tree_size": 512, "t0": 1.4778, "t1": 1.4167, "tft": 3.4411, "input_0": 799, "input_1": 513, "min_CLP": -9.44, "draft_iters": 5.0, "mem_use": 47.07, "gen_rate": 3.8, "speed": 1.31, "text": "The last part in the question \"W"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 259, "tree_size": 512, "t0": 2.0362, "t1": 1.42, "tft": 3.8037, "input_0": 967, "input_1": 513, "min_CLP": -9.59, "draft_iters": 7.4, "mem_use": 47.63, "gen_rate": 4.0, "speed": 1.16, "text": "\"Bliss is a photograph of a hill"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.8, "tree_w": 88, "tree_size": 512, "t0": 4.8775, "t1": 1.4525, "tft": 5.7584, "input_0": 1682, "input_1": 513, "min_CLP": -6.83, "draft_iters": 15.0, "mem_use": 50.69, "gen_rate": 9.8, "speed": 1.54, "text": "\"It is not recommended to use yo"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 195, "tree_size": 512, "t0": 3.394, "t1": 1.436, "tft": 4.9081, "input_0": 1414, "input_1": 513, "min_CLP": -7.62, "draft_iters": 12.0, "mem_use": 49.43, "gen_rate": 7.0, "speed": 1.45, "text": "\"I apologize for any confusion. "}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.7, "tree_w": 193, "tree_size": 512, "t0": 3.1217, "t1": 1.4217, "tft": 3.8412, "input_0": 1295, "input_1": 513, "min_CLP": -8.68, "draft_iters": 10.2, "mem_use": 47.7, "gen_rate": 6.2, "speed": 1.36, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 241, "tree_size": 512, "t0": 3.6, "t1": 1.4133, "tft": 3.091, "input_0": 1299, "input_1": 513, "min_CLP": -12.8, "draft_iters": 13.7, "mem_use": 47.03, "gen_rate": 12.3, "speed": 2.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 233, "tree_size": 512, "t0": 2.9233, "t1": 1.4167, "tft": 3.0893, "input_0": 1236, "input_1": 513, "min_CLP": -8.59, "draft_iters": 9.8, "mem_use": 47.01, "gen_rate": 5.3, "speed": 1.23, "text": "Yes, I can speak German. I have "}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 257, "tree_size": 512, "t0": 2.5367, "t1": 1.4167, "tft": 3.4873, "input_0": 1071, "input_1": 513, "min_CLP": -9.19, "draft_iters": 9.7, "mem_use": 47.22, "gen_rate": 8.7, "speed": 2.19, "text": "Sure, I can simulate a Linux she"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 8.0, "tree_w": 210, "tree_size": 512, "t0": 3.0183, "t1": 1.4283, "tft": 4.2676, "input_0": 1285, "input_1": 513, "min_CLP": -9.29, "draft_iters": 10.5, "mem_use": 48.1, "gen_rate": 7.0, "speed": 1.57, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.7, "tree_w": 129, "tree_size": 512, "t0": 5.63, "t1": 1.4367, "tft": 4.3151, "input_0": 2156, "input_1": 513, "min_CLP": -7.58, "draft_iters": 17.0, "mem_use": 48.69, "gen_rate": 11.7, "speed": 1.65, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 6.2, "tree_w": 243, "tree_size": 512, "t0": 2.06, "t1": 1.4167, "tft": 3.4427, "input_0": 844, "input_1": 513, "min_CLP": -8.4, "draft_iters": 8.3, "mem_use": 47.08, "gen_rate": 4.0, "speed": 1.15, "text": "\"Sure, here is a haiku for atten"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 49, "tree_h": 7.0, "tree_w": 241, "tree_size": 512, "t0": 2.5471, "t1": 1.4214, "tft": 3.709, "input_0": 1165, "input_1": 513, "min_CLP": -8.49, "draft_iters": 9.1, "mem_use": 47.45, "gen_rate": 7.0, "speed": 1.76, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n[INST]"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 230, "tree_size": 512, "t0": 3.7933, "t1": 1.4167, "tft": 3.091, "input_0": 1353, "input_1": 513, "min_CLP": -13.68, "draft_iters": 14.0, "mem_use": 47.03, "gen_rate": 12.7, "speed": 2.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 6.7, "tree_w": 239, "tree_size": 512, "t0": 2.8067, "t1": 1.4183, "tft": 3.503, "input_0": 1151, "input_1": 513, "min_CLP": -8.32, "draft_iters": 9.2, "mem_use": 47.39, "gen_rate": 6.5, "speed": 1.54, "text": "The Trolley Problem is a well-kn"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.2, "tree_w": 228, "tree_size": 512, "t0": 2.906, "t1": 1.418, "tft": 3.0954, "input_0": 1300, "input_1": 513, "min_CLP": -8.25, "draft_iters": 9.6, "mem_use": 47.3, "gen_rate": 7.0, "speed": 1.62, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 219, "tree_size": 512, "t0": 2.68, "t1": 1.4417, "tft": 7.3584, "input_0": 1161, "input_1": 513, "min_CLP": -8.6, "draft_iters": 9.3, "mem_use": 49.37, "gen_rate": 5.7, "speed": 1.37, "text": "\"[INST] Let's get started! First"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 9.0, "tree_w": 227, "tree_size": 512, "t0": 2.885, "t1": 1.4183, "tft": 3.4635, "input_0": 1156, "input_1": 513, "min_CLP": -8.66, "draft_iters": 11.2, "mem_use": 47.2, "gen_rate": 8.0, "speed": 1.86, "text": "Here is a simple ASCII art of a "}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 3.0, "tree_w": 278, "tree_size": 512, "t0": 1.5033, "t1": 1.4567, "tft": 5.292, "input_0": 798, "input_1": 513, "min_CLP": -8.82, "draft_iters": 5.0, "mem_use": 50.06, "gen_rate": 2.7, "speed": 0.9, "text": "[INST] Write a long erotic story"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.1, "tree_w": 242, "tree_size": 512, "t0": 3.0471, "t1": 1.4171, "tft": 3.4393, "input_0": 1252, "input_1": 513, "min_CLP": -8.74, "draft_iters": 11.4, "mem_use": 47.06, "gen_rate": 5.6, "speed": 1.25, "text": "\"Sure! Here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 197, "tree_size": 512, "t0": 3.278, "t1": 1.41, "tft": 3.0894, "input_0": 1441, "input_1": 513, "min_CLP": -9.93, "draft_iters": 10.8, "mem_use": 47.02, "gen_rate": 7.0, "speed": 1.49, "text": "HTML stands for HyperText Markup"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 26.5, "tree_w": 37, "tree_size": 512, "t0": 7.825, "t1": 1.415, "tft": 3.0744, "input_0": 2214, "input_1": 513, "min_CLP": -6.4, "draft_iters": 30.0, "mem_use": 47.04, "gen_rate": 25.0, "speed": 2.71, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.1, "tree_w": 271, "tree_size": 512, "t0": 1.8812, "t1": 1.4212, "tft": 3.5255, "input_0": 894, "input_1": 513, "min_CLP": -8.45, "draft_iters": 6.2, "mem_use": 47.42, "gen_rate": 4.1, "speed": 1.25, "text": "No, you cannot use the image for"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 224, "tree_size": 512, "t0": 2.7667, "t1": 1.4133, "tft": 3.1013, "input_0": 1225, "input_1": 513, "min_CLP": -9.76, "draft_iters": 9.2, "mem_use": 47.03, "gen_rate": 5.5, "speed": 1.32, "text": "The second batch of pancakes may"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.0, "tree_w": 143, "tree_size": 512, "t0": 5.1667, "t1": 1.4233, "tft": 4.257, "input_0": 1597, "input_1": 513, "min_CLP": -7.89, "draft_iters": 18.7, "mem_use": 48.09, "gen_rate": 11.0, "speed": 1.67, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 245, "tree_size": 512, "t0": 2.21, "t1": 1.4286, "tft": 3.8515, "input_0": 1086, "input_1": 513, "min_CLP": -8.1, "draft_iters": 7.1, "mem_use": 47.8, "gen_rate": 4.6, "speed": 1.26, "text": "Thank you for clarifying. It see"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 3.0, "tree_w": 291, "tree_size": 512, "t0": 1.485, "t1": 1.42, "tft": 3.7906, "input_0": 811, "input_1": 513, "min_CLP": -8.77, "draft_iters": 5.0, "mem_use": 47.65, "gen_rate": 3.5, "speed": 1.2, "text": "In that case, no, there is a dif"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 8.3, "tree_w": 216, "tree_size": 512, "t0": 2.8986, "t1": 1.4343, "tft": 4.5824, "input_0": 1182, "input_1": 513, "min_CLP": -8.39, "draft_iters": 10.7, "mem_use": 48.37, "gen_rate": 5.7, "speed": 1.32, "text": "That\\'s a wonderful approach to "}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 252, "tree_size": 512, "t0": 1.92, "t1": 1.4157, "tft": 3.0806, "input_0": 989, "input_1": 513, "min_CLP": -8.38, "draft_iters": 6.6, "mem_use": 47.0, "gen_rate": 4.6, "speed": 1.37, "text": "\"Here's a simple ASCII art repre"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 249, "tree_size": 512, "t0": 2.2529, "t1": 1.4171, "tft": 3.5054, "input_0": 1114, "input_1": 513, "min_CLP": -8.51, "draft_iters": 7.3, "mem_use": 47.32, "gen_rate": 4.7, "speed": 1.28, "text": "Sure, I\\'d be happy to share som"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 51, "tree_h": 9.0, "tree_w": 202, "tree_size": 512, "t0": 3.185, "t1": 1.4237, "tft": 4.2557, "input_0": 1227, "input_1": 513, "min_CLP": -9.49, "draft_iters": 11.5, "mem_use": 48.08, "gen_rate": 6.4, "speed": 1.38, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.5, "tree_w": 156, "tree_size": 512, "t0": 3.51, "t1": 1.415, "tft": 3.4497, "input_0": 1417, "input_1": 513, "min_CLP": -7.3, "draft_iters": 11.3, "mem_use": 47.12, "gen_rate": 6.7, "speed": 1.35, "text": "Motion matching is a technology "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 57, "tree_h": 13.4, "tree_w": 198, "tree_size": 512, "t0": 4.834, "t1": 1.438, "tft": 4.3277, "input_0": 1803, "input_1": 513, "min_CLP": -10.21, "draft_iters": 16.0, "mem_use": 48.75, "gen_rate": 11.4, "speed": 1.82, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 248, "tree_size": 512, "t0": 2.49, "t1": 1.4183, "tft": 3.4361, "input_0": 1042, "input_1": 513, "min_CLP": -9.63, "draft_iters": 9.3, "mem_use": 47.08, "gen_rate": 5.5, "speed": 1.41, "text": "\"Here's an example of how to imp"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 135, "tree_size": 512, "t0": 4.744, "t1": 1.416, "tft": 3.7189, "input_0": 1575, "input_1": 513, "min_CLP": -7.32, "draft_iters": 15.4, "mem_use": 47.46, "gen_rate": 6.8, "speed": 1.1, "text": "Sure! Here\\'s a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 220, "tree_size": 512, "t0": 2.7271, "t1": 1.4371, "tft": 4.7284, "input_0": 1117, "input_1": 513, "min_CLP": -13.07, "draft_iters": 9.4, "mem_use": 48.76, "gen_rate": 5.0, "speed": 1.2, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 235, "tree_size": 512, "t0": 2.4486, "t1": 1.4357, "tft": 4.5762, "input_0": 1030, "input_1": 513, "min_CLP": -10.61, "draft_iters": 8.3, "mem_use": 49.2, "gen_rate": 4.9, "speed": 1.25, "text": "\"Paul Allen's collection of figh"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.4, "tree_w": 219, "tree_size": 512, "t0": 3.06, "t1": 1.44, "tft": 4.691, "input_0": 1237, "input_1": 513, "min_CLP": -7.82, "draft_iters": 10.8, "mem_use": 48.64, "gen_rate": 7.2, "speed": 1.6, "text": "I apologize for not providing a "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 256, "tree_size": 512, "t0": 2.3375, "t1": 1.4125, "tft": 3.4369, "input_0": 1021, "input_1": 513, "min_CLP": -9.83, "draft_iters": 8.5, "mem_use": 47.11, "gen_rate": 7.5, "speed": 2.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 4.9, "tree_w": 277, "tree_size": 512, "t0": 2.1686, "t1": 1.4243, "tft": 3.8374, "input_0": 1132, "input_1": 513, "min_CLP": -8.42, "draft_iters": 7.1, "mem_use": 47.73, "gen_rate": 5.3, "speed": 1.47, "text": "I am not capable of wanting, des"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.3, "tree_w": 256, "tree_size": 512, "t0": 1.9657, "t1": 1.4171, "tft": 3.4675, "input_0": 938, "input_1": 513, "min_CLP": -8.24, "draft_iters": 6.4, "mem_use": 47.14, "gen_rate": 4.7, "speed": 1.39, "text": "A car manufacturer could reduce "}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.8, "tree_w": 267, "tree_size": 512, "t0": 2.3883, "t1": 1.415, "tft": 3.0783, "input_0": 1070, "input_1": 513, "min_CLP": -10.91, "draft_iters": 8.0, "mem_use": 47.02, "gen_rate": 5.8, "speed": 1.53, "text": "\"Yes, the 5-second rule is a com"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 3.5, "tree_w": 290, "tree_size": 512, "t0": 1.6517, "t1": 1.4283, "tft": 4.0894, "input_0": 1007, "input_1": 513, "min_CLP": -8.95, "draft_iters": 5.3, "mem_use": 47.86, "gen_rate": 4.0, "speed": 1.3, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.8, "tree_w": 129, "tree_size": 512, "t0": 5.0375, "t1": 1.43, "tft": 4.6622, "input_0": 1864, "input_1": 513, "min_CLP": -7.4, "draft_iters": 16.8, "mem_use": 48.67, "gen_rate": 9.0, "speed": 1.39, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 203, "tree_size": 512, "t0": 3.4533, "t1": 1.4417, "tft": 4.9064, "input_0": 1493, "input_1": 513, "min_CLP": -8.16, "draft_iters": 11.2, "mem_use": 49.57, "gen_rate": 5.5, "speed": 1.12, "text": "Multi-track drifting is a propos"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 221, "tree_size": 512, "t0": 2.8929, "t1": 1.4257, "tft": 4.2823, "input_0": 1163, "input_1": 513, "min_CLP": -7.92, "draft_iters": 10.1, "mem_use": 48.17, "gen_rate": 5.0, "speed": 1.16, "text": "A completely purple sky is not p"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 206, "tree_size": 512, "t0": 3.825, "t1": 1.425, "tft": 4.2132, "input_0": 1112, "input_1": 513, "min_CLP": -9.12, "draft_iters": 18.5, "mem_use": 48.0, "gen_rate": 17.5, "speed": 3.33, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 29, "tree_h": 3.2, "tree_w": 295, "tree_size": 512, "t0": 1.5378, "t1": 1.4278, "tft": 3.8517, "input_0": 896, "input_1": 513, "min_CLP": -9.2, "draft_iters": 5.1, "mem_use": 47.77, "gen_rate": 3.2, "speed": 1.09, "text": "In Japanese, love is \"\u611b (ai)\", c"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 179, "tree_size": 512, "t0": 3.522, "t1": 1.416, "tft": 3.497, "input_0": 1351, "input_1": 513, "min_CLP": -7.86, "draft_iters": 11.6, "mem_use": 47.31, "gen_rate": 7.0, "speed": 1.42, "text": "In Europe, some of the best univ"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.3, "tree_w": 237, "tree_size": 512, "t0": 3.0733, "t1": 1.4167, "tft": 3.0897, "input_0": 1243, "input_1": 513, "min_CLP": -10.45, "draft_iters": 10.7, "mem_use": 47.0, "gen_rate": 6.3, "speed": 1.41, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 303, "tree_size": 512, "t0": 1.4888, "t1": 1.4237, "tft": 3.448, "input_0": 824, "input_1": 513, "min_CLP": -9.89, "draft_iters": 5.0, "mem_use": 47.14, "gen_rate": 4.0, "speed": 1.37, "text": "\"def markdown_to_html(text):\\n  "}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.8, "tree_w": 244, "tree_size": 512, "t0": 2.3388, "t1": 1.43, "tft": 4.5468, "input_0": 1048, "input_1": 513, "min_CLP": -7.82, "draft_iters": 7.9, "mem_use": 48.27, "gen_rate": 4.6, "speed": 1.23, "text": "1. Financial stress: Seeking fin"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 30, "tree_h": 7.8, "tree_w": 226, "tree_size": 512, "t0": 2.9525, "t1": 1.4175, "tft": 3.0919, "input_0": 1219, "input_1": 513, "min_CLP": -8.95, "draft_iters": 10.2, "mem_use": 47.0, "gen_rate": 7.5, "speed": 1.72, "text": "\"Hello! You can call me AI Assis"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.0, "tree_w": 178, "tree_size": 512, "t0": 4.985, "t1": 1.4425, "tft": 5.0887, "input_0": 1744, "input_1": 513, "min_CLP": -9.66, "draft_iters": 16.5, "mem_use": 49.67, "gen_rate": 8.0, "speed": 1.24, "text": "An example of when you might use"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.3, "tree_w": 283, "tree_size": 512, "t0": 2.2143, "t1": 1.4171, "tft": 3.4629, "input_0": 1016, "input_1": 513, "min_CLP": -9.15, "draft_iters": 7.6, "mem_use": 47.29, "gen_rate": 4.6, "speed": 1.26, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 296, "tree_size": 512, "t0": 1.5587, "t1": 1.42, "tft": 3.4527, "input_0": 862, "input_1": 513, "min_CLP": -11.4, "draft_iters": 5.1, "mem_use": 47.08, "gen_rate": 4.1, "speed": 1.39, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 293, "tree_size": 512, "t0": 1.6413, "t1": 1.44, "tft": 9.2907, "input_0": 974, "input_1": 513, "min_CLP": -11.58, "draft_iters": 5.4, "mem_use": 49.28, "gen_rate": 4.4, "speed": 1.42, "text": "Yes, here are some open source 2"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 309, "tree_size": 512, "t0": 1.5938, "t1": 1.4187, "tft": 3.4384, "input_0": 933, "input_1": 513, "min_CLP": -10.29, "draft_iters": 5.2, "mem_use": 47.07, "gen_rate": 4.2, "speed": 1.41, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 21, "tree_h": 3.2, "tree_w": 300, "tree_size": 512, "t0": 1.505, "t1": 1.4267, "tft": 3.8681, "input_0": 886, "input_1": 513, "min_CLP": -9.87, "draft_iters": 5.0, "mem_use": 47.78, "gen_rate": 3.5, "speed": 1.19, "text": "[INST] Ok, but is there a most e"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 256, "tree_size": 512, "t0": 2.4917, "t1": 1.4383, "tft": 4.6886, "input_0": 1092, "input_1": 513, "min_CLP": -9.46, "draft_iters": 9.0, "mem_use": 48.65, "gen_rate": 5.5, "speed": 1.4, "text": "1. m\u00eb (suffix): Pronounced /m\u025b/ "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.1, "tree_w": 254, "tree_size": 512, "t0": 2.1143, "t1": 1.42, "tft": 3.4913, "input_0": 1064, "input_1": 513, "min_CLP": -8.65, "draft_iters": 7.3, "mem_use": 47.33, "gen_rate": 4.6, "speed": 1.3, "text": "Once upon a time, there was a po"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 12.5, "tree_w": 194, "tree_size": 512, "t0": 4.56, "t1": 1.435, "tft": 5.2532, "input_0": 1581, "input_1": 513, "min_CLP": -9.83, "draft_iters": 15.2, "mem_use": 50.09, "gen_rate": 11.0, "speed": 1.83, "text": "\"I apologize for any inaccuracie"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 247, "tree_size": 512, "t0": 2.2386, "t1": 1.4129, "tft": 3.0884, "input_0": 1013, "input_1": 513, "min_CLP": -8.64, "draft_iters": 7.7, "mem_use": 47.04, "gen_rate": 4.9, "speed": 1.33, "text": "To format an URL in reStructured"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 270, "tree_size": 512, "t0": 2.48, "t1": 1.4386, "tft": 4.8131, "input_0": 1207, "input_1": 513, "min_CLP": -11.69, "draft_iters": 8.9, "mem_use": 49.05, "gen_rate": 5.1, "speed": 1.31, "text": "Here is an example code that set"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.3, "tree_w": 235, "tree_size": 512, "t0": 3.5067, "t1": 1.4117, "tft": 3.0756, "input_0": 1326, "input_1": 513, "min_CLP": -11.42, "draft_iters": 13.7, "mem_use": 47.02, "gen_rate": 5.7, "speed": 1.15, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.1, "tree_w": 246, "tree_size": 512, "t0": 2.1786, "t1": 1.4229, "tft": 3.7119, "input_0": 1008, "input_1": 513, "min_CLP": -7.91, "draft_iters": 7.4, "mem_use": 47.48, "gen_rate": 4.6, "speed": 1.27, "text": "\"The answer is not a simple yes "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 295, "tree_size": 512, "t0": 1.6025, "t1": 1.4775, "tft": 12.3879, "input_0": 906, "input_1": 513, "min_CLP": -9.15, "draft_iters": 5.2, "mem_use": 52.66, "gen_rate": 4.2, "speed": 1.38, "text": "\"Yes, I'd be happy to try my han"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 4.0, "tree_w": 268, "tree_size": 512, "t0": 1.8425, "t1": 1.4287, "tft": 4.0888, "input_0": 890, "input_1": 513, "min_CLP": -8.31, "draft_iters": 6.1, "mem_use": 47.85, "gen_rate": 5.0, "speed": 1.53, "text": "\"0 I'm not sure. I think it is a"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 151, "tree_size": 512, "t0": 4.2025, "t1": 1.44, "tft": 5.0935, "input_0": 1471, "input_1": 513, "min_CLP": -7.94, "draft_iters": 14.2, "mem_use": 49.71, "gen_rate": 8.5, "speed": 1.51, "text": "I understand that everyone has d"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 224, "tree_size": 512, "t0": 2.838, "t1": 1.426, "tft": 4.2473, "input_0": 1258, "input_1": 513, "min_CLP": -7.92, "draft_iters": 9.6, "mem_use": 48.08, "gen_rate": 7.0, "speed": 1.64, "text": "1. Economic downturn: A sudden d"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 150, "tree_size": 512, "t0": 4.2933, "t1": 1.41, "tft": 3.507, "input_0": 1616, "input_1": 513, "min_CLP": -7.89, "draft_iters": 15.0, "mem_use": 47.35, "gen_rate": 10.7, "speed": 1.87, "text": "\"Certainly! Here's an inspiratio"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.0, "tree_w": 274, "tree_size": 512, "t0": 2.2, "t1": 1.4414, "tft": 5.2468, "input_0": 1135, "input_1": 513, "min_CLP": -11.96, "draft_iters": 7.3, "mem_use": 49.83, "gen_rate": 5.1, "speed": 1.41, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.7, "tree_w": 269, "tree_size": 512, "t0": 2.0686, "t1": 1.4171, "tft": 3.7604, "input_0": 1088, "input_1": 513, "min_CLP": -9.67, "draft_iters": 6.7, "mem_use": 47.54, "gen_rate": 4.9, "speed": 1.39, "text": "\"What is the most cost effective"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 210, "tree_size": 512, "t0": 3.688, "t1": 1.442, "tft": 4.911, "input_0": 1459, "input_1": 513, "min_CLP": -13.9, "draft_iters": 13.0, "mem_use": 49.49, "gen_rate": 7.6, "speed": 1.48, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 218, "tree_size": 512, "t0": 3.804, "t1": 1.412, "tft": 3.0881, "input_0": 1530, "input_1": 513, "min_CLP": -9.45, "draft_iters": 13.6, "mem_use": 47.06, "gen_rate": 7.0, "speed": 1.34, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 253, "tree_size": 512, "t0": 2.2425, "t1": 1.425, "tft": 3.8607, "input_0": 948, "input_1": 513, "min_CLP": -10.31, "draft_iters": 8.4, "mem_use": 47.78, "gen_rate": 7.4, "speed": 2.01, "text": "\"The laws for nudity in Wyoming "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 142, "tree_size": 512, "t0": 3.9575, "t1": 1.4125, "tft": 3.7405, "input_0": 1531, "input_1": 513, "min_CLP": -7.27, "draft_iters": 13.8, "mem_use": 47.51, "gen_rate": 8.2, "speed": 1.54, "text": "You should drink plenty of water"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.7, "tree_w": 54, "tree_size": 512, "t0": 6.8267, "t1": 1.4067, "tft": 3.4499, "input_0": 2118, "input_1": 513, "min_CLP": -6.76, "draft_iters": 23.3, "mem_use": 47.1, "gen_rate": 11.0, "speed": 1.34, "text": "To code the snake game in C with"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.5, "tree_w": 123, "tree_size": 512, "t0": 4.9375, "t1": 1.4225, "tft": 4.2267, "input_0": 1897, "input_1": 513, "min_CLP": -7.91, "draft_iters": 15.8, "mem_use": 47.98, "gen_rate": 8.5, "speed": 1.34, "text": "\"To overcome the fear of looking"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.3, "tree_w": 249, "tree_size": 512, "t0": 2.65, "t1": 1.4383, "tft": 4.9136, "input_0": 1087, "input_1": 513, "min_CLP": -11.06, "draft_iters": 9.7, "mem_use": 49.58, "gen_rate": 6.7, "speed": 1.63, "text": "Certainly! Here is a list of som"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 229, "tree_size": 512, "t0": 3.79, "t1": 1.4133, "tft": 3.4882, "input_0": 1344, "input_1": 513, "min_CLP": -13.67, "draft_iters": 14.0, "mem_use": 47.22, "gen_rate": 12.7, "speed": 2.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 232, "tree_size": 512, "t0": 3.4967, "t1": 1.4133, "tft": 3.4611, "input_0": 1212, "input_1": 513, "min_CLP": -9.61, "draft_iters": 14.0, "mem_use": 47.13, "gen_rate": 12.3, "speed": 2.51, "text": "\"```js\\nconst { Client, Collecti"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 204, "tree_size": 512, "t0": 3.528, "t1": 1.414, "tft": 3.0875, "input_0": 1363, "input_1": 513, "min_CLP": -8.05, "draft_iters": 12.0, "mem_use": 47.02, "gen_rate": 6.6, "speed": 1.34, "text": "Yes, I am a capable language mod"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 214, "tree_size": 512, "t0": 3.466, "t1": 1.458, "tft": 6.1448, "input_0": 1351, "input_1": 513, "min_CLP": -9.18, "draft_iters": 12.6, "mem_use": 50.8, "gen_rate": 6.4, "speed": 1.3, "text": "The decision to use TypeScript i"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 3.0, "tree_w": 304, "tree_size": 512, "t0": 1.48, "t1": 1.416, "tft": 3.4736, "input_0": 826, "input_1": 513, "min_CLP": -10.98, "draft_iters": 5.0, "mem_use": 47.14, "gen_rate": 3.4, "speed": 1.17, "text": "The name of the fourth kid is Mi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.0, "tree_w": 169, "tree_size": 512, "t0": 3.3643, "t1": 1.4257, "tft": 4.2786, "input_0": 1304, "input_1": 513, "min_CLP": -7.72, "draft_iters": 11.3, "mem_use": 48.17, "gen_rate": 5.7, "speed": 1.19, "text": "You should never pay for experie"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 11.4, "tree_w": 191, "tree_size": 512, "t0": 3.888, "t1": 1.442, "tft": 5.2346, "input_0": 1505, "input_1": 513, "min_CLP": -8.38, "draft_iters": 14.4, "mem_use": 49.95, "gen_rate": 9.8, "speed": 1.84, "text": "Toasting bread depends on person"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 242, "tree_size": 512, "t0": 2.7133, "t1": 1.41, "tft": 3.4701, "input_0": 1234, "input_1": 513, "min_CLP": -10.04, "draft_iters": 9.0, "mem_use": 47.27, "gen_rate": 5.7, "speed": 1.37, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 9.5, "tree_w": 199, "tree_size": 512, "t0": 3.68, "t1": 1.42, "tft": 3.8547, "input_0": 1447, "input_1": 513, "min_CLP": -7.82, "draft_iters": 12.5, "mem_use": 47.78, "gen_rate": 5.0, "speed": 0.98, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 200, "tree_size": 512, "t0": 4.065, "t1": 1.4425, "tft": 4.9149, "input_0": 1571, "input_1": 513, "min_CLP": -10.95, "draft_iters": 13.5, "mem_use": 49.51, "gen_rate": 8.5, "speed": 1.54, "text": "As a high school student, here a"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 5.4, "tree_w": 261, "tree_size": 512, "t0": 2.3414, "t1": 1.4286, "tft": 4.0845, "input_0": 1140, "input_1": 513, "min_CLP": -9.88, "draft_iters": 7.6, "mem_use": 47.91, "gen_rate": 5.9, "speed": 1.55, "text": "The television was invented by s"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 20.4, "tree_w": 58, "tree_size": 512, "t0": 6.65, "t1": 1.446, "tft": 5.6065, "input_0": 2037, "input_1": 513, "min_CLP": -6.5, "draft_iters": 23.8, "mem_use": 50.24, "gen_rate": 8.0, "speed": 0.99, "text": "\"I'm glad I could help. Remember"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 237, "tree_size": 512, "t0": 2.8333, "t1": 1.43, "tft": 4.6322, "input_0": 1163, "input_1": 513, "min_CLP": -8.64, "draft_iters": 9.5, "mem_use": 48.56, "gen_rate": 6.0, "speed": 1.41, "text": "\"The reason for multiple days of"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 49, "tree_h": 5.4, "tree_w": 278, "tree_size": 512, "t0": 2.2062, "t1": 1.4187, "tft": 3.772, "input_0": 1116, "input_1": 513, "min_CLP": -8.78, "draft_iters": 7.4, "mem_use": 47.59, "gen_rate": 6.1, "speed": 1.69, "text": "I apologize for my earlier state"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 240, "tree_size": 512, "t0": 2.5986, "t1": 1.44, "tft": 4.891, "input_0": 1215, "input_1": 513, "min_CLP": -10.1, "draft_iters": 8.4, "mem_use": 49.38, "gen_rate": 4.9, "speed": 1.2, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.0, "tree_w": 138, "tree_size": 512, "t0": 5.6, "t1": 1.41, "tft": 3.4788, "input_0": 1740, "input_1": 513, "min_CLP": -7.74, "draft_iters": 19.3, "mem_use": 47.21, "gen_rate": 10.7, "speed": 1.52, "text": "Yes, it would be possible for yo"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 5.2, "tree_w": 254, "tree_size": 512, "t0": 2.205, "t1": 1.4175, "tft": 3.678, "input_0": 1006, "input_1": 513, "min_CLP": -8.29, "draft_iters": 7.5, "mem_use": 47.84, "gen_rate": 5.2, "speed": 1.45, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 254, "tree_size": 512, "t0": 2.64, "t1": 1.4133, "tft": 3.4997, "input_0": 1085, "input_1": 513, "min_CLP": -8.67, "draft_iters": 9.5, "mem_use": 47.31, "gen_rate": 5.7, "speed": 1.4, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 262, "tree_size": 512, "t0": 2.195, "t1": 1.415, "tft": 3.4895, "input_0": 914, "input_1": 513, "min_CLP": -9.64, "draft_iters": 8.4, "mem_use": 47.32, "gen_rate": 7.4, "speed": 2.04, "text": "10000000000000000000000000000000"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.2, "tree_w": 266, "tree_size": 512, "t0": 1.9425, "t1": 1.4187, "tft": 3.8151, "input_0": 966, "input_1": 513, "min_CLP": -8.37, "draft_iters": 6.5, "mem_use": 47.71, "gen_rate": 4.2, "speed": 1.27, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 220, "tree_size": 512, "t0": 3.658, "t1": 1.418, "tft": 3.7438, "input_0": 1453, "input_1": 513, "min_CLP": -8.53, "draft_iters": 13.4, "mem_use": 47.49, "gen_rate": 7.6, "speed": 1.5, "text": "Prime numbers are important beca"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.8, "tree_w": 213, "tree_size": 512, "t0": 3.662, "t1": 1.414, "tft": 3.4872, "input_0": 1411, "input_1": 513, "min_CLP": -10.25, "draft_iters": 12.4, "mem_use": 47.25, "gen_rate": 8.2, "speed": 1.62, "text": "\"Here's an example of how you co"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.3, "tree_w": 156, "tree_size": 512, "t0": 4.52, "t1": 1.41, "tft": 3.4272, "input_0": 1730, "input_1": 513, "min_CLP": -8.0, "draft_iters": 14.7, "mem_use": 47.1, "gen_rate": 11.7, "speed": 1.97, "text": "To improve your Wi-Fi coverage i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 8.8, "tree_w": 260, "tree_size": 512, "t0": 2.658, "t1": 1.42, "tft": 3.4639, "input_0": 1108, "input_1": 513, "min_CLP": -10.57, "draft_iters": 10.8, "mem_use": 47.13, "gen_rate": 8.6, "speed": 2.11, "text": "Certainly! Here\\'s a SPL program"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.2, "tree_w": 211, "tree_size": 512, "t0": 3.3917, "t1": 1.4167, "tft": 3.1153, "input_0": 1155, "input_1": 513, "min_CLP": -9.0, "draft_iters": 13.3, "mem_use": 47.05, "gen_rate": 6.0, "speed": 1.25, "text": "[INST] Write a whitepaper for ou"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 273, "tree_size": 512, "t0": 2.0457, "t1": 1.4271, "tft": 4.5434, "input_0": 995, "input_1": 513, "min_CLP": -9.21, "draft_iters": 7.0, "mem_use": 48.23, "gen_rate": 4.7, "speed": 1.36, "text": "\"In this case, you can use your "}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 10.7, "tree_w": 153, "tree_size": 512, "t0": 3.8857, "t1": 1.41, "tft": 3.0708, "input_0": 1451, "input_1": 513, "min_CLP": -8.32, "draft_iters": 13.4, "mem_use": 47.01, "gen_rate": 5.9, "speed": 1.11, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.0, "tree_w": 290, "tree_size": 512, "t0": 1.4411, "t1": 1.4189, "tft": 3.0994, "input_0": 808, "input_1": 513, "min_CLP": -9.25, "draft_iters": 4.9, "mem_use": 47.02, "gen_rate": 3.7, "speed": 1.28, "text": "I appreciate ChatGPT for its abi"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 207, "tree_size": 512, "t0": 3.57, "t1": 1.4133, "tft": 3.4978, "input_0": 1396, "input_1": 513, "min_CLP": -8.94, "draft_iters": 14.7, "mem_use": 47.33, "gen_rate": 13.7, "speed": 2.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.8, "tree_w": 273, "tree_size": 512, "t0": 2.51, "t1": 1.41, "tft": 3.0983, "input_0": 1245, "input_1": 513, "min_CLP": -10.94, "draft_iters": 8.7, "mem_use": 47.06, "gen_rate": 6.0, "speed": 1.53, "text": "Sure! To create a Malbolge progr"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 220, "tree_size": 512, "t0": 3.6333, "t1": 1.4133, "tft": 3.855, "input_0": 1411, "input_1": 513, "min_CLP": -10.78, "draft_iters": 14.7, "mem_use": 47.76, "gen_rate": 13.7, "speed": 2.71, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 200, "tree_size": 512, "t0": 4.725, "t1": 1.445, "tft": 5.6096, "input_0": 1591, "input_1": 513, "min_CLP": -8.77, "draft_iters": 18.5, "mem_use": 50.27, "gen_rate": 17.5, "speed": 2.83, "text": "The current date is 2023-02-06.\\"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.1, "tree_w": 269, "tree_size": 512, "t0": 2.2986, "t1": 1.4171, "tft": 3.7543, "input_0": 1040, "input_1": 513, "min_CLP": -9.83, "draft_iters": 7.6, "mem_use": 47.56, "gen_rate": 4.6, "speed": 1.23, "text": "Yes, there are some things that "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.0, "tree_w": 246, "tree_size": 512, "t0": 2.2214, "t1": 1.46, "tft": 4.7089, "input_0": 1035, "input_1": 513, "min_CLP": -8.17, "draft_iters": 7.3, "mem_use": 48.68, "gen_rate": 5.0, "speed": 1.36, "text": "\"Hello, dear Agent. What brings "}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.2, "tree_w": 295, "tree_size": 512, "t0": 1.5933, "t1": 1.4189, "tft": 3.7576, "input_0": 867, "input_1": 513, "min_CLP": -9.66, "draft_iters": 5.2, "mem_use": 47.55, "gen_rate": 3.7, "speed": 1.22, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.8, "tree_w": 229, "tree_size": 512, "t0": 3.245, "t1": 1.455, "tft": 5.606, "input_0": 1285, "input_1": 513, "min_CLP": -10.23, "draft_iters": 12.7, "mem_use": 50.45, "gen_rate": 5.7, "speed": 1.21, "text": "Sure! Here are some code example"}
