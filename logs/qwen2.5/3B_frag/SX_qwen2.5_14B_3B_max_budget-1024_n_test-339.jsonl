{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-3B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "1024", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 339, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-30 22:35:50", "date": "250330", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 152, "tree_size": 1024, "t0": 8.6633, "t1": 2.3367, "tft": 16.2005, "input_0": 4124, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 25.7, "mem_use": 50.07, "gen_rate": 12.0, "speed": 1.09, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 21.0, "tree_w": 136, "tree_size": 1024, "t0": 8.6767, "t1": 2.3367, "tft": 14.3023, "input_0": 3559, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 28.0, "mem_use": 51.61, "gen_rate": 10.7, "speed": 0.97, "text": "I apologize for the error. The f"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 17.2, "tree_w": 158, "tree_size": 1024, "t0": 8.655, "t1": 2.335, "tft": 14.071, "input_0": 3779, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 26.2, "mem_use": 52.51, "gen_rate": 11.5, "speed": 1.05, "text": "1. Minecraft: Minecraft is a pop"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 259, "tree_size": 1024, "t0": 9.06, "t1": 2.3067, "tft": 12.8283, "input_0": 4854, "input_1": 1025, "min_CLP": -10.57, "draft_iters": 24.0, "mem_use": 50.24, "gen_rate": 11.3, "speed": 1.0, "text": "```python\\ndef average_rate_of_c"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.3, "tree_w": 115, "tree_size": 1024, "t0": 9.8333, "t1": 2.3, "tft": 10.894, "input_0": 4340, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 27.3, "mem_use": 50.08, "gen_rate": 10.7, "speed": 0.88, "text": "\"Of course! I'd be happy to help"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.0, "tree_w": 166, "tree_size": 1024, "t0": 11.35, "t1": 2.3367, "tft": 16.7306, "input_0": 5563, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 30.3, "mem_use": 52.64, "gen_rate": 13.0, "speed": 0.95, "text": "Sure, here is a potential bullet"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.7, "tree_w": 132, "tree_size": 1024, "t0": 11.42, "t1": 2.3667, "tft": 16.178, "input_0": 5427, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 30.7, "mem_use": 53.24, "gen_rate": 11.7, "speed": 0.85, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 20.3, "tree_w": 123, "tree_size": 1024, "t0": 10.5733, "t1": 2.4, "tft": 18.7371, "input_0": 4994, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 31.0, "mem_use": 55.41, "gen_rate": 14.0, "speed": 1.08, "text": "Sure, let me break down some str"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 24.0, "tree_w": 111, "tree_size": 1024, "t0": 10.7933, "t1": 2.3367, "tft": 14.6076, "input_0": 4805, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 12.3, "speed": 0.94, "text": "Sure, here is a list of the lega"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.3, "tree_w": 120, "tree_size": 1024, "t0": 9.1433, "t1": 2.3433, "tft": 14.4152, "input_0": 4234, "input_1": 1025, "min_CLP": -7.29, "draft_iters": 26.0, "mem_use": 52.21, "gen_rate": 11.3, "speed": 0.99, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 26, "tree_h": 25.5, "tree_w": 129, "tree_size": 1024, "t0": 9.88, "t1": 2.33, "tft": 12.2217, "input_0": 3824, "input_1": 1025, "min_CLP": -9.21, "draft_iters": 32.0, "mem_use": 50.75, "gen_rate": 13.0, "speed": 1.06, "text": "``The first number is A.\\nRead A"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.5, "tree_w": 164, "tree_size": 1024, "t0": 9.2925, "t1": 2.3425, "tft": 15.7994, "input_0": 4332, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 26.2, "mem_use": 52.58, "gen_rate": 8.5, "speed": 0.73, "text": "Certainly! Here\\'s a shorter ver"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.0, "tree_w": 93, "tree_size": 1024, "t0": 12.045, "t1": 2.345, "tft": 15.1067, "input_0": 4724, "input_1": 1025, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 51.8, "gen_rate": 16.5, "speed": 1.15, "text": "Sure, here is an example python "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 105, "tree_size": 1024, "t0": 9.88, "t1": 2.31, "tft": 12.6338, "input_0": 3737, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 50.07, "gen_rate": 26.0, "speed": 2.13, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.5, "tree_w": 161, "tree_size": 1024, "t0": 8.3175, "t1": 2.365, "tft": 13.2126, "input_0": 3653, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 26.2, "mem_use": 53.21, "gen_rate": 9.0, "speed": 0.84, "text": "With limited time available, it "}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.3, "tree_w": 141, "tree_size": 1024, "t0": 9.41, "t1": 2.3067, "tft": 12.4424, "input_0": 4198, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 29.7, "mem_use": 50.4, "gen_rate": 12.7, "speed": 1.08, "text": "\"To ensure a smooth streaming ex"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 20.0, "tree_w": 99, "tree_size": 1024, "t0": 12.565, "t1": 2.305, "tft": 14.3677, "input_0": 5865, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 32.0, "mem_use": 50.08, "gen_rate": 21.0, "speed": 1.41, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.5, "tree_w": 136, "tree_size": 1024, "t0": 8.7325, "t1": 2.3, "tft": 11.0372, "input_0": 3516, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 27.0, "mem_use": 50.06, "gen_rate": 10.5, "speed": 0.95, "text": "def generate_java_hello_world():"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 22.5, "tree_w": 110, "tree_size": 1024, "t0": 9.63, "t1": 2.31, "tft": 13.2191, "input_0": 4110, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 30.5, "mem_use": 50.6, "gen_rate": 19.0, "speed": 1.59, "text": "D-theanine is another form of th"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 22.0, "tree_w": 94, "tree_size": 1024, "t0": 11.835, "t1": 2.32, "tft": 13.2274, "input_0": 5027, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 32.0, "mem_use": 50.07, "gen_rate": 17.5, "speed": 1.24, "text": "The Balfour Declaration was a pu"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 16.7, "tree_w": 272, "tree_size": 1024, "t0": 6.78, "t1": 2.3333, "tft": 12.2474, "input_0": 2653, "input_1": 1025, "min_CLP": -8.56, "draft_iters": 23.7, "mem_use": 50.92, "gen_rate": 3.3, "speed": 0.37, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 19.0, "tree_w": 225, "tree_size": 1024, "t0": 8.84, "t1": 2.3, "tft": 10.0788, "input_0": 4204, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 28.0, "mem_use": 50.07, "gen_rate": 11.0, "speed": 0.99, "text": "Hello there Obi-Wan Kenobi! How "}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 21.5, "tree_w": 110, "tree_size": 1024, "t0": 10.6575, "t1": 2.3275, "tft": 15.4333, "input_0": 5065, "input_1": 1025, "min_CLP": -7.23, "draft_iters": 31.2, "mem_use": 52.42, "gen_rate": 12.2, "speed": 0.94, "text": "Given that your dataset has an a"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 17.6, "tree_w": 130, "tree_size": 1024, "t0": 8.658, "t1": 2.308, "tft": 10.671, "input_0": 3819, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 26.2, "mem_use": 50.13, "gen_rate": 8.2, "speed": 0.75, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 19, "tree_h": 19.0, "tree_w": 158, "tree_size": 1024, "t0": 8.6725, "t1": 2.3275, "tft": 14.2755, "input_0": 3538, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 27.2, "mem_use": 51.11, "gen_rate": 4.8, "speed": 0.43, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 78, "tree_size": 1024, "t0": 11.21, "t1": 2.29, "tft": 12.3429, "input_0": 4534, "input_1": 1025, "min_CLP": -11.32, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 25.0, "speed": 1.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.2, "tree_w": 169, "tree_size": 1024, "t0": 7.3325, "t1": 2.315, "tft": 13.8672, "input_0": 3288, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 22.2, "mem_use": 50.78, "gen_rate": 8.5, "speed": 0.88, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 20.0, "tree_w": 174, "tree_size": 1024, "t0": 10.92, "t1": 2.31, "tft": 12.9372, "input_0": 4787, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 32.0, "mem_use": 50.63, "gen_rate": 8.0, "speed": 0.6, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 270, "tree_size": 1024, "t0": 6.42, "t1": 2.33, "tft": 12.7131, "input_0": 3168, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 20.4, "mem_use": 52.57, "gen_rate": 7.6, "speed": 0.87, "text": "\"(Verse 1)\\nIn a land of magic a"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 140, "tree_size": 1024, "t0": 9.815, "t1": 2.305, "tft": 10.9228, "input_0": 3975, "input_1": 1025, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 26.0, "speed": 2.14, "text": "## [INST] <<SYS>>\\nYou are a hel"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.5, "tree_w": 73, "tree_size": 1024, "t0": 11.25, "t1": 2.33, "tft": 14.7732, "input_0": 4704, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 50.82, "gen_rate": 16.0, "speed": 1.18, "text": "\"Yes, that's correct. Into the B"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.5, "tree_w": 132, "tree_size": 1024, "t0": 10.45, "t1": 2.33, "tft": 12.3507, "input_0": 4651, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 32.0, "mem_use": 51.23, "gen_rate": 16.5, "speed": 1.29, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 198, "tree_size": 1024, "t0": 7.1325, "t1": 2.3075, "tft": 10.0681, "input_0": 3372, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 22.2, "mem_use": 50.58, "gen_rate": 9.8, "speed": 1.03, "text": "Freyja, the great goddess of lov"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.4, "tree_w": 192, "tree_size": 1024, "t0": 7.468, "t1": 2.344, "tft": 11.9191, "input_0": 3571, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 23.2, "mem_use": 52.23, "gen_rate": 6.4, "speed": 0.65, "text": "\"You can make a cheese substitut"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 18.7, "tree_w": 148, "tree_size": 1024, "t0": 10.0733, "t1": 2.3433, "tft": 12.8793, "input_0": 4874, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 29.3, "mem_use": 52.27, "gen_rate": 12.3, "speed": 0.99, "text": "\"It's important to consider a fe"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 17.0, "tree_w": 144, "tree_size": 1024, "t0": 9.1133, "t1": 2.4133, "tft": 18.6851, "input_0": 4423, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 26.7, "mem_use": 55.0, "gen_rate": 12.3, "speed": 1.07, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 22.0, "tree_w": 115, "tree_size": 1024, "t0": 10.9, "t1": 2.31, "tft": 11.8279, "input_0": 5359, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 32.0, "mem_use": 50.1, "gen_rate": 11.0, "speed": 0.83, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 22.3, "tree_w": 131, "tree_size": 1024, "t0": 9.2867, "t1": 2.3033, "tft": 13.0127, "input_0": 3759, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 30.0, "mem_use": 50.63, "gen_rate": 12.0, "speed": 1.04, "text": "I apologize, but I don\\'t have i"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 18.2, "tree_w": 147, "tree_size": 1024, "t0": 9.1, "t1": 2.345, "tft": 13.6021, "input_0": 4211, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 27.5, "mem_use": 53.0, "gen_rate": 9.5, "speed": 0.83, "text": "\"Sure, I can try to act like I h"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 19.4, "tree_w": 142, "tree_size": 1024, "t0": 9.176, "t1": 2.324, "tft": 15.364, "input_0": 4212, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 28.2, "mem_use": 51.03, "gen_rate": 7.6, "speed": 0.66, "text": "The Copenhagen interpretation of"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 235, "tree_size": 1024, "t0": 6.046, "t1": 2.306, "tft": 9.7348, "input_0": 2866, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 17.8, "mem_use": 50.32, "gen_rate": 7.6, "speed": 0.91, "text": "My power is not to be trifled wi"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 69, "tree_size": 1024, "t0": 11.72, "t1": 2.34, "tft": 13.246, "input_0": 4501, "input_1": 1025, "min_CLP": -11.02, "draft_iters": 32.0, "mem_use": 52.82, "gen_rate": 24.5, "speed": 1.74, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 137, "tree_size": 1024, "t0": 10.31, "t1": 2.345, "tft": 12.4651, "input_0": 4056, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 32.0, "mem_use": 53.26, "gen_rate": 25.0, "speed": 1.98, "text": "\"[INST] Certainly! It sounds lik"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 15.8, "tree_w": 249, "tree_size": 1024, "t0": 8.815, "t1": 2.3425, "tft": 13.7136, "input_0": 4534, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 25.0, "mem_use": 51.6, "gen_rate": 12.2, "speed": 1.1, "text": "It\\'s difficult to determine whi"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.5, "tree_w": 250, "tree_size": 1024, "t0": 7.7525, "t1": 2.3175, "tft": 14.8292, "input_0": 3184, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 26.0, "mem_use": 50.85, "gen_rate": 10.5, "speed": 1.04, "text": "You\\'re welcome! Let me know if "}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 20.6, "tree_w": 237, "tree_size": 1024, "t0": 7.5186, "t1": 2.3071, "tft": 12.2604, "input_0": 2636, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 27.0, "mem_use": 50.59, "gen_rate": 5.3, "speed": 0.54, "text": "o\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 20.0, "tree_w": 102, "tree_size": 1024, "t0": 11.7033, "t1": 2.29, "tft": 12.2753, "input_0": 5319, "input_1": 1025, "min_CLP": -7.17, "draft_iters": 31.7, "mem_use": 50.1, "gen_rate": 13.3, "speed": 0.95, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.5, "tree_w": 91, "tree_size": 1024, "t0": 11.175, "t1": 2.405, "tft": 17.5356, "input_0": 4789, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 32.0, "mem_use": 55.55, "gen_rate": 16.0, "speed": 1.18, "text": "\"Absolutely! Here's a revised ve"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 307, "tree_size": 1024, "t0": 5.512, "t1": 2.334, "tft": 11.1375, "input_0": 2716, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 16.4, "mem_use": 51.84, "gen_rate": 7.0, "speed": 0.89, "text": "\"Yes, yes, I know it sounds insa"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 17.6, "tree_w": 224, "tree_size": 1024, "t0": 7.408, "t1": 2.314, "tft": 6.6254, "input_0": 2973, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 25.0, "mem_use": 50.84, "gen_rate": 6.6, "speed": 0.68, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 16.0, "tree_w": 170, "tree_size": 1024, "t0": 8.2, "t1": 2.3, "tft": 10.5359, "input_0": 3635, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 25.0, "mem_use": 50.37, "gen_rate": 16.0, "speed": 1.52, "text": "\u70b9\u51fb\u7387\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u9886\u57df\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002\\n[I"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 21.0, "tree_w": 122, "tree_size": 1024, "t0": 11.605, "t1": 2.345, "tft": 15.6899, "input_0": 5652, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 32.0, "mem_use": 52.27, "gen_rate": 22.0, "speed": 1.58, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 18.8, "tree_w": 170, "tree_size": 1024, "t0": 9.002, "t1": 2.334, "tft": 15.7807, "input_0": 4062, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 27.6, "mem_use": 51.48, "gen_rate": 7.6, "speed": 0.67, "text": "Here are some more historical ev"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.3, "tree_w": 125, "tree_size": 1024, "t0": 9.8433, "t1": 2.3367, "tft": 13.3883, "input_0": 4176, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 31.0, "mem_use": 51.82, "gen_rate": 11.7, "speed": 0.96, "text": "I appreciate your question. Whil"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 12.7, "tree_w": 188, "tree_size": 1024, "t0": 7.3017, "t1": 2.3033, "tft": 9.1168, "input_0": 3600, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 21.0, "mem_use": 50.27, "gen_rate": 5.8, "speed": 0.61, "text": "\"In real life, people of all gen"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.0, "tree_w": 185, "tree_size": 1024, "t0": 7.2825, "t1": 2.33, "tft": 14.8889, "input_0": 3156, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 22.5, "mem_use": 52.67, "gen_rate": 8.2, "speed": 0.86, "text": "Title: FullView.IO - Your All-in"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 19.5, "tree_w": 158, "tree_size": 1024, "t0": 8.71, "t1": 2.36, "tft": 14.5179, "input_0": 3749, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 27.8, "mem_use": 53.93, "gen_rate": 10.8, "speed": 0.97, "text": "\"You're absolutely right, I apol"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.3, "tree_w": 277, "tree_size": 1024, "t0": 7.13, "t1": 2.33, "tft": 14.6724, "input_0": 3778, "input_1": 1025, "min_CLP": -8.75, "draft_iters": 21.7, "mem_use": 54.1, "gen_rate": 11.0, "speed": 1.16, "text": "Keras is indeed a great choice f"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.7, "tree_w": 144, "tree_size": 1024, "t0": 8.8033, "t1": 2.4367, "tft": 14.3775, "input_0": 3680, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 29.0, "mem_use": 51.75, "gen_rate": 13.0, "speed": 1.16, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 17.0, "tree_w": 132, "tree_size": 1024, "t0": 8.6025, "t1": 2.2975, "tft": 11.4594, "input_0": 3870, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 25.5, "mem_use": 50.09, "gen_rate": 9.8, "speed": 0.89, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 23.3, "tree_w": 149, "tree_size": 1024, "t0": 9.0733, "t1": 2.3233, "tft": 13.2156, "input_0": 3762, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 30.3, "mem_use": 52.5, "gen_rate": 15.0, "speed": 1.32, "text": "No.\\n[INST] Can you cook an egg "}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 15.4, "tree_w": 161, "tree_size": 1024, "t0": 8.42, "t1": 2.356, "tft": 14.1294, "input_0": 4083, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 24.6, "mem_use": 53.35, "gen_rate": 8.6, "speed": 0.8, "text": "[The scene opens with the Sparta"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 16.0, "tree_w": 245, "tree_size": 1024, "t0": 7.116, "t1": 2.318, "tft": 9.9115, "input_0": 2937, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 23.8, "mem_use": 51.04, "gen_rate": 6.6, "speed": 0.7, "text": "I see. How about this one instea"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.7, "tree_w": 198, "tree_size": 1024, "t0": 7.155, "t1": 2.3117, "tft": 13.4046, "input_0": 3264, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 21.7, "mem_use": 50.76, "gen_rate": 6.7, "speed": 0.7, "text": "The proof-of-stake concept works"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 25.3, "tree_w": 223, "tree_size": 1024, "t0": 8.5367, "t1": 2.3233, "tft": 11.3474, "input_0": 2862, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 32.0, "mem_use": 50.88, "gen_rate": 12.7, "speed": 1.17, "text": "[INST] You didn\\'t answer my que"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.0, "tree_w": 142, "tree_size": 1024, "t0": 10.9733, "t1": 2.3567, "tft": 15.1778, "input_0": 5332, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 30.0, "mem_use": 52.96, "gen_rate": 13.3, "speed": 1.0, "text": "Void pointers are a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.8, "tree_w": 166, "tree_size": 1024, "t0": 7.5625, "t1": 2.3775, "tft": 13.7991, "input_0": 3572, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 22.5, "mem_use": 53.48, "gen_rate": 8.8, "speed": 0.88, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 19.7, "tree_w": 111, "tree_size": 1024, "t0": 10.05, "t1": 2.3367, "tft": 15.8952, "input_0": 4224, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 29.0, "mem_use": 52.68, "gen_rate": 12.7, "speed": 1.02, "text": "\"To implement Two-Factor Authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 23.7, "tree_w": 178, "tree_size": 1024, "t0": 9.93, "t1": 2.3033, "tft": 10.6259, "input_0": 4480, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 32.0, "mem_use": 50.5, "gen_rate": 15.7, "speed": 1.28, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.0, "tree_w": 148, "tree_size": 1024, "t0": 8.8467, "t1": 2.3033, "tft": 10.9943, "input_0": 3819, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 25.3, "mem_use": 50.09, "gen_rate": 12.0, "speed": 1.08, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.3, "tree_w": 151, "tree_size": 1024, "t0": 11.4433, "t1": 2.3267, "tft": 16.4407, "input_0": 5001, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 32.0, "mem_use": 52.92, "gen_rate": 13.0, "speed": 0.94, "text": "\"Certainly, here's an updated ta"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 22.5, "tree_w": 206, "tree_size": 1024, "t0": 7.8775, "t1": 2.2875, "tft": 10.4538, "input_0": 3073, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 30.0, "mem_use": 50.04, "gen_rate": 4.5, "speed": 0.44, "text": "Who made Berlin [?]\\nI do not ha"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 80, "tree_size": 1024, "t0": 11.68, "t1": 2.34, "tft": 12.3164, "input_0": 4710, "input_1": 1025, "min_CLP": -9.37, "draft_iters": 32.0, "mem_use": 52.38, "gen_rate": 24.0, "speed": 1.71, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.7, "tree_w": 109, "tree_size": 1024, "t0": 9.6533, "t1": 2.3333, "tft": 14.8594, "input_0": 4197, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 29.3, "mem_use": 52.23, "gen_rate": 13.0, "speed": 1.08, "text": "Certainly. While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.3, "tree_w": 133, "tree_size": 1024, "t0": 9.2767, "t1": 2.3, "tft": 10.75, "input_0": 4314, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 26.7, "mem_use": 50.06, "gen_rate": 13.0, "speed": 1.12, "text": "The origin of pornography can be"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 23.0, "tree_w": 169, "tree_size": 1024, "t0": 10.675, "t1": 2.305, "tft": 10.3879, "input_0": 4140, "input_1": 1025, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 50.37, "gen_rate": 22.5, "speed": 1.73, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 241, "tree_size": 1024, "t0": 6.302, "t1": 2.3, "tft": 9.9483, "input_0": 2949, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 18.2, "mem_use": 50.46, "gen_rate": 7.4, "speed": 0.86, "text": "The 5 second rule is not a scien"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 25.0, "tree_w": 177, "tree_size": 1024, "t0": 9.22, "t1": 2.3, "tft": 11.4529, "input_0": 3370, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 32.0, "mem_use": 50.18, "gen_rate": 0.0, "speed": 0.0, "text": "I have 5 eggs left."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.0, "tree_w": 97, "tree_size": 1024, "t0": 10.61, "t1": 2.31, "tft": 14.1353, "input_0": 4347, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 29.5, "mem_use": 50.93, "gen_rate": 17.5, "speed": 1.35, "text": "Sure! One of the most famous alg"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.0, "tree_w": 195, "tree_size": 1024, "t0": 8.2125, "t1": 2.305, "tft": 10.3671, "input_0": 3636, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 24.2, "mem_use": 50.5, "gen_rate": 10.0, "speed": 0.95, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 19.8, "tree_w": 138, "tree_size": 1024, "t0": 9.2675, "t1": 2.31, "tft": 11.2534, "input_0": 4027, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 28.2, "mem_use": 50.21, "gen_rate": 8.2, "speed": 0.71, "text": "Here\\'s a potential announcement"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.8, "tree_w": 152, "tree_size": 1024, "t0": 8.72, "t1": 2.31, "tft": 13.6918, "input_0": 4191, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 25.8, "mem_use": 50.82, "gen_rate": 8.0, "speed": 0.73, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.0, "tree_w": 120, "tree_size": 1024, "t0": 9.3967, "t1": 2.3433, "tft": 14.1529, "input_0": 4091, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 27.3, "mem_use": 51.87, "gen_rate": 11.7, "speed": 0.99, "text": "AI assistants can also be extrem"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 145, "tree_size": 1024, "t0": 9.33, "t1": 2.345, "tft": 14.4563, "input_0": 3260, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 52.89, "gen_rate": 27.0, "speed": 2.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.0, "tree_w": 145, "tree_size": 1024, "t0": 8.6825, "t1": 2.33, "tft": 13.1637, "input_0": 4025, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 26.0, "mem_use": 51.38, "gen_rate": 10.0, "speed": 0.91, "text": "The scp command is available on "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.0, "tree_w": 162, "tree_size": 1024, "t0": 11.09, "t1": 2.345, "tft": 13.766, "input_0": 4491, "input_1": 1025, "min_CLP": -8.29, "draft_iters": 32.0, "mem_use": 52.03, "gen_rate": 18.5, "speed": 1.38, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 15.3, "tree_w": 188, "tree_size": 1024, "t0": 7.4967, "t1": 2.3017, "tft": 11.4255, "input_0": 3623, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 23.7, "mem_use": 50.11, "gen_rate": 6.8, "speed": 0.7, "text": "It is not illegal to keep a foun"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 291, "tree_size": 1024, "t0": 7.9325, "t1": 2.3075, "tft": 5.4967, "input_0": 4133, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 22.2, "mem_use": 50.36, "gen_rate": 8.5, "speed": 0.83, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 25.0, "tree_w": 87, "tree_size": 1024, "t0": 9.6, "t1": 2.3, "tft": 10.5941, "input_0": 3411, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 32.0, "mem_use": 50.7, "gen_rate": 0.0, "speed": 0.0, "text": "Does the 5 second rule actually "}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 14.0, "tree_w": 297, "tree_size": 1024, "t0": 6.12, "t1": 2.31, "tft": 9.4044, "input_0": 2895, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 21.5, "mem_use": 50.38, "gen_rate": 4.5, "speed": 0.53, "text": "\"Thank you, I'm glad you liked i"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 149, "tree_size": 1024, "t0": 9.25, "t1": 2.305, "tft": 12.1921, "input_0": 3765, "input_1": 1025, "min_CLP": -9.41, "draft_iters": 32.0, "mem_use": 50.15, "gen_rate": 26.5, "speed": 2.29, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 22.7, "tree_w": 114, "tree_size": 1024, "t0": 10.9367, "t1": 2.2967, "tft": 11.8183, "input_0": 4793, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 32.0, "mem_use": 50.13, "gen_rate": 14.7, "speed": 1.11, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 21.0, "tree_w": 104, "tree_size": 1024, "t0": 9.87, "t1": 2.34, "tft": 15.7011, "input_0": 4248, "input_1": 1025, "min_CLP": -7.26, "draft_iters": 30.0, "mem_use": 51.86, "gen_rate": 10.7, "speed": 0.87, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 139, "tree_size": 1024, "t0": 9.94, "t1": 2.31, "tft": 11.0245, "input_0": 4101, "input_1": 1025, "min_CLP": -9.82, "draft_iters": 32.0, "mem_use": 50.12, "gen_rate": 25.5, "speed": 2.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 22.3, "tree_w": 93, "tree_size": 1024, "t0": 10.6767, "t1": 2.3033, "tft": 13.3707, "input_0": 4490, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 31.0, "mem_use": 50.43, "gen_rate": 12.0, "speed": 0.92, "text": "To write a first person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 148, "tree_size": 1024, "t0": 9.235, "t1": 2.3, "tft": 10.8822, "input_0": 3748, "input_1": 1025, "min_CLP": -9.45, "draft_iters": 32.0, "mem_use": 50.09, "gen_rate": 26.5, "speed": 2.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.6, "tree_w": 216, "tree_size": 1024, "t0": 6.834, "t1": 2.308, "tft": 8.6728, "input_0": 3279, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 21.4, "mem_use": 50.41, "gen_rate": 6.4, "speed": 0.7, "text": "To become one with the Force, yo"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 194, "tree_size": 1024, "t0": 7.006, "t1": 2.3, "tft": 10.7323, "input_0": 3223, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 20.4, "mem_use": 50.26, "gen_rate": 6.4, "speed": 0.69, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.7, "tree_w": 122, "tree_size": 1024, "t0": 9.57, "t1": 2.3033, "tft": 13.3459, "input_0": 4297, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 29.3, "mem_use": 50.51, "gen_rate": 13.0, "speed": 1.09, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 16.2, "tree_w": 160, "tree_size": 1024, "t0": 8.27, "t1": 2.355, "tft": 13.1648, "input_0": 3876, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 25.2, "mem_use": 53.37, "gen_rate": 6.7, "speed": 0.63, "text": "Certainly! One option you could "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.0, "tree_w": 166, "tree_size": 1024, "t0": 8.21, "t1": 2.3033, "tft": 11.2017, "input_0": 3617, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 26.3, "mem_use": 50.58, "gen_rate": 10.7, "speed": 1.01, "text": "Yes, it is reasonable to compens"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 14.7, "tree_w": 169, "tree_size": 1024, "t0": 8.13, "t1": 2.34, "tft": 12.8082, "input_0": 3792, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 23.7, "mem_use": 53.47, "gen_rate": 8.0, "speed": 0.76, "text": "Xin ch\u00e0o, t\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd \u1ea3o v"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 13.4, "tree_w": 308, "tree_size": 1024, "t0": 5.89, "t1": 2.3175, "tft": 10.502, "input_0": 2417, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 20.1, "mem_use": 50.94, "gen_rate": 4.5, "speed": 0.55, "text": "You were deceived, but you can b"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 23.3, "tree_w": 96, "tree_size": 1024, "t0": 11.0433, "t1": 2.3033, "tft": 13.0185, "input_0": 4241, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 50.46, "gen_rate": 11.7, "speed": 0.87, "text": "Sure! Here\\'s an example of how "}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 19.3, "tree_w": 130, "tree_size": 1024, "t0": 10.9, "t1": 2.34, "tft": 13.207, "input_0": 4571, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 30.7, "mem_use": 51.89, "gen_rate": 13.0, "speed": 0.98, "text": "The 10 most popular German rock "}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.0, "tree_w": 243, "tree_size": 1024, "t0": 6.63, "t1": 2.302, "tft": 10.2287, "input_0": 2996, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 20.6, "mem_use": 50.42, "gen_rate": 8.0, "speed": 0.9, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.7, "tree_w": 114, "tree_size": 1024, "t0": 10.94, "t1": 2.3467, "tft": 15.0962, "input_0": 5098, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 31.3, "mem_use": 52.43, "gen_rate": 11.7, "speed": 0.88, "text": "\"To acquire revenue from custome"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.3, "tree_w": 161, "tree_size": 1024, "t0": 8.62, "t1": 2.32, "tft": 9.9952, "input_0": 4196, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 25.0, "mem_use": 51.05, "gen_rate": 11.0, "speed": 1.01, "text": "Yes, I can simulate various imag"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.7, "tree_w": 102, "tree_size": 1024, "t0": 10.6633, "t1": 2.3067, "tft": 10.4629, "input_0": 4367, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 31.0, "mem_use": 50.58, "gen_rate": 15.7, "speed": 1.21, "text": "Certainly, I would be happy to h"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 19.0, "tree_w": 113, "tree_size": 1024, "t0": 9.3475, "t1": 2.3125, "tft": 11.9372, "input_0": 4275, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 28.0, "mem_use": 50.72, "gen_rate": 8.2, "speed": 0.71, "text": "There are many popular APIs, lib"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.0, "tree_w": 482, "tree_size": 1024, "t0": 4.7925, "t1": 2.34, "tft": 14.6677, "input_0": 2115, "input_1": 1025, "min_CLP": -9.43, "draft_iters": 15.1, "mem_use": 52.0, "gen_rate": 4.2, "speed": 0.6, "text": "\"Certainly! Here's a poem in Que"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.0, "tree_w": 162, "tree_size": 1024, "t0": 8.6975, "t1": 2.3, "tft": 12.1602, "input_0": 4136, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 25.2, "mem_use": 50.1, "gen_rate": 10.2, "speed": 0.93, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 18.0, "tree_w": 180, "tree_size": 1024, "t0": 7.762, "t1": 2.302, "tft": 11.3476, "input_0": 3498, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 25.8, "mem_use": 50.14, "gen_rate": 8.0, "speed": 0.8, "text": "The code has a syntax error. The"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 16.5, "tree_w": 193, "tree_size": 1024, "t0": 8.44, "t1": 2.33, "tft": 11.537, "input_0": 3752, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 26.0, "mem_use": 51.53, "gen_rate": 6.0, "speed": 0.56, "text": "\"Sure, I'll be happy to help! Wh"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 269, "tree_size": 1024, "t0": 7.655, "t1": 2.3125, "tft": 11.2135, "input_0": 3862, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 23.2, "mem_use": 50.74, "gen_rate": 8.2, "speed": 0.83, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.8, "tree_w": 204, "tree_size": 1024, "t0": 9.01, "t1": 2.315, "tft": 11.3984, "input_0": 4179, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 25.8, "mem_use": 50.87, "gen_rate": 11.0, "speed": 0.97, "text": "\"To create a Python program that"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.0, "tree_w": 156, "tree_size": 1024, "t0": 8.0075, "t1": 2.33, "tft": 14.2099, "input_0": 3591, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 24.0, "mem_use": 52.66, "gen_rate": 9.0, "speed": 0.87, "text": "\"As an AI language model, I cann"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 84, "tree_size": 1024, "t0": 12.565, "t1": 2.315, "tft": 10.7236, "input_0": 5246, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 32.0, "mem_use": 50.66, "gen_rate": 24.5, "speed": 1.65, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 21.0, "tree_w": 84, "tree_size": 1024, "t0": 12.31, "t1": 2.335, "tft": 15.42, "input_0": 5359, "input_1": 1025, "min_CLP": -7.25, "draft_iters": 32.0, "mem_use": 52.02, "gen_rate": 19.0, "speed": 1.3, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.8, "tree_w": 285, "tree_size": 1024, "t0": 6.3533, "t1": 2.295, "tft": 11.0271, "input_0": 2666, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 21.7, "mem_use": 50.08, "gen_rate": 6.0, "speed": 0.69, "text": "my name is aaron and i am a 21 y"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.8, "tree_w": 343, "tree_size": 1024, "t0": 4.9287, "t1": 2.3075, "tft": 9.2491, "input_0": 2515, "input_1": 1025, "min_CLP": -8.67, "draft_iters": 15.0, "mem_use": 50.3, "gen_rate": 4.1, "speed": 0.57, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 20.3, "tree_w": 150, "tree_size": 1024, "t0": 9.3633, "t1": 2.3033, "tft": 10.8, "input_0": 4304, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 29.7, "mem_use": 50.55, "gen_rate": 7.3, "speed": 0.63, "text": "\"Thanks! I'm here to help and pr"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 16.2, "tree_w": 252, "tree_size": 1024, "t0": 7.01, "t1": 2.3375, "tft": 11.4509, "input_0": 3425, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 23.0, "mem_use": 52.14, "gen_rate": 12.2, "speed": 1.31, "text": "\"Thou art the sun that shineth b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 20.5, "tree_w": 165, "tree_size": 1024, "t0": 8.265, "t1": 2.31, "tft": 11.7034, "input_0": 3250, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 28.0, "mem_use": 50.72, "gen_rate": 2.0, "speed": 0.19, "text": "<|answer|>"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 116, "tree_size": 1024, "t0": 10.63, "t1": 2.3, "tft": 12.186, "input_0": 4332, "input_1": 1025, "min_CLP": -10.37, "draft_iters": 32.0, "mem_use": 50.12, "gen_rate": 26.0, "speed": 2.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 89, "tree_size": 1024, "t0": 10.485, "t1": 2.305, "tft": 12.0044, "input_0": 4162, "input_1": 1025, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 50.1, "gen_rate": 25.0, "speed": 1.96, "text": "\"Presidents' Day, officially kno"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.5, "tree_w": 210, "tree_size": 1024, "t0": 7.1017, "t1": 2.3017, "tft": 10.5376, "input_0": 3435, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 20.8, "mem_use": 50.4, "gen_rate": 6.8, "speed": 0.73, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.0, "tree_w": 152, "tree_size": 1024, "t0": 8.04, "t1": 2.3233, "tft": 14.5834, "input_0": 3927, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 23.0, "mem_use": 51.21, "gen_rate": 11.0, "speed": 1.06, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.3, "tree_w": 282, "tree_size": 1024, "t0": 6.1867, "t1": 2.3083, "tft": 10.386, "input_0": 2803, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 19.0, "mem_use": 50.48, "gen_rate": 5.8, "speed": 0.69, "text": "Why were the Windows users so sa"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 25, "tree_h": 12.7, "tree_w": 195, "tree_size": 1024, "t0": 6.9933, "t1": 2.3067, "tft": 10.313, "input_0": 3098, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 20.3, "mem_use": 50.55, "gen_rate": 8.3, "speed": 0.9, "text": "Opie is a great name, thank you!"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 22.5, "tree_w": 90, "tree_size": 1024, "t0": 10.665, "t1": 2.3, "tft": 11.3692, "input_0": 4906, "input_1": 1025, "min_CLP": -7.31, "draft_iters": 31.5, "mem_use": 50.1, "gen_rate": 21.0, "speed": 1.62, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 249, "tree_size": 1024, "t0": 6.528, "t1": 2.312, "tft": 9.6709, "input_0": 3295, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 19.0, "mem_use": 50.79, "gen_rate": 6.8, "speed": 0.77, "text": "\"oh come on, are you serious? Te"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 71, "tree_size": 1024, "t0": 11.585, "t1": 2.31, "tft": 11.4948, "input_0": 4525, "input_1": 1025, "min_CLP": -13.45, "draft_iters": 32.0, "mem_use": 50.21, "gen_rate": 26.0, "speed": 1.87, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.3, "tree_w": 124, "tree_size": 1024, "t0": 9.22, "t1": 2.3167, "tft": 10.6204, "input_0": 3883, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 28.3, "mem_use": 51.45, "gen_rate": 11.3, "speed": 0.98, "text": "Yes, there are various movies an"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.7, "tree_w": 204, "tree_size": 1024, "t0": 8.3333, "t1": 2.3067, "tft": 9.7202, "input_0": 3587, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 25.0, "mem_use": 50.55, "gen_rate": 11.0, "speed": 1.03, "text": "\"I'm an AI assistant, I don't ha"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.0, "tree_w": 147, "tree_size": 1024, "t0": 8.63, "t1": 2.3333, "tft": 15.106, "input_0": 3948, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 26.0, "mem_use": 51.75, "gen_rate": 11.0, "speed": 1.0, "text": "I would recommend the Emerald La"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 15.7, "tree_w": 179, "tree_size": 1024, "t0": 7.77, "t1": 2.3033, "tft": 11.1719, "input_0": 3469, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 24.0, "mem_use": 50.5, "gen_rate": 6.2, "speed": 0.61, "text": "\"Open Assistant: \ud83d\udea8 Attention, Ch"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 18.8, "tree_w": 132, "tree_size": 1024, "t0": 9.4375, "t1": 2.31, "tft": 11.4599, "input_0": 3961, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 28.5, "mem_use": 50.39, "gen_rate": 12.0, "speed": 1.02, "text": "\"Certainly! Here's a diagram to "}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 20.5, "tree_w": 119, "tree_size": 1024, "t0": 10.565, "t1": 2.32, "tft": 13.5168, "input_0": 4601, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 31.5, "mem_use": 52.73, "gen_rate": 18.5, "speed": 1.44, "text": "The issue you are experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.0, "tree_w": 278, "tree_size": 1024, "t0": 6.7833, "t1": 2.3033, "tft": 12.4076, "input_0": 3557, "input_1": 1025, "min_CLP": -8.98, "draft_iters": 20.0, "mem_use": 50.08, "gen_rate": 12.0, "speed": 1.32, "text": "No, you cannot directly compile "}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 269, "tree_size": 1024, "t0": 6.184, "t1": 2.3, "tft": 10.2196, "input_0": 2765, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 18.8, "mem_use": 50.64, "gen_rate": 7.0, "speed": 0.83, "text": "The people who make games deserv"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.5, "tree_w": 208, "tree_size": 1024, "t0": 7.64, "t1": 2.2975, "tft": 10.4964, "input_0": 3317, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 24.5, "mem_use": 50.26, "gen_rate": 8.0, "speed": 0.8, "text": "The hot pan causes the pancakes "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 21.2, "tree_w": 148, "tree_size": 1024, "t0": 9.955, "t1": 2.2925, "tft": 11.8144, "input_0": 4516, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 30.8, "mem_use": 50.1, "gen_rate": 8.8, "speed": 0.71, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.7, "tree_w": 139, "tree_size": 1024, "t0": 9.2867, "t1": 2.33, "tft": 13.604, "input_0": 4380, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 28.3, "mem_use": 52.19, "gen_rate": 11.7, "speed": 1.0, "text": "\"It's possible that your friend "}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 19.2, "tree_w": 192, "tree_size": 1024, "t0": 7.835, "t1": 2.3033, "tft": 11.3483, "input_0": 3497, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 26.8, "mem_use": 50.06, "gen_rate": 5.8, "speed": 0.58, "text": "\"No, a thumb war is not violent."}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 20.1, "tree_w": 274, "tree_size": 1024, "t0": 6.9625, "t1": 2.2988, "tft": 12.8577, "input_0": 2832, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 27.0, "mem_use": 50.14, "gen_rate": 4.1, "speed": 0.45, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 16.5, "tree_w": 167, "tree_size": 1024, "t0": 8.6275, "t1": 2.3325, "tft": 13.9365, "input_0": 3905, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 25.5, "mem_use": 53.43, "gen_rate": 10.8, "speed": 0.98, "text": "As of my knowledge cutoff in 202"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.7, "tree_w": 135, "tree_size": 1024, "t0": 9.1567, "t1": 2.31, "tft": 12.8064, "input_0": 4555, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 27.0, "mem_use": 51.41, "gen_rate": 13.0, "speed": 1.13, "text": "I understand that you would like"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.3, "tree_w": 118, "tree_size": 1024, "t0": 9.3667, "t1": 2.3033, "tft": 10.8251, "input_0": 3878, "input_1": 1025, "min_CLP": -7.21, "draft_iters": 28.0, "mem_use": 50.35, "gen_rate": 12.0, "speed": 1.03, "text": "Certainly! To learn German, you "}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 19.2, "tree_w": 132, "tree_size": 1024, "t0": 8.81, "t1": 2.3, "tft": 11.5661, "input_0": 3819, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 27.4, "mem_use": 50.33, "gen_rate": 8.8, "speed": 0.79, "text": "A:\\nAs an AI language model, I c"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.0, "tree_w": 245, "tree_size": 1024, "t0": 7.155, "t1": 2.3025, "tft": 12.7358, "input_0": 3587, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 21.8, "mem_use": 50.1, "gen_rate": 8.8, "speed": 0.93, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 107, "tree_size": 1024, "t0": 9.71, "t1": 2.325, "tft": 12.0192, "input_0": 3433, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 32.0, "mem_use": 50.91, "gen_rate": 26.0, "speed": 2.16, "text": "[INST] Sorry, I will clarify. Pl"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 16.0, "tree_w": 251, "tree_size": 1024, "t0": 9.52, "t1": 2.31, "tft": 13.5902, "input_0": 4353, "input_1": 1025, "min_CLP": -9.44, "draft_iters": 24.0, "mem_use": 50.94, "gen_rate": 17.0, "speed": 1.44, "text": "\"Por supuesto, aqu\u00ed tienes las t"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 64, "tree_size": 1024, "t0": 12.41, "t1": 2.365, "tft": 14.9937, "input_0": 4612, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 32.0, "mem_use": 53.45, "gen_rate": 24.5, "speed": 1.66, "text": "Step 1 \u2014 Starting the TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 77, "tree_size": 1024, "t0": 11.575, "t1": 2.295, "tft": 11.4144, "input_0": 4520, "input_1": 1025, "min_CLP": -13.25, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 24.5, "speed": 1.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.5, "tree_w": 255, "tree_size": 1024, "t0": 6.85, "t1": 2.3, "tft": 10.0604, "input_0": 3073, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 23.0, "mem_use": 50.67, "gen_rate": 8.0, "speed": 0.87, "text": "Berlin is known for its producti"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 22.7, "tree_w": 73, "tree_size": 1024, "t0": 12.58, "t1": 2.3033, "tft": 12.6894, "input_0": 5776, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 32.0, "mem_use": 50.14, "gen_rate": 17.3, "speed": 1.16, "text": "Sure, here\\'s a simple script th"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 23.3, "tree_w": 74, "tree_size": 1024, "t0": 11.39, "t1": 2.3233, "tft": 13.6701, "input_0": 4536, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 32.0, "mem_use": 52.65, "gen_rate": 17.7, "speed": 1.29, "text": "## Vegetarian\\n Microwave Sausag"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 225, "tree_size": 1024, "t0": 6.985, "t1": 2.2975, "tft": 10.4901, "input_0": 3196, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 22.0, "mem_use": 50.06, "gen_rate": 8.2, "speed": 0.89, "text": "Answer: As an AI language model,"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.8, "tree_w": 305, "tree_size": 1024, "t0": 6.77, "t1": 2.3275, "tft": 13.2723, "input_0": 3822, "input_1": 1025, "min_CLP": -8.8, "draft_iters": 19.8, "mem_use": 52.32, "gen_rate": 8.8, "speed": 0.96, "text": "Here are some potential steps th"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 21.3, "tree_w": 150, "tree_size": 1024, "t0": 9.57, "t1": 2.3, "tft": 10.9835, "input_0": 4357, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 30.0, "mem_use": 50.07, "gen_rate": 11.0, "speed": 0.93, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.5, "tree_w": 368, "tree_size": 1024, "t0": 6.62, "t1": 2.29, "tft": 10.0826, "input_0": 2760, "input_1": 1025, "min_CLP": -9.05, "draft_iters": 22.5, "mem_use": 50.05, "gen_rate": 8.5, "speed": 0.95, "text": "Human: \u5973\u5b69\u4eec\u5728\u6cb3\u8fb9\u91ce\u9910\u3002\\n\\n\\nAssistant:"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 19.7, "tree_w": 130, "tree_size": 1024, "t0": 9.59, "t1": 2.3033, "tft": 11.4409, "input_0": 4426, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 28.7, "mem_use": 50.21, "gen_rate": 13.0, "speed": 1.09, "text": "\"I don't have personal experienc"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.0, "tree_w": 247, "tree_size": 1024, "t0": 7.4725, "t1": 2.3225, "tft": 13.4209, "input_0": 3600, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 22.2, "mem_use": 51.27, "gen_rate": 9.0, "speed": 0.92, "text": "While there were many advancemen"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 22.0, "tree_w": 106, "tree_size": 1024, "t0": 9.985, "t1": 2.295, "tft": 10.8416, "input_0": 4394, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 30.5, "mem_use": 50.16, "gen_rate": 16.0, "speed": 1.3, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 19.7, "tree_w": 158, "tree_size": 1024, "t0": 8.5967, "t1": 2.3, "tft": 11.0243, "input_0": 3623, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 28.3, "mem_use": 50.36, "gen_rate": 12.7, "speed": 1.16, "text": "In reStructuredText (RST) format"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 21.3, "tree_w": 108, "tree_size": 1024, "t0": 10.1033, "t1": 2.3067, "tft": 12.5796, "input_0": 4379, "input_1": 1025, "min_CLP": -7.16, "draft_iters": 30.3, "mem_use": 50.7, "gen_rate": 13.3, "speed": 1.07, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 250, "tree_size": 1024, "t0": 6.2383, "t1": 2.305, "tft": 11.663, "input_0": 3570, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 17.5, "mem_use": 50.25, "gen_rate": 5.5, "speed": 0.64, "text": "I am the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 21.5, "tree_w": 84, "tree_size": 1024, "t0": 11.925, "t1": 2.325, "tft": 13.5256, "input_0": 5392, "input_1": 1025, "min_CLP": -7.21, "draft_iters": 32.0, "mem_use": 51.47, "gen_rate": 22.0, "speed": 1.54, "text": "On a Windows machine, you can us"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.2, "tree_w": 249, "tree_size": 1024, "t0": 8.0525, "t1": 2.3075, "tft": 12.2492, "input_0": 3867, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 23.8, "mem_use": 50.14, "gen_rate": 9.0, "speed": 0.87, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 21.7, "tree_w": 102, "tree_size": 1024, "t0": 10.94, "t1": 2.3233, "tft": 14.601, "input_0": 4676, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 50.99, "gen_rate": 13.3, "speed": 1.01, "text": "\"Microwave ovens became a common"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 241, "tree_size": 1024, "t0": 7.3625, "t1": 2.2925, "tft": 11.652, "input_0": 3530, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 23.5, "mem_use": 50.25, "gen_rate": 8.8, "speed": 0.91, "text": " Pros:\\n1. Improved tolerance to"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 25.0, "tree_w": 143, "tree_size": 1024, "t0": 8.89, "t1": 2.28, "tft": 12.2701, "input_0": 3306, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 32.0, "mem_use": 50.08, "gen_rate": 2.0, "speed": 0.18, "text": "None of your business."}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.7, "tree_w": 133, "tree_size": 1024, "t0": 11.0233, "t1": 2.3767, "tft": 16.4983, "input_0": 5241, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 31.0, "mem_use": 54.38, "gen_rate": 11.3, "speed": 0.85, "text": "\"If your friends are not happy w"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 98, "tree_size": 1024, "t0": 11.36, "t1": 2.3, "tft": 9.6244, "input_0": 3906, "input_1": 1025, "min_CLP": -10.46, "draft_iters": 32.0, "mem_use": 50.39, "gen_rate": 26.0, "speed": 1.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.0, "tree_w": 163, "tree_size": 1024, "t0": 10.36, "t1": 2.3225, "tft": 6.8736, "input_0": 4852, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 28.8, "mem_use": 51.22, "gen_rate": 9.0, "speed": 0.71, "text": "It is not possible to determine "}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 14.9, "tree_w": 218, "tree_size": 1024, "t0": 6.6129, "t1": 2.3343, "tft": 11.4919, "input_0": 2955, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 21.9, "mem_use": 52.52, "gen_rate": 5.3, "speed": 0.59, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 12.5, "tree_w": 256, "tree_size": 1024, "t0": 6.095, "t1": 2.2983, "tft": 9.2521, "input_0": 2592, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 19.7, "mem_use": 50.36, "gen_rate": 5.0, "speed": 0.6, "text": "What did the broke college stude"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.5, "tree_w": 169, "tree_size": 1024, "t0": 8.135, "t1": 2.2975, "tft": 11.1962, "input_0": 3695, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 25.0, "mem_use": 50.4, "gen_rate": 9.0, "speed": 0.86, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 15.8, "tree_w": 153, "tree_size": 1024, "t0": 8.8725, "t1": 2.315, "tft": 13.3037, "input_0": 4221, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 25.0, "mem_use": 50.88, "gen_rate": 10.2, "speed": 0.92, "text": "\"There are several 3D animation "}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 142, "tree_size": 1024, "t0": 9.055, "t1": 2.3, "tft": 13.0026, "input_0": 3249, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 50.38, "gen_rate": 27.0, "speed": 2.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.8, "tree_w": 183, "tree_size": 1024, "t0": 7.444, "t1": 2.322, "tft": 11.7153, "input_0": 3604, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 22.0, "mem_use": 51.07, "gen_rate": 7.0, "speed": 0.72, "text": "The transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.0, "tree_w": 301, "tree_size": 1024, "t0": 6.214, "t1": 2.306, "tft": 10.337, "input_0": 3330, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 20.0, "mem_use": 50.4, "gen_rate": 7.8, "speed": 0.92, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 16.6, "tree_w": 142, "tree_size": 1024, "t0": 8.592, "t1": 2.298, "tft": 11.8255, "input_0": 3936, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 25.2, "mem_use": 50.13, "gen_rate": 9.2, "speed": 0.84, "text": "\"1. Environment: The environment"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 19.8, "tree_w": 194, "tree_size": 1024, "t0": 8.3683, "t1": 2.295, "tft": 11.1856, "input_0": 3426, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 27.7, "mem_use": 50.09, "gen_rate": 5.8, "speed": 0.55, "text": " [A]. Time dilation [B]. Illusio"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 25.7, "tree_w": 163, "tree_size": 1024, "t0": 9.5233, "t1": 2.38, "tft": 17.0517, "input_0": 3448, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 32.0, "mem_use": 54.37, "gen_rate": 18.0, "speed": 1.51, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 162, "tree_size": 1024, "t0": 8.1575, "t1": 2.3, "tft": 10.6449, "input_0": 3728, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 23.8, "mem_use": 50.22, "gen_rate": 8.0, "speed": 0.77, "text": "Javascript is commonly used in w"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 21.7, "tree_w": 103, "tree_size": 1024, "t0": 11.0, "t1": 2.33, "tft": 12.9905, "input_0": 4685, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 51.76, "gen_rate": 13.3, "speed": 1.0, "text": "Sure, F-centers can be produced "}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 20.0, "tree_w": 121, "tree_size": 1024, "t0": 10.4067, "t1": 2.3233, "tft": 6.9219, "input_0": 4926, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 30.3, "mem_use": 51.49, "gen_rate": 14.0, "speed": 1.1, "text": "In option 2, \"Use the Command Pr"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 16.8, "tree_w": 142, "tree_size": 1024, "t0": 9.4775, "t1": 2.2975, "tft": 12.6359, "input_0": 4711, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 27.2, "mem_use": 50.35, "gen_rate": 11.0, "speed": 0.93, "text": "\"To approach this problem using "}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.3, "tree_w": 133, "tree_size": 1024, "t0": 9.8967, "t1": 2.3, "tft": 11.2766, "input_0": 4495, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 28.0, "mem_use": 50.17, "gen_rate": 11.7, "speed": 0.96, "text": "The best method for extracting d"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 94, "tree_size": 1024, "t0": 10.985, "t1": 2.305, "tft": 12.358, "input_0": 4244, "input_1": 1025, "min_CLP": -11.58, "draft_iters": 32.0, "mem_use": 50.15, "gen_rate": 26.0, "speed": 1.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 19.3, "tree_w": 128, "tree_size": 1024, "t0": 9.9233, "t1": 2.3133, "tft": 12.4224, "input_0": 4734, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 29.3, "mem_use": 51.15, "gen_rate": 12.7, "speed": 1.03, "text": "\"I'm glad you're looking to impr"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.4, "tree_w": 277, "tree_size": 1024, "t0": 5.7329, "t1": 2.2957, "tft": 9.7297, "input_0": 2735, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 18.3, "mem_use": 50.49, "gen_rate": 5.3, "speed": 0.66, "text": "I will be giving you follow up q"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 21.5, "tree_w": 108, "tree_size": 1024, "t0": 11.73, "t1": 2.34, "tft": 14.4922, "input_0": 5261, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 32.0, "mem_use": 51.8, "gen_rate": 20.5, "speed": 1.46, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.7, "tree_w": 221, "tree_size": 1024, "t0": 6.64, "t1": 2.3117, "tft": 10.5085, "input_0": 2991, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 21.2, "mem_use": 50.72, "gen_rate": 6.2, "speed": 0.69, "text": "I think that one can draw the co"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 19.2, "tree_w": 211, "tree_size": 1024, "t0": 7.478, "t1": 2.3, "tft": 10.1323, "input_0": 2784, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 26.4, "mem_use": 50.56, "gen_rate": 6.4, "speed": 0.65, "text": "\"The ATF gunwalking scandal was "}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.5, "tree_w": 148, "tree_size": 1024, "t0": 8.94, "t1": 2.3, "tft": 12.0165, "input_0": 4119, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 26.0, "mem_use": 50.29, "gen_rate": 10.2, "speed": 0.91, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 60, "tree_size": 1024, "t0": 12.075, "t1": 2.34, "tft": 14.774, "input_0": 4520, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 32.0, "mem_use": 53.09, "gen_rate": 23.5, "speed": 1.63, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 63, "tree_size": 1024, "t0": 11.67, "t1": 2.35, "tft": 13.7582, "input_0": 4401, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 32.0, "mem_use": 53.03, "gen_rate": 26.0, "speed": 1.85, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 245, "tree_size": 1024, "t0": 6.402, "t1": 2.296, "tft": 10.9885, "input_0": 2921, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 18.8, "mem_use": 50.08, "gen_rate": 7.4, "speed": 0.85, "text": "The night is a canvas painted wi"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 22.5, "tree_w": 122, "tree_size": 1024, "t0": 11.51, "t1": 2.32, "tft": 14.4847, "input_0": 4712, "input_1": 1025, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 51.25, "gen_rate": 19.0, "speed": 1.37, "text": "Absolutely! Here\\'s the revised "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 21.0, "tree_w": 101, "tree_size": 1024, "t0": 9.555, "t1": 2.345, "tft": 13.5004, "input_0": 3728, "input_1": 1025, "min_CLP": -7.22, "draft_iters": 28.5, "mem_use": 51.7, "gen_rate": 16.5, "speed": 1.39, "text": "I apologize if my previous respo"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 23.0, "tree_w": 88, "tree_size": 1024, "t0": 11.34, "t1": 2.3, "tft": 12.4454, "input_0": 4840, "input_1": 1025, "min_CLP": -7.12, "draft_iters": 32.0, "mem_use": 50.07, "gen_rate": 20.0, "speed": 1.47, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.3, "tree_w": 349, "tree_size": 1024, "t0": 5.5383, "t1": 2.3, "tft": 9.8016, "input_0": 2835, "input_1": 1025, "min_CLP": -8.87, "draft_iters": 17.5, "mem_use": 50.36, "gen_rate": 5.8, "speed": 0.74, "text": "What? You think I, Freyja, would"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 19.0, "tree_w": 130, "tree_size": 1024, "t0": 10.75, "t1": 2.3333, "tft": 14.4923, "input_0": 4918, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 29.7, "mem_use": 51.95, "gen_rate": 12.7, "speed": 0.97, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 18.8, "tree_w": 162, "tree_size": 1024, "t0": 8.9025, "t1": 2.2975, "tft": 11.9572, "input_0": 3959, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 27.2, "mem_use": 50.3, "gen_rate": 9.5, "speed": 0.85, "text": "## Reasoning\\nA large learning m"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 180, "tree_size": 1024, "t0": 9.2033, "t1": 2.34, "tft": 13.0327, "input_0": 4516, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 27.0, "mem_use": 51.65, "gen_rate": 10.7, "speed": 0.92, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.7, "tree_w": 158, "tree_size": 1024, "t0": 8.3333, "t1": 2.2967, "tft": 11.4395, "input_0": 3961, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 25.3, "mem_use": 50.11, "gen_rate": 13.7, "speed": 1.29, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 86, "tree_size": 1024, "t0": 11.515, "t1": 2.295, "tft": 12.1993, "input_0": 4370, "input_1": 1025, "min_CLP": -11.72, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 24.0, "speed": 1.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 16.2, "tree_w": 232, "tree_size": 1024, "t0": 7.3075, "t1": 2.3125, "tft": 9.7733, "input_0": 3460, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 23.2, "mem_use": 50.75, "gen_rate": 11.0, "speed": 1.14, "text": "\"Okay, I'll try to do both!\\n\\nH"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.4, "tree_w": 273, "tree_size": 1024, "t0": 6.708, "t1": 2.318, "tft": 12.1314, "input_0": 2790, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 20.0, "mem_use": 50.99, "gen_rate": 6.6, "speed": 0.73, "text": "I apologize for the mistake. Her"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 17.8, "tree_w": 170, "tree_size": 1024, "t0": 8.1425, "t1": 2.295, "tft": 11.8364, "input_0": 3607, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 25.8, "mem_use": 50.09, "gen_rate": 11.0, "speed": 1.05, "text": "The AK47 is a type of assault ri"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.0, "tree_w": 136, "tree_size": 1024, "t0": 9.5367, "t1": 2.3, "tft": 11.9563, "input_0": 4255, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 27.7, "mem_use": 50.43, "gen_rate": 11.3, "speed": 0.96, "text": "\"To copy a directory from server"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.5, "tree_w": 108, "tree_size": 1024, "t0": 12.185, "t1": 2.425, "tft": 13.4834, "input_0": 4865, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 32.0, "mem_use": 51.82, "gen_rate": 23.0, "speed": 1.57, "text": "Statistical modeling is the proc"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.0, "tree_w": 142, "tree_size": 1024, "t0": 8.5725, "t1": 2.3075, "tft": 11.9823, "input_0": 3823, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 26.2, "mem_use": 50.41, "gen_rate": 10.0, "speed": 0.92, "text": "To start a successful gaming soc"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.2, "tree_w": 148, "tree_size": 1024, "t0": 9.9375, "t1": 2.3175, "tft": 12.5494, "input_0": 4525, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 28.8, "mem_use": 50.92, "gen_rate": 8.2, "speed": 0.67, "text": "\"While there's no harm in just l"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.7, "tree_w": 287, "tree_size": 1024, "t0": 6.1417, "t1": 2.305, "tft": 9.4983, "input_0": 2890, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 19.5, "mem_use": 50.56, "gen_rate": 6.0, "speed": 0.71, "text": "The only way to cheer them up is"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 15.3, "tree_w": 298, "tree_size": 1024, "t0": 6.6086, "t1": 2.3057, "tft": 11.4296, "input_0": 2672, "input_1": 1025, "min_CLP": -8.52, "draft_iters": 22.6, "mem_use": 50.67, "gen_rate": 4.7, "speed": 0.53, "text": "Can you write an episode of The "}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.8, "tree_w": 143, "tree_size": 1024, "t0": 8.635, "t1": 2.3025, "tft": 10.5933, "input_0": 3830, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 26.5, "mem_use": 50.07, "gen_rate": 8.8, "speed": 0.8, "text": "\"I'm not capable of having thoug"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.2, "tree_w": 239, "tree_size": 1024, "t0": 8.18, "t1": 2.3, "tft": 11.402, "input_0": 4079, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 22.8, "mem_use": 50.08, "gen_rate": 9.2, "speed": 0.88, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.8, "tree_w": 167, "tree_size": 1024, "t0": 8.87, "t1": 2.3075, "tft": 12.4481, "input_0": 3777, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 28.2, "mem_use": 50.62, "gen_rate": 8.2, "speed": 0.74, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 22.0, "tree_w": 88, "tree_size": 1024, "t0": 12.22, "t1": 2.305, "tft": 11.5152, "input_0": 5141, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 32.0, "mem_use": 50.38, "gen_rate": 17.0, "speed": 1.17, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 55, "tree_h": 26.5, "tree_w": 134, "tree_size": 1024, "t0": 9.245, "t1": 2.295, "tft": 11.4237, "input_0": 3291, "input_1": 1025, "min_CLP": -8.56, "draft_iters": 32.0, "mem_use": 50.16, "gen_rate": 27.5, "speed": 2.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.0, "tree_w": 167, "tree_size": 1024, "t0": 8.0067, "t1": 2.3033, "tft": 11.0237, "input_0": 3375, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.7, "mem_use": 50.13, "gen_rate": 11.3, "speed": 1.1, "text": "The stars are still there, but t"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.0, "tree_w": 214, "tree_size": 1024, "t0": 6.8733, "t1": 2.3083, "tft": 9.9476, "input_0": 3512, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 20.0, "mem_use": 50.69, "gen_rate": 6.7, "speed": 0.73, "text": "Yes, the image was chosen for it"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.8, "tree_w": 166, "tree_size": 1024, "t0": 8.245, "t1": 2.375, "tft": 13.4844, "input_0": 3725, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 23.8, "mem_use": 53.75, "gen_rate": 9.8, "speed": 0.92, "text": "\"I'm sorry, but using your neigh"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.4, "tree_w": 189, "tree_size": 1024, "t0": 7.206, "t1": 2.32, "tft": 11.1741, "input_0": 3496, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 21.6, "mem_use": 52.49, "gen_rate": 8.0, "speed": 0.84, "text": "\"Hello Mike, thank you for shari"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.5, "tree_w": 166, "tree_size": 1024, "t0": 8.3925, "t1": 2.305, "tft": 12.2222, "input_0": 3756, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.5, "mem_use": 50.75, "gen_rate": 10.2, "speed": 0.96, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.7, "tree_w": 133, "tree_size": 1024, "t0": 9.38, "t1": 2.3, "tft": 12.0207, "input_0": 3985, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 28.7, "mem_use": 50.08, "gen_rate": 10.7, "speed": 0.91, "text": "No, there are no completely free"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 17.0, "tree_w": 192, "tree_size": 1024, "t0": 7.6, "t1": 2.2975, "tft": 10.7257, "input_0": 3417, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 24.8, "mem_use": 50.07, "gen_rate": 5.0, "speed": 0.51, "text": "Yes, I can speak German. I can h"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.7, "tree_w": 105, "tree_size": 1024, "t0": 10.7267, "t1": 2.2933, "tft": 11.6664, "input_0": 5206, "input_1": 1025, "min_CLP": -7.11, "draft_iters": 30.0, "mem_use": 50.27, "gen_rate": 12.3, "speed": 0.95, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.3, "tree_w": 142, "tree_size": 1024, "t0": 9.1667, "t1": 2.3133, "tft": 11.2262, "input_0": 4190, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 27.7, "mem_use": 51.16, "gen_rate": 12.0, "speed": 1.05, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 244, "tree_size": 1024, "t0": 7.57, "t1": 2.335, "tft": 15.7128, "input_0": 3612, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 24.2, "mem_use": 51.75, "gen_rate": 8.5, "speed": 0.86, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 12.1, "tree_w": 293, "tree_size": 1024, "t0": 6.1443, "t1": 2.2971, "tft": 11.7668, "input_0": 2914, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 19.9, "mem_use": 50.13, "gen_rate": 4.6, "speed": 0.54, "text": "\"Sure, here are a few haikus:\\n\\"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 18.8, "tree_w": 268, "tree_size": 1024, "t0": 6.9367, "t1": 2.3017, "tft": 11.5741, "input_0": 2815, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 25.8, "mem_use": 50.5, "gen_rate": 5.7, "speed": 0.61, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n     /"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 11.3, "tree_w": 194, "tree_size": 1024, "t0": 7.05, "t1": 2.2967, "tft": 12.0101, "input_0": 3275, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 20.0, "mem_use": 50.08, "gen_rate": 6.3, "speed": 0.68, "text": "\"The polar bear's thick fur and "}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.8, "tree_w": 168, "tree_size": 1024, "t0": 8.775, "t1": 2.3025, "tft": 12.1084, "input_0": 3868, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 26.0, "mem_use": 50.44, "gen_rate": 9.5, "speed": 0.86, "text": "No, there is not a universally a"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 17.6, "tree_w": 155, "tree_size": 1024, "t0": 8.984, "t1": 2.298, "tft": 11.2509, "input_0": 4102, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 26.8, "mem_use": 50.36, "gen_rate": 8.6, "speed": 0.76, "text": "Sure, I can help with that. Can "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.2, "tree_w": 191, "tree_size": 1024, "t0": 7.144, "t1": 2.33, "tft": 11.7953, "input_0": 3381, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 21.2, "mem_use": 52.41, "gen_rate": 7.4, "speed": 0.78, "text": "Of course, my dear sous-chef! I "}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 21.0, "tree_w": 156, "tree_size": 1024, "t0": 8.8575, "t1": 2.2975, "tft": 11.0921, "input_0": 3520, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 29.5, "mem_use": 50.25, "gen_rate": 9.8, "speed": 0.87, "text": "\"Here's a drawing of a man using"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.8, "tree_w": 148, "tree_size": 1024, "t0": 8.2475, "t1": 2.335, "tft": 13.7326, "input_0": 3688, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 24.2, "mem_use": 53.12, "gen_rate": 8.8, "speed": 0.83, "text": "Once upon a time, in a faraway l"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 23.0, "tree_w": 114, "tree_size": 1024, "t0": 10.3767, "t1": 2.2933, "tft": 12.4408, "input_0": 4456, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 31.7, "mem_use": 50.12, "gen_rate": 15.0, "speed": 1.18, "text": "\"Sure, here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 21.7, "tree_w": 106, "tree_size": 1024, "t0": 11.5167, "t1": 2.2967, "tft": 12.9396, "input_0": 5270, "input_1": 1025, "min_CLP": -7.26, "draft_iters": 32.0, "mem_use": 50.08, "gen_rate": 17.0, "speed": 1.23, "text": "HTML (Hypertext Markup Language)"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 23.5, "tree_w": 69, "tree_size": 1024, "t0": 11.445, "t1": 2.3, "tft": 11.7895, "input_0": 4768, "input_1": 1025, "min_CLP": -7.11, "draft_iters": 32.0, "mem_use": 50.1, "gen_rate": 22.0, "speed": 1.6, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.0, "tree_w": 228, "tree_size": 1024, "t0": 6.5, "t1": 2.295, "tft": 10.6982, "input_0": 2907, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 20.3, "mem_use": 50.48, "gen_rate": 5.7, "speed": 0.64, "text": "\"Bliss\" is protected by copyrigh"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.8, "tree_w": 201, "tree_size": 1024, "t0": 7.414, "t1": 2.292, "tft": 11.8599, "input_0": 3062, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 24.0, "mem_use": 50.09, "gen_rate": 6.4, "speed": 0.66, "text": " [A]. the moisture from the firs"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 20.5, "tree_w": 97, "tree_size": 1024, "t0": 11.055, "t1": 2.315, "tft": 14.3217, "input_0": 4953, "input_1": 1025, "min_CLP": -7.09, "draft_iters": 31.0, "mem_use": 51.15, "gen_rate": 18.5, "speed": 1.38, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 155, "tree_size": 1024, "t0": 8.2, "t1": 2.3067, "tft": 9.1545, "input_0": 3874, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 24.0, "mem_use": 50.86, "gen_rate": 10.7, "speed": 1.02, "text": "\"If you're looking for a high-ra"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.2, "tree_w": 186, "tree_size": 1024, "t0": 8.03, "t1": 2.3125, "tft": 6.1833, "input_0": 3143, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 26.8, "mem_use": 50.68, "gen_rate": 8.8, "speed": 0.85, "text": "\"Yes, if everyone just pirates t"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.6, "tree_w": 257, "tree_size": 1024, "t0": 6.812, "t1": 2.316, "tft": 11.1644, "input_0": 3017, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 20.6, "mem_use": 51.43, "gen_rate": 6.4, "speed": 0.7, "text": "\"That's a great choice of style,"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 21.3, "tree_w": 175, "tree_size": 1024, "t0": 8.6667, "t1": 2.2967, "tft": 10.9125, "input_0": 3289, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 29.3, "mem_use": 50.07, "gen_rate": 7.3, "speed": 0.67, "text": "Here is an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 214, "tree_size": 1024, "t0": 6.955, "t1": 2.295, "tft": 9.2451, "input_0": 3425, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 20.8, "mem_use": 50.38, "gen_rate": 8.0, "speed": 0.86, "text": "Sure! In some languages, I am re"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 19.7, "tree_w": 142, "tree_size": 1024, "t0": 9.8367, "t1": 2.32, "tft": 12.9314, "input_0": 4556, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 28.7, "mem_use": 51.13, "gen_rate": 13.3, "speed": 1.1, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 28, "tree_h": 17.7, "tree_w": 178, "tree_size": 1024, "t0": 8.64, "t1": 2.2967, "tft": 9.3594, "input_0": 4366, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 26.7, "mem_use": 50.18, "gen_rate": 9.3, "speed": 0.85, "text": "\"I'm sorry, but I don't have eno"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 78, "tree_size": 1024, "t0": 10.29, "t1": 2.33, "tft": 16.1073, "input_0": 3903, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 32.0, "mem_use": 51.81, "gen_rate": 25.5, "speed": 2.02, "text": "Sure, here\\'s a modified version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 165, "tree_size": 1024, "t0": 9.025, "t1": 2.295, "tft": 12.311, "input_0": 3215, "input_1": 1025, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 50.13, "gen_rate": 26.0, "speed": 2.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 14.0, "tree_w": 275, "tree_size": 1024, "t0": 6.2, "t1": 2.3067, "tft": 11.9543, "input_0": 3025, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 20.3, "mem_use": 50.52, "gen_rate": 4.7, "speed": 0.55, "text": "Sure, here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 144, "tree_size": 1024, "t0": 8.2775, "t1": 2.3375, "tft": 13.8639, "input_0": 3722, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 24.8, "mem_use": 51.82, "gen_rate": 8.2, "speed": 0.78, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 16.0, "tree_w": 154, "tree_size": 1024, "t0": 8.465, "t1": 2.32, "tft": 13.6012, "input_0": 3672, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 24.8, "mem_use": 52.26, "gen_rate": 11.2, "speed": 1.04, "text": "Paul Allen has a collection of v"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.2, "tree_w": 174, "tree_size": 1024, "t0": 8.2175, "t1": 2.33, "tft": 12.19, "input_0": 3950, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 24.5, "mem_use": 51.7, "gen_rate": 9.2, "speed": 0.88, "text": "I apologize for the oversight. Y"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.5, "tree_w": 176, "tree_size": 1024, "t0": 8.8925, "t1": 2.3, "tft": 11.0371, "input_0": 3624, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 28.5, "mem_use": 50.16, "gen_rate": 10.0, "speed": 0.89, "text": "[Rationale] The task requires wr"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.8, "tree_w": 183, "tree_size": 1024, "t0": 7.1525, "t1": 2.305, "tft": 11.0749, "input_0": 3400, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 21.5, "mem_use": 50.79, "gen_rate": 9.2, "speed": 0.98, "text": "I\\'m not quite sure I understand"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.0, "tree_w": 103, "tree_size": 1024, "t0": 9.905, "t1": 2.29, "tft": 12.4822, "input_0": 4270, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 28.0, "mem_use": 50.19, "gen_rate": 17.5, "speed": 1.43, "text": "Here are some of the main method"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.4, "tree_w": 220, "tree_size": 1024, "t0": 7.066, "t1": 2.296, "tft": 11.9517, "input_0": 3112, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 22.6, "mem_use": 50.08, "gen_rate": 6.4, "speed": 0.68, "text": "\"A) Yes, because I drop food on "}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.0, "tree_w": 285, "tree_size": 1024, "t0": 6.156, "t1": 2.314, "tft": 11.2997, "input_0": 2960, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 20.0, "mem_use": 50.91, "gen_rate": 6.6, "speed": 0.78, "text": "\"[INST] You're welcome! If you h"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 17.8, "tree_w": 165, "tree_size": 1024, "t0": 8.2225, "t1": 2.3325, "tft": 13.5414, "input_0": 3912, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 25.8, "mem_use": 51.72, "gen_rate": 9.8, "speed": 0.92, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 16.2, "tree_w": 159, "tree_size": 1024, "t0": 8.6375, "t1": 2.3175, "tft": 15.2511, "input_0": 4218, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 25.2, "mem_use": 52.63, "gen_rate": 9.8, "speed": 0.89, "text": "Ah, the \"multi-track drifting\" s"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.0, "tree_w": 135, "tree_size": 1024, "t0": 10.5633, "t1": 2.3167, "tft": 14.3324, "input_0": 4762, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 30.3, "mem_use": 51.22, "gen_rate": 11.3, "speed": 0.88, "text": "\"Yes, it is theoretically possib"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 242, "tree_size": 1024, "t0": 5.982, "t1": 2.314, "tft": 11.1893, "input_0": 2751, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 17.2, "mem_use": 51.06, "gen_rate": 6.4, "speed": 0.77, "text": "\"Sunshine, you're my favorite,\\n"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 24.0, "tree_w": 85, "tree_size": 1024, "t0": 11.23, "t1": 2.3067, "tft": 13.8164, "input_0": 4335, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 32.0, "mem_use": 50.83, "gen_rate": 12.0, "speed": 0.89, "text": "In Japanese, \"love\" is \"\u611b\" (ai),"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 232, "tree_size": 1024, "t0": 7.18, "t1": 2.296, "tft": 10.2225, "input_0": 3181, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 22.4, "mem_use": 50.37, "gen_rate": 7.2, "speed": 0.76, "text": "Some of the top universities for"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.0, "tree_w": 132, "tree_size": 1024, "t0": 9.3267, "t1": 2.3033, "tft": 12.5068, "input_0": 4693, "input_1": 1025, "min_CLP": -7.28, "draft_iters": 26.7, "mem_use": 50.07, "gen_rate": 11.7, "speed": 1.0, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 23.0, "tree_w": 102, "tree_size": 1024, "t0": 10.81, "t1": 2.295, "tft": 11.8662, "input_0": 4727, "input_1": 1025, "min_CLP": -7.22, "draft_iters": 32.0, "mem_use": 50.19, "gen_rate": 17.0, "speed": 1.3, "text": "```cpp\\n#include <string>\\n#incl"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.8, "tree_w": 163, "tree_size": 1024, "t0": 7.9975, "t1": 2.3175, "tft": 11.7083, "input_0": 3712, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 23.8, "mem_use": 51.32, "gen_rate": 8.8, "speed": 0.85, "text": "There are several ways to addres"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 18.0, "tree_w": 175, "tree_size": 1024, "t0": 8.16, "t1": 2.2933, "tft": 10.6075, "input_0": 3489, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 26.7, "mem_use": 50.06, "gen_rate": 8.0, "speed": 0.77, "text": "\" Hello! I am an AI language mod"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.0, "tree_w": 137, "tree_size": 1024, "t0": 10.9967, "t1": 2.32, "tft": 7.8272, "input_0": 4888, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 30.3, "mem_use": 52.69, "gen_rate": 13.7, "speed": 1.03, "text": "\"One example of where you might "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 19.5, "tree_w": 138, "tree_size": 1024, "t0": 9.215, "t1": 2.3, "tft": 10.983, "input_0": 4431, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 28.5, "mem_use": 50.35, "gen_rate": 16.5, "speed": 1.43, "text": "\"Yes, I can help you with that. "}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.0, "tree_w": 249, "tree_size": 1024, "t0": 6.456, "t1": 2.298, "tft": 11.4331, "input_0": 2528, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 20.8, "mem_use": 50.14, "gen_rate": 7.2, "speed": 0.82, "text": "the windows XP background image "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 18.5, "tree_w": 202, "tree_size": 1024, "t0": 8.6233, "t1": 2.31, "tft": 15.6474, "input_0": 3658, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 27.2, "mem_use": 52.32, "gen_rate": 6.0, "speed": 0.55, "text": "Certainly! Here are some open so"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.0, "tree_w": 111, "tree_size": 1024, "t0": 10.3033, "t1": 2.2967, "tft": 13.5979, "input_0": 4530, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 29.3, "mem_use": 50.13, "gen_rate": 10.7, "speed": 0.85, "text": "To use software defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.2, "tree_w": 218, "tree_size": 1024, "t0": 7.965, "t1": 2.315, "tft": 11.9119, "input_0": 3129, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 26.8, "mem_use": 50.84, "gen_rate": 8.0, "speed": 0.78, "text": "\"No, there isn't. The Unus Annus"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 22.6, "tree_w": 145, "tree_size": 1024, "t0": 10.488, "t1": 2.328, "tft": 13.9788, "input_0": 4137, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 31.4, "mem_use": 51.7, "gen_rate": 9.4, "speed": 0.73, "text": "1. m\u00eb (suffix) is pronounced as "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.0, "tree_w": 160, "tree_size": 1024, "t0": 9.1533, "t1": 2.3, "tft": 9.3009, "input_0": 4065, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 27.0, "mem_use": 50.38, "gen_rate": 12.7, "speed": 1.11, "text": "Alright, let me tell you a story"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 24.0, "tree_w": 83, "tree_size": 1024, "t0": 10.78, "t1": 2.3533, "tft": 14.7181, "input_0": 4654, "input_1": 1025, "min_CLP": -7.26, "draft_iters": 32.0, "mem_use": 53.15, "gen_rate": 14.0, "speed": 1.07, "text": "\"I apologize for any confusion c"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.0, "tree_w": 142, "tree_size": 1024, "t0": 9.0733, "t1": 2.2967, "tft": 11.7589, "input_0": 4667, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 27.0, "mem_use": 50.09, "gen_rate": 11.0, "speed": 0.97, "text": "Certainly! In reStructuredText ("}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 21.5, "tree_w": 75, "tree_size": 1024, "t0": 12.48, "t1": 2.335, "tft": 15.4618, "input_0": 5505, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 32.0, "mem_use": 52.1, "gen_rate": 19.0, "speed": 1.28, "text": "To set up a window for your game"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 25.0, "tree_w": 137, "tree_size": 1024, "t0": 9.6, "t1": 2.29, "tft": 13.3, "input_0": 3431, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 50.07, "gen_rate": 4.0, "speed": 0.34, "text": "None of the above."}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 273, "tree_size": 1024, "t0": 5.5633, "t1": 2.3, "tft": 8.6514, "input_0": 2610, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 16.3, "mem_use": 50.54, "gen_rate": 5.8, "speed": 0.74, "text": "AI assistants will probably take"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 277, "tree_size": 1024, "t0": 5.69, "t1": 2.396, "tft": 17.6959, "input_0": 2679, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 18.4, "mem_use": 55.7, "gen_rate": 6.4, "speed": 0.79, "text": "\"Certainly! Here's a new song ab"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.2, "tree_w": 262, "tree_size": 1024, "t0": 6.03, "t1": 2.312, "tft": 11.7874, "input_0": 2781, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 17.6, "mem_use": 50.9, "gen_rate": 6.8, "speed": 0.82, "text": "0 They are independent and not p"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.2, "tree_w": 151, "tree_size": 1024, "t0": 8.096, "t1": 2.336, "tft": 14.0863, "input_0": 4086, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 23.8, "mem_use": 52.76, "gen_rate": 7.8, "speed": 0.75, "text": "As a business professional, I un"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 236, "tree_size": 1024, "t0": 6.71, "t1": 2.312, "tft": 11.8218, "input_0": 3117, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 20.6, "mem_use": 51.13, "gen_rate": 7.0, "speed": 0.78, "text": "1. Economic downturn: If there i"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 2, "tree_h": 26.0, "tree_w": 171, "tree_size": 1024, "t0": 8.48, "t1": 2.3, "tft": 11.513, "input_0": 3219, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 32.0, "mem_use": 50.41, "gen_rate": 2.0, "speed": 0.19, "text": "<INST>"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 15.0, "tree_w": 258, "tree_size": 1024, "t0": 8.33, "t1": 2.3367, "tft": 17.634, "input_0": 4197, "input_1": 1025, "min_CLP": -9.14, "draft_iters": 23.0, "mem_use": 52.88, "gen_rate": 14.7, "speed": 1.37, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 20.2, "tree_w": 164, "tree_size": 1024, "t0": 8.51, "t1": 2.3075, "tft": 11.4515, "input_0": 3630, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 28.2, "mem_use": 50.59, "gen_rate": 9.0, "speed": 0.83, "text": "[Answer]\\nAs an AI language mode"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 21.3, "tree_w": 107, "tree_size": 1024, "t0": 11.2767, "t1": 2.3233, "tft": 17.1939, "input_0": 5375, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 52.55, "gen_rate": 11.0, "speed": 0.81, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.2, "tree_w": 165, "tree_size": 1024, "t0": 8.7725, "t1": 2.2925, "tft": 12.8149, "input_0": 4119, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 26.8, "mem_use": 50.11, "gen_rate": 8.2, "speed": 0.75, "text": "Sure! Below is an implementation"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 184, "tree_size": 1024, "t0": 7.0533, "t1": 2.3, "tft": 10.8807, "input_0": 2862, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 21.3, "mem_use": 50.84, "gen_rate": 10.7, "speed": 1.14, "text": "[INST] Who is responsible for es"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 19.2, "tree_w": 154, "tree_size": 1024, "t0": 8.5075, "t1": 2.305, "tft": 10.9402, "input_0": 3541, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 27.2, "mem_use": 50.56, "gen_rate": 12.0, "speed": 1.11, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 337, "tree_size": 1024, "t0": 5.56, "t1": 2.3, "tft": 5.5565, "input_0": 2999, "input_1": 1025, "min_CLP": -10.26, "draft_iters": 20.0, "mem_use": 50.12, "gen_rate": 16.0, "speed": 2.04, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.7, "tree_w": 138, "tree_size": 1024, "t0": 8.99, "t1": 2.3167, "tft": 12.0266, "input_0": 4055, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 27.7, "mem_use": 51.04, "gen_rate": 10.7, "speed": 0.94, "text": "\"Overcoming the fear of looking "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 63, "tree_size": 1024, "t0": 11.405, "t1": 2.34, "tft": 15.9278, "input_0": 4329, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 32.0, "mem_use": 52.64, "gen_rate": 25.5, "speed": 1.85, "text": "Here is a list of some of the mo"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 10, "tree_h": 22.0, "tree_w": 120, "tree_size": 1024, "t0": 10.96, "t1": 2.3, "tft": 12.1219, "input_0": 5084, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 50.27, "gen_rate": 10.0, "speed": 0.75, "text": "The total travel time, including"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 126, "tree_size": 1024, "t0": 12.15, "t1": 2.295, "tft": 12.4013, "input_0": 5566, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 32.0, "mem_use": 50.18, "gen_rate": 21.5, "speed": 1.49, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 19.8, "tree_w": 121, "tree_size": 1024, "t0": 9.9425, "t1": 2.3, "tft": 11.3015, "input_0": 4388, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 29.8, "mem_use": 50.08, "gen_rate": 11.2, "speed": 0.92, "text": "Yes, I am capable of answering q"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 21.8, "tree_w": 128, "tree_size": 1024, "t0": 9.7075, "t1": 2.3675, "tft": 8.6121, "input_0": 4022, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 30.8, "mem_use": 53.82, "gen_rate": 11.5, "speed": 0.95, "text": "\"TypeScript is an extension of J"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 24.0, "tree_w": 134, "tree_size": 1024, "t0": 9.8367, "t1": 2.3, "tft": 11.676, "input_0": 3928, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 32.0, "mem_use": 50.19, "gen_rate": 11.0, "speed": 0.91, "text": "The answer is: The answer is \"Mi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.5, "tree_w": 205, "tree_size": 1024, "t0": 7.2025, "t1": 2.3125, "tft": 11.9611, "input_0": 3174, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 22.5, "mem_use": 51.23, "gen_rate": 9.2, "speed": 0.97, "text": "You can find a vendor online by "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 17.7, "tree_w": 126, "tree_size": 1024, "t0": 10.0667, "t1": 2.3533, "tft": 12.7511, "input_0": 4647, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 28.0, "mem_use": 53.01, "gen_rate": 14.0, "speed": 1.13, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 19.0, "tree_w": 170, "tree_size": 1024, "t0": 8.62, "t1": 2.292, "tft": 11.0497, "input_0": 3919, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 27.2, "mem_use": 50.33, "gen_rate": 7.2, "speed": 0.66, "text": "You are not going in the right d"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 18.0, "tree_w": 116, "tree_size": 1024, "t0": 9.48, "t1": 2.31, "tft": 11.1992, "input_0": 3958, "input_1": 1025, "min_CLP": -7.17, "draft_iters": 27.0, "mem_use": 50.84, "gen_rate": 9.0, "speed": 0.76, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 20.5, "tree_w": 119, "tree_size": 1024, "t0": 10.555, "t1": 2.32, "tft": 16.0533, "input_0": 4634, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 31.0, "mem_use": 52.56, "gen_rate": 19.0, "speed": 1.48, "text": "\"If you're a high school student"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 20.8, "tree_w": 116, "tree_size": 1024, "t0": 10.455, "t1": 2.315, "tft": 13.0646, "input_0": 4572, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 30.0, "mem_use": 50.96, "gen_rate": 11.0, "speed": 0.86, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 20.0, "tree_w": 127, "tree_size": 1024, "t0": 9.54, "t1": 2.335, "tft": 13.2307, "input_0": 4069, "input_1": 1025, "min_CLP": -7.31, "draft_iters": 29.0, "mem_use": 53.29, "gen_rate": 8.8, "speed": 0.74, "text": "\"I'm glad to hear that you'll tr"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 20.0, "tree_w": 128, "tree_size": 1024, "t0": 9.8467, "t1": 2.3233, "tft": 13.7483, "input_0": 4467, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 29.3, "mem_use": 51.62, "gen_rate": 13.3, "speed": 1.1, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 15.8, "tree_w": 206, "tree_size": 1024, "t0": 7.184, "t1": 2.306, "tft": 10.4392, "input_0": 3292, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 23.2, "mem_use": 50.64, "gen_rate": 8.6, "speed": 0.91, "text": "What is a question you cannot an"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.3, "tree_w": 125, "tree_size": 1024, "t0": 10.0533, "t1": 2.32, "tft": 16.3021, "input_0": 4769, "input_1": 1025, "min_CLP": -7.1, "draft_iters": 30.3, "mem_use": 52.44, "gen_rate": 15.7, "speed": 1.27, "text": "Learning how to write Chinese ch"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 80, "tree_size": 1024, "t0": 11.215, "t1": 2.3, "tft": 11.5712, "input_0": 4355, "input_1": 1025, "min_CLP": -13.09, "draft_iters": 32.0, "mem_use": 50.27, "gen_rate": 26.0, "speed": 1.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 283, "tree_size": 1024, "t0": 6.6225, "t1": 2.32, "tft": 12.6028, "input_0": 3196, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 21.2, "mem_use": 50.89, "gen_rate": 8.0, "speed": 0.89, "text": "Sure, how about this one: \"A wis"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.0, "tree_w": 260, "tree_size": 1024, "t0": 6.1517, "t1": 2.3, "tft": 9.5193, "input_0": 2567, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 20.3, "mem_use": 50.36, "gen_rate": 5.5, "speed": 0.65, "text": "\"If you wanted to know how deep "}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 76, "tree_size": 1024, "t0": 11.295, "t1": 2.3, "tft": 12.7842, "input_0": 4419, "input_1": 1025, "min_CLP": -13.04, "draft_iters": 32.0, "mem_use": 50.38, "gen_rate": 26.0, "speed": 1.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 15.0, "tree_w": 185, "tree_size": 1024, "t0": 7.3275, "t1": 2.3125, "tft": 11.3679, "input_0": 3421, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 22.8, "mem_use": 50.76, "gen_rate": 11.2, "speed": 1.17, "text": "\"Google Authenticator is a two-f"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.0, "tree_w": 264, "tree_size": 1024, "t0": 7.56, "t1": 2.3067, "tft": 14.6963, "input_0": 3884, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 21.3, "mem_use": 50.55, "gen_rate": 12.3, "speed": 1.25, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 21.8, "tree_w": 107, "tree_size": 1024, "t0": 10.22, "t1": 2.3, "tft": 11.7611, "input_0": 4447, "input_1": 1025, "min_CLP": -7.25, "draft_iters": 31.2, "mem_use": 50.31, "gen_rate": 8.6, "speed": 0.69, "text": "\"Sure! Below is an example of ho"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 18.8, "tree_w": 157, "tree_size": 1024, "t0": 9.1325, "t1": 2.3025, "tft": 11.468, "input_0": 4102, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 27.8, "mem_use": 50.16, "gen_rate": 9.5, "speed": 0.83, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 21.2, "tree_w": 176, "tree_size": 1024, "t0": 8.386, "t1": 2.292, "tft": 11.2706, "input_0": 3488, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 28.8, "mem_use": 50.19, "gen_rate": 6.8, "speed": 0.64, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 155, "tree_size": 1024, "t0": 10.66, "t1": 2.305, "tft": 10.5289, "input_0": 4279, "input_1": 1025, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 24.0, "speed": 1.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.3, "tree_w": 133, "tree_size": 1024, "t0": 9.44, "t1": 2.32, "tft": 11.5649, "input_0": 4249, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 28.7, "mem_use": 51.29, "gen_rate": 11.3, "speed": 0.96, "text": "To copy the directory from one s"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 23.7, "tree_w": 90, "tree_size": 1024, "t0": 10.7567, "t1": 2.2967, "tft": 12.6152, "input_0": 4440, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 32.0, "mem_use": 50.07, "gen_rate": 11.7, "speed": 0.89, "text": "The \"@\" symbol in Python has sev"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 15.0, "tree_w": 213, "tree_size": 1024, "t0": 6.8014, "t1": 2.2929, "tft": 12.0079, "input_0": 2972, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 22.0, "mem_use": 50.08, "gen_rate": 5.9, "speed": 0.64, "text": "\"my chatbot is a cutting-edge AI"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 172, "tree_size": 1024, "t0": 8.44, "t1": 2.295, "tft": 10.559, "input_0": 4373, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 24.8, "mem_use": 50.38, "gen_rate": 8.8, "speed": 0.82, "text": "\"As a master psychologist, my ap"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 184, "tree_size": 1024, "t0": 7.5375, "t1": 2.2975, "tft": 10.8915, "input_0": 3204, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 23.2, "mem_use": 50.11, "gen_rate": 8.5, "speed": 0.86, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 150, "tree_size": 1024, "t0": 9.64, "t1": 2.31, "tft": 13.0679, "input_0": 3896, "input_1": 1025, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 50.81, "gen_rate": 26.5, "speed": 2.22, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.8, "tree_w": 292, "tree_size": 1024, "t0": 6.0967, "t1": 2.3517, "tft": 13.0022, "input_0": 2511, "input_1": 1025, "min_CLP": -9.07, "draft_iters": 19.7, "mem_use": 53.32, "gen_rate": 5.3, "speed": 0.63, "text": "The current date is 2023-02-06.<"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 22.0, "tree_w": 94, "tree_size": 1024, "t0": 11.4333, "t1": 2.3033, "tft": 13.168, "input_0": 5474, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 32.0, "mem_use": 50.62, "gen_rate": 14.3, "speed": 1.04, "text": "Yes, there are some things that "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.6, "tree_w": 192, "tree_size": 1024, "t0": 7.098, "t1": 2.328, "tft": 12.2197, "input_0": 3425, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 21.2, "mem_use": 51.74, "gen_rate": 7.6, "speed": 0.81, "text": "Hello, Agent. It is an honour to"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 23.2, "tree_w": 186, "tree_size": 1024, "t0": 8.245, "t1": 2.305, "tft": 12.1083, "input_0": 3257, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 30.5, "mem_use": 50.61, "gen_rate": 9.2, "speed": 0.88, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.3, "tree_w": 86, "tree_size": 1024, "t0": 11.7333, "t1": 2.3633, "tft": 8.4125, "input_0": 5266, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 32.0, "mem_use": 53.47, "gen_rate": 12.0, "speed": 0.85, "text": "Certainly! Here are some example"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 1024, "max_branch_width": 32, "gen_rate": 11.78, "gen_rate_micro": 10.29, "gen_speed": 1.018, "gen_speed_micro": 0.959, "t0": 8.9174, "t1": 2.3162, "input_0": 3929.4, "input_1": 1025.0, "tree_size": 1024.0, "tree_w": 167.2, "tree_h": 18.4, "prompt_len": 293.8, "min_CLP": -7.96, "mem_use": 55.7, "exp_time": 17474.41}
