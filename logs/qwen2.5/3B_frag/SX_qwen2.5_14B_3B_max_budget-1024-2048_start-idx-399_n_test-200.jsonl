{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-3B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "1024, 2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 200, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-30 11:41:45", "date": "250330", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.5, "tree_w": 203, "tree_size": 1024, "t0": 7.2725, "t1": 2.4175, "tft": 16.3221, "input_0": 3205, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 23.5, "mem_use": 51.35, "gen_rate": 9.0, "speed": 0.93, "text": "Spritesla is the first evolution"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.5, "tree_w": 146, "tree_size": 1024, "t0": 9.015, "t1": 2.3825, "tft": 10.5385, "input_0": 4140, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 26.5, "mem_use": 50.2, "gen_rate": 9.0, "speed": 0.79, "text": "The human genome is a complex se"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 21.0, "tree_w": 128, "tree_size": 1024, "t0": 10.2167, "t1": 2.38, "tft": 12.7404, "input_0": 4610, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 29.7, "mem_use": 50.07, "gen_rate": 13.7, "speed": 1.09, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 191, "tree_size": 1024, "t0": 7.346, "t1": 2.39, "tft": 11.366, "input_0": 3699, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 20.4, "mem_use": 50.31, "gen_rate": 6.6, "speed": 0.68, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.3, "tree_w": 113, "tree_size": 1024, "t0": 10.7633, "t1": 2.3633, "tft": 9.6306, "input_0": 4767, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 30.0, "mem_use": 50.61, "gen_rate": 11.3, "speed": 0.86, "text": "Sure! Here are some TV shows tha"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 21.5, "tree_w": 93, "tree_size": 1024, "t0": 10.8, "t1": 2.38, "tft": 16.0813, "input_0": 4769, "input_1": 1025, "min_CLP": -7.25, "draft_iters": 31.0, "mem_use": 52.22, "gen_rate": 18.0, "speed": 1.37, "text": "Sure, here are some software and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 148, "tree_size": 1024, "t0": 8.5267, "t1": 2.3667, "tft": 13.6582, "input_0": 4171, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 25.7, "mem_use": 51.33, "gen_rate": 12.0, "speed": 1.1, "text": "\"When F-centers are present in a"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 14.2, "tree_w": 216, "tree_size": 1024, "t0": 7.0367, "t1": 2.335, "tft": 12.1592, "input_0": 3152, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 21.8, "mem_use": 50.25, "gen_rate": 5.8, "speed": 0.62, "text": "The atomic bomb game (in go) is "}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 23.7, "tree_w": 88, "tree_size": 1024, "t0": 11.14, "t1": 2.37, "tft": 14.4834, "input_0": 4632, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 32.0, "mem_use": 52.87, "gen_rate": 18.7, "speed": 1.38, "text": "\"Sure, here's the commented code"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 30, "tree_h": 16.0, "tree_w": 186, "tree_size": 1024, "t0": 7.954, "t1": 2.366, "tft": 13.5703, "input_0": 3707, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 24.6, "mem_use": 51.36, "gen_rate": 6.0, "speed": 0.58, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.8, "tree_w": 161, "tree_size": 1024, "t0": 8.8025, "t1": 2.345, "tft": 11.4927, "input_0": 3936, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 27.5, "mem_use": 50.08, "gen_rate": 10.2, "speed": 0.92, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 26, "tree_h": 23.0, "tree_w": 120, "tree_size": 1024, "t0": 11.05, "t1": 2.335, "tft": 12.0222, "input_0": 5153, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 32.0, "mem_use": 50.17, "gen_rate": 13.0, "speed": 0.97, "text": "```md\\nHere\\'s an example of a c"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.2, "tree_w": 185, "tree_size": 1024, "t0": 7.0975, "t1": 2.3675, "tft": 12.357, "input_0": 3208, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 21.2, "mem_use": 51.2, "gen_rate": 9.5, "speed": 1.0, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.7, "tree_w": 137, "tree_size": 1024, "t0": 8.35, "t1": 2.3833, "tft": 12.5222, "input_0": 3460, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 27.0, "mem_use": 52.15, "gen_rate": 11.0, "speed": 1.03, "text": "\"In JavaScript, you can't tell t"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.5, "tree_w": 248, "tree_size": 1024, "t0": 6.655, "t1": 2.345, "tft": 10.7222, "input_0": 3465, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 19.0, "mem_use": 50.69, "gen_rate": 9.0, "speed": 1.0, "text": "Of course! Here is a basic train"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.0, "tree_w": 151, "tree_size": 1024, "t0": 8.0375, "t1": 2.3725, "tft": 13.1665, "input_0": 3900, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 23.5, "mem_use": 51.17, "gen_rate": 9.2, "speed": 0.89, "text": "My assumption was based on the s"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.7, "tree_w": 143, "tree_size": 1024, "t0": 9.41, "t1": 2.3533, "tft": 11.936, "input_0": 4392, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 27.0, "mem_use": 50.08, "gen_rate": 12.7, "speed": 1.08, "text": "JavaScript can be used for both "}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.0, "tree_w": 159, "tree_size": 1024, "t0": 7.3625, "t1": 2.3375, "tft": 12.0294, "input_0": 3213, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 21.8, "mem_use": 50.07, "gen_rate": 8.2, "speed": 0.85, "text": "The L-theanine is an amino acid "}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 19.2, "tree_w": 139, "tree_size": 1024, "t0": 10.536, "t1": 2.36, "tft": 11.3987, "input_0": 4674, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 30.0, "mem_use": 50.78, "gen_rate": 7.0, "speed": 0.54, "text": "Sure, here is the list in two co"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.0, "tree_w": 158, "tree_size": 1024, "t0": 9.0367, "t1": 2.3467, "tft": 11.8575, "input_0": 4123, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 26.0, "mem_use": 50.19, "gen_rate": 10.7, "speed": 0.94, "text": "Hippoplaisir is a unique and inn"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.0, "tree_w": 198, "tree_size": 1024, "t0": 7.27, "t1": 2.348, "tft": 11.9268, "input_0": 3667, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 22.4, "mem_use": 50.19, "gen_rate": 6.8, "speed": 0.71, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.0, "tree_w": 184, "tree_size": 1024, "t0": 7.428, "t1": 2.344, "tft": 11.7036, "input_0": 3763, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 21.8, "mem_use": 50.17, "gen_rate": 7.2, "speed": 0.74, "text": "To memorize how to write Chinese"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 70, "tree_size": 1024, "t0": 10.875, "t1": 2.455, "tft": 14.9978, "input_0": 4227, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 32.0, "mem_use": 54.95, "gen_rate": 25.5, "speed": 1.91, "text": "Here is a possible monologue scr"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 22.3, "tree_w": 107, "tree_size": 1024, "t0": 9.9267, "t1": 2.38, "tft": 14.6338, "input_0": 4326, "input_1": 1025, "min_CLP": -7.26, "draft_iters": 30.7, "mem_use": 52.57, "gen_rate": 10.7, "speed": 0.87, "text": "\"Sure! Fermat's Last Theorem say"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 20.0, "tree_w": 76, "tree_size": 1024, "t0": 12.73, "t1": 2.375, "tft": 14.0947, "input_0": 6124, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 32.0, "mem_use": 51.0, "gen_rate": 21.0, "speed": 1.39, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.3, "tree_w": 142, "tree_size": 1024, "t0": 10.7567, "t1": 2.3667, "tft": 12.0311, "input_0": 5150, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 51.17, "gen_rate": 11.3, "speed": 0.86, "text": "Oh, we can learn so much from po"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.4, "tree_w": 246, "tree_size": 1024, "t0": 7.384, "t1": 2.392, "tft": 13.9944, "input_0": 3982, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 20.8, "mem_use": 52.23, "gen_rate": 7.6, "speed": 0.78, "text": "You can serve lemon wedges along"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.8, "tree_w": 179, "tree_size": 1024, "t0": 7.675, "t1": 2.3575, "tft": 9.6559, "input_0": 3681, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 22.8, "mem_use": 50.26, "gen_rate": 9.2, "speed": 0.92, "text": "Sure, I\\'d be happy to play the "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 196, "tree_size": 1024, "t0": 7.0125, "t1": 2.35, "tft": 9.4097, "input_0": 3290, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 21.5, "mem_use": 50.22, "gen_rate": 8.8, "speed": 0.93, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.0, "tree_w": 91, "tree_size": 1024, "t0": 11.62, "t1": 2.355, "tft": 13.5423, "input_0": 5162, "input_1": 1025, "min_CLP": -7.26, "draft_iters": 32.0, "mem_use": 50.1, "gen_rate": 19.5, "speed": 1.4, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.7, "tree_w": 257, "tree_size": 1024, "t0": 7.1867, "t1": 2.3833, "tft": 11.6619, "input_0": 3832, "input_1": 1025, "min_CLP": -10.15, "draft_iters": 22.0, "mem_use": 51.68, "gen_rate": 12.0, "speed": 1.25, "text": "There have been several cities t"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.5, "tree_w": 172, "tree_size": 1024, "t0": 7.84, "t1": 2.3675, "tft": 15.5846, "input_0": 3593, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 23.0, "mem_use": 51.21, "gen_rate": 8.2, "speed": 0.81, "text": "In addition to the Dyson Sphere,"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 24.3, "tree_w": 168, "tree_size": 1024, "t0": 10.1467, "t1": 2.3433, "tft": 11.5454, "input_0": 3482, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 32.0, "mem_use": 50.05, "gen_rate": 14.3, "speed": 1.15, "text": "def fibonacci(n):\\n    if n == 0"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.7, "tree_w": 147, "tree_size": 1024, "t0": 8.9, "t1": 2.3567, "tft": 13.0762, "input_0": 3706, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 27.7, "mem_use": 50.8, "gen_rate": 11.0, "speed": 0.98, "text": "You\\'re welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 77, "tree_size": 1024, "t0": 12.31, "t1": 2.365, "tft": 15.5879, "input_0": 5213, "input_1": 1025, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 51.4, "gen_rate": 25.5, "speed": 1.74, "text": "Of course! Here are the complete"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 17.8, "tree_w": 234, "tree_size": 1024, "t0": 7.866, "t1": 2.354, "tft": 11.3366, "input_0": 3674, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 24.8, "mem_use": 50.42, "gen_rate": 8.8, "speed": 0.86, "text": "1.    Work pressure and job inse"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.5, "tree_w": 139, "tree_size": 1024, "t0": 9.07, "t1": 2.3475, "tft": 10.0788, "input_0": 4014, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 26.8, "mem_use": 50.09, "gen_rate": 8.8, "speed": 0.77, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.2, "tree_w": 187, "tree_size": 1024, "t0": 6.89, "t1": 2.355, "tft": 11.5366, "input_0": 3311, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 20.0, "mem_use": 50.65, "gen_rate": 8.5, "speed": 0.92, "text": "Tensorflow and PyTorch are both "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.8, "tree_w": 121, "tree_size": 1024, "t0": 9.325, "t1": 2.365, "tft": 12.7032, "input_0": 4170, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 27.8, "mem_use": 51.09, "gen_rate": 11.0, "speed": 0.94, "text": "[Mathematical questions]: {How c"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.0, "tree_w": 128, "tree_size": 1024, "t0": 9.8167, "t1": 2.36, "tft": 12.5563, "input_0": 4637, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 30.0, "mem_use": 50.76, "gen_rate": 11.3, "speed": 0.93, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 84, "tree_size": 1024, "t0": 12.18, "t1": 2.395, "tft": 16.3601, "input_0": 5302, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 52.89, "gen_rate": 23.5, "speed": 1.61, "text": "\"Yes, I do know what L'Hopital's"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 20.2, "tree_w": 132, "tree_size": 1024, "t0": 9.9225, "t1": 2.415, "tft": 14.9804, "input_0": 4804, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 30.5, "mem_use": 54.46, "gen_rate": 9.2, "speed": 0.75, "text": "For vegan cheese alternatives, t"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.6, "tree_w": 211, "tree_size": 1024, "t0": 7.074, "t1": 2.374, "tft": 10.9071, "input_0": 3546, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 21.8, "mem_use": 51.47, "gen_rate": 7.4, "speed": 0.78, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 82, "tree_size": 1024, "t0": 11.9, "t1": 2.39, "tft": 14.5608, "input_0": 5155, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 32.0, "mem_use": 51.86, "gen_rate": 23.0, "speed": 1.61, "text": "\"Sure, here are the three most i"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 21.0, "tree_w": 133, "tree_size": 1024, "t0": 9.8233, "t1": 2.3467, "tft": 13.4802, "input_0": 4331, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 30.3, "mem_use": 50.09, "gen_rate": 10.7, "speed": 0.88, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.5, "tree_w": 160, "tree_size": 1024, "t0": 9.07, "t1": 2.3675, "tft": 12.5535, "input_0": 3939, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 28.2, "mem_use": 51.43, "gen_rate": 10.2, "speed": 0.9, "text": "Based on the current date of the"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 16.2, "tree_w": 220, "tree_size": 1024, "t0": 8.168, "t1": 2.346, "tft": 11.8706, "input_0": 4039, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 24.4, "mem_use": 50.26, "gen_rate": 7.2, "speed": 0.68, "text": "Sure! Here\\'s a short story in a"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.8, "tree_w": 271, "tree_size": 1024, "t0": 6.1725, "t1": 2.3475, "tft": 11.8013, "input_0": 3334, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 18.8, "mem_use": 50.14, "gen_rate": 10.0, "speed": 1.17, "text": "To cook an egg using only direct"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 64, "tree_size": 1024, "t0": 10.865, "t1": 2.355, "tft": 11.6849, "input_0": 4338, "input_1": 1025, "min_CLP": -13.82, "draft_iters": 32.0, "mem_use": 50.13, "gen_rate": 26.5, "speed": 2.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.2, "tree_w": 291, "tree_size": 1024, "t0": 5.4917, "t1": 2.3433, "tft": 8.6937, "input_0": 2456, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 17.3, "mem_use": 50.08, "gen_rate": 5.8, "speed": 0.74, "text": "my name is arielle and I am 11 y"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.0, "tree_w": 312, "tree_size": 1024, "t0": 6.8367, "t1": 2.48, "tft": 13.8695, "input_0": 2503, "input_1": 1025, "min_CLP": -8.68, "draft_iters": 26.3, "mem_use": 51.35, "gen_rate": 12.3, "speed": 1.32, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 21.0, "tree_w": 104, "tree_size": 1024, "t0": 11.925, "t1": 2.35, "tft": 12.1008, "input_0": 5517, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 32.0, "mem_use": 50.47, "gen_rate": 18.0, "speed": 1.26, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 155, "tree_size": 1024, "t0": 8.18, "t1": 2.455, "tft": 16.7637, "input_0": 3712, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 24.0, "mem_use": 55.56, "gen_rate": 8.2, "speed": 0.78, "text": "There is evidence that sexual di"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 340, "tree_size": 1024, "t0": 5.48, "t1": 2.356, "tft": 9.7564, "input_0": 3291, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 15.4, "mem_use": 50.6, "gen_rate": 6.6, "speed": 0.84, "text": "Large language models require a "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 17.3, "tree_w": 186, "tree_size": 1024, "t0": 8.93, "t1": 2.3567, "tft": 11.9694, "input_0": 3786, "input_1": 1025, "min_CLP": -10.14, "draft_iters": 24.0, "mem_use": 50.17, "gen_rate": 18.3, "speed": 1.62, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 20.8, "tree_w": 139, "tree_size": 1024, "t0": 9.395, "t1": 2.3625, "tft": 11.9044, "input_0": 3876, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 29.8, "mem_use": 50.38, "gen_rate": 10.0, "speed": 0.85, "text": "\"Here is a eulogy for your 100-y"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 24.8, "tree_w": 164, "tree_size": 1024, "t0": 8.7875, "t1": 2.3825, "tft": 11.3343, "input_0": 3189, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 31.8, "mem_use": 51.86, "gen_rate": 11.2, "speed": 1.01, "text": "No, that covers the basics of co"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 259, "tree_size": 1024, "t0": 6.885, "t1": 2.36, "tft": 11.6233, "input_0": 3454, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 20.5, "mem_use": 50.25, "gen_rate": 9.0, "speed": 0.97, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.0, "tree_w": 245, "tree_size": 1024, "t0": 6.3783, "t1": 2.3467, "tft": 11.4092, "input_0": 3060, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 20.5, "mem_use": 50.23, "gen_rate": 6.2, "speed": 0.71, "text": "Sure, how about suggesting a fun"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.0, "tree_w": 144, "tree_size": 1024, "t0": 9.6433, "t1": 2.35, "tft": 11.1109, "input_0": 4954, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 26.3, "mem_use": 50.06, "gen_rate": 12.7, "speed": 1.06, "text": "The color of Mars is often descr"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.7, "tree_w": 234, "tree_size": 1024, "t0": 6.905, "t1": 2.3833, "tft": 13.7762, "input_0": 2720, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 22.0, "mem_use": 52.29, "gen_rate": 6.5, "speed": 0.7, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 17.5, "tree_w": 179, "tree_size": 1024, "t0": 12.155, "t1": 2.35, "tft": 12.1205, "input_0": 5797, "input_1": 1025, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 50.15, "gen_rate": 16.0, "speed": 1.1, "text": "Sure! Here\\'s a two-paragraph su"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.7, "tree_w": 214, "tree_size": 1024, "t0": 7.3967, "t1": 2.3567, "tft": 10.3449, "input_0": 3150, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 23.7, "mem_use": 50.69, "gen_rate": 10.7, "speed": 1.09, "text": "\"No, the ATF's regulations are n"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 22.3, "tree_w": 86, "tree_size": 1024, "t0": 11.3667, "t1": 2.36, "tft": 11.6849, "input_0": 4682, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 31.7, "mem_use": 50.15, "gen_rate": 16.3, "speed": 1.19, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 12.0, "tree_w": 255, "tree_size": 1024, "t0": 6.886, "t1": 2.36, "tft": 11.5639, "input_0": 3577, "input_1": 1025, "min_CLP": -8.54, "draft_iters": 20.2, "mem_use": 50.58, "gen_rate": 9.0, "speed": 0.97, "text": "\"Sure, I'd be happy to help! Her"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 10, "tree_h": 19.0, "tree_w": 141, "tree_size": 1024, "t0": 8.51, "t1": 2.35, "tft": 12.0914, "input_0": 3644, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 27.0, "mem_use": 50.26, "gen_rate": 10.0, "speed": 0.92, "text": "New South Wales was the capital "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 123, "tree_size": 1024, "t0": 10.015, "t1": 2.35, "tft": 10.115, "input_0": 3773, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 50.44, "gen_rate": 26.0, "speed": 2.1, "text": "[INST] write a eulogy for my 100"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.3, "tree_w": 141, "tree_size": 1024, "t0": 9.1233, "t1": 2.39, "tft": 13.4992, "input_0": 4091, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 27.7, "mem_use": 52.66, "gen_rate": 12.3, "speed": 1.07, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.3, "tree_w": 228, "tree_size": 1024, "t0": 6.61, "t1": 2.3529, "tft": 10.7458, "input_0": 3185, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 19.9, "mem_use": 50.25, "gen_rate": 5.0, "speed": 0.56, "text": "Yes, this is a real story. In 19"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 22.8, "tree_w": 144, "tree_size": 1024, "t0": 9.465, "t1": 2.385, "tft": 12.4222, "input_0": 3871, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 30.5, "mem_use": 51.55, "gen_rate": 12.2, "speed": 1.03, "text": "\"Let's choose a vector A = (12, "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 18.5, "tree_w": 135, "tree_size": 1024, "t0": 8.78, "t1": 2.35, "tft": 11.4056, "input_0": 3671, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 26.2, "mem_use": 50.11, "gen_rate": 11.2, "speed": 1.01, "text": "## Solution\\nTo determine if a g"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.7, "tree_w": 287, "tree_size": 1024, "t0": 5.7129, "t1": 2.3557, "tft": 10.5612, "input_0": 2619, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 17.0, "mem_use": 50.17, "gen_rate": 4.6, "speed": 0.57, "text": "\"Ah, greetings to you, traveler!"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 16, "tree_h": 26.0, "tree_w": 138, "tree_size": 1024, "t0": 9.52, "t1": 2.35, "tft": 12.4726, "input_0": 3263, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 32.0, "mem_use": 50.12, "gen_rate": 16.0, "speed": 1.35, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.2, "tree_w": 127, "tree_size": 1024, "t0": 9.2425, "t1": 2.3675, "tft": 11.6446, "input_0": 3866, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 28.0, "mem_use": 50.69, "gen_rate": 9.8, "speed": 0.84, "text": "Sum of squares error (SSE) is th"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 19.0, "tree_w": 165, "tree_size": 1024, "t0": 7.675, "t1": 2.37, "tft": 11.6507, "input_0": 3206, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 26.0, "mem_use": 50.99, "gen_rate": 3.5, "speed": 0.35, "text": "\"Find your inner strength, one s"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.0, "tree_w": 236, "tree_size": 1024, "t0": 6.56, "t1": 2.3667, "tft": 11.3784, "input_0": 3029, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 22.3, "mem_use": 50.77, "gen_rate": 11.0, "speed": 1.23, "text": "The best place in the lower 48 t"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.2, "tree_w": 224, "tree_size": 1024, "t0": 7.262, "t1": 2.354, "tft": 11.528, "input_0": 3583, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 21.2, "mem_use": 50.11, "gen_rate": 7.2, "speed": 0.75, "text": "Top 10 Funniest Ways to Die:\\n\\n"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.0, "tree_w": 168, "tree_size": 1024, "t0": 8.092, "t1": 2.362, "tft": 11.3985, "input_0": 3823, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 24.2, "mem_use": 50.67, "gen_rate": 6.4, "speed": 0.61, "text": "If the two dropped eggs landed o"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.3, "tree_w": 131, "tree_size": 1024, "t0": 8.9633, "t1": 2.36, "tft": 9.6569, "input_0": 4298, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 26.3, "mem_use": 50.54, "gen_rate": 11.3, "speed": 1.0, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.3, "tree_w": 119, "tree_size": 1024, "t0": 10.54, "t1": 2.3967, "tft": 14.7038, "input_0": 4843, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 31.0, "mem_use": 53.62, "gen_rate": 11.3, "speed": 0.88, "text": "Certainly, here are some tools t"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 18.7, "tree_w": 113, "tree_size": 1024, "t0": 10.01, "t1": 2.4033, "tft": 14.7459, "input_0": 4431, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 28.0, "mem_use": 52.3, "gen_rate": 14.3, "speed": 1.15, "text": "Building your own PC can be a gr"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 29, "tree_h": 20.0, "tree_w": 123, "tree_size": 1024, "t0": 9.8933, "t1": 2.3533, "tft": 11.0079, "input_0": 4336, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 29.3, "mem_use": 50.07, "gen_rate": 9.7, "speed": 0.79, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-3B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 19.0, "tree_w": 202, "tree_size": 1024, "t0": 9.068, "t1": 2.358, "tft": 12.096, "input_0": 3871, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 29.2, "mem_use": 50.32, "gen_rate": 7.0, "speed": 0.61, "text": "Here are five words where the le"}
