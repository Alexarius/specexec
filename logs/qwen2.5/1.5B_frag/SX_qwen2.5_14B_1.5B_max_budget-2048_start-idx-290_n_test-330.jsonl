{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-1.5B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 330, "seed": 0, "dataset": "oasst", "timestamp": "2025-04-02 05:01:10", "date": "250402", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.0, "tree_w": 610, "tree_size": 2048, "t0": 5.3967, "t1": 6.1717, "tft": 15.9359, "input_0": 5118, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 25.2, "mem_use": 53.57, "gen_rate": 6.0, "speed": 0.52, "text": "0 It is an independent professio"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.2, "tree_w": 412, "tree_size": 2048, "t0": 6.835, "t1": 5.89, "tft": 14.8472, "input_0": 6914, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 55.42, "gen_rate": 8.2, "speed": 0.65, "text": "As a business professional, I un"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 14.0, "tree_w": 402, "tree_size": 2048, "t0": 6.716, "t1": 6.096, "tft": 12.4493, "input_0": 5335, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 53.78, "gen_rate": 8.6, "speed": 0.67, "text": "1. A sudden change in the neighb"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.0, "tree_w": 583, "tree_size": 2048, "t0": 5.885, "t1": 6.0667, "tft": 11.7675, "input_0": 5852, "input_1": 2049, "min_CLP": -9.33, "draft_iters": 27.7, "mem_use": 53.08, "gen_rate": 6.7, "speed": 0.56, "text": "\"Here's a possible script:\\n\\n--"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 378, "tree_size": 2048, "t0": 7.0975, "t1": 5.8875, "tft": 14.5105, "input_0": 7827, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 55.55, "gen_rate": 10.2, "speed": 0.79, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.4, "tree_w": 374, "tree_size": 2048, "t0": 7.064, "t1": 6.078, "tft": 12.2093, "input_0": 7174, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 53.26, "gen_rate": 8.0, "speed": 0.61, "text": "Yes, as an AI language model, I "}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 395, "tree_size": 2048, "t0": 7.1825, "t1": 5.895, "tft": 14.3195, "input_0": 8274, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 55.21, "gen_rate": 9.8, "speed": 0.75, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 343, "tree_size": 2048, "t0": 7.0733, "t1": 6.07, "tft": 11.3594, "input_0": 7037, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 11.0, "speed": 0.84, "text": "Here is an implementation of the"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 511, "tree_size": 2048, "t0": 5.872, "t1": 6.102, "tft": 12.3542, "input_0": 5130, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 27.4, "mem_use": 53.51, "gen_rate": 7.6, "speed": 0.63, "text": "The first law regarding public i"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 419, "tree_size": 2048, "t0": 7.1125, "t1": 6.08, "tft": 12.1454, "input_0": 8209, "input_1": 2049, "min_CLP": -14.01, "draft_iters": 32.0, "mem_use": 53.23, "gen_rate": 10.0, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 378, "tree_size": 2048, "t0": 7.0733, "t1": 6.0633, "tft": 12.3209, "input_0": 7743, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.7, "speed": 0.81, "text": "\"To create a smooth and visually"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 351, "tree_size": 2048, "t0": 7.0333, "t1": 6.11, "tft": 12.7303, "input_0": 7293, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 53.71, "gen_rate": 10.7, "speed": 0.81, "text": "\"If you're afraid of looking dum"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.8, "tree_w": 467, "tree_size": 2048, "t0": 7.055, "t1": 5.82, "tft": 14.3853, "input_0": 7820, "input_1": 2049, "min_CLP": -10.11, "draft_iters": 32.0, "mem_use": 55.29, "gen_rate": 10.0, "speed": 0.78, "text": "Here is a list of some of the mo"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 347, "tree_size": 2048, "t0": 7.01, "t1": 6.0875, "tft": 11.8962, "input_0": 6924, "input_1": 2049, "min_CLP": -9.6, "draft_iters": 32.0, "mem_use": 52.94, "gen_rate": 10.0, "speed": 0.76, "text": "The total travel time is 8 hours"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 390, "tree_size": 2048, "t0": 7.0475, "t1": 6.0675, "tft": 12.1543, "input_0": 8106, "input_1": 2049, "min_CLP": -10.13, "draft_iters": 32.0, "mem_use": 52.85, "gen_rate": 10.2, "speed": 0.78, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.2, "tree_w": 378, "tree_size": 2048, "t0": 7.06, "t1": 6.065, "tft": 7.7243, "input_0": 7849, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 52.69, "gen_rate": 9.5, "speed": 0.72, "text": "Yes, I am capable of answering q"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.5, "tree_w": 375, "tree_size": 2048, "t0": 7.3175, "t1": 6.035, "tft": 20.3385, "input_0": 7947, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 56.51, "gen_rate": 10.0, "speed": 0.75, "text": "\"You can use TypeScript instead "}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 370, "tree_size": 2048, "t0": 7.084, "t1": 6.076, "tft": 12.127, "input_0": 6889, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 7.2, "speed": 0.55, "text": "\"Q: The name of the fourth kid i"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 439, "tree_size": 2048, "t0": 7.1175, "t1": 6.1125, "tft": 12.0401, "input_0": 7784, "input_1": 2049, "min_CLP": -12.72, "draft_iters": 32.0, "mem_use": 53.9, "gen_rate": 10.0, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 445, "tree_size": 2048, "t0": 7.115, "t1": 5.985, "tft": 14.2707, "input_0": 9066, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 55.67, "gen_rate": 9.2, "speed": 0.71, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 406, "tree_size": 2048, "t0": 7.078, "t1": 6.076, "tft": 12.1489, "input_0": 7549, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 52.99, "gen_rate": 6.6, "speed": 0.5, "text": "\"It's understandable to feel ove"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.7, "tree_w": 394, "tree_size": 2048, "t0": 6.9733, "t1": 6.0967, "tft": 12.4914, "input_0": 6767, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 53.51, "gen_rate": 6.2, "speed": 0.47, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 445, "tree_size": 2048, "t0": 7.085, "t1": 5.8, "tft": 14.3955, "input_0": 8255, "input_1": 2049, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 55.21, "gen_rate": 10.2, "speed": 0.8, "text": "\"If you are a high school studen"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 470, "tree_size": 2048, "t0": 7.16, "t1": 6.115, "tft": 12.2566, "input_0": 7877, "input_1": 2049, "min_CLP": -9.7, "draft_iters": 32.0, "mem_use": 53.63, "gen_rate": 9.5, "speed": 0.72, "text": "The invention of the television "}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 389, "tree_size": 2048, "t0": 7.0325, "t1": 5.9225, "tft": 14.5041, "input_0": 7831, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 55.96, "gen_rate": 8.0, "speed": 0.62, "text": "Great, I hope these suggestions "}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 372, "tree_size": 2048, "t0": 7.056, "t1": 6.154, "tft": 12.6875, "input_0": 7841, "input_1": 2049, "min_CLP": -8.41, "draft_iters": 32.0, "mem_use": 54.29, "gen_rate": 7.4, "speed": 0.56, "text": "\"The celebration of Christmas on"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.8, "tree_w": 466, "tree_size": 2048, "t0": 6.21, "t1": 6.0833, "tft": 11.7444, "input_0": 6222, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 28.5, "mem_use": 53.31, "gen_rate": 6.0, "speed": 0.49, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.0, "tree_w": 543, "tree_size": 2048, "t0": 7.08, "t1": 5.785, "tft": 14.2858, "input_0": 9313, "input_1": 2049, "min_CLP": -9.17, "draft_iters": 32.0, "mem_use": 55.1, "gen_rate": 8.8, "speed": 0.68, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 396, "tree_size": 2048, "t0": 7.1767, "t1": 6.07, "tft": 12.0065, "input_0": 8070, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 32.0, "mem_use": 52.93, "gen_rate": 10.7, "speed": 0.81, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.0, "tree_w": 351, "tree_size": 2048, "t0": 7.062, "t1": 6.108, "tft": 12.7711, "input_0": 6476, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 53.55, "gen_rate": 8.4, "speed": 0.64, "text": "Sure, how about this one: \"A wis"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 13.0, "tree_w": 489, "tree_size": 2048, "t0": 6.414, "t1": 6.092, "tft": 11.5444, "input_0": 4944, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 30.6, "mem_use": 53.03, "gen_rate": 4.0, "speed": 0.32, "text": "\"As if you could afford to even "}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 8.0, "tree_w": 554, "tree_size": 2048, "t0": 6.4175, "t1": 6.0875, "tft": 12.3393, "input_0": 7485, "input_1": 2049, "min_CLP": -10.58, "draft_iters": 28.5, "mem_use": 53.05, "gen_rate": 8.8, "speed": 0.7, "text": "The distance from Earth to Sagit"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 369, "tree_size": 2048, "t0": 7.06, "t1": 6.1125, "tft": 12.3509, "input_0": 7310, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 53.43, "gen_rate": 9.2, "speed": 0.7, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 496, "tree_size": 2048, "t0": 7.17, "t1": 6.085, "tft": 12.5338, "input_0": 8996, "input_1": 2049, "min_CLP": -9.51, "draft_iters": 32.0, "mem_use": 53.21, "gen_rate": 8.8, "speed": 0.66, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 437, "tree_size": 2048, "t0": 7.08, "t1": 6.09, "tft": 12.4049, "input_0": 8647, "input_1": 2049, "min_CLP": -9.35, "draft_iters": 32.0, "mem_use": 52.97, "gen_rate": 8.8, "speed": 0.66, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 384, "tree_size": 2048, "t0": 7.0725, "t1": 6.09, "tft": 12.3794, "input_0": 7821, "input_1": 2049, "min_CLP": -9.01, "draft_iters": 32.0, "mem_use": 52.82, "gen_rate": 8.5, "speed": 0.65, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 11.1, "tree_w": 474, "tree_size": 2048, "t0": 6.3971, "t1": 6.0857, "tft": 12.3187, "input_0": 5946, "input_1": 2049, "min_CLP": -9.28, "draft_iters": 29.1, "mem_use": 52.86, "gen_rate": 6.0, "speed": 0.48, "text": "Here is a Shakespeare Programmin"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 422, "tree_size": 2048, "t0": 6.9025, "t1": 6.075, "tft": 11.7175, "input_0": 6949, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 9.2, "speed": 0.71, "text": "[INST] Provide a comprehensive a"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 357, "tree_size": 2048, "t0": 7.1075, "t1": 6.1175, "tft": 12.939, "input_0": 7753, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 53.96, "gen_rate": 9.2, "speed": 0.7, "text": "\"You can use your local laptop a"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.6, "tree_w": 518, "tree_size": 2048, "t0": 6.254, "t1": 6.056, "tft": 12.1253, "input_0": 6986, "input_1": 2049, "min_CLP": -9.46, "draft_iters": 27.8, "mem_use": 52.73, "gen_rate": 7.8, "speed": 0.63, "text": "The \"@\" symbol in Python has dif"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 358, "tree_size": 2048, "t0": 7.0975, "t1": 6.0675, "tft": 12.2073, "input_0": 7838, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 8.8, "speed": 0.66, "text": "ChatGPT is an incredibly advance"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 322, "tree_size": 2048, "t0": 7.19, "t1": 6.0875, "tft": 11.5054, "input_0": 7113, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 8.8, "speed": 0.66, "text": "To approach this task, I would f"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 11.0, "tree_w": 373, "tree_size": 2048, "t0": 7.09, "t1": 6.08, "tft": 11.2099, "input_0": 6475, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 4.5, "speed": 0.34, "text": "[INST]What is the capital of Fra"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 370, "tree_size": 2048, "t0": 7.158, "t1": 6.108, "tft": 12.4217, "input_0": 7379, "input_1": 2049, "min_CLP": -14.24, "draft_iters": 32.0, "mem_use": 53.48, "gen_rate": 6.6, "speed": 0.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 452, "tree_size": 2048, "t0": 6.666, "t1": 5.86, "tft": 14.6185, "input_0": 6792, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 31.4, "mem_use": 55.99, "gen_rate": 7.4, "speed": 0.59, "text": "These are all names of different"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 399, "tree_size": 2048, "t0": 7.14, "t1": 6.09, "tft": 12.1614, "input_0": 8535, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 53.28, "gen_rate": 9.5, "speed": 0.72, "text": "Decorators in Python are a way t"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 9.0, "tree_w": 383, "tree_size": 2048, "t0": 7.1, "t1": 6.13, "tft": 13.1466, "input_0": 7006, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 54.41, "gen_rate": 6.0, "speed": 0.45, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 17, "tree_h": 9.8, "tree_w": 517, "tree_size": 2048, "t0": 6.2783, "t1": 6.0883, "tft": 12.3871, "input_0": 6285, "input_1": 2049, "min_CLP": -9.51, "draft_iters": 29.0, "mem_use": 53.26, "gen_rate": 2.8, "speed": 0.23, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 363, "tree_size": 2048, "t0": 7.0675, "t1": 5.935, "tft": 14.8414, "input_0": 7622, "input_1": 2049, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 56.17, "gen_rate": 10.0, "speed": 0.77, "text": "Sure! Here are some examples of "}
