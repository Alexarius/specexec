{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-1.5B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 200, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-30 01:11:01", "date": "250330", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.8, "tree_w": 505, "tree_size": 2048, "t0": 6.274, "t1": 6.212, "tft": 15.9224, "input_0": 5821, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 28.8, "mem_use": 53.27, "gen_rate": 7.2, "speed": 0.58, "text": "LLMs are a large class of models"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 11.2, "tree_w": 487, "tree_size": 2048, "t0": 6.6867, "t1": 6.1067, "tft": 11.5873, "input_0": 6767, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 30.8, "mem_use": 52.83, "gen_rate": 5.0, "speed": 0.39, "text": "\"Sure, here's a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 348, "tree_size": 2048, "t0": 7.1675, "t1": 6.065, "tft": 12.1595, "input_0": 7543, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 9.8, "speed": 0.74, "text": "\"Here is a eulogy for your grand"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 7.8, "tree_w": 591, "tree_size": 2048, "t0": 6.1275, "t1": 6.145, "tft": 10.3005, "input_0": 7131, "input_1": 2049, "min_CLP": -10.59, "draft_iters": 27.2, "mem_use": 54.47, "gen_rate": 8.8, "speed": 0.71, "text": "[INST] How to implement collisio"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 360, "tree_size": 2048, "t0": 7.204, "t1": 6.072, "tft": 12.4455, "input_0": 7694, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 52.9, "gen_rate": 7.0, "speed": 0.53, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 489, "tree_size": 2048, "t0": 7.1825, "t1": 6.0875, "tft": 11.355, "input_0": 8196, "input_1": 2049, "min_CLP": -13.24, "draft_iters": 32.0, "mem_use": 52.89, "gen_rate": 10.0, "speed": 0.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 354, "tree_size": 2048, "t0": 7.095, "t1": 6.07, "tft": 11.9018, "input_0": 6875, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 8.8, "speed": 0.66, "text": "The color of Mars is a reddish-b"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 497, "tree_size": 2048, "t0": 5.966, "t1": 5.762, "tft": 15.3221, "input_0": 5001, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 28.4, "mem_use": 54.96, "gen_rate": 7.0, "speed": 0.6, "text": "In Quenya, \"I love you\" can be e"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 441, "tree_size": 2048, "t0": 7.255, "t1": 6.0825, "tft": 12.1153, "input_0": 8488, "input_1": 2049, "min_CLP": -14.95, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.2, "speed": 0.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 354, "tree_size": 2048, "t0": 7.0825, "t1": 6.08, "tft": 12.3785, "input_0": 6377, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 53.35, "gen_rate": 9.2, "speed": 0.7, "text": "\"The ATF is responsible for enfo"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 453, "tree_size": 2048, "t0": 7.2525, "t1": 6.08, "tft": 12.2542, "input_0": 8060, "input_1": 2049, "min_CLP": -10.78, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.0, "speed": 0.75, "text": "No, there is no formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.2, "tree_w": 426, "tree_size": 2048, "t0": 7.1575, "t1": 6.0975, "tft": 12.5823, "input_0": 7991, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 53.23, "gen_rate": 9.5, "speed": 0.72, "text": "\"Sure, I'd be happy to help! As "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 330, "tree_size": 2048, "t0": 7.224, "t1": 6.088, "tft": 12.3313, "input_0": 7083, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 52.93, "gen_rate": 7.0, "speed": 0.53, "text": "The Australian Capital Territory"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 419, "tree_size": 2048, "t0": 7.07, "t1": 6.0933, "tft": 12.4482, "input_0": 7534, "input_1": 2049, "min_CLP": -10.23, "draft_iters": 32.0, "mem_use": 53.09, "gen_rate": 10.7, "speed": 0.81, "text": "Hello\\n[INST] yes [\\\\INST]\\nHell"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 365, "tree_size": 2048, "t0": 6.9125, "t1": 5.8975, "tft": 14.9615, "input_0": 6505, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 55.32, "gen_rate": 8.8, "speed": 0.68, "text": "Title: The Unapologetic Advocate"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.2, "tree_w": 466, "tree_size": 2048, "t0": 6.645, "t1": 6.09, "tft": 12.042, "input_0": 6229, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 31.3, "mem_use": 52.91, "gen_rate": 5.5, "speed": 0.43, "text": "\"It's true that there was a famo"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 426, "tree_size": 2048, "t0": 7.2725, "t1": 6.135, "tft": 13.1166, "input_0": 8382, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 54.19, "gen_rate": 8.8, "speed": 0.65, "text": "\"Sure, let's consider a vector A"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 358, "tree_size": 2048, "t0": 7.258, "t1": 6.168, "tft": 11.7569, "input_0": 6620, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 7.4, "speed": 0.55, "text": "The main issues with using a sym"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 397, "tree_size": 2048, "t0": 7.13, "t1": 6.0825, "tft": 11.4397, "input_0": 6634, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 8.2, "speed": 0.62, "text": "Once upon a time, in the vast an"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 481, "tree_size": 2048, "t0": 6.1175, "t1": 6.08, "tft": 12.3058, "input_0": 6004, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 27.2, "mem_use": 52.78, "gen_rate": 9.0, "speed": 0.74, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 370, "tree_size": 2048, "t0": 7.1025, "t1": 6.09, "tft": 12.6246, "input_0": 7171, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 53.35, "gen_rate": 10.0, "speed": 0.76, "text": "Variance and sum of squares are "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.7, "tree_w": 354, "tree_size": 2048, "t0": 7.0017, "t1": 6.1183, "tft": 12.7534, "input_0": 6539, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 53.64, "gen_rate": 5.5, "speed": 0.42, "text": "\"Ride Your Way to Wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.2, "tree_w": 600, "tree_size": 2048, "t0": 5.784, "t1": 6.102, "tft": 12.5997, "input_0": 6236, "input_1": 2049, "min_CLP": -10.52, "draft_iters": 26.6, "mem_use": 53.43, "gen_rate": 8.2, "speed": 0.69, "text": "If you want to see the best star"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.0, "tree_w": 431, "tree_size": 2048, "t0": 6.974, "t1": 6.084, "tft": 12.2026, "input_0": 7097, "input_1": 2049, "min_CLP": -9.26, "draft_iters": 31.4, "mem_use": 52.77, "gen_rate": 7.6, "speed": 0.58, "text": "Here is a top 10 list of the fun"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.2, "tree_w": 465, "tree_size": 2048, "t0": 6.96, "t1": 6.1075, "tft": 12.2976, "input_0": 6801, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 32.0, "mem_use": 53.34, "gen_rate": 9.0, "speed": 0.69, "text": "If the two dropped eggs landed o"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.0, "tree_w": 415, "tree_size": 2048, "t0": 7.0067, "t1": 6.1033, "tft": 12.5046, "input_0": 6678, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 53.2, "gen_rate": 11.0, "speed": 0.84, "text": "The following are some ways to c"}
