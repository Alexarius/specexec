{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-1.5B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 330, "seed": 0, "dataset": "oasst", "timestamp": "2025-04-01 00:09:42", "date": "250401", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 516, "tree_size": 2048, "t0": 7.29, "t1": 6.23, "tft": 16.8269, "input_0": 9024, "input_1": 2049, "min_CLP": -9.86, "draft_iters": 32.0, "mem_use": 53.69, "gen_rate": 10.0, "speed": 0.74, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 11.3, "tree_w": 738, "tree_size": 2048, "t0": 5.2243, "t1": 6.1771, "tft": 12.2878, "input_0": 4024, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 26.0, "mem_use": 52.99, "gen_rate": 4.3, "speed": 0.38, "text": "I was not summoned here for my p"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 475, "tree_size": 2048, "t0": 7.18, "t1": 6.0, "tft": 20.1416, "input_0": 7549, "input_1": 2049, "min_CLP": -10.01, "draft_iters": 32.0, "mem_use": 55.48, "gen_rate": 11.0, "speed": 0.83, "text": "\"The monologue you presented off"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 445, "tree_size": 2048, "t0": 7.0033, "t1": 5.7233, "tft": 14.4511, "input_0": 6467, "input_1": 2049, "min_CLP": -10.42, "draft_iters": 32.0, "mem_use": 55.92, "gen_rate": 11.0, "speed": 0.86, "text": "[INST] AI assistant. I am lookin"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 508, "tree_size": 2048, "t0": 7.135, "t1": 6.165, "tft": 12.7826, "input_0": 9513, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 54.25, "gen_rate": 10.2, "speed": 0.77, "text": "It\\'s difficult to determine whi"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.2, "tree_w": 462, "tree_size": 2048, "t0": 7.055, "t1": 6.14, "tft": 12.7043, "input_0": 7200, "input_1": 2049, "min_CLP": -11.92, "draft_iters": 32.0, "mem_use": 53.5, "gen_rate": 9.8, "speed": 0.74, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.3, "tree_w": 599, "tree_size": 2048, "t0": 5.8317, "t1": 6.11, "tft": 12.5401, "input_0": 5248, "input_1": 2049, "min_CLP": -9.87, "draft_iters": 27.8, "mem_use": 53.25, "gen_rate": 6.2, "speed": 0.52, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.0, "tree_w": 422, "tree_size": 2048, "t0": 7.2175, "t1": 6.085, "tft": 12.1094, "input_0": 8059, "input_1": 2049, "min_CLP": -10.09, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 9.8, "speed": 0.73, "text": "To check your system drive for e"}
