{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-1.5B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "1024, 2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 200, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-28 17:08:28", "date": "250328", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.7, "tree_w": 108, "tree_size": 1024, "t0": 5.5567, "t1": 2.3267, "tft": 12.5352, "input_0": 4596, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 29.7, "mem_use": 48.46, "gen_rate": 12.3, "speed": 1.56, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 23.3, "tree_w": 172, "tree_size": 1024, "t0": 5.7333, "t1": 2.3067, "tft": 6.9593, "input_0": 4335, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 32.0, "mem_use": 46.73, "gen_rate": 14.0, "speed": 1.74, "text": "You should describe the task and"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 21.2, "tree_w": 135, "tree_size": 1024, "t0": 5.14, "t1": 2.2575, "tft": 6.8214, "input_0": 4249, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 30.0, "mem_use": 46.84, "gen_rate": 8.5, "speed": 1.15, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.2, "tree_w": 235, "tree_size": 1024, "t0": 3.68, "t1": 2.285, "tft": 8.8791, "input_0": 2927, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 20.5, "mem_use": 49.62, "gen_rate": 9.2, "speed": 1.55, "text": "Sure, here are some name ideas f"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 139, "tree_size": 1024, "t0": 4.6433, "t1": 2.28, "tft": 6.1071, "input_0": 3477, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 27.7, "mem_use": 46.79, "gen_rate": 13.0, "speed": 1.88, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 22.5, "tree_w": 122, "tree_size": 1024, "t0": 5.885, "t1": 2.3525, "tft": 11.3482, "input_0": 5134, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 32.0, "mem_use": 51.79, "gen_rate": 10.0, "speed": 1.21, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.2, "tree_w": 176, "tree_size": 1024, "t0": 4.45, "t1": 2.265, "tft": 5.8442, "input_0": 3252, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 25.8, "mem_use": 47.13, "gen_rate": 9.0, "speed": 1.34, "text": "You should install the parts in "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 139, "tree_size": 1024, "t0": 5.1233, "t1": 2.3067, "tft": 7.1303, "input_0": 4273, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 26.7, "mem_use": 46.98, "gen_rate": 11.7, "speed": 1.57, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.5, "tree_w": 212, "tree_size": 1024, "t0": 3.67, "t1": 2.285, "tft": 6.7281, "input_0": 3249, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 19.8, "mem_use": 47.04, "gen_rate": 6.8, "speed": 1.15, "text": "I will be free to say what I wan"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.0, "tree_w": 137, "tree_size": 1024, "t0": 5.3067, "t1": 2.3367, "tft": 8.5934, "input_0": 4580, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 26.3, "mem_use": 48.4, "gen_rate": 11.7, "speed": 1.53, "text": "The main PC components that play"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 20.8, "tree_w": 150, "tree_size": 1024, "t0": 5.565, "t1": 2.2775, "tft": 7.0703, "input_0": 4679, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 30.2, "mem_use": 47.11, "gen_rate": 11.8, "speed": 1.5, "text": "The Keyhole series is a group of"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.8, "tree_w": 189, "tree_size": 1024, "t0": 4.21, "t1": 2.296, "tft": 6.6125, "input_0": 3556, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 24.2, "mem_use": 47.28, "gen_rate": 7.4, "speed": 1.14, "text": "\"Here's a simple and delicious r"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 16.8, "tree_w": 177, "tree_size": 1024, "t0": 4.512, "t1": 2.292, "tft": 7.7059, "input_0": 3655, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 25.4, "mem_use": 47.34, "gen_rate": 10.2, "speed": 1.5, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.3, "tree_w": 142, "tree_size": 1024, "t0": 4.7767, "t1": 2.3033, "tft": 8.8104, "input_0": 4084, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 26.0, "mem_use": 49.25, "gen_rate": 11.3, "speed": 1.6, "text": "I\\'m sorry, as an AI language mo"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 21.3, "tree_w": 143, "tree_size": 1024, "t0": 5.1667, "t1": 2.3233, "tft": 6.4684, "input_0": 4069, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 30.0, "mem_use": 46.69, "gen_rate": 11.0, "speed": 1.47, "text": "A:\\n\\nYes, stainless steel can b"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 25.3, "tree_w": 141, "tree_size": 1024, "t0": 5.22, "t1": 2.3133, "tft": 7.2441, "input_0": 3708, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 32.0, "mem_use": 46.83, "gen_rate": 10.7, "speed": 1.42, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 275, "tree_size": 1024, "t0": 3.125, "t1": 2.3267, "tft": 7.8642, "input_0": 2838, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 16.7, "mem_use": 48.27, "gen_rate": 5.7, "speed": 1.04, "text": "\"When data's the name of the gam"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 22.7, "tree_w": 126, "tree_size": 1024, "t0": 5.5567, "t1": 2.3233, "tft": 9.278, "input_0": 4584, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 32.0, "mem_use": 49.42, "gen_rate": 14.3, "speed": 1.82, "text": "\"Indeed, the power of magic is a"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 24.5, "tree_w": 154, "tree_size": 1024, "t0": 5.055, "t1": 2.295, "tft": 6.6151, "input_0": 3530, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 32.0, "mem_use": 46.67, "gen_rate": 3.0, "speed": 0.41, "text": "The current date is [insert the "}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.3, "tree_w": 160, "tree_size": 1024, "t0": 4.56, "t1": 2.35, "tft": 7.8787, "input_0": 3950, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 26.0, "mem_use": 48.15, "gen_rate": 10.7, "speed": 1.54, "text": "Yes, you\\'re absolutely right. R"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 31, "tree_h": 17.2, "tree_w": 234, "tree_size": 1024, "t0": 3.958, "t1": 2.284, "tft": 6.0691, "input_0": 2988, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 24.4, "mem_use": 47.03, "gen_rate": 6.2, "speed": 0.99, "text": "\"That's so not true. Technology "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 24.0, "tree_w": 72, "tree_size": 1024, "t0": 6.1, "t1": 2.31, "tft": 6.0318, "input_0": 4263, "input_1": 1025, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 21.0, "speed": 2.5, "text": "To estimate the variance of a va"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 15, "tree_h": 26.0, "tree_w": 87, "tree_size": 1024, "t0": 5.21, "t1": 2.33, "tft": 6.9021, "input_0": 3709, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 32.0, "mem_use": 47.09, "gen_rate": 15.0, "speed": 1.99, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 14.8, "tree_w": 172, "tree_size": 1024, "t0": 4.216, "t1": 2.31, "tft": 5.9387, "input_0": 3788, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 23.0, "mem_use": 46.67, "gen_rate": 8.0, "speed": 1.23, "text": "Metabolism is the set of process"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 18.0, "tree_w": 157, "tree_size": 1024, "t0": 4.65, "t1": 2.356, "tft": 8.3689, "input_0": 3774, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 25.8, "mem_use": 48.01, "gen_rate": 7.2, "speed": 1.03, "text": "\"Great! You're welcome. If you h"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 26.0, "tree_w": 230, "tree_size": 1024, "t0": 4.61, "t1": 2.34, "tft": 6.6683, "input_0": 3065, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 32.0, "mem_use": 46.86, "gen_rate": 0.0, "speed": 0.0, "text": "Answer: John"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 19.0, "tree_w": 142, "tree_size": 1024, "t0": 4.805, "t1": 2.28, "tft": 7.3122, "input_0": 3508, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 27.5, "mem_use": 47.25, "gen_rate": 18.0, "speed": 2.54, "text": "The oceans in the world are:\\n1."}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.7, "tree_w": 202, "tree_size": 1024, "t0": 3.8614, "t1": 2.3357, "tft": 7.2862, "input_0": 3206, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 20.9, "mem_use": 47.48, "gen_rate": 5.0, "speed": 0.81, "text": "To start, you should consider th"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 23.0, "tree_w": 122, "tree_size": 1024, "t0": 5.44, "t1": 2.3125, "tft": 7.4872, "input_0": 4050, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 31.5, "mem_use": 46.89, "gen_rate": 9.5, "speed": 1.23, "text": "\"# Basic PyGame project with ESC"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.3, "tree_w": 152, "tree_size": 1024, "t0": 4.34, "t1": 2.3533, "tft": 8.1353, "input_0": 3688, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 23.7, "mem_use": 47.99, "gen_rate": 11.3, "speed": 1.69, "text": "DLL stands for \"Dynamic Link Lib"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.5, "tree_w": 194, "tree_size": 1024, "t0": 4.3375, "t1": 2.315, "tft": 6.1562, "input_0": 4044, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 23.5, "mem_use": 47.14, "gen_rate": 8.5, "speed": 1.28, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 15.5, "tree_w": 202, "tree_size": 1024, "t0": 4.1133, "t1": 2.3233, "tft": 6.0719, "input_0": 3458, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 23.8, "mem_use": 46.68, "gen_rate": 5.3, "speed": 0.83, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 143, "tree_size": 1024, "t0": 5.02, "t1": 2.295, "tft": 6.9716, "input_0": 4146, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 29.5, "mem_use": 46.79, "gen_rate": 8.2, "speed": 1.13, "text": "Here is a high-quality testing f"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 11.0, "tree_w": 286, "tree_size": 1024, "t0": 3.228, "t1": 2.338, "tft": 7.2593, "input_0": 2677, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 17.8, "mem_use": 46.94, "gen_rate": 5.6, "speed": 1.01, "text": "\"You can't deny that they are a "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.3, "tree_w": 264, "tree_size": 1024, "t0": 3.6283, "t1": 2.3517, "tft": 7.5029, "input_0": 2774, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 21.2, "mem_use": 47.46, "gen_rate": 5.7, "speed": 0.95, "text": "\"Well, I don't like the show bec"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 169, "tree_size": 1024, "t0": 4.8525, "t1": 2.355, "tft": 7.6663, "input_0": 4161, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 25.5, "mem_use": 48.31, "gen_rate": 8.5, "speed": 1.18, "text": "\"I'm here to help you with any q"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.3, "tree_w": 94, "tree_size": 1024, "t0": 6.2567, "t1": 2.34, "tft": 8.8885, "input_0": 4887, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 32.0, "mem_use": 48.83, "gen_rate": 15.7, "speed": 1.82, "text": "There are many languages that ar"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 16.8, "tree_w": 170, "tree_size": 1024, "t0": 4.618, "t1": 2.348, "tft": 7.6069, "input_0": 3851, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 25.6, "mem_use": 47.28, "gen_rate": 8.0, "speed": 1.15, "text": "\"Most of these AI tools offer fr"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 173, "tree_size": 1024, "t0": 3.9125, "t1": 2.3425, "tft": 7.2253, "input_0": 3494, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 20.8, "mem_use": 47.15, "gen_rate": 8.8, "speed": 1.4, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.7, "tree_w": 180, "tree_size": 1024, "t0": 4.205, "t1": 2.3633, "tft": 7.2471, "input_0": 3723, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 23.0, "mem_use": 47.36, "gen_rate": 5.7, "speed": 0.86, "text": "I understand that labeling promp"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.3, "tree_w": 124, "tree_size": 1024, "t0": 5.05, "t1": 2.3467, "tft": 7.9861, "input_0": 4060, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 28.0, "mem_use": 47.37, "gen_rate": 11.0, "speed": 1.49, "text": "The \"A\" in AK-47 stands for Avto"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 16.7, "tree_w": 179, "tree_size": 1024, "t0": 4.385, "t1": 2.31, "tft": 6.9446, "input_0": 3298, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 25.2, "mem_use": 46.8, "gen_rate": 5.7, "speed": 0.85, "text": "\"<|bot|> As an AI language model"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 17.0, "tree_w": 169, "tree_size": 1024, "t0": 4.524, "t1": 2.382, "tft": 8.5476, "input_0": 3336, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 25.2, "mem_use": 48.46, "gen_rate": 7.8, "speed": 1.13, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 15.9, "tree_w": 232, "tree_size": 1024, "t0": 4.1757, "t1": 2.3371, "tft": 7.4733, "input_0": 3205, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 24.0, "mem_use": 46.94, "gen_rate": 4.6, "speed": 0.7, "text": "\"Hippoplaisir's psychomotor ther"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 286, "tree_size": 1024, "t0": 4.18, "t1": 2.335, "tft": 7.132, "input_0": 3611, "input_1": 1025, "min_CLP": -8.75, "draft_iters": 22.0, "mem_use": 46.77, "gen_rate": 8.5, "speed": 1.3, "text": "Sure, here\\'s a list of ten name"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 21.2, "tree_w": 140, "tree_size": 1024, "t0": 5.06, "t1": 2.372, "tft": 6.9839, "input_0": 3748, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 29.4, "mem_use": 47.25, "gen_rate": 8.2, "speed": 1.1, "text": "I\\'m doing well, thank you for a"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 20.0, "tree_w": 135, "tree_size": 1024, "t0": 4.978, "t1": 2.348, "tft": 9.0191, "input_0": 4130, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 28.6, "mem_use": 48.93, "gen_rate": 8.0, "speed": 1.09, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 213, "tree_size": 1024, "t0": 3.525, "t1": 2.3617, "tft": 7.4259, "input_0": 3100, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 19.2, "mem_use": 47.72, "gen_rate": 5.7, "speed": 0.96, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.3, "tree_w": 147, "tree_size": 1024, "t0": 5.3167, "t1": 2.3733, "tft": 8.4022, "input_0": 4370, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 29.0, "mem_use": 48.15, "gen_rate": 10.7, "speed": 1.39, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 91, "tree_size": 1024, "t0": 5.945, "t1": 2.34, "tft": 6.6091, "input_0": 4506, "input_1": 1025, "min_CLP": -9.11, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 25.5, "speed": 3.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.0, "tree_w": 273, "tree_size": 1024, "t0": 4.35, "t1": 2.4975, "tft": 10.3991, "input_0": 3621, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 24.2, "mem_use": 51.44, "gen_rate": 8.5, "speed": 1.24, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 19.2, "tree_w": 154, "tree_size": 1024, "t0": 4.874, "t1": 2.36, "tft": 8.268, "input_0": 3673, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 28.2, "mem_use": 47.86, "gen_rate": 7.4, "speed": 1.02, "text": "To transform other text words or"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 19.5, "tree_w": 128, "tree_size": 1024, "t0": 5.0475, "t1": 2.355, "tft": 8.2791, "input_0": 3952, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 28.0, "mem_use": 47.72, "gen_rate": 10.2, "speed": 1.38, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 20.5, "tree_w": 127, "tree_size": 1024, "t0": 5.655, "t1": 2.325, "tft": 6.0767, "input_0": 5056, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 30.5, "mem_use": 46.74, "gen_rate": 18.5, "speed": 2.32, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.8, "tree_w": 243, "tree_size": 1024, "t0": 3.835, "t1": 2.3425, "tft": 6.7319, "input_0": 3433, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 21.5, "mem_use": 47.08, "gen_rate": 8.2, "speed": 1.33, "text": "\"You got me, here's another one:"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 14.0, "tree_w": 197, "tree_size": 1024, "t0": 4.2867, "t1": 2.3267, "tft": 5.8616, "input_0": 3762, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 23.3, "mem_use": 46.7, "gen_rate": 8.7, "speed": 1.31, "text": "There are approximately 100 know"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 192, "tree_size": 1024, "t0": 4.35, "t1": 2.45, "tft": 10.5438, "input_0": 3061, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 28.0, "mem_use": 51.5, "gen_rate": 10.7, "speed": 1.57, "text": "I apologize for misunderstanding"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.2, "tree_w": 153, "tree_size": 1024, "t0": 5.4125, "t1": 2.3525, "tft": 6.7866, "input_0": 4328, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 30.0, "mem_use": 46.78, "gen_rate": 9.8, "speed": 1.26, "text": "The furthest back we can scienti"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 151, "tree_size": 1024, "t0": 4.8075, "t1": 2.4875, "tft": 12.1484, "input_0": 3972, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.5, "mem_use": 53.73, "gen_rate": 8.8, "speed": 1.2, "text": "Thank you for explaining the Mal"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 15.2, "tree_w": 241, "tree_size": 1024, "t0": 3.7867, "t1": 2.375, "tft": 7.8142, "input_0": 2818, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 22.7, "mem_use": 47.96, "gen_rate": 6.7, "speed": 1.08, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 18.8, "tree_w": 168, "tree_size": 1024, "t0": 4.54, "t1": 2.35, "tft": 7.0553, "input_0": 3602, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 27.0, "mem_use": 46.81, "gen_rate": 6.6, "speed": 0.96, "text": "The human genome is a complex sy"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 19.0, "tree_w": 136, "tree_size": 1024, "t0": 5.18, "t1": 2.35, "tft": 6.543, "input_0": 4161, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 28.2, "mem_use": 46.68, "gen_rate": 8.8, "speed": 1.17, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.5, "tree_w": 237, "tree_size": 1024, "t0": 3.71, "t1": 2.36, "tft": 6.8036, "input_0": 3242, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 20.5, "mem_use": 46.92, "gen_rate": 5.5, "speed": 0.91, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.3, "tree_w": 118, "tree_size": 1024, "t0": 5.8067, "t1": 2.39, "tft": 6.595, "input_0": 4784, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 30.3, "mem_use": 47.22, "gen_rate": 12.3, "speed": 1.5, "text": "Sure, here are a few TV show rec"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 21.5, "tree_w": 106, "tree_size": 1024, "t0": 6.2375, "t1": 2.3975, "tft": 10.039, "input_0": 5250, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 32.0, "mem_use": 48.83, "gen_rate": 9.8, "speed": 1.13, "text": "\"Sure, here are some software an"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.5, "tree_w": 141, "tree_size": 1024, "t0": 4.8375, "t1": 2.3725, "tft": 8.2099, "input_0": 3836, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 28.2, "mem_use": 47.94, "gen_rate": 8.0, "speed": 1.11, "text": "When F-centers are present in a "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 22.7, "tree_w": 219, "tree_size": 1024, "t0": 4.4814, "t1": 2.36, "tft": 6.9476, "input_0": 2953, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 29.3, "mem_use": 46.86, "gen_rate": 4.7, "speed": 0.69, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 24.0, "tree_w": 104, "tree_size": 1024, "t0": 5.5833, "t1": 2.3967, "tft": 9.3017, "input_0": 4166, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 32.0, "mem_use": 49.48, "gen_rate": 15.0, "speed": 1.88, "text": "\"Sure, here's the same code with"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 16.8, "tree_w": 193, "tree_size": 1024, "t0": 4.21, "t1": 2.3883, "tft": 8.4954, "input_0": 3381, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 24.8, "mem_use": 47.97, "gen_rate": 6.2, "speed": 0.93, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 169, "tree_size": 1024, "t0": 4.4075, "t1": 2.39, "tft": 6.3756, "input_0": 3877, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 23.8, "mem_use": 46.7, "gen_rate": 8.2, "speed": 1.21, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 20.5, "tree_w": 170, "tree_size": 1024, "t0": 4.47, "t1": 2.34, "tft": 6.8398, "input_0": 3185, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 28.0, "mem_use": 46.78, "gen_rate": 6.5, "speed": 0.95, "text": "```markdown\\n```markdown\\n# This"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.3, "tree_w": 140, "tree_size": 1024, "t0": 5.2, "t1": 2.37, "tft": 8.0581, "input_0": 4074, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 28.0, "mem_use": 47.81, "gen_rate": 10.7, "speed": 1.41, "text": "\"Sure! Here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 22.7, "tree_w": 135, "tree_size": 1024, "t0": 5.18, "t1": 2.4167, "tft": 8.7436, "input_0": 4109, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 30.7, "mem_use": 48.76, "gen_rate": 13.0, "speed": 1.71, "text": "\"In JavaScript, you can achieve "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.2, "tree_w": 240, "tree_size": 1024, "t0": 3.876, "t1": 2.388, "tft": 7.2758, "input_0": 3274, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 20.8, "mem_use": 47.3, "gen_rate": 6.6, "speed": 1.05, "text": "\"Of course! Here's a simple trai"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.8, "tree_w": 134, "tree_size": 1024, "t0": 5.1575, "t1": 2.375, "tft": 8.2935, "input_0": 4052, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 27.2, "mem_use": 47.78, "gen_rate": 8.8, "speed": 1.16, "text": "My previous response assumed tha"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.5, "tree_w": 157, "tree_size": 1024, "t0": 5.095, "t1": 2.3625, "tft": 6.1963, "input_0": 4340, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 28.0, "mem_use": 46.69, "gen_rate": 10.5, "speed": 1.41, "text": "\"JavaScript is a versatile progr"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.6, "tree_w": 155, "tree_size": 1024, "t0": 4.472, "t1": 2.366, "tft": 6.8621, "input_0": 3505, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 25.0, "mem_use": 46.68, "gen_rate": 7.0, "speed": 1.02, "text": "The L-theanine chemical is found"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 21.2, "tree_w": 117, "tree_size": 1024, "t0": 5.5175, "t1": 2.385, "tft": 7.824, "input_0": 4180, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 30.5, "mem_use": 47.4, "gen_rate": 8.8, "speed": 1.11, "text": "\"Sure! Here's a list of the 5 wo"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 17.0, "tree_w": 221, "tree_size": 1024, "t0": 4.27, "t1": 2.364, "tft": 7.0274, "input_0": 3479, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 25.2, "mem_use": 46.81, "gen_rate": 8.2, "speed": 1.24, "text": "\"Hippoplaisir is a psychologists"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.8, "tree_w": 188, "tree_size": 1024, "t0": 3.8625, "t1": 2.385, "tft": 6.5614, "input_0": 3267, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 20.8, "mem_use": 46.81, "gen_rate": 8.5, "speed": 1.36, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 19.0, "tree_w": 156, "tree_size": 1024, "t0": 4.625, "t1": 2.36, "tft": 6.6388, "input_0": 3285, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 27.0, "mem_use": 46.78, "gen_rate": 16.0, "speed": 2.29, "text": "To memorize how to write Chinese"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 24.2, "tree_w": 181, "tree_size": 1024, "t0": 4.765, "t1": 2.47, "tft": 9.6394, "input_0": 3407, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 31.5, "mem_use": 51.55, "gen_rate": 8.2, "speed": 1.14, "text": "\"Here's a revised version of the"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 18.3, "tree_w": 148, "tree_size": 1024, "t0": 4.54, "t1": 2.3967, "tft": 9.85, "input_0": 3404, "input_1": 1025, "min_CLP": -7.31, "draft_iters": 26.7, "mem_use": 49.17, "gen_rate": 12.7, "speed": 1.83, "text": "\"Sure! Imagine you have a puzzle"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 19.3, "tree_w": 96, "tree_size": 1024, "t0": 6.5567, "t1": 2.3833, "tft": 8.3158, "input_0": 5795, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 47.61, "gen_rate": 14.0, "speed": 1.57, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.7, "tree_w": 161, "tree_size": 1024, "t0": 4.71, "t1": 2.39, "tft": 7.4632, "input_0": 3834, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 26.7, "mem_use": 47.78, "gen_rate": 11.3, "speed": 1.6, "text": "Oh, the lessons we can learn fro"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.5, "tree_w": 141, "tree_size": 1024, "t0": 5.0, "t1": 2.405, "tft": 8.7566, "input_0": 3769, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 28.5, "mem_use": 48.84, "gen_rate": 9.2, "speed": 1.25, "text": "You can serve lemon wedges with "}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.0, "tree_w": 145, "tree_size": 1024, "t0": 4.865, "t1": 2.3525, "tft": 7.0382, "input_0": 4072, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 25.8, "mem_use": 46.87, "gen_rate": 10.0, "speed": 1.39, "text": "\"Sure, I'll be happy to play the"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 14.7, "tree_w": 217, "tree_size": 1024, "t0": 3.8814, "t1": 2.3729, "tft": 6.2406, "input_0": 2894, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 22.4, "mem_use": 46.83, "gen_rate": 5.7, "speed": 0.91, "text": "\"I'm sorry to hear that. Please "}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.5, "tree_w": 79, "tree_size": 1024, "t0": 6.23, "t1": 2.36, "tft": 6.6224, "input_0": 4676, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 16.5, "speed": 1.92, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.5, "tree_w": 135, "tree_size": 1024, "t0": 4.465, "t1": 2.405, "tft": 8.7078, "input_0": 3657, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 24.0, "mem_use": 48.29, "gen_rate": 8.5, "speed": 1.24, "text": "There are some examples of citie"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 16.6, "tree_w": 150, "tree_size": 1024, "t0": 5.052, "t1": 2.402, "tft": 7.9734, "input_0": 4445, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 26.8, "mem_use": 47.82, "gen_rate": 7.8, "speed": 1.05, "text": "In addition to the Dyson Sphere,"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.0, "tree_w": 187, "tree_size": 1024, "t0": 4.9667, "t1": 2.3733, "tft": 5.3225, "input_0": 3651, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 27.3, "mem_use": 46.67, "gen_rate": 11.3, "speed": 1.54, "text": "def get_max(numbers):\\n    max_n"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.8, "tree_w": 256, "tree_size": 1024, "t0": 4.05, "t1": 2.398, "tft": 7.6085, "input_0": 3384, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 22.4, "mem_use": 47.42, "gen_rate": 7.0, "speed": 1.09, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 18.4, "tree_w": 170, "tree_size": 1024, "t0": 4.946, "t1": 2.41, "tft": 9.2579, "input_0": 3754, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 26.8, "mem_use": 48.02, "gen_rate": 6.8, "speed": 0.92, "text": "Of course! Here is the full lyri"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.8, "tree_w": 150, "tree_size": 1024, "t0": 5.0675, "t1": 2.38, "tft": 7.0712, "input_0": 3957, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 26.5, "mem_use": 47.03, "gen_rate": 10.0, "speed": 1.34, "text": "1.    Prioritize and manage work"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 17.0, "tree_w": 140, "tree_size": 1024, "t0": 4.942, "t1": 2.386, "tft": 6.6487, "input_0": 4300, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 26.4, "mem_use": 46.7, "gen_rate": 8.8, "speed": 1.2, "text": "Sure! Self-attention mechanism i"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.5, "tree_w": 164, "tree_size": 1024, "t0": 4.565, "t1": 2.375, "tft": 7.0612, "input_0": 3760, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.5, "mem_use": 47.26, "gen_rate": 9.5, "speed": 1.37, "text": "TensorFlow and PyTorch are two o"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.8, "tree_w": 180, "tree_size": 1024, "t0": 4.775, "t1": 2.4, "tft": 8.0778, "input_0": 4018, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 26.0, "mem_use": 47.7, "gen_rate": 8.0, "speed": 1.11, "text": "[Mathematical questions]: {How c"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 22.0, "tree_w": 155, "tree_size": 1024, "t0": 4.64, "t1": 2.398, "tft": 7.4973, "input_0": 3287, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 29.0, "mem_use": 47.37, "gen_rate": 7.8, "speed": 1.11, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 98, "tree_size": 1024, "t0": 6.1, "t1": 2.425, "tft": 9.3584, "input_0": 4845, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 32.0, "mem_use": 49.49, "gen_rate": 24.0, "speed": 2.82, "text": "\"Yes, I apologize for the confus"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.7, "tree_w": 111, "tree_size": 1024, "t0": 5.6, "t1": 2.47, "tft": 9.6932, "input_0": 4667, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 29.7, "mem_use": 51.07, "gen_rate": 11.7, "speed": 1.45, "text": "\"For vegan cheese, some popular "}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.6, "tree_w": 148, "tree_size": 1024, "t0": 4.652, "t1": 2.41, "tft": 7.7049, "input_0": 3877, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 25.4, "mem_use": 48.08, "gen_rate": 7.0, "speed": 0.99, "text": "As an AI language model, I am no"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 95, "tree_size": 1024, "t0": 6.76, "t1": 2.405, "tft": 8.9669, "input_0": 5620, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 32.0, "mem_use": 48.47, "gen_rate": 20.0, "speed": 2.18, "text": "Sure, here are three of the most"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.7, "tree_w": 121, "tree_size": 1024, "t0": 5.6033, "t1": 2.3867, "tft": 6.11, "input_0": 4566, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 29.7, "mem_use": 46.7, "gen_rate": 11.7, "speed": 1.46, "text": "Sure! In Python, both sets and l"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 14.4, "tree_w": 218, "tree_size": 1024, "t0": 3.748, "t1": 2.39, "tft": 8.359, "input_0": 3380, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 21.6, "mem_use": 48.04, "gen_rate": 8.4, "speed": 1.37, "text": "Based on the current date of 20t"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.5, "tree_w": 115, "tree_size": 1024, "t0": 6.455, "t1": 2.385, "tft": 6.8312, "input_0": 5830, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 32.0, "mem_use": 46.87, "gen_rate": 16.5, "speed": 1.87, "text": "\"Sure, I'd be happy to tell you "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 16.3, "tree_w": 168, "tree_size": 1024, "t0": 4.465, "t1": 2.3883, "tft": 7.3289, "input_0": 3623, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 24.7, "mem_use": 46.75, "gen_rate": 7.7, "speed": 1.12, "text": "To cook an egg using direct sunl"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 84, "tree_size": 1024, "t0": 6.24, "t1": 2.39, "tft": 7.0921, "input_0": 4724, "input_1": 1025, "min_CLP": -11.35, "draft_iters": 32.0, "mem_use": 46.74, "gen_rate": 24.5, "speed": 2.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.5, "tree_w": 336, "tree_size": 1024, "t0": 2.7513, "t1": 2.3825, "tft": 5.977, "input_0": 2334, "input_1": 1025, "min_CLP": -8.59, "draft_iters": 14.5, "mem_use": 46.69, "gen_rate": 4.4, "speed": 0.85, "text": "\"my name is alyssa, i'm 28 and i"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 25.0, "tree_w": 78, "tree_size": 1024, "t0": 5.77, "t1": 2.39, "tft": 8.7908, "input_0": 4313, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 32.0, "mem_use": 47.96, "gen_rate": 18.0, "speed": 2.21, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 23.7, "tree_w": 96, "tree_size": 1024, "t0": 6.06, "t1": 2.3867, "tft": 8.146, "input_0": 4611, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 32.0, "mem_use": 47.08, "gen_rate": 10.7, "speed": 1.26, "text": "# Install the Tailwind CLI globa"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 16.0, "tree_w": 188, "tree_size": 1024, "t0": 4.174, "t1": 2.492, "tft": 10.6504, "input_0": 3386, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 23.8, "mem_use": 52.16, "gen_rate": 6.6, "speed": 0.99, "text": "There is some evidence that the "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.2, "tree_w": 164, "tree_size": 1024, "t0": 4.9375, "t1": 2.3825, "tft": 5.9397, "input_0": 4174, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 28.5, "mem_use": 47.21, "gen_rate": 9.2, "speed": 1.26, "text": "Large language models (LLMs) req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 149, "tree_size": 1024, "t0": 5.72, "t1": 2.4, "tft": 5.8006, "input_0": 4234, "input_1": 1025, "min_CLP": -9.01, "draft_iters": 32.0, "mem_use": 46.78, "gen_rate": 23.5, "speed": 2.89, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 22.3, "tree_w": 124, "tree_size": 1024, "t0": 5.3967, "t1": 2.3567, "tft": 7.1331, "input_0": 4207, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 30.7, "mem_use": 46.99, "gen_rate": 10.7, "speed": 1.38, "text": "Here\\'s a potential eulogy for y"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 21.4, "tree_w": 148, "tree_size": 1024, "t0": 4.994, "t1": 2.428, "tft": 7.9817, "input_0": 3743, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 29.6, "mem_use": 48.47, "gen_rate": 8.2, "speed": 1.1, "text": "\"No, that's all for now. Thanks "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.2, "tree_w": 143, "tree_size": 1024, "t0": 4.475, "t1": 2.4075, "tft": 7.7115, "input_0": 3727, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 24.0, "mem_use": 46.86, "gen_rate": 9.8, "speed": 1.42, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 15.0, "tree_w": 158, "tree_size": 1024, "t0": 4.382, "t1": 2.396, "tft": 6.6232, "input_0": 3715, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 23.4, "mem_use": 46.83, "gen_rate": 8.0, "speed": 1.18, "text": "Sure, here are a few options to "}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.0, "tree_w": 181, "tree_size": 1024, "t0": 4.3475, "t1": 2.3875, "tft": 5.7297, "input_0": 3782, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 24.5, "mem_use": 46.68, "gen_rate": 9.2, "speed": 1.37, "text": "The color of Mars is often descr"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.5, "tree_w": 275, "tree_size": 1024, "t0": 3.805, "t1": 2.4433, "tft": 8.6852, "input_0": 3162, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 22.5, "mem_use": 48.9, "gen_rate": 5.7, "speed": 0.91, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.5, "tree_w": 122, "tree_size": 1024, "t0": 5.705, "t1": 2.38, "tft": 7.2367, "input_0": 4773, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 30.0, "mem_use": 46.76, "gen_rate": 18.0, "speed": 2.23, "text": "Sure, I\\'d be happy to summarize"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.8, "tree_w": 144, "tree_size": 1024, "t0": 4.6375, "t1": 2.4, "tft": 7.2671, "input_0": 3850, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 26.8, "mem_use": 47.3, "gen_rate": 8.0, "speed": 1.14, "text": "No, the ATF does not restrict fi"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 23.7, "tree_w": 88, "tree_size": 1024, "t0": 5.85, "t1": 2.3833, "tft": 7.134, "input_0": 4363, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 11.7, "speed": 1.42, "text": "Yes, there are formulas that can"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 19.2, "tree_w": 137, "tree_size": 1024, "t0": 5.3625, "t1": 2.41, "tft": 7.9276, "input_0": 4779, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 29.2, "mem_use": 47.19, "gen_rate": 10.8, "speed": 1.38, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 18.2, "tree_w": 161, "tree_size": 1024, "t0": 4.4625, "t1": 2.3875, "tft": 7.1999, "input_0": 3311, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 26.0, "mem_use": 46.87, "gen_rate": 6.5, "speed": 0.95, "text": "New South Wales, Sydney was the "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.3, "tree_w": 148, "tree_size": 1024, "t0": 5.0567, "t1": 2.4133, "tft": 7.6577, "input_0": 3667, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 28.7, "mem_use": 47.04, "gen_rate": 10.7, "speed": 1.43, "text": "\"[INST] Hello, how are you? [\\\\I"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.0, "tree_w": 126, "tree_size": 1024, "t0": 4.9233, "t1": 2.4333, "tft": 9.0814, "input_0": 4019, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 26.7, "mem_use": 49.27, "gen_rate": 13.3, "speed": 1.81, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.8, "tree_w": 260, "tree_size": 1024, "t0": 3.5417, "t1": 2.3917, "tft": 6.7545, "input_0": 2892, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 20.0, "mem_use": 46.87, "gen_rate": 5.5, "speed": 0.93, "text": "\"Yes, this is a real story. It h"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 112, "tree_size": 1024, "t0": 5.745, "t1": 2.445, "tft": 8.716, "input_0": 4019, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 32.0, "mem_use": 48.15, "gen_rate": 24.5, "speed": 2.99, "text": "Let vector A be a vector with it"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 17.7, "tree_w": 170, "tree_size": 1024, "t0": 4.555, "t1": 2.39, "tft": 5.9899, "input_0": 3586, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 26.2, "mem_use": 46.73, "gen_rate": 6.7, "speed": 0.96, "text": "## Issues with Symmetric Probabi"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.5, "tree_w": 209, "tree_size": 1024, "t0": 4.1967, "t1": 2.3983, "tft": 6.7185, "input_0": 3952, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 23.0, "mem_use": 46.78, "gen_rate": 6.2, "speed": 0.93, "text": "\"Ah, the Elder Scrolls universe."}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 18.5, "tree_w": 197, "tree_size": 1024, "t0": 4.2433, "t1": 2.38, "tft": 7.1653, "input_0": 3165, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 26.3, "mem_use": 46.73, "gen_rate": 6.3, "speed": 0.96, "text": "You should know that L\u2019Hopital\u2019s"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 15.0, "tree_w": 391, "tree_size": 1024, "t0": 2.99, "t1": 2.42, "tft": 7.5139, "input_0": 2750, "input_1": 1025, "min_CLP": -9.57, "draft_iters": 19.5, "mem_use": 47.3, "gen_rate": 4.5, "speed": 0.83, "text": "Sum of squares error is the same"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 17.5, "tree_w": 194, "tree_size": 1024, "t0": 4.0225, "t1": 2.4175, "tft": 8.2675, "input_0": 2823, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 24.5, "mem_use": 47.6, "gen_rate": 6.0, "speed": 0.93, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.2, "tree_w": 189, "tree_size": 1024, "t0": 3.884, "t1": 2.4, "tft": 7.4272, "input_0": 3397, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 21.2, "mem_use": 47.38, "gen_rate": 8.2, "speed": 1.3, "text": "The best place in the lower 48 s"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 247, "tree_size": 1024, "t0": 3.48, "t1": 2.3967, "tft": 7.1863, "input_0": 3111, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 18.3, "mem_use": 46.72, "gen_rate": 5.5, "speed": 0.94, "text": "Top 10 Funniest Ways to Die:\\n1."}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 17.7, "tree_w": 187, "tree_size": 1024, "t0": 4.47, "t1": 2.4167, "tft": 7.2503, "input_0": 3426, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 26.2, "mem_use": 47.28, "gen_rate": 7.3, "speed": 1.06, "text": "If the two dropped eggs landed o"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 21.0, "tree_w": 150, "tree_size": 1024, "t0": 4.9633, "t1": 2.3967, "tft": 7.1893, "input_0": 4101, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 29.3, "mem_use": 47.15, "gen_rate": 14.3, "speed": 1.95, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 22.0, "tree_w": 150, "tree_size": 1024, "t0": 5.4733, "t1": 2.4433, "tft": 10.0727, "input_0": 4118, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 31.7, "mem_use": 50.23, "gen_rate": 14.0, "speed": 1.77, "text": "Certainly, here are some tools f"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 22.0, "tree_w": 99, "tree_size": 1024, "t0": 5.89, "t1": 2.4267, "tft": 9.0862, "input_0": 4662, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 31.3, "mem_use": 48.9, "gen_rate": 12.7, "speed": 1.52, "text": "Building your own PC has several"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 28, "tree_h": 22.3, "tree_w": 135, "tree_size": 1024, "t0": 5.4833, "t1": 2.3833, "tft": 6.1423, "input_0": 3988, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 31.7, "mem_use": 46.68, "gen_rate": 9.3, "speed": 1.19, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 19.5, "tree_w": 179, "tree_size": 1024, "t0": 5.6925, "t1": 2.3975, "tft": 6.9908, "input_0": 4498, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 30.2, "mem_use": 46.93, "gen_rate": 11.8, "speed": 1.45, "text": "Here is a list of 5 words where "}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 158, "tree_size": 1024, "t0": 4.7075, "t1": 2.545, "tft": 13.4451, "input_0": 4033, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 24.5, "mem_use": 53.75, "gen_rate": 8.8, "speed": 1.21, "text": "Certainly! The `_physics_process"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 143, "tree_size": 1024, "t0": 4.3833, "t1": 2.4067, "tft": 7.9631, "input_0": 3549, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 22.7, "mem_use": 47.11, "gen_rate": 10.7, "speed": 1.57, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 17.5, "tree_w": 238, "tree_size": 1024, "t0": 4.77, "t1": 2.39, "tft": 6.7722, "input_0": 4087, "input_1": 1025, "min_CLP": -8.84, "draft_iters": 25.8, "mem_use": 46.81, "gen_rate": 13.8, "speed": 1.92, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.8, "tree_w": 200, "tree_size": 1024, "t0": 3.968, "t1": 2.412, "tft": 4.0355, "input_0": 3110, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 23.4, "mem_use": 46.78, "gen_rate": 7.2, "speed": 1.13, "text": "The Wyoming statutes address pub"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.3, "tree_w": 175, "tree_size": 1024, "t0": 4.4567, "t1": 2.4433, "tft": 8.5629, "input_0": 4091, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 23.7, "mem_use": 49.35, "gen_rate": 12.0, "speed": 1.74, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 109, "tree_size": 1024, "t0": 6.61, "t1": 2.41, "tft": 7.6997, "input_0": 5725, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 32.0, "mem_use": 47.23, "gen_rate": 20.5, "speed": 2.27, "text": "Certainly, here are some of the "}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 21.5, "tree_w": 195, "tree_size": 1024, "t0": 4.7438, "t1": 2.4162, "tft": 7.633, "input_0": 3480, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 29.4, "mem_use": 47.42, "gen_rate": 5.8, "speed": 0.8, "text": "I know that. I was trying to tes"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.7, "tree_w": 262, "tree_size": 1024, "t0": 3.7533, "t1": 2.4167, "tft": 6.3515, "input_0": 3361, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 21.0, "mem_use": 47.02, "gen_rate": 11.7, "speed": 1.89, "text": "To enhance the visual quality of"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.8, "tree_w": 210, "tree_size": 1024, "t0": 4.256, "t1": 2.418, "tft": 7.43, "input_0": 3068, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 24.6, "mem_use": 47.26, "gen_rate": 6.4, "speed": 0.96, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.8, "tree_w": 210, "tree_size": 1024, "t0": 3.75, "t1": 2.398, "tft": 5.9582, "input_0": 3148, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 21.2, "mem_use": 47.04, "gen_rate": 6.4, "speed": 1.04, "text": "\"In that case, it is important t"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.0, "tree_w": 179, "tree_size": 1024, "t0": 4.03, "t1": 2.4425, "tft": 9.2236, "input_0": 3343, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 23.5, "mem_use": 49.02, "gen_rate": 8.2, "speed": 1.27, "text": "\"It's always a good idea to prep"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 22.7, "tree_w": 141, "tree_size": 1024, "t0": 5.0833, "t1": 2.3867, "tft": 7.1742, "input_0": 3651, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 30.3, "mem_use": 46.81, "gen_rate": 15.3, "speed": 2.05, "text": "Canberra is located in southeast"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 20.3, "tree_w": 140, "tree_size": 1024, "t0": 5.4233, "t1": 2.4067, "tft": 6.6218, "input_0": 4341, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 29.7, "mem_use": 46.82, "gen_rate": 13.3, "speed": 1.7, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfC\u00f3"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 185, "tree_size": 1024, "t0": 4.232, "t1": 2.406, "tft": 7.1604, "input_0": 3732, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 22.0, "mem_use": 46.8, "gen_rate": 7.6, "speed": 1.14, "text": "F-centers, also known as Frenkel"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.3, "tree_w": 220, "tree_size": 1024, "t0": 5.0433, "t1": 2.52, "tft": 10.3254, "input_0": 4245, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 26.7, "mem_use": 51.35, "gen_rate": 11.3, "speed": 1.5, "text": "You\\'re welcome! Let me know if "}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 22.0, "tree_w": 141, "tree_size": 1024, "t0": 5.46, "t1": 2.4325, "tft": 8.288, "input_0": 4596, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 31.2, "mem_use": 48.44, "gen_rate": 11.5, "speed": 1.46, "text": "Apologies for misunderstanding y"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 20.3, "tree_w": 112, "tree_size": 1024, "t0": 5.99, "t1": 2.3867, "tft": 7.4363, "input_0": 5175, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 30.7, "mem_use": 47.23, "gen_rate": 15.0, "speed": 1.79, "text": "\"Certainly! Here's a list of pro"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.0, "tree_w": 169, "tree_size": 1024, "t0": 4.525, "t1": 2.4425, "tft": 9.2538, "input_0": 3982, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 25.5, "mem_use": 49.13, "gen_rate": 8.8, "speed": 1.26, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 20.2, "tree_w": 161, "tree_size": 1024, "t0": 4.994, "t1": 2.426, "tft": 9.3005, "input_0": 3932, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 28.6, "mem_use": 49.1, "gen_rate": 6.4, "speed": 0.86, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.0, "tree_w": 178, "tree_size": 1024, "t0": 4.4675, "t1": 2.455, "tft": 7.4176, "input_0": 3961, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 25.5, "mem_use": 48.45, "gen_rate": 9.0, "speed": 1.3, "text": "\"Im sorry, but I'm not allowed t"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.1, "tree_w": 227, "tree_size": 1024, "t0": 3.4829, "t1": 2.42, "tft": 6.9357, "input_0": 2935, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 18.7, "mem_use": 47.47, "gen_rate": 5.0, "speed": 0.85, "text": "If the lost property has a name "}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 24.5, "tree_w": 83, "tree_size": 1024, "t0": 6.005, "t1": 2.41, "tft": 6.5888, "input_0": 4500, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 47.06, "gen_rate": 21.0, "speed": 2.49, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. Vaswani, A., Shaz"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 92, "tree_size": 1024, "t0": 6.93, "t1": 2.425, "tft": 7.1503, "input_0": 5974, "input_1": 1025, "min_CLP": -10.87, "draft_iters": 32.0, "mem_use": 46.86, "gen_rate": 22.5, "speed": 2.41, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 16.0, "tree_w": 151, "tree_size": 1024, "t0": 4.4675, "t1": 2.44, "tft": 8.2197, "input_0": 3877, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 24.5, "mem_use": 48.15, "gen_rate": 11.5, "speed": 1.67, "text": "In general, laws against public "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 155, "tree_size": 1024, "t0": 4.3175, "t1": 2.4175, "tft": 7.0812, "input_0": 4064, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 23.5, "mem_use": 47.27, "gen_rate": 8.0, "speed": 1.19, "text": "There are many ways to deliver a"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 133, "tree_size": 1024, "t0": 4.73, "t1": 2.44, "tft": 8.2331, "input_0": 3964, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 25.2, "mem_use": 48.14, "gen_rate": 8.5, "speed": 1.19, "text": "The optimal thickness for mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.0, "tree_w": 202, "tree_size": 1024, "t0": 5.05, "t1": 2.4325, "tft": 8.04, "input_0": 4709, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 27.2, "mem_use": 47.52, "gen_rate": 11.0, "speed": 1.47, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.0, "tree_w": 251, "tree_size": 1024, "t0": 3.6683, "t1": 2.415, "tft": 6.8559, "input_0": 3153, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 20.8, "mem_use": 46.79, "gen_rate": 6.7, "speed": 1.1, "text": "Here is a list of nicknames you "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 134, "tree_size": 1024, "t0": 5.2933, "t1": 2.43, "tft": 7.9556, "input_0": 4524, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 30.0, "mem_use": 47.2, "gen_rate": 10.7, "speed": 1.38, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 80, "tree_size": 1024, "t0": 6.13, "t1": 2.445, "tft": 8.8397, "input_0": 4336, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 32.0, "mem_use": 47.95, "gen_rate": 24.5, "speed": 2.86, "text": "\"Felices:\\n1. \u00ab(I Can't Get No) "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.0, "tree_w": 74, "tree_size": 1024, "t0": 6.73, "t1": 2.4, "tft": 7.0635, "input_0": 5931, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 32.0, "mem_use": 46.89, "gen_rate": 17.5, "speed": 1.92, "text": "Sure! Below is a table showing t"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 80, "tree_size": 1024, "t0": 6.28, "t1": 2.43, "tft": 7.3189, "input_0": 4763, "input_1": 1025, "min_CLP": -10.26, "draft_iters": 32.0, "mem_use": 47.28, "gen_rate": 24.0, "speed": 2.76, "text": "````\\n```markdown\\n# This is a T"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.0, "tree_w": 266, "tree_size": 1024, "t0": 3.8, "t1": 2.4275, "tft": 7.9936, "input_0": 3115, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 23.0, "mem_use": 47.65, "gen_rate": 8.5, "speed": 1.37, "text": "I apologize for the previous res"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.0, "tree_w": 142, "tree_size": 1024, "t0": 4.96, "t1": 2.4433, "tft": 9.4349, "input_0": 4322, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 26.3, "mem_use": 48.41, "gen_rate": 11.7, "speed": 1.58, "text": "Sure, I can guide you through bu"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 16.5, "tree_w": 223, "tree_size": 1024, "t0": 4.66, "t1": 2.4225, "tft": 7.4567, "input_0": 3827, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 25.2, "mem_use": 46.9, "gen_rate": 11.5, "speed": 1.62, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 23.7, "tree_w": 160, "tree_size": 1024, "t0": 5.24, "t1": 2.4033, "tft": 7.2241, "input_0": 4067, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 32.0, "mem_use": 46.82, "gen_rate": 4.3, "speed": 0.57, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.5, "tree_w": 217, "tree_size": 1024, "t0": 4.025, "t1": 2.505, "tft": 10.2711, "input_0": 3296, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 22.5, "mem_use": 50.94, "gen_rate": 6.0, "speed": 0.92, "text": "Discovery:\\n- Find a market need"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 99, "tree_size": 1024, "t0": 6.215, "t1": 2.43, "tft": 5.8426, "input_0": 4563, "input_1": 1025, "min_CLP": -11.07, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 24.0, "speed": 2.78, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.7, "tree_w": 129, "tree_size": 1024, "t0": 5.23, "t1": 2.4933, "tft": 6.9478, "input_0": 4177, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 27.7, "mem_use": 46.68, "gen_rate": 10.7, "speed": 1.38, "text": "\"To build a PC, you'll need to g"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.5, "tree_w": 147, "tree_size": 1024, "t0": 4.7875, "t1": 2.4975, "tft": 10.3846, "input_0": 3829, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 26.2, "mem_use": 50.93, "gen_rate": 8.8, "speed": 1.2, "text": "Hey there! How can I help you to"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 232, "tree_size": 1024, "t0": 3.692, "t1": 2.46, "tft": 8.3187, "input_0": 3036, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 20.8, "mem_use": 48.74, "gen_rate": 7.0, "speed": 1.14, "text": "\"\u2022 Focus on building a habit, no"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 154, "tree_size": 1024, "t0": 4.3833, "t1": 2.42, "tft": 7.8736, "input_0": 3457, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 24.3, "mem_use": 47.99, "gen_rate": 10.7, "speed": 1.57, "text": "You are correct that the player "}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 19.2, "tree_w": 158, "tree_size": 1024, "t0": 4.8175, "t1": 2.4125, "tft": 7.1598, "input_0": 3629, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 27.8, "mem_use": 46.86, "gen_rate": 8.5, "speed": 1.18, "text": "Yes, here is a summary of the im"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 20.3, "tree_w": 116, "tree_size": 1024, "t0": 5.2633, "t1": 2.4033, "tft": 7.0489, "input_0": 4213, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 29.3, "mem_use": 46.88, "gen_rate": 14.0, "speed": 1.83, "text": "In the context of the turn-based"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 96, "tree_size": 1024, "t0": 5.9667, "t1": 2.4367, "tft": 8.5557, "input_0": 5000, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 30.7, "mem_use": 47.7, "gen_rate": 13.0, "speed": 1.55, "text": "\"[API_REQUEST]: curl -X GET 'htt"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 22.7, "tree_w": 78, "tree_size": 1024, "t0": 6.4167, "t1": 2.4533, "tft": 8.342, "input_0": 4839, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 32.0, "mem_use": 48.24, "gen_rate": 15.7, "speed": 1.77, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 16.0, "tree_w": 123, "tree_size": 1024, "t0": 4.34, "t1": 2.44, "tft": 8.0408, "input_0": 3277, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 23.0, "mem_use": 47.66, "gen_rate": 8.0, "speed": 1.18, "text": "Hi! How can I assist you today?"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.2, "tree_w": 269, "tree_size": 1024, "t0": 3.1787, "t1": 2.4337, "tft": 8.2987, "input_0": 2873, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 17.2, "mem_use": 47.77, "gen_rate": 4.2, "speed": 0.76, "text": "\"With eyes as blue as the ocean'"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 17.2, "tree_w": 214, "tree_size": 1024, "t0": 3.9, "t1": 2.4233, "tft": 7.0412, "input_0": 2854, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 24.0, "mem_use": 47.16, "gen_rate": 6.5, "speed": 1.03, "text": "\"It is unclear how this would af"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.3, "tree_w": 131, "tree_size": 1024, "t0": 5.17, "t1": 2.42, "tft": 7.9441, "input_0": 4685, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 27.0, "mem_use": 47.13, "gen_rate": 12.7, "speed": 1.67, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 21.8, "tree_w": 129, "tree_size": 1024, "t0": 5.386, "t1": 2.45, "tft": 8.0269, "input_0": 4042, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 31.2, "mem_use": 48.45, "gen_rate": 7.0, "speed": 0.89, "text": "\"You're welcome! If the command "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 137, "tree_size": 1024, "t0": 4.7725, "t1": 2.45, "tft": 8.2703, "input_0": 3850, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 25.8, "mem_use": 48.37, "gen_rate": 8.5, "speed": 1.18, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 22.5, "tree_w": 133, "tree_size": 1024, "t0": 5.37, "t1": 2.4675, "tft": 9.3575, "input_0": 4264, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 31.0, "mem_use": 49.83, "gen_rate": 8.0, "speed": 1.02, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.7, "tree_w": 163, "tree_size": 1024, "t0": 5.68, "t1": 2.4167, "tft": 6.4858, "input_0": 4588, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 29.3, "mem_use": 46.68, "gen_rate": 11.3, "speed": 1.4, "text": "The current President of Germany"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.3, "tree_w": 269, "tree_size": 1024, "t0": 3.395, "t1": 2.43, "tft": 7.5733, "input_0": 2542, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 19.5, "mem_use": 47.6, "gen_rate": 5.7, "speed": 0.97, "text": "\"PostCSS is a tool for transform"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 22.0, "tree_w": 163, "tree_size": 1024, "t0": 5.63, "t1": 2.47, "tft": 9.4793, "input_0": 4715, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 32.0, "mem_use": 49.49, "gen_rate": 3.0, "speed": 0.37, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.2, "tree_w": 136, "tree_size": 1024, "t0": 5.1525, "t1": 2.43, "tft": 7.1808, "input_0": 4145, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 28.5, "mem_use": 47.19, "gen_rate": 9.2, "speed": 1.22, "text": "- Introduction to the topic of t"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 128, "tree_size": 1024, "t0": 4.8433, "t1": 2.4233, "tft": 8.5593, "input_0": 4236, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 26.0, "mem_use": 48.05, "gen_rate": 11.0, "speed": 1.51, "text": "I apologize for the confusion. A"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 1024, "max_branch_width": 32, "gen_rate": 10.23, "gen_rate_micro": 9.11, "gen_speed": 1.386, "gen_speed_micro": 1.299, "t0": 4.8282, "t1": 2.3876, "input_0": 3898.2, "input_1": 1025.0, "tree_size": 1024.0, "tree_w": 164.5, "tree_h": 18.2, "prompt_len": 297.9, "min_CLP": -7.85, "mem_use": 53.75, "exp_time": 7252.0}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 288, "tree_size": 2048, "t0": 7.2467, "t1": 6.1933, "tft": 15.9319, "input_0": 7041, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 54.5, "gen_rate": 11.0, "speed": 0.82, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 399, "tree_size": 2048, "t0": 7.1467, "t1": 6.13, "tft": 11.9731, "input_0": 8114, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 11.0, "speed": 0.83, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 425, "tree_size": 2048, "t0": 7.2975, "t1": 6.13, "tft": 11.8751, "input_0": 8086, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 52.91, "gen_rate": 9.8, "speed": 0.73, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 360, "tree_size": 2048, "t0": 7.1575, "t1": 5.795, "tft": 17.6631, "input_0": 6320, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 55.68, "gen_rate": 8.5, "speed": 0.66, "text": "Sure, I can definitely help with"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 406, "tree_size": 2048, "t0": 7.2825, "t1": 6.1425, "tft": 11.8887, "input_0": 8387, "input_1": 2049, "min_CLP": -10.41, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 9.0, "speed": 0.67, "text": "\"Sure, I'd be happy to give you "}
