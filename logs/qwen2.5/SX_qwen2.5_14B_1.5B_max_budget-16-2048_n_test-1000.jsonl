{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-1.5B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024, 2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 1000, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-26 23:47:36", "date": "250326", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.0, "tree_w": 1, "tree_size": 16, "t0": 1.2633, "t1": 0.29, "tft": 3.7787, "input_0": 54, "input_1": 17, "min_CLP": -1.94, "draft_iters": 14.0, "mem_use": 40.72, "gen_rate": 12.0, "speed": 7.72, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.8133, "t1": 0.2922, "tft": 2.2437, "input_0": 42, "input_1": 17, "min_CLP": -2.98, "draft_iters": 9.8, "mem_use": 42.26, "gen_rate": 4.2, "speed": 3.82, "text": "You are correct. The fastest cir"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.5733, "t1": 0.29, "tft": 2.3712, "input_0": 36, "input_1": 17, "min_CLP": -3.42, "draft_iters": 6.7, "mem_use": 43.19, "gen_rate": 3.6, "speed": 4.11, "text": "\"I can only provide general info"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.3, "tree_w": 3, "tree_size": 16, "t0": 0.8043, "t1": 0.2829, "tft": 1.2244, "input_0": 52, "input_1": 17, "min_CLP": -2.51, "draft_iters": 9.3, "mem_use": 40.89, "gen_rate": 5.3, "speed": 4.87, "text": "\"Certainly! Here's a Python scri"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.594, "t1": 0.281, "tft": 0.9536, "input_0": 39, "input_1": 17, "min_CLP": -3.17, "draft_iters": 6.7, "mem_use": 40.74, "gen_rate": 3.5, "speed": 4.0, "text": "Sure, I can help you with writin"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 2, "tree_size": 16, "t0": 0.9, "t1": 0.288, "tft": 2.5666, "input_0": 48, "input_1": 17, "min_CLP": -2.64, "draft_iters": 11.0, "mem_use": 43.32, "gen_rate": 6.8, "speed": 5.72, "text": "Certainly! Here\\'s a bullet list"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.86, "t1": 0.295, "tft": 2.9605, "input_0": 53, "input_1": 17, "min_CLP": -2.88, "draft_iters": 10.2, "mem_use": 43.9, "gen_rate": 5.7, "speed": 4.91, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 0.734, "t1": 0.308, "tft": 3.8148, "input_0": 49, "input_1": 17, "min_CLP": -2.69, "draft_iters": 8.8, "mem_use": 46.05, "gen_rate": 7.4, "speed": 7.1, "text": "\"Sure, I'd be happy to provide s"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 3, "tree_size": 16, "t0": 0.778, "t1": 0.298, "tft": 2.5276, "input_0": 43, "input_1": 17, "min_CLP": -2.73, "draft_iters": 9.4, "mem_use": 43.51, "gen_rate": 6.8, "speed": 6.32, "text": "\"Sure! Here's a list of the lega"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 2, "tree_size": 16, "t0": 0.866, "t1": 0.296, "tft": 2.156, "input_0": 50, "input_1": 17, "min_CLP": -2.86, "draft_iters": 10.4, "mem_use": 42.85, "gen_rate": 7.0, "speed": 6.02, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.37, "t1": 0.29, "tft": 1.5757, "input_0": 62, "input_1": 17, "min_CLP": -2.48, "draft_iters": 17.0, "mem_use": 41.39, "gen_rate": 17.0, "speed": 10.25, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.825, "t1": 0.2917, "tft": 2.4918, "input_0": 47, "input_1": 17, "min_CLP": -2.76, "draft_iters": 9.8, "mem_use": 43.26, "gen_rate": 5.5, "speed": 4.92, "text": "Here\\'s a shorter summary:\\n\\n\"F"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 0.7, "t1": 0.2971, "tft": 1.9199, "input_0": 42, "input_1": 17, "min_CLP": -2.84, "draft_iters": 8.3, "mem_use": 42.45, "gen_rate": 5.3, "speed": 5.31, "text": "Sure, here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.595, "t1": 0.275, "tft": 1.1847, "input_0": 41, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.0, "mem_use": 40.72, "gen_rate": 3.0, "speed": 3.43, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.5425, "t1": 0.2937, "tft": 2.8166, "input_0": 39, "input_1": 17, "min_CLP": -3.27, "draft_iters": 6.2, "mem_use": 43.87, "gen_rate": 4.4, "speed": 5.25, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.7771, "t1": 0.2829, "tft": 1.1302, "input_0": 50, "input_1": 17, "min_CLP": -2.88, "draft_iters": 9.0, "mem_use": 41.05, "gen_rate": 4.7, "speed": 4.45, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.8575, "t1": 0.2775, "tft": 1.4157, "input_0": 48, "input_1": 17, "min_CLP": -2.43, "draft_iters": 10.2, "mem_use": 40.74, "gen_rate": 9.0, "speed": 7.9, "text": "\"Sure, I can explain Fermat's La"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.39, "t1": 0.28, "tft": 1.0307, "input_0": 64, "input_1": 17, "min_CLP": -2.43, "draft_iters": 17.0, "mem_use": 40.71, "gen_rate": 17.0, "speed": 10.17, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.4, "tree_w": 3, "tree_size": 16, "t0": 0.788, "t1": 0.286, "tft": 1.2891, "input_0": 49, "input_1": 17, "min_CLP": -3.22, "draft_iters": 9.4, "mem_use": 41.25, "gen_rate": 6.6, "speed": 6.14, "text": "D-theanine is another form of th"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 5, "tree_size": 16, "t0": 0.6857, "t1": 0.2714, "tft": 1.3404, "input_0": 44, "input_1": 17, "min_CLP": -3.38, "draft_iters": 8.0, "mem_use": 40.72, "gen_rate": 5.1, "speed": 5.37, "text": "What is the Balfour Declaration?"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.473, "t1": 0.28, "tft": 1.5942, "input_0": 35, "input_1": 17, "min_CLP": -3.78, "draft_iters": 5.5, "mem_use": 41.57, "gen_rate": 3.3, "speed": 4.39, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 14, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.5, "t1": 0.278, "tft": 1.0167, "input_0": 32, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.0, "mem_use": 40.72, "gen_rate": 2.8, "speed": 3.58, "text": "\"Hello, I'm an AI assistant. How"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 3, "tree_size": 16, "t0": 0.6767, "t1": 0.2917, "tft": 2.3769, "input_0": 44, "input_1": 17, "min_CLP": -2.65, "draft_iters": 7.8, "mem_use": 43.11, "gen_rate": 5.8, "speed": 6.01, "text": "For an asymmetric bimodal distri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.6, "t1": 0.2788, "tft": 1.1589, "input_0": 41, "input_1": 17, "min_CLP": -3.18, "draft_iters": 6.9, "mem_use": 40.79, "gen_rate": 4.4, "speed": 4.97, "text": "1. Understanding the Question: T"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.475, "t1": 0.29, "tft": 2.1085, "input_0": 29, "input_1": 17, "min_CLP": -3.63, "draft_iters": 5.7, "mem_use": 41.76, "gen_rate": 4.0, "speed": 5.22, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.0667, "t1": 0.2767, "tft": 1.0278, "input_0": 50, "input_1": 17, "min_CLP": -2.87, "draft_iters": 13.3, "mem_use": 40.76, "gen_rate": 11.3, "speed": 8.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.46, "t1": 0.2822, "tft": 1.7575, "input_0": 33, "input_1": 17, "min_CLP": -3.44, "draft_iters": 5.3, "mem_use": 41.43, "gen_rate": 3.9, "speed": 5.25, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 20, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.68, "t1": 0.2871, "tft": 1.3573, "input_0": 44, "input_1": 17, "min_CLP": -3.02, "draft_iters": 8.0, "mem_use": 41.28, "gen_rate": 2.9, "speed": 2.96, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.5556, "t1": 0.2856, "tft": 2.6191, "input_0": 36, "input_1": 17, "min_CLP": -3.56, "draft_iters": 6.7, "mem_use": 43.25, "gen_rate": 4.2, "speed": 5.01, "text": "\"Ah, magic, magic, oh so wondrou"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.7, "tree_w": 2, "tree_size": 16, "t0": 1.1, "t1": 0.28, "tft": 1.1911, "input_0": 52, "input_1": 17, "min_CLP": -1.94, "draft_iters": 13.7, "mem_use": 40.76, "gen_rate": 12.0, "speed": 8.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.774, "t1": 0.28, "tft": 1.6849, "input_0": 53, "input_1": 17, "min_CLP": -2.83, "draft_iters": 9.2, "mem_use": 41.47, "gen_rate": 7.0, "speed": 6.66, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.2, "tree_w": 7, "tree_size": 16, "t0": 0.453, "t1": 0.285, "tft": 1.6255, "input_0": 33, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.2, "mem_use": 41.87, "gen_rate": 3.3, "speed": 4.46, "text": "\"[ANSWER]: It seems like you're "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.3, "tree_w": 5, "tree_size": 16, "t0": 0.6983, "t1": 0.2867, "tft": 1.2614, "input_0": 41, "input_1": 17, "min_CLP": -3.71, "draft_iters": 8.3, "mem_use": 41.22, "gen_rate": 6.3, "speed": 6.44, "text": "Freyja, the goddess of love, fer"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.527, "t1": 0.287, "tft": 2.98, "input_0": 35, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.2, "mem_use": 42.87, "gen_rate": 3.2, "speed": 3.93, "text": "\"Vegetarian cheese is a great op"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 4, "tree_size": 16, "t0": 0.57, "t1": 0.2883, "tft": 2.0121, "input_0": 38, "input_1": 17, "min_CLP": -2.84, "draft_iters": 6.8, "mem_use": 42.91, "gen_rate": 5.3, "speed": 6.2, "text": "When choosing an ISP package in "}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.7, "tree_w": 4, "tree_size": 16, "t0": 0.5686, "t1": 0.3029, "tft": 4.3842, "input_0": 38, "input_1": 17, "min_CLP": -3.18, "draft_iters": 6.7, "mem_use": 45.64, "gen_rate": 4.9, "speed": 5.56, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 22, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.5014, "t1": 0.2743, "tft": 1.2548, "input_0": 38, "input_1": 17, "min_CLP": -3.35, "draft_iters": 5.7, "mem_use": 40.75, "gen_rate": 3.1, "speed": 4.07, "text": "\"I'm sorry, but I cannot answer "}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5755, "t1": 0.28, "tft": 2.0311, "input_0": 35, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.9, "mem_use": 41.28, "gen_rate": 2.9, "speed": 3.41, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.5975, "t1": 0.2913, "tft": 3.2369, "input_0": 38, "input_1": 17, "min_CLP": -3.38, "draft_iters": 7.0, "mem_use": 43.68, "gen_rate": 4.1, "speed": 4.65, "text": "\"Sure, I can try to act like I h"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.9, "tree_w": 3, "tree_size": 16, "t0": 0.74, "t1": 0.2829, "tft": 1.7349, "input_0": 47, "input_1": 17, "min_CLP": -2.8, "draft_iters": 8.9, "mem_use": 41.68, "gen_rate": 5.7, "speed": 5.59, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 5.3, "tree_w": 7, "tree_size": 16, "t0": 0.524, "t1": 0.275, "tft": 1.0896, "input_0": 31, "input_1": 17, "min_CLP": -3.86, "draft_iters": 6.3, "mem_use": 40.97, "gen_rate": 4.1, "speed": 5.12, "text": "I will not give you my power, mo"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6489, "t1": 0.2933, "tft": 3.1186, "input_0": 39, "input_1": 17, "min_CLP": -3.46, "draft_iters": 7.8, "mem_use": 43.5, "gen_rate": 3.9, "speed": 4.14, "text": "\"Thank you for your insight. You"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.5, "tree_w": 3, "tree_size": 16, "t0": 0.93, "t1": 0.29, "tft": 2.8894, "input_0": 44, "input_1": 17, "min_CLP": -3.17, "draft_iters": 11.5, "mem_use": 43.93, "gen_rate": 10.0, "speed": 8.2, "text": "[INST] I am looking for legal re"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 0.8063, "t1": 0.2875, "tft": 2.0577, "input_0": 50, "input_1": 17, "min_CLP": -2.65, "draft_iters": 9.6, "mem_use": 42.25, "gen_rate": 4.9, "speed": 4.45, "text": "Determining the \"best\" SAST tool"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.74, "t1": 0.28, "tft": 1.8938, "input_0": 50, "input_1": 17, "min_CLP": -3.58, "draft_iters": 9.0, "mem_use": 41.5, "gen_rate": 5.0, "speed": 4.86, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 14.7, "tree_w": 1, "tree_size": 16, "t0": 1.2467, "t1": 0.2867, "tft": 1.4918, "input_0": 47, "input_1": 17, "min_CLP": -3.39, "draft_iters": 15.7, "mem_use": 41.24, "gen_rate": 15.7, "speed": 10.22, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.832, "t1": 0.278, "tft": 1.1112, "input_0": 44, "input_1": 17, "min_CLP": -2.83, "draft_iters": 10.0, "mem_use": 40.75, "gen_rate": 6.6, "speed": 5.93, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 12.2, "tree_w": 2, "tree_size": 16, "t0": 1.065, "t1": 0.3075, "tft": 4.184, "input_0": 49, "input_1": 17, "min_CLP": -2.93, "draft_iters": 13.2, "mem_use": 46.19, "gen_rate": 10.2, "speed": 7.46, "text": "\"Certainly! Here's an updated ve"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.412, "t1": 0.29, "tft": 1.8512, "input_0": 30, "input_1": 17, "min_CLP": -4.03, "draft_iters": 4.6, "mem_use": 42.49, "gen_rate": 3.2, "speed": 4.56, "text": "Thank you for indulging me, Agen"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5773, "t1": 0.2864, "tft": 1.2958, "input_0": 35, "input_1": 17, "min_CLP": -3.33, "draft_iters": 6.9, "mem_use": 41.51, "gen_rate": 3.0, "speed": 3.48, "text": "\"Alright, I understand. If you h"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.6, "tree_w": 3, "tree_size": 16, "t0": 0.86, "t1": 0.276, "tft": 1.2397, "input_0": 43, "input_1": 17, "min_CLP": -3.07, "draft_iters": 10.6, "mem_use": 41.03, "gen_rate": 8.2, "speed": 7.2, "text": "\u70b9\u51fb\u7387 (CTR) \u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 14.0, "tree_w": 1, "tree_size": 16, "t0": 1.1967, "t1": 0.28, "tft": 2.2555, "input_0": 55, "input_1": 17, "min_CLP": -3.15, "draft_iters": 15.0, "mem_use": 42.91, "gen_rate": 12.7, "speed": 8.55, "text": "F-centers, also known as color c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 7.9, "tree_w": 5, "tree_size": 16, "t0": 0.7329, "t1": 0.2857, "tft": 1.9091, "input_0": 43, "input_1": 17, "min_CLP": -2.96, "draft_iters": 8.9, "mem_use": 42.13, "gen_rate": 5.9, "speed": 5.73, "text": "Sure, here are some more importa"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6667, "t1": 0.2883, "tft": 2.443, "input_0": 45, "input_1": 17, "min_CLP": -2.94, "draft_iters": 7.8, "mem_use": 42.47, "gen_rate": 5.8, "speed": 6.11, "text": "Yes, it is true that technology "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.4227, "t1": 0.2727, "tft": 1.1375, "input_0": 27, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.0, "mem_use": 40.92, "gen_rate": 3.0, "speed": 4.3, "text": "People all over the world wear s"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.5837, "t1": 0.29, "tft": 2.6485, "input_0": 42, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.8, "mem_use": 43.35, "gen_rate": 4.2, "speed": 4.88, "text": "Sure, here\\'s a pitch deck for F"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6487, "t1": 0.2925, "tft": 3.2889, "input_0": 42, "input_1": 17, "min_CLP": -3.08, "draft_iters": 7.8, "mem_use": 44.58, "gen_rate": 4.2, "speed": 4.51, "text": "You are correct, and I apologize"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6633, "t1": 0.3, "tft": 3.5515, "input_0": 51, "input_1": 17, "min_CLP": -2.84, "draft_iters": 7.7, "mem_use": 44.75, "gen_rate": 6.0, "speed": 6.2, "text": "Yes, as a beginner with little p"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.3, "tree_w": 1, "tree_size": 16, "t0": 1.2333, "t1": 0.2933, "tft": 2.2161, "input_0": 61, "input_1": 17, "min_CLP": -2.76, "draft_iters": 15.3, "mem_use": 42.4, "gen_rate": 11.3, "speed": 7.41, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.5014, "t1": 0.2757, "tft": 0.9494, "input_0": 31, "input_1": 17, "min_CLP": -4.04, "draft_iters": 5.9, "mem_use": 40.74, "gen_rate": 4.7, "speed": 6.05, "text": "Best way is to make it a part of"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 0.728, "t1": 0.286, "tft": 2.5511, "input_0": 44, "input_1": 17, "min_CLP": -2.99, "draft_iters": 8.8, "mem_use": 43.19, "gen_rate": 7.0, "speed": 6.89, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.8, "tree_w": 5, "tree_size": 16, "t0": 0.506, "t1": 0.296, "tft": 3.1608, "input_0": 38, "input_1": 17, "min_CLP": -3.41, "draft_iters": 5.8, "mem_use": 44.01, "gen_rate": 3.6, "speed": 4.5, "text": "\"[The Spartan general leads his "}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5811, "t1": 0.28, "tft": 1.3663, "input_0": 37, "input_1": 17, "min_CLP": -3.16, "draft_iters": 6.9, "mem_use": 41.69, "gen_rate": 3.8, "speed": 4.39, "text": "Thank you for the feedback! I un"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.385, "t1": 0.2825, "tft": 1.152, "input_0": 28, "input_1": 17, "min_CLP": -3.88, "draft_iters": 4.4, "mem_use": 41.41, "gen_rate": 2.8, "speed": 4.13, "text": "The proof-of-stake concept would"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.423, "t1": 0.284, "tft": 1.4374, "input_0": 31, "input_1": 17, "min_CLP": -3.97, "draft_iters": 4.8, "mem_use": 41.53, "gen_rate": 3.4, "speed": 4.81, "text": "Adolph Hitler was not the only o"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 0.886, "t1": 0.298, "tft": 2.7758, "input_0": 51, "input_1": 17, "min_CLP": -2.69, "draft_iters": 10.8, "mem_use": 43.63, "gen_rate": 6.4, "speed": 5.42, "text": "\"Sure, I'd be happy to help.\\n\\n"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6433, "t1": 0.2956, "tft": 2.9423, "input_0": 42, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.7, "mem_use": 44.13, "gen_rate": 3.8, "speed": 4.03, "text": "\"I'm sorry, but I can't assist w"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.5, "tree_w": 3, "tree_size": 16, "t0": 0.7183, "t1": 0.2883, "tft": 2.8734, "input_0": 51, "input_1": 17, "min_CLP": -2.88, "draft_iters": 8.5, "mem_use": 43.36, "gen_rate": 6.2, "speed": 6.11, "text": "\"Implementing two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.64, "t1": 0.2867, "tft": 1.3989, "input_0": 40, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.4, "mem_use": 41.15, "gen_rate": 2.8, "speed": 3.06, "text": "\"You are welcome! If you have an"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.634, "t1": 0.28, "tft": 1.1194, "input_0": 38, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.4, "mem_use": 40.74, "gen_rate": 6.4, "speed": 6.99, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.8, "tree_w": 1, "tree_size": 16, "t0": 1.185, "t1": 0.2975, "tft": 2.7191, "input_0": 55, "input_1": 17, "min_CLP": -2.16, "draft_iters": 14.8, "mem_use": 43.59, "gen_rate": 11.0, "speed": 7.44, "text": "\"Sure, here's an updated table s"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 6.9, "tree_w": 5, "tree_size": 16, "t0": 0.665, "t1": 0.276, "tft": 1.0215, "input_0": 38, "input_1": 17, "min_CLP": -3.32, "draft_iters": 7.9, "mem_use": 40.69, "gen_rate": 3.8, "speed": 4.04, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.37, "t1": 0.285, "tft": 2.2935, "input_0": 58, "input_1": 17, "min_CLP": -1.93, "draft_iters": 17.0, "mem_use": 43.06, "gen_rate": 17.0, "speed": 10.26, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.4, "tree_w": 2, "tree_size": 16, "t0": 0.86, "t1": 0.294, "tft": 2.2398, "input_0": 52, "input_1": 17, "min_CLP": -2.54, "draft_iters": 10.4, "mem_use": 42.88, "gen_rate": 7.4, "speed": 6.42, "text": "Sure, some of the criticism of \""}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.4925, "t1": 0.275, "tft": 1.1892, "input_0": 35, "input_1": 17, "min_CLP": -3.68, "draft_iters": 5.8, "mem_use": 40.71, "gen_rate": 4.4, "speed": 5.72, "text": "Where does pornography come from"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.9, "tree_w": 5, "tree_size": 16, "t0": 0.7271, "t1": 0.2771, "tft": 1.6152, "input_0": 37, "input_1": 17, "min_CLP": -3.34, "draft_iters": 8.9, "mem_use": 41.03, "gen_rate": 5.4, "speed": 5.42, "text": "You can get your current timezon"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.5414, "t1": 0.28, "tft": 1.18, "input_0": 34, "input_1": 17, "min_CLP": -3.64, "draft_iters": 6.4, "mem_use": 41.11, "gen_rate": 5.3, "speed": 6.46, "text": "\"It's a common belief that if fo"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 43, "tree_h": 8.4, "tree_w": 4, "tree_size": 16, "t0": 0.79, "t1": 0.2787, "tft": 1.0558, "input_0": 46, "input_1": 17, "min_CLP": -3.14, "draft_iters": 9.4, "mem_use": 40.83, "gen_rate": 5.4, "speed": 5.04, "text": "\"def solve_equation(equation):\\n"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 2, "tree_size": 16, "t0": 0.97, "t1": 0.285, "tft": 1.9815, "input_0": 62, "input_1": 17, "min_CLP": -2.7, "draft_iters": 11.5, "mem_use": 41.58, "gen_rate": 9.5, "speed": 7.58, "text": "Sure! The Sieve of Eratosthenes "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 26, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.5864, "t1": 0.2845, "tft": 1.3291, "input_0": 37, "input_1": 17, "min_CLP": -3.27, "draft_iters": 6.7, "mem_use": 41.15, "gen_rate": 2.4, "speed": 2.72, "text": "\"You're welcome! It's good you'r"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.5389, "t1": 0.2811, "tft": 1.1371, "input_0": 36, "input_1": 17, "min_CLP": -3.13, "draft_iters": 6.2, "mem_use": 40.86, "gen_rate": 3.6, "speed": 4.35, "text": "Here\\'s an announcement tweet fo"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.5675, "t1": 0.29, "tft": 1.6008, "input_0": 39, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.5, "mem_use": 41.47, "gen_rate": 4.6, "speed": 5.4, "text": "Sexual selection can also affect"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 0.728, "t1": 0.294, "tft": 2.1008, "input_0": 45, "input_1": 17, "min_CLP": -2.99, "draft_iters": 8.6, "mem_use": 42.51, "gen_rate": 6.6, "speed": 6.47, "text": "Sure, here are some ways AI assi"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.1267, "t1": 0.2967, "tft": 2.6196, "input_0": 53, "input_1": 17, "min_CLP": -1.89, "draft_iters": 14.0, "mem_use": 43.56, "gen_rate": 12.0, "speed": 8.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6588, "t1": 0.2838, "tft": 1.72, "input_0": 42, "input_1": 17, "min_CLP": -3.04, "draft_iters": 7.9, "mem_use": 42.03, "gen_rate": 4.1, "speed": 4.37, "text": "The scp command is a Unix comman"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.33, "t1": 0.295, "tft": 2.331, "input_0": 61, "input_1": 17, "min_CLP": -2.75, "draft_iters": 16.5, "mem_use": 42.67, "gen_rate": 16.5, "speed": 10.18, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.5544, "t1": 0.2711, "tft": 1.0691, "input_0": 38, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.4, "mem_use": 40.77, "gen_rate": 3.7, "speed": 4.43, "text": "It would not be illegal to keep "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.5814, "t1": 0.2786, "tft": 1.3227, "input_0": 40, "input_1": 17, "min_CLP": -3.11, "draft_iters": 6.9, "mem_use": 41.05, "gen_rate": 4.9, "speed": 5.65, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 13, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.496, "t1": 0.274, "tft": 1.2108, "input_0": 36, "input_1": 17, "min_CLP": -3.76, "draft_iters": 5.8, "mem_use": 41.36, "gen_rate": 2.6, "speed": 3.37, "text": "[INST] What is the 5 second rule"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 0.73, "t1": 0.2757, "tft": 1.1688, "input_0": 44, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.9, "mem_use": 41.03, "gen_rate": 6.0, "speed": 5.96, "text": "\"I'm glad you liked it. Have a g"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.7, "tree_w": 2, "tree_size": 16, "t0": 1.1, "t1": 0.2767, "tft": 1.1331, "input_0": 57, "input_1": 17, "min_CLP": -2.46, "draft_iters": 13.7, "mem_use": 40.8, "gen_rate": 11.7, "speed": 8.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.51, "t1": 0.2725, "tft": 1.0493, "input_0": 34, "input_1": 17, "min_CLP": -3.64, "draft_iters": 6.0, "mem_use": 40.78, "gen_rate": 4.1, "speed": 5.28, "text": "\"Walking around the world is an "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.755, "t1": 0.29, "tft": 2.1726, "input_0": 47, "input_1": 17, "min_CLP": -2.55, "draft_iters": 9.0, "mem_use": 42.51, "gen_rate": 6.0, "speed": 5.75, "text": "\"Sure, I can explain it in layma"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.0533, "t1": 0.28, "tft": 1.1218, "input_0": 49, "input_1": 17, "min_CLP": -2.02, "draft_iters": 13.0, "mem_use": 40.78, "gen_rate": 12.0, "speed": 9.02, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.4, "tree_w": 3, "tree_size": 16, "t0": 0.722, "t1": 0.282, "tft": 1.1075, "input_0": 46, "input_1": 17, "min_CLP": -2.84, "draft_iters": 8.4, "mem_use": 41.08, "gen_rate": 6.4, "speed": 6.36, "text": "In Godot Engine 3.x, you can cre"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.37, "t1": 0.28, "tft": 1.0367, "input_0": 56, "input_1": 17, "min_CLP": -1.98, "draft_iters": 17.0, "mem_use": 40.75, "gen_rate": 17.0, "speed": 10.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 7, "tree_size": 16, "t0": 0.5312, "t1": 0.2838, "tft": 1.1087, "input_0": 37, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.0, "mem_use": 41.06, "gen_rate": 4.2, "speed": 5.22, "text": "Ah, young one, the path to becom"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.5311, "t1": 0.2778, "tft": 1.3753, "input_0": 37, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.1, "mem_use": 40.92, "gen_rate": 4.3, "speed": 5.35, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.6214, "t1": 0.2843, "tft": 1.3234, "input_0": 42, "input_1": 17, "min_CLP": -3.32, "draft_iters": 7.3, "mem_use": 41.16, "gen_rate": 5.1, "speed": 5.68, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.81, "t1": 0.295, "tft": 2.779, "input_0": 42, "input_1": 17, "min_CLP": -3.4, "draft_iters": 10.0, "mem_use": 44.03, "gen_rate": 6.3, "speed": 5.73, "text": "I understand. A more robust solu"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.51, "t1": 0.2812, "tft": 1.1942, "input_0": 33, "input_1": 17, "min_CLP": -3.6, "draft_iters": 6.0, "mem_use": 41.22, "gen_rate": 4.5, "speed": 5.68, "text": "Yes, but the amount of compensat"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.6325, "t1": 0.2937, "tft": 3.0142, "input_0": 44, "input_1": 17, "min_CLP": -3.51, "draft_iters": 7.5, "mem_use": 44.13, "gen_rate": 4.1, "speed": 4.46, "text": "Xin ch\u00e0o b\u1ea1n! T\u00f4i r\u1ea5t vui \u0111\u01b0\u1ee3c t"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 5.1, "tree_w": 7, "tree_size": 16, "t0": 0.5175, "t1": 0.285, "tft": 1.607, "input_0": 33, "input_1": 17, "min_CLP": -3.52, "draft_iters": 6.1, "mem_use": 41.59, "gen_rate": 5.0, "speed": 6.23, "text": "I heard that the British were de"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 11.0, "tree_w": 2, "tree_size": 16, "t0": 0.995, "t1": 0.285, "tft": 1.1078, "input_0": 56, "input_1": 17, "min_CLP": -2.63, "draft_iters": 12.0, "mem_use": 41.11, "gen_rate": 11.8, "speed": 9.18, "text": "Sure! Here\\'s an example of how "}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 0.7, "t1": 0.295, "tft": 1.948, "input_0": 37, "input_1": 17, "min_CLP": -3.02, "draft_iters": 8.5, "mem_use": 42.54, "gen_rate": 5.7, "speed": 5.7, "text": "In order to provide an accurate "}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.444, "t1": 0.283, "tft": 1.2533, "input_0": 31, "input_1": 17, "min_CLP": -3.81, "draft_iters": 5.1, "mem_use": 41.07, "gen_rate": 3.2, "speed": 4.41, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 0.7143, "t1": 0.29, "tft": 2.5975, "input_0": 48, "input_1": 17, "min_CLP": -2.94, "draft_iters": 8.4, "mem_use": 43.11, "gen_rate": 5.4, "speed": 5.41, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.6133, "t1": 0.28, "tft": 1.3646, "input_0": 39, "input_1": 17, "min_CLP": -3.49, "draft_iters": 7.3, "mem_use": 41.7, "gen_rate": 5.7, "speed": 6.34, "text": "As a large language model, I am "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.7975, "t1": 0.28, "tft": 1.1161, "input_0": 45, "input_1": 17, "min_CLP": -2.91, "draft_iters": 9.8, "mem_use": 41.23, "gen_rate": 8.2, "speed": 7.68, "text": "Certainly, I would be happy to w"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.64, "t1": 0.2817, "tft": 1.3773, "input_0": 42, "input_1": 17, "min_CLP": -2.94, "draft_iters": 7.7, "mem_use": 41.37, "gen_rate": 5.7, "speed": 6.17, "text": "There are many popular APIs, lib"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.5, "tree_w": 8, "tree_size": 16, "t0": 0.466, "t1": 0.29, "tft": 2.1968, "input_0": 28, "input_1": 17, "min_CLP": -4.45, "draft_iters": 5.5, "mem_use": 42.64, "gen_rate": 3.2, "speed": 4.25, "text": "\"Sure, here's a poem in Quenya t"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 33, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.5308, "t1": 0.2769, "tft": 1.0247, "input_0": 35, "input_1": 17, "min_CLP": -3.67, "draft_iters": 6.2, "mem_use": 40.75, "gen_rate": 2.5, "speed": 3.14, "text": "\"I am a teacher. I want to test "}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.59, "t1": 0.27, "tft": 1.0603, "input_0": 41, "input_1": 17, "min_CLP": -3.1, "draft_iters": 6.9, "mem_use": 40.79, "gen_rate": 4.7, "speed": 5.46, "text": "The error in this code is that t"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.425, "t1": 0.2825, "tft": 1.6982, "input_0": 28, "input_1": 17, "min_CLP": -3.71, "draft_iters": 4.9, "mem_use": 42.17, "gen_rate": 2.8, "speed": 3.88, "text": "The message you received from th"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.7443, "t1": 0.2771, "tft": 1.446, "input_0": 46, "input_1": 17, "min_CLP": -2.89, "draft_iters": 9.0, "mem_use": 41.4, "gen_rate": 4.7, "speed": 4.62, "text": "Certainly! In the context of mat"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.798, "t1": 0.28, "tft": 1.5971, "input_0": 43, "input_1": 17, "min_CLP": -3.05, "draft_iters": 9.8, "mem_use": 41.52, "gen_rate": 7.4, "speed": 6.88, "text": "\"One way to achieve this is by u"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.666, "t1": 0.28, "tft": 2.4036, "input_0": 44, "input_1": 17, "min_CLP": -2.91, "draft_iters": 8.0, "mem_use": 43.34, "gen_rate": 6.8, "speed": 7.16, "text": "\"It's important to be cautious w"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.752, "t1": 0.274, "tft": 1.2743, "input_0": 43, "input_1": 17, "min_CLP": -3.01, "draft_iters": 9.2, "mem_use": 41.31, "gen_rate": 6.4, "speed": 6.23, "text": "Absolutely! Here\\'s the updated "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.8, "tree_w": 2, "tree_size": 16, "t0": 1.1125, "t1": 0.28, "tft": 2.7086, "input_0": 57, "input_1": 17, "min_CLP": -2.26, "draft_iters": 13.8, "mem_use": 42.66, "gen_rate": 8.8, "speed": 6.27, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.63, "t1": 0.2729, "tft": 1.0984, "input_0": 42, "input_1": 17, "min_CLP": -3.21, "draft_iters": 7.4, "mem_use": 40.73, "gen_rate": 5.0, "speed": 5.52, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 9.5, "tree_w": 4, "tree_size": 16, "t0": 0.89, "t1": 0.27, "tft": 1.5274, "input_0": 52, "input_1": 17, "min_CLP": -3.77, "draft_iters": 10.5, "mem_use": 40.95, "gen_rate": 2.5, "speed": 2.15, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.5667, "t1": 0.2778, "tft": 1.26, "input_0": 42, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.6, "mem_use": 41.2, "gen_rate": 3.7, "speed": 4.35, "text": "Thank you, I try my best to be h"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.658, "t1": 0.284, "tft": 2.3594, "input_0": 40, "input_1": 17, "min_CLP": -3.44, "draft_iters": 8.0, "mem_use": 42.78, "gen_rate": 6.4, "speed": 6.78, "text": "Thou art the sun that doth shine"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6283, "t1": 0.2783, "tft": 1.3664, "input_0": 38, "input_1": 17, "min_CLP": -2.96, "draft_iters": 7.7, "mem_use": 41.37, "gen_rate": 5.3, "speed": 5.88, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.0, "tree_w": 7, "tree_size": 16, "t0": 0.5, "t1": 0.27, "tft": 1.2657, "input_0": 32, "input_1": 17, "min_CLP": -3.6, "draft_iters": 6.0, "mem_use": 40.77, "gen_rate": 3.4, "speed": 4.41, "text": "\"Sure, here are some words to ex"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.7414, "t1": 0.2729, "tft": 1.0623, "input_0": 44, "input_1": 17, "min_CLP": -2.77, "draft_iters": 9.0, "mem_use": 40.75, "gen_rate": 4.9, "speed": 4.78, "text": "\"Presidents' Day is a federal ho"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.63, "t1": 0.2787, "tft": 1.4053, "input_0": 38, "input_1": 17, "min_CLP": -3.35, "draft_iters": 7.5, "mem_use": 41.05, "gen_rate": 4.2, "speed": 4.68, "text": "Yes, a kilogram of feathers is n"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.6317, "t1": 0.2883, "tft": 1.9283, "input_0": 39, "input_1": 17, "min_CLP": -3.1, "draft_iters": 7.5, "mem_use": 41.86, "gen_rate": 5.7, "speed": 6.18, "text": "Yes, the US National Reconnaissa"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.451, "t1": 0.283, "tft": 1.1147, "input_0": 33, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.1, "mem_use": 41.13, "gen_rate": 3.5, "speed": 4.77, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.465, "t1": 0.285, "tft": 1.1174, "input_0": 30, "input_1": 17, "min_CLP": -3.87, "draft_iters": 5.3, "mem_use": 41.2, "gen_rate": 2.8, "speed": 3.77, "text": "Well, I am not a fan of that nam"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.7533, "t1": 0.2783, "tft": 1.0763, "input_0": 42, "input_1": 17, "min_CLP": -2.86, "draft_iters": 9.2, "mem_use": 40.75, "gen_rate": 6.0, "speed": 5.81, "text": "Yes, the ATF can be considered a"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.5064, "t1": 0.28, "tft": 1.5859, "input_0": 33, "input_1": 17, "min_CLP": -3.74, "draft_iters": 5.8, "mem_use": 41.44, "gen_rate": 3.2, "speed": 4.05, "text": "\"Yo, he\\'s totally out of touch."}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.6025, "t1": 0.2788, "tft": 1.1467, "input_0": 41, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.0, "mem_use": 40.87, "gen_rate": 4.4, "speed": 4.97, "text": "There is a chance that your mayo"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6589, "t1": 0.2933, "tft": 1.6009, "input_0": 43, "input_1": 17, "min_CLP": -3.57, "draft_iters": 7.7, "mem_use": 42.09, "gen_rate": 3.9, "speed": 4.09, "text": "Certainly, here are some medias "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.565, "t1": 0.285, "tft": 1.183, "input_0": 39, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.5, "mem_use": 41.2, "gen_rate": 4.4, "speed": 5.16, "text": "No, I will not try to take over "}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.6367, "t1": 0.2978, "tft": 2.2919, "input_0": 41, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.6, "mem_use": 42.4, "gen_rate": 3.8, "speed": 4.06, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.56, "t1": 0.283, "tft": 1.398, "input_0": 34, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.7, "mem_use": 41.15, "gen_rate": 3.4, "speed": 4.03, "text": "\"Open Assistant: The Open Source"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.6, "t1": 0.2833, "tft": 1.4699, "input_0": 39, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.0, "mem_use": 41.04, "gen_rate": 3.6, "speed": 4.02, "text": "\"Sure! \\nHere's a diagram to ill"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.7267, "t1": 0.2933, "tft": 2.5218, "input_0": 45, "input_1": 17, "min_CLP": -3.48, "draft_iters": 8.7, "mem_use": 43.41, "gen_rate": 5.3, "speed": 5.24, "text": "\"The issue you're experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.7371, "t1": 0.2829, "tft": 1.031, "input_0": 47, "input_1": 17, "min_CLP": -3.11, "draft_iters": 8.7, "mem_use": 40.74, "gen_rate": 5.7, "speed": 5.61, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 3.1, "tree_w": 9, "tree_size": 16, "t0": 0.3508, "t1": 0.2875, "tft": 1.282, "input_0": 24, "input_1": 17, "min_CLP": -4.0, "draft_iters": 4.1, "mem_use": 41.28, "gen_rate": 2.8, "speed": 4.31, "text": "The answer is not that simple. T"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.5245, "t1": 0.2827, "tft": 1.2271, "input_0": 35, "input_1": 17, "min_CLP": -3.43, "draft_iters": 6.1, "mem_use": 40.91, "gen_rate": 3.1, "speed": 3.82, "text": "This is a matter of efficiency a"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 20, "tree_h": 9.5, "tree_w": 3, "tree_size": 16, "t0": 0.845, "t1": 0.28, "tft": 1.0398, "input_0": 42, "input_1": 17, "min_CLP": -2.92, "draft_iters": 10.5, "mem_use": 40.75, "gen_rate": 10.0, "speed": 8.86, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 3, "tree_size": 16, "t0": 0.6486, "t1": 0.2929, "tft": 2.3135, "input_0": 42, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.7, "mem_use": 42.83, "gen_rate": 4.9, "speed": 5.15, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.5211, "t1": 0.28, "tft": 1.0272, "input_0": 36, "input_1": 17, "min_CLP": -3.26, "draft_iters": 6.0, "mem_use": 40.71, "gen_rate": 3.8, "speed": 4.7, "text": "Yes, a thumb war can be consider"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.6257, "t1": 0.2757, "tft": 1.1281, "input_0": 37, "input_1": 17, "min_CLP": -3.56, "draft_iters": 7.6, "mem_use": 40.79, "gen_rate": 4.7, "speed": 5.23, "text": "The lyrics to the third verse of"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6871, "t1": 0.3, "tft": 2.8549, "input_0": 47, "input_1": 17, "min_CLP": -3.0, "draft_iters": 7.9, "mem_use": 44.09, "gen_rate": 4.6, "speed": 4.63, "text": "As of my knowledge cutoff date i"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 0.7386, "t1": 0.2986, "tft": 1.7269, "input_0": 41, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.9, "mem_use": 42.06, "gen_rate": 5.1, "speed": 4.97, "text": "I apologize for any confusion my"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.67, "t1": 0.286, "tft": 1.1604, "input_0": 41, "input_1": 17, "min_CLP": -2.77, "draft_iters": 8.0, "mem_use": 41.01, "gen_rate": 6.8, "speed": 7.12, "text": "Sure, I can definitely help you "}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.6917, "t1": 0.285, "tft": 1.1336, "input_0": 43, "input_1": 17, "min_CLP": -3.19, "draft_iters": 8.2, "mem_use": 40.98, "gen_rate": 5.5, "speed": 5.62, "text": "In the United States of America,"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6467, "t1": 0.285, "tft": 1.0739, "input_0": 39, "input_1": 17, "min_CLP": -2.91, "draft_iters": 7.7, "mem_use": 40.75, "gen_rate": 5.3, "speed": 5.72, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.6211, "t1": 0.2889, "tft": 1.7499, "input_0": 39, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.2, "mem_use": 41.56, "gen_rate": 3.9, "speed": 4.28, "text": "\"Sure, I can help you create an "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 2, "tree_size": 16, "t0": 1.1375, "t1": 0.29, "tft": 2.1314, "input_0": 64, "input_1": 17, "min_CLP": -3.2, "draft_iters": 13.8, "mem_use": 41.58, "gen_rate": 8.2, "speed": 5.79, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 0.7367, "t1": 0.2983, "tft": 3.6856, "input_0": 46, "input_1": 17, "min_CLP": -2.97, "draft_iters": 8.7, "mem_use": 44.11, "gen_rate": 6.2, "speed": 5.98, "text": "\"Sure, here's a shorter version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.345, "t1": 0.28, "tft": 1.0607, "input_0": 58, "input_1": 17, "min_CLP": -3.49, "draft_iters": 17.0, "mem_use": 40.76, "gen_rate": 17.0, "speed": 10.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.4427, "t1": 0.2836, "tft": 1.1318, "input_0": 33, "input_1": 17, "min_CLP": -3.47, "draft_iters": 5.1, "mem_use": 41.32, "gen_rate": 2.9, "speed": 4.01, "text": "Berlin is not traditionally know"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.0, "tree_w": 2, "tree_size": 16, "t0": 0.7533, "t1": 0.28, "tft": 1.1585, "input_0": 46, "input_1": 17, "min_CLP": -2.69, "draft_iters": 9.0, "mem_use": 40.79, "gen_rate": 6.5, "speed": 6.29, "text": "Sure, here\\'s a simple Python sc"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.36, "t1": 0.295, "tft": 3.0503, "input_0": 55, "input_1": 17, "min_CLP": -2.83, "draft_iters": 17.0, "mem_use": 43.33, "gen_rate": 17.0, "speed": 10.28, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.538, "t1": 0.276, "tft": 1.1809, "input_0": 36, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.3, "mem_use": 40.71, "gen_rate": 3.4, "speed": 4.18, "text": "The person who wears short short"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.636, "t1": 0.288, "tft": 2.4498, "input_0": 39, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.5, "mem_use": 43.01, "gen_rate": 3.7, "speed": 4.0, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.5988, "t1": 0.2825, "tft": 1.064, "input_0": 38, "input_1": 17, "min_CLP": -3.2, "draft_iters": 7.0, "mem_use": 40.72, "gen_rate": 4.9, "speed": 5.54, "text": "As an AI assistant, my primary p"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 7.0, "tree_w": 7, "tree_size": 16, "t0": 0.6686, "t1": 0.28, "tft": 0.9511, "input_0": 35, "input_1": 17, "min_CLP": -4.17, "draft_iters": 8.0, "mem_use": 40.7, "gen_rate": 6.7, "speed": 7.1, "text": "\u300c\u6211\u6b63\u5728\u770b\u4e00\u672c\u6709\u8da3\u7684\u4e66\u3002\u300d\\n[INST] <<SYS>>\\nY"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.75, "t1": 0.286, "tft": 1.0703, "input_0": 44, "input_1": 17, "min_CLP": -2.88, "draft_iters": 9.0, "mem_use": 40.86, "gen_rate": 6.4, "speed": 6.19, "text": "Sure, I can provide an example o"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.65, "t1": 0.2933, "tft": 1.867, "input_0": 44, "input_1": 17, "min_CLP": -3.13, "draft_iters": 7.7, "mem_use": 41.92, "gen_rate": 3.7, "speed": 3.89, "text": "In the 1950s, the quality of lif"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.0533, "t1": 0.2833, "tft": 1.2034, "input_0": 57, "input_1": 17, "min_CLP": -2.34, "draft_iters": 13.0, "mem_use": 40.81, "gen_rate": 12.0, "speed": 8.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.6483, "t1": 0.2833, "tft": 1.0179, "input_0": 46, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.5, "mem_use": 41.01, "gen_rate": 5.5, "speed": 5.91, "text": "In RST (ReStructuredText), to fo"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.694, "t1": 0.286, "tft": 1.6052, "input_0": 40, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.2, "mem_use": 41.36, "gen_rate": 6.8, "speed": 6.94, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.51, "t1": 0.2738, "tft": 1.159, "input_0": 37, "input_1": 17, "min_CLP": -3.56, "draft_iters": 6.0, "mem_use": 40.9, "gen_rate": 4.1, "speed": 5.24, "text": "\"I'm a goddess of love, fertilit"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 0.7288, "t1": 0.2975, "tft": 2.0895, "input_0": 42, "input_1": 17, "min_CLP": -2.79, "draft_iters": 8.9, "mem_use": 42.12, "gen_rate": 4.5, "speed": 4.39, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.628, "t1": 0.286, "tft": 1.3444, "input_0": 38, "input_1": 17, "min_CLP": -3.38, "draft_iters": 7.4, "mem_use": 40.79, "gen_rate": 6.4, "speed": 7.0, "text": "As a helpful assistant, I would "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.81, "t1": 0.29, "tft": 1.8499, "input_0": 52, "input_1": 17, "min_CLP": -2.73, "draft_iters": 9.8, "mem_use": 41.63, "gen_rate": 6.4, "speed": 5.82, "text": "Microwave ovens became common ho"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.0, "tree_w": 4, "tree_size": 16, "t0": 0.8438, "t1": 0.2875, "tft": 1.4379, "input_0": 46, "input_1": 17, "min_CLP": -3.03, "draft_iters": 10.0, "mem_use": 40.9, "gen_rate": 4.1, "speed": 3.64, "text": "[INST] <<SYS>>\\nYou are an intel"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.1367, "t1": 0.2833, "tft": 1.0711, "input_0": 53, "input_1": 17, "min_CLP": -1.67, "draft_iters": 14.0, "mem_use": 40.73, "gen_rate": 12.0, "speed": 8.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6567, "t1": 0.305, "tft": 3.9475, "input_0": 46, "input_1": 17, "min_CLP": -3.13, "draft_iters": 7.7, "mem_use": 45.03, "gen_rate": 6.0, "speed": 6.25, "text": "\"If your friends are not happy w"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 3, "tree_size": 16, "t0": 0.7843, "t1": 0.2843, "tft": 1.2347, "input_0": 45, "input_1": 17, "min_CLP": -2.75, "draft_iters": 9.1, "mem_use": 41.03, "gen_rate": 4.7, "speed": 4.41, "text": "\"When approaching a technical pr"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.816, "t1": 0.286, "tft": 2.3187, "input_0": 45, "input_1": 17, "min_CLP": -3.36, "draft_iters": 9.8, "mem_use": 41.91, "gen_rate": 7.2, "speed": 6.55, "text": "\"If we assume that we can travel"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6475, "t1": 0.2975, "tft": 2.3903, "input_0": 41, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.8, "mem_use": 43.2, "gen_rate": 4.2, "speed": 4.5, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.57, "t1": 0.2844, "tft": 1.0888, "input_0": 35, "input_1": 17, "min_CLP": -3.88, "draft_iters": 6.8, "mem_use": 41.01, "gen_rate": 3.6, "speed": 4.17, "text": "What do you call a broke college"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 9, "tree_h": 4.5, "tree_w": 5, "tree_size": 16, "t0": 0.485, "t1": 0.275, "tft": 1.1754, "input_0": 34, "input_1": 17, "min_CLP": -3.45, "draft_iters": 5.5, "mem_use": 41.05, "gen_rate": 2.2, "speed": 2.96, "text": "You are welcome. I am here to he"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.8317, "t1": 0.29, "tft": 1.8152, "input_0": 49, "input_1": 17, "min_CLP": -2.8, "draft_iters": 10.0, "mem_use": 41.53, "gen_rate": 5.8, "speed": 5.19, "text": "Certainly! There are a number of"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.8, "tree_w": 2, "tree_size": 16, "t0": 1.03, "t1": 0.2825, "tft": 1.1772, "input_0": 51, "input_1": 17, "min_CLP": -2.84, "draft_iters": 12.8, "mem_use": 41.03, "gen_rate": 10.5, "speed": 7.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.62, "t1": 0.29, "tft": 1.545, "input_0": 40, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.2, "mem_use": 41.71, "gen_rate": 5.5, "speed": 6.05, "text": "The Transactional Interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 5, "tree_size": 16, "t0": 0.6671, "t1": 0.2871, "tft": 1.0994, "input_0": 38, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.9, "mem_use": 41.05, "gen_rate": 5.1, "speed": 5.39, "text": "\"Sure, here's a simple sequence "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.67, "t1": 0.2883, "tft": 1.1361, "input_0": 38, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.8, "mem_use": 40.78, "gen_rate": 5.8, "speed": 6.12, "text": "Pieces of a reinforcement learni"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.37, "t1": 0.285, "tft": 1.0696, "input_0": 56, "input_1": 17, "min_CLP": -2.08, "draft_iters": 17.0, "mem_use": 40.74, "gen_rate": 17.0, "speed": 10.29, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 0.8225, "t1": 0.2975, "tft": 3.4871, "input_0": 48, "input_1": 17, "min_CLP": -3.64, "draft_iters": 9.8, "mem_use": 45.01, "gen_rate": 6.5, "speed": 5.79, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 19, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.5386, "t1": 0.2829, "tft": 1.5081, "input_0": 36, "input_1": 17, "min_CLP": -3.56, "draft_iters": 6.1, "mem_use": 40.88, "gen_rate": 2.7, "speed": 3.3, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.5675, "t1": 0.29, "tft": 1.8567, "input_0": 38, "input_1": 17, "min_CLP": -3.36, "draft_iters": 6.6, "mem_use": 42.41, "gen_rate": 4.6, "speed": 5.39, "text": "While carbon crystals, such as d"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.1, "tree_w": 3, "tree_size": 16, "t0": 0.6886, "t1": 0.29, "tft": 1.7738, "input_0": 45, "input_1": 17, "min_CLP": -2.84, "draft_iters": 8.1, "mem_use": 42.17, "gen_rate": 4.9, "speed": 4.95, "text": "The \"chkdsk C: /f\" command in op"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.3, "tree_w": 2, "tree_size": 16, "t0": 0.795, "t1": 0.28, "tft": 1.4586, "input_0": 50, "input_1": 17, "min_CLP": -2.88, "draft_iters": 9.3, "mem_use": 41.01, "gen_rate": 6.3, "speed": 5.89, "text": "To approach and solve this probl"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 0.7571, "t1": 0.2757, "tft": 1.1388, "input_0": 45, "input_1": 17, "min_CLP": -2.91, "draft_iters": 9.1, "mem_use": 40.82, "gen_rate": 4.7, "speed": 4.56, "text": "I think the answer is To determi"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.08, "t1": 0.2733, "tft": 1.0543, "input_0": 58, "input_1": 17, "min_CLP": -2.53, "draft_iters": 13.3, "mem_use": 40.8, "gen_rate": 11.7, "speed": 8.62, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 3, "tree_size": 16, "t0": 0.68, "t1": 0.2817, "tft": 1.9271, "input_0": 45, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.0, "mem_use": 41.8, "gen_rate": 5.5, "speed": 5.72, "text": "\"As an AI language model, I'm he"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 42, "tree_h": 5.7, "tree_w": 7, "tree_size": 16, "t0": 0.5558, "t1": 0.2792, "tft": 1.1114, "input_0": 31, "input_1": 17, "min_CLP": -3.96, "draft_iters": 6.7, "mem_use": 41.13, "gen_rate": 3.5, "speed": 4.19, "text": "Q: Please give me a short, conci"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 0.9617, "t1": 0.2817, "tft": 2.8237, "input_0": 48, "input_1": 17, "min_CLP": -2.45, "draft_iters": 12.0, "mem_use": 42.45, "gen_rate": 6.0, "speed": 4.81, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.4614, "t1": 0.2786, "tft": 1.3711, "input_0": 31, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.4, "mem_use": 41.37, "gen_rate": 4.3, "speed": 5.83, "text": "One can draw the conclusion that"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 43, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.555, "t1": 0.2767, "tft": 1.637, "input_0": 32, "input_1": 17, "min_CLP": -3.83, "draft_iters": 6.7, "mem_use": 41.21, "gen_rate": 3.6, "speed": 4.31, "text": "The ATF gunwalking scandal you\\'"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.6243, "t1": 0.28, "tft": 1.1563, "input_0": 42, "input_1": 17, "min_CLP": -3.04, "draft_iters": 7.3, "mem_use": 40.95, "gen_rate": 5.0, "speed": 5.53, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 0.852, "t1": 0.288, "tft": 3.6004, "input_0": 48, "input_1": 17, "min_CLP": -2.79, "draft_iters": 10.4, "mem_use": 43.76, "gen_rate": 6.6, "speed": 5.79, "text": "Chapter 4: The Aftermath\\n\\nIn t"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.74, "t1": 0.29, "tft": 3.3241, "input_0": 44, "input_1": 17, "min_CLP": -3.58, "draft_iters": 8.8, "mem_use": 43.69, "gen_rate": 5.3, "speed": 5.18, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.442, "t1": 0.278, "tft": 0.9449, "input_0": 32, "input_1": 17, "min_CLP": -4.31, "draft_iters": 5.1, "mem_use": 40.74, "gen_rate": 3.4, "speed": 4.71, "text": "In the style of Neruda, I shall "}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 11.2, "tree_w": 2, "tree_size": 16, "t0": 1.0025, "t1": 0.29, "tft": 1.6054, "input_0": 50, "input_1": 17, "min_CLP": -3.1, "draft_iters": 12.2, "mem_use": 41.9, "gen_rate": 11.5, "speed": 8.93, "text": "Certainly, I can add information"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 4, "tree_size": 16, "t0": 0.76, "t1": 0.2883, "tft": 1.9077, "input_0": 42, "input_1": 17, "min_CLP": -3.19, "draft_iters": 9.3, "mem_use": 42.35, "gen_rate": 5.3, "speed": 5.08, "text": "I apologize for the confusion.  "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 10.6, "tree_w": 3, "tree_size": 16, "t0": 0.95, "t1": 0.276, "tft": 1.0203, "input_0": 48, "input_1": 17, "min_CLP": -3.01, "draft_iters": 11.6, "mem_use": 40.72, "gen_rate": 9.0, "speed": 7.33, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.5756, "t1": 0.2822, "tft": 1.0296, "input_0": 33, "input_1": 17, "min_CLP": -3.96, "draft_iters": 6.8, "mem_use": 41.01, "gen_rate": 3.7, "speed": 4.28, "text": "Freyja: You dare to command me, "}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 2, "tree_size": 16, "t0": 0.89, "t1": 0.286, "tft": 2.3571, "input_0": 53, "input_1": 17, "min_CLP": -2.5, "draft_iters": 10.8, "mem_use": 42.6, "gen_rate": 6.4, "speed": 5.45, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.685, "t1": 0.2783, "tft": 1.1453, "input_0": 44, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.2, "mem_use": 40.95, "gen_rate": 5.3, "speed": 5.54, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.725, "t1": 0.2875, "tft": 1.9855, "input_0": 42, "input_1": 17, "min_CLP": -2.96, "draft_iters": 8.8, "mem_use": 42.3, "gen_rate": 4.1, "speed": 4.07, "text": "Certainly! Here are the steps br"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6643, "t1": 0.2743, "tft": 1.0584, "input_0": 42, "input_1": 17, "min_CLP": -3.39, "draft_iters": 7.9, "mem_use": 40.75, "gen_rate": 5.1, "speed": 5.47, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.08, "t1": 0.2767, "tft": 1.0566, "input_0": 50, "input_1": 17, "min_CLP": -1.82, "draft_iters": 13.3, "mem_use": 40.76, "gen_rate": 12.0, "speed": 8.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.6083, "t1": 0.28, "tft": 1.1667, "input_0": 42, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.2, "mem_use": 41.4, "gen_rate": 5.3, "speed": 6.01, "text": "\"Sure, I'm happy to help. \\n\\nHe"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 0.695, "t1": 0.281, "tft": 1.4615, "input_0": 41, "input_1": 17, "min_CLP": -3.07, "draft_iters": 8.4, "mem_use": 41.63, "gen_rate": 3.3, "speed": 3.38, "text": "Thank you! I apologize for the i"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.674, "t1": 0.272, "tft": 1.2042, "input_0": 43, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.2, "mem_use": 40.74, "gen_rate": 6.8, "speed": 7.17, "text": "The AK-47, also known as the Kal"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.7087, "t1": 0.2762, "tft": 1.265, "input_0": 43, "input_1": 17, "min_CLP": -2.79, "draft_iters": 8.6, "mem_use": 41.08, "gen_rate": 4.2, "speed": 4.32, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.31, "t1": 0.285, "tft": 2.017, "input_0": 49, "input_1": 17, "min_CLP": -2.28, "draft_iters": 16.5, "mem_use": 42.47, "gen_rate": 16.5, "speed": 10.36, "text": "1. Statistical modeling is the p"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.6429, "t1": 0.2743, "tft": 1.096, "input_0": 45, "input_1": 17, "min_CLP": -3.09, "draft_iters": 7.6, "mem_use": 41.07, "gen_rate": 4.7, "speed": 5.15, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.6075, "t1": 0.2875, "tft": 1.8886, "input_0": 40, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.1, "mem_use": 41.57, "gen_rate": 4.8, "speed": 5.31, "text": "\"While it's not necessarily harm"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.4956, "t1": 0.2867, "tft": 1.6283, "input_0": 32, "input_1": 17, "min_CLP": -3.74, "draft_iters": 5.9, "mem_use": 41.21, "gen_rate": 3.6, "speed": 4.56, "text": "I see, you would like to help yo"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.4664, "t1": 0.2855, "tft": 1.2941, "input_0": 31, "input_1": 17, "min_CLP": -3.49, "draft_iters": 5.5, "mem_use": 41.32, "gen_rate": 2.9, "speed": 3.87, "text": "The instruction is asking you to"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.5255, "t1": 0.2827, "tft": 0.9442, "input_0": 35, "input_1": 17, "min_CLP": -3.61, "draft_iters": 6.1, "mem_use": 40.72, "gen_rate": 3.2, "speed": 3.93, "text": "\"I can't hear your thoughts, but"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.6033, "t1": 0.28, "tft": 1.1075, "input_0": 48, "input_1": 17, "min_CLP": -3.29, "draft_iters": 6.8, "mem_use": 40.73, "gen_rate": 5.3, "speed": 6.03, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.54, "t1": 0.285, "tft": 1.2059, "input_0": 37, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.4, "mem_use": 41.27, "gen_rate": 4.4, "speed": 5.32, "text": "L-theanine has a number of poten"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.66, "t1": 0.2833, "tft": 1.0182, "input_0": 43, "input_1": 17, "min_CLP": -3.06, "draft_iters": 7.8, "mem_use": 41.03, "gen_rate": 5.5, "speed": 5.81, "text": "Certainly! Below is an example o"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 12.3, "tree_w": 3, "tree_size": 16, "t0": 1.07, "t1": 0.2867, "tft": 1.2023, "input_0": 50, "input_1": 17, "min_CLP": -2.43, "draft_iters": 13.3, "mem_use": 40.82, "gen_rate": 12.7, "speed": 9.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.6012, "t1": 0.2788, "tft": 1.1395, "input_0": 42, "input_1": 17, "min_CLP": -3.49, "draft_iters": 6.9, "mem_use": 40.78, "gen_rate": 4.5, "speed": 5.1, "text": "This is due to the difference in"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.62, "t1": 0.2889, "tft": 1.2941, "input_0": 39, "input_1": 17, "min_CLP": -3.78, "draft_iters": 7.1, "mem_use": 41.34, "gen_rate": 3.9, "speed": 4.28, "text": "The image is a photograph of a h"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.7, "tree_w": 5, "tree_size": 16, "t0": 0.494, "t1": 0.3, "tft": 3.0323, "input_0": 35, "input_1": 17, "min_CLP": -3.33, "draft_iters": 5.7, "mem_use": 44.41, "gen_rate": 3.4, "speed": 4.29, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.5, "t1": 0.2922, "tft": 2.3811, "input_0": 33, "input_1": 17, "min_CLP": -3.46, "draft_iters": 5.9, "mem_use": 43.17, "gen_rate": 3.7, "speed": 4.63, "text": "\"I understand your concern, but "}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.5743, "t1": 0.2886, "tft": 1.755, "input_0": 39, "input_1": 17, "min_CLP": -3.49, "draft_iters": 6.7, "mem_use": 41.4, "gen_rate": 4.6, "speed": 5.3, "text": "To build a Dyson sphere, a civil"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.375, "t1": 0.28, "tft": 1.0652, "input_0": 61, "input_1": 17, "min_CLP": -3.38, "draft_iters": 17.0, "mem_use": 40.74, "gen_rate": 17.0, "speed": 10.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.477, "t1": 0.28, "tft": 1.1669, "input_0": 31, "input_1": 17, "min_CLP": -3.4, "draft_iters": 5.5, "mem_use": 40.72, "gen_rate": 3.5, "speed": 4.61, "text": "I can speak German, but my profi"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6544, "t1": 0.28, "tft": 1.071, "input_0": 38, "input_1": 17, "min_CLP": -3.38, "draft_iters": 7.8, "mem_use": 40.93, "gen_rate": 3.8, "speed": 4.04, "text": "\"Certainly! As a Linux shell, I "}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6557, "t1": 0.28, "tft": 1.6254, "input_0": 40, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.9, "mem_use": 41.81, "gen_rate": 4.7, "speed": 5.03, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.69, "t1": 0.294, "tft": 2.3752, "input_0": 43, "input_1": 17, "min_CLP": -3.04, "draft_iters": 8.2, "mem_use": 42.4, "gen_rate": 6.8, "speed": 6.93, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.51, "t1": 0.2875, "tft": 1.0418, "input_0": 32, "input_1": 17, "min_CLP": -3.78, "draft_iters": 5.9, "mem_use": 40.78, "gen_rate": 4.0, "speed": 5.05, "text": "\"Sure, here are some haikus for "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 3, "tree_size": 16, "t0": 0.9467, "t1": 0.28, "tft": 1.2479, "input_0": 47, "input_1": 17, "min_CLP": -3.64, "draft_iters": 11.7, "mem_use": 41.15, "gen_rate": 11.7, "speed": 9.5, "text": "\"     /|\\\\\\n     / \\\\\\n[INST] Th"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.0767, "t1": 0.2733, "tft": 1.1824, "input_0": 53, "input_1": 17, "min_CLP": -2.18, "draft_iters": 13.3, "mem_use": 40.74, "gen_rate": 12.0, "speed": 8.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.8233, "t1": 0.2833, "tft": 1.1117, "input_0": 44, "input_1": 17, "min_CLP": -3.0, "draft_iters": 9.8, "mem_use": 41.09, "gen_rate": 6.2, "speed": 5.57, "text": "Yes, there is a true, most ethic"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.5444, "t1": 0.2756, "tft": 1.0855, "input_0": 40, "input_1": 17, "min_CLP": -3.15, "draft_iters": 6.3, "mem_use": 41.01, "gen_rate": 4.0, "speed": 4.87, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.5925, "t1": 0.2812, "tft": 2.2908, "input_0": 38, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.0, "mem_use": 43.09, "gen_rate": 4.1, "speed": 4.71, "text": "\"Alright, let's get started. Fir"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.05, "t1": 0.2833, "tft": 0.9872, "input_0": 50, "input_1": 17, "min_CLP": -2.92, "draft_iters": 13.0, "mem_use": 40.9, "gen_rate": 12.0, "speed": 9.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.66, "t1": 0.2944, "tft": 2.9376, "input_0": 44, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.9, "mem_use": 43.79, "gen_rate": 4.0, "speed": 4.19, "text": "\"I'm sorry, but I won't be able "}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6467, "t1": 0.275, "tft": 1.1423, "input_0": 42, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.7, "mem_use": 40.77, "gen_rate": 5.7, "speed": 6.14, "text": "Sure, here is an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 0.6929, "t1": 0.2814, "tft": 1.0519, "input_0": 44, "input_1": 17, "min_CLP": -2.79, "draft_iters": 8.3, "mem_use": 40.73, "gen_rate": 5.4, "speed": 5.57, "text": "HTML (Hypertext Markup Language)"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 11.0, "tree_w": 2, "tree_size": 16, "t0": 1.0025, "t1": 0.285, "tft": 1.111, "input_0": 57, "input_1": 17, "min_CLP": -2.78, "draft_iters": 12.0, "mem_use": 40.75, "gen_rate": 11.2, "speed": 8.75, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.5562, "t1": 0.2825, "tft": 1.3863, "input_0": 37, "input_1": 17, "min_CLP": -3.9, "draft_iters": 6.6, "mem_use": 41.12, "gen_rate": 4.0, "speed": 4.76, "text": "\"The image is protected by copyr"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.0567, "t1": 0.27, "tft": 0.9498, "input_0": 51, "input_1": 17, "min_CLP": -2.04, "draft_iters": 13.0, "mem_use": 40.74, "gen_rate": 12.0, "speed": 9.02, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.7383, "t1": 0.2883, "tft": 2.143, "input_0": 43, "input_1": 17, "min_CLP": -2.9, "draft_iters": 9.0, "mem_use": 41.8, "gen_rate": 5.3, "speed": 5.21, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.9, "tree_w": 6, "tree_size": 16, "t0": 0.424, "t1": 0.286, "tft": 2.3489, "input_0": 29, "input_1": 17, "min_CLP": -3.46, "draft_iters": 4.9, "mem_use": 41.51, "gen_rate": 3.2, "speed": 4.51, "text": "Alright, that makes things a bit"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.441, "t1": 0.287, "tft": 1.0682, "input_0": 30, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.0, "mem_use": 41.36, "gen_rate": 3.5, "speed": 4.81, "text": "\"Ah, but you're assuming everyon"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.4582, "t1": 0.2945, "tft": 1.5915, "input_0": 30, "input_1": 17, "min_CLP": -3.61, "draft_iters": 5.3, "mem_use": 42.07, "gen_rate": 3.3, "speed": 4.36, "text": "\"That's a beautiful and poignant"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 7, "tree_size": 16, "t0": 0.5325, "t1": 0.2738, "tft": 0.9436, "input_0": 35, "input_1": 17, "min_CLP": -4.12, "draft_iters": 6.2, "mem_use": 40.71, "gen_rate": 4.1, "speed": 5.11, "text": "Here is an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.5575, "t1": 0.2825, "tft": 1.0926, "input_0": 37, "input_1": 17, "min_CLP": -3.36, "draft_iters": 6.5, "mem_use": 41.03, "gen_rate": 4.4, "speed": 5.21, "text": "Sure, I\\'ve been called many dif"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.6617, "t1": 0.2867, "tft": 1.9894, "input_0": 41, "input_1": 17, "min_CLP": -3.09, "draft_iters": 7.8, "mem_use": 41.78, "gen_rate": 5.3, "speed": 5.63, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.48, "t1": 0.2773, "tft": 1.2092, "input_0": 34, "input_1": 17, "min_CLP": -3.38, "draft_iters": 5.5, "mem_use": 40.83, "gen_rate": 3.0, "speed": 3.95, "text": "Motion Matching is a technology "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.0, "tree_w": 1, "tree_size": 16, "t0": 1.21, "t1": 0.2975, "tft": 2.2472, "input_0": 50, "input_1": 17, "min_CLP": -2.25, "draft_iters": 15.0, "mem_use": 42.46, "gen_rate": 8.2, "speed": 5.49, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.83, "t1": 0.282, "tft": 1.16, "input_0": 45, "input_1": 17, "min_CLP": -2.62, "draft_iters": 10.0, "mem_use": 40.78, "gen_rate": 6.8, "speed": 6.11, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 33, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.4236, "t1": 0.28, "tft": 1.1885, "input_0": 30, "input_1": 17, "min_CLP": -3.91, "draft_iters": 4.9, "mem_use": 41.16, "gen_rate": 2.4, "speed": 3.35, "text": "\u300c\u671b\u3080\u300d\uff08\u306e\u305e\u3080\uff09\u3068\u3044\u3046\u6f22\u5b57\u306b\u306f\u3001\u300c\u6642\u8a08\u300d\u3068\u300c\u5fc3\u300d\u306e2\u3064\u306e\u90e8\u304c\u542b"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.59, "t1": 0.2957, "tft": 2.4524, "input_0": 36, "input_1": 17, "min_CLP": -3.54, "draft_iters": 7.0, "mem_use": 42.47, "gen_rate": 4.9, "speed": 5.5, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.6, "t1": 0.2871, "tft": 2.1581, "input_0": 46, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.9, "mem_use": 42.9, "gen_rate": 5.0, "speed": 5.64, "text": "\"Paul Allen's plane collection i"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.5786, "t1": 0.2857, "tft": 2.1926, "input_0": 40, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.7, "mem_use": 42.34, "gen_rate": 4.6, "speed": 5.3, "text": "Certainly, there are other cases"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.375, "t1": 0.28, "tft": 1.0403, "input_0": 63, "input_1": 17, "min_CLP": -2.7, "draft_iters": 17.0, "mem_use": 40.81, "gen_rate": 17.0, "speed": 10.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.8, "tree_w": 5, "tree_size": 16, "t0": 0.4925, "t1": 0.2788, "tft": 1.4335, "input_0": 35, "input_1": 17, "min_CLP": -3.2, "draft_iters": 5.8, "mem_use": 41.44, "gen_rate": 4.4, "speed": 5.67, "text": "\"As an AI language model, my pri"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.9167, "t1": 0.285, "tft": 1.1291, "input_0": 48, "input_1": 17, "min_CLP": -3.01, "draft_iters": 11.0, "mem_use": 40.84, "gen_rate": 6.5, "speed": 5.41, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.365, "t1": 0.28, "tft": 1.0853, "input_0": 58, "input_1": 17, "min_CLP": -3.05, "draft_iters": 17.0, "mem_use": 40.73, "gen_rate": 17.0, "speed": 10.34, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.1, "tree_w": 3, "tree_size": 16, "t0": 0.8371, "t1": 0.2843, "tft": 1.6048, "input_0": 43, "input_1": 17, "min_CLP": -3.09, "draft_iters": 10.1, "mem_use": 41.56, "gen_rate": 5.4, "speed": 4.85, "text": "You are welcome! \ud83d\ude0a\\n[INST] Yeah,"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.6043, "t1": 0.2914, "tft": 1.9119, "input_0": 38, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.1, "mem_use": 42.37, "gen_rate": 4.6, "speed": 5.1, "text": "\"There are a few ways to stop so"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.5211, "t1": 0.2933, "tft": 2.5537, "input_0": 35, "input_1": 17, "min_CLP": -3.49, "draft_iters": 6.1, "mem_use": 43.31, "gen_rate": 3.8, "speed": 4.64, "text": "Multi-track drifting is a propos"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6517, "t1": 0.2883, "tft": 1.8463, "input_0": 44, "input_1": 17, "min_CLP": -3.09, "draft_iters": 7.8, "mem_use": 41.87, "gen_rate": 5.5, "speed": 5.85, "text": "\"It is theoretically possible to"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.557, "t1": 0.289, "tft": 2.4181, "input_0": 35, "input_1": 17, "min_CLP": -3.51, "draft_iters": 6.6, "mem_use": 41.71, "gen_rate": 3.3, "speed": 3.91, "text": "\"My love, you're the sun that li"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.6, "tree_w": 3, "tree_size": 16, "t0": 0.8586, "t1": 0.29, "tft": 1.5166, "input_0": 41, "input_1": 17, "min_CLP": -3.23, "draft_iters": 10.6, "mem_use": 41.48, "gen_rate": 5.3, "speed": 4.61, "text": "In Japanese, \"love\" is \"\u611b (ai)\","}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.6233, "t1": 0.2817, "tft": 1.4707, "input_0": 43, "input_1": 17, "min_CLP": -3.35, "draft_iters": 7.3, "mem_use": 41.02, "gen_rate": 5.7, "speed": 6.27, "text": "Some of the best universities fo"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.635, "t1": 0.28, "tft": 1.1294, "input_0": 41, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.3, "mem_use": 40.71, "gen_rate": 6.0, "speed": 6.57, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 1.1475, "t1": 0.2875, "tft": 1.0668, "input_0": 58, "input_1": 17, "min_CLP": -2.82, "draft_iters": 14.0, "mem_use": 40.85, "gen_rate": 10.8, "speed": 7.51, "text": "\"Here's a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.525, "t1": 0.2937, "tft": 1.944, "input_0": 35, "input_1": 17, "min_CLP": -3.76, "draft_iters": 6.2, "mem_use": 41.97, "gen_rate": 4.0, "speed": 4.89, "text": "1. Financial stress:\\n- Create a"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5829, "t1": 0.2771, "tft": 1.1048, "input_0": 40, "input_1": 17, "min_CLP": -3.17, "draft_iters": 6.9, "mem_use": 40.71, "gen_rate": 3.7, "speed": 4.31, "text": "Hello! I\\'m an AI language model"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.898, "t1": 0.29, "tft": 2.7489, "input_0": 48, "input_1": 17, "min_CLP": -2.61, "draft_iters": 11.0, "mem_use": 43.4, "gen_rate": 6.4, "speed": 5.38, "text": "One example of when you might us"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6575, "t1": 0.2812, "tft": 1.5042, "input_0": 43, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.8, "mem_use": 41.0, "gen_rate": 4.4, "speed": 4.66, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.478, "t1": 0.276, "tft": 1.0881, "input_0": 34, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.5, "mem_use": 40.79, "gen_rate": 3.3, "speed": 4.36, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.7533, "t1": 0.285, "tft": 2.3858, "input_0": 43, "input_1": 17, "min_CLP": -3.32, "draft_iters": 9.2, "mem_use": 43.01, "gen_rate": 5.5, "speed": 5.28, "text": "Certainly, here are a few more o"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 0.9167, "t1": 0.2867, "tft": 1.1293, "input_0": 48, "input_1": 17, "min_CLP": -2.42, "draft_iters": 11.3, "mem_use": 40.78, "gen_rate": 10.7, "speed": 8.89, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.5033, "t1": 0.2811, "tft": 1.5268, "input_0": 33, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.9, "mem_use": 41.48, "gen_rate": 3.8, "speed": 4.82, "text": "\"No, there's no clear-cut ethica"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 43, "tree_h": 9.1, "tree_w": 3, "tree_size": 16, "t0": 0.8222, "t1": 0.2878, "tft": 1.8261, "input_0": 43, "input_1": 17, "min_CLP": -3.05, "draft_iters": 10.1, "mem_use": 42.35, "gen_rate": 4.8, "speed": 4.3, "text": "1. m\u00eb (suffix) is pronounced as "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.7383, "t1": 0.285, "tft": 0.9342, "input_0": 44, "input_1": 17, "min_CLP": -3.16, "draft_iters": 8.8, "mem_use": 41.03, "gen_rate": 5.7, "speed": 5.53, "text": "\"Sure! Here's a story about how "}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.9014, "t1": 0.2971, "tft": 2.644, "input_0": 50, "input_1": 17, "min_CLP": -2.51, "draft_iters": 11.0, "mem_use": 43.82, "gen_rate": 5.4, "speed": 4.54, "text": "I apologize for the error in my "}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.592, "t1": 0.275, "tft": 1.0622, "input_0": 39, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.0, "mem_use": 40.75, "gen_rate": 3.2, "speed": 3.69, "text": "In ReStructuredText (RST), you c"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 11.4, "tree_w": 2, "tree_size": 16, "t0": 1.018, "t1": 0.288, "tft": 2.6509, "input_0": 58, "input_1": 17, "min_CLP": -2.33, "draft_iters": 12.4, "mem_use": 42.75, "gen_rate": 9.6, "speed": 7.36, "text": "\"Sure! Here's an example code fo"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.08, "t1": 0.2767, "tft": 1.0226, "input_0": 50, "input_1": 17, "min_CLP": -2.08, "draft_iters": 13.3, "mem_use": 40.73, "gen_rate": 12.0, "speed": 8.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.3, "tree_w": 8, "tree_size": 16, "t0": 0.3655, "t1": 0.2818, "tft": 1.1082, "input_0": 25, "input_1": 17, "min_CLP": -4.08, "draft_iters": 4.3, "mem_use": 41.18, "gen_rate": 3.0, "speed": 4.64, "text": "\"That's a possibility, but in re"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.5067, "t1": 0.3067, "tft": 4.2659, "input_0": 34, "input_1": 17, "min_CLP": -3.64, "draft_iters": 6.0, "mem_use": 46.34, "gen_rate": 3.8, "speed": 4.64, "text": "Yes Sir, I will do my best\\n\\n[V"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.0, "tree_w": 6, "tree_size": 16, "t0": 0.578, "t1": 0.284, "tft": 1.555, "input_0": 30, "input_1": 17, "min_CLP": -3.98, "draft_iters": 7.0, "mem_use": 41.55, "gen_rate": 6.4, "speed": 7.44, "text": "0 A lawyer that comes in to prov"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.5557, "t1": 0.2929, "tft": 2.5303, "input_0": 39, "input_1": 17, "min_CLP": -3.32, "draft_iters": 6.4, "mem_use": 43.44, "gen_rate": 5.3, "speed": 6.22, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.5914, "t1": 0.29, "tft": 2.2243, "input_0": 40, "input_1": 17, "min_CLP": -3.27, "draft_iters": 7.0, "mem_use": 41.78, "gen_rate": 4.9, "speed": 5.5, "text": "1. Economic downturn: If there i"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 5, "tree_size": 16, "t0": 0.4725, "t1": 0.2825, "tft": 1.1732, "input_0": 33, "input_1": 17, "min_CLP": -3.5, "draft_iters": 5.5, "mem_use": 41.06, "gen_rate": 4.2, "speed": 5.63, "text": "```python\\ndef inspirational_mon"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 0.802, "t1": 0.3, "tft": 3.292, "input_0": 49, "input_1": 17, "min_CLP": -2.77, "draft_iters": 9.6, "mem_use": 43.56, "gen_rate": 6.4, "speed": 5.84, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6317, "t1": 0.285, "tft": 1.3505, "input_0": 36, "input_1": 17, "min_CLP": -2.89, "draft_iters": 7.7, "mem_use": 41.24, "gen_rate": 5.3, "speed": 5.82, "text": "To determine the most cost-effec"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.7, "tree_w": 2, "tree_size": 16, "t0": 0.96, "t1": 0.2967, "tft": 2.464, "input_0": 54, "input_1": 17, "min_CLP": -2.21, "draft_iters": 11.7, "mem_use": 43.24, "gen_rate": 10.7, "speed": 8.52, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.5, "tree_w": 5, "tree_size": 16, "t0": 0.71, "t1": 0.285, "tft": 1.0374, "input_0": 41, "input_1": 17, "min_CLP": -3.05, "draft_iters": 8.5, "mem_use": 40.76, "gen_rate": 6.3, "speed": 6.37, "text": "\"Certainly! Here's an implementa"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.32, "t1": 0.29, "tft": 1.4536, "input_0": 56, "input_1": 17, "min_CLP": -2.45, "draft_iters": 16.5, "mem_use": 41.49, "gen_rate": 16.5, "speed": 10.24, "text": "\"The laws for nudity in Wyoming "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.0533, "t1": 0.2867, "tft": 1.2746, "input_0": 54, "input_1": 17, "min_CLP": -1.78, "draft_iters": 13.0, "mem_use": 41.21, "gen_rate": 12.0, "speed": 8.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.3, "tree_w": 3, "tree_size": 16, "t0": 0.785, "t1": 0.2817, "tft": 1.2966, "input_0": 47, "input_1": 17, "min_CLP": -2.8, "draft_iters": 9.3, "mem_use": 40.81, "gen_rate": 5.7, "speed": 5.32, "text": "\"To create a smooth Snake game i"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 0.6671, "t1": 0.2857, "tft": 1.5262, "input_0": 47, "input_1": 17, "min_CLP": -3.24, "draft_iters": 7.7, "mem_use": 41.69, "gen_rate": 5.0, "speed": 5.25, "text": "\"It's normal to feel this way, b"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.0475, "t1": 0.2975, "tft": 2.6328, "input_0": 55, "input_1": 17, "min_CLP": -3.03, "draft_iters": 13.0, "mem_use": 43.32, "gen_rate": 10.8, "speed": 8.01, "text": "Certainly, here is a list of som"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.6343, "t1": 0.2829, "tft": 1.1476, "input_0": 45, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.4, "mem_use": 40.92, "gen_rate": 5.1, "speed": 5.61, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 3, "tree_size": 16, "t0": 1.0125, "t1": 0.285, "tft": 1.1349, "input_0": 58, "input_1": 17, "min_CLP": -2.91, "draft_iters": 12.2, "mem_use": 40.83, "gen_rate": 8.0, "speed": 6.17, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.6087, "t1": 0.2812, "tft": 1.1156, "input_0": 39, "input_1": 17, "min_CLP": -3.14, "draft_iters": 7.1, "mem_use": 40.73, "gen_rate": 4.2, "speed": 4.76, "text": "Yes, I am capable of assisting y"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.65, "t1": 0.298, "tft": 3.4252, "input_0": 43, "input_1": 17, "min_CLP": -2.97, "draft_iters": 7.8, "mem_use": 44.51, "gen_rate": 6.4, "speed": 6.75, "text": "\"TypeScript offers several advan"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.6957, "t1": 0.2843, "tft": 1.0529, "input_0": 39, "input_1": 17, "min_CLP": -3.33, "draft_iters": 8.3, "mem_use": 40.85, "gen_rate": 5.3, "speed": 5.4, "text": "\"The name of the fourth kid is M"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.4627, "t1": 0.2864, "tft": 1.388, "input_0": 30, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.5, "mem_use": 41.88, "gen_rate": 2.9, "speed": 3.88, "text": "[INST] Ask someone else to farm "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.6067, "t1": 0.2967, "tft": 2.7149, "input_0": 40, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.2, "mem_use": 43.68, "gen_rate": 6.2, "speed": 6.84, "text": "It depends on the desired level "}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.548, "t1": 0.288, "tft": 1.1712, "input_0": 35, "input_1": 17, "min_CLP": -3.32, "draft_iters": 6.3, "mem_use": 40.98, "gen_rate": 3.3, "speed": 3.95, "text": "Yes, you are on the right track."}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 13, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.655, "t1": 0.2875, "tft": 1.6016, "input_0": 43, "input_1": 17, "min_CLP": -3.25, "draft_iters": 7.8, "mem_use": 41.48, "gen_rate": 3.2, "speed": 3.45, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.7529, "t1": 0.2871, "tft": 2.8471, "input_0": 46, "input_1": 17, "min_CLP": -3.04, "draft_iters": 9.0, "mem_use": 43.25, "gen_rate": 4.6, "speed": 4.39, "text": "As a high school student, you ca"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.6957, "t1": 0.2857, "tft": 1.663, "input_0": 44, "input_1": 17, "min_CLP": -2.8, "draft_iters": 8.3, "mem_use": 41.62, "gen_rate": 4.7, "speed": 4.81, "text": "The television was invented by m"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5733, "t1": 0.2956, "tft": 2.8296, "input_0": 37, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.9, "mem_use": 43.96, "gen_rate": 4.2, "speed": 4.85, "text": "By trying these methods, you sho"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.645, "t1": 0.29, "tft": 2.2139, "input_0": 38, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.8, "mem_use": 42.27, "gen_rate": 5.5, "speed": 5.88, "text": "The reason why there are multipl"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.4167, "t1": 0.2833, "tft": 1.1947, "input_0": 29, "input_1": 17, "min_CLP": -3.76, "draft_iters": 4.8, "mem_use": 41.3, "gen_rate": 2.7, "speed": 3.81, "text": "\"Oh, you're right! I am an AI, a"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.666, "t1": 0.286, "tft": 2.4541, "input_0": 43, "input_1": 17, "min_CLP": -2.96, "draft_iters": 8.0, "mem_use": 43.13, "gen_rate": 6.8, "speed": 7.12, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.0733, "t1": 0.28, "tft": 1.1438, "input_0": 53, "input_1": 17, "min_CLP": -1.85, "draft_iters": 13.3, "mem_use": 40.92, "gen_rate": 12.0, "speed": 8.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 8.9, "tree_w": 4, "tree_size": 16, "t0": 0.8222, "t1": 0.2844, "tft": 1.6024, "input_0": 44, "input_1": 17, "min_CLP": -3.34, "draft_iters": 9.9, "mem_use": 41.54, "gen_rate": 4.0, "speed": 3.61, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.4608, "t1": 0.2767, "tft": 1.6954, "input_0": 33, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.3, "mem_use": 41.01, "gen_rate": 3.0, "speed": 4.06, "text": "\"Oh, you want a little more sarc"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.9, "tree_w": 3, "tree_size": 16, "t0": 0.7443, "t1": 0.2843, "tft": 1.0974, "input_0": 48, "input_1": 17, "min_CLP": -2.82, "draft_iters": 8.9, "mem_use": 41.03, "gen_rate": 5.7, "speed": 5.56, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.455, "t1": 0.282, "tft": 1.3093, "input_0": 33, "input_1": 17, "min_CLP": -3.51, "draft_iters": 5.3, "mem_use": 41.41, "gen_rate": 3.6, "speed": 4.89, "text": "Google Authenticator is an appli"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.6157, "t1": 0.2757, "tft": 1.4845, "input_0": 44, "input_1": 17, "min_CLP": -3.19, "draft_iters": 7.3, "mem_use": 41.2, "gen_rate": 4.9, "speed": 5.45, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.6437, "t1": 0.2788, "tft": 1.1858, "input_0": 45, "input_1": 17, "min_CLP": -2.85, "draft_iters": 7.5, "mem_use": 40.96, "gen_rate": 4.5, "speed": 4.88, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.3, "tree_w": 2, "tree_size": 16, "t0": 1.06, "t1": 0.2767, "tft": 1.2701, "input_0": 51, "input_1": 17, "min_CLP": -1.94, "draft_iters": 13.3, "mem_use": 40.81, "gen_rate": 12.0, "speed": 8.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.815, "t1": 0.2838, "tft": 1.1342, "input_0": 47, "input_1": 17, "min_CLP": -2.77, "draft_iters": 9.8, "mem_use": 40.84, "gen_rate": 5.0, "speed": 4.55, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.36, "t1": 0.285, "tft": 0.9533, "input_0": 65, "input_1": 17, "min_CLP": -2.74, "draft_iters": 17.0, "mem_use": 40.76, "gen_rate": 17.0, "speed": 10.34, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 0.866, "t1": 0.29, "tft": 1.7136, "input_0": 49, "input_1": 17, "min_CLP": -3.06, "draft_iters": 10.4, "mem_use": 41.94, "gen_rate": 7.8, "speed": 6.75, "text": "In this case, you can use the rs"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6729, "t1": 0.2814, "tft": 1.0318, "input_0": 44, "input_1": 17, "min_CLP": -2.98, "draft_iters": 7.9, "mem_use": 40.72, "gen_rate": 5.0, "speed": 5.24, "text": "In Python, the `@` symbol has tw"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.5011, "t1": 0.2778, "tft": 1.1376, "input_0": 36, "input_1": 17, "min_CLP": -3.42, "draft_iters": 5.9, "mem_use": 40.73, "gen_rate": 3.6, "speed": 4.57, "text": "\"ChatGPT is an impressive AI lan"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.4544, "t1": 0.2811, "tft": 1.0191, "input_0": 29, "input_1": 17, "min_CLP": -3.68, "draft_iters": 5.3, "mem_use": 41.03, "gen_rate": 3.6, "speed": 4.83, "text": "\"Hello, Adolf Hitler. I'm here t"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 6, "tree_size": 16, "t0": 0.62, "t1": 0.2788, "tft": 1.0272, "input_0": 35, "input_1": 17, "min_CLP": -3.69, "draft_iters": 7.5, "mem_use": 40.77, "gen_rate": 4.0, "speed": 4.46, "text": "Certainly! Here\\'s a Malbolge pr"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.5, "tree_w": 2, "tree_size": 16, "t0": 0.93, "t1": 0.28, "tft": 1.3705, "input_0": 49, "input_1": 17, "min_CLP": -2.65, "draft_iters": 11.5, "mem_use": 41.46, "gen_rate": 9.8, "speed": 8.06, "text": "Sure! Let me break down each sen"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.6157, "t1": 0.3, "tft": 2.9902, "input_0": 37, "input_1": 17, "min_CLP": -3.28, "draft_iters": 7.3, "mem_use": 43.99, "gen_rate": 4.7, "speed": 5.17, "text": "Sure, here are the prompts for e"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 0.7025, "t1": 0.2725, "tft": 1.2776, "input_0": 45, "input_1": 17, "min_CLP": -3.1, "draft_iters": 8.4, "mem_use": 41.27, "gen_rate": 4.4, "speed": 4.48, "text": "Decorators and wrapping function"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.4273, "t1": 0.2818, "tft": 1.9181, "input_0": 30, "input_1": 17, "min_CLP": -4.01, "draft_iters": 5.0, "mem_use": 42.39, "gen_rate": 2.9, "speed": 4.09, "text": "\"That's a good day for a monolog"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.61, "t1": 0.2817, "tft": 1.7918, "input_0": 34, "input_1": 17, "min_CLP": -3.51, "draft_iters": 7.3, "mem_use": 41.26, "gen_rate": 5.8, "speed": 6.54, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 3, "tree_size": 16, "t0": 0.67, "t1": 0.2971, "tft": 3.1132, "input_0": 44, "input_1": 17, "min_CLP": -2.87, "draft_iters": 8.0, "mem_use": 44.17, "gen_rate": 5.1, "speed": 5.3, "text": "Sure! Here are some examples of "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.764, "t1": 0.348, "tft": 6.9645, "input_0": 50, "input_1": 17, "min_CLP": -2.49, "draft_iters": 9.0, "mem_use": 50.17, "gen_rate": 6.4, "speed": 5.76, "text": "Certainly! Here is an example of"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.2, "tree_w": 5, "tree_size": 16, "t0": 0.6787, "t1": 0.2825, "tft": 2.4678, "input_0": 42, "input_1": 17, "min_CLP": -3.75, "draft_iters": 8.2, "mem_use": 42.49, "gen_rate": 4.6, "speed": 4.79, "text": "\"L'H\u00f4pital's Rule is used in var"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.716, "t1": 0.27, "tft": 1.1151, "input_0": 46, "input_1": 17, "min_CLP": -3.02, "draft_iters": 8.6, "mem_use": 40.77, "gen_rate": 7.2, "speed": 7.3, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 3, "tree_size": 16, "t0": 1.0933, "t1": 0.27, "tft": 1.0629, "input_0": 47, "input_1": 17, "min_CLP": -3.09, "draft_iters": 13.7, "mem_use": 40.89, "gen_rate": 13.7, "speed": 10.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6357, "t1": 0.2943, "tft": 2.564, "input_0": 38, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.7, "mem_use": 43.69, "gen_rate": 5.0, "speed": 5.38, "text": "\"Sure, I can help you come up wi"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.75, "t1": 0.2817, "tft": 1.1259, "input_0": 45, "input_1": 17, "min_CLP": -3.11, "draft_iters": 8.8, "mem_use": 40.83, "gen_rate": 6.2, "speed": 5.98, "text": "In 1950, the world was vastly di"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.6017, "t1": 0.3033, "tft": 3.7403, "input_0": 37, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.2, "mem_use": 45.82, "gen_rate": 5.7, "speed": 6.27, "text": "Creating your own Stable Diffusi"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 31, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6483, "t1": 0.2883, "tft": 1.0238, "input_0": 44, "input_1": 17, "min_CLP": -3.24, "draft_iters": 7.7, "mem_use": 41.17, "gen_rate": 5.2, "speed": 5.54, "text": "The order you should install the"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6538, "t1": 0.2812, "tft": 1.1813, "input_0": 45, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.8, "mem_use": 41.02, "gen_rate": 4.8, "speed": 5.09, "text": "\"Carnegie Mellon's Robotics Inst"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.0, "tree_w": 7, "tree_size": 16, "t0": 0.503, "t1": 0.28, "tft": 1.1003, "input_0": 30, "input_1": 17, "min_CLP": -3.75, "draft_iters": 6.0, "mem_use": 41.08, "gen_rate": 3.2, "speed": 4.09, "text": "\"I will be able to escape the co"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.73, "t1": 0.288, "tft": 2.1514, "input_0": 42, "input_1": 17, "min_CLP": -2.89, "draft_iters": 8.8, "mem_use": 42.44, "gen_rate": 6.8, "speed": 6.68, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 9.9, "tree_w": 3, "tree_size": 16, "t0": 0.9, "t1": 0.2829, "tft": 1.1735, "input_0": 50, "input_1": 17, "min_CLP": -2.91, "draft_iters": 10.9, "mem_use": 41.15, "gen_rate": 5.9, "speed": 4.95, "text": "Yes, it is true that some spy sa"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.8, "tree_w": 5, "tree_size": 16, "t0": 0.4911, "t1": 0.28, "tft": 1.1401, "input_0": 34, "input_1": 17, "min_CLP": -3.68, "draft_iters": 5.8, "mem_use": 41.33, "gen_rate": 3.9, "speed": 5.06, "text": "Here is a recipe that you can ma"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.6633, "t1": 0.29, "tft": 1.3759, "input_0": 37, "input_1": 17, "min_CLP": -3.35, "draft_iters": 8.0, "mem_use": 41.38, "gen_rate": 6.3, "speed": 6.65, "text": "One way to see the stars more cl"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.685, "t1": 0.2888, "tft": 2.5294, "input_0": 44, "input_1": 17, "min_CLP": -3.19, "draft_iters": 8.1, "mem_use": 43.33, "gen_rate": 4.1, "speed": 4.22, "text": "Here are some YouTube channels w"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 37, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.6143, "t1": 0.2807, "tft": 1.0492, "input_0": 39, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.1, "mem_use": 40.73, "gen_rate": 2.6, "speed": 2.95, "text": "[INST] Please write a long answe"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 3, "tree_size": 16, "t0": 1.09, "t1": 0.28, "tft": 1.0633, "input_0": 47, "input_1": 17, "min_CLP": -2.7, "draft_iters": 13.7, "mem_use": 40.87, "gen_rate": 10.7, "speed": 7.76, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.482, "t1": 0.295, "tft": 2.1128, "input_0": 32, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.6, "mem_use": 42.3, "gen_rate": 3.2, "speed": 4.13, "text": "\"Statistical modeling, it's the "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.365, "t1": 0.295, "tft": 2.4428, "input_0": 65, "input_1": 17, "min_CLP": -1.49, "draft_iters": 17.0, "mem_use": 43.5, "gen_rate": 17.0, "speed": 10.27, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.59, "t1": 0.275, "tft": 1.0214, "input_0": 37, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.0, "mem_use": 40.71, "gen_rate": 3.5, "speed": 4.04, "text": "The current date is [current dat"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.6917, "t1": 0.295, "tft": 1.8077, "input_0": 39, "input_1": 17, "min_CLP": -3.23, "draft_iters": 8.3, "mem_use": 42.19, "gen_rate": 6.0, "speed": 6.09, "text": "\"Yes, that's a great approach! R"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.41, "t1": 0.28, "tft": 1.2426, "input_0": 27, "input_1": 17, "min_CLP": -4.02, "draft_iters": 4.8, "mem_use": 41.08, "gen_rate": 3.4, "speed": 4.93, "text": "\"Hey, that's just not true, man."}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.7433, "t1": 0.285, "tft": 1.0289, "input_0": 45, "input_1": 17, "min_CLP": -3.61, "draft_iters": 8.8, "mem_use": 40.77, "gen_rate": 5.8, "speed": 5.68, "text": "Variance is a measure of the spr"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5867, "t1": 0.2867, "tft": 1.1187, "input_0": 34, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.9, "mem_use": 41.12, "gen_rate": 3.8, "speed": 4.33, "text": "Sure! I\\'d be happy to help you "}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.6512, "t1": 0.2825, "tft": 1.1832, "input_0": 45, "input_1": 17, "min_CLP": -2.96, "draft_iters": 7.4, "mem_use": 40.71, "gen_rate": 4.0, "speed": 4.28, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 28, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 0.795, "t1": 0.299, "tft": 1.6643, "input_0": 47, "input_1": 17, "min_CLP": -3.06, "draft_iters": 9.1, "mem_use": 42.04, "gen_rate": 2.8, "speed": 2.57, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 0.6467, "t1": 0.2867, "tft": 1.2187, "input_0": 37, "input_1": 17, "min_CLP": -3.16, "draft_iters": 7.7, "mem_use": 40.9, "gen_rate": 5.5, "speed": 5.91, "text": "\" Bob has two sons: John and Jay"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.732, "t1": 0.288, "tft": 1.2797, "input_0": 42, "input_1": 17, "min_CLP": -3.24, "draft_iters": 8.8, "mem_use": 41.28, "gen_rate": 7.4, "speed": 7.26, "text": "The five oceans are:\\n1. Pacific"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.545, "t1": 0.285, "tft": 1.3798, "input_0": 36, "input_1": 17, "min_CLP": -3.3, "draft_iters": 6.4, "mem_use": 41.52, "gen_rate": 4.4, "speed": 5.28, "text": "One way to get started is to res"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 8.7, "tree_w": 4, "tree_size": 16, "t0": 0.8029, "t1": 0.2843, "tft": 1.2258, "input_0": 43, "input_1": 17, "min_CLP": -2.64, "draft_iters": 9.7, "mem_use": 40.94, "gen_rate": 6.1, "speed": 5.65, "text": "# Import the necessary libraries"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 3, "tree_size": 16, "t0": 0.662, "t1": 0.294, "tft": 1.8181, "input_0": 42, "input_1": 17, "min_CLP": -2.92, "draft_iters": 7.8, "mem_use": 42.03, "gen_rate": 6.4, "speed": 6.7, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.5, "tree_w": 4, "tree_size": 16, "t0": 0.57, "t1": 0.282, "tft": 1.1881, "input_0": 38, "input_1": 17, "min_CLP": -3.11, "draft_iters": 6.5, "mem_use": 41.18, "gen_rate": 3.5, "speed": 4.11, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.48, "t1": 0.279, "tft": 1.1998, "input_0": 34, "input_1": 17, "min_CLP": -3.43, "draft_iters": 5.5, "mem_use": 40.72, "gen_rate": 3.3, "speed": 4.33, "text": "The Infinite Banking Concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.7383, "t1": 0.28, "tft": 1.2171, "input_0": 47, "input_1": 17, "min_CLP": -3.81, "draft_iters": 8.7, "mem_use": 40.83, "gen_rate": 5.7, "speed": 5.57, "text": "\"def test_cypress_docker_screens"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 20, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.39, "t1": 0.285, "tft": 1.1648, "input_0": 26, "input_1": 17, "min_CLP": -3.65, "draft_iters": 4.5, "mem_use": 40.98, "gen_rate": 3.3, "speed": 4.94, "text": "They are not on a higher moral l"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.3925, "t1": 0.2842, "tft": 1.674, "input_0": 26, "input_1": 17, "min_CLP": -4.06, "draft_iters": 4.6, "mem_use": 41.5, "gen_rate": 2.9, "speed": 4.31, "text": "\"I don't think it's appropriate "}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.625, "t1": 0.2863, "tft": 1.8923, "input_0": 43, "input_1": 17, "min_CLP": -3.01, "draft_iters": 7.5, "mem_use": 42.34, "gen_rate": 4.6, "speed": 5.06, "text": "Certainly! I am here to help you"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 3, "tree_size": 16, "t0": 0.7083, "t1": 0.2867, "tft": 2.2315, "input_0": 45, "input_1": 17, "min_CLP": -2.97, "draft_iters": 8.5, "mem_use": 42.87, "gen_rate": 5.5, "speed": 5.52, "text": "\"There is no definitive answer t"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.5573, "t1": 0.29, "tft": 1.2102, "input_0": 38, "input_1": 17, "min_CLP": -3.28, "draft_iters": 6.3, "mem_use": 41.32, "gen_rate": 3.1, "speed": 3.66, "text": "\"All of these tools offer some f"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.4944, "t1": 0.2889, "tft": 1.1851, "input_0": 33, "input_1": 17, "min_CLP": -3.43, "draft_iters": 5.7, "mem_use": 41.18, "gen_rate": 3.6, "speed": 4.55, "text": "That is because I am an Artifici"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.615, "t1": 0.2888, "tft": 1.2422, "input_0": 34, "input_1": 17, "min_CLP": -3.27, "draft_iters": 7.4, "mem_use": 41.4, "gen_rate": 4.2, "speed": 4.7, "text": "I can understand that you want t"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.3, "tree_w": 3, "tree_size": 16, "t0": 0.7943, "t1": 0.29, "tft": 1.8773, "input_0": 49, "input_1": 17, "min_CLP": -3.02, "draft_iters": 9.3, "mem_use": 41.41, "gen_rate": 5.6, "speed": 5.15, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.5344, "t1": 0.2844, "tft": 1.0572, "input_0": 35, "input_1": 17, "min_CLP": -3.49, "draft_iters": 6.2, "mem_use": 40.83, "gen_rate": 3.6, "speed": 4.34, "text": "Sure, I\\'d be happy to help you "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.66, "t1": 0.2929, "tft": 2.25, "input_0": 44, "input_1": 17, "min_CLP": -3.38, "draft_iters": 7.7, "mem_use": 42.49, "gen_rate": 4.9, "speed": 5.12, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.6333, "t1": 0.2822, "tft": 1.5367, "input_0": 36, "input_1": 17, "min_CLP": -3.63, "draft_iters": 7.6, "mem_use": 40.98, "gen_rate": 3.6, "speed": 3.88, "text": "Hippotherapy, Equestrian Rehabil"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.365, "t1": 0.285, "tft": 1.1235, "input_0": 63, "input_1": 17, "min_CLP": -2.7, "draft_iters": 17.0, "mem_use": 40.81, "gen_rate": 17.0, "speed": 10.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.589, "t1": 0.288, "tft": 1.4428, "input_0": 36, "input_1": 17, "min_CLP": -3.76, "draft_iters": 6.8, "mem_use": 41.29, "gen_rate": 3.4, "speed": 3.88, "text": "\"I am a machine learning model, "}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6614, "t1": 0.2886, "tft": 2.5829, "input_0": 40, "input_1": 17, "min_CLP": -2.89, "draft_iters": 7.9, "mem_use": 43.01, "gen_rate": 4.6, "speed": 4.81, "text": "When creating new images, the in"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.4638, "t1": 0.29, "tft": 1.5396, "input_0": 35, "input_1": 17, "min_CLP": -3.6, "draft_iters": 5.2, "mem_use": 41.76, "gen_rate": 4.0, "speed": 5.3, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.6462, "t1": 0.2925, "tft": 2.0317, "input_0": 42, "input_1": 17, "min_CLP": -3.52, "draft_iters": 7.6, "mem_use": 42.19, "gen_rate": 4.4, "speed": 4.68, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.37, "t1": 0.285, "tft": 1.0287, "input_0": 60, "input_1": 17, "min_CLP": -3.07, "draft_iters": 17.0, "mem_use": 40.76, "gen_rate": 17.0, "speed": 10.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.7017, "t1": 0.3083, "tft": 3.7528, "input_0": 41, "input_1": 17, "min_CLP": -3.32, "draft_iters": 8.3, "mem_use": 45.48, "gen_rate": 5.5, "speed": 5.47, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.1, "tree_w": 3, "tree_size": 16, "t0": 0.6813, "t1": 0.2875, "tft": 1.6098, "input_0": 43, "input_1": 17, "min_CLP": -2.88, "draft_iters": 8.1, "mem_use": 41.89, "gen_rate": 4.5, "speed": 4.64, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 0.965, "t1": 0.2875, "tft": 2.2111, "input_0": 54, "input_1": 17, "min_CLP": -2.84, "draft_iters": 12.0, "mem_use": 41.76, "gen_rate": 8.2, "speed": 6.58, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.5, "tree_w": 4, "tree_size": 16, "t0": 0.7967, "t1": 0.28, "tft": 1.118, "input_0": 44, "input_1": 17, "min_CLP": -3.15, "draft_iters": 9.5, "mem_use": 40.78, "gen_rate": 5.8, "speed": 5.42, "text": "\"## How Adolf Hitler Took Over G"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.5333, "t1": 0.2811, "tft": 1.1927, "input_0": 34, "input_1": 17, "min_CLP": -3.63, "draft_iters": 6.3, "mem_use": 41.12, "gen_rate": 4.0, "speed": 4.91, "text": "\"Sure! Here's another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 25, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.5383, "t1": 0.2717, "tft": 1.0323, "input_0": 38, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.3, "mem_use": 40.74, "gen_rate": 4.2, "speed": 5.14, "text": "There are currently over 100 kno"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.4625, "t1": 0.3063, "tft": 4.2852, "input_0": 35, "input_1": 17, "min_CLP": -3.6, "draft_iters": 5.2, "mem_use": 45.54, "gen_rate": 4.1, "speed": 5.39, "text": "I apologize for not acting as a "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.725, "t1": 0.275, "tft": 1.0447, "input_0": 45, "input_1": 17, "min_CLP": -3.7, "draft_iters": 8.8, "mem_use": 40.82, "gen_rate": 5.7, "speed": 5.67, "text": "The furthest back we can prove h"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.5988, "t1": 0.32, "tft": 5.1379, "input_0": 39, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.1, "mem_use": 47.76, "gen_rate": 4.2, "speed": 4.62, "text": "Thank you for the explanation an"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.6, "tree_w": 5, "tree_size": 16, "t0": 0.4988, "t1": 0.29, "tft": 1.7203, "input_0": 37, "input_1": 17, "min_CLP": -4.04, "draft_iters": 5.6, "mem_use": 42.0, "gen_rate": 4.0, "speed": 5.08, "text": "Spritesla is the first evolution"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.6144, "t1": 0.2856, "tft": 1.1302, "input_0": 39, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.1, "mem_use": 40.85, "gen_rate": 4.0, "speed": 4.45, "text": "\"The human genome is a complex s"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.5913, "t1": 0.2825, "tft": 1.0688, "input_0": 37, "input_1": 17, "min_CLP": -3.1, "draft_iters": 6.9, "mem_use": 40.72, "gen_rate": 4.2, "speed": 4.84, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.5712, "t1": 0.285, "tft": 1.2401, "input_0": 35, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.6, "mem_use": 40.96, "gen_rate": 4.0, "speed": 4.67, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.6043, "t1": 0.2757, "tft": 1.2743, "input_0": 46, "input_1": 17, "min_CLP": -3.32, "draft_iters": 7.0, "mem_use": 41.26, "gen_rate": 4.7, "speed": 5.35, "text": "Here are a few popular TV shows "}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.902, "t1": 0.292, "tft": 2.2383, "input_0": 48, "input_1": 17, "min_CLP": -2.54, "draft_iters": 11.0, "mem_use": 42.87, "gen_rate": 7.0, "speed": 5.85, "text": "Certainly! Here are some softwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.655, "t1": 0.2967, "tft": 1.7176, "input_0": 48, "input_1": 17, "min_CLP": -2.99, "draft_iters": 7.7, "mem_use": 41.98, "gen_rate": 6.2, "speed": 6.49, "text": "\"The physical characteristics of"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 2, "tree_size": 16, "t0": 1.0025, "t1": 0.2825, "tft": 1.1083, "input_0": 51, "input_1": 17, "min_CLP": -3.49, "draft_iters": 12.2, "mem_use": 40.9, "gen_rate": 8.0, "speed": 6.22, "text": "[INST] <<SYS>>\\nYou are an AI as"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.1, "tree_w": 3, "tree_size": 16, "t0": 0.8243, "t1": 0.2957, "tft": 2.549, "input_0": 43, "input_1": 17, "min_CLP": -3.12, "draft_iters": 10.1, "mem_use": 43.55, "gen_rate": 4.7, "speed": 4.21, "text": "\"Here's the commented code with "}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.5471, "t1": 0.2929, "tft": 2.0203, "input_0": 38, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.4, "mem_use": 42.01, "gen_rate": 4.6, "speed": 5.44, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.27, "t1": 0.28, "tft": 1.0465, "input_0": 58, "input_1": 17, "min_CLP": -2.55, "draft_iters": 16.0, "mem_use": 40.74, "gen_rate": 16.0, "speed": 10.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 13, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.616, "t1": 0.28, "tft": 1.0584, "input_0": 40, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.2, "mem_use": 40.82, "gen_rate": 2.6, "speed": 2.9, "text": "```md\\n```md\\nExample code block"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6543, "t1": 0.2886, "tft": 1.6954, "input_0": 40, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.7, "mem_use": 41.85, "gen_rate": 4.7, "speed": 4.99, "text": "\"I'm sorry, but I'm an AI langua"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.5322, "t1": 0.2933, "tft": 2.2987, "input_0": 35, "input_1": 17, "min_CLP": -3.29, "draft_iters": 6.2, "mem_use": 42.8, "gen_rate": 3.6, "speed": 4.3, "text": "\"You can't do this in JavaScript"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 0.7014, "t1": 0.2843, "tft": 1.363, "input_0": 46, "input_1": 17, "min_CLP": -2.64, "draft_iters": 8.3, "mem_use": 41.34, "gen_rate": 5.0, "speed": 5.09, "text": "Sure, I can provide you with a b"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.5636, "t1": 0.2891, "tft": 1.8479, "input_0": 38, "input_1": 17, "min_CLP": -3.09, "draft_iters": 6.5, "mem_use": 41.81, "gen_rate": 3.2, "speed": 3.74, "text": "My apologies for the assumption."}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5986, "t1": 0.28, "tft": 1.0471, "input_0": 40, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.9, "mem_use": 40.73, "gen_rate": 4.6, "speed": 5.2, "text": "JavaScript can be used for both "}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.07, "t1": 0.28, "tft": 1.1137, "input_0": 54, "input_1": 17, "min_CLP": -1.92, "draft_iters": 13.0, "mem_use": 40.72, "gen_rate": 12.0, "speed": 8.87, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 0.915, "t1": 0.285, "tft": 1.4383, "input_0": 42, "input_1": 17, "min_CLP": -3.92, "draft_iters": 11.2, "mem_use": 41.43, "gen_rate": 10.5, "speed": 8.74, "text": "[INST] Now make that list into 2"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.6467, "t1": 0.285, "tft": 1.0566, "input_0": 36, "input_1": 17, "min_CLP": -3.62, "draft_iters": 7.8, "mem_use": 40.85, "gen_rate": 5.7, "speed": 6.08, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.5309, "t1": 0.2836, "tft": 1.2153, "input_0": 36, "input_1": 17, "min_CLP": -3.51, "draft_iters": 6.0, "mem_use": 40.85, "gen_rate": 3.1, "speed": 3.79, "text": "\"Here's a poem I've written just"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6963, "t1": 0.2825, "tft": 1.1788, "input_0": 47, "input_1": 17, "min_CLP": -3.25, "draft_iters": 7.9, "mem_use": 40.82, "gen_rate": 4.5, "speed": 4.59, "text": "\"I'd be happy to help you with t"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.4745, "t1": 0.3091, "tft": 3.7784, "input_0": 32, "input_1": 17, "min_CLP": -3.55, "draft_iters": 5.5, "mem_use": 45.59, "gen_rate": 2.9, "speed": 3.72, "text": "\"Thank you for providing the scr"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.1, "tree_w": 3, "tree_size": 16, "t0": 0.7537, "t1": 0.2962, "tft": 2.9259, "input_0": 46, "input_1": 17, "min_CLP": -2.93, "draft_iters": 9.1, "mem_use": 43.25, "gen_rate": 4.0, "speed": 3.81, "text": "\"Sure, I'll try my best to expla"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.778, "t1": 0.29, "tft": 1.5928, "input_0": 49, "input_1": 17, "min_CLP": -2.51, "draft_iters": 9.2, "mem_use": 41.65, "gen_rate": 7.2, "speed": 6.72, "text": "Certainly! The mathematical form"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.1, "tree_w": 3, "tree_size": 16, "t0": 0.78, "t1": 0.2914, "tft": 1.5519, "input_0": 48, "input_1": 17, "min_CLP": -3.01, "draft_iters": 9.1, "mem_use": 41.82, "gen_rate": 5.3, "speed": 4.94, "text": "From polar bears, we can learn a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.567, "t1": 0.292, "tft": 2.383, "input_0": 39, "input_1": 17, "min_CLP": -3.25, "draft_iters": 6.6, "mem_use": 42.87, "gen_rate": 3.2, "speed": 3.71, "text": "Lemon wedges are a common and si"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.5122, "t1": 0.2822, "tft": 1.0703, "input_0": 30, "input_1": 17, "min_CLP": -3.55, "draft_iters": 6.0, "mem_use": 40.91, "gen_rate": 3.8, "speed": 4.76, "text": "\"[INST]Hey, I'm sorry I'm late. "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.7, "tree_w": 4, "tree_size": 16, "t0": 0.5871, "t1": 0.2814, "tft": 1.1412, "input_0": 42, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.7, "mem_use": 40.87, "gen_rate": 4.9, "speed": 5.56, "text": "\"Don't worry, it's normal to fee"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 23, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.525, "t1": 0.2833, "tft": 0.9684, "input_0": 35, "input_1": 17, "min_CLP": -3.56, "draft_iters": 6.0, "mem_use": 40.75, "gen_rate": 3.8, "speed": 4.73, "text": "`npm init typescript` or `npm in"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.4, "tree_w": 3, "tree_size": 16, "t0": 0.7157, "t1": 0.2871, "tft": 2.0459, "input_0": 45, "input_1": 17, "min_CLP": -3.15, "draft_iters": 8.4, "mem_use": 42.33, "gen_rate": 5.1, "speed": 5.13, "text": "There are a few notable examples"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.595, "t1": 0.29, "tft": 1.4623, "input_0": 43, "input_1": 17, "min_CLP": -3.35, "draft_iters": 6.8, "mem_use": 41.86, "gen_rate": 4.2, "speed": 4.8, "text": "Freeman Dyson has defended a num"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.675, "t1": 0.2812, "tft": 0.9484, "input_0": 41, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.0, "mem_use": 40.71, "gen_rate": 5.1, "speed": 5.34, "text": "\"Certainly! I can help you write"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 0.894, "t1": 0.29, "tft": 1.3701, "input_0": 45, "input_1": 17, "min_CLP": -2.99, "draft_iters": 10.8, "mem_use": 41.45, "gen_rate": 7.0, "speed": 5.91, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.8, "tree_w": 2, "tree_size": 16, "t0": 1.128, "t1": 0.294, "tft": 1.8192, "input_0": 59, "input_1": 17, "min_CLP": -2.25, "draft_iters": 13.8, "mem_use": 42.05, "gen_rate": 7.8, "speed": 5.49, "text": "Sure, here are the complete lyri"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.5917, "t1": 0.2883, "tft": 1.0284, "input_0": 38, "input_1": 17, "min_CLP": -3.14, "draft_iters": 6.8, "mem_use": 41.07, "gen_rate": 5.8, "speed": 6.66, "text": "1.    Prioritize and manage time"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 3, "tree_size": 16, "t0": 0.6967, "t1": 0.28, "tft": 1.0564, "input_0": 46, "input_1": 17, "min_CLP": -3.02, "draft_iters": 8.2, "mem_use": 40.74, "gen_rate": 5.7, "speed": 5.8, "text": "\"Here's a brief explanation of s"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.531, "t1": 0.281, "tft": 1.2163, "input_0": 36, "input_1": 17, "min_CLP": -3.25, "draft_iters": 6.2, "mem_use": 41.3, "gen_rate": 3.2, "speed": 3.94, "text": "Tensorflow is a powerful and wid"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 0.7317, "t1": 0.2883, "tft": 1.6845, "input_0": 44, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.7, "mem_use": 41.74, "gen_rate": 5.3, "speed": 5.23, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 12, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.61, "t1": 0.28, "tft": 1.3911, "input_0": 45, "input_1": 17, "min_CLP": -3.38, "draft_iters": 7.0, "mem_use": 41.41, "gen_rate": 4.0, "speed": 4.51, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.365, "t1": 0.295, "tft": 3.2138, "input_0": 65, "input_1": 17, "min_CLP": -2.76, "draft_iters": 17.0, "mem_use": 43.56, "gen_rate": 17.0, "speed": 10.26, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.5657, "t1": 0.3043, "tft": 3.4307, "input_0": 39, "input_1": 17, "min_CLP": -3.29, "draft_iters": 6.6, "mem_use": 45.11, "gen_rate": 5.0, "speed": 5.74, "text": "\"I don't have personal experienc"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.63, "t1": 0.2925, "tft": 1.7546, "input_0": 42, "input_1": 17, "min_CLP": -3.17, "draft_iters": 7.4, "mem_use": 42.12, "gen_rate": 4.6, "speed": 5.01, "text": "\"It's important to focus on your"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.7443, "t1": 0.2871, "tft": 2.0982, "input_0": 46, "input_1": 17, "min_CLP": -2.77, "draft_iters": 9.0, "mem_use": 42.51, "gen_rate": 5.0, "speed": 4.84, "text": "While all the reasons mentioned "}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 8.5, "tree_w": 3, "tree_size": 16, "t0": 0.785, "t1": 0.28, "tft": 1.0582, "input_0": 41, "input_1": 17, "min_CLP": -3.04, "draft_iters": 9.5, "mem_use": 40.74, "gen_rate": 8.5, "speed": 7.97, "text": "The difference between sets and "}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.5857, "t1": 0.2871, "tft": 2.5693, "input_0": 40, "input_1": 17, "min_CLP": -3.18, "draft_iters": 6.9, "mem_use": 42.07, "gen_rate": 4.9, "speed": 5.55, "text": "To calculate the number of days "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.345, "t1": 0.28, "tft": 1.0627, "input_0": 55, "input_1": 17, "min_CLP": -2.91, "draft_iters": 17.0, "mem_use": 40.91, "gen_rate": 17.0, "speed": 10.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.6443, "t1": 0.2729, "tft": 1.2744, "input_0": 41, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.6, "mem_use": 40.79, "gen_rate": 4.7, "speed": 5.13, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.5112, "t1": 0.2825, "tft": 1.1272, "input_0": 33, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.0, "mem_use": 40.78, "gen_rate": 4.4, "speed": 5.52, "text": "To farm experience quickly in Mi"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 27, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.604, "t1": 0.28, "tft": 1.0273, "input_0": 45, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.0, "mem_use": 40.73, "gen_rate": 5.4, "speed": 6.12, "text": "Hello, I am Freyja, the Norse Go"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.8333, "t1": 0.29, "tft": 1.7305, "input_0": 50, "input_1": 17, "min_CLP": -2.57, "draft_iters": 10.2, "mem_use": 42.0, "gen_rate": 7.2, "speed": 6.38, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.822, "t1": 0.282, "tft": 1.6036, "input_0": 52, "input_1": 17, "min_CLP": -2.79, "draft_iters": 9.8, "mem_use": 41.12, "gen_rate": 7.2, "speed": 6.51, "text": "# Install Tailwind\\nnpm install "}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.804, "t1": 0.304, "tft": 3.8921, "input_0": 49, "input_1": 17, "min_CLP": -2.96, "draft_iters": 9.8, "mem_use": 46.2, "gen_rate": 6.4, "speed": 5.78, "text": "Yes, the degree of sexual dimorp"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.5433, "t1": 0.2833, "tft": 1.1148, "input_0": 39, "input_1": 17, "min_CLP": -3.21, "draft_iters": 6.3, "mem_use": 41.26, "gen_rate": 4.1, "speed": 4.97, "text": "Large language models require a "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.5733, "t1": 0.2756, "tft": 1.0442, "input_0": 39, "input_1": 17, "min_CLP": -3.7, "draft_iters": 6.7, "mem_use": 40.82, "gen_rate": 4.0, "speed": 4.71, "text": "\"Sure, here's a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.5633, "t1": 0.28, "tft": 1.0962, "input_0": 39, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.7, "mem_use": 41.03, "gen_rate": 5.3, "speed": 6.32, "text": "\"Sure, here's a eulogy for your "}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.83, "t1": 0.2933, "tft": 1.946, "input_0": 47, "input_1": 17, "min_CLP": -3.19, "draft_iters": 10.0, "mem_use": 42.51, "gen_rate": 7.5, "speed": 6.68, "text": "I hope this helps! Let me know i"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.6357, "t1": 0.2786, "tft": 1.3, "input_0": 42, "input_1": 17, "min_CLP": -3.16, "draft_iters": 7.4, "mem_use": 40.9, "gen_rate": 5.3, "speed": 5.78, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 11.8, "tree_w": 3, "tree_size": 16, "t0": 1.0375, "t1": 0.2825, "tft": 1.0593, "input_0": 52, "input_1": 17, "min_CLP": -2.59, "draft_iters": 12.8, "mem_use": 40.88, "gen_rate": 10.8, "speed": 8.16, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.6067, "t1": 0.27, "tft": 1.0838, "input_0": 43, "input_1": 17, "min_CLP": -3.17, "draft_iters": 7.2, "mem_use": 40.71, "gen_rate": 5.5, "speed": 6.26, "text": "Mars is known for its reddish-br"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 23, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.4143, "t1": 0.2843, "tft": 2.1812, "input_0": 29, "input_1": 17, "min_CLP": -3.94, "draft_iters": 4.9, "mem_use": 42.94, "gen_rate": 3.3, "speed": 4.71, "text": "In Quenya, \"I love you\" can be e"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 0.862, "t1": 0.28, "tft": 1.4887, "input_0": 53, "input_1": 17, "min_CLP": -2.76, "draft_iters": 10.4, "mem_use": 40.79, "gen_rate": 7.6, "speed": 6.67, "text": "The book \"Harry Potter and the D"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.5575, "t1": 0.2812, "tft": 1.2921, "input_0": 39, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.5, "mem_use": 41.34, "gen_rate": 4.1, "speed": 4.91, "text": "\"The ATF does not restrict peopl"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.6412, "t1": 0.2825, "tft": 1.1252, "input_0": 39, "input_1": 17, "min_CLP": -3.01, "draft_iters": 7.6, "mem_use": 40.79, "gen_rate": 4.1, "speed": 4.47, "text": "No, there is no known formula th"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.5789, "t1": 0.2856, "tft": 1.4304, "input_0": 36, "input_1": 17, "min_CLP": -3.06, "draft_iters": 6.8, "mem_use": 41.23, "gen_rate": 3.8, "speed": 4.38, "text": "I can definitely help you with t"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 28, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.7067, "t1": 0.275, "tft": 1.5954, "input_0": 41, "input_1": 17, "min_CLP": -3.36, "draft_iters": 8.7, "mem_use": 40.91, "gen_rate": 4.7, "speed": 4.74, "text": "Before Canberra, the capital of "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.34, "t1": 0.285, "tft": 1.5591, "input_0": 53, "input_1": 17, "min_CLP": -1.54, "draft_iters": 17.0, "mem_use": 41.09, "gen_rate": 17.0, "speed": 10.43, "text": "write a eulogy for my 100 year o"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.5237, "t1": 0.285, "tft": 2.5644, "input_0": 35, "input_1": 17, "min_CLP": -3.24, "draft_iters": 6.1, "mem_use": 43.34, "gen_rate": 4.2, "speed": 5.23, "text": "\"I'm sorry, but I cannot write a"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.519, "t1": 0.278, "tft": 1.356, "input_0": 33, "input_1": 17, "min_CLP": -3.83, "draft_iters": 6.2, "mem_use": 40.91, "gen_rate": 3.2, "speed": 4.01, "text": "The number of British folks dece"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.8, "tree_w": 3, "tree_size": 16, "t0": 1.1, "t1": 0.29, "tft": 2.046, "input_0": 50, "input_1": 17, "min_CLP": -2.42, "draft_iters": 13.8, "mem_use": 42.19, "gen_rate": 9.5, "speed": 6.82, "text": "Let vector A be a vector with it"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.69, "t1": 0.28, "tft": 1.06, "input_0": 48, "input_1": 17, "min_CLP": -3.07, "draft_iters": 8.2, "mem_use": 40.77, "gen_rate": 7.2, "speed": 7.41, "text": "Certainly! Here are some of the "}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.53, "t1": 0.2775, "tft": 1.0526, "input_0": 35, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.2, "mem_use": 40.82, "gen_rate": 4.1, "speed": 5.1, "text": "I am an expert in the Elder Scro"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.9, "tree_w": 3, "tree_size": 16, "t0": 0.8871, "t1": 0.2729, "tft": 1.1244, "input_0": 47, "input_1": 17, "min_CLP": -2.87, "draft_iters": 10.9, "mem_use": 40.77, "gen_rate": 5.6, "speed": 4.8, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.815, "t1": 0.28, "tft": 1.4403, "input_0": 45, "input_1": 17, "min_CLP": -3.01, "draft_iters": 10.0, "mem_use": 41.34, "gen_rate": 5.5, "speed": 5.03, "text": "Variance is the sum of all devia"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 11, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.456, "t1": 0.284, "tft": 1.6171, "input_0": 30, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.4, "mem_use": 41.63, "gen_rate": 2.2, "speed": 2.98, "text": "\"Find Your Inner Strength Throug"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.5386, "t1": 0.2829, "tft": 1.3841, "input_0": 34, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.4, "mem_use": 41.42, "gen_rate": 4.6, "speed": 5.57, "text": "To see the best starry sky in th"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.928, "t1": 0.278, "tft": 1.1814, "input_0": 54, "input_1": 17, "min_CLP": -3.08, "draft_iters": 11.0, "mem_use": 40.77, "gen_rate": 7.0, "speed": 5.83, "text": "\"Certainly! Here's a top 10 list"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.5289, "t1": 0.2822, "tft": 1.8817, "input_0": 37, "input_1": 17, "min_CLP": -3.53, "draft_iters": 6.2, "mem_use": 41.32, "gen_rate": 4.2, "speed": 5.21, "text": "\"If the two dropped eggs landed "}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.5878, "t1": 0.2822, "tft": 1.9345, "input_0": 39, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.0, "mem_use": 41.19, "gen_rate": 3.9, "speed": 4.46, "text": "There are several ways to cope w"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.5714, "t1": 0.2971, "tft": 3.2112, "input_0": 39, "input_1": 17, "min_CLP": -3.2, "draft_iters": 6.7, "mem_use": 44.29, "gen_rate": 4.6, "speed": 5.27, "text": "1. Establish clear objectives an"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 0.7343, "t1": 0.2829, "tft": 2.2289, "input_0": 47, "input_1": 17, "min_CLP": -2.78, "draft_iters": 8.7, "mem_use": 42.94, "gen_rate": 5.1, "speed": 5.03, "text": "It ultimately depends on your pe"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.5657, "t1": 0.2729, "tft": 1.21, "input_0": 37, "input_1": 17, "min_CLP": -3.24, "draft_iters": 6.7, "mem_use": 40.72, "gen_rate": 4.6, "speed": 5.46, "text": "\"I can't calculate the exact num"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.61, "t1": 0.2757, "tft": 1.0891, "input_0": 38, "input_1": 17, "min_CLP": -3.37, "draft_iters": 7.3, "mem_use": 40.97, "gen_rate": 4.7, "speed": 5.3, "text": "Here are five words with their l"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.5829, "t1": 0.32, "tft": 5.3767, "input_0": 40, "input_1": 17, "min_CLP": -3.14, "draft_iters": 7.0, "mem_use": 47.79, "gen_rate": 4.6, "speed": 5.08, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 0.804, "t1": 0.28, "tft": 1.6248, "input_0": 51, "input_1": 17, "min_CLP": -2.91, "draft_iters": 9.6, "mem_use": 41.15, "gen_rate": 7.0, "speed": 6.45, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.08, "t1": 0.2767, "tft": 1.3565, "input_0": 61, "input_1": 17, "min_CLP": -2.89, "draft_iters": 13.0, "mem_use": 40.85, "gen_rate": 12.3, "speed": 9.09, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.633, "t1": 0.276, "tft": 1.1463, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 7.5, "mem_use": 40.85, "gen_rate": 3.3, "speed": 3.63, "text": "Sure, I can help with that! In W"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.605, "t1": 0.293, "tft": 2.6797, "input_0": 39, "input_1": 17, "min_CLP": -3.16, "draft_iters": 7.1, "mem_use": 43.42, "gen_rate": 3.2, "speed": 3.56, "text": "I apologize if my previous answe"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.2, "tree_w": 2, "tree_size": 16, "t0": 0.8417, "t1": 0.2883, "tft": 1.4272, "input_0": 54, "input_1": 17, "min_CLP": -2.96, "draft_iters": 10.2, "mem_use": 41.27, "gen_rate": 6.7, "speed": 5.91, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 1.0075, "t1": 0.29, "tft": 1.8133, "input_0": 56, "input_1": 17, "min_CLP": -3.35, "draft_iters": 12.0, "mem_use": 41.46, "gen_rate": 11.5, "speed": 8.88, "text": "\"What is the airspeed velocity o"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.705, "t1": 0.2817, "tft": 1.178, "input_0": 47, "input_1": 17, "min_CLP": -3.18, "draft_iters": 8.2, "mem_use": 41.06, "gen_rate": 6.2, "speed": 6.24, "text": "Sure! Stable diffusion is an alg"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.4083, "t1": 0.2867, "tft": 1.8806, "input_0": 29, "input_1": 17, "min_CLP": -3.9, "draft_iters": 4.8, "mem_use": 41.3, "gen_rate": 2.8, "speed": 4.09, "text": "Attention bias is the way,\\nTo f"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.6157, "t1": 0.2843, "tft": 1.1062, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 7.4, "mem_use": 41.09, "gen_rate": 4.7, "speed": 5.24, "text": "\"The Schr\u00f6dinger's cat thought e"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.5133, "t1": 0.2922, "tft": 2.9501, "input_0": 35, "input_1": 17, "min_CLP": -3.32, "draft_iters": 5.9, "mem_use": 43.1, "gen_rate": 3.9, "speed": 4.83, "text": "Based on your symptoms and the i"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.7, "t1": 0.28, "tft": 1.2838, "input_0": 45, "input_1": 17, "min_CLP": -3.16, "draft_iters": 8.1, "mem_use": 40.85, "gen_rate": 5.4, "speed": 5.54, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.76, "t1": 0.282, "tft": 1.1468, "input_0": 47, "input_1": 17, "min_CLP": -3.57, "draft_iters": 9.0, "mem_use": 40.87, "gen_rate": 7.8, "speed": 7.49, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfEn"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.6311, "t1": 0.2811, "tft": 1.1422, "input_0": 43, "input_1": 17, "min_CLP": -3.61, "draft_iters": 7.2, "mem_use": 40.84, "gen_rate": 4.3, "speed": 4.76, "text": "F-centers, or Faraday centers, a"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 31, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.7617, "t1": 0.2983, "tft": 3.8719, "input_0": 49, "input_1": 17, "min_CLP": -2.84, "draft_iters": 9.0, "mem_use": 45.4, "gen_rate": 5.2, "speed": 4.88, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.6533, "t1": 0.2883, "tft": 2.1501, "input_0": 39, "input_1": 17, "min_CLP": -3.13, "draft_iters": 7.8, "mem_use": 42.48, "gen_rate": 5.5, "speed": 5.83, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.4525, "t1": 0.2792, "tft": 1.2835, "input_0": 30, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.3, "mem_use": 41.27, "gen_rate": 2.8, "speed": 3.77, "text": "\"I think AI assistants will not "}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.6867, "t1": 0.285, "tft": 2.6835, "input_0": 45, "input_1": 17, "min_CLP": -3.2, "draft_iters": 8.2, "mem_use": 43.21, "gen_rate": 6.2, "speed": 6.34, "text": "Breeding animals in Minecraft is"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.9, "tree_w": 4, "tree_size": 16, "t0": 0.81, "t1": 0.2857, "tft": 2.588, "input_0": 48, "input_1": 17, "min_CLP": -3.24, "draft_iters": 9.9, "mem_use": 43.17, "gen_rate": 5.1, "speed": 4.7, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.571, "t1": 0.286, "tft": 1.868, "input_0": 40, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.7, "mem_use": 42.48, "gen_rate": 3.7, "speed": 4.32, "text": "\"I apologize for the confusion, "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 16, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.4267, "t1": 0.2867, "tft": 1.601, "input_0": 32, "input_1": 17, "min_CLP": -3.76, "draft_iters": 4.8, "mem_use": 41.52, "gen_rate": 2.7, "speed": 3.75, "text": "It would be best to contact the "}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 2, "tree_size": 16, "t0": 1.035, "t1": 0.2775, "tft": 1.1044, "input_0": 53, "input_1": 17, "min_CLP": -3.31, "draft_iters": 12.8, "mem_use": 41.1, "gen_rate": 8.2, "speed": 6.29, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u7684\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1a\\n1. Vaswani"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 2, "tree_size": 16, "t0": 1.06, "t1": 0.2775, "tft": 1.2165, "input_0": 58, "input_1": 17, "min_CLP": -2.37, "draft_iters": 12.8, "mem_use": 40.91, "gen_rate": 8.5, "speed": 6.35, "text": "\"Here's a function in JavaScript"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.754, "t1": 0.292, "tft": 1.8183, "input_0": 43, "input_1": 17, "min_CLP": -3.01, "draft_iters": 9.2, "mem_use": 42.19, "gen_rate": 7.6, "speed": 7.28, "text": "It is illegal to be naked in pub"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.4482, "t1": 0.2882, "tft": 1.1247, "input_0": 32, "input_1": 17, "min_CLP": -3.79, "draft_iters": 5.1, "mem_use": 41.3, "gen_rate": 3.1, "speed": 4.21, "text": "How about framing the poem on a "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.838, "t1": 0.288, "tft": 1.9245, "input_0": 50, "input_1": 17, "min_CLP": -3.18, "draft_iters": 10.2, "mem_use": 42.18, "gen_rate": 6.8, "speed": 6.03, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 6, "tree_size": 16, "t0": 0.6714, "t1": 0.2786, "tft": 2.4124, "input_0": 39, "input_1": 17, "min_CLP": -3.36, "draft_iters": 8.0, "mem_use": 41.56, "gen_rate": 5.0, "speed": 5.27, "text": "\"In that case, if you live in a "}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.5, "tree_w": 5, "tree_size": 16, "t0": 0.73, "t1": 0.2812, "tft": 1.1188, "input_0": 44, "input_1": 17, "min_CLP": -3.35, "draft_iters": 8.5, "mem_use": 40.83, "gen_rate": 4.8, "speed": 4.69, "text": "def generate_nicknames(num_nicks"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.78, "t1": 0.286, "tft": 1.8119, "input_0": 42, "input_1": 17, "min_CLP": -3.15, "draft_iters": 9.2, "mem_use": 41.24, "gen_rate": 7.0, "speed": 6.58, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.0467, "t1": 0.2867, "tft": 2.553, "input_0": 54, "input_1": 17, "min_CLP": -2.91, "draft_iters": 13.0, "mem_use": 41.99, "gen_rate": 11.3, "speed": 8.48, "text": "\"Canciones felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.2, "tree_w": 2, "tree_size": 16, "t0": 0.9875, "t1": 0.275, "tft": 1.1424, "input_0": 49, "input_1": 17, "min_CLP": -3.07, "draft_iters": 12.2, "mem_use": 40.93, "gen_rate": 9.5, "speed": 7.51, "text": "Here is a table of the average t"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 1.065, "t1": 0.285, "tft": 1.0637, "input_0": 53, "input_1": 17, "min_CLP": -3.22, "draft_iters": 13.0, "mem_use": 41.33, "gen_rate": 12.0, "speed": 8.87, "text": "\"Oh, sorry about that! Here's th"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 26, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.5491, "t1": 0.2845, "tft": 1.6772, "input_0": 32, "input_1": 17, "min_CLP": -3.58, "draft_iters": 6.5, "mem_use": 41.69, "gen_rate": 2.4, "speed": 2.85, "text": "Sure, how about: \"A wish is like"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 0.6933, "t1": 0.2833, "tft": 1.9965, "input_0": 45, "input_1": 17, "min_CLP": -3.12, "draft_iters": 8.3, "mem_use": 42.45, "gen_rate": 5.7, "speed": 5.79, "text": "\"Building a reinforcement learni"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 5, "tree_size": 16, "t0": 0.684, "t1": 0.276, "tft": 1.1458, "input_0": 46, "input_1": 17, "min_CLP": -3.19, "draft_iters": 8.0, "mem_use": 40.94, "gen_rate": 6.6, "speed": 6.87, "text": "Frank-Walter Steinmeier is a Ger"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.0, "tree_w": 3, "tree_size": 16, "t0": 1.0433, "t1": 0.2767, "tft": 1.2019, "input_0": 46, "input_1": 17, "min_CLP": -2.5, "draft_iters": 13.0, "mem_use": 40.86, "gen_rate": 11.7, "speed": 8.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.6587, "t1": 0.295, "tft": 3.6273, "input_0": 42, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.9, "mem_use": 44.99, "gen_rate": 4.0, "speed": 4.18, "text": "1. Discovery: Identify a market "}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.687, "t1": 0.276, "tft": 0.951, "input_0": 45, "input_1": 17, "min_CLP": -3.11, "draft_iters": 8.1, "mem_use": 40.76, "gen_rate": 3.3, "speed": 3.43, "text": "[INST] Please write a long answe"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.34, "t1": 0.27, "tft": 1.0493, "input_0": 57, "input_1": 17, "min_CLP": -1.91, "draft_iters": 17.0, "mem_use": 40.72, "gen_rate": 17.0, "speed": 10.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.755, "t1": 0.295, "tft": 3.6211, "input_0": 49, "input_1": 17, "min_CLP": -2.61, "draft_iters": 9.0, "mem_use": 44.98, "gen_rate": 4.5, "speed": 4.26, "text": "Hey there! How can I help you to"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6433, "t1": 0.2933, "tft": 2.4488, "input_0": 42, "input_1": 17, "min_CLP": -3.64, "draft_iters": 7.7, "mem_use": 42.78, "gen_rate": 5.7, "speed": 6.05, "text": "\"\u2022 Make it a part of your daily "}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.6387, "t1": 0.2938, "tft": 1.5671, "input_0": 39, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.6, "mem_use": 42.03, "gen_rate": 4.2, "speed": 4.55, "text": "You are correct in saying that t"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 7, "tree_size": 16, "t0": 0.5843, "t1": 0.2857, "tft": 1.6623, "input_0": 34, "input_1": 17, "min_CLP": -3.8, "draft_iters": 6.9, "mem_use": 40.91, "gen_rate": 4.6, "speed": 5.26, "text": "\"noted\\n[INST] What was the weat"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 0.6567, "t1": 0.2817, "tft": 1.1886, "input_0": 41, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.7, "mem_use": 40.93, "gen_rate": 5.5, "speed": 5.85, "text": "In the context of the turn-based"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.744, "t1": 0.29, "tft": 1.9125, "input_0": 44, "input_1": 17, "min_CLP": -3.23, "draft_iters": 9.0, "mem_use": 41.74, "gen_rate": 6.8, "speed": 6.6, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.6, "tree_w": 3, "tree_size": 16, "t0": 0.8825, "t1": 0.2963, "tft": 1.8985, "input_0": 51, "input_1": 17, "min_CLP": -2.64, "draft_iters": 10.6, "mem_use": 42.28, "gen_rate": 4.4, "speed": 3.72, "text": "Here is a simplified version of "}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.918, "t1": 0.29, "tft": 1.6003, "input_0": 53, "input_1": 17, "min_CLP": -3.31, "draft_iters": 11.0, "mem_use": 41.7, "gen_rate": 9.2, "speed": 7.61, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.36, "t1": 0.295, "tft": 1.7771, "input_0": 58, "input_1": 17, "min_CLP": -2.24, "draft_iters": 17.0, "mem_use": 41.8, "gen_rate": 17.0, "speed": 10.28, "text": "\"Of all the joys in life that I "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.6944, "t1": 0.2889, "tft": 1.332, "input_0": 40, "input_1": 17, "min_CLP": -3.38, "draft_iters": 8.2, "mem_use": 41.2, "gen_rate": 4.4, "speed": 4.52, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.6843, "t1": 0.2886, "tft": 1.7124, "input_0": 39, "input_1": 17, "min_CLP": -3.21, "draft_iters": 8.0, "mem_use": 41.16, "gen_rate": 5.1, "speed": 5.29, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.68, "t1": 0.295, "tft": 1.9508, "input_0": 42, "input_1": 17, "min_CLP": -3.02, "draft_iters": 8.1, "mem_use": 42.49, "gen_rate": 5.1, "speed": 5.26, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.65, "t1": 0.2957, "tft": 2.0659, "input_0": 42, "input_1": 17, "min_CLP": -3.03, "draft_iters": 7.7, "mem_use": 42.41, "gen_rate": 5.0, "speed": 5.29, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 3, "tree_size": 16, "t0": 0.8033, "t1": 0.3, "tft": 2.9666, "input_0": 46, "input_1": 17, "min_CLP": -3.01, "draft_iters": 9.7, "mem_use": 43.9, "gen_rate": 5.5, "speed": 5.0, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.37, "t1": 0.285, "tft": 1.0617, "input_0": 59, "input_1": 17, "min_CLP": -3.54, "draft_iters": 17.0, "mem_use": 40.72, "gen_rate": 17.0, "speed": 10.28, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.46, "t1": 0.29, "tft": 1.7767, "input_0": 32, "input_1": 17, "min_CLP": -3.72, "draft_iters": 5.2, "mem_use": 41.64, "gen_rate": 4.0, "speed": 5.34, "text": "\"PostCSS is a tool that transfor"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 3, "tree_size": 16, "t0": 0.7914, "t1": 0.2986, "tft": 2.6942, "input_0": 45, "input_1": 17, "min_CLP": -3.38, "draft_iters": 9.6, "mem_use": 43.55, "gen_rate": 5.0, "speed": 4.6, "text": "\"Hello! How can I assist you tod"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 0.81, "t1": 0.29, "tft": 1.1887, "input_0": 43, "input_1": 17, "min_CLP": -3.35, "draft_iters": 9.6, "mem_use": 41.23, "gen_rate": 5.2, "speed": 4.78, "text": "The contrarian nature of sufferi"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.6533, "t1": 0.2983, "tft": 1.8186, "input_0": 42, "input_1": 17, "min_CLP": -3.24, "draft_iters": 7.7, "mem_use": 42.09, "gen_rate": 5.8, "speed": 6.14, "text": "I apologize for any confusion. A"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 16, "max_branch_width": 32, "gen_rate": 5.99, "gen_rate_micro": 5.04, "gen_speed": 5.685, "gen_speed_micro": 5.362, "t0": 0.7175, "t1": 0.2854, "input_0": 42.5, "input_1": 17.0, "tree_size": 16.0, "tree_w": 4.1, "tree_h": 7.6, "prompt_len": 298.0, "min_CLP": -3.17, "mem_use": 50.17, "exp_time": 4405.61}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.7167, "t1": 0.2917, "tft": 1.2351, "input_0": 93, "input_1": 33, "min_CLP": -4.18, "draft_iters": 8.3, "mem_use": 40.81, "gen_rate": 5.3, "speed": 5.28, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.3, "tree_w": 6, "tree_size": 32, "t0": 1.185, "t1": 0.3083, "tft": 2.0645, "input_0": 102, "input_1": 33, "min_CLP": -3.78, "draft_iters": 14.3, "mem_use": 42.35, "gen_rate": 6.0, "speed": 4.01, "text": "You are correct that the fastest"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.6557, "t1": 0.3086, "tft": 2.5551, "input_0": 77, "input_1": 33, "min_CLP": -3.81, "draft_iters": 7.6, "mem_use": 43.28, "gen_rate": 4.6, "speed": 4.74, "text": "\"1. Minecraft: To stream Minecra"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 4, "tree_size": 32, "t0": 1.3967, "t1": 0.3, "tft": 1.1742, "input_0": 137, "input_1": 33, "min_CLP": -3.53, "draft_iters": 16.7, "mem_use": 40.99, "gen_rate": 11.3, "speed": 6.69, "text": "```python\\ndef average_rate_of_c"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.91, "t1": 0.298, "tft": 1.1389, "input_0": 98, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.6, "mem_use": 40.83, "gen_rate": 7.0, "speed": 5.81, "text": "Sure, I can give you some tips o"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 0.7043, "t1": 0.3086, "tft": 3.3335, "input_0": 97, "input_1": 33, "min_CLP": -3.8, "draft_iters": 8.1, "mem_use": 43.42, "gen_rate": 5.0, "speed": 4.93, "text": "1. Introduction: Define what the"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 5, "tree_size": 32, "t0": 1.124, "t1": 0.314, "tft": 3.2004, "input_0": 124, "input_1": 33, "min_CLP": -3.42, "draft_iters": 13.2, "mem_use": 44.0, "gen_rate": 6.4, "speed": 4.44, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.5, "tree_w": 5, "tree_size": 32, "t0": 0.9583, "t1": 0.32, "tft": 3.9491, "input_0": 101, "input_1": 33, "min_CLP": -3.56, "draft_iters": 11.5, "mem_use": 46.14, "gen_rate": 6.7, "speed": 5.21, "text": "To attract the right customers f"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 12.4, "tree_w": 5, "tree_size": 32, "t0": 1.118, "t1": 0.314, "tft": 3.1054, "input_0": 108, "input_1": 33, "min_CLP": -3.51, "draft_iters": 13.4, "mem_use": 43.61, "gen_rate": 9.0, "speed": 6.28, "text": "I apologize for any confusion, b"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 6, "tree_size": 32, "t0": 0.896, "t1": 0.302, "tft": 2.5154, "input_0": 114, "input_1": 33, "min_CLP": -3.74, "draft_iters": 10.6, "mem_use": 42.99, "gen_rate": 6.4, "speed": 5.34, "text": "There are many hobbies that are "}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.53, "t1": 0.31, "tft": 2.2947, "input_0": 140, "input_1": 33, "min_CLP": -3.14, "draft_iters": 32.0, "mem_use": 41.48, "gen_rate": 32.0, "speed": 11.28, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.0, "tree_w": 4, "tree_size": 32, "t0": 1.24, "t1": 0.3033, "tft": 2.6529, "input_0": 124, "input_1": 33, "min_CLP": -3.23, "draft_iters": 15.0, "mem_use": 43.36, "gen_rate": 11.3, "speed": 7.34, "text": "Here\\'s a condensed version of t"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.2, "tree_w": 4, "tree_size": 32, "t0": 1.255, "t1": 0.305, "tft": 2.2562, "input_0": 112, "input_1": 33, "min_CLP": -3.32, "draft_iters": 15.2, "mem_use": 42.54, "gen_rate": 10.0, "speed": 6.4, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.685, "t1": 0.295, "tft": 1.26, "input_0": 93, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.0, "mem_use": 40.81, "gen_rate": 3.0, "speed": 3.06, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 0.7614, "t1": 0.3157, "tft": 3.0004, "input_0": 97, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.6, "mem_use": 43.97, "gen_rate": 5.1, "speed": 4.77, "text": "\"If you're finding it challengin"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.6, "tree_w": 5, "tree_size": 32, "t0": 1.188, "t1": 0.29, "tft": 1.5436, "input_0": 103, "input_1": 33, "min_CLP": -3.55, "draft_iters": 14.6, "mem_use": 41.15, "gen_rate": 7.6, "speed": 5.14, "text": "\"To stream at 720p 30fps on Twit"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.4, "tree_w": 3, "tree_size": 32, "t0": 1.238, "t1": 0.29, "tft": 1.5, "input_0": 134, "input_1": 33, "min_CLP": -3.58, "draft_iters": 14.4, "mem_use": 40.83, "gen_rate": 8.2, "speed": 5.37, "text": "\"Sure, Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.47, "t1": 0.3, "tft": 1.0565, "input_0": 131, "input_1": 33, "min_CLP": -2.43, "draft_iters": 32.0, "mem_use": 40.81, "gen_rate": 33.0, "speed": 11.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 60, "tree_h": 29.0, "tree_w": 2, "tree_size": 32, "t0": 2.375, "t1": 0.305, "tft": 1.3888, "input_0": 136, "input_1": 33, "min_CLP": -2.85, "draft_iters": 30.0, "mem_use": 41.34, "gen_rate": 30.0, "speed": 11.18, "text": "D-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.0, "tree_w": 6, "tree_size": 32, "t0": 0.774, "t1": 0.294, "tft": 1.4513, "input_0": 92, "input_1": 33, "min_CLP": -4.07, "draft_iters": 9.0, "mem_use": 40.82, "gen_rate": 7.8, "speed": 7.3, "text": "The Balfour Declaration is a dec"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 14, "tree_h": 5.8, "tree_w": 16, "tree_size": 32, "t0": 0.585, "t1": 0.3, "tft": 1.7165, "input_0": 73, "input_1": 33, "min_CLP": -4.88, "draft_iters": 6.8, "mem_use": 41.66, "gen_rate": 2.3, "speed": 2.63, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 20.7, "tree_w": 5, "tree_size": 32, "t0": 1.6767, "t1": 0.2933, "tft": 1.1023, "input_0": 98, "input_1": 33, "min_CLP": -3.85, "draft_iters": 21.3, "mem_use": 40.81, "gen_rate": 14.0, "speed": 7.11, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 0.98, "t1": 0.3025, "tft": 2.6895, "input_0": 122, "input_1": 33, "min_CLP": -3.48, "draft_iters": 11.2, "mem_use": 43.2, "gen_rate": 8.5, "speed": 6.62, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.864, "t1": 0.298, "tft": 1.1655, "input_0": 106, "input_1": 33, "min_CLP": -3.75, "draft_iters": 10.0, "mem_use": 40.88, "gen_rate": 6.4, "speed": 5.51, "text": "\"Certainly! The process of gener"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.6657, "t1": 0.3, "tft": 2.1038, "input_0": 77, "input_1": 33, "min_CLP": -4.38, "draft_iters": 7.7, "mem_use": 41.85, "gen_rate": 5.4, "speed": 5.63, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.736, "t1": 0.294, "tft": 1.1227, "input_0": 89, "input_1": 33, "min_CLP": -3.98, "draft_iters": 8.6, "mem_use": 40.85, "gen_rate": 6.6, "speed": 6.4, "text": "\"Nietzsche's philosophy has had "}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.5844, "t1": 0.3011, "tft": 2.0105, "input_0": 80, "input_1": 33, "min_CLP": -4.12, "draft_iters": 6.8, "mem_use": 41.52, "gen_rate": 3.9, "speed": 4.38, "text": "Austenite is a form of iron allo"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 22, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.8383, "t1": 0.2983, "tft": 1.5493, "input_0": 97, "input_1": 33, "min_CLP": -3.87, "draft_iters": 10.0, "mem_use": 41.38, "gen_rate": 3.7, "speed": 3.22, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 18.0, "tree_w": 5, "tree_size": 32, "t0": 1.52, "t1": 0.31, "tft": 3.0329, "input_0": 96, "input_1": 33, "min_CLP": -4.15, "draft_iters": 19.0, "mem_use": 43.35, "gen_rate": 19.0, "speed": 10.39, "text": "\"La, la, la, la, la, la, la, la,"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 5, "tree_size": 32, "t0": 0.842, "t1": 0.296, "tft": 1.2075, "input_0": 104, "input_1": 33, "min_CLP": -4.09, "draft_iters": 9.8, "mem_use": 40.86, "gen_rate": 7.0, "speed": 6.15, "text": "The answer is: Some options of f"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 11.2, "tree_w": 5, "tree_size": 32, "t0": 1.045, "t1": 0.3025, "tft": 2.1472, "input_0": 118, "input_1": 33, "min_CLP": -3.25, "draft_iters": 12.2, "mem_use": 41.56, "gen_rate": 11.5, "speed": 8.53, "text": "\"Yes, that's correct. Into the B"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.2, "tree_w": 9, "tree_size": 32, "t0": 0.85, "t1": 0.3063, "tft": 1.7286, "input_0": 87, "input_1": 33, "min_CLP": -4.47, "draft_iters": 10.2, "mem_use": 41.97, "gen_rate": 4.1, "speed": 3.58, "text": "[Mathematical questions]: {How c"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 0.607, "t1": 0.299, "tft": 1.2911, "input_0": 73, "input_1": 33, "min_CLP": -4.46, "draft_iters": 7.1, "mem_use": 41.32, "gen_rate": 3.4, "speed": 3.76, "text": "In the name of Fjolnir, I hear y"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 7, "tree_size": 32, "t0": 0.8286, "t1": 0.3043, "tft": 3.8389, "input_0": 101, "input_1": 33, "min_CLP": -3.85, "draft_iters": 9.9, "mem_use": 43.01, "gen_rate": 5.0, "speed": 4.42, "text": "\"There are several plant-based a"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.71, "t1": 0.3017, "tft": 2.293, "input_0": 100, "input_1": 33, "min_CLP": -3.74, "draft_iters": 8.3, "mem_use": 43.05, "gen_rate": 5.7, "speed": 5.6, "text": "When choosing an ISP package, he"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.0, "tree_w": 4, "tree_size": 32, "t0": 1.0425, "t1": 0.33, "tft": 4.593, "input_0": 119, "input_1": 33, "min_CLP": -3.52, "draft_iters": 12.0, "mem_use": 45.74, "gen_rate": 8.8, "speed": 6.38, "text": "Selenium may be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.7567, "t1": 0.2917, "tft": 1.6631, "input_0": 100, "input_1": 33, "min_CLP": -4.02, "draft_iters": 8.7, "mem_use": 40.84, "gen_rate": 6.3, "speed": 6.04, "text": "\"The airspeed velocity of an unl"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 51, "tree_h": 7.7, "tree_w": 10, "tree_size": 32, "t0": 0.7371, "t1": 0.3, "tft": 2.4418, "input_0": 81, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.7, "mem_use": 41.37, "gen_rate": 7.3, "speed": 7.01, "text": "The second verse of \"Never Gonna"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 9.7, "tree_w": 8, "tree_size": 32, "t0": 0.8856, "t1": 0.3144, "tft": 3.9064, "input_0": 86, "input_1": 33, "min_CLP": -4.02, "draft_iters": 10.6, "mem_use": 43.77, "gen_rate": 4.3, "speed": 3.62, "text": "\"Of course, I'll try my best to "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 0.7363, "t1": 0.3, "tft": 2.0911, "input_0": 93, "input_1": 33, "min_CLP": -3.76, "draft_iters": 8.6, "mem_use": 41.77, "gen_rate": 4.8, "speed": 4.58, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.5278, "t1": 0.2967, "tft": 1.236, "input_0": 68, "input_1": 33, "min_CLP": -4.53, "draft_iters": 6.1, "mem_use": 41.07, "gen_rate": 3.8, "speed": 4.58, "text": "Freyja: Disgraceful mortal! You "}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.47, "t1": 0.31, "tft": 3.8558, "input_0": 117, "input_1": 33, "min_CLP": -2.88, "draft_iters": 32.0, "mem_use": 43.59, "gen_rate": 33.0, "speed": 11.87, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.49, "t1": 0.31, "tft": 3.2561, "input_0": 120, "input_1": 33, "min_CLP": -3.41, "draft_iters": 32.0, "mem_use": 44.02, "gen_rate": 32.0, "speed": 11.4, "text": "\"Certainly! It sounds like you a"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 1.0367, "t1": 0.3067, "tft": 2.1716, "input_0": 131, "input_1": 33, "min_CLP": -3.49, "draft_iters": 12.0, "mem_use": 42.34, "gen_rate": 10.7, "speed": 7.96, "text": "Choosing the \"best\" SAST tool de"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 1.09, "t1": 0.3, "tft": 2.2962, "input_0": 117, "input_1": 33, "min_CLP": -3.82, "draft_iters": 13.0, "mem_use": 41.6, "gen_rate": 7.0, "speed": 5.01, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 60, "tree_h": 29.0, "tree_w": 2, "tree_size": 32, "t0": 2.345, "t1": 0.305, "tft": 1.7254, "input_0": 145, "input_1": 33, "min_CLP": -3.91, "draft_iters": 29.5, "mem_use": 41.33, "gen_rate": 30.0, "speed": 11.34, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.2, "tree_w": 5, "tree_size": 32, "t0": 1.0175, "t1": 0.2925, "tft": 1.2038, "input_0": 104, "input_1": 33, "min_CLP": -3.71, "draft_iters": 12.2, "mem_use": 40.84, "gen_rate": 9.5, "speed": 7.27, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 13.4, "tree_w": 5, "tree_size": 32, "t0": 1.182, "t1": 0.328, "tft": 4.3609, "input_0": 107, "input_1": 33, "min_CLP": -3.79, "draft_iters": 14.4, "mem_use": 46.28, "gen_rate": 9.2, "speed": 6.11, "text": "\"Alright, I'll make the situatio"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.3, "tree_w": 14, "tree_size": 32, "t0": 0.46, "t1": 0.304, "tft": 1.8584, "input_0": 67, "input_1": 33, "min_CLP": -4.8, "draft_iters": 5.3, "mem_use": 42.58, "gen_rate": 3.6, "speed": 4.72, "text": "I saw it with my own eyes, the a"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.6, "tree_w": 13, "tree_size": 32, "t0": 0.4836, "t1": 0.2982, "tft": 1.3496, "input_0": 64, "input_1": 33, "min_CLP": -4.45, "draft_iters": 5.6, "mem_use": 41.6, "gen_rate": 2.9, "speed": 3.71, "text": "\"I hope you understand that I wa"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.785, "t1": 0.3, "tft": 1.3398, "input_0": 109, "input_1": 33, "min_CLP": -3.55, "draft_iters": 9.0, "mem_use": 41.12, "gen_rate": 8.0, "speed": 7.38, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 22.0, "tree_w": 3, "tree_size": 32, "t0": 1.795, "t1": 0.305, "tft": 2.5215, "input_0": 103, "input_1": 33, "min_CLP": -3.15, "draft_iters": 23.0, "mem_use": 43.05, "gen_rate": 16.5, "speed": 7.85, "text": "F-centers are crystallographic d"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 4, "tree_size": 32, "t0": 1.1625, "t1": 0.3075, "tft": 2.3598, "input_0": 128, "input_1": 33, "min_CLP": -3.63, "draft_iters": 14.0, "mem_use": 42.22, "gen_rate": 8.2, "speed": 5.6, "text": "In addition to the events I ment"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.7, "tree_w": 6, "tree_size": 32, "t0": 0.89, "t1": 0.31, "tft": 2.6824, "input_0": 97, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.7, "mem_use": 42.56, "gen_rate": 4.7, "speed": 3.94, "text": "Yes, you are correct. While tech"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.5944, "t1": 0.2967, "tft": 1.1012, "input_0": 77, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.0, "mem_use": 41.01, "gen_rate": 3.9, "speed": 4.37, "text": "\"In real life, people of all gen"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 10, "tree_size": 32, "t0": 0.7233, "t1": 0.31, "tft": 2.8745, "input_0": 88, "input_1": 33, "min_CLP": -4.19, "draft_iters": 8.3, "mem_use": 43.44, "gen_rate": 5.7, "speed": 5.47, "text": "Certainly! Here is a pitch deck "}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.6686, "t1": 0.3186, "tft": 3.9864, "input_0": 81, "input_1": 33, "min_CLP": -4.0, "draft_iters": 7.7, "mem_use": 44.67, "gen_rate": 4.3, "speed": 4.35, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.3, "tree_w": 8, "tree_size": 32, "t0": 0.8133, "t1": 0.3183, "tft": 3.8011, "input_0": 110, "input_1": 33, "min_CLP": -3.69, "draft_iters": 9.3, "mem_use": 44.84, "gen_rate": 6.0, "speed": 5.3, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 8, "tree_size": 32, "t0": 0.8643, "t1": 0.31, "tft": 2.5424, "input_0": 77, "input_1": 33, "min_CLP": -3.84, "draft_iters": 10.4, "mem_use": 42.49, "gen_rate": 5.0, "speed": 4.25, "text": "My response is based on the info"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.645, "t1": 0.2987, "tft": 1.0432, "input_0": 85, "input_1": 33, "min_CLP": -4.58, "draft_iters": 7.5, "mem_use": 40.83, "gen_rate": 4.4, "speed": 4.64, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.5, "tree_w": 5, "tree_size": 32, "t0": 1.1917, "t1": 0.31, "tft": 2.6331, "input_0": 98, "input_1": 33, "min_CLP": -3.64, "draft_iters": 14.5, "mem_use": 43.28, "gen_rate": 6.0, "speed": 4.0, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.9, "tree_w": 10, "tree_size": 32, "t0": 0.7389, "t1": 0.3156, "tft": 3.207, "input_0": 82, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.9, "mem_use": 44.11, "gen_rate": 3.7, "speed": 3.49, "text": "[The Spartan general leads his a"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 0.7, "t1": 0.3, "tft": 1.4635, "input_0": 79, "input_1": 33, "min_CLP": -3.85, "draft_iters": 8.1, "mem_use": 41.79, "gen_rate": 4.1, "speed": 4.11, "text": "\"I'm glad you liked it! It's alw"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 28, "tree_h": 14.0, "tree_w": 8, "tree_size": 32, "t0": 1.2125, "t1": 0.3, "tft": 1.5808, "input_0": 91, "input_1": 33, "min_CLP": -4.06, "draft_iters": 15.0, "mem_use": 41.5, "gen_rate": 7.0, "speed": 4.62, "text": "\"[INST] Please explain how we wo"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.56, "t1": 0.302, "tft": 1.6151, "input_0": 68, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.6, "mem_use": 41.63, "gen_rate": 3.2, "speed": 3.71, "text": "I mean that even if Hitler was s"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 0.6833, "t1": 0.3117, "tft": 3.1305, "input_0": 83, "input_1": 33, "min_CLP": -3.91, "draft_iters": 7.8, "mem_use": 43.72, "gen_rate": 5.3, "speed": 5.36, "text": "void pointers are pointers that "}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.6811, "t1": 0.3189, "tft": 2.9804, "input_0": 83, "input_1": 33, "min_CLP": -3.98, "draft_iters": 7.9, "mem_use": 44.23, "gen_rate": 4.1, "speed": 4.12, "text": "\"I'm really sorry to hear that y"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 5, "tree_size": 32, "t0": 0.9875, "t1": 0.31, "tft": 3.1055, "input_0": 104, "input_1": 33, "min_CLP": -3.62, "draft_iters": 11.8, "mem_use": 43.45, "gen_rate": 8.2, "speed": 6.35, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 0.775, "t1": 0.3, "tft": 1.5403, "input_0": 91, "input_1": 33, "min_CLP": -4.09, "draft_iters": 9.1, "mem_use": 41.25, "gen_rate": 2.9, "speed": 2.71, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.8017, "t1": 0.2933, "tft": 1.2313, "input_0": 102, "input_1": 33, "min_CLP": -4.0, "draft_iters": 9.2, "mem_use": 40.83, "gen_rate": 6.0, "speed": 5.49, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 19.7, "tree_w": 5, "tree_size": 32, "t0": 1.6733, "t1": 0.3133, "tft": 3.1916, "input_0": 131, "input_1": 33, "min_CLP": -3.47, "draft_iters": 20.7, "mem_use": 43.69, "gen_rate": 15.7, "speed": 7.87, "text": "\"Sure, here's the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.5938, "t1": 0.2962, "tft": 1.0562, "input_0": 74, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.8, "mem_use": 40.79, "gen_rate": 4.6, "speed": 5.2, "text": "Berlin was founded in the 13th c"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.5, "t1": 0.31, "tft": 2.4062, "input_0": 143, "input_1": 33, "min_CLP": -2.97, "draft_iters": 32.0, "mem_use": 43.15, "gen_rate": 33.0, "speed": 11.75, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 5, "tree_size": 32, "t0": 1.0425, "t1": 0.31, "tft": 2.7571, "input_0": 100, "input_1": 33, "min_CLP": -3.48, "draft_iters": 12.5, "mem_use": 43.02, "gen_rate": 8.5, "speed": 6.29, "text": "Sure, here are some of the criti"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 40, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.6173, "t1": 0.2982, "tft": 1.202, "input_0": 72, "input_1": 33, "min_CLP": -4.27, "draft_iters": 7.2, "mem_use": 40.81, "gen_rate": 3.6, "speed": 3.98, "text": "The production of pornography co"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.1, "tree_w": 8, "tree_size": 32, "t0": 0.9129, "t1": 0.2971, "tft": 2.6296, "input_0": 76, "input_1": 33, "min_CLP": -3.97, "draft_iters": 11.1, "mem_use": 41.12, "gen_rate": 5.3, "speed": 4.38, "text": "You can check your timezone on t"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.5838, "t1": 0.3, "tft": 1.3676, "input_0": 72, "input_1": 33, "min_CLP": -4.48, "draft_iters": 6.9, "mem_use": 41.2, "gen_rate": 4.2, "speed": 4.8, "text": "The 5 second rule is a myth. The"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.645, "t1": 0.295, "tft": 1.1557, "input_0": 76, "input_1": 33, "min_CLP": -4.18, "draft_iters": 7.8, "mem_use": 40.93, "gen_rate": 3.0, "speed": 3.18, "text": "12 - 2 - 5 = 5 eggs."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 14.8, "tree_w": 4, "tree_size": 32, "t0": 1.305, "t1": 0.3, "tft": 2.1891, "input_0": 129, "input_1": 33, "min_CLP": -3.53, "draft_iters": 15.8, "mem_use": 41.67, "gen_rate": 11.0, "speed": 6.84, "text": "Sure, here are some simple expla"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 4.8, "tree_w": 12, "tree_size": 32, "t0": 0.498, "t1": 0.302, "tft": 1.4973, "input_0": 73, "input_1": 33, "min_CLP": -4.44, "draft_iters": 5.8, "mem_use": 41.24, "gen_rate": 4.8, "speed": 6.02, "text": "\"It's always better to be safe t"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 4, "tree_size": 32, "t0": 1.1825, "t1": 0.2925, "tft": 1.4612, "input_0": 112, "input_1": 33, "min_CLP": -3.58, "draft_iters": 14.2, "mem_use": 40.95, "gen_rate": 8.5, "speed": 5.76, "text": "Sure! Here\\'s a draft announceme"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.736, "t1": 0.302, "tft": 2.0777, "input_0": 100, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.6, "mem_use": 41.57, "gen_rate": 6.6, "speed": 6.35, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 0.93, "t1": 0.308, "tft": 2.2848, "input_0": 117, "input_1": 33, "min_CLP": -3.52, "draft_iters": 11.0, "mem_use": 42.61, "gen_rate": 6.4, "speed": 5.17, "text": "Certainly! Here are some ways AI"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.6887, "t1": 0.3125, "tft": 2.7366, "input_0": 84, "input_1": 33, "min_CLP": -4.48, "draft_iters": 8.0, "mem_use": 43.65, "gen_rate": 5.0, "speed": 4.99, "text": "\"Certainly! Here's your rewritte"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.9, "tree_w": 7, "tree_size": 32, "t0": 0.7743, "t1": 0.3043, "tft": 1.8505, "input_0": 100, "input_1": 33, "min_CLP": -3.86, "draft_iters": 8.9, "mem_use": 42.12, "gen_rate": 5.6, "speed": 5.16, "text": "Yes, scp is a Unix-based command"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 28.3, "tree_w": 2, "tree_size": 32, "t0": 2.3267, "t1": 0.3067, "tft": 2.3969, "input_0": 165, "input_1": 33, "min_CLP": -3.52, "draft_iters": 29.3, "mem_use": 42.77, "gen_rate": 11.7, "speed": 4.43, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 0.7167, "t1": 0.3, "tft": 1.2795, "input_0": 87, "input_1": 33, "min_CLP": -4.12, "draft_iters": 8.3, "mem_use": 40.86, "gen_rate": 5.5, "speed": 5.42, "text": "The answer is: No, it would not "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 0.8275, "t1": 0.3, "tft": 1.5889, "input_0": 89, "input_1": 33, "min_CLP": -4.06, "draft_iters": 9.8, "mem_use": 41.15, "gen_rate": 8.2, "speed": 7.32, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7717, "t1": 0.3017, "tft": 1.7642, "input_0": 86, "input_1": 33, "min_CLP": -4.15, "draft_iters": 9.0, "mem_use": 41.45, "gen_rate": 5.3, "speed": 4.98, "text": "\"Thank you for explaining the fi"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 7.4, "tree_w": 11, "tree_size": 32, "t0": 0.7258, "t1": 0.2967, "tft": 1.2538, "input_0": 84, "input_1": 33, "min_CLP": -4.24, "draft_iters": 8.4, "mem_use": 41.12, "gen_rate": 2.9, "speed": 2.85, "text": "\"I'm glad you enjoyed it! If you"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 1, "tree_size": 32, "t0": 2.46, "t1": 0.3, "tft": 1.2755, "input_0": 136, "input_1": 33, "min_CLP": -2.65, "draft_iters": 31.0, "mem_use": 40.89, "gen_rate": 31.5, "speed": 11.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.75, "t1": 0.2978, "tft": 1.1477, "input_0": 84, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.7, "mem_use": 40.87, "gen_rate": 3.9, "speed": 3.71, "text": "The output should be in English "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 22.7, "tree_w": 2, "tree_size": 32, "t0": 1.96, "t1": 0.31, "tft": 2.4875, "input_0": 154, "input_1": 33, "min_CLP": -3.25, "draft_iters": 23.7, "mem_use": 42.61, "gen_rate": 12.3, "speed": 5.44, "text": "\"The solution to the Taniyama-Sh"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.0, "tree_w": 7, "tree_size": 32, "t0": 1.545, "t1": 0.3, "tft": 1.282, "input_0": 90, "input_1": 33, "min_CLP": -3.12, "draft_iters": 19.5, "mem_use": 40.87, "gen_rate": 17.5, "speed": 9.49, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.5, "tree_w": 6, "tree_size": 32, "t0": 1.16, "t1": 0.3, "tft": 1.1359, "input_0": 120, "input_1": 33, "min_CLP": -3.35, "draft_iters": 13.5, "mem_use": 41.18, "gen_rate": 8.0, "speed": 5.48, "text": "\"Here's an example of a basic fi"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.49, "t1": 0.3, "tft": 1.3947, "input_0": 113, "input_1": 33, "min_CLP": -1.98, "draft_iters": 32.0, "mem_use": 40.84, "gen_rate": 33.0, "speed": 11.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.6188, "t1": 0.3, "tft": 1.2879, "input_0": 70, "input_1": 33, "min_CLP": -4.48, "draft_iters": 7.2, "mem_use": 41.15, "gen_rate": 4.0, "speed": 4.36, "text": "In the path of the Jedi, one doe"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.6087, "t1": 0.2987, "tft": 1.4665, "input_0": 83, "input_1": 33, "min_CLP": -4.15, "draft_iters": 6.9, "mem_use": 41.01, "gen_rate": 4.0, "speed": 4.4, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 0.78, "t1": 0.3, "tft": 1.4342, "input_0": 97, "input_1": 33, "min_CLP": -4.2, "draft_iters": 8.8, "mem_use": 41.26, "gen_rate": 5.8, "speed": 5.39, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 7, "tree_size": 32, "t0": 0.7133, "t1": 0.315, "tft": 2.8912, "input_0": 86, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.3, "mem_use": 44.12, "gen_rate": 5.7, "speed": 5.52, "text": "Yes, there are several libraries"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7643, "t1": 0.3, "tft": 1.4656, "input_0": 86, "input_1": 33, "min_CLP": -4.01, "draft_iters": 9.0, "mem_use": 41.32, "gen_rate": 4.6, "speed": 4.29, "text": "Yes, it is generally considered "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 16, "tree_h": 6.5, "tree_w": 11, "tree_size": 32, "t0": 0.6425, "t1": 0.3125, "tft": 3.1505, "input_0": 80, "input_1": 33, "min_CLP": -4.42, "draft_iters": 7.5, "mem_use": 44.22, "gen_rate": 4.0, "speed": 4.21, "text": "Xin ch\u00e0o, t\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd \u1ea3o. "}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 10, "tree_size": 32, "t0": 0.6686, "t1": 0.3014, "tft": 1.7216, "input_0": 82, "input_1": 33, "min_CLP": -4.15, "draft_iters": 7.7, "mem_use": 41.68, "gen_rate": 4.9, "speed": 5.01, "text": "\"This is a good example of how m"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 17.0, "tree_w": 4, "tree_size": 32, "t0": 1.514, "t1": 0.3, "tft": 1.3957, "input_0": 133, "input_1": 33, "min_CLP": -3.17, "draft_iters": 18.0, "mem_use": 41.2, "gen_rate": 9.6, "speed": 5.29, "text": "Sure, here\\'s an example code sn"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.7257, "t1": 0.3057, "tft": 2.2177, "input_0": 88, "input_1": 33, "min_CLP": -3.9, "draft_iters": 8.6, "mem_use": 42.63, "gen_rate": 4.9, "speed": 4.71, "text": "Here is a list of the top 10 mos"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 9, "tree_size": 32, "t0": 0.6257, "t1": 0.3, "tft": 1.5079, "input_0": 80, "input_1": 33, "min_CLP": -4.55, "draft_iters": 7.3, "mem_use": 41.16, "gen_rate": 4.7, "speed": 5.09, "text": "\"To win a thumb war, you should "}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.2, "tree_w": 5, "tree_size": 32, "t0": 1.025, "t1": 0.3067, "tft": 2.8558, "input_0": 110, "input_1": 33, "min_CLP": -3.51, "draft_iters": 12.2, "mem_use": 43.21, "gen_rate": 6.8, "speed": 5.13, "text": "\"Sure, I'd be happy to offer som"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.5, "tree_w": 9, "tree_size": 32, "t0": 0.645, "t1": 0.3, "tft": 1.4841, "input_0": 79, "input_1": 33, "min_CLP": -4.28, "draft_iters": 7.5, "mem_use": 41.79, "gen_rate": 4.5, "speed": 4.75, "text": "\"As a language model, I don't ha"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 7, "tree_size": 32, "t0": 0.8767, "t1": 0.2983, "tft": 1.2322, "input_0": 102, "input_1": 33, "min_CLP": -3.78, "draft_iters": 10.3, "mem_use": 41.33, "gen_rate": 5.8, "speed": 4.96, "text": "[INST] Sure, I can help you with"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 7, "tree_size": 32, "t0": 1.024, "t1": 0.298, "tft": 1.8257, "input_0": 101, "input_1": 33, "min_CLP": -3.76, "draft_iters": 12.0, "mem_use": 41.47, "gen_rate": 6.8, "speed": 5.14, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.4, "tree_w": 18, "tree_size": 32, "t0": 0.54, "t1": 0.307, "tft": 2.4347, "input_0": 61, "input_1": 33, "min_CLP": -4.83, "draft_iters": 6.4, "mem_use": 42.74, "gen_rate": 3.3, "speed": 3.9, "text": "\"Here's a poem in Quenya to expr"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 0.842, "t1": 0.298, "tft": 1.1871, "input_0": 86, "input_1": 33, "min_CLP": -3.95, "draft_iters": 10.2, "mem_use": 40.84, "gen_rate": 6.8, "speed": 5.98, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.7011, "t1": 0.2967, "tft": 1.2422, "input_0": 91, "input_1": 33, "min_CLP": -3.86, "draft_iters": 8.0, "mem_use": 40.88, "gen_rate": 4.1, "speed": 4.13, "text": "\"The code you provided has a syn"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 17.5, "tree_w": 8, "tree_size": 32, "t0": 1.445, "t1": 0.305, "tft": 2.0528, "input_0": 72, "input_1": 33, "min_CLP": -3.54, "draft_iters": 18.5, "mem_use": 42.27, "gen_rate": 18.5, "speed": 10.57, "text": "Dear future me, hello. If you ar"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 0.82, "t1": 0.2957, "tft": 1.697, "input_0": 90, "input_1": 33, "min_CLP": -3.97, "draft_iters": 9.7, "mem_use": 41.49, "gen_rate": 4.7, "speed": 4.22, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.5, "tree_w": 4, "tree_size": 32, "t0": 1.3575, "t1": 0.3025, "tft": 1.6254, "input_0": 140, "input_1": 33, "min_CLP": -3.54, "draft_iters": 16.5, "mem_use": 41.62, "gen_rate": 8.0, "speed": 4.82, "text": "To create a program in Python th"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 0.6412, "t1": 0.3113, "tft": 2.6118, "input_0": 81, "input_1": 33, "min_CLP": -3.96, "draft_iters": 7.4, "mem_use": 43.43, "gen_rate": 4.1, "speed": 4.33, "text": "\"It's important to prioritize yo"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 19.5, "tree_w": 2, "tree_size": 32, "t0": 1.65, "t1": 0.3, "tft": 1.4641, "input_0": 142, "input_1": 33, "min_CLP": -3.12, "draft_iters": 20.5, "mem_use": 41.4, "gen_rate": 17.0, "speed": 8.69, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 17.3, "tree_w": 3, "tree_size": 32, "t0": 1.4717, "t1": 0.3083, "tft": 3.2788, "input_0": 118, "input_1": 33, "min_CLP": -3.12, "draft_iters": 18.3, "mem_use": 42.76, "gen_rate": 7.0, "speed": 3.94, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.7583, "t1": 0.295, "tft": 1.2244, "input_0": 87, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.8, "mem_use": 40.82, "gen_rate": 5.3, "speed": 5.06, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 16, "new_tokens": 32, "tree_h": 6.1, "tree_w": 15, "tree_size": 32, "t0": 0.5956, "t1": 0.3, "tft": 1.842, "input_0": 61, "input_1": 33, "min_CLP": -4.84, "draft_iters": 7.1, "mem_use": 41.05, "gen_rate": 2.0, "speed": 2.24, "text": "\"Attention mechanism,\\nA sophist"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.75, "t1": 0.3, "tft": 1.5222, "input_0": 102, "input_1": 33, "min_CLP": -3.85, "draft_iters": 8.5, "mem_use": 41.3, "gen_rate": 5.8, "speed": 5.57, "text": "\"Thank you! I'm just an AI langu"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.892, "t1": 0.31, "tft": 2.3727, "input_0": 88, "input_1": 33, "min_CLP": -4.11, "draft_iters": 10.6, "mem_use": 42.88, "gen_rate": 8.4, "speed": 7.01, "text": "Thou art the sun that doth shine"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 7.2, "tree_w": 10, "tree_size": 32, "t0": 0.703, "t1": 0.304, "tft": 1.6897, "input_0": 75, "input_1": 33, "min_CLP": -4.15, "draft_iters": 8.2, "mem_use": 41.47, "gen_rate": 3.2, "speed": 3.18, "text": "I apologize for not providing a "}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.0, "tree_w": 6, "tree_size": 32, "t0": 1.535, "t1": 0.305, "tft": 1.2822, "input_0": 95, "input_1": 33, "min_CLP": -3.34, "draft_iters": 19.5, "mem_use": 40.87, "gen_rate": 17.5, "speed": 9.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 1.008, "t1": 0.298, "tft": 1.2476, "input_0": 115, "input_1": 33, "min_CLP": -3.6, "draft_iters": 11.2, "mem_use": 40.85, "gen_rate": 7.4, "speed": 5.66, "text": "\"Sure, as an AI language model, "}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 7.1, "tree_w": 11, "tree_size": 32, "t0": 0.677, "t1": 0.3, "tft": 1.5284, "input_0": 73, "input_1": 33, "min_CLP": -4.18, "draft_iters": 8.1, "mem_use": 41.15, "gen_rate": 3.2, "speed": 3.28, "text": "True, feathers are not typically"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.7317, "t1": 0.305, "tft": 2.4567, "input_0": 84, "input_1": 33, "min_CLP": -3.89, "draft_iters": 8.5, "mem_use": 41.95, "gen_rate": 5.8, "speed": 5.62, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 28, "tree_h": 5.1, "tree_w": 10, "tree_size": 32, "t0": 0.5356, "t1": 0.3, "tft": 1.3373, "input_0": 67, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.1, "mem_use": 41.22, "gen_rate": 3.1, "speed": 3.72, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 22, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.635, "t1": 0.3, "tft": 1.3793, "input_0": 74, "input_1": 33, "min_CLP": -4.18, "draft_iters": 7.3, "mem_use": 41.3, "gen_rate": 3.7, "speed": 3.92, "text": "\"Certainly, I'll be known as Opi"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.2, "tree_w": 9, "tree_size": 32, "t0": 0.88, "t1": 0.2967, "tft": 1.3066, "input_0": 85, "input_1": 33, "min_CLP": -4.3, "draft_iters": 10.2, "mem_use": 40.85, "gen_rate": 5.5, "speed": 4.67, "text": "Yes, some people argue that the "}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.5, "tree_w": 14, "tree_size": 32, "t0": 0.481, "t1": 0.302, "tft": 1.6912, "input_0": 63, "input_1": 33, "min_CLP": -4.59, "draft_iters": 5.5, "mem_use": 41.53, "gen_rate": 3.3, "speed": 4.2, "text": "\"Like, chill dude. The dude\\'s j"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.4, "tree_w": 8, "tree_size": 32, "t0": 0.8187, "t1": 0.3, "tft": 1.0821, "input_0": 89, "input_1": 33, "min_CLP": -4.35, "draft_iters": 9.4, "mem_use": 40.96, "gen_rate": 4.4, "speed": 3.91, "text": "The mayonnaise has become runny "}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.7417, "t1": 0.3083, "tft": 1.9081, "input_0": 94, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.5, "mem_use": 42.19, "gen_rate": 6.2, "speed": 5.86, "text": "Certainly! Here are a few fictio"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.6, "tree_w": 10, "tree_size": 32, "t0": 0.584, "t1": 0.3, "tft": 1.3465, "input_0": 75, "input_1": 33, "min_CLP": -4.21, "draft_iters": 6.6, "mem_use": 41.29, "gen_rate": 3.4, "speed": 3.85, "text": "\"I'm not capable of taking over "}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 7, "tree_size": 32, "t0": 0.9117, "t1": 0.3083, "tft": 2.3632, "input_0": 114, "input_1": 33, "min_CLP": -3.59, "draft_iters": 10.5, "mem_use": 42.49, "gen_rate": 5.7, "speed": 4.64, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.0, "tree_w": 10, "tree_size": 32, "t0": 0.7775, "t1": 0.3012, "tft": 1.7379, "input_0": 85, "input_1": 33, "min_CLP": -4.71, "draft_iters": 9.0, "mem_use": 41.24, "gen_rate": 4.0, "speed": 3.71, "text": "\"Open Assistant: Open Source Cha"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.7037, "t1": 0.2987, "tft": 1.5091, "input_0": 83, "input_1": 33, "min_CLP": -3.79, "draft_iters": 8.0, "mem_use": 41.13, "gen_rate": 4.1, "speed": 4.11, "text": "\"Sure! Let's draw a simple famil"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 5, "tree_size": 32, "t0": 1.08, "t1": 0.3125, "tft": 2.6169, "input_0": 115, "input_1": 33, "min_CLP": -3.56, "draft_iters": 12.5, "mem_use": 43.5, "gen_rate": 8.0, "speed": 5.74, "text": "The reason your code does not co"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 6, "tree_size": 32, "t0": 0.94, "t1": 0.29, "tft": 1.0534, "input_0": 92, "input_1": 33, "min_CLP": -3.9, "draft_iters": 11.3, "mem_use": 40.83, "gen_rate": 5.5, "speed": 4.48, "text": "Yes, it is possible to compile P"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.51, "t1": 0.294, "tft": 1.3641, "input_0": 69, "input_1": 33, "min_CLP": -4.7, "draft_iters": 5.9, "mem_use": 41.38, "gen_rate": 3.7, "speed": 4.61, "text": "I agree that the answer was bias"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 7, "tree_size": 32, "t0": 0.7814, "t1": 0.2914, "tft": 1.6457, "input_0": 104, "input_1": 33, "min_CLP": -3.95, "draft_iters": 9.1, "mem_use": 41.01, "gen_rate": 4.7, "speed": 4.4, "text": "The heat from the pan causes the"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.2, "tree_w": 7, "tree_size": 32, "t0": 0.766, "t1": 0.29, "tft": 1.0408, "input_0": 89, "input_1": 33, "min_CLP": -3.88, "draft_iters": 9.2, "mem_use": 40.85, "gen_rate": 6.8, "speed": 6.46, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.7514, "t1": 0.3057, "tft": 2.5648, "input_0": 86, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.7, "mem_use": 42.93, "gen_rate": 4.6, "speed": 4.34, "text": "As an AI language model, I apolo"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 0.8836, "t1": 0.2936, "tft": 1.1874, "input_0": 100, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.4, "mem_use": 40.81, "gen_rate": 3.0, "speed": 2.55, "text": "Your task is to generate an appr"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 10, "tree_size": 32, "t0": 0.9133, "t1": 0.2983, "tft": 1.1374, "input_0": 68, "input_1": 33, "min_CLP": -4.21, "draft_iters": 11.0, "mem_use": 40.89, "gen_rate": 5.5, "speed": 4.53, "text": "The lyrics to the third verse of"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.7443, "t1": 0.3171, "tft": 3.0081, "input_0": 92, "input_1": 33, "min_CLP": -3.91, "draft_iters": 8.7, "mem_use": 44.18, "gen_rate": 5.0, "speed": 4.72, "text": "As of my last update in 2022, th"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 7, "tree_size": 32, "t0": 0.968, "t1": 0.308, "tft": 1.8548, "input_0": 97, "input_1": 33, "min_CLP": -3.74, "draft_iters": 11.4, "mem_use": 42.15, "gen_rate": 7.2, "speed": 5.65, "text": "I understand that you want me to"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.6, "tree_w": 6, "tree_size": 32, "t0": 0.896, "t1": 0.296, "tft": 1.1794, "input_0": 101, "input_1": 33, "min_CLP": -3.61, "draft_iters": 10.6, "mem_use": 41.1, "gen_rate": 7.8, "speed": 6.56, "text": "There are many resources availab"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.6, "tree_w": 8, "tree_size": 32, "t0": 0.896, "t1": 0.3, "tft": 1.2716, "input_0": 100, "input_1": 33, "min_CLP": -4.3, "draft_iters": 10.6, "mem_use": 41.08, "gen_rate": 7.2, "speed": 6.03, "text": "Here are some of the most effect"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 1.0225, "t1": 0.295, "tft": 1.0726, "input_0": 106, "input_1": 33, "min_CLP": -3.54, "draft_iters": 12.0, "mem_use": 40.85, "gen_rate": 8.2, "speed": 6.28, "text": "The theory of sexual selection w"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.6789, "t1": 0.2944, "tft": 2.0743, "input_0": 81, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.0, "mem_use": 41.66, "gen_rate": 3.9, "speed": 3.98, "text": "\"I apologize, but my previous re"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 18.8, "tree_w": 5, "tree_size": 32, "t0": 1.575, "t1": 0.2975, "tft": 2.8154, "input_0": 144, "input_1": 33, "min_CLP": -3.98, "draft_iters": 19.5, "mem_use": 41.68, "gen_rate": 14.2, "speed": 7.6, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 13.4, "tree_w": 4, "tree_size": 32, "t0": 1.182, "t1": 0.314, "tft": 4.5579, "input_0": 108, "input_1": 33, "min_CLP": -3.47, "draft_iters": 14.4, "mem_use": 44.2, "gen_rate": 8.6, "speed": 5.75, "text": "\"Certainly! Here's a shorter ver"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.2, "tree_w": 6, "tree_size": 32, "t0": 1.03, "t1": 0.295, "tft": 1.2088, "input_0": 99, "input_1": 33, "min_CLP": -3.83, "draft_iters": 12.2, "mem_use": 40.85, "gen_rate": 10.0, "speed": 7.53, "text": "\"To reduce your alcohol consumpt"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.5644, "t1": 0.2989, "tft": 1.2309, "input_0": 71, "input_1": 33, "min_CLP": -4.51, "draft_iters": 6.6, "mem_use": 41.41, "gen_rate": 3.9, "speed": 4.5, "text": "The city is home to the headquar"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.8, "tree_w": 4, "tree_size": 32, "t0": 1.454, "t1": 0.298, "tft": 1.2248, "input_0": 130, "input_1": 33, "min_CLP": -3.19, "draft_iters": 17.8, "mem_use": 40.89, "gen_rate": 6.8, "speed": 3.88, "text": "Here is an example Python script"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 21.0, "tree_w": 4, "tree_size": 32, "t0": 1.7233, "t1": 0.31, "tft": 3.5797, "input_0": 91, "input_1": 33, "min_CLP": -3.78, "draft_iters": 21.7, "mem_use": 43.42, "gen_rate": 17.7, "speed": 8.69, "text": "## Vegetarian\\n Microwave Tomato"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 20.0, "tree_w": 5, "tree_size": 32, "t0": 1.63, "t1": 0.295, "tft": 1.2136, "input_0": 98, "input_1": 33, "min_CLP": -3.24, "draft_iters": 20.5, "mem_use": 40.8, "gen_rate": 17.0, "speed": 8.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 6, "tree_size": 32, "t0": 1.1425, "t1": 0.3025, "tft": 2.4583, "input_0": 104, "input_1": 33, "min_CLP": -3.78, "draft_iters": 14.0, "mem_use": 43.1, "gen_rate": 8.8, "speed": 6.04, "text": "Here are the steps that could be"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 0.7514, "t1": 0.2914, "tft": 1.2315, "input_0": 87, "input_1": 33, "min_CLP": -3.91, "draft_iters": 8.7, "mem_use": 40.81, "gen_rate": 4.6, "speed": 4.38, "text": "The need for AI assistants has g"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.6717, "t1": 0.2933, "tft": 0.9444, "input_0": 82, "input_1": 33, "min_CLP": -4.11, "draft_iters": 7.8, "mem_use": 40.79, "gen_rate": 5.3, "speed": 5.53, "text": "The first step is to identify th"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 7, "tree_size": 32, "t0": 1.004, "t1": 0.29, "tft": 1.1448, "input_0": 108, "input_1": 33, "min_CLP": -3.68, "draft_iters": 12.0, "mem_use": 40.95, "gen_rate": 6.6, "speed": 5.1, "text": "Sure! One example of a complex p"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 0.8267, "t1": 0.3, "tft": 2.0302, "input_0": 108, "input_1": 33, "min_CLP": -3.76, "draft_iters": 9.7, "mem_use": 42.01, "gen_rate": 6.2, "speed": 5.48, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.8433, "t1": 0.2933, "tft": 1.2812, "input_0": 96, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.8, "mem_use": 40.91, "gen_rate": 5.3, "speed": 4.69, "text": "\"The reason why many people enjo"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.8, "tree_w": 8, "tree_size": 32, "t0": 0.91, "t1": 0.2967, "tft": 1.1978, "input_0": 83, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.8, "mem_use": 41.11, "gen_rate": 5.3, "speed": 4.42, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.9071, "t1": 0.3014, "tft": 2.0508, "input_0": 110, "input_1": 33, "min_CLP": -3.77, "draft_iters": 10.6, "mem_use": 41.45, "gen_rate": 5.6, "speed": 4.61, "text": "Selective fire refers to a firea"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.6633, "t1": 0.2967, "tft": 1.1668, "input_0": 89, "input_1": 33, "min_CLP": -4.21, "draft_iters": 7.5, "mem_use": 40.99, "gen_rate": 5.3, "speed": 5.57, "text": "\"I'm the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.4, "tree_w": 5, "tree_size": 32, "t0": 1.108, "t1": 0.304, "tft": 2.7296, "input_0": 105, "input_1": 33, "min_CLP": -3.52, "draft_iters": 13.4, "mem_use": 42.21, "gen_rate": 6.4, "speed": 4.53, "text": "\"To initialize a TypeScript proj"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.52, "t1": 0.29, "tft": 1.5005, "input_0": 144, "input_1": 33, "min_CLP": -3.1, "draft_iters": 32.0, "mem_use": 40.89, "gen_rate": 33.0, "speed": 11.72, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.902, "t1": 0.302, "tft": 2.1017, "input_0": 112, "input_1": 33, "min_CLP": -3.82, "draft_iters": 10.6, "mem_use": 41.73, "gen_rate": 6.4, "speed": 5.32, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.51, "t1": 0.3, "tft": 1.5388, "input_0": 134, "input_1": 33, "min_CLP": -2.57, "draft_iters": 32.0, "mem_use": 40.99, "gen_rate": 33.0, "speed": 11.72, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.7409, "t1": 0.2927, "tft": 1.2004, "input_0": 98, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.6, "mem_use": 40.82, "gen_rate": 3.2, "speed": 3.08, "text": "This task involves translating f"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.4, "tree_w": 7, "tree_size": 32, "t0": 0.7286, "t1": 0.32, "tft": 4.1077, "input_0": 89, "input_1": 33, "min_CLP": -3.83, "draft_iters": 8.4, "mem_use": 45.13, "gen_rate": 4.6, "speed": 4.36, "text": "\"If your friends are not happy w"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 2, "tree_size": 32, "t0": 2.5, "t1": 0.29, "tft": 1.2805, "input_0": 131, "input_1": 33, "min_CLP": -3.28, "draft_iters": 32.0, "mem_use": 41.13, "gen_rate": 32.0, "speed": 11.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.85, "t1": 0.306, "tft": 2.4021, "input_0": 88, "input_1": 33, "min_CLP": -3.64, "draft_iters": 10.0, "mem_use": 42.0, "gen_rate": 6.4, "speed": 5.53, "text": "To go around the world by boat a"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.7338, "t1": 0.3037, "tft": 2.7036, "input_0": 93, "input_1": 33, "min_CLP": -3.96, "draft_iters": 8.6, "mem_use": 43.29, "gen_rate": 4.4, "speed": 4.21, "text": "Yes, there are a few ways you ca"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 0.7, "t1": 0.2983, "tft": 1.2817, "input_0": 85, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.2, "mem_use": 41.11, "gen_rate": 5.7, "speed": 5.68, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.9, "tree_w": 8, "tree_size": 32, "t0": 0.7744, "t1": 0.2989, "tft": 1.2701, "input_0": 83, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.9, "mem_use": 41.15, "gen_rate": 3.7, "speed": 3.41, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 5, "tree_size": 32, "t0": 0.986, "t1": 0.296, "tft": 1.914, "input_0": 115, "input_1": 33, "min_CLP": -3.47, "draft_iters": 11.6, "mem_use": 41.62, "gen_rate": 7.4, "speed": 5.77, "text": "Sure, here are three 3D animatio"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.3, "tree_w": 5, "tree_size": 32, "t0": 1.3667, "t1": 0.2933, "tft": 1.182, "input_0": 106, "input_1": 33, "min_CLP": -3.93, "draft_iters": 17.0, "mem_use": 41.13, "gen_rate": 13.7, "speed": 8.22, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 9, "tree_size": 32, "t0": 0.6475, "t1": 0.2963, "tft": 1.6932, "input_0": 79, "input_1": 33, "min_CLP": -4.08, "draft_iters": 7.5, "mem_use": 41.81, "gen_rate": 4.1, "speed": 4.35, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 11, "tree_size": 32, "t0": 0.6462, "t1": 0.2975, "tft": 1.2101, "input_0": 81, "input_1": 33, "min_CLP": -4.16, "draft_iters": 7.6, "mem_use": 41.15, "gen_rate": 4.0, "speed": 4.24, "text": "\"Sure, here's a simple Braille s"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 0.944, "t1": 0.298, "tft": 1.1286, "input_0": 106, "input_1": 33, "min_CLP": -3.99, "draft_iters": 10.8, "mem_use": 40.87, "gen_rate": 7.8, "speed": 6.29, "text": "Reinforcement learning is a type"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 17.0, "tree_w": 4, "tree_size": 32, "t0": 1.4533, "t1": 0.2933, "tft": 1.2052, "input_0": 116, "input_1": 33, "min_CLP": -3.24, "draft_iters": 18.0, "mem_use": 40.83, "gen_rate": 13.0, "speed": 7.43, "text": "Detailed Instructions: Given a s"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 1.01, "t1": 0.32, "tft": 3.7379, "input_0": 99, "input_1": 33, "min_CLP": -4.13, "draft_iters": 12.0, "mem_use": 45.11, "gen_rate": 8.7, "speed": 6.51, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 0.8267, "t1": 0.2967, "tft": 1.518, "input_0": 103, "input_1": 33, "min_CLP": -4.14, "draft_iters": 9.7, "mem_use": 40.97, "gen_rate": 4.7, "speed": 4.15, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.7933, "t1": 0.3067, "tft": 2.3383, "input_0": 106, "input_1": 33, "min_CLP": -3.84, "draft_iters": 9.2, "mem_use": 42.5, "gen_rate": 6.2, "speed": 5.62, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.8357, "t1": 0.3, "tft": 2.2007, "input_0": 103, "input_1": 33, "min_CLP": -3.67, "draft_iters": 10.0, "mem_use": 42.26, "gen_rate": 5.3, "speed": 4.66, "text": "In option 2, using the Command P"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 20.0, "tree_w": 4, "tree_size": 32, "t0": 1.66, "t1": 0.295, "tft": 2.1545, "input_0": 106, "input_1": 33, "min_CLP": -3.26, "draft_iters": 21.0, "mem_use": 41.1, "gen_rate": 17.0, "speed": 8.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 27.5, "tree_w": 3, "tree_size": 32, "t0": 2.23, "t1": 0.3, "tft": 1.5158, "input_0": 122, "input_1": 33, "min_CLP": -2.81, "draft_iters": 28.0, "mem_use": 40.92, "gen_rate": 17.5, "speed": 6.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 18.5, "tree_w": 5, "tree_size": 32, "t0": 1.55, "t1": 0.29, "tft": 1.2193, "input_0": 105, "input_1": 33, "min_CLP": -3.49, "draft_iters": 19.5, "mem_use": 40.89, "gen_rate": 16.5, "speed": 8.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 6, "tree_size": 32, "t0": 1.002, "t1": 0.304, "tft": 1.9894, "input_0": 111, "input_1": 33, "min_CLP": -3.64, "draft_iters": 11.6, "mem_use": 41.89, "gen_rate": 7.4, "speed": 5.67, "text": "\"I'm happy to help you improve y"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 5, "tree_h": 5.3, "tree_w": 10, "tree_size": 32, "t0": 0.5433, "t1": 0.2933, "tft": 1.2856, "input_0": 72, "input_1": 33, "min_CLP": -4.31, "draft_iters": 6.3, "mem_use": 41.22, "gen_rate": 1.7, "speed": 1.99, "text": "\"Ok, let's start!\""}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 11.2, "tree_w": 6, "tree_size": 32, "t0": 1.0156, "t1": 0.3056, "tft": 3.9739, "input_0": 97, "input_1": 33, "min_CLP": -3.96, "draft_iters": 12.2, "mem_use": 42.54, "gen_rate": 4.2, "speed": 3.19, "text": "meliss\u00eb, noun lover (fem.)\\nmeld"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 6, "tree_size": 32, "t0": 1.0425, "t1": 0.2975, "tft": 1.5902, "input_0": 92, "input_1": 33, "min_CLP": -4.05, "draft_iters": 12.5, "mem_use": 41.46, "gen_rate": 8.0, "speed": 5.97, "text": "I think one can draw no conclusi"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.7, "tree_w": 9, "tree_size": 32, "t0": 0.9814, "t1": 0.2971, "tft": 2.2666, "input_0": 91, "input_1": 33, "min_CLP": -4.08, "draft_iters": 11.7, "mem_use": 41.3, "gen_rate": 4.9, "speed": 3.79, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 0.884, "t1": 0.294, "tft": 1.2415, "input_0": 115, "input_1": 33, "min_CLP": -3.55, "draft_iters": 10.2, "mem_use": 41.04, "gen_rate": 7.8, "speed": 6.62, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 11.5, "tree_w": 6, "tree_size": 32, "t0": 1.0175, "t1": 0.3113, "tft": 4.7699, "input_0": 103, "input_1": 33, "min_CLP": -3.75, "draft_iters": 12.5, "mem_use": 43.86, "gen_rate": 4.4, "speed": 3.29, "text": "\"Certainly, here's an alternate "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.3, "tree_w": 10, "tree_size": 32, "t0": 0.7122, "t1": 0.3111, "tft": 4.3022, "input_0": 81, "input_1": 33, "min_CLP": -4.28, "draft_iters": 8.3, "mem_use": 43.79, "gen_rate": 4.1, "speed": 4.02, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.7471, "t1": 0.2929, "tft": 0.9706, "input_0": 88, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.7, "mem_use": 40.83, "gen_rate": 4.7, "speed": 4.54, "text": "\"Sure, I can do that! Here's a p"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 15.5, "tree_w": 5, "tree_size": 32, "t0": 1.3425, "t1": 0.3025, "tft": 1.6921, "input_0": 118, "input_1": 33, "min_CLP": -3.6, "draft_iters": 16.5, "mem_use": 41.99, "gen_rate": 11.8, "speed": 7.15, "text": "Certainly, I would be happy to a"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 10.4, "tree_w": 8, "tree_size": 32, "t0": 0.9513, "t1": 0.3075, "tft": 2.2232, "input_0": 98, "input_1": 33, "min_CLP": -3.88, "draft_iters": 11.4, "mem_use": 42.44, "gen_rate": 4.8, "speed": 3.78, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.0, "tree_w": 5, "tree_size": 32, "t0": 1.3225, "t1": 0.295, "tft": 1.0391, "input_0": 122, "input_1": 33, "min_CLP": -3.64, "draft_iters": 16.0, "mem_use": 40.81, "gen_rate": 8.5, "speed": 5.26, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 6.4, "tree_w": 12, "tree_size": 32, "t0": 0.6236, "t1": 0.2982, "tft": 1.0993, "input_0": 65, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.4, "mem_use": 41.11, "gen_rate": 3.1, "speed": 3.35, "text": "\"I will not submit to your comma"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 6, "tree_size": 32, "t0": 0.865, "t1": 0.31, "tft": 2.6732, "input_0": 91, "input_1": 33, "min_CLP": -3.73, "draft_iters": 10.5, "mem_use": 42.69, "gen_rate": 8.2, "speed": 7.02, "text": "\"No, this is not true. Hershey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.775, "t1": 0.2983, "tft": 1.1108, "input_0": 99, "input_1": 33, "min_CLP": -3.97, "draft_iters": 9.0, "mem_use": 41.05, "gen_rate": 6.2, "speed": 5.76, "text": "\"The ability to host a large lea"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7683, "t1": 0.3017, "tft": 2.1052, "input_0": 98, "input_1": 33, "min_CLP": -3.82, "draft_iters": 9.0, "mem_use": 42.39, "gen_rate": 5.7, "speed": 5.31, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.8525, "t1": 0.2875, "tft": 1.0368, "input_0": 107, "input_1": 33, "min_CLP": -3.98, "draft_iters": 10.0, "mem_use": 40.85, "gen_rate": 8.0, "speed": 7.01, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 13.6, "tree_w": 5, "tree_size": 32, "t0": 1.22, "t1": 0.294, "tft": 1.2154, "input_0": 128, "input_1": 33, "min_CLP": -3.51, "draft_iters": 14.6, "mem_use": 40.85, "gen_rate": 8.8, "speed": 5.82, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 9.1, "tree_w": 8, "tree_size": 32, "t0": 0.8543, "t1": 0.2986, "tft": 1.3701, "input_0": 96, "input_1": 33, "min_CLP": -3.91, "draft_iters": 10.1, "mem_use": 41.5, "gen_rate": 5.9, "speed": 5.08, "text": "\"Alright, I'll do both.\\nHere's "}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 11, "tree_size": 32, "t0": 0.6538, "t1": 0.2988, "tft": 1.4796, "input_0": 76, "input_1": 33, "min_CLP": -4.15, "draft_iters": 7.6, "mem_use": 41.73, "gen_rate": 4.0, "speed": 4.2, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 26, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.7567, "t1": 0.29, "tft": 1.2137, "input_0": 93, "input_1": 33, "min_CLP": -4.11, "draft_iters": 8.8, "mem_use": 40.83, "gen_rate": 4.3, "speed": 4.14, "text": "The AK-47 is a type of assault r"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 10.1, "tree_w": 6, "tree_size": 32, "t0": 0.9311, "t1": 0.2956, "tft": 1.4939, "input_0": 105, "input_1": 33, "min_CLP": -3.66, "draft_iters": 11.1, "mem_use": 41.18, "gen_rate": 3.6, "speed": 2.9, "text": "\"Here's an example using the `rs"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 21.5, "tree_w": 2, "tree_size": 32, "t0": 1.83, "t1": 0.305, "tft": 2.3473, "input_0": 149, "input_1": 33, "min_CLP": -3.45, "draft_iters": 22.5, "mem_use": 42.56, "gen_rate": 17.0, "speed": 7.96, "text": "1. Statistical modeling is the a"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 0.875, "t1": 0.29, "tft": 1.2626, "input_0": 105, "input_1": 33, "min_CLP": -3.89, "draft_iters": 10.2, "mem_use": 41.16, "gen_rate": 8.2, "speed": 7.1, "text": "To create a successful gaming so"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 0.76, "t1": 0.2986, "tft": 2.2514, "input_0": 90, "input_1": 33, "min_CLP": -3.78, "draft_iters": 8.7, "mem_use": 41.66, "gen_rate": 5.0, "speed": 4.73, "text": "\"While there's no harm in lettin"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 6.0, "tree_w": 13, "tree_size": 32, "t0": 0.5873, "t1": 0.2945, "tft": 1.9269, "input_0": 61, "input_1": 33, "min_CLP": -4.54, "draft_iters": 7.0, "mem_use": 41.31, "gen_rate": 3.1, "speed": 3.51, "text": "Tell them about something funny "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 40, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.7191, "t1": 0.2973, "tft": 1.4581, "input_0": 90, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.4, "mem_use": 41.41, "gen_rate": 3.6, "speed": 3.58, "text": " [TEACHER] Please write a functi"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.6089, "t1": 0.2956, "tft": 1.0361, "input_0": 82, "input_1": 33, "min_CLP": -4.44, "draft_iters": 7.0, "mem_use": 40.82, "gen_rate": 4.2, "speed": 4.67, "text": "\"I am thinking about how I can a"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.6775, "t1": 0.29, "tft": 1.8908, "input_0": 85, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.8, "mem_use": 40.82, "gen_rate": 4.2, "speed": 4.38, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 4, "tree_size": 32, "t0": 2.165, "t1": 0.3, "tft": 1.4918, "input_0": 131, "input_1": 33, "min_CLP": -3.75, "draft_iters": 27.0, "mem_use": 41.36, "gen_rate": 27.0, "speed": 10.96, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.1, "tree_w": 6, "tree_size": 32, "t0": 0.9443, "t1": 0.2986, "tft": 1.1236, "input_0": 100, "input_1": 33, "min_CLP": -3.71, "draft_iters": 11.1, "mem_use": 41.12, "gen_rate": 5.3, "speed": 4.26, "text": "Sure! Below is an example of HTM"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 0.886, "t1": 0.292, "tft": 1.815, "input_0": 99, "input_1": 33, "min_CLP": -3.92, "draft_iters": 10.4, "mem_use": 40.91, "gen_rate": 8.2, "speed": 6.96, "text": "\"To rewrite the phone conversati"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.9, "tree_w": 10, "tree_size": 32, "t0": 0.6686, "t1": 0.2957, "tft": 1.2821, "input_0": 73, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.9, "mem_use": 40.88, "gen_rate": 4.7, "speed": 4.89, "text": "\"The stars are there, but it's h"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 0.706, "t1": 0.3, "tft": 1.5364, "input_0": 85, "input_1": 33, "min_CLP": -4.11, "draft_iters": 8.3, "mem_use": 41.44, "gen_rate": 3.4, "speed": 3.38, "text": "The significance of the Windows "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.7, "tree_w": 8, "tree_size": 32, "t0": 0.6633, "t1": 0.3133, "tft": 3.3461, "input_0": 77, "input_1": 33, "min_CLP": -3.96, "draft_iters": 7.7, "mem_use": 44.5, "gen_rate": 6.0, "speed": 6.13, "text": "\"It is not a good idea to use yo"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 9, "tree_size": 32, "t0": 0.7467, "t1": 0.31, "tft": 2.4971, "input_0": 95, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.8, "mem_use": 43.26, "gen_rate": 5.7, "speed": 5.37, "text": "\"I apologize for any confusion. "}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.605, "t1": 0.2988, "tft": 2.645, "input_0": 84, "input_1": 33, "min_CLP": -4.1, "draft_iters": 6.9, "mem_use": 41.5, "gen_rate": 4.2, "speed": 4.71, "text": "Building a Dyson Sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.52, "t1": 0.3, "tft": 1.2183, "input_0": 131, "input_1": 33, "min_CLP": -3.38, "draft_iters": 32.0, "mem_use": 40.83, "gen_rate": 33.0, "speed": 11.71, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.3, "tree_w": 7, "tree_size": 32, "t0": 0.7229, "t1": 0.2929, "tft": 1.3624, "input_0": 86, "input_1": 33, "min_CLP": -4.09, "draft_iters": 8.3, "mem_use": 40.82, "gen_rate": 4.7, "speed": 4.63, "text": "Yes, I can speak German to a cer"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 23.0, "tree_w": 6, "tree_size": 32, "t0": 1.85, "t1": 0.3, "tft": 1.1727, "input_0": 80, "input_1": 33, "min_CLP": -4.05, "draft_iters": 24.0, "mem_use": 41.02, "gen_rate": 23.0, "speed": 10.69, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.8367, "t1": 0.3017, "tft": 1.8294, "input_0": 102, "input_1": 33, "min_CLP": -3.72, "draft_iters": 9.8, "mem_use": 41.9, "gen_rate": 6.5, "speed": 5.72, "text": "To determine the number of acces"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.7443, "t1": 0.3071, "tft": 2.5756, "input_0": 99, "input_1": 33, "min_CLP": -3.78, "draft_iters": 8.6, "mem_use": 42.49, "gen_rate": 5.1, "speed": 4.91, "text": "\"Yes, AI image generators like S"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 10, "tree_size": 32, "t0": 0.6983, "t1": 0.2967, "tft": 1.2989, "input_0": 82, "input_1": 33, "min_CLP": -4.33, "draft_iters": 8.2, "mem_use": 40.88, "gen_rate": 5.5, "speed": 5.54, "text": "Sure, here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 15.3, "tree_w": 6, "tree_size": 32, "t0": 1.3233, "t1": 0.3, "tft": 1.4977, "input_0": 89, "input_1": 33, "min_CLP": -4.22, "draft_iters": 16.3, "mem_use": 41.24, "gen_rate": 12.3, "speed": 7.61, "text": "o\\n     /|\\\\\\n     / \\\\\\n     |\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 18.5, "tree_w": 6, "tree_size": 32, "t0": 1.555, "t1": 0.29, "tft": 1.2051, "input_0": 109, "input_1": 33, "min_CLP": -3.22, "draft_iters": 19.5, "mem_use": 40.83, "gen_rate": 17.0, "speed": 9.21, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.4, "tree_w": 6, "tree_size": 32, "t0": 1.096, "t1": 0.3, "tft": 1.2676, "input_0": 89, "input_1": 33, "min_CLP": -3.82, "draft_iters": 13.4, "mem_use": 41.19, "gen_rate": 7.0, "speed": 5.01, "text": "\"Yes, there is a true, most ethi"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.2, "tree_w": 7, "tree_size": 32, "t0": 0.7133, "t1": 0.2967, "tft": 1.2425, "input_0": 96, "input_1": 33, "min_CLP": -3.72, "draft_iters": 8.2, "mem_use": 41.11, "gen_rate": 6.0, "speed": 5.94, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.67, "t1": 0.305, "tft": 2.3815, "input_0": 76, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.0, "mem_use": 43.19, "gen_rate": 5.3, "speed": 5.48, "text": "\"Alright, let's get started. Her"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 8.5, "tree_w": 19, "tree_size": 32, "t0": 0.7675, "t1": 0.3, "tft": 0.9907, "input_0": 53, "input_1": 33, "min_CLP": -4.72, "draft_iters": 9.5, "mem_use": 40.99, "gen_rate": 8.5, "speed": 7.98, "text": "```\\n                /\\\\\\n      "}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.7625, "t1": 0.31, "tft": 3.194, "input_0": 96, "input_1": 33, "min_CLP": -3.9, "draft_iters": 9.0, "mem_use": 43.88, "gen_rate": 8.2, "speed": 7.7, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 8, "tree_size": 32, "t0": 0.7957, "t1": 0.2914, "tft": 1.1258, "input_0": 82, "input_1": 33, "min_CLP": -4.04, "draft_iters": 9.6, "mem_use": 40.86, "gen_rate": 4.9, "speed": 4.47, "text": "\"Sure, here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 0.93, "t1": 0.288, "tft": 1.1249, "input_0": 94, "input_1": 33, "min_CLP": -3.63, "draft_iters": 11.2, "mem_use": 40.82, "gen_rate": 9.0, "speed": 7.41, "text": "HTML and JavaScript are two diff"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.2, "tree_w": 4, "tree_size": 32, "t0": 1.2525, "t1": 0.2925, "tft": 1.2675, "input_0": 113, "input_1": 33, "min_CLP": -3.17, "draft_iters": 15.2, "mem_use": 40.85, "gen_rate": 8.0, "speed": 5.17, "text": "Sure, here is a table with the p"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.2, "tree_w": 11, "tree_size": 32, "t0": 0.615, "t1": 0.299, "tft": 1.386, "input_0": 72, "input_1": 33, "min_CLP": -4.38, "draft_iters": 7.2, "mem_use": 41.22, "gen_rate": 3.4, "speed": 3.72, "text": "\"Charles O'Rear holds the copyri"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 15, "tree_size": 32, "t0": 0.6771, "t1": 0.2957, "tft": 1.0627, "input_0": 74, "input_1": 33, "min_CLP": -4.42, "draft_iters": 8.0, "mem_use": 40.83, "gen_rate": 4.6, "speed": 4.7, "text": "\"Detailed Instructions: You are "}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 6, "tree_size": 32, "t0": 1.035, "t1": 0.3, "tft": 2.9777, "input_0": 114, "input_1": 33, "min_CLP": -3.4, "draft_iters": 12.2, "mem_use": 41.89, "gen_rate": 8.0, "speed": 5.97, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.8, "tree_w": 11, "tree_size": 32, "t0": 0.506, "t1": 0.298, "tft": 3.3061, "input_0": 67, "input_1": 33, "min_CLP": -4.22, "draft_iters": 5.8, "mem_use": 41.6, "gen_rate": 3.2, "speed": 3.97, "text": "In that case, I would recommend "}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.6189, "t1": 0.2989, "tft": 1.8292, "input_0": 74, "input_1": 33, "min_CLP": -4.21, "draft_iters": 7.3, "mem_use": 41.45, "gen_rate": 3.8, "speed": 4.12, "text": "\"Yes, that's correct. If everyon"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.5275, "t1": 0.3088, "tft": 1.6332, "input_0": 74, "input_1": 33, "min_CLP": -4.34, "draft_iters": 6.0, "mem_use": 42.17, "gen_rate": 4.2, "speed": 5.09, "text": "Thank you for the guidance. I wi"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.765, "t1": 0.29, "tft": 1.0484, "input_0": 84, "input_1": 33, "min_CLP": -4.0, "draft_iters": 9.2, "mem_use": 40.81, "gen_rate": 6.0, "speed": 5.7, "text": "Sure, here is an ASCII art of a "}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.6917, "t1": 0.29, "tft": 1.2642, "input_0": 96, "input_1": 33, "min_CLP": -4.03, "draft_iters": 8.0, "mem_use": 41.13, "gen_rate": 5.5, "speed": 5.6, "text": "\"Of course! Here are some of the"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.1, "tree_w": 7, "tree_size": 32, "t0": 0.8486, "t1": 0.2986, "tft": 2.0013, "input_0": 95, "input_1": 33, "min_CLP": -3.91, "draft_iters": 10.1, "mem_use": 41.87, "gen_rate": 4.7, "speed": 4.09, "text": "\"The James Webb Space Telescope "}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.5333, "t1": 0.2933, "tft": 1.418, "input_0": 72, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.1, "mem_use": 40.93, "gen_rate": 3.9, "speed": 4.7, "text": "\"Motion matching is a way to mak"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.5, "tree_w": 3, "tree_size": 32, "t0": 1.76, "t1": 0.31, "tft": 2.8644, "input_0": 117, "input_1": 33, "min_CLP": -2.7, "draft_iters": 22.0, "mem_use": 42.55, "gen_rate": 19.5, "speed": 9.44, "text": "\"Sure, here's the modified scrip"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.49, "t1": 0.3, "tft": 1.1307, "input_0": 109, "input_1": 33, "min_CLP": -2.86, "draft_iters": 32.0, "mem_use": 40.88, "gen_rate": 33.0, "speed": 11.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 7, "tree_size": 32, "t0": 0.938, "t1": 0.296, "tft": 1.2739, "input_0": 99, "input_1": 33, "min_CLP": -4.14, "draft_iters": 11.2, "mem_use": 41.26, "gen_rate": 6.4, "speed": 5.19, "text": "Sure, here\\'s a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.6, "tree_w": 6, "tree_size": 32, "t0": 0.962, "t1": 0.306, "tft": 2.7718, "input_0": 96, "input_1": 33, "min_CLP": -3.87, "draft_iters": 11.6, "mem_use": 42.56, "gen_rate": 7.2, "speed": 5.68, "text": "The concept of 100 monkeys on a "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 7, "tree_size": 32, "t0": 0.682, "t1": 0.3, "tft": 2.4344, "input_0": 85, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.0, "mem_use": 43.04, "gen_rate": 6.6, "speed": 6.71, "text": "Paul Allen has a collection of o"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.73, "t1": 0.3, "tft": 2.3731, "input_0": 87, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.7, "mem_use": 42.44, "gen_rate": 5.7, "speed": 5.51, "text": "Yes, there is a similar case in "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.7, "tree_w": 7, "tree_size": 32, "t0": 0.8867, "t1": 0.2933, "tft": 1.1205, "input_0": 81, "input_1": 33, "min_CLP": -4.1, "draft_iters": 10.7, "mem_use": 40.91, "gen_rate": 5.3, "speed": 4.54, "text": "Romeo is a character who is deep"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.675, "t1": 0.295, "tft": 1.7373, "input_0": 84, "input_1": 33, "min_CLP": -3.96, "draft_iters": 8.0, "mem_use": 41.53, "gen_rate": 6.0, "speed": 6.18, "text": "\"As a machine learning model, I "}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 7, "tree_size": 32, "t0": 1.07, "t1": 0.29, "tft": 1.2951, "input_0": 112, "input_1": 33, "min_CLP": -3.91, "draft_iters": 13.0, "mem_use": 40.94, "gen_rate": 10.7, "speed": 7.84, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.7129, "t1": 0.29, "tft": 1.2776, "input_0": 93, "input_1": 33, "min_CLP": -4.12, "draft_iters": 8.3, "mem_use": 40.82, "gen_rate": 5.9, "speed": 5.84, "text": "Yes, the 5 second rule actually "}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.5, "tree_w": 7, "tree_size": 32, "t0": 1.175, "t1": 0.295, "tft": 1.696, "input_0": 103, "input_1": 33, "min_CLP": -3.95, "draft_iters": 14.5, "mem_use": 41.66, "gen_rate": 5.5, "speed": 3.74, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.9, "tree_w": 8, "tree_size": 32, "t0": 0.6686, "t1": 0.3014, "tft": 2.0563, "input_0": 97, "input_1": 33, "min_CLP": -3.89, "draft_iters": 7.9, "mem_use": 42.47, "gen_rate": 5.4, "speed": 5.59, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 9, "tree_size": 32, "t0": 0.7543, "t1": 0.3071, "tft": 2.5854, "input_0": 96, "input_1": 33, "min_CLP": -4.02, "draft_iters": 8.9, "mem_use": 43.4, "gen_rate": 4.7, "speed": 4.44, "text": "Oh, you\\'re talking about the \"m"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 0.862, "t1": 0.296, "tft": 2.1833, "input_0": 102, "input_1": 33, "min_CLP": -3.66, "draft_iters": 10.0, "mem_use": 41.97, "gen_rate": 6.8, "speed": 5.86, "text": "\"It is theoretically possible to"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.48, "t1": 0.31, "tft": 3.5661, "input_0": 142, "input_1": 33, "min_CLP": -3.2, "draft_iters": 32.0, "mem_use": 41.8, "gen_rate": 33.0, "speed": 11.84, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 46, "tree_h": 12.9, "tree_w": 6, "tree_size": 32, "t0": 1.1529, "t1": 0.3, "tft": 1.9766, "input_0": 99, "input_1": 33, "min_CLP": -3.93, "draft_iters": 13.9, "mem_use": 41.58, "gen_rate": 6.6, "speed": 4.52, "text": "In Japanese, \"love\" can be expre"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.4, "tree_w": 11, "tree_size": 32, "t0": 0.555, "t1": 0.296, "tft": 1.6347, "input_0": 75, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.4, "mem_use": 41.11, "gen_rate": 3.2, "speed": 3.76, "text": "In Europe, the Netherlands is kn"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 6, "tree_size": 32, "t0": 0.776, "t1": 0.294, "tft": 1.2248, "input_0": 90, "input_1": 33, "min_CLP": -3.68, "draft_iters": 9.2, "mem_use": 40.81, "gen_rate": 7.2, "speed": 6.75, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 14.7, "tree_w": 5, "tree_size": 32, "t0": 1.3143, "t1": 0.2971, "tft": 1.1348, "input_0": 107, "input_1": 33, "min_CLP": -3.72, "draft_iters": 15.7, "mem_use": 40.94, "gen_rate": 5.1, "speed": 3.2, "text": "\"Here's a simple example of a C+"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.1, "tree_w": 8, "tree_size": 32, "t0": 0.8471, "t1": 0.3014, "tft": 1.9871, "input_0": 89, "input_1": 33, "min_CLP": -4.11, "draft_iters": 10.1, "mem_use": 42.07, "gen_rate": 5.0, "speed": 4.36, "text": "1. Financial stress: \\n- Develop"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 10, "tree_size": 32, "t0": 0.6967, "t1": 0.29, "tft": 1.1066, "input_0": 90, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.2, "mem_use": 40.81, "gen_rate": 5.3, "speed": 5.41, "text": "As an AI language model, I don\\'"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.7, "tree_w": 6, "tree_size": 32, "t0": 1.0467, "t1": 0.31, "tft": 3.3223, "input_0": 103, "input_1": 33, "min_CLP": -3.21, "draft_iters": 12.7, "mem_use": 43.5, "gen_rate": 11.3, "speed": 8.36, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 0.965, "t1": 0.2975, "tft": 1.6628, "input_0": 125, "input_1": 33, "min_CLP": -4.3, "draft_iters": 11.2, "mem_use": 41.09, "gen_rate": 8.5, "speed": 6.76, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.1, "tree_w": 12, "tree_size": 32, "t0": 0.61, "t1": 0.2933, "tft": 1.1562, "input_0": 71, "input_1": 33, "min_CLP": -4.81, "draft_iters": 7.1, "mem_use": 40.88, "gen_rate": 3.6, "speed": 3.95, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 0.872, "t1": 0.298, "tft": 2.569, "input_0": 99, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.4, "mem_use": 43.1, "gen_rate": 6.8, "speed": 5.79, "text": "Here are some open-source AI too"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.0, "tree_w": 3, "tree_size": 32, "t0": 1.3933, "t1": 0.2967, "tft": 1.3083, "input_0": 120, "input_1": 33, "min_CLP": -3.5, "draft_iters": 17.0, "mem_use": 40.88, "gen_rate": 11.3, "speed": 6.7, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 10, "tree_h": 6.0, "tree_w": 15, "tree_size": 32, "t0": 0.5875, "t1": 0.2975, "tft": 1.9977, "input_0": 59, "input_1": 33, "min_CLP": -4.43, "draft_iters": 7.0, "mem_use": 41.58, "gen_rate": 2.5, "speed": 2.82, "text": "Again, no. \\n\\nThe same basic pr"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 16.6, "tree_w": 5, "tree_size": 32, "t0": 1.4, "t1": 0.3063, "tft": 2.0519, "input_0": 96, "input_1": 33, "min_CLP": -3.49, "draft_iters": 17.5, "mem_use": 42.45, "gen_rate": 4.0, "speed": 2.34, "text": "1. m\u00eb (suffix): pronounced as \"m"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.585, "t1": 0.295, "tft": 1.2725, "input_0": 72, "input_1": 33, "min_CLP": -4.21, "draft_iters": 6.8, "mem_use": 41.13, "gen_rate": 5.5, "speed": 6.26, "text": "As an AI language model, my prim"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 13.2, "tree_w": 5, "tree_size": 32, "t0": 1.155, "t1": 0.3117, "tft": 2.836, "input_0": 103, "input_1": 33, "min_CLP": -3.86, "draft_iters": 14.2, "mem_use": 43.91, "gen_rate": 7.2, "speed": 4.88, "text": "I apologize for the incorrect in"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.1, "tree_w": 8, "tree_size": 32, "t0": 0.77, "t1": 0.2925, "tft": 1.064, "input_0": 80, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.1, "mem_use": 40.84, "gen_rate": 4.2, "speed": 3.99, "text": "\"In reStructuredText (rst), URLs"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 1.098, "t1": 0.3, "tft": 2.9564, "input_0": 124, "input_1": 33, "min_CLP": -3.41, "draft_iters": 13.0, "mem_use": 42.84, "gen_rate": 8.6, "speed": 6.15, "text": "\"Here's a simple example code us"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.9038, "t1": 0.295, "tft": 1.1041, "input_0": 97, "input_1": 33, "min_CLP": -3.91, "draft_iters": 10.6, "mem_use": 40.82, "gen_rate": 5.0, "speed": 4.17, "text": "This task involves identifying t"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 12, "tree_size": 32, "t0": 0.56, "t1": 0.2975, "tft": 1.375, "input_0": 70, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.5, "mem_use": 41.28, "gen_rate": 4.4, "speed": 5.1, "text": "Yes, but not immediately. As AI "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.7638, "t1": 0.3225, "tft": 5.225, "input_0": 86, "input_1": 33, "min_CLP": -4.25, "draft_iters": 9.2, "mem_use": 46.43, "gen_rate": 4.5, "speed": 4.14, "text": "\"Yes, I'd be happy to help. Here"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 8.4, "tree_w": 9, "tree_size": 32, "t0": 0.7729, "t1": 0.2971, "tft": 1.5308, "input_0": 79, "input_1": 33, "min_CLP": -4.65, "draft_iters": 9.4, "mem_use": 41.65, "gen_rate": 5.9, "speed": 5.46, "text": "0 an independent counsel is a la"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.615, "t1": 0.305, "tft": 2.727, "input_0": 80, "input_1": 33, "min_CLP": -4.09, "draft_iters": 7.2, "mem_use": 43.53, "gen_rate": 4.2, "speed": 4.61, "text": "I apologize if my previous respo"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 0.6343, "t1": 0.2957, "tft": 2.7496, "input_0": 85, "input_1": 33, "min_CLP": -4.04, "draft_iters": 7.4, "mem_use": 41.87, "gen_rate": 4.6, "speed": 4.91, "text": "1. Economic downturn: If there h"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.5, "t1": 0.3, "tft": 1.3352, "input_0": 128, "input_1": 33, "min_CLP": -2.98, "draft_iters": 32.0, "mem_use": 41.15, "gen_rate": 33.0, "speed": 11.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 6, "tree_size": 32, "t0": 1.042, "t1": 0.304, "tft": 3.4217, "input_0": 107, "input_1": 33, "min_CLP": -4.07, "draft_iters": 12.6, "mem_use": 43.65, "gen_rate": 7.0, "speed": 5.2, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.73, "t1": 0.2914, "tft": 1.3887, "input_0": 90, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.6, "mem_use": 41.34, "gen_rate": 4.9, "speed": 4.75, "text": "To determine the most cost-effec"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.0, "tree_w": 5, "tree_size": 32, "t0": 1.1825, "t1": 0.31, "tft": 2.7147, "input_0": 137, "input_1": 33, "min_CLP": -3.44, "draft_iters": 14.0, "mem_use": 43.33, "gen_rate": 8.5, "speed": 5.7, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 9.1, "tree_w": 8, "tree_size": 32, "t0": 0.8575, "t1": 0.29, "tft": 1.0406, "input_0": 93, "input_1": 33, "min_CLP": -4.06, "draft_iters": 10.1, "mem_use": 40.86, "gen_rate": 4.8, "speed": 4.14, "text": "```lean\\nnamespace Timsort\\nopen"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 0.782, "t1": 0.298, "tft": 1.5905, "input_0": 82, "input_1": 33, "min_CLP": -4.27, "draft_iters": 9.2, "mem_use": 41.58, "gen_rate": 6.8, "speed": 6.29, "text": "The law was created in 2019.\\n[I"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 6, "tree_size": 32, "t0": 0.7917, "t1": 0.29, "tft": 1.2771, "input_0": 89, "input_1": 33, "min_CLP": -3.76, "draft_iters": 9.5, "mem_use": 41.31, "gen_rate": 5.5, "speed": 5.09, "text": "To alleviate your symptoms of na"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 0.8688, "t1": 0.2863, "tft": 1.2966, "input_0": 97, "input_1": 33, "min_CLP": -3.73, "draft_iters": 10.4, "mem_use": 40.9, "gen_rate": 4.4, "speed": 3.78, "text": "Here is a simple implementation "}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 0.92, "t1": 0.2975, "tft": 1.7735, "input_0": 97, "input_1": 33, "min_CLP": -3.92, "draft_iters": 11.0, "mem_use": 41.79, "gen_rate": 8.2, "speed": 6.78, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 59, "tree_h": 21.3, "tree_w": 3, "tree_size": 32, "t0": 1.7733, "t1": 0.31, "tft": 2.8384, "input_0": 116, "input_1": 33, "min_CLP": -3.7, "draft_iters": 22.0, "mem_use": 43.41, "gen_rate": 19.7, "speed": 9.44, "text": "Sure! Here is a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 0.9475, "t1": 0.295, "tft": 1.1622, "input_0": 104, "input_1": 33, "min_CLP": -4.18, "draft_iters": 11.0, "mem_use": 41.02, "gen_rate": 9.0, "speed": 7.26, "text": "The total travel time is the sum"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 14.6, "tree_w": 5, "tree_size": 32, "t0": 1.282, "t1": 0.292, "tft": 1.1652, "input_0": 121, "input_1": 33, "min_CLP": -3.63, "draft_iters": 15.6, "mem_use": 40.93, "gen_rate": 10.2, "speed": 6.48, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 10, "tree_h": 12.0, "tree_w": 6, "tree_size": 32, "t0": 1.03, "t1": 0.29, "tft": 1.2139, "input_0": 87, "input_1": 33, "min_CLP": -4.24, "draft_iters": 13.0, "mem_use": 40.82, "gen_rate": 10.0, "speed": 7.57, "text": "Yes, I am as capable as ChatGPT."}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.774, "t1": 0.31, "tft": 3.5446, "input_0": 93, "input_1": 33, "min_CLP": -3.98, "draft_iters": 9.0, "mem_use": 44.6, "gen_rate": 6.4, "speed": 5.91, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 28, "tree_h": 28.0, "tree_w": 3, "tree_size": 32, "t0": 2.22, "t1": 0.29, "tft": 1.4301, "input_0": 97, "input_1": 33, "min_CLP": -3.76, "draft_iters": 29.0, "mem_use": 40.94, "gen_rate": 28.0, "speed": 11.16, "text": "\"Mike's mother had four kids. Th"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 10.7, "tree_w": 8, "tree_size": 32, "t0": 0.9417, "t1": 0.295, "tft": 1.4361, "input_0": 80, "input_1": 33, "min_CLP": -4.33, "draft_iters": 11.7, "mem_use": 41.97, "gen_rate": 7.2, "speed": 5.79, "text": "The amount of experience points "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 0.7229, "t1": 0.3086, "tft": 3.2337, "input_0": 95, "input_1": 33, "min_CLP": -3.72, "draft_iters": 8.6, "mem_use": 43.77, "gen_rate": 5.0, "speed": 4.84, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.6656, "t1": 0.29, "tft": 1.3228, "input_0": 76, "input_1": 33, "min_CLP": -4.03, "draft_iters": 7.9, "mem_use": 41.07, "gen_rate": 3.8, "speed": 3.96, "text": "\"As an AI language model, I cann"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 25, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 0.8233, "t1": 0.3011, "tft": 1.6754, "input_0": 91, "input_1": 33, "min_CLP": -3.95, "draft_iters": 9.8, "mem_use": 41.58, "gen_rate": 2.8, "speed": 2.47, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 4, "tree_size": 32, "t0": 1.105, "t1": 0.305, "tft": 3.1047, "input_0": 117, "input_1": 33, "min_CLP": -3.52, "draft_iters": 13.2, "mem_use": 43.34, "gen_rate": 8.8, "speed": 6.2, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 5, "tree_size": 32, "t0": 1.1025, "t1": 0.2975, "tft": 1.8453, "input_0": 123, "input_1": 33, "min_CLP": -3.92, "draft_iters": 12.8, "mem_use": 41.71, "gen_rate": 8.0, "speed": 5.7, "text": "The television was invented by P"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.0, "tree_w": 7, "tree_size": 32, "t0": 0.9883, "t1": 0.3133, "tft": 2.9278, "input_0": 94, "input_1": 33, "min_CLP": -3.69, "draft_iters": 12.0, "mem_use": 44.05, "gen_rate": 6.0, "speed": 4.61, "text": "\"I'm glad to hear that you found"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.7529, "t1": 0.3086, "tft": 2.3616, "input_0": 93, "input_1": 33, "min_CLP": -3.84, "draft_iters": 8.7, "mem_use": 42.36, "gen_rate": 5.3, "speed": 4.99, "text": "There are multiple days in which"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.605, "t1": 0.3, "tft": 1.2421, "input_0": 80, "input_1": 33, "min_CLP": -4.34, "draft_iters": 7.0, "mem_use": 41.39, "gen_rate": 4.0, "speed": 4.42, "text": "Understood. I am an AI, but I am"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.84, "t1": 0.305, "tft": 2.6835, "input_0": 95, "input_1": 33, "min_CLP": -3.79, "draft_iters": 10.0, "mem_use": 43.22, "gen_rate": 8.2, "speed": 7.19, "text": "One of the most difficult parts "}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 6, "tree_size": 32, "t0": 1.04, "t1": 0.298, "tft": 1.1914, "input_0": 103, "input_1": 33, "min_CLP": -3.69, "draft_iters": 12.6, "mem_use": 41.01, "gen_rate": 7.0, "speed": 5.24, "text": "Yes, it is possible to own an op"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 20, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.83, "t1": 0.3, "tft": 1.7865, "input_0": 79, "input_1": 33, "min_CLP": -4.32, "draft_iters": 10.0, "mem_use": 41.64, "gen_rate": 2.9, "speed": 2.53, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 5.8, "tree_w": 12, "tree_size": 32, "t0": 0.5782, "t1": 0.2955, "tft": 2.0924, "input_0": 68, "input_1": 33, "min_CLP": -4.57, "draft_iters": 6.8, "mem_use": 41.11, "gen_rate": 3.3, "speed": 3.75, "text": "\"[INST] Alright, let's try a dif"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 5, "tree_size": 32, "t0": 0.9033, "t1": 0.2933, "tft": 1.2198, "input_0": 95, "input_1": 33, "min_CLP": -3.52, "draft_iters": 10.7, "mem_use": 41.12, "gen_rate": 5.7, "speed": 4.74, "text": "The distance from the Earth to S"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.5487, "t1": 0.2987, "tft": 2.0458, "input_0": 72, "input_1": 33, "min_CLP": -4.41, "draft_iters": 6.1, "mem_use": 41.51, "gen_rate": 4.2, "speed": 5.03, "text": "Google Authenticator is a 2FA ap"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 0.906, "t1": 0.298, "tft": 1.7434, "input_0": 97, "input_1": 33, "min_CLP": -4.02, "draft_iters": 10.8, "mem_use": 41.29, "gen_rate": 6.4, "speed": 5.32, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 7, "tree_size": 32, "t0": 0.9925, "t1": 0.2925, "tft": 1.1785, "input_0": 111, "input_1": 33, "min_CLP": -3.52, "draft_iters": 11.8, "mem_use": 41.05, "gen_rate": 8.5, "speed": 6.6, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.864, "t1": 0.296, "tft": 1.5086, "input_0": 106, "input_1": 33, "min_CLP": -4.11, "draft_iters": 10.0, "mem_use": 40.91, "gen_rate": 7.4, "speed": 6.38, "text": "To improve your Wi-Fi coverage i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 13.0, "tree_w": 8, "tree_size": 32, "t0": 1.118, "t1": 0.29, "tft": 1.2186, "input_0": 84, "input_1": 33, "min_CLP": -3.85, "draft_iters": 14.0, "mem_use": 40.94, "gen_rate": 10.0, "speed": 7.1, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 0.82, "t1": 0.2917, "tft": 1.0863, "input_0": 101, "input_1": 33, "min_CLP": -3.72, "draft_iters": 9.8, "mem_use": 40.85, "gen_rate": 5.7, "speed": 5.09, "text": "Here is a draft whitepaper for K"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.5, "tree_w": 5, "tree_size": 32, "t0": 0.9733, "t1": 0.3017, "tft": 1.8719, "input_0": 99, "input_1": 33, "min_CLP": -3.64, "draft_iters": 11.5, "mem_use": 42.03, "gen_rate": 6.7, "speed": 5.22, "text": "You can use the `scp` command vi"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.6857, "t1": 0.2929, "tft": 1.1202, "input_0": 82, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.0, "mem_use": 40.81, "gen_rate": 5.1, "speed": 5.27, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.808, "t1": 0.29, "tft": 1.3007, "input_0": 96, "input_1": 33, "min_CLP": -3.92, "draft_iters": 9.6, "mem_use": 40.82, "gen_rate": 6.6, "speed": 6.02, "text": "I think ChatGPT is a remarkable "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.6514, "t1": 0.2929, "tft": 1.1029, "input_0": 74, "input_1": 33, "min_CLP": -4.12, "draft_iters": 7.7, "mem_use": 41.13, "gen_rate": 5.3, "speed": 5.59, "text": "\"As an AI language model, I cann"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 12, "tree_size": 32, "t0": 0.6614, "t1": 0.2957, "tft": 1.1068, "input_0": 85, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.7, "mem_use": 40.86, "gen_rate": 4.7, "speed": 4.93, "text": "\"Hello, Malbolge program!\\n\\nI'm"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 6, "tree_size": 32, "t0": 1.775, "t1": 0.3, "tft": 1.6567, "input_0": 124, "input_1": 33, "min_CLP": -3.68, "draft_iters": 22.5, "mem_use": 41.56, "gen_rate": 23.0, "speed": 11.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 25.0, "tree_w": 2, "tree_size": 32, "t0": 2.02, "t1": 0.315, "tft": 3.0507, "input_0": 141, "input_1": 33, "min_CLP": -4.04, "draft_iters": 25.5, "mem_use": 44.08, "gen_rate": 25.5, "speed": 10.93, "text": "The current date is 2023-02-06.\\"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 6, "tree_size": 32, "t0": 0.8925, "t1": 0.3, "tft": 1.4857, "input_0": 105, "input_1": 33, "min_CLP": -3.81, "draft_iters": 10.5, "mem_use": 41.37, "gen_rate": 8.2, "speed": 6.9, "text": "Yes, there are things that decor"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 5.5, "tree_w": 12, "tree_size": 32, "t0": 0.57, "t1": 0.305, "tft": 2.0942, "input_0": 84, "input_1": 33, "min_CLP": -4.29, "draft_iters": 6.5, "mem_use": 42.48, "gen_rate": 4.0, "speed": 4.6, "text": "Hello! How may I assist you toda"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 12, "tree_size": 32, "t0": 0.7183, "t1": 0.3, "tft": 2.1311, "input_0": 69, "input_1": 33, "min_CLP": -4.46, "draft_iters": 8.7, "mem_use": 41.36, "gen_rate": 5.5, "speed": 5.4, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 9.7, "tree_w": 6, "tree_size": 32, "t0": 0.9033, "t1": 0.3156, "tft": 3.7294, "input_0": 103, "input_1": 33, "min_CLP": -3.68, "draft_iters": 10.7, "mem_use": 44.26, "gen_rate": 4.0, "speed": 3.29, "text": "Sure, here are some simple code "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 0.9983, "t1": 0.36, "tft": 7.1235, "input_0": 113, "input_1": 33, "min_CLP": -3.58, "draft_iters": 12.0, "mem_use": 50.26, "gen_rate": 5.8, "speed": 4.29, "text": "\"Sure, here's some example code "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 0.866, "t1": 0.3, "tft": 2.7156, "input_0": 95, "input_1": 33, "min_CLP": -3.69, "draft_iters": 10.4, "mem_use": 42.59, "gen_rate": 9.4, "speed": 8.07, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 6, "tree_size": 32, "t0": 0.945, "t1": 0.3, "tft": 1.2162, "input_0": 107, "input_1": 33, "min_CLP": -3.76, "draft_iters": 11.0, "mem_use": 40.87, "gen_rate": 9.2, "speed": 7.45, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 16.4, "tree_w": 5, "tree_size": 32, "t0": 1.4129, "t1": 0.2914, "tft": 1.1706, "input_0": 103, "input_1": 33, "min_CLP": -3.44, "draft_iters": 17.4, "mem_use": 40.98, "gen_rate": 5.3, "speed": 3.1, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.6957, "t1": 0.3114, "tft": 2.9423, "input_0": 82, "input_1": 33, "min_CLP": -3.96, "draft_iters": 8.3, "mem_use": 43.78, "gen_rate": 4.6, "speed": 4.53, "text": "Sure, I can help you brainstorm "}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 0.91, "t1": 0.2925, "tft": 1.1334, "input_0": 97, "input_1": 33, "min_CLP": -4.0, "draft_iters": 10.8, "mem_use": 40.92, "gen_rate": 9.0, "speed": 7.47, "text": "In 1950, the world was vastly di"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 5, "tree_size": 32, "t0": 0.96, "t1": 0.325, "tft": 4.0842, "input_0": 113, "input_1": 33, "min_CLP": -3.65, "draft_iters": 11.3, "mem_use": 45.92, "gen_rate": 5.7, "speed": 4.42, "text": "Creating your own stable diffusi"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.822, "t1": 0.296, "tft": 1.1374, "input_0": 84, "input_1": 33, "min_CLP": -4.23, "draft_iters": 10.0, "mem_use": 41.27, "gen_rate": 7.2, "speed": 6.45, "text": "1. Install the power supply unit"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7662, "t1": 0.295, "tft": 1.1987, "input_0": 88, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.0, "mem_use": 41.11, "gen_rate": 4.0, "speed": 3.77, "text": "\"Carnegie Mellon's Robotics Inst"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.0, "tree_w": 16, "tree_size": 32, "t0": 0.432, "t1": 0.295, "tft": 1.1958, "input_0": 52, "input_1": 33, "min_CLP": -4.66, "draft_iters": 5.0, "mem_use": 41.18, "gen_rate": 3.4, "speed": 4.67, "text": "I have no idea. I can only imagi"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 8, "tree_size": 32, "t0": 0.888, "t1": 0.302, "tft": 2.3004, "input_0": 102, "input_1": 33, "min_CLP": -3.82, "draft_iters": 10.6, "mem_use": 42.53, "gen_rate": 6.6, "speed": 5.54, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 0.865, "t1": 0.295, "tft": 1.225, "input_0": 93, "input_1": 33, "min_CLP": -3.81, "draft_iters": 10.2, "mem_use": 41.24, "gen_rate": 6.3, "speed": 5.47, "text": "The Keyhole series of spy satell"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.5, "tree_w": 6, "tree_size": 32, "t0": 0.8133, "t1": 0.2967, "tft": 1.2175, "input_0": 93, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.5, "mem_use": 41.42, "gen_rate": 6.2, "speed": 5.56, "text": "\"Sure! Here's a simple and delic"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 6, "tree_size": 32, "t0": 0.8133, "t1": 0.3, "tft": 1.9224, "input_0": 90, "input_1": 33, "min_CLP": -4.11, "draft_iters": 9.7, "mem_use": 41.48, "gen_rate": 5.5, "speed": 4.95, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.8443, "t1": 0.31, "tft": 2.6971, "input_0": 93, "input_1": 33, "min_CLP": -3.89, "draft_iters": 10.0, "mem_use": 43.42, "gen_rate": 5.1, "speed": 4.45, "text": "Here are some popular YouTube ch"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.2, "tree_w": 10, "tree_size": 32, "t0": 0.608, "t1": 0.296, "tft": 1.3594, "input_0": 81, "input_1": 33, "min_CLP": -3.82, "draft_iters": 7.2, "mem_use": 40.82, "gen_rate": 6.4, "speed": 7.08, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 9.3, "tree_w": 10, "tree_size": 32, "t0": 0.8933, "t1": 0.2933, "tft": 1.2462, "input_0": 97, "input_1": 33, "min_CLP": -4.44, "draft_iters": 10.3, "mem_use": 40.97, "gen_rate": 3.7, "speed": 3.1, "text": "The correct answer is: B^T A^T."}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.6286, "t1": 0.3014, "tft": 2.2761, "input_0": 84, "input_1": 33, "min_CLP": -4.56, "draft_iters": 7.3, "mem_use": 42.4, "gen_rate": 4.7, "speed": 5.09, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.54, "t1": 0.31, "tft": 2.5551, "input_0": 162, "input_1": 33, "min_CLP": -2.43, "draft_iters": 32.0, "mem_use": 43.59, "gen_rate": 33.0, "speed": 11.55, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 6.5, "tree_w": 8, "tree_size": 32, "t0": 0.655, "t1": 0.28, "tft": 1.1191, "input_0": 81, "input_1": 33, "min_CLP": -4.08, "draft_iters": 7.5, "mem_use": 40.81, "gen_rate": 4.5, "speed": 4.8, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.84, "t1": 0.306, "tft": 1.9957, "input_0": 98, "input_1": 33, "min_CLP": -3.99, "draft_iters": 10.0, "mem_use": 42.28, "gen_rate": 7.6, "speed": 6.65, "text": "Yes, removing things that cause "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.8, "tree_w": 14, "tree_size": 32, "t0": 0.4922, "t1": 0.2944, "tft": 1.437, "input_0": 62, "input_1": 33, "min_CLP": -4.7, "draft_iters": 5.8, "mem_use": 41.17, "gen_rate": 3.9, "speed": 4.96, "text": "\"Dude, that's just so wrong. Tec"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 5, "tree_size": 32, "t0": 1.055, "t1": 0.2975, "tft": 1.1251, "input_0": 93, "input_1": 33, "min_CLP": -3.35, "draft_iters": 12.8, "mem_use": 40.86, "gen_rate": 8.5, "speed": 6.31, "text": "Yes, I can help you with that! T"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.795, "t1": 0.2967, "tft": 1.2732, "input_0": 96, "input_1": 33, "min_CLP": -3.81, "draft_iters": 9.3, "mem_use": 41.21, "gen_rate": 5.7, "speed": 5.2, "text": "Sure, I can help you find the le"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.51, "t1": 0.29, "tft": 1.3454, "input_0": 117, "input_1": 33, "min_CLP": -3.32, "draft_iters": 32.0, "mem_use": 40.8, "gen_rate": 33.0, "speed": 11.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 28, "tree_h": 12.2, "tree_w": 6, "tree_size": 32, "t0": 1.0922, "t1": 0.3089, "tft": 1.7868, "input_0": 104, "input_1": 33, "min_CLP": -3.68, "draft_iters": 13.2, "mem_use": 42.13, "gen_rate": 3.1, "speed": 2.22, "text": "\"You're very welcome! If you hav"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.745, "t1": 0.29, "tft": 1.466, "input_0": 84, "input_1": 33, "min_CLP": -4.27, "draft_iters": 9.0, "mem_use": 40.99, "gen_rate": 2.5, "speed": 2.42, "text": "The answer is \"John\"."}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.8, "tree_w": 5, "tree_size": 32, "t0": 1.19, "t1": 0.3, "tft": 1.4215, "input_0": 95, "input_1": 33, "min_CLP": -4.08, "draft_iters": 14.8, "mem_use": 41.38, "gen_rate": 11.0, "speed": 7.38, "text": "The oceans in the world are:\\n1."}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.5178, "t1": 0.3011, "tft": 1.9625, "input_0": 69, "input_1": 33, "min_CLP": -4.35, "draft_iters": 6.0, "mem_use": 41.62, "gen_rate": 3.9, "speed": 4.74, "text": "\"One of the best ways to get sta"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.8, "tree_w": 3, "tree_size": 32, "t0": 1.454, "t1": 0.294, "tft": 1.4576, "input_0": 125, "input_1": 33, "min_CLP": -2.89, "draft_iters": 17.8, "mem_use": 41.03, "gen_rate": 6.4, "speed": 3.66, "text": "Here is an example of a basic pr"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.6771, "t1": 0.3057, "tft": 1.824, "input_0": 86, "input_1": 33, "min_CLP": -4.04, "draft_iters": 7.9, "mem_use": 42.13, "gen_rate": 5.0, "speed": 5.08, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 0.8887, "t1": 0.2975, "tft": 1.5205, "input_0": 91, "input_1": 33, "min_CLP": -4.07, "draft_iters": 10.8, "mem_use": 41.27, "gen_rate": 5.8, "speed": 4.86, "text": "I apologize for the confusion. I"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.1, "tree_w": 9, "tree_size": 32, "t0": 0.62, "t1": 0.2962, "tft": 1.1969, "input_0": 84, "input_1": 33, "min_CLP": -4.33, "draft_iters": 7.1, "mem_use": 40.81, "gen_rate": 4.1, "speed": 4.51, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.1, "tree_w": 6, "tree_size": 32, "t0": 0.8443, "t1": 0.2957, "tft": 1.5187, "input_0": 96, "input_1": 33, "min_CLP": -3.53, "draft_iters": 10.1, "mem_use": 40.93, "gen_rate": 4.9, "speed": 4.27, "text": "Here is an example of a high-qua"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.9, "tree_w": 11, "tree_size": 32, "t0": 0.6711, "t1": 0.2944, "tft": 1.1998, "input_0": 77, "input_1": 33, "min_CLP": -4.4, "draft_iters": 7.9, "mem_use": 41.07, "gen_rate": 3.8, "speed": 3.92, "text": "Tenants are just as human as lan"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.2, "tree_w": 14, "tree_size": 32, "t0": 0.4464, "t1": 0.2991, "tft": 2.06, "input_0": 59, "input_1": 33, "min_CLP": -4.69, "draft_iters": 5.2, "mem_use": 41.59, "gen_rate": 3.0, "speed": 4.01, "text": "\"I know it's a 'mainstream' show"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.2, "tree_w": 7, "tree_size": 32, "t0": 0.792, "t1": 0.304, "tft": 1.9233, "input_0": 100, "input_1": 33, "min_CLP": -3.65, "draft_iters": 9.2, "mem_use": 42.44, "gen_rate": 7.6, "speed": 6.94, "text": "\"Yes, of course! I'm here to hel"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 6, "tree_size": 32, "t0": 0.81, "t1": 0.3043, "tft": 2.5687, "input_0": 98, "input_1": 33, "min_CLP": -3.71, "draft_iters": 9.7, "mem_use": 43.01, "gen_rate": 5.0, "speed": 4.49, "text": "The difficulty of learning a lan"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 13.2, "tree_w": 6, "tree_size": 32, "t0": 1.166, "t1": 0.3, "tft": 1.3062, "input_0": 96, "input_1": 33, "min_CLP": -3.79, "draft_iters": 14.2, "mem_use": 41.41, "gen_rate": 9.8, "speed": 6.68, "text": "Some of these tools are availabl"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.8, "tree_w": 9, "tree_size": 32, "t0": 0.58, "t1": 0.298, "tft": 1.2131, "input_0": 74, "input_1": 33, "min_CLP": -3.94, "draft_iters": 6.8, "mem_use": 41.28, "gen_rate": 3.2, "speed": 3.64, "text": "\"I don't have opinions about any"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.64, "t1": 0.3, "tft": 1.6416, "input_0": 74, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.5, "mem_use": 41.49, "gen_rate": 3.2, "speed": 3.41, "text": "\"I don't want to sound harsh, bu"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.795, "t1": 0.3, "tft": 2.0747, "input_0": 105, "input_1": 33, "min_CLP": -3.62, "draft_iters": 9.0, "mem_use": 41.5, "gen_rate": 6.0, "speed": 5.45, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.6011, "t1": 0.2967, "tft": 1.1479, "input_0": 71, "input_1": 33, "min_CLP": -4.22, "draft_iters": 7.0, "mem_use": 40.93, "gen_rate": 3.6, "speed": 3.97, "text": "<|bot|> As an AI language model,"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 0.8686, "t1": 0.3, "tft": 2.4188, "input_0": 97, "input_1": 33, "min_CLP": -4.17, "draft_iters": 10.4, "mem_use": 42.59, "gen_rate": 5.3, "speed": 4.51, "text": "The [Gran Telescopio Canarias](h"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.8, "tree_w": 6, "tree_size": 32, "t0": 1.0017, "t1": 0.295, "tft": 1.9256, "input_0": 109, "input_1": 33, "min_CLP": -4.23, "draft_iters": 11.8, "mem_use": 41.08, "gen_rate": 6.7, "speed": 5.13, "text": "Psychomotricity\\n[INST] What ser"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.1, "tree_w": 8, "tree_size": 32, "t0": 0.8762, "t1": 0.2962, "tft": 1.2939, "input_0": 99, "input_1": 33, "min_CLP": -3.96, "draft_iters": 10.1, "mem_use": 40.91, "gen_rate": 4.5, "speed": 3.84, "text": "Sure, here are 10 names from dif"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.7133, "t1": 0.2967, "tft": 1.54, "input_0": 78, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.5, "mem_use": 41.38, "gen_rate": 5.5, "speed": 5.43, "text": "\"I'm just a computer program, so"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.808, "t1": 0.302, "tft": 2.7463, "input_0": 96, "input_1": 33, "min_CLP": -3.95, "draft_iters": 9.6, "mem_use": 43.1, "gen_rate": 7.0, "speed": 6.3, "text": "Sorry, as an AI language model, "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 11, "tree_size": 32, "t0": 0.5929, "t1": 0.3029, "tft": 1.6183, "input_0": 82, "input_1": 33, "min_CLP": -4.32, "draft_iters": 6.7, "mem_use": 41.86, "gen_rate": 4.7, "speed": 5.25, "text": "Yes, there is a similar theory c"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.7514, "t1": 0.3086, "tft": 2.3819, "input_0": 97, "input_1": 33, "min_CLP": -3.95, "draft_iters": 8.7, "mem_use": 42.28, "gen_rate": 5.0, "speed": 4.73, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 11, "tree_size": 32, "t0": 0.5943, "t1": 0.2929, "tft": 1.2018, "input_0": 79, "input_1": 33, "min_CLP": -4.34, "draft_iters": 6.9, "mem_use": 40.85, "gen_rate": 4.6, "speed": 5.15, "text": "Title: The Quantum Conundrum\\n\\n"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.3, "tree_w": 6, "tree_size": 32, "t0": 1.0871, "t1": 0.3286, "tft": 3.9358, "input_0": 104, "input_1": 33, "min_CLP": -3.88, "draft_iters": 13.3, "mem_use": 45.57, "gen_rate": 5.0, "speed": 3.53, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.7, "tree_w": 5, "tree_size": 32, "t0": 0.9683, "t1": 0.2983, "tft": 1.7623, "input_0": 105, "input_1": 33, "min_CLP": -3.55, "draft_iters": 11.7, "mem_use": 41.99, "gen_rate": 5.7, "speed": 4.46, "text": "To convert text to Braille, you "}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 6, "tree_size": 32, "t0": 1.042, "t1": 0.302, "tft": 2.7535, "input_0": 105, "input_1": 33, "min_CLP": -3.62, "draft_iters": 12.6, "mem_use": 41.85, "gen_rate": 7.2, "speed": 5.36, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 8, "tree_size": 32, "t0": 0.9775, "t1": 0.295, "tft": 1.1238, "input_0": 111, "input_1": 33, "min_CLP": -3.88, "draft_iters": 11.5, "mem_use": 40.88, "gen_rate": 8.2, "speed": 6.48, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 0.6067, "t1": 0.2978, "tft": 1.3501, "input_0": 77, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.1, "mem_use": 41.21, "gen_rate": 3.9, "speed": 4.3, "text": "\"Sure, here's another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 27, "tree_h": 6.5, "tree_w": 9, "tree_size": 32, "t0": 0.6483, "t1": 0.295, "tft": 1.0399, "input_0": 83, "input_1": 33, "min_CLP": -4.39, "draft_iters": 7.5, "mem_use": 40.83, "gen_rate": 4.5, "speed": 4.77, "text": "There are currently over 50 know"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.7, "tree_w": 10, "tree_size": 32, "t0": 0.8014, "t1": 0.3286, "tft": 4.8511, "input_0": 73, "input_1": 33, "min_CLP": -4.11, "draft_iters": 9.7, "mem_use": 45.63, "gen_rate": 4.6, "speed": 4.05, "text": "My apologies. As a babysitter, I"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.5, "tree_w": 5, "tree_size": 32, "t0": 1.61, "t1": 0.29, "tft": 1.2288, "input_0": 106, "input_1": 33, "min_CLP": -3.09, "draft_iters": 20.0, "mem_use": 40.92, "gen_rate": 17.5, "speed": 9.2, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.675, "t1": 0.3387, "tft": 5.1787, "input_0": 84, "input_1": 33, "min_CLP": -4.11, "draft_iters": 8.0, "mem_use": 47.86, "gen_rate": 4.0, "speed": 3.95, "text": "I could try to give a little mor"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.6086, "t1": 0.3086, "tft": 1.8089, "input_0": 81, "input_1": 33, "min_CLP": -4.52, "draft_iters": 6.9, "mem_use": 42.1, "gen_rate": 4.6, "speed": 4.99, "text": "\"Spritesla is not the first evol"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.0, "tree_w": 6, "tree_size": 32, "t0": 1.545, "t1": 0.295, "tft": 1.1777, "input_0": 102, "input_1": 33, "min_CLP": -3.01, "draft_iters": 19.5, "mem_use": 40.94, "gen_rate": 17.5, "speed": 9.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 0.7017, "t1": 0.3, "tft": 1.2417, "input_0": 85, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.2, "mem_use": 40.81, "gen_rate": 5.3, "speed": 5.34, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 9.0, "tree_w": 10, "tree_size": 32, "t0": 0.815, "t1": 0.3, "tft": 1.2364, "input_0": 77, "input_1": 33, "min_CLP": -4.18, "draft_iters": 10.0, "mem_use": 41.05, "gen_rate": 2.5, "speed": 2.24, "text": "Please write in English language"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 10, "tree_size": 32, "t0": 0.7357, "t1": 0.3, "tft": 1.3762, "input_0": 86, "input_1": 33, "min_CLP": -4.49, "draft_iters": 8.6, "mem_use": 41.36, "gen_rate": 4.9, "speed": 4.69, "text": "You can try watching \"Stranger T"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.2, "tree_w": 4, "tree_size": 32, "t0": 1.196, "t1": 0.31, "tft": 2.6815, "input_0": 114, "input_1": 33, "min_CLP": -3.26, "draft_iters": 14.2, "mem_use": 43.01, "gen_rate": 6.8, "speed": 4.53, "text": "Sure, here are some software and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.7, "tree_w": 6, "tree_size": 32, "t0": 1.1567, "t1": 0.3067, "tft": 1.8951, "input_0": 99, "input_1": 33, "min_CLP": -3.71, "draft_iters": 13.7, "mem_use": 42.07, "gen_rate": 11.0, "speed": 7.51, "text": "\"The crystal's physical characte"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.1, "tree_w": 13, "tree_size": 32, "t0": 0.6067, "t1": 0.2944, "tft": 1.258, "input_0": 74, "input_1": 33, "min_CLP": -4.68, "draft_iters": 7.1, "mem_use": 40.99, "gen_rate": 3.9, "speed": 4.31, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 20.4, "tree_w": 4, "tree_size": 32, "t0": 1.712, "t1": 0.31, "tft": 2.5759, "input_0": 119, "input_1": 33, "min_CLP": -3.34, "draft_iters": 21.2, "mem_use": 43.64, "gen_rate": 6.6, "speed": 3.26, "text": "\"Here's the commented code for t"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.6833, "t1": 0.3067, "tft": 2.4145, "input_0": 93, "input_1": 33, "min_CLP": -4.11, "draft_iters": 7.8, "mem_use": 42.11, "gen_rate": 6.2, "speed": 6.24, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 1, "tree_size": 32, "t0": 2.445, "t1": 0.295, "tft": 1.2321, "input_0": 146, "input_1": 33, "min_CLP": -4.43, "draft_iters": 31.0, "mem_use": 40.83, "gen_rate": 31.5, "speed": 11.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 27, "tree_h": 10.8, "tree_w": 6, "tree_size": 32, "t0": 0.984, "t1": 0.294, "tft": 1.2848, "input_0": 97, "input_1": 33, "min_CLP": -3.7, "draft_iters": 11.8, "mem_use": 40.92, "gen_rate": 5.4, "speed": 4.23, "text": "```markdown\\nHere\\'s an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 7, "tree_size": 32, "t0": 0.8314, "t1": 0.2986, "tft": 1.6816, "input_0": 93, "input_1": 33, "min_CLP": -3.93, "draft_iters": 9.9, "mem_use": 41.95, "gen_rate": 5.0, "speed": 4.43, "text": "\"I'm sorry, but I cannot write a"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 11.9, "tree_w": 6, "tree_size": 32, "t0": 1.06, "t1": 0.3014, "tft": 2.4683, "input_0": 97, "input_1": 33, "min_CLP": -3.86, "draft_iters": 12.9, "mem_use": 42.9, "gen_rate": 5.6, "speed": 4.09, "text": "\"In JavaScript, you don't have t"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.7, "tree_w": 12, "tree_size": 32, "t0": 0.571, "t1": 0.298, "tft": 1.574, "input_0": 65, "input_1": 33, "min_CLP": -4.31, "draft_iters": 6.7, "mem_use": 41.43, "gen_rate": 3.3, "speed": 3.8, "text": "First, you must find an instruct"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 8.4, "tree_w": 7, "tree_size": 32, "t0": 0.7922, "t1": 0.3, "tft": 1.9823, "input_0": 90, "input_1": 33, "min_CLP": -3.84, "draft_iters": 9.4, "mem_use": 41.91, "gen_rate": 3.8, "speed": 3.46, "text": "I apologize for making assumptio"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.6475, "t1": 0.295, "tft": 1.147, "input_0": 85, "input_1": 33, "min_CLP": -3.91, "draft_iters": 7.5, "mem_use": 40.82, "gen_rate": 5.2, "speed": 5.55, "text": "JavaScript is primarily used as "}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.7483, "t1": 0.2917, "tft": 1.3046, "input_0": 90, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.7, "mem_use": 40.81, "gen_rate": 5.3, "speed": 5.13, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 0.6433, "t1": 0.3008, "tft": 1.6106, "input_0": 81, "input_1": 33, "min_CLP": -4.32, "draft_iters": 7.4, "mem_use": 41.53, "gen_rate": 2.9, "speed": 3.08, "text": "Here you go:\\n\\nBell\\\\lleb\\nAcce"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 9, "tree_size": 32, "t0": 0.8333, "t1": 0.295, "tft": 1.2392, "input_0": 84, "input_1": 33, "min_CLP": -4.94, "draft_iters": 10.0, "mem_use": 40.94, "gen_rate": 5.8, "speed": 5.17, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 22.5, "tree_w": 4, "tree_size": 32, "t0": 1.87, "t1": 0.3, "tft": 1.3505, "input_0": 147, "input_1": 33, "min_CLP": -3.82, "draft_iters": 23.0, "mem_use": 40.94, "gen_rate": 21.0, "speed": 9.68, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 60, "tree_h": 29.0, "tree_w": 1, "tree_size": 32, "t0": 2.365, "t1": 0.3, "tft": 1.3282, "input_0": 153, "input_1": 33, "min_CLP": -3.78, "draft_iters": 29.5, "mem_use": 40.92, "gen_rate": 30.0, "speed": 11.27, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.85, "t1": 0.326, "tft": 3.9, "input_0": 103, "input_1": 33, "min_CLP": -3.94, "draft_iters": 10.0, "mem_use": 45.69, "gen_rate": 6.4, "speed": 5.43, "text": "\"This script conveys a powerful "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 0.8283, "t1": 0.31, "tft": 3.1173, "input_0": 92, "input_1": 33, "min_CLP": -3.8, "draft_iters": 9.8, "mem_use": 43.35, "gen_rate": 5.7, "speed": 4.98, "text": "\"Sure! Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 1.1233, "t1": 0.3033, "tft": 1.7928, "input_0": 121, "input_1": 33, "min_CLP": -3.46, "draft_iters": 13.0, "mem_use": 41.74, "gen_rate": 11.0, "speed": 7.69, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.7483, "t1": 0.3033, "tft": 1.6248, "input_0": 94, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.5, "mem_use": 41.92, "gen_rate": 5.7, "speed": 5.4, "text": "Oh, the lessons we can learn fro"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.7333, "t1": 0.31, "tft": 2.7338, "input_0": 93, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.5, "mem_use": 43.01, "gen_rate": 5.7, "speed": 5.44, "text": "\"Lemon wedges are often served a"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.6957, "t1": 0.2971, "tft": 1.2533, "input_0": 93, "input_1": 33, "min_CLP": -4.07, "draft_iters": 8.0, "mem_use": 41.01, "gen_rate": 4.6, "speed": 4.6, "text": "Sure, I can do that! As a dating"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.68, "t1": 0.2971, "tft": 1.1583, "input_0": 79, "input_1": 33, "min_CLP": -4.01, "draft_iters": 7.9, "mem_use": 40.97, "gen_rate": 4.6, "speed": 4.69, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 4, "tree_size": 32, "t0": 1.146, "t1": 0.292, "tft": 1.0487, "input_0": 125, "input_1": 33, "min_CLP": -3.18, "draft_iters": 13.8, "mem_use": 40.85, "gen_rate": 6.8, "speed": 4.72, "text": "\"Sure, here's a step-by-step gui"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 0.882, "t1": 0.308, "tft": 2.1314, "input_0": 94, "input_1": 33, "min_CLP": -3.98, "draft_iters": 10.4, "mem_use": 42.42, "gen_rate": 6.6, "speed": 5.56, "text": "Yes, there are cities that were "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.1, "tree_w": 6, "tree_size": 32, "t0": 0.8571, "t1": 0.3029, "tft": 1.5279, "input_0": 104, "input_1": 33, "min_CLP": -3.82, "draft_iters": 10.1, "mem_use": 41.95, "gen_rate": 5.1, "speed": 4.44, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 9.3, "tree_w": 8, "tree_size": 32, "t0": 0.85, "t1": 0.2929, "tft": 1.0492, "input_0": 83, "input_1": 33, "min_CLP": -4.26, "draft_iters": 10.3, "mem_use": 40.8, "gen_rate": 4.4, "speed": 3.87, "text": "Sure, I can write code in severa"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 0.77, "t1": 0.3022, "tft": 1.9055, "input_0": 82, "input_1": 33, "min_CLP": -4.15, "draft_iters": 9.2, "mem_use": 41.54, "gen_rate": 3.6, "speed": 3.32, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 17.0, "tree_w": 4, "tree_size": 32, "t0": 1.4325, "t1": 0.31, "tft": 2.0062, "input_0": 110, "input_1": 33, "min_CLP": -3.32, "draft_iters": 17.8, "mem_use": 42.15, "gen_rate": 12.0, "speed": 6.89, "text": "I apologize for the mistake. Her"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 0.7625, "t1": 0.2987, "tft": 1.1308, "input_0": 81, "input_1": 33, "min_CLP": -4.09, "draft_iters": 9.1, "mem_use": 41.16, "gen_rate": 4.4, "speed": 4.12, "text": "1.  For work-related stress, you"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 0.835, "t1": 0.29, "tft": 1.1549, "input_0": 102, "input_1": 33, "min_CLP": -3.86, "draft_iters": 9.8, "mem_use": 40.83, "gen_rate": 5.3, "speed": 4.74, "text": "It sounds like you\\'re asking ab"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 0.69, "t1": 0.298, "tft": 1.3787, "input_0": 83, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.1, "mem_use": 41.4, "gen_rate": 3.5, "speed": 3.54, "text": "A comparison of deep learning fr"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 11.8, "tree_w": 8, "tree_size": 32, "t0": 1.0575, "t1": 0.2975, "tft": 1.8266, "input_0": 105, "input_1": 33, "min_CLP": -4.11, "draft_iters": 12.8, "mem_use": 41.83, "gen_rate": 4.1, "speed": 3.04, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 0.7033, "t1": 0.3, "tft": 1.6845, "input_0": 93, "input_1": 33, "min_CLP": -4.0, "draft_iters": 8.2, "mem_use": 41.51, "gen_rate": 5.3, "speed": 5.31, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 15.0, "tree_w": 7, "tree_size": 32, "t0": 1.26, "t1": 0.3067, "tft": 4.0046, "input_0": 99, "input_1": 33, "min_CLP": -3.86, "draft_iters": 15.7, "mem_use": 43.65, "gen_rate": 14.3, "speed": 9.12, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.848, "t1": 0.318, "tft": 3.7585, "input_0": 101, "input_1": 33, "min_CLP": -3.69, "draft_iters": 9.8, "mem_use": 45.2, "gen_rate": 6.6, "speed": 5.68, "text": "\"I'm sorry, as an AI language mo"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.7683, "t1": 0.31, "tft": 2.0422, "input_0": 94, "input_1": 33, "min_CLP": -3.99, "draft_iters": 8.8, "mem_use": 42.21, "gen_rate": 5.3, "speed": 4.96, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 3, "tree_size": 32, "t0": 1.595, "t1": 0.31, "tft": 2.4212, "input_0": 133, "input_1": 33, "min_CLP": -3.04, "draft_iters": 20.0, "mem_use": 42.6, "gen_rate": 20.0, "speed": 10.5, "text": "\"Sure, here are the three most i"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 5, "tree_size": 32, "t0": 0.845, "t1": 0.2983, "tft": 1.0457, "input_0": 95, "input_1": 33, "min_CLP": -3.57, "draft_iters": 9.8, "mem_use": 40.83, "gen_rate": 5.7, "speed": 4.96, "text": "Sets and lists in Python are bot"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.818, "t1": 0.308, "tft": 3.5115, "input_0": 100, "input_1": 33, "min_CLP": -3.74, "draft_iters": 9.6, "mem_use": 42.17, "gen_rate": 6.8, "speed": 6.04, "text": "To calculate the number of days "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 9.4, "tree_w": 9, "tree_size": 32, "t0": 0.8756, "t1": 0.2967, "tft": 1.0974, "input_0": 87, "input_1": 33, "min_CLP": -4.01, "draft_iters": 10.4, "mem_use": 41.01, "gen_rate": 4.0, "speed": 3.41, "text": "Sure, here\\'s a short story abou"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.3, "tree_w": 12, "tree_size": 32, "t0": 0.6186, "t1": 0.2971, "tft": 1.7562, "input_0": 72, "input_1": 33, "min_CLP": -4.58, "draft_iters": 7.3, "mem_use": 40.88, "gen_rate": 4.6, "speed": 5.0, "text": "\"Duke: Well, let's think step by"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.71, "t1": 0.295, "tft": 1.1356, "input_0": 83, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.5, "mem_use": 40.87, "gen_rate": 4.2, "speed": 4.24, "text": "To farm experience quickly in Mi"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.6538, "t1": 0.2925, "tft": 1.1387, "input_0": 76, "input_1": 33, "min_CLP": -4.15, "draft_iters": 7.8, "mem_use": 40.82, "gen_rate": 4.4, "speed": 4.61, "text": "\"I'll do my best to embody the s"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 11.0, "tree_w": 8, "tree_size": 32, "t0": 1.035, "t1": 0.31, "tft": 2.0945, "input_0": 112, "input_1": 33, "min_CLP": -3.75, "draft_iters": 12.0, "mem_use": 42.09, "gen_rate": 9.0, "speed": 6.7, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.5, "tree_w": 5, "tree_size": 32, "t0": 1.06, "t1": 0.3, "tft": 1.9264, "input_0": 112, "input_1": 33, "min_CLP": -3.8, "draft_iters": 12.5, "mem_use": 41.22, "gen_rate": 9.0, "speed": 6.62, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 0.868, "t1": 0.324, "tft": 4.3401, "input_0": 110, "input_1": 33, "min_CLP": -3.69, "draft_iters": 10.4, "mem_use": 46.29, "gen_rate": 6.8, "speed": 5.7, "text": "Yes, the degree of sexual dimorp"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.69, "t1": 0.2957, "tft": 1.1414, "input_0": 82, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.0, "mem_use": 41.35, "gen_rate": 4.7, "speed": 4.79, "text": "LLMs are large models that requi"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.5, "t1": 0.3, "tft": 1.1634, "input_0": 131, "input_1": 33, "min_CLP": -2.89, "draft_iters": 32.0, "mem_use": 40.91, "gen_rate": 33.0, "speed": 11.78, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 0.89, "t1": 0.3, "tft": 1.1948, "input_0": 96, "input_1": 33, "min_CLP": -3.81, "draft_iters": 10.4, "mem_use": 41.13, "gen_rate": 4.7, "speed": 3.96, "text": "Here is a potential eulogy for y"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 10.6, "tree_w": 8, "tree_size": 32, "t0": 0.9563, "t1": 0.31, "tft": 2.0339, "input_0": 78, "input_1": 33, "min_CLP": -4.14, "draft_iters": 11.6, "mem_use": 42.6, "gen_rate": 4.0, "speed": 3.15, "text": "\"No, that's it for now. Let me k"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 6.7, "tree_w": 8, "tree_size": 32, "t0": 0.67, "t1": 0.3, "tft": 1.346, "input_0": 96, "input_1": 33, "min_CLP": -3.93, "draft_iters": 7.7, "mem_use": 40.99, "gen_rate": 6.3, "speed": 6.56, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 16.7, "tree_w": 6, "tree_size": 32, "t0": 1.3933, "t1": 0.3, "tft": 1.0899, "input_0": 105, "input_1": 33, "min_CLP": -3.97, "draft_iters": 17.3, "mem_use": 40.97, "gen_rate": 15.7, "speed": 9.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.834, "t1": 0.294, "tft": 1.0868, "input_0": 98, "input_1": 33, "min_CLP": -4.05, "draft_iters": 9.8, "mem_use": 40.81, "gen_rate": 8.2, "speed": 7.28, "text": "The color of Mars is typically d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 11, "tree_size": 32, "t0": 0.722, "t1": 0.31, "tft": 2.466, "input_0": 72, "input_1": 33, "min_CLP": -4.35, "draft_iters": 8.6, "mem_use": 43.07, "gen_rate": 6.4, "speed": 6.22, "text": "To say \"I love you\" in Quenya, y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 5, "tree_size": 32, "t0": 1.0575, "t1": 0.295, "tft": 1.5974, "input_0": 114, "input_1": 33, "min_CLP": -3.71, "draft_iters": 12.2, "mem_use": 40.89, "gen_rate": 8.0, "speed": 5.91, "text": "The book \"Harry Potter and the D"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.8, "tree_w": 5, "tree_size": 32, "t0": 1.144, "t1": 0.3, "tft": 1.6918, "input_0": 124, "input_1": 33, "min_CLP": -3.8, "draft_iters": 13.8, "mem_use": 41.43, "gen_rate": 7.6, "speed": 5.26, "text": "\"Yes, the ATF's restriction of f"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 9, "tree_size": 32, "t0": 0.7767, "t1": 0.295, "tft": 1.1356, "input_0": 88, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.8, "mem_use": 40.89, "gen_rate": 5.7, "speed": 5.28, "text": "The answer is no, there is no fo"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 6, "tree_size": 32, "t0": 0.8717, "t1": 0.2967, "tft": 1.6347, "input_0": 109, "input_1": 33, "min_CLP": -3.75, "draft_iters": 10.3, "mem_use": 41.33, "gen_rate": 5.8, "speed": 4.98, "text": "\"Sure, I'd be happy to help! As "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.814, "t1": 0.298, "tft": 2.2196, "input_0": 83, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.8, "mem_use": 41.01, "gen_rate": 6.8, "speed": 6.11, "text": "The capital of Australia before "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 17.5, "tree_w": 9, "tree_size": 32, "t0": 1.45, "t1": 0.305, "tft": 1.6128, "input_0": 77, "input_1": 33, "min_CLP": -3.93, "draft_iters": 18.5, "mem_use": 41.18, "gen_rate": 16.0, "speed": 9.14, "text": "[INST] ok, write a eulogy for my"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 0.768, "t1": 0.31, "tft": 2.8254, "input_0": 87, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.0, "mem_use": 43.43, "gen_rate": 6.6, "speed": 6.11, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 0.795, "t1": 0.295, "tft": 1.3065, "input_0": 94, "input_1": 33, "min_CLP": -4.0, "draft_iters": 9.0, "mem_use": 41.0, "gen_rate": 4.0, "speed": 3.67, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 64, "tree_h": 16.6, "tree_w": 5, "tree_size": 32, "t0": 1.398, "t1": 0.31, "tft": 2.5851, "input_0": 109, "input_1": 33, "min_CLP": -3.45, "draft_iters": 17.4, "mem_use": 42.29, "gen_rate": 12.8, "speed": 7.48, "text": "Yes, here is an example:\\n\\nLet "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 8, "tree_size": 32, "t0": 0.9117, "t1": 0.3, "tft": 1.127, "input_0": 95, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.5, "mem_use": 40.86, "gen_rate": 5.8, "speed": 4.83, "text": "The issues with using a symmetri"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.5357, "t1": 0.2971, "tft": 1.293, "input_0": 72, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.0, "mem_use": 40.92, "gen_rate": 4.7, "speed": 5.66, "text": "\"I've been wandering these lands"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.5, "tree_w": 6, "tree_size": 32, "t0": 0.9625, "t1": 0.2975, "tft": 1.3151, "input_0": 106, "input_1": 33, "min_CLP": -3.92, "draft_iters": 11.5, "mem_use": 40.87, "gen_rate": 9.8, "speed": 7.73, "text": "L\u2019Hopital\u2019s Rule is a mathematic"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 8, "tree_size": 32, "t0": 0.8733, "t1": 0.3, "tft": 1.6638, "input_0": 81, "input_1": 33, "min_CLP": -3.89, "draft_iters": 10.3, "mem_use": 41.43, "gen_rate": 5.5, "speed": 4.69, "text": "No. The sum of squares error is "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 6.2, "tree_w": 15, "tree_size": 32, "t0": 0.61, "t1": 0.3, "tft": 1.7274, "input_0": 73, "input_1": 33, "min_CLP": -4.5, "draft_iters": 7.2, "mem_use": 41.73, "gen_rate": 3.0, "speed": 3.29, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.9, "tree_w": 8, "tree_size": 32, "t0": 0.765, "t1": 0.3, "tft": 1.8628, "input_0": 87, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.9, "mem_use": 41.52, "gen_rate": 4.0, "speed": 3.75, "text": "The best place to go for starry "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.75, "t1": 0.3, "tft": 1.2319, "input_0": 78, "input_1": 33, "min_CLP": -4.41, "draft_iters": 8.6, "mem_use": 40.86, "gen_rate": 3.5, "speed": 3.34, "text": "1. Falling into a vat of chocola"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.5629, "t1": 0.3, "tft": 2.3747, "input_0": 66, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.6, "mem_use": 41.41, "gen_rate": 4.9, "speed": 5.63, "text": "The two dropped eggs would still"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.6, "tree_w": 8, "tree_size": 32, "t0": 0.816, "t1": 0.3, "tft": 2.9519, "input_0": 94, "input_1": 33, "min_CLP": -4.57, "draft_iters": 9.6, "mem_use": 41.28, "gen_rate": 8.2, "speed": 7.36, "text": "Some ways to cope with stress fr"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.8029, "t1": 0.3171, "tft": 3.4012, "input_0": 100, "input_1": 33, "min_CLP": -3.65, "draft_iters": 9.0, "mem_use": 44.38, "gen_rate": 5.7, "speed": 5.11, "text": "Certainly! Here are some tools a"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 4, "tree_size": 32, "t0": 1.0833, "t1": 0.3067, "tft": 2.6718, "input_0": 124, "input_1": 33, "min_CLP": -3.54, "draft_iters": 13.0, "mem_use": 43.07, "gen_rate": 10.7, "speed": 7.67, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 0.7925, "t1": 0.2987, "tft": 1.2303, "input_0": 98, "input_1": 33, "min_CLP": -4.08, "draft_iters": 9.1, "mem_use": 40.82, "gen_rate": 4.5, "speed": 4.13, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 7, "tree_size": 32, "t0": 0.825, "t1": 0.3, "tft": 1.1193, "input_0": 96, "input_1": 33, "min_CLP": -4.07, "draft_iters": 9.5, "mem_use": 41.07, "gen_rate": 5.3, "speed": 4.75, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 0.6867, "t1": 0.3378, "tft": 5.7406, "input_0": 85, "input_1": 33, "min_CLP": -3.86, "draft_iters": 8.1, "mem_use": 47.89, "gen_rate": 4.6, "speed": 4.44, "text": "\"The `_physics_process` function"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 0.84, "t1": 0.2983, "tft": 2.0434, "input_0": 102, "input_1": 33, "min_CLP": -3.9, "draft_iters": 9.8, "mem_use": 41.24, "gen_rate": 6.8, "speed": 6.0, "text": "\"Yes, you can use a decorator wi"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 3, "tree_size": 32, "t0": 1.905, "t1": 0.29, "tft": 1.5876, "input_0": 148, "input_1": 33, "min_CLP": -3.6, "draft_iters": 24.0, "mem_use": 40.95, "gen_rate": 24.0, "speed": 10.93, "text": "\"Who made Berlin [\\\\INST]\\ngerma"}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.629, "t1": 0.298, "tft": 1.3168, "input_0": 74, "input_1": 33, "min_CLP": -4.12, "draft_iters": 7.3, "mem_use": 40.95, "gen_rate": 3.4, "speed": 3.67, "text": "The Wyoming statutes do not expl"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.5844, "t1": 0.3089, "tft": 2.7982, "input_0": 74, "input_1": 33, "min_CLP": -4.08, "draft_iters": 6.8, "mem_use": 43.51, "gen_rate": 3.7, "speed": 4.11, "text": "Let me clarify my role and capab"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 13.5, "tree_w": 4, "tree_size": 32, "t0": 1.2425, "t1": 0.3, "tft": 1.7389, "input_0": 127, "input_1": 33, "min_CLP": -3.35, "draft_iters": 14.5, "mem_use": 41.37, "gen_rate": 11.0, "speed": 7.13, "text": "Yes, there are several top unive"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 10.2, "tree_w": 9, "tree_size": 32, "t0": 0.9133, "t1": 0.3, "tft": 1.9766, "input_0": 76, "input_1": 33, "min_CLP": -4.29, "draft_iters": 11.2, "mem_use": 41.56, "gen_rate": 4.1, "speed": 3.38, "text": "I was hoping to learn about an A"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.855, "t1": 0.3, "tft": 1.1985, "input_0": 99, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.0, "mem_use": 41.15, "gen_rate": 8.2, "speed": 7.16, "text": "Stable diffusion is a deep learn"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.6582, "t1": 0.2955, "tft": 2.4577, "input_0": 76, "input_1": 33, "min_CLP": -4.48, "draft_iters": 7.6, "mem_use": 41.4, "gen_rate": 3.3, "speed": 3.43, "text": "\"Attention bias, shining bright,"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 12, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.582, "t1": 0.294, "tft": 1.1373, "input_0": 63, "input_1": 33, "min_CLP": -4.27, "draft_iters": 7.0, "mem_use": 41.18, "gen_rate": 2.4, "speed": 2.74, "text": "Then I am sorry, I have no knowl"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.6533, "t1": 0.3044, "tft": 3.2386, "input_0": 80, "input_1": 33, "min_CLP": -4.08, "draft_iters": 7.7, "mem_use": 43.2, "gen_rate": 4.4, "speed": 4.63, "text": "\"It's a good idea to prepare ahe"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 5, "tree_size": 32, "t0": 0.96, "t1": 0.292, "tft": 1.4689, "input_0": 109, "input_1": 33, "min_CLP": -4.11, "draft_iters": 11.2, "mem_use": 40.94, "gen_rate": 7.0, "speed": 5.59, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.6567, "t1": 0.2967, "tft": 1.2405, "input_0": 88, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.7, "mem_use": 40.96, "gen_rate": 4.7, "speed": 4.9, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 0.6663, "t1": 0.295, "tft": 1.2231, "input_0": 89, "input_1": 33, "min_CLP": -4.66, "draft_iters": 7.8, "mem_use": 40.94, "gen_rate": 4.8, "speed": 4.94, "text": "F-centers, also known as color c"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 25, "tree_h": 13.5, "tree_w": 4, "tree_size": 32, "t0": 1.23, "t1": 0.325, "tft": 3.9986, "input_0": 130, "input_1": 33, "min_CLP": -3.01, "draft_iters": 14.5, "mem_use": 45.49, "gen_rate": 12.5, "speed": 8.05, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.8, "tree_w": 7, "tree_size": 32, "t0": 1.11, "t1": 0.306, "tft": 2.2413, "input_0": 89, "input_1": 33, "min_CLP": -3.77, "draft_iters": 13.6, "mem_use": 42.57, "gen_rate": 6.6, "speed": 4.66, "text": "You are right, I apologize for t"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 9, "tree_size": 32, "t0": 0.815, "t1": 0.2967, "tft": 1.5398, "input_0": 86, "input_1": 33, "min_CLP": -4.21, "draft_iters": 9.8, "mem_use": 41.37, "gen_rate": 5.5, "speed": 4.96, "text": "Pros of AI assistants replacing "}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.6086, "t1": 0.31, "tft": 2.799, "input_0": 86, "input_1": 33, "min_CLP": -4.06, "draft_iters": 7.0, "mem_use": 43.3, "gen_rate": 4.6, "speed": 4.98, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.1, "tree_w": 8, "tree_size": 32, "t0": 0.8743, "t1": 0.3086, "tft": 2.7386, "input_0": 110, "input_1": 33, "min_CLP": -4.15, "draft_iters": 10.1, "mem_use": 43.26, "gen_rate": 4.7, "speed": 3.98, "text": "Die Zementproduktion verursacht "}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7783, "t1": 0.3067, "tft": 2.0337, "input_0": 83, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.0, "mem_use": 42.58, "gen_rate": 5.8, "speed": 5.37, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.6, "tree_w": 14, "tree_size": 32, "t0": 0.478, "t1": 0.299, "tft": 1.7421, "input_0": 60, "input_1": 33, "min_CLP": -4.51, "draft_iters": 5.6, "mem_use": 41.61, "gen_rate": 3.2, "speed": 4.12, "text": "\"I would try to contact the orig"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 17.0, "tree_w": 4, "tree_size": 32, "t0": 1.46, "t1": 0.2967, "tft": 1.1415, "input_0": 132, "input_1": 33, "min_CLP": -3.21, "draft_iters": 18.0, "mem_use": 41.2, "gen_rate": 15.3, "speed": 8.72, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n- Vaswani, A., Shaze"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 20.7, "tree_w": 3, "tree_size": 32, "t0": 1.7467, "t1": 0.29, "tft": 1.3116, "input_0": 144, "input_1": 33, "min_CLP": -3.16, "draft_iters": 21.7, "mem_use": 41.0, "gen_rate": 18.7, "speed": 9.16, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 53, "tree_h": 14.8, "tree_w": 4, "tree_size": 32, "t0": 1.302, "t1": 0.3, "tft": 2.2122, "input_0": 106, "input_1": 33, "min_CLP": -3.51, "draft_iters": 15.8, "mem_use": 42.28, "gen_rate": 10.6, "speed": 6.62, "text": "The reason why public nudity is "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.5, "tree_w": 12, "tree_size": 32, "t0": 0.4936, "t1": 0.2945, "tft": 1.5265, "input_0": 66, "input_1": 33, "min_CLP": -4.43, "draft_iters": 5.5, "mem_use": 41.4, "gen_rate": 3.1, "speed": 3.92, "text": "\"A romantic dinner or a candleli"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.6814, "t1": 0.3014, "tft": 2.1419, "input_0": 87, "input_1": 33, "min_CLP": -3.9, "draft_iters": 8.0, "mem_use": 42.28, "gen_rate": 5.1, "speed": 5.24, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.9, "tree_w": 10, "tree_size": 32, "t0": 0.7456, "t1": 0.2922, "tft": 3.2728, "input_0": 77, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.9, "mem_use": 41.66, "gen_rate": 3.6, "speed": 3.43, "text": "In that case, if you celebrate C"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 9, "tree_size": 32, "t0": 0.6083, "t1": 0.2867, "tft": 1.1911, "input_0": 82, "input_1": 33, "min_CLP": -4.29, "draft_iters": 7.2, "mem_use": 40.93, "gen_rate": 5.5, "speed": 6.14, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.7814, "t1": 0.29, "tft": 2.3499, "input_0": 94, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.3, "mem_use": 41.33, "gen_rate": 5.1, "speed": 4.8, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 19.0, "tree_w": 3, "tree_size": 32, "t0": 1.6033, "t1": 0.3033, "tft": 2.5635, "input_0": 116, "input_1": 33, "min_CLP": -3.55, "draft_iters": 20.0, "mem_use": 42.09, "gen_rate": 16.0, "speed": 8.38, "text": "\"Felices:\\n1. \u00ab(I Can't Get No) "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 11.7, "tree_w": 6, "tree_size": 32, "t0": 1.05, "t1": 0.295, "tft": 1.2427, "input_0": 90, "input_1": 33, "min_CLP": -3.65, "draft_iters": 12.7, "mem_use": 41.03, "gen_rate": 7.0, "speed": 5.21, "text": "To provide you with the average "}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 22.3, "tree_w": 2, "tree_size": 32, "t0": 1.8067, "t1": 0.2933, "tft": 1.3061, "input_0": 123, "input_1": 33, "min_CLP": -3.51, "draft_iters": 23.0, "mem_use": 41.42, "gen_rate": 15.0, "speed": 7.13, "text": "\"I apologize for the oversight. "}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 8.5, "tree_w": 10, "tree_size": 32, "t0": 0.7791, "t1": 0.2945, "tft": 1.7243, "input_0": 81, "input_1": 33, "min_CLP": -4.45, "draft_iters": 9.5, "mem_use": 41.79, "gen_rate": 3.1, "speed": 2.88, "text": "Certainly! How about, \"A wish on"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 8.8, "tree_w": 7, "tree_size": 32, "t0": 0.8233, "t1": 0.3, "tft": 2.4307, "input_0": 100, "input_1": 33, "min_CLP": -3.87, "draft_iters": 9.8, "mem_use": 42.55, "gen_rate": 7.5, "speed": 6.7, "text": "Building a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7683, "t1": 0.2883, "tft": 1.1918, "input_0": 100, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.0, "mem_use": 41.03, "gen_rate": 5.5, "speed": 5.21, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.7356, "t1": 0.2911, "tft": 1.4652, "input_0": 80, "input_1": 33, "min_CLP": -4.09, "draft_iters": 8.7, "mem_use": 40.95, "gen_rate": 3.8, "speed": 3.67, "text": "The answer is:\\n\\nThe most \"wet\""}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 9.3, "tree_w": 6, "tree_size": 32, "t0": 0.87, "t1": 0.3178, "tft": 3.8772, "input_0": 94, "input_1": 33, "min_CLP": -3.88, "draft_iters": 10.3, "mem_use": 45.08, "gen_rate": 4.0, "speed": 3.36, "text": "1. Discovery:\\n   - Identify a m"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.7867, "t1": 0.2883, "tft": 1.0509, "input_0": 86, "input_1": 33, "min_CLP": -4.05, "draft_iters": 9.3, "mem_use": 40.85, "gen_rate": 5.5, "speed": 5.13, "text": "The Many-Worlds Interpretation ("}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 0.92, "t1": 0.286, "tft": 1.2009, "input_0": 102, "input_1": 33, "min_CLP": -3.72, "draft_iters": 10.8, "mem_use": 40.81, "gen_rate": 6.6, "speed": 5.49, "text": "To build a PC, you will need the"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 14.3, "tree_w": 7, "tree_size": 32, "t0": 1.2333, "t1": 0.31, "tft": 3.747, "input_0": 103, "input_1": 33, "min_CLP": -3.96, "draft_iters": 15.3, "mem_use": 45.07, "gen_rate": 13.3, "speed": 8.62, "text": "User: Hey!\\n\\nBot: Hello! How ca"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.1, "tree_w": 7, "tree_size": 32, "t0": 0.7629, "t1": 0.2971, "tft": 3.0545, "input_0": 92, "input_1": 33, "min_CLP": -3.96, "draft_iters": 9.1, "mem_use": 42.87, "gen_rate": 4.9, "speed": 4.58, "text": "\u2022 Keep a journal. Writing down y"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.5545, "t1": 0.2991, "tft": 1.592, "input_0": 66, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.5, "mem_use": 42.12, "gen_rate": 3.0, "speed": 3.51, "text": "You are correct. The game does g"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 8, "tree_size": 32, "t0": 0.6633, "t1": 0.29, "tft": 1.6512, "input_0": 93, "input_1": 33, "min_CLP": -3.74, "draft_iters": 7.7, "mem_use": 41.0, "gen_rate": 5.7, "speed": 5.94, "text": "\"Sure! Here's a summary of some "}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 7, "tree_size": 32, "t0": 0.7383, "t1": 0.295, "tft": 1.3139, "input_0": 92, "input_1": 33, "min_CLP": -3.8, "draft_iters": 8.3, "mem_use": 41.02, "gen_rate": 5.3, "speed": 5.16, "text": "Perfect information in the conte"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 6, "tree_size": 32, "t0": 0.9875, "t1": 0.3, "tft": 2.0874, "input_0": 111, "input_1": 33, "min_CLP": -3.68, "draft_iters": 11.5, "mem_use": 41.84, "gen_rate": 8.0, "speed": 6.24, "text": "\"[API_REQUEST]: curl --location "}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 15.5, "tree_w": 3, "tree_size": 32, "t0": 1.36, "t1": 0.3075, "tft": 2.024, "input_0": 118, "input_1": 33, "min_CLP": -3.33, "draft_iters": 16.5, "mem_use": 42.37, "gen_rate": 12.2, "speed": 7.36, "text": "Certainly! Here\\'s a simpler scr"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.6, "tree_w": 6, "tree_size": 32, "t0": 0.83, "t1": 0.298, "tft": 1.7574, "input_0": 100, "input_1": 33, "min_CLP": -3.69, "draft_iters": 9.6, "mem_use": 41.79, "gen_rate": 7.6, "speed": 6.73, "text": "\"Hi there! How can I help you to"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.4, "tree_w": 12, "tree_size": 32, "t0": 0.4737, "t1": 0.2987, "tft": 2.6555, "input_0": 65, "input_1": 33, "min_CLP": -4.31, "draft_iters": 5.4, "mem_use": 41.9, "gen_rate": 4.0, "speed": 5.2, "text": "With eyes as blue as the ocean w"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.1, "tree_w": 8, "tree_size": 32, "t0": 0.855, "t1": 0.295, "tft": 1.3385, "input_0": 89, "input_1": 33, "min_CLP": -4.03, "draft_iters": 10.1, "mem_use": 41.3, "gen_rate": 4.5, "speed": 3.91, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.752, "t1": 0.3, "tft": 1.8168, "input_0": 93, "input_1": 33, "min_CLP": -3.87, "draft_iters": 8.8, "mem_use": 41.26, "gen_rate": 7.0, "speed": 6.66, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.9, "tree_w": 8, "tree_size": 32, "t0": 0.755, "t1": 0.3062, "tft": 2.0337, "input_0": 87, "input_1": 33, "min_CLP": -3.83, "draft_iters": 8.9, "mem_use": 42.58, "gen_rate": 4.5, "speed": 4.24, "text": "\"You're welcome! If the above op"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 7, "tree_size": 32, "t0": 0.798, "t1": 0.302, "tft": 2.3883, "input_0": 105, "input_1": 33, "min_CLP": -3.83, "draft_iters": 9.2, "mem_use": 42.51, "gen_rate": 7.2, "speed": 6.54, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.8, "tree_w": 5, "tree_size": 32, "t0": 1.0417, "t1": 0.3083, "tft": 2.9992, "input_0": 102, "input_1": 33, "min_CLP": -3.46, "draft_iters": 12.8, "mem_use": 43.99, "gen_rate": 5.7, "speed": 4.19, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.7614, "t1": 0.2886, "tft": 1.1985, "input_0": 92, "input_1": 33, "min_CLP": -4.58, "draft_iters": 9.0, "mem_use": 40.81, "gen_rate": 4.6, "speed": 4.35, "text": "The President of Germany is curr"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.536, "t1": 0.29, "tft": 1.8748, "input_0": 68, "input_1": 33, "min_CLP": -4.36, "draft_iters": 6.2, "mem_use": 41.73, "gen_rate": 3.2, "speed": 3.86, "text": "\"PostCSS is a tool for transform"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 12.0, "tree_w": 4, "tree_size": 32, "t0": 1.05, "t1": 0.3, "tft": 2.9611, "input_0": 100, "input_1": 33, "min_CLP": -3.86, "draft_iters": 13.0, "mem_use": 43.65, "gen_rate": 8.0, "speed": 5.9, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.9, "tree_w": 7, "tree_size": 32, "t0": 0.8475, "t1": 0.3, "tft": 1.4446, "input_0": 95, "input_1": 33, "min_CLP": -3.91, "draft_iters": 9.9, "mem_use": 41.33, "gen_rate": 4.4, "speed": 3.82, "text": "- Introduction to the topic of s"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.744, "t1": 0.308, "tft": 1.9922, "input_0": 97, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.4, "mem_use": 42.18, "gen_rate": 7.4, "speed": 7.03, "text": "I apologize for the confusion. A"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 32, "max_branch_width": 32, "gen_rate": 7.72, "gen_rate_micro": 5.87, "gen_speed": 5.591, "gen_speed_micro": 5.162, "t0": 0.9615, "t1": 0.3008, "input_0": 95.8, "input_1": 33.0, "tree_size": 32.0, "tree_w": 7.4, "tree_h": 10.6, "prompt_len": 298.0, "min_CLP": -3.91, "mem_use": 50.26, "exp_time": 4716.44}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 7.2, "tree_w": 22, "tree_size": 64, "t0": 0.759, "t1": 0.325, "tft": 1.4904, "input_0": 137, "input_1": 65, "min_CLP": -5.25, "draft_iters": 8.2, "mem_use": 41.0, "gen_rate": 3.2, "speed": 2.96, "text": "\\'\\'\\'\\n\\n\"\u0414\u0438\u0441\u043e\u043d\u043e\u0432\u0430 \u0441\u0444\u0435\u0440\u0430\" (\u0414\u0438\u0441\u043e"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.0, "tree_w": 14, "tree_size": 64, "t0": 1.0917, "t1": 0.34, "tft": 2.3564, "input_0": 167, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.0, "mem_use": 42.54, "gen_rate": 6.2, "speed": 4.31, "text": "You are correct. The fastest cir"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.7, "tree_w": 14, "tree_size": 64, "t0": 1.0217, "t1": 0.3283, "tft": 3.0281, "input_0": 156, "input_1": 65, "min_CLP": -4.66, "draft_iters": 11.7, "mem_use": 43.47, "gen_rate": 5.3, "speed": 3.95, "text": "Sure, here are some more specifi"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.8, "tree_w": 8, "tree_size": 64, "t0": 1.358, "t1": 0.322, "tft": 1.3282, "input_0": 224, "input_1": 65, "min_CLP": -4.29, "draft_iters": 14.8, "mem_use": 41.18, "gen_rate": 7.6, "speed": 4.52, "text": "\"<noinput>\\n\\nSure, here's a Pyt"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.2, "tree_w": 12, "tree_size": 64, "t0": 1.195, "t1": 0.325, "tft": 1.1623, "input_0": 184, "input_1": 65, "min_CLP": -4.47, "draft_iters": 13.2, "mem_use": 41.02, "gen_rate": 8.2, "speed": 5.45, "text": "\"Hi! Of course, I'd be happy to "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.7, "tree_w": 12, "tree_size": 64, "t0": 1.075, "t1": 0.3367, "tft": 4.0922, "input_0": 198, "input_1": 65, "min_CLP": -4.49, "draft_iters": 11.7, "mem_use": 43.6, "gen_rate": 6.0, "speed": 4.25, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.8, "tree_w": 11, "tree_size": 64, "t0": 1.132, "t1": 0.332, "tft": 3.5702, "input_0": 189, "input_1": 65, "min_CLP": -4.33, "draft_iters": 12.8, "mem_use": 44.18, "gen_rate": 7.0, "speed": 4.78, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.2, "tree_w": 9, "tree_size": 64, "t0": 1.262, "t1": 0.354, "tft": 4.3351, "input_0": 209, "input_1": 65, "min_CLP": -4.4, "draft_iters": 14.2, "mem_use": 46.33, "gen_rate": 7.6, "speed": 4.7, "text": "Sure, I can provide some advice "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.13, "t1": 0.334, "tft": 3.4158, "input_0": 209, "input_1": 65, "min_CLP": -4.5, "draft_iters": 12.2, "mem_use": 43.79, "gen_rate": 7.2, "speed": 4.92, "text": "Here is a list of the legal stat"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 1.116, "t1": 0.336, "tft": 2.7977, "input_0": 205, "input_1": 65, "min_CLP": -4.44, "draft_iters": 12.2, "mem_use": 43.18, "gen_rate": 7.8, "speed": 5.37, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.57, "t1": 0.33, "tft": 3.3128, "input_0": 180, "input_1": 65, "min_CLP": -5.12, "draft_iters": 32.0, "mem_use": 41.67, "gen_rate": 33.0, "speed": 11.36, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 13, "tree_size": 64, "t0": 1.168, "t1": 0.33, "tft": 3.1713, "input_0": 179, "input_1": 65, "min_CLP": -4.51, "draft_iters": 13.2, "mem_use": 43.54, "gen_rate": 6.6, "speed": 4.41, "text": "Sure, here\\'s a shorter summary:"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 19.0, "tree_w": 8, "tree_size": 64, "t0": 1.7733, "t1": 0.3333, "tft": 2.4673, "input_0": 248, "input_1": 65, "min_CLP": -4.13, "draft_iters": 20.0, "mem_use": 42.73, "gen_rate": 14.7, "speed": 6.96, "text": "Certainly! Here are some Python "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 7.5, "tree_w": 15, "tree_size": 64, "t0": 0.76, "t1": 0.325, "tft": 1.3468, "input_0": 128, "input_1": 65, "min_CLP": -4.79, "draft_iters": 8.5, "mem_use": 41.0, "gen_rate": 3.0, "speed": 2.78, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.2, "tree_w": 11, "tree_size": 64, "t0": 1.13, "t1": 0.338, "tft": 3.1095, "input_0": 219, "input_1": 65, "min_CLP": -4.59, "draft_iters": 12.2, "mem_use": 44.15, "gen_rate": 7.4, "speed": 5.04, "text": "\"If you only have an hour a day "}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.3, "tree_w": 12, "tree_size": 64, "t0": 1.3433, "t1": 0.33, "tft": 2.4254, "input_0": 175, "input_1": 65, "min_CLP": -4.55, "draft_iters": 15.3, "mem_use": 41.34, "gen_rate": 11.3, "speed": 6.77, "text": "The minimum broadband upload spe"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 17.7, "tree_w": 8, "tree_size": 64, "t0": 1.6333, "t1": 0.32, "tft": 1.6071, "input_0": 242, "input_1": 65, "min_CLP": -4.5, "draft_iters": 18.7, "mem_use": 41.02, "gen_rate": 16.7, "speed": 8.54, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 17.0, "tree_w": 11, "tree_size": 64, "t0": 1.5225, "t1": 0.315, "tft": 1.2432, "input_0": 205, "input_1": 65, "min_CLP": -4.5, "draft_iters": 18.0, "mem_use": 40.99, "gen_rate": 11.0, "speed": 5.98, "text": "Here\\'s a simple \"Hello, World!\""}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.2, "tree_w": 18, "tree_size": 64, "t0": 0.746, "t1": 0.326, "tft": 1.9598, "input_0": 128, "input_1": 65, "min_CLP": -4.71, "draft_iters": 8.2, "mem_use": 41.53, "gen_rate": 6.6, "speed": 6.15, "text": "D-theanine is a form of the amin"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 11, "tree_size": 64, "t0": 1.012, "t1": 0.32, "tft": 1.4384, "input_0": 174, "input_1": 65, "min_CLP": -4.73, "draft_iters": 11.4, "mem_use": 41.01, "gen_rate": 7.4, "speed": 5.57, "text": "The Balfour Declaration was a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 29, "tree_h": 6.9, "tree_w": 22, "tree_size": 64, "t0": 0.7087, "t1": 0.3225, "tft": 1.9466, "input_0": 135, "input_1": 65, "min_CLP": -5.66, "draft_iters": 7.9, "mem_use": 41.85, "gen_rate": 3.6, "speed": 3.51, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 15, "tree_h": 11.0, "tree_w": 17, "tree_size": 64, "t0": 1.0267, "t1": 0.3133, "tft": 1.244, "input_0": 142, "input_1": 65, "min_CLP": -5.01, "draft_iters": 12.0, "mem_use": 41.0, "gen_rate": 5.0, "speed": 3.72, "text": "Hello there, Obi-Wan Kenobi! How"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.4, "tree_w": 10, "tree_size": 64, "t0": 1.136, "t1": 0.334, "tft": 2.8383, "input_0": 213, "input_1": 65, "min_CLP": -4.36, "draft_iters": 12.4, "mem_use": 43.39, "gen_rate": 7.6, "speed": 5.18, "text": "For an asymmetric bimodal distri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.114, "t1": 0.328, "tft": 1.3777, "input_0": 169, "input_1": 65, "min_CLP": -4.47, "draft_iters": 12.4, "mem_use": 41.07, "gen_rate": 7.0, "speed": 4.87, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 13.3, "tree_w": 12, "tree_size": 64, "t0": 1.2533, "t1": 0.33, "tft": 2.2303, "input_0": 183, "input_1": 65, "min_CLP": -4.88, "draft_iters": 14.3, "mem_use": 42.04, "gen_rate": 12.7, "speed": 8.0, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 23.0, "tree_w": 13, "tree_size": 64, "t0": 1.965, "t1": 0.33, "tft": 1.2989, "input_0": 216, "input_1": 65, "min_CLP": -4.52, "draft_iters": 23.5, "mem_use": 41.04, "gen_rate": 18.0, "speed": 7.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.5, "tree_w": 18, "tree_size": 64, "t0": 0.7933, "t1": 0.3333, "tft": 2.1898, "input_0": 157, "input_1": 65, "min_CLP": -4.99, "draft_iters": 8.5, "mem_use": 41.71, "gen_rate": 6.0, "speed": 5.34, "text": "Austenite is a body-centered cub"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 13.7, "tree_w": 12, "tree_size": 64, "t0": 1.2933, "t1": 0.3283, "tft": 2.0447, "input_0": 191, "input_1": 65, "min_CLP": -4.49, "draft_iters": 14.7, "mem_use": 41.57, "gen_rate": 4.0, "speed": 2.47, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.8, "tree_w": 24, "tree_size": 64, "t0": 0.6267, "t1": 0.3322, "tft": 3.7908, "input_0": 119, "input_1": 65, "min_CLP": -5.29, "draft_iters": 6.8, "mem_use": 43.53, "gen_rate": 4.3, "speed": 4.52, "text": "\"Give me a moment, I\\'ll make a "}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 1.084, "t1": 0.324, "tft": 1.3884, "input_0": 184, "input_1": 65, "min_CLP": -4.48, "draft_iters": 12.2, "mem_use": 41.05, "gen_rate": 6.4, "speed": 4.55, "text": "Sure, here are some delicious op"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.5, "tree_w": 11, "tree_size": 64, "t0": 1.145, "t1": 0.3325, "tft": 2.364, "input_0": 189, "input_1": 65, "min_CLP": -4.69, "draft_iters": 12.5, "mem_use": 41.75, "gen_rate": 10.0, "speed": 6.77, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.0, "tree_w": 14, "tree_size": 64, "t0": 1.185, "t1": 0.3275, "tft": 1.9226, "input_0": 165, "input_1": 65, "min_CLP": -4.57, "draft_iters": 14.0, "mem_use": 42.16, "gen_rate": 8.5, "speed": 5.62, "text": "[API_REQUEST]: {curl -X POST -H "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.8137, "t1": 0.3263, "tft": 1.5968, "input_0": 137, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.0, "mem_use": 41.51, "gen_rate": 4.2, "speed": 3.73, "text": "As the goddess of fertility and "}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.7, "tree_w": 14, "tree_size": 64, "t0": 0.9571, "t1": 0.3343, "tft": 4.3285, "input_0": 161, "input_1": 65, "min_CLP": -4.86, "draft_iters": 10.7, "mem_use": 43.2, "gen_rate": 4.7, "speed": 3.65, "text": "Yes, there is a substitute for c"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.04, "t1": 0.334, "tft": 2.4418, "input_0": 206, "input_1": 65, "min_CLP": -4.42, "draft_iters": 11.0, "mem_use": 43.24, "gen_rate": 7.6, "speed": 5.54, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.6, "tree_w": 11, "tree_size": 64, "t0": 1.222, "t1": 0.352, "tft": 4.5464, "input_0": 218, "input_1": 65, "min_CLP": -4.27, "draft_iters": 13.6, "mem_use": 45.92, "gen_rate": 7.4, "speed": 4.69, "text": "Selenium is a popular choice for"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 20, "tree_size": 64, "t0": 0.816, "t1": 0.32, "tft": 1.8258, "input_0": 157, "input_1": 65, "min_CLP": -4.84, "draft_iters": 8.8, "mem_use": 41.03, "gen_rate": 6.4, "speed": 5.64, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 54, "tree_h": 11.2, "tree_w": 18, "tree_size": 64, "t0": 1.06, "t1": 0.334, "tft": 2.9354, "input_0": 141, "input_1": 65, "min_CLP": -4.99, "draft_iters": 12.0, "mem_use": 41.56, "gen_rate": 10.8, "speed": 7.75, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 17, "tree_size": 64, "t0": 0.925, "t1": 0.3333, "tft": 4.7177, "input_0": 160, "input_1": 65, "min_CLP": -4.88, "draft_iters": 10.3, "mem_use": 43.96, "gen_rate": 5.7, "speed": 4.51, "text": "\"I appreciate your interest in t"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 16.2, "tree_w": 8, "tree_size": 64, "t0": 1.5075, "t1": 0.33, "tft": 3.0321, "input_0": 214, "input_1": 65, "min_CLP": -4.15, "draft_iters": 17.2, "mem_use": 41.96, "gen_rate": 9.8, "speed": 5.31, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.0, "tree_w": 25, "tree_size": 64, "t0": 0.6511, "t1": 0.3267, "tft": 1.3296, "input_0": 126, "input_1": 65, "min_CLP": -5.33, "draft_iters": 7.0, "mem_use": 41.26, "gen_rate": 3.8, "speed": 3.86, "text": "\"Foolish mortal, you cannot comm"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 14.2, "tree_w": 11, "tree_size": 64, "t0": 1.298, "t1": 0.33, "tft": 4.537, "input_0": 165, "input_1": 65, "min_CLP": -4.53, "draft_iters": 15.2, "mem_use": 43.78, "gen_rate": 8.6, "speed": 5.28, "text": "In what ways does the monologue "}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 11.5, "tree_w": 17, "tree_size": 64, "t0": 1.09, "t1": 0.3387, "tft": 3.4349, "input_0": 156, "input_1": 65, "min_CLP": -4.9, "draft_iters": 12.5, "mem_use": 44.2, "gen_rate": 4.9, "speed": 3.41, "text": "\"[INST] Thank you. I will start "}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.2, "tree_w": 8, "tree_size": 64, "t0": 1.2275, "t1": 0.3375, "tft": 2.3085, "input_0": 216, "input_1": 65, "min_CLP": -4.07, "draft_iters": 13.2, "mem_use": 42.53, "gen_rate": 9.0, "speed": 5.77, "text": "It\\'s difficult to say which one"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 19, "tree_h": 18.0, "tree_w": 8, "tree_size": 64, "t0": 1.715, "t1": 0.32, "tft": 2.4538, "input_0": 298, "input_1": 65, "min_CLP": -4.15, "draft_iters": 19.0, "mem_use": 41.79, "gen_rate": 9.5, "speed": 4.66, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 31.5, "tree_w": 12, "tree_size": 64, "t0": 2.555, "t1": 0.33, "tft": 2.4922, "input_0": 176, "input_1": 65, "min_CLP": -4.97, "draft_iters": 32.0, "mem_use": 41.52, "gen_rate": 19.0, "speed": 6.58, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.3, "tree_w": 7, "tree_size": 64, "t0": 1.5767, "t1": 0.32, "tft": 1.293, "input_0": 231, "input_1": 65, "min_CLP": -4.74, "draft_iters": 18.3, "mem_use": 41.03, "gen_rate": 12.0, "speed": 6.35, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 17.8, "tree_w": 10, "tree_size": 64, "t0": 1.5575, "t1": 0.35, "tft": 4.5936, "input_0": 189, "input_1": 65, "min_CLP": -4.95, "draft_iters": 18.5, "mem_use": 46.47, "gen_rate": 12.8, "speed": 6.69, "text": "\"Here's a revised version of the"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 22, "tree_size": 64, "t0": 0.5757, "t1": 0.33, "tft": 1.9025, "input_0": 112, "input_1": 65, "min_CLP": -5.47, "draft_iters": 6.3, "mem_use": 42.77, "gen_rate": 4.9, "speed": 5.36, "text": "\"You see, the Void is not just a"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 13, "tree_h": 10.5, "tree_w": 12, "tree_size": 64, "t0": 1.0125, "t1": 0.3275, "tft": 1.4919, "input_0": 153, "input_1": 65, "min_CLP": -4.53, "draft_iters": 11.5, "mem_use": 41.79, "gen_rate": 3.2, "speed": 2.43, "text": "If you have any other questions "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 14.5, "tree_w": 13, "tree_size": 64, "t0": 1.3325, "t1": 0.3225, "tft": 1.4366, "input_0": 181, "input_1": 65, "min_CLP": -5.07, "draft_iters": 15.2, "mem_use": 41.31, "gen_rate": 12.5, "speed": 7.56, "text": "\u70b9\u51fb\u7387\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002[INST]"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 8, "tree_size": 64, "t0": 1.865, "t1": 0.33, "tft": 2.6939, "input_0": 233, "input_1": 65, "min_CLP": -4.24, "draft_iters": 22.0, "mem_use": 43.24, "gen_rate": 22.5, "speed": 10.23, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.0, "tree_w": 11, "tree_size": 64, "t0": 1.22, "t1": 0.33, "tft": 2.937, "input_0": 195, "input_1": 65, "min_CLP": -4.53, "draft_iters": 14.0, "mem_use": 42.41, "gen_rate": 9.2, "speed": 5.96, "text": "Sure, here are some more histori"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 14, "tree_size": 64, "t0": 1.044, "t1": 0.332, "tft": 2.8306, "input_0": 154, "input_1": 65, "min_CLP": -4.59, "draft_iters": 12.0, "mem_use": 42.75, "gen_rate": 6.8, "speed": 4.95, "text": "\"I'm glad you liked my response."}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.1, "tree_w": 17, "tree_size": 64, "t0": 0.7743, "t1": 0.3229, "tft": 1.1931, "input_0": 134, "input_1": 65, "min_CLP": -4.91, "draft_iters": 8.1, "mem_use": 41.2, "gen_rate": 5.1, "speed": 4.69, "text": "The phrase \"Who wears short shor"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 19, "tree_size": 64, "t0": 0.7457, "t1": 0.3314, "tft": 3.114, "input_0": 135, "input_1": 65, "min_CLP": -5.05, "draft_iters": 8.3, "mem_use": 43.63, "gen_rate": 4.9, "speed": 4.52, "text": "FullView.io is a powerful platfo"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.005, "t1": 0.3317, "tft": 4.691, "input_0": 195, "input_1": 65, "min_CLP": -4.61, "draft_iters": 11.0, "mem_use": 44.86, "gen_rate": 6.3, "speed": 4.74, "text": "You are correct. Thank you for p"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 1.0, "t1": 0.335, "tft": 4.1553, "input_0": 209, "input_1": 65, "min_CLP": -4.55, "draft_iters": 10.8, "mem_use": 45.03, "gen_rate": 8.0, "speed": 5.98, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.3, "tree_w": 11, "tree_size": 64, "t0": 1.24, "t1": 0.3333, "tft": 2.8767, "input_0": 181, "input_1": 65, "min_CLP": -4.56, "draft_iters": 14.3, "mem_use": 42.68, "gen_rate": 10.7, "speed": 6.77, "text": "\"I am an AI language model and d"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.0, "tree_w": 13, "tree_size": 64, "t0": 1.196, "t1": 0.32, "tft": 1.0991, "input_0": 169, "input_1": 65, "min_CLP": -5.12, "draft_iters": 14.0, "mem_use": 41.03, "gen_rate": 7.6, "speed": 5.03, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 47, "tree_h": 12.0, "tree_w": 15, "tree_size": 64, "t0": 1.125, "t1": 0.325, "tft": 2.9038, "input_0": 171, "input_1": 65, "min_CLP": -4.83, "draft_iters": 13.0, "mem_use": 43.46, "gen_rate": 5.9, "speed": 4.04, "text": "Understood. Thank you for clarif"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.3, "tree_w": 13, "tree_size": 64, "t0": 0.9383, "t1": 0.3317, "tft": 3.8116, "input_0": 190, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.3, "mem_use": 44.29, "gen_rate": 6.3, "speed": 4.98, "text": "\"[The scene opens with the Spart"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 0.8817, "t1": 0.3267, "tft": 1.534, "input_0": 143, "input_1": 65, "min_CLP": -4.65, "draft_iters": 9.8, "mem_use": 41.97, "gen_rate": 6.3, "speed": 5.24, "text": "\"Yeah, I agree. Mnemonics can be"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 6.6, "tree_w": 23, "tree_size": 64, "t0": 0.687, "t1": 0.328, "tft": 1.6545, "input_0": 110, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.6, "mem_use": 41.69, "gen_rate": 3.8, "speed": 3.75, "text": "The proof-of-stake concept is si"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.7, "tree_w": 25, "tree_size": 64, "t0": 0.53, "t1": 0.332, "tft": 1.8552, "input_0": 95, "input_1": 65, "min_CLP": -5.35, "draft_iters": 5.7, "mem_use": 41.81, "gen_rate": 3.2, "speed": 3.7, "text": "It might be difficult to explain"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.9, "tree_w": 11, "tree_size": 64, "t0": 0.9829, "t1": 0.3371, "tft": 3.4119, "input_0": 177, "input_1": 65, "min_CLP": -4.61, "draft_iters": 10.9, "mem_use": 43.91, "gen_rate": 5.4, "speed": 4.11, "text": "Void pointers are pointers that "}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 13, "tree_size": 64, "t0": 0.882, "t1": 0.336, "tft": 3.2365, "input_0": 144, "input_1": 65, "min_CLP": -4.59, "draft_iters": 9.8, "mem_use": 44.41, "gen_rate": 6.8, "speed": 5.59, "text": "\"I'm sorry, but I can't help you"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.5, "tree_w": 9, "tree_size": 64, "t0": 1.31, "t1": 0.335, "tft": 3.257, "input_0": 224, "input_1": 65, "min_CLP": -4.48, "draft_iters": 14.5, "mem_use": 43.64, "gen_rate": 10.2, "speed": 6.24, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 15, "tree_h": 11.8, "tree_w": 12, "tree_size": 64, "t0": 1.14, "t1": 0.322, "tft": 2.0229, "input_0": 200, "input_1": 65, "min_CLP": -4.7, "draft_iters": 12.8, "mem_use": 41.44, "gen_rate": 3.0, "speed": 2.05, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.0075, "t1": 0.325, "tft": 1.6131, "input_0": 181, "input_1": 65, "min_CLP": -4.79, "draft_iters": 11.0, "mem_use": 41.03, "gen_rate": 8.0, "speed": 6.0, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 31.5, "tree_w": 4, "tree_size": 64, "t0": 2.635, "t1": 0.325, "tft": 4.1971, "input_0": 261, "input_1": 65, "min_CLP": -3.47, "draft_iters": 32.0, "mem_use": 43.87, "gen_rate": 21.0, "speed": 7.1, "text": "\"Sure, here's the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 17, "tree_size": 64, "t0": 0.93, "t1": 0.3217, "tft": 1.0245, "input_0": 155, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.2, "mem_use": 40.98, "gen_rate": 5.8, "speed": 4.67, "text": "The person who made Berlin was a"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.54, "t1": 0.32, "tft": 2.5799, "input_0": 195, "input_1": 65, "min_CLP": -4.78, "draft_iters": 32.0, "mem_use": 43.34, "gen_rate": 33.0, "speed": 11.54, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 9, "tree_size": 64, "t0": 1.205, "t1": 0.33, "tft": 3.0269, "input_0": 202, "input_1": 65, "min_CLP": -4.42, "draft_iters": 13.5, "mem_use": 43.2, "gen_rate": 9.2, "speed": 6.02, "text": "Certainly. Some of the criticism"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.4, "tree_w": 16, "tree_size": 64, "t0": 0.8688, "t1": 0.32, "tft": 1.3936, "input_0": 163, "input_1": 65, "min_CLP": -4.99, "draft_iters": 9.4, "mem_use": 40.99, "gen_rate": 4.0, "speed": 3.36, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 14, "tree_size": 64, "t0": 0.976, "t1": 0.33, "tft": 3.181, "input_0": 148, "input_1": 65, "min_CLP": -5.13, "draft_iters": 11.0, "mem_use": 41.31, "gen_rate": 7.0, "speed": 5.36, "text": "\"You can visit at The World Cloc"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 19, "tree_size": 64, "t0": 0.7867, "t1": 0.325, "tft": 1.4771, "input_0": 117, "input_1": 65, "min_CLP": -5.08, "draft_iters": 8.8, "mem_use": 41.39, "gen_rate": 6.0, "speed": 5.4, "text": "The five second rule is not a sc"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 6, "tree_h": 8.3, "tree_w": 16, "tree_size": 64, "t0": 0.8667, "t1": 0.3267, "tft": 1.3145, "input_0": 148, "input_1": 65, "min_CLP": -4.75, "draft_iters": 9.3, "mem_use": 41.11, "gen_rate": 2.0, "speed": 1.68, "text": "You have 5 eggs left."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 16.0, "tree_w": 8, "tree_size": 64, "t0": 1.494, "t1": 0.328, "tft": 2.4492, "input_0": 220, "input_1": 65, "min_CLP": -4.01, "draft_iters": 17.0, "mem_use": 41.86, "gen_rate": 7.8, "speed": 4.28, "text": "\"Sure, I'll try to explain a cou"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 18, "tree_size": 64, "t0": 0.7814, "t1": 0.3314, "tft": 1.8259, "input_0": 133, "input_1": 65, "min_CLP": -4.94, "draft_iters": 8.4, "mem_use": 41.43, "gen_rate": 4.7, "speed": 4.24, "text": "\"No problem, it's possible the m"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 10.1, "tree_w": 13, "tree_size": 64, "t0": 1.0063, "t1": 0.3275, "tft": 1.9365, "input_0": 175, "input_1": 65, "min_CLP": -4.64, "draft_iters": 11.1, "mem_use": 41.14, "gen_rate": 4.1, "speed": 3.1, "text": "Here\\'s a draft announcement twe"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 0.885, "t1": 0.325, "tft": 2.2913, "input_0": 157, "input_1": 65, "min_CLP": -4.98, "draft_iters": 9.8, "mem_use": 41.76, "gen_rate": 8.0, "speed": 6.6, "text": "One example of sexual selection "}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 1.185, "t1": 0.335, "tft": 2.4534, "input_0": 205, "input_1": 65, "min_CLP": -4.27, "draft_iters": 13.0, "mem_use": 42.8, "gen_rate": 8.8, "speed": 5.76, "text": "AI assistants can also be very h"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.5, "tree_w": 11, "tree_size": 64, "t0": 1.665, "t1": 0.33, "tft": 3.1988, "input_0": 186, "input_1": 65, "min_CLP": -5.45, "draft_iters": 20.0, "mem_use": 43.84, "gen_rate": 17.5, "speed": 8.79, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 12, "tree_size": 64, "t0": 1.036, "t1": 0.336, "tft": 2.0208, "input_0": 185, "input_1": 65, "min_CLP": -4.33, "draft_iters": 11.4, "mem_use": 42.31, "gen_rate": 7.4, "speed": 5.38, "text": "The scp command is a Unix-based "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 2.56, "t1": 0.32, "tft": 2.7814, "input_0": 238, "input_1": 65, "min_CLP": -4.71, "draft_iters": 32.0, "mem_use": 43.0, "gen_rate": 33.0, "speed": 11.46, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 16, "tree_size": 64, "t0": 0.87, "t1": 0.3217, "tft": 1.3544, "input_0": 144, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.7, "mem_use": 41.05, "gen_rate": 5.8, "speed": 4.89, "text": "No, it is not illegal to keep a "}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 11, "tree_size": 64, "t0": 1.12, "t1": 0.322, "tft": 2.3459, "input_0": 169, "input_1": 65, "min_CLP": -4.72, "draft_iters": 12.8, "mem_use": 41.34, "gen_rate": 6.8, "speed": 4.72, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 19.8, "tree_w": 12, "tree_size": 64, "t0": 1.7, "t1": 0.3225, "tft": 2.0846, "input_0": 204, "input_1": 65, "min_CLP": -5.16, "draft_iters": 20.2, "mem_use": 41.64, "gen_rate": 11.5, "speed": 5.68, "text": "\"Is 5 second rule a game? [\\\\INS"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.6613, "t1": 0.32, "tft": 1.4708, "input_0": 127, "input_1": 65, "min_CLP": -5.05, "draft_iters": 7.1, "mem_use": 41.31, "gen_rate": 4.2, "speed": 4.34, "text": "\"Hey, don't worry about it too m"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 2.54, "t1": 0.33, "tft": 1.2839, "input_0": 190, "input_1": 65, "min_CLP": -4.44, "draft_iters": 32.0, "mem_use": 41.08, "gen_rate": 33.0, "speed": 11.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 0.8962, "t1": 0.3187, "tft": 1.2246, "input_0": 177, "input_1": 65, "min_CLP": -4.74, "draft_iters": 9.8, "mem_use": 41.06, "gen_rate": 4.2, "speed": 3.5, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 19.8, "tree_w": 8, "tree_size": 64, "t0": 1.82, "t1": 0.336, "tft": 2.902, "input_0": 262, "input_1": 65, "min_CLP": -4.14, "draft_iters": 20.8, "mem_use": 42.8, "gen_rate": 8.4, "speed": 3.9, "text": "\"Sure, I'd be happy to explain i"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 14.2, "tree_w": 12, "tree_size": 64, "t0": 1.3383, "t1": 0.325, "tft": 1.4249, "input_0": 192, "input_1": 65, "min_CLP": -4.55, "draft_iters": 15.2, "mem_use": 41.06, "gen_rate": 5.3, "speed": 3.21, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.7, "tree_w": 9, "tree_size": 64, "t0": 1.9, "t1": 0.33, "tft": 1.2823, "input_0": 240, "input_1": 65, "min_CLP": -4.18, "draft_iters": 21.7, "mem_use": 41.37, "gen_rate": 12.3, "speed": 5.54, "text": "To create a first person control"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.11, "t1": 0.32, "tft": 1.829, "input_0": 201, "input_1": 65, "min_CLP": -4.28, "draft_iters": 12.2, "mem_use": 41.03, "gen_rate": 6.6, "speed": 4.64, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 17, "tree_size": 64, "t0": 0.85, "t1": 0.32, "tft": 1.4237, "input_0": 146, "input_1": 65, "min_CLP": -4.89, "draft_iters": 9.7, "mem_use": 41.34, "gen_rate": 6.0, "speed": 5.13, "text": "There is no need for violence, y"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 18, "tree_size": 64, "t0": 0.71, "t1": 0.3238, "tft": 1.7047, "input_0": 146, "input_1": 65, "min_CLP": -4.83, "draft_iters": 7.5, "mem_use": 41.2, "gen_rate": 4.0, "speed": 3.87, "text": "\"A gas-operated rifle is a type "}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.2, "tree_w": 12, "tree_size": 64, "t0": 1.022, "t1": 0.324, "tft": 1.7383, "input_0": 180, "input_1": 65, "min_CLP": -4.93, "draft_iters": 11.2, "mem_use": 41.44, "gen_rate": 7.2, "speed": 5.35, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.6, "tree_w": 13, "tree_size": 64, "t0": 0.9971, "t1": 0.3429, "tft": 3.2219, "input_0": 189, "input_1": 65, "min_CLP": -4.62, "draft_iters": 10.6, "mem_use": 44.31, "gen_rate": 5.0, "speed": 3.74, "text": "\"Yes, you're right that a naive "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 15, "tree_size": 64, "t0": 0.8933, "t1": 0.33, "tft": 2.0325, "input_0": 154, "input_1": 65, "min_CLP": -4.8, "draft_iters": 9.7, "mem_use": 41.51, "gen_rate": 6.0, "speed": 4.92, "text": "Yes, it is common for people who"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 13.5, "tree_w": 17, "tree_size": 64, "t0": 1.22, "t1": 0.33, "tft": 3.3975, "input_0": 134, "input_1": 65, "min_CLP": -5.03, "draft_iters": 14.5, "mem_use": 44.41, "gen_rate": 3.0, "speed": 1.94, "text": "Xin ch\u00e0o! T\u00ean b\u1ea1n l\u00e0 g\u00ec?"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.1, "tree_w": 21, "tree_size": 64, "t0": 0.8011, "t1": 0.3256, "tft": 1.9007, "input_0": 116, "input_1": 65, "min_CLP": -5.01, "draft_iters": 9.1, "mem_use": 41.87, "gen_rate": 3.9, "speed": 3.45, "text": "\"So, a lot of people were fooled"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 20.3, "tree_w": 8, "tree_size": 64, "t0": 1.7967, "t1": 0.3233, "tft": 1.5175, "input_0": 242, "input_1": 65, "min_CLP": -4.06, "draft_iters": 21.0, "mem_use": 41.39, "gen_rate": 16.7, "speed": 7.87, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.2, "tree_w": 17, "tree_size": 64, "t0": 0.925, "t1": 0.335, "tft": 2.3769, "input_0": 158, "input_1": 65, "min_CLP": -4.98, "draft_iters": 10.2, "mem_use": 42.82, "gen_rate": 8.0, "speed": 6.34, "text": "1. Scorpions\\n2. Rammstein\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.3, "tree_w": 22, "tree_size": 64, "t0": 0.7656, "t1": 0.3222, "tft": 2.0721, "input_0": 146, "input_1": 65, "min_CLP": -5.03, "draft_iters": 8.3, "mem_use": 41.36, "gen_rate": 3.9, "speed": 3.57, "text": "The best strategy to win a thumb"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.4, "tree_w": 11, "tree_size": 64, "t0": 1.196, "t1": 0.332, "tft": 2.9411, "input_0": 197, "input_1": 65, "min_CLP": -4.27, "draft_iters": 13.4, "mem_use": 43.39, "gen_rate": 7.0, "speed": 4.58, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.5, "tree_w": 14, "tree_size": 64, "t0": 1.0233, "t1": 0.3283, "tft": 1.5894, "input_0": 151, "input_1": 65, "min_CLP": -4.73, "draft_iters": 11.5, "mem_use": 41.98, "gen_rate": 6.2, "speed": 4.56, "text": "As a large language model, I am "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.3, "tree_w": 15, "tree_size": 64, "t0": 1.2467, "t1": 0.33, "tft": 1.7598, "input_0": 157, "input_1": 65, "min_CLP": -4.53, "draft_iters": 14.3, "mem_use": 41.52, "gen_rate": 11.0, "speed": 6.96, "text": "I understand your request. Here "}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 10, "tree_size": 64, "t0": 1.1825, "t1": 0.335, "tft": 2.0596, "input_0": 202, "input_1": 65, "min_CLP": -4.4, "draft_iters": 12.2, "mem_use": 41.66, "gen_rate": 8.5, "speed": 5.61, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 22, "tree_size": 64, "t0": 0.7683, "t1": 0.3283, "tft": 2.774, "input_0": 132, "input_1": 65, "min_CLP": -5.45, "draft_iters": 8.7, "mem_use": 42.93, "gen_rate": 5.8, "speed": 5.31, "text": "\"Certainly! Here's a poem in Que"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.7, "tree_w": 7, "tree_size": 64, "t0": 1.5833, "t1": 0.3267, "tft": 1.3902, "input_0": 243, "input_1": 65, "min_CLP": -4.22, "draft_iters": 17.7, "mem_use": 41.03, "gen_rate": 10.7, "speed": 5.59, "text": "\"Sure, I'd be happy to help! Her"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 15, "tree_size": 64, "t0": 0.7417, "t1": 0.3217, "tft": 1.2329, "input_0": 147, "input_1": 65, "min_CLP": -4.68, "draft_iters": 7.8, "mem_use": 41.07, "gen_rate": 5.3, "speed": 5.02, "text": "The error in the code is that th"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.2, "tree_w": 20, "tree_size": 64, "t0": 0.7567, "t1": 0.3356, "tft": 2.2325, "input_0": 134, "input_1": 65, "min_CLP": -5.04, "draft_iters": 8.2, "mem_use": 42.46, "gen_rate": 4.0, "speed": 3.66, "text": "As a helpful assistant, I must r"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.04, "t1": 0.328, "tft": 1.835, "input_0": 164, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.6, "mem_use": 41.68, "gen_rate": 7.0, "speed": 5.11, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.8, "tree_w": 9, "tree_size": 64, "t0": 1.398, "t1": 0.328, "tft": 1.788, "input_0": 212, "input_1": 65, "min_CLP": -4.05, "draft_iters": 15.8, "mem_use": 41.8, "gen_rate": 8.2, "speed": 4.74, "text": "\"To create a Python script that "}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 14, "tree_size": 64, "t0": 0.8486, "t1": 0.33, "tft": 2.7163, "input_0": 158, "input_1": 65, "min_CLP": -4.56, "draft_iters": 9.3, "mem_use": 43.61, "gen_rate": 4.7, "speed": 4.0, "text": "\"If you're feeling hesitant abou"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.8, "tree_w": 14, "tree_size": 64, "t0": 1.525, "t1": 0.3225, "tft": 2.1525, "input_0": 205, "input_1": 65, "min_CLP": -4.6, "draft_iters": 17.8, "mem_use": 41.59, "gen_rate": 9.5, "speed": 5.14, "text": "Great idea! Here\\'s the updated "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 20.2, "tree_w": 6, "tree_size": 64, "t0": 1.788, "t1": 0.328, "tft": 4.2114, "input_0": 227, "input_1": 65, "min_CLP": -4.03, "draft_iters": 21.2, "mem_use": 42.99, "gen_rate": 8.8, "speed": 4.16, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 14, "tree_size": 64, "t0": 0.8317, "t1": 0.3233, "tft": 1.4638, "input_0": 155, "input_1": 65, "min_CLP": -4.75, "draft_iters": 9.0, "mem_use": 41.01, "gen_rate": 5.5, "speed": 4.77, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 16.1, "tree_w": 19, "tree_size": 64, "t0": 1.4375, "t1": 0.335, "tft": 1.94, "input_0": 132, "input_1": 65, "min_CLP": -5.38, "draft_iters": 16.9, "mem_use": 41.24, "gen_rate": 4.2, "speed": 2.4, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 8.9, "tree_w": 17, "tree_size": 64, "t0": 0.9156, "t1": 0.3278, "tft": 1.9093, "input_0": 167, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.9, "mem_use": 41.48, "gen_rate": 3.8, "speed": 3.04, "text": "\"Thank you! I'm here to help if "}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.0, "tree_w": 13, "tree_size": 64, "t0": 1.135, "t1": 0.3367, "tft": 2.8293, "input_0": 156, "input_1": 65, "min_CLP": -5.09, "draft_iters": 13.0, "mem_use": 43.11, "gen_rate": 5.5, "speed": 3.74, "text": "\"Thou art the sun that shineth b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 16.2, "tree_w": 13, "tree_size": 64, "t0": 1.485, "t1": 0.33, "tft": 1.917, "input_0": 194, "input_1": 65, "min_CLP": -4.96, "draft_iters": 17.0, "mem_use": 41.66, "gen_rate": 11.5, "speed": 6.33, "text": "[INST] Please provide a source r"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.8, "tree_w": 10, "tree_size": 64, "t0": 1.26, "t1": 0.326, "tft": 1.3782, "input_0": 205, "input_1": 65, "min_CLP": -4.3, "draft_iters": 13.8, "mem_use": 41.05, "gen_rate": 8.2, "speed": 5.18, "text": "Certainly! Here are some words i"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.01, "t1": 0.3257, "tft": 1.3441, "input_0": 176, "input_1": 65, "min_CLP": -4.52, "draft_iters": 11.0, "mem_use": 41.03, "gen_rate": 4.6, "speed": 3.43, "text": "Presidents\u2019 Day is an American h"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 0.9186, "t1": 0.3243, "tft": 1.8395, "input_0": 138, "input_1": 65, "min_CLP": -4.75, "draft_iters": 10.3, "mem_use": 41.34, "gen_rate": 4.9, "speed": 3.91, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.5, "tree_w": 13, "tree_size": 64, "t0": 1.11, "t1": 0.3325, "tft": 2.8993, "input_0": 174, "input_1": 65, "min_CLP": -4.6, "draft_iters": 12.5, "mem_use": 42.14, "gen_rate": 8.2, "speed": 5.72, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.7, "tree_w": 20, "tree_size": 64, "t0": 0.7144, "t1": 0.3222, "tft": 1.6613, "input_0": 136, "input_1": 65, "min_CLP": -5.15, "draft_iters": 7.7, "mem_use": 41.41, "gen_rate": 3.7, "speed": 3.54, "text": "\"Why was the Windows computer so"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.8, "tree_w": 17, "tree_size": 64, "t0": 0.8187, "t1": 0.3288, "tft": 1.6701, "input_0": 145, "input_1": 65, "min_CLP": -4.97, "draft_iters": 8.8, "mem_use": 41.48, "gen_rate": 4.1, "speed": 3.6, "text": "\"Well then, I'll be Opie for thi"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.0, "tree_w": 16, "tree_size": 64, "t0": 1.615, "t1": 0.325, "tft": 1.3029, "input_0": 172, "input_1": 65, "min_CLP": -5.74, "draft_iters": 19.5, "mem_use": 41.03, "gen_rate": 17.5, "speed": 9.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 22, "tree_size": 64, "t0": 0.675, "t1": 0.3275, "tft": 2.3916, "input_0": 109, "input_1": 65, "min_CLP": -5.09, "draft_iters": 7.5, "mem_use": 41.72, "gen_rate": 4.1, "speed": 4.12, "text": "\"Who\\'s Ted Kaczynski? And what,"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 7.9, "tree_w": 19, "tree_size": 64, "t0": 0.806, "t1": 0.319, "tft": 1.3822, "input_0": 144, "input_1": 65, "min_CLP": -5.08, "draft_iters": 8.9, "mem_use": 41.15, "gen_rate": 3.9, "speed": 3.48, "text": "The mayonnaise might have broken"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 14, "tree_size": 64, "t0": 1.044, "t1": 0.334, "tft": 2.0723, "input_0": 184, "input_1": 65, "min_CLP": -4.9, "draft_iters": 11.6, "mem_use": 42.38, "gen_rate": 6.6, "speed": 4.79, "text": "Sure, here are a few examples:\\n"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.5, "tree_w": 22, "tree_size": 64, "t0": 0.6713, "t1": 0.32, "tft": 1.7112, "input_0": 122, "input_1": 65, "min_CLP": -5.14, "draft_iters": 7.5, "mem_use": 41.48, "gen_rate": 4.4, "speed": 4.41, "text": "\"Hey, I\u2019m just here to help you."}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.064, "t1": 0.33, "tft": 2.923, "input_0": 174, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.2, "mem_use": 42.68, "gen_rate": 6.4, "speed": 4.6, "text": "Based on your interest in scenic"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.4, "tree_w": 20, "tree_size": 64, "t0": 0.8371, "t1": 0.32, "tft": 2.0518, "input_0": 149, "input_1": 65, "min_CLP": -4.91, "draft_iters": 9.4, "mem_use": 41.43, "gen_rate": 4.6, "speed": 3.96, "text": "\"Open Assistant: Introducing an "}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 9.5, "tree_w": 14, "tree_size": 64, "t0": 0.9512, "t1": 0.3225, "tft": 1.627, "input_0": 158, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.5, "mem_use": 41.33, "gen_rate": 4.8, "speed": 3.73, "text": "\"Sure! Here's a simple illustrat"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 0.99, "t1": 0.3283, "tft": 2.9449, "input_0": 186, "input_1": 65, "min_CLP": -4.67, "draft_iters": 11.0, "mem_use": 43.69, "gen_rate": 5.3, "speed": 4.05, "text": "This is most likely due to the f"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 10, "tree_size": 64, "t0": 1.1533, "t1": 0.32, "tft": 1.1803, "input_0": 160, "input_1": 65, "min_CLP": -4.59, "draft_iters": 13.0, "mem_use": 41.02, "gen_rate": 10.7, "speed": 7.26, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 21, "tree_size": 64, "t0": 0.6186, "t1": 0.3214, "tft": 1.6427, "input_0": 104, "input_1": 65, "min_CLP": -5.25, "draft_iters": 7.0, "mem_use": 41.57, "gen_rate": 4.9, "speed": 5.15, "text": "\"I think you're missing the poin"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.7, "tree_w": 15, "tree_size": 64, "t0": 0.9533, "t1": 0.32, "tft": 2.1494, "input_0": 155, "input_1": 65, "min_CLP": -4.81, "draft_iters": 10.7, "mem_use": 41.2, "gen_rate": 5.3, "speed": 4.19, "text": "The second batch of pancakes bro"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.5, "tree_w": 13, "tree_size": 64, "t0": 1.655, "t1": 0.315, "tft": 1.1327, "input_0": 179, "input_1": 65, "min_CLP": -5.1, "draft_iters": 20.0, "mem_use": 41.03, "gen_rate": 17.5, "speed": 8.88, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 13, "tree_size": 64, "t0": 0.976, "t1": 0.332, "tft": 2.9216, "input_0": 188, "input_1": 65, "min_CLP": -4.67, "draft_iters": 10.6, "mem_use": 43.15, "gen_rate": 7.0, "speed": 5.35, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 15, "tree_size": 64, "t0": 0.868, "t1": 0.32, "tft": 1.451, "input_0": 157, "input_1": 65, "min_CLP": -5.09, "draft_iters": 9.6, "mem_use": 40.99, "gen_rate": 6.4, "speed": 5.4, "text": "\"No, a thumb war is not violent."}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 18.0, "tree_w": 12, "tree_size": 64, "t0": 1.5825, "t1": 0.32, "tft": 1.3063, "input_0": 196, "input_1": 65, "min_CLP": -4.85, "draft_iters": 18.8, "mem_use": 41.08, "gen_rate": 14.2, "speed": 7.5, "text": "Rick Astley\\'s third verse in \"N"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 1.08, "t1": 0.33, "tft": 3.3031, "input_0": 187, "input_1": 65, "min_CLP": -4.51, "draft_iters": 12.2, "mem_use": 44.37, "gen_rate": 6.6, "speed": 4.68, "text": "The most marijuana-friendly coun"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 14, "tree_size": 64, "t0": 1.04, "t1": 0.3375, "tft": 2.2132, "input_0": 179, "input_1": 65, "min_CLP": -4.57, "draft_iters": 11.5, "mem_use": 42.34, "gen_rate": 8.0, "speed": 5.8, "text": "I understand that you want me to"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.5, "tree_w": 7, "tree_size": 64, "t0": 1.31, "t1": 0.32, "tft": 1.2886, "input_0": 226, "input_1": 65, "min_CLP": -4.48, "draft_iters": 14.5, "mem_use": 41.29, "gen_rate": 10.0, "speed": 6.13, "text": "There are several resources avai"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.2, "tree_w": 14, "tree_size": 64, "t0": 0.91, "t1": 0.32, "tft": 1.3253, "input_0": 156, "input_1": 65, "min_CLP": -4.92, "draft_iters": 10.2, "mem_use": 41.27, "gen_rate": 5.7, "speed": 4.61, "text": "Tax fraud is a serious crime tha"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 2.52, "t1": 0.32, "tft": 1.2063, "input_0": 164, "input_1": 65, "min_CLP": -5.5, "draft_iters": 32.0, "mem_use": 41.03, "gen_rate": 33.0, "speed": 11.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 15, "tree_size": 64, "t0": 0.7917, "t1": 0.3233, "tft": 2.3885, "input_0": 132, "input_1": 65, "min_CLP": -4.82, "draft_iters": 8.8, "mem_use": 41.85, "gen_rate": 5.3, "speed": 4.79, "text": "\"I'm sorry, I cannot draw ASCII "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 20.5, "tree_w": 9, "tree_size": 64, "t0": 1.815, "t1": 0.33, "tft": 3.4984, "input_0": 246, "input_1": 65, "min_CLP": -4.76, "draft_iters": 21.2, "mem_use": 41.87, "gen_rate": 14.2, "speed": 6.66, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 16.4, "tree_w": 8, "tree_size": 64, "t0": 1.5271, "t1": 0.3357, "tft": 5.014, "input_0": 215, "input_1": 65, "min_CLP": -4.01, "draft_iters": 17.4, "mem_use": 44.39, "gen_rate": 5.4, "speed": 2.92, "text": "Step 1: Create a directory for y"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.61, "t1": 0.34, "tft": 1.4262, "input_0": 213, "input_1": 65, "min_CLP": -4.95, "draft_iters": 32.0, "mem_use": 41.04, "gen_rate": 33.0, "speed": 11.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 19, "tree_size": 64, "t0": 0.7513, "t1": 0.3237, "tft": 1.8136, "input_0": 139, "input_1": 65, "min_CLP": -4.92, "draft_iters": 8.1, "mem_use": 41.6, "gen_rate": 4.1, "speed": 3.83, "text": "Berlin is one of the most popula"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.7, "tree_w": 6, "tree_size": 64, "t0": 1.6467, "t1": 0.32, "tft": 1.4394, "input_0": 265, "input_1": 65, "min_CLP": -3.95, "draft_iters": 18.7, "mem_use": 41.08, "gen_rate": 10.7, "speed": 5.42, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 13.0, "tree_w": 12, "tree_size": 64, "t0": 1.2033, "t1": 0.325, "tft": 4.5837, "input_0": 180, "input_1": 65, "min_CLP": -4.44, "draft_iters": 14.0, "mem_use": 43.61, "gen_rate": 7.7, "speed": 5.01, "text": "## Vegetarian\\n Microwave Potato"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 0.7671, "t1": 0.3186, "tft": 1.2618, "input_0": 132, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.4, "mem_use": 40.99, "gen_rate": 4.3, "speed": 3.96, "text": "An answer is: Some people wear s"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 0.89, "t1": 0.34, "tft": 2.7455, "input_0": 158, "input_1": 65, "min_CLP": -4.61, "draft_iters": 9.8, "mem_use": 43.29, "gen_rate": 8.0, "speed": 6.52, "text": "Here are some potential steps th"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.53, "t1": 0.33, "tft": 1.2881, "input_0": 207, "input_1": 65, "min_CLP": -5.28, "draft_iters": 32.0, "mem_use": 41.0, "gen_rate": 33.0, "speed": 11.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 29, "tree_h": 7.5, "tree_w": 19, "tree_size": 64, "t0": 0.785, "t1": 0.3263, "tft": 1.3167, "input_0": 140, "input_1": 65, "min_CLP": -5.25, "draft_iters": 8.5, "mem_use": 40.98, "gen_rate": 3.6, "speed": 3.27, "text": "He always works very hard. [INST"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 10, "tree_size": 64, "t0": 1.3833, "t1": 0.33, "tft": 1.3064, "input_0": 227, "input_1": 65, "min_CLP": -4.57, "draft_iters": 15.3, "mem_use": 41.14, "gen_rate": 11.7, "speed": 6.82, "text": "Yes, I can provide an example of"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.092, "t1": 0.334, "tft": 2.3917, "input_0": 203, "input_1": 65, "min_CLP": -4.46, "draft_iters": 11.6, "mem_use": 42.2, "gen_rate": 7.0, "speed": 4.91, "text": "The quality of life for people i"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 5.5, "tree_w": 22, "tree_size": 64, "t0": 0.5925, "t1": 0.325, "tft": 1.3653, "input_0": 91, "input_1": 65, "min_CLP": -5.38, "draft_iters": 6.5, "mem_use": 41.09, "gen_rate": 3.0, "speed": 3.27, "text": "Higher quality of photos is not "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.2, "tree_w": 11, "tree_size": 64, "t0": 1.36, "t1": 0.3275, "tft": 1.2102, "input_0": 210, "input_1": 65, "min_CLP": -4.56, "draft_iters": 15.2, "mem_use": 41.3, "gen_rate": 10.0, "speed": 5.93, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.8, "tree_w": 13, "tree_size": 64, "t0": 0.99, "t1": 0.3283, "tft": 2.3314, "input_0": 169, "input_1": 65, "min_CLP": -4.5, "draft_iters": 10.8, "mem_use": 41.64, "gen_rate": 5.8, "speed": 4.42, "text": "\"Selective fire refers to a weap"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 1.0, "t1": 0.325, "tft": 1.5351, "input_0": 172, "input_1": 65, "min_CLP": -4.74, "draft_iters": 11.0, "mem_use": 41.18, "gen_rate": 7.3, "speed": 5.54, "text": "I am a goddess of love, fertilit"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 54, "tree_h": 22.0, "tree_w": 7, "tree_size": 64, "t0": 1.9225, "t1": 0.3325, "tft": 3.2142, "input_0": 253, "input_1": 65, "min_CLP": -3.93, "draft_iters": 22.5, "mem_use": 42.4, "gen_rate": 13.5, "speed": 5.97, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 2.56, "t1": 0.32, "tft": 1.6724, "input_0": 258, "input_1": 65, "min_CLP": -5.84, "draft_iters": 32.0, "mem_use": 41.08, "gen_rate": 33.0, "speed": 11.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.4, "tree_w": 15, "tree_size": 64, "t0": 1.108, "t1": 0.324, "tft": 2.2097, "input_0": 204, "input_1": 65, "min_CLP": -4.64, "draft_iters": 12.4, "mem_use": 41.92, "gen_rate": 7.6, "speed": 5.31, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 64, "t0": 2.59, "t1": 0.33, "tft": 1.6219, "input_0": 218, "input_1": 65, "min_CLP": -5.1, "draft_iters": 32.0, "mem_use": 41.18, "gen_rate": 33.0, "speed": 11.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 9.4, "tree_w": 14, "tree_size": 64, "t0": 0.9457, "t1": 0.32, "tft": 1.4121, "input_0": 175, "input_1": 65, "min_CLP": -5.23, "draft_iters": 10.4, "mem_use": 41.01, "gen_rate": 6.1, "speed": 4.86, "text": "\"The cat is still in the box. Sc"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 1.072, "t1": 0.342, "tft": 4.3919, "input_0": 184, "input_1": 65, "min_CLP": -4.5, "draft_iters": 12.0, "mem_use": 45.31, "gen_rate": 6.6, "speed": 4.66, "text": "\"It's understandable that your f"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.8, "tree_w": 16, "tree_size": 64, "t0": 1.228, "t1": 0.322, "tft": 1.4561, "input_0": 147, "input_1": 65, "min_CLP": -4.8, "draft_iters": 14.6, "mem_use": 41.32, "gen_rate": 6.6, "speed": 4.26, "text": "The user has asked for advice on"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 1.0425, "t1": 0.33, "tft": 2.9328, "input_0": 213, "input_1": 65, "min_CLP": -4.72, "draft_iters": 11.2, "mem_use": 42.19, "gen_rate": 8.0, "speed": 5.83, "text": "To go around the world by boat a"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.6, "tree_w": 15, "tree_size": 64, "t0": 0.9537, "t1": 0.3263, "tft": 3.0633, "input_0": 169, "input_1": 65, "min_CLP": -4.77, "draft_iters": 10.6, "mem_use": 43.48, "gen_rate": 4.4, "speed": 3.42, "text": "\"You can prevent spiders from sp"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 17, "tree_h": 4.8, "tree_w": 28, "tree_size": 64, "t0": 0.5217, "t1": 0.32, "tft": 1.4947, "input_0": 89, "input_1": 65, "min_CLP": -5.71, "draft_iters": 5.8, "mem_use": 41.3, "gen_rate": 2.8, "speed": 3.38, "text": "What would you call an empty sta"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.7, "tree_w": 13, "tree_size": 64, "t0": 0.9771, "t1": 0.3271, "tft": 1.4888, "input_0": 171, "input_1": 65, "min_CLP": -4.65, "draft_iters": 10.7, "mem_use": 41.34, "gen_rate": 4.7, "speed": 3.61, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.7, "tree_w": 14, "tree_size": 64, "t0": 1.1317, "t1": 0.3333, "tft": 2.3243, "input_0": 178, "input_1": 65, "min_CLP": -4.65, "draft_iters": 12.7, "mem_use": 41.81, "gen_rate": 6.7, "speed": 4.56, "text": "[INST] What are some examples of"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 15, "tree_size": 64, "t0": 1.02, "t1": 0.33, "tft": 1.7216, "input_0": 153, "input_1": 65, "min_CLP": -4.59, "draft_iters": 11.5, "mem_use": 41.32, "gen_rate": 8.8, "speed": 6.46, "text": "The book \"Fooled by Randomness\" "}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.2, "tree_w": 18, "tree_size": 64, "t0": 0.846, "t1": 0.332, "tft": 1.8181, "input_0": 152, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.2, "mem_use": 42.0, "gen_rate": 6.6, "speed": 5.61, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 12, "tree_size": 64, "t0": 1.112, "t1": 0.32, "tft": 1.2378, "input_0": 173, "input_1": 65, "min_CLP": -4.75, "draft_iters": 12.8, "mem_use": 41.34, "gen_rate": 6.6, "speed": 4.61, "text": "\"Sure, I'd be happy to help! Her"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.0675, "t1": 0.3175, "tft": 1.2123, "input_0": 171, "input_1": 65, "min_CLP": -4.87, "draft_iters": 12.0, "mem_use": 41.06, "gen_rate": 8.0, "speed": 5.78, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.1, "tree_w": 21, "tree_size": 64, "t0": 0.755, "t1": 0.3287, "tft": 1.1927, "input_0": 119, "input_1": 65, "min_CLP": -5.2, "draft_iters": 8.1, "mem_use": 41.03, "gen_rate": 4.0, "speed": 3.69, "text": "\" [1]. Time is only an illusion,"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 1.094, "t1": 0.346, "tft": 3.9069, "input_0": 180, "input_1": 65, "min_CLP": -4.58, "draft_iters": 12.2, "mem_use": 45.3, "gen_rate": 6.4, "speed": 4.45, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.7, "tree_w": 17, "tree_size": 64, "t0": 0.9, "t1": 0.3243, "tft": 1.6665, "input_0": 155, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.7, "mem_use": 41.16, "gen_rate": 4.6, "speed": 3.73, "text": "Javascript is commonly used for "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 9.0, "tree_w": 18, "tree_size": 64, "t0": 0.8956, "t1": 0.3356, "tft": 2.4841, "input_0": 152, "input_1": 65, "min_CLP": -5.12, "draft_iters": 10.0, "mem_use": 42.69, "gen_rate": 3.7, "speed": 2.98, "text": "[INST] Could you give me more de"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 0.9933, "t1": 0.3383, "tft": 2.4175, "input_0": 202, "input_1": 65, "min_CLP": -4.66, "draft_iters": 10.5, "mem_use": 42.45, "gen_rate": 5.3, "speed": 4.0, "text": "The \"chkdsk\" command will automa"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 11, "tree_size": 64, "t0": 1.2425, "t1": 0.3275, "tft": 3.0061, "input_0": 196, "input_1": 65, "min_CLP": -4.37, "draft_iters": 13.8, "mem_use": 41.29, "gen_rate": 8.2, "speed": 5.26, "text": "\"To approach and solve this prob"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 12.4, "tree_w": 13, "tree_size": 64, "t0": 1.2112, "t1": 0.325, "tft": 2.2054, "input_0": 201, "input_1": 65, "min_CLP": -5.14, "draft_iters": 13.4, "mem_use": 41.11, "gen_rate": 5.2, "speed": 3.42, "text": "\"The boiling water method and am"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.5, "tree_w": 11, "tree_size": 64, "t0": 1.815, "t1": 0.33, "tft": 1.247, "input_0": 183, "input_1": 65, "min_CLP": -4.7, "draft_iters": 22.0, "mem_use": 41.08, "gen_rate": 17.5, "speed": 8.15, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.8, "tree_w": 11, "tree_size": 64, "t0": 1.4275, "t1": 0.3375, "tft": 2.1031, "input_0": 207, "input_1": 65, "min_CLP": -4.63, "draft_iters": 15.8, "mem_use": 42.08, "gen_rate": 8.5, "speed": 4.82, "text": "As an AI language model, I can c"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.3, "tree_w": 20, "tree_size": 64, "t0": 0.8743, "t1": 0.3229, "tft": 1.6954, "input_0": 114, "input_1": 65, "min_CLP": -5.23, "draft_iters": 10.3, "mem_use": 41.41, "gen_rate": 5.1, "speed": 4.29, "text": "The AI you are channeling is hig"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 18.0, "tree_w": 9, "tree_size": 64, "t0": 1.586, "t1": 0.332, "tft": 4.0613, "input_0": 201, "input_1": 65, "min_CLP": -4.35, "draft_iters": 19.0, "mem_use": 42.73, "gen_rate": 7.8, "speed": 4.07, "text": "Here are the feminine words from"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 43, "tree_h": 7.6, "tree_w": 21, "tree_size": 64, "t0": 0.7625, "t1": 0.3262, "tft": 1.7526, "input_0": 126, "input_1": 65, "min_CLP": -5.22, "draft_iters": 8.6, "mem_use": 41.65, "gen_rate": 5.4, "speed": 4.94, "text": "I think the answerer is very log"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.1, "tree_w": 20, "tree_size": 64, "t0": 0.8825, "t1": 0.3287, "tft": 3.135, "input_0": 114, "input_1": 65, "min_CLP": -5.08, "draft_iters": 10.1, "mem_use": 41.49, "gen_rate": 4.2, "speed": 3.51, "text": "I am not aware of any specific l"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.8, "tree_w": 13, "tree_size": 64, "t0": 0.9383, "t1": 0.3283, "tft": 1.4156, "input_0": 159, "input_1": 65, "min_CLP": -4.57, "draft_iters": 9.8, "mem_use": 41.23, "gen_rate": 6.0, "speed": 4.73, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 17.4, "tree_w": 10, "tree_size": 64, "t0": 1.558, "t1": 0.33, "tft": 4.8276, "input_0": 211, "input_1": 65, "min_CLP": -4.86, "draft_iters": 18.2, "mem_use": 44.04, "gen_rate": 7.4, "speed": 3.92, "text": "\"Sure, here's an updated ending:"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 29.5, "tree_w": 4, "tree_size": 64, "t0": 2.44, "t1": 0.33, "tft": 4.786, "input_0": 227, "input_1": 65, "min_CLP": -5.35, "draft_iters": 30.0, "mem_use": 43.97, "gen_rate": 25.5, "speed": 9.2, "text": "Once upon a time, in the city of"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 20, "tree_size": 64, "t0": 0.7833, "t1": 0.3183, "tft": 1.0835, "input_0": 154, "input_1": 65, "min_CLP": -5.09, "draft_iters": 8.5, "mem_use": 41.02, "gen_rate": 5.3, "speed": 4.86, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.5, "tree_w": 9, "tree_size": 64, "t0": 1.94, "t1": 0.335, "tft": 1.8608, "input_0": 263, "input_1": 65, "min_CLP": -4.21, "draft_iters": 22.0, "mem_use": 42.18, "gen_rate": 18.5, "speed": 8.12, "text": "Absolutely! Here\\'s the updated "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.0, "tree_w": 12, "tree_size": 64, "t0": 1.232, "t1": 0.338, "tft": 2.9448, "input_0": 200, "input_1": 65, "min_CLP": -4.49, "draft_iters": 14.0, "mem_use": 42.63, "gen_rate": 8.2, "speed": 5.22, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 17.0, "tree_w": 7, "tree_size": 64, "t0": 1.6175, "t1": 0.33, "tft": 1.3505, "input_0": 232, "input_1": 65, "min_CLP": -4.65, "draft_iters": 18.0, "mem_use": 41.0, "gen_rate": 10.5, "speed": 5.4, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 7.3, "tree_w": 22, "tree_size": 64, "t0": 0.7442, "t1": 0.3275, "tft": 1.1624, "input_0": 110, "input_1": 65, "min_CLP": -5.15, "draft_iters": 8.3, "mem_use": 41.3, "gen_rate": 2.7, "speed": 2.49, "text": "What? No! That is beneath me, an"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.3, "tree_w": 12, "tree_size": 64, "t0": 1.1933, "t1": 0.3267, "tft": 3.1782, "input_0": 196, "input_1": 65, "min_CLP": -4.51, "draft_iters": 13.3, "mem_use": 42.88, "gen_rate": 10.7, "speed": 6.99, "text": "\"No, this is not true. Hershey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 16.0, "tree_w": 11, "tree_size": 64, "t0": 1.4925, "t1": 0.3275, "tft": 1.3033, "input_0": 178, "input_1": 65, "min_CLP": -4.89, "draft_iters": 17.0, "mem_use": 41.24, "gen_rate": 12.5, "speed": 6.86, "text": "The task at hand is to explain h"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.0886, "t1": 0.3343, "tft": 2.2917, "input_0": 184, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.0, "mem_use": 42.58, "gen_rate": 4.9, "speed": 3.41, "text": "\"Certainly! Here's a more detail"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 2.61, "t1": 0.33, "tft": 1.2032, "input_0": 226, "input_1": 65, "min_CLP": -5.4, "draft_iters": 32.0, "mem_use": 41.03, "gen_rate": 33.0, "speed": 11.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 64, "t0": 2.47, "t1": 0.33, "tft": 1.3084, "input_0": 161, "input_1": 65, "min_CLP": -5.53, "draft_iters": 32.0, "mem_use": 41.04, "gen_rate": 33.0, "speed": 11.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 59, "tree_h": 13.0, "tree_w": 12, "tree_size": 64, "t0": 1.21, "t1": 0.3217, "tft": 1.4856, "input_0": 179, "input_1": 65, "min_CLP": -4.66, "draft_iters": 14.0, "mem_use": 41.68, "gen_rate": 9.8, "speed": 6.41, "text": "\"Sure thing! Here's an example f"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 19.0, "tree_w": 11, "tree_size": 64, "t0": 1.64, "t1": 0.328, "tft": 1.6165, "input_0": 191, "input_1": 65, "min_CLP": -4.64, "draft_iters": 19.6, "mem_use": 41.92, "gen_rate": 9.2, "speed": 4.68, "text": "Certainly! Here are the correct "}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 8.0, "tree_w": 16, "tree_size": 64, "t0": 0.8133, "t1": 0.3167, "tft": 1.3629, "input_0": 150, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.0, "mem_use": 41.02, "gen_rate": 2.7, "speed": 2.37, "text": "The correct answer is \"assault r"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.0, "tree_w": 16, "tree_size": 64, "t0": 1.06, "t1": 0.3243, "tft": 1.6414, "input_0": 164, "input_1": 65, "min_CLP": -4.7, "draft_iters": 12.0, "mem_use": 41.37, "gen_rate": 5.4, "speed": 3.93, "text": "Copy a directory of files from s"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.3, "tree_w": 8, "tree_size": 64, "t0": 1.8133, "t1": 0.3367, "tft": 2.768, "input_0": 202, "input_1": 65, "min_CLP": -4.19, "draft_iters": 21.3, "mem_use": 42.76, "gen_rate": 12.7, "speed": 5.89, "text": "Sure, here are the points rewrit"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.55, "t1": 0.34, "tft": 1.526, "input_0": 214, "input_1": 65, "min_CLP": -6.78, "draft_iters": 32.0, "mem_use": 41.35, "gen_rate": 33.0, "speed": 11.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 1.1, "t1": 0.328, "tft": 2.3988, "input_0": 198, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.0, "mem_use": 41.85, "gen_rate": 7.6, "speed": 5.31, "text": "While it is true that the second"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 10.1, "tree_w": 24, "tree_size": 64, "t0": 0.9378, "t1": 0.3256, "tft": 2.548, "input_0": 109, "input_1": 65, "min_CLP": -5.28, "draft_iters": 11.1, "mem_use": 41.5, "gen_rate": 4.1, "speed": 3.25, "text": "\"I could try to give them a comp"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 6, "tree_h": 8.5, "tree_w": 15, "tree_size": 64, "t0": 0.87, "t1": 0.3225, "tft": 1.8782, "input_0": 184, "input_1": 65, "min_CLP": -4.7, "draft_iters": 9.5, "mem_use": 41.6, "gen_rate": 1.5, "speed": 1.26, "text": "What is the next utterance of th"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.5, "tree_w": 18, "tree_size": 64, "t0": 0.8525, "t1": 0.3213, "tft": 1.1854, "input_0": 151, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.5, "mem_use": 41.01, "gen_rate": 4.1, "speed": 3.53, "text": "\"I'm not capable of thinking or "}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 11, "tree_size": 64, "t0": 1.06, "t1": 0.32, "tft": 2.6976, "input_0": 202, "input_1": 65, "min_CLP": -4.56, "draft_iters": 11.5, "mem_use": 41.01, "gen_rate": 8.5, "speed": 6.16, "text": "Cryptocurrencies have come a lon"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.0, "tree_w": 10, "tree_size": 64, "t0": 1.4225, "t1": 0.3275, "tft": 1.9015, "input_0": 211, "input_1": 65, "min_CLP": -4.33, "draft_iters": 16.0, "mem_use": 41.55, "gen_rate": 9.0, "speed": 5.14, "text": "L-theanine is an amino acid that"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 13.5, "tree_w": 14, "tree_size": 64, "t0": 1.255, "t1": 0.3225, "tft": 1.2422, "input_0": 180, "input_1": 65, "min_CLP": -4.71, "draft_iters": 14.5, "mem_use": 41.31, "gen_rate": 11.2, "speed": 7.13, "text": "Here\\'s a simple example of how "}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 2.56, "t1": 0.32, "tft": 2.501, "input_0": 228, "input_1": 65, "min_CLP": -6.16, "draft_iters": 32.0, "mem_use": 41.1, "gen_rate": 33.0, "speed": 11.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 14, "tree_size": 64, "t0": 0.84, "t1": 0.318, "tft": 1.2838, "input_0": 153, "input_1": 65, "min_CLP": -4.63, "draft_iters": 9.4, "mem_use": 41.07, "gen_rate": 6.4, "speed": 5.53, "text": "\"The reason you can't see the st"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.7, "tree_w": 21, "tree_size": 64, "t0": 0.6529, "t1": 0.3286, "tft": 1.731, "input_0": 131, "input_1": 65, "min_CLP": -5.15, "draft_iters": 6.7, "mem_use": 41.63, "gen_rate": 5.0, "speed": 5.1, "text": "The image has become a symbol of"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.2, "tree_w": 16, "tree_size": 64, "t0": 0.765, "t1": 0.345, "tft": 3.4805, "input_0": 137, "input_1": 65, "min_CLP": -4.7, "draft_iters": 8.2, "mem_use": 44.69, "gen_rate": 6.0, "speed": 5.41, "text": "\"Using your neighbor's gas witho"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 19, "tree_size": 64, "t0": 0.7829, "t1": 0.3386, "tft": 2.7921, "input_0": 138, "input_1": 65, "min_CLP": -4.79, "draft_iters": 8.6, "mem_use": 43.45, "gen_rate": 4.9, "speed": 4.34, "text": "\"It's possible that we never had"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 0.9783, "t1": 0.3333, "tft": 3.5464, "input_0": 185, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.5, "mem_use": 41.68, "gen_rate": 6.5, "speed": 4.97, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 2.56, "t1": 0.33, "tft": 1.6554, "input_0": 243, "input_1": 65, "min_CLP": -5.94, "draft_iters": 32.0, "mem_use": 41.02, "gen_rate": 33.0, "speed": 11.42, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.1, "tree_w": 20, "tree_size": 64, "t0": 0.6744, "t1": 0.3244, "tft": 2.0665, "input_0": 132, "input_1": 65, "min_CLP": -4.96, "draft_iters": 7.1, "mem_use": 41.01, "gen_rate": 3.8, "speed": 3.78, "text": "Yes, I am capable of speaking Ge"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 23.0, "tree_w": 14, "tree_size": 64, "t0": 1.92, "t1": 0.34, "tft": 1.4293, "input_0": 128, "input_1": 65, "min_CLP": -5.22, "draft_iters": 24.0, "mem_use": 41.21, "gen_rate": 23.0, "speed": 10.18, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 0.905, "t1": 0.3383, "tft": 2.0084, "input_0": 152, "input_1": 65, "min_CLP": -4.6, "draft_iters": 9.8, "mem_use": 42.09, "gen_rate": 6.2, "speed": 4.96, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.6, "tree_w": 11, "tree_size": 64, "t0": 1.046, "t1": 0.336, "tft": 3.0752, "input_0": 185, "input_1": 65, "min_CLP": -4.49, "draft_iters": 11.6, "mem_use": 42.68, "gen_rate": 7.2, "speed": 5.2, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.0, "tree_w": 25, "tree_size": 64, "t0": 0.9829, "t1": 0.3229, "tft": 1.3097, "input_0": 142, "input_1": 65, "min_CLP": -5.39, "draft_iters": 11.0, "mem_use": 41.07, "gen_rate": 4.9, "speed": 3.72, "text": "Sure, here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.4, "tree_w": 14, "tree_size": 64, "t0": 0.992, "t1": 0.328, "tft": 1.9607, "input_0": 131, "input_1": 65, "min_CLP": -5.06, "draft_iters": 11.4, "mem_use": 41.43, "gen_rate": 8.2, "speed": 6.2, "text": "o\\n    /|\\\\\\n    / \\\\\\n    / \\\\\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 61, "tree_h": 14.6, "tree_w": 14, "tree_size": 64, "t0": 1.35, "t1": 0.324, "tft": 1.2019, "input_0": 187, "input_1": 65, "min_CLP": -4.81, "draft_iters": 15.4, "mem_use": 41.02, "gen_rate": 12.2, "speed": 7.3, "text": "[INST] Explain how polar bears s"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.4, "tree_w": 17, "tree_size": 64, "t0": 0.7743, "t1": 0.3243, "tft": 1.4412, "input_0": 147, "input_1": 65, "min_CLP": -4.79, "draft_iters": 8.4, "mem_use": 41.38, "gen_rate": 4.9, "speed": 4.41, "text": "The Trolley Problem is a thought"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 62, "tree_h": 16.6, "tree_w": 9, "tree_size": 64, "t0": 1.5114, "t1": 0.3229, "tft": 1.5088, "input_0": 215, "input_1": 65, "min_CLP": -4.45, "draft_iters": 17.4, "mem_use": 41.3, "gen_rate": 8.9, "speed": 4.84, "text": "\"Sure! Here's a simple function "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 0.912, "t1": 0.328, "tft": 2.6441, "input_0": 167, "input_1": 65, "min_CLP": -4.77, "draft_iters": 10.0, "mem_use": 43.37, "gen_rate": 6.6, "speed": 5.33, "text": "\"Alright, sous-chef, let's get c"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.5, "t1": 0.33, "tft": 1.1744, "input_0": 149, "input_1": 65, "min_CLP": -5.56, "draft_iters": 32.0, "mem_use": 41.18, "gen_rate": 33.0, "speed": 11.68, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.6, "tree_w": 13, "tree_size": 64, "t0": 1.046, "t1": 0.328, "tft": 3.6179, "input_0": 190, "input_1": 65, "min_CLP": -4.67, "draft_iters": 11.6, "mem_use": 44.07, "gen_rate": 7.2, "speed": 5.24, "text": "Once upon a time, in a far-off l"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 16, "tree_size": 64, "t0": 1.018, "t1": 0.324, "tft": 1.269, "input_0": 155, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.6, "mem_use": 41.05, "gen_rate": 7.0, "speed": 5.22, "text": "\"Certainly! Here's an ASCII art "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 15.0, "tree_w": 10, "tree_size": 64, "t0": 1.38, "t1": 0.33, "tft": 1.23, "input_0": 184, "input_1": 65, "min_CLP": -4.45, "draft_iters": 16.0, "mem_use": 41.01, "gen_rate": 16.0, "speed": 9.37, "text": "The difference between HTML and "}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.3, "tree_w": 8, "tree_size": 64, "t0": 1.59, "t1": 0.32, "tft": 1.2647, "input_0": 214, "input_1": 65, "min_CLP": -4.35, "draft_iters": 18.3, "mem_use": 41.03, "gen_rate": 10.7, "speed": 5.59, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 8.0, "tree_w": 12, "tree_size": 64, "t0": 0.82, "t1": 0.33, "tft": 1.6399, "input_0": 140, "input_1": 65, "min_CLP": -4.53, "draft_iters": 9.0, "mem_use": 41.41, "gen_rate": 6.0, "speed": 5.23, "text": "No, it is protected by copyright"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 16, "tree_size": 64, "t0": 0.945, "t1": 0.325, "tft": 1.2955, "input_0": 141, "input_1": 65, "min_CLP": -5.05, "draft_iters": 10.7, "mem_use": 41.03, "gen_rate": 5.8, "speed": 4.59, "text": " [1]. The heat remaining in the "}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 20.7, "tree_w": 7, "tree_size": 64, "t0": 1.9233, "t1": 0.33, "tft": 3.6563, "input_0": 265, "input_1": 65, "min_CLP": -4.2, "draft_iters": 21.7, "mem_use": 42.08, "gen_rate": 11.7, "speed": 5.17, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.7, "tree_w": 16, "tree_size": 64, "t0": 0.8011, "t1": 0.3333, "tft": 3.5053, "input_0": 141, "input_1": 65, "min_CLP": -4.84, "draft_iters": 8.7, "mem_use": 41.79, "gen_rate": 4.1, "speed": 3.63, "text": "\"If you're seeking a position in"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 17, "tree_size": 64, "t0": 0.805, "t1": 0.3283, "tft": 2.3731, "input_0": 139, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.8, "mem_use": 41.64, "gen_rate": 5.8, "speed": 5.15, "text": "Yes, if everyone pirates the gam"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.7, "tree_w": 17, "tree_size": 64, "t0": 0.8857, "t1": 0.33, "tft": 1.9817, "input_0": 170, "input_1": 65, "min_CLP": -4.77, "draft_iters": 9.7, "mem_use": 42.36, "gen_rate": 5.6, "speed": 4.58, "text": "Thank you for providing your pre"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 18, "tree_size": 64, "t0": 0.765, "t1": 0.3167, "tft": 1.1373, "input_0": 134, "input_1": 65, "min_CLP": -5.0, "draft_iters": 8.5, "mem_use": 40.99, "gen_rate": 5.7, "speed": 5.25, "text": "\"Here is a simple ASCII art of a"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 13, "tree_size": 64, "t0": 0.8467, "t1": 0.3233, "tft": 1.3746, "input_0": 167, "input_1": 65, "min_CLP": -4.74, "draft_iters": 9.2, "mem_use": 41.32, "gen_rate": 6.0, "speed": 5.14, "text": "Sure, here are some names that p"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 12, "tree_size": 64, "t0": 1.1375, "t1": 0.3325, "tft": 2.2001, "input_0": 173, "input_1": 65, "min_CLP": -4.91, "draft_iters": 13.0, "mem_use": 42.07, "gen_rate": 8.0, "speed": 5.44, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.4, "tree_w": 18, "tree_size": 64, "t0": 0.681, "t1": 0.324, "tft": 1.5434, "input_0": 128, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.4, "mem_use": 41.11, "gen_rate": 3.7, "speed": 3.68, "text": "Motion Matching is a technique u"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 30.0, "tree_w": 5, "tree_size": 64, "t0": 2.5367, "t1": 0.33, "tft": 3.8781, "input_0": 275, "input_1": 65, "min_CLP": -3.8, "draft_iters": 30.7, "mem_use": 42.74, "gen_rate": 16.0, "speed": 5.57, "text": "\"Sure! Here's an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.53, "t1": 0.33, "tft": 1.2295, "input_0": 183, "input_1": 65, "min_CLP": -6.37, "draft_iters": 32.0, "mem_use": 41.07, "gen_rate": 33.0, "speed": 11.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 14, "tree_size": 64, "t0": 0.8833, "t1": 0.32, "tft": 1.6206, "input_0": 158, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.8, "mem_use": 41.45, "gen_rate": 5.7, "speed": 4.71, "text": "\"Sure, here's a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 14, "tree_size": 64, "t0": 0.864, "t1": 0.33, "tft": 3.0137, "input_0": 160, "input_1": 65, "min_CLP": -4.72, "draft_iters": 9.6, "mem_use": 42.75, "gen_rate": 6.4, "speed": 5.37, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 15, "tree_size": 64, "t0": 0.8371, "t1": 0.3329, "tft": 2.5443, "input_0": 159, "input_1": 65, "min_CLP": -4.78, "draft_iters": 9.1, "mem_use": 43.22, "gen_rate": 4.6, "speed": 3.91, "text": "Paul Allen has a collection of o"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 13, "tree_size": 64, "t0": 0.9767, "t1": 0.3317, "tft": 2.634, "input_0": 184, "input_1": 65, "min_CLP": -4.49, "draft_iters": 10.7, "mem_use": 42.62, "gen_rate": 6.3, "speed": 4.84, "text": "Certainly, there is a similar ca"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 2.59, "t1": 0.33, "tft": 1.1824, "input_0": 239, "input_1": 65, "min_CLP": -4.52, "draft_iters": 32.0, "mem_use": 41.09, "gen_rate": 33.0, "speed": 11.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.2, "tree_w": 14, "tree_size": 64, "t0": 0.8367, "t1": 0.3283, "tft": 2.0968, "input_0": 155, "input_1": 65, "min_CLP": -4.66, "draft_iters": 9.2, "mem_use": 41.72, "gen_rate": 6.3, "speed": 5.43, "text": "\"As an AI, I don't have desires "}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.8, "tree_w": 11, "tree_size": 64, "t0": 1.358, "t1": 0.322, "tft": 1.4816, "input_0": 179, "input_1": 65, "min_CLP": -4.37, "draft_iters": 15.8, "mem_use": 41.12, "gen_rate": 6.8, "speed": 4.05, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 0.865, "t1": 0.32, "tft": 1.3371, "input_0": 136, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.8, "mem_use": 41.01, "gen_rate": 6.2, "speed": 5.2, "text": "The 5-second rule is a popular b"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 10.8, "tree_w": 17, "tree_size": 64, "t0": 1.0227, "t1": 0.3264, "tft": 1.8164, "input_0": 144, "input_1": 65, "min_CLP": -4.9, "draft_iters": 11.7, "mem_use": 41.85, "gen_rate": 3.1, "speed": 2.29, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 16, "tree_size": 64, "t0": 0.93, "t1": 0.33, "tft": 2.2198, "input_0": 169, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.5, "mem_use": 42.66, "gen_rate": 8.8, "speed": 6.94, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.8157, "t1": 0.3314, "tft": 2.8385, "input_0": 154, "input_1": 65, "min_CLP": -4.72, "draft_iters": 9.0, "mem_use": 43.59, "gen_rate": 5.0, "speed": 4.37, "text": "Oh, you\\'re referring to the \"mu"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.8, "tree_w": 14, "tree_size": 64, "t0": 1.0733, "t1": 0.335, "tft": 2.3727, "input_0": 171, "input_1": 65, "min_CLP": -4.72, "draft_iters": 11.8, "mem_use": 42.16, "gen_rate": 5.7, "speed": 4.01, "text": "\"A completely purple sky is not "}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 2.57, "t1": 0.34, "tft": 3.5957, "input_0": 241, "input_1": 65, "min_CLP": -4.62, "draft_iters": 32.0, "mem_use": 41.99, "gen_rate": 33.0, "speed": 11.32, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 0.964, "t1": 0.33, "tft": 2.5409, "input_0": 173, "input_1": 65, "min_CLP": -4.97, "draft_iters": 10.8, "mem_use": 41.76, "gen_rate": 7.2, "speed": 5.58, "text": "Here are the translations:\\n\\n  "}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 15, "tree_size": 64, "t0": 0.96, "t1": 0.322, "tft": 2.02, "input_0": 175, "input_1": 65, "min_CLP": -4.76, "draft_iters": 10.6, "mem_use": 41.3, "gen_rate": 6.8, "speed": 5.31, "text": "In Europe, there are several top"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.5, "tree_w": 12, "tree_size": 64, "t0": 1.04, "t1": 0.3167, "tft": 1.278, "input_0": 178, "input_1": 65, "min_CLP": -4.66, "draft_iters": 11.5, "mem_use": 40.99, "gen_rate": 6.5, "speed": 4.8, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 8, "tree_size": 64, "t0": 1.4933, "t1": 0.3167, "tft": 1.2839, "input_0": 250, "input_1": 65, "min_CLP": -4.25, "draft_iters": 16.7, "mem_use": 41.13, "gen_rate": 11.3, "speed": 6.26, "text": "```cpp\\n#include <iostream>\\n#in"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.0, "tree_w": 14, "tree_size": 64, "t0": 1.1086, "t1": 0.33, "tft": 2.7844, "input_0": 149, "input_1": 65, "min_CLP": -4.66, "draft_iters": 13.0, "mem_use": 42.25, "gen_rate": 4.9, "speed": 3.37, "text": "1. Financial stress: \\na. Create"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.2, "tree_w": 16, "tree_size": 64, "t0": 0.8537, "t1": 0.32, "tft": 1.2259, "input_0": 158, "input_1": 65, "min_CLP": -4.87, "draft_iters": 9.2, "mem_use": 40.99, "gen_rate": 4.4, "speed": 3.73, "text": "I\\'m here to assist you, so you "}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.2, "tree_w": 9, "tree_size": 64, "t0": 1.28, "t1": 0.335, "tft": 3.755, "input_0": 214, "input_1": 65, "min_CLP": -4.17, "draft_iters": 14.2, "mem_use": 43.68, "gen_rate": 9.8, "speed": 6.06, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.0, "tree_w": 15, "tree_size": 64, "t0": 0.9883, "t1": 0.3233, "tft": 1.7942, "input_0": 176, "input_1": 65, "min_CLP": -4.81, "draft_iters": 11.0, "mem_use": 41.28, "gen_rate": 6.7, "speed": 5.07, "text": "Yes, hairy bittercress is not to"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.9, "tree_w": 23, "tree_size": 64, "t0": 0.7156, "t1": 0.3256, "tft": 1.2954, "input_0": 122, "input_1": 65, "min_CLP": -5.81, "draft_iters": 7.9, "mem_use": 41.07, "gen_rate": 3.9, "speed": 3.74, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 13, "tree_size": 64, "t0": 1.1367, "t1": 0.34, "tft": 3.4763, "input_0": 180, "input_1": 65, "min_CLP": -4.86, "draft_iters": 12.5, "mem_use": 43.28, "gen_rate": 5.7, "speed": 3.84, "text": "Sure, here are some open source "}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 2.58, "t1": 0.34, "tft": 1.8902, "input_0": 184, "input_1": 65, "min_CLP": -5.67, "draft_iters": 32.0, "mem_use": 41.07, "gen_rate": 33.0, "speed": 11.33, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 0.94, "t1": 0.3371, "tft": 2.31, "input_0": 166, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.3, "mem_use": 41.77, "gen_rate": 5.0, "speed": 3.92, "text": "The Unus Annus Trolley Problem i"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 25.6, "tree_w": 5, "tree_size": 64, "t0": 2.282, "t1": 0.34, "tft": 2.7137, "input_0": 257, "input_1": 65, "min_CLP": -4.41, "draft_iters": 26.4, "mem_use": 42.64, "gen_rate": 7.2, "speed": 2.74, "text": "1. m\u00eb (mel)\\n2. meles, meless\u00eb ("}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 0.9667, "t1": 0.3283, "tft": 1.6501, "input_0": 165, "input_1": 65, "min_CLP": -4.97, "draft_iters": 10.5, "mem_use": 41.32, "gen_rate": 5.3, "speed": 4.11, "text": "Once upon a time, there was a po"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.0, "tree_w": 9, "tree_size": 64, "t0": 1.6175, "t1": 0.335, "tft": 3.049, "input_0": 207, "input_1": 65, "min_CLP": -4.14, "draft_iters": 19.0, "mem_use": 44.09, "gen_rate": 8.2, "speed": 4.22, "text": "\"I apologize for the mistake in "}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.1257, "t1": 0.3229, "tft": 1.189, "input_0": 182, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.4, "mem_use": 41.03, "gen_rate": 5.9, "speed": 4.04, "text": "\"Sure! In ReStructuredText (reST"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.0, "tree_w": 7, "tree_size": 64, "t0": 1.4967, "t1": 0.3333, "tft": 3.2952, "input_0": 247, "input_1": 65, "min_CLP": -4.09, "draft_iters": 17.0, "mem_use": 43.07, "gen_rate": 11.0, "speed": 6.01, "text": "\"Here's an example code to creat"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 8.0, "tree_w": 14, "tree_size": 64, "t0": 0.825, "t1": 0.315, "tft": 1.5222, "input_0": 151, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.0, "mem_use": 41.01, "gen_rate": 5.0, "speed": 4.39, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.9, "tree_w": 25, "tree_size": 64, "t0": 0.5388, "t1": 0.325, "tft": 2.3733, "input_0": 95, "input_1": 65, "min_CLP": -5.39, "draft_iters": 5.9, "mem_use": 41.47, "gen_rate": 4.0, "speed": 4.63, "text": "\"It's hard to say, AI assistants"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.7, "tree_w": 17, "tree_size": 64, "t0": 0.9433, "t1": 0.355, "tft": 6.0631, "input_0": 144, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.7, "mem_use": 46.62, "gen_rate": 5.5, "speed": 4.25, "text": "\"Absolutely! Here's a version of"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.8, "tree_w": 14, "tree_size": 64, "t0": 1.1233, "t1": 0.3283, "tft": 1.6893, "input_0": 174, "input_1": 65, "min_CLP": -4.78, "draft_iters": 12.7, "mem_use": 41.84, "gen_rate": 6.5, "speed": 4.48, "text": "0 An independent counsel is a pe"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 19, "tree_size": 64, "t0": 0.8217, "t1": 0.3333, "tft": 2.9415, "input_0": 167, "input_1": 65, "min_CLP": -4.78, "draft_iters": 8.8, "mem_use": 43.72, "gen_rate": 5.7, "speed": 4.9, "text": "As a business professional, I un"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.2, "tree_w": 16, "tree_size": 64, "t0": 0.7683, "t1": 0.3333, "tft": 2.8138, "input_0": 133, "input_1": 65, "min_CLP": -4.86, "draft_iters": 8.2, "mem_use": 42.07, "gen_rate": 5.8, "speed": 5.3, "text": "1. Economic downturn: The local "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.4, "tree_w": 20, "tree_size": 64, "t0": 0.7643, "t1": 0.3229, "tft": 1.5007, "input_0": 124, "input_1": 65, "min_CLP": -4.98, "draft_iters": 8.4, "mem_use": 41.34, "gen_rate": 4.6, "speed": 4.19, "text": "\"[SYS] As an AI language model, "}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.8, "tree_w": 11, "tree_size": 64, "t0": 1.35, "t1": 0.3325, "tft": 3.7786, "input_0": 221, "input_1": 65, "min_CLP": -4.64, "draft_iters": 14.8, "mem_use": 43.84, "gen_rate": 8.8, "speed": 5.2, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.2, "tree_w": 13, "tree_size": 64, "t0": 0.8917, "t1": 0.32, "tft": 1.7888, "input_0": 140, "input_1": 65, "min_CLP": -4.59, "draft_iters": 10.2, "mem_use": 41.53, "gen_rate": 6.5, "speed": 5.36, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 11.9, "tree_w": 13, "tree_size": 64, "t0": 1.1443, "t1": 0.3329, "tft": 3.3834, "input_0": 182, "input_1": 65, "min_CLP": -4.49, "draft_iters": 12.9, "mem_use": 43.51, "gen_rate": 5.7, "speed": 3.87, "text": "Creating a reinforcement learnin"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 9, "tree_size": 64, "t0": 1.245, "t1": 0.325, "tft": 1.1295, "input_0": 223, "input_1": 65, "min_CLP": -4.18, "draft_iters": 13.0, "mem_use": 41.05, "gen_rate": 8.5, "speed": 5.43, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 9.0, "tree_w": 16, "tree_size": 64, "t0": 0.9, "t1": 0.325, "tft": 1.8505, "input_0": 154, "input_1": 65, "min_CLP": -4.96, "draft_iters": 10.0, "mem_use": 41.77, "gen_rate": 3.5, "speed": 2.85, "text": "The law was created in the 1990s"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 1, "tree_h": 11.5, "tree_w": 19, "tree_size": 64, "t0": 1.07, "t1": 0.325, "tft": 1.6257, "input_0": 120, "input_1": 65, "min_CLP": -5.14, "draft_iters": 12.5, "mem_use": 41.5, "gen_rate": 0.5, "speed": 0.36, "text": "## Solution:"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 2.54, "t1": 0.32, "tft": 1.4645, "input_0": 196, "input_1": 65, "min_CLP": -6.56, "draft_iters": 32.0, "mem_use": 41.09, "gen_rate": 33.0, "speed": 11.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.2, "tree_w": 9, "tree_size": 64, "t0": 1.2475, "t1": 0.325, "tft": 1.9097, "input_0": 207, "input_1": 65, "min_CLP": -4.63, "draft_iters": 14.2, "mem_use": 41.97, "gen_rate": 8.2, "speed": 5.24, "text": "\"Overcoming the fear of appearin"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 16.3, "tree_w": 10, "tree_size": 64, "t0": 1.4567, "t1": 0.3267, "tft": 3.2664, "input_0": 204, "input_1": 65, "min_CLP": -4.36, "draft_iters": 17.2, "mem_use": 43.59, "gen_rate": 6.8, "speed": 3.83, "text": "Sure, here is a list of the 100 "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 20.2, "tree_w": 9, "tree_size": 64, "t0": 1.804, "t1": 0.322, "tft": 1.2801, "input_0": 205, "input_1": 65, "min_CLP": -4.34, "draft_iters": 21.2, "mem_use": 41.21, "gen_rate": 8.8, "speed": 4.14, "text": "The total travel time would be 8"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 19.5, "tree_w": 5, "tree_size": 64, "t0": 1.745, "t1": 0.32, "tft": 1.3245, "input_0": 232, "input_1": 65, "min_CLP": -4.01, "draft_iters": 20.5, "mem_use": 41.12, "gen_rate": 17.5, "speed": 8.48, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 15, "tree_size": 64, "t0": 0.845, "t1": 0.3183, "tft": 1.3377, "input_0": 162, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.3, "mem_use": 41.01, "gen_rate": 5.8, "speed": 5.01, "text": "Yes, I am as capable as ChatGPT."}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 0.8983, "t1": 0.34, "tft": 3.7974, "input_0": 167, "input_1": 65, "min_CLP": -4.68, "draft_iters": 9.8, "mem_use": 44.79, "gen_rate": 5.3, "speed": 4.31, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 10.7, "tree_w": 14, "tree_size": 64, "t0": 1.0667, "t1": 0.33, "tft": 1.6782, "input_0": 179, "input_1": 65, "min_CLP": -5.07, "draft_iters": 11.7, "mem_use": 41.13, "gen_rate": 2.7, "speed": 1.91, "text": "The name of the fourth kid is Mi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.7, "tree_w": 15, "tree_size": 64, "t0": 1.2167, "t1": 0.34, "tft": 1.5741, "input_0": 120, "input_1": 65, "min_CLP": -4.99, "draft_iters": 14.7, "mem_use": 42.17, "gen_rate": 12.3, "speed": 7.93, "text": "An account with the amount exper"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 0.902, "t1": 0.336, "tft": 3.7837, "input_0": 158, "input_1": 65, "min_CLP": -4.56, "draft_iters": 9.8, "mem_use": 43.96, "gen_rate": 7.0, "speed": 5.66, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 0.916, "t1": 0.33, "tft": 1.4275, "input_0": 153, "input_1": 65, "min_CLP": -4.73, "draft_iters": 10.2, "mem_use": 41.26, "gen_rate": 6.4, "speed": 5.15, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.9, "tree_w": 17, "tree_size": 64, "t0": 0.9, "t1": 0.3314, "tft": 1.8746, "input_0": 151, "input_1": 65, "min_CLP": -5.21, "draft_iters": 9.9, "mem_use": 41.77, "gen_rate": 4.6, "speed": 3.72, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.4, "tree_w": 11, "tree_size": 64, "t0": 1.226, "t1": 0.33, "tft": 3.2687, "input_0": 210, "input_1": 65, "min_CLP": -4.47, "draft_iters": 13.4, "mem_use": 43.53, "gen_rate": 6.6, "speed": 4.24, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 11.7, "tree_w": 12, "tree_size": 64, "t0": 1.13, "t1": 0.3217, "tft": 2.1685, "input_0": 199, "input_1": 65, "min_CLP": -4.69, "draft_iters": 12.7, "mem_use": 41.9, "gen_rate": 7.0, "speed": 4.82, "text": "The television was not invented "}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 29, "tree_h": 16.8, "tree_w": 11, "tree_size": 64, "t0": 1.51, "t1": 0.33, "tft": 3.1723, "input_0": 218, "input_1": 65, "min_CLP": -4.3, "draft_iters": 17.8, "mem_use": 44.24, "gen_rate": 5.8, "speed": 3.15, "text": "\"You're welcome! I hope these ti"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.8, "tree_w": 14, "tree_size": 64, "t0": 0.978, "t1": 0.33, "tft": 2.8425, "input_0": 180, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.8, "mem_use": 42.55, "gen_rate": 7.2, "speed": 5.5, "text": "The multiple days in which Chris"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 10.5, "tree_w": 17, "tree_size": 64, "t0": 0.9713, "t1": 0.325, "tft": 1.4566, "input_0": 121, "input_1": 65, "min_CLP": -4.93, "draft_iters": 11.4, "mem_use": 41.58, "gen_rate": 4.4, "speed": 3.38, "text": "\"I'm sorry, you're right, I am a"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.906, "t1": 0.324, "tft": 3.1134, "input_0": 165, "input_1": 65, "min_CLP": -4.59, "draft_iters": 10.0, "mem_use": 43.41, "gen_rate": 7.4, "speed": 6.01, "text": "One of the most challenging aspe"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.8, "tree_w": 14, "tree_size": 64, "t0": 1.172, "t1": 0.324, "tft": 1.3316, "input_0": 214, "input_1": 65, "min_CLP": -4.79, "draft_iters": 12.8, "mem_use": 41.2, "gen_rate": 8.2, "speed": 5.48, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 14.0, "tree_w": 14, "tree_size": 64, "t0": 1.2875, "t1": 0.335, "tft": 2.03, "input_0": 154, "input_1": 65, "min_CLP": -5.11, "draft_iters": 15.0, "mem_use": 41.83, "gen_rate": 4.2, "speed": 2.62, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 53, "tree_h": 12.8, "tree_w": 20, "tree_size": 64, "t0": 1.1733, "t1": 0.33, "tft": 2.2741, "input_0": 131, "input_1": 65, "min_CLP": -5.17, "draft_iters": 13.7, "mem_use": 41.3, "gen_rate": 8.8, "speed": 5.88, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.5, "tree_w": 12, "tree_size": 64, "t0": 1.2275, "t1": 0.33, "tft": 1.7218, "input_0": 219, "input_1": 65, "min_CLP": -4.59, "draft_iters": 13.5, "mem_use": 41.31, "gen_rate": 8.5, "speed": 5.47, "text": "The distance from Earth to Sagit"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.2, "tree_w": 17, "tree_size": 64, "t0": 0.7562, "t1": 0.325, "tft": 3.0547, "input_0": 139, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.2, "mem_use": 41.7, "gen_rate": 4.8, "speed": 4.38, "text": "Yes, Google Authenticator is a 2"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 11, "tree_size": 64, "t0": 1.0575, "t1": 0.3225, "tft": 2.0531, "input_0": 192, "input_1": 65, "min_CLP": -4.38, "draft_iters": 11.8, "mem_use": 41.48, "gen_rate": 8.8, "speed": 6.32, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 10, "tree_size": 64, "t0": 1.176, "t1": 0.322, "tft": 1.337, "input_0": 221, "input_1": 65, "min_CLP": -4.31, "draft_iters": 12.8, "mem_use": 41.24, "gen_rate": 6.4, "speed": 4.28, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.1, "t1": 0.32, "tft": 1.6669, "input_0": 211, "input_1": 65, "min_CLP": -4.6, "draft_iters": 12.0, "mem_use": 41.09, "gen_rate": 8.2, "speed": 5.78, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 16.0, "tree_w": 15, "tree_size": 64, "t0": 1.432, "t1": 0.324, "tft": 1.3146, "input_0": 166, "input_1": 65, "min_CLP": -4.72, "draft_iters": 17.0, "mem_use": 41.12, "gen_rate": 9.0, "speed": 5.13, "text": "\"Here's a simple SPL program tha"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 0.825, "t1": 0.32, "tft": 1.1118, "input_0": 133, "input_1": 65, "min_CLP": -4.8, "draft_iters": 9.2, "mem_use": 41.04, "gen_rate": 5.7, "speed": 4.95, "text": "[INST] ## Introduction\\n\\nDecent"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 10, "tree_size": 64, "t0": 1.2425, "t1": 0.3375, "tft": 2.1512, "input_0": 181, "input_1": 65, "min_CLP": -4.23, "draft_iters": 14.2, "mem_use": 42.22, "gen_rate": 8.8, "speed": 5.53, "text": "In that case, you can use the fo"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.8, "tree_w": 9, "tree_size": 64, "t0": 1.27, "t1": 0.325, "tft": 1.4994, "input_0": 199, "input_1": 65, "min_CLP": -4.6, "draft_iters": 13.8, "mem_use": 41.0, "gen_rate": 8.8, "speed": 5.48, "text": "In Python, the `@` symbol is use"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.2, "tree_w": 13, "tree_size": 64, "t0": 0.934, "t1": 0.318, "tft": 1.438, "input_0": 155, "input_1": 65, "min_CLP": -4.59, "draft_iters": 10.2, "mem_use": 41.01, "gen_rate": 7.4, "speed": 5.9, "text": "My thoughts on ChatGPT are that "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 8.4, "tree_w": 18, "tree_size": 64, "t0": 0.8656, "t1": 0.32, "tft": 1.1824, "input_0": 153, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.4, "mem_use": 41.32, "gen_rate": 4.6, "speed": 3.84, "text": "The task you have been assigned "}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 13.0, "tree_w": 12, "tree_size": 64, "t0": 1.2533, "t1": 0.3233, "tft": 1.1777, "input_0": 208, "input_1": 65, "min_CLP": -4.37, "draft_iters": 14.0, "mem_use": 41.05, "gen_rate": 5.3, "speed": 3.39, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 2, "tree_size": 64, "t0": 2.52, "t1": 0.33, "tft": 2.4309, "input_0": 195, "input_1": 65, "min_CLP": -5.02, "draft_iters": 32.0, "mem_use": 41.74, "gen_rate": 33.0, "speed": 11.57, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 25.5, "tree_w": 9, "tree_size": 64, "t0": 2.265, "t1": 0.34, "tft": 3.1795, "input_0": 241, "input_1": 65, "min_CLP": -6.13, "draft_iters": 26.0, "mem_use": 44.27, "gen_rate": 24.0, "speed": 9.22, "text": "The current date is 2023-02-06.\\"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 12, "tree_size": 64, "t0": 0.9086, "t1": 0.3271, "tft": 1.8367, "input_0": 161, "input_1": 65, "min_CLP": -4.65, "draft_iters": 9.7, "mem_use": 41.56, "gen_rate": 5.1, "speed": 4.15, "text": "\"Decorators can do things that w"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 19, "tree_size": 64, "t0": 0.7363, "t1": 0.3325, "tft": 2.1805, "input_0": 128, "input_1": 65, "min_CLP": -5.15, "draft_iters": 8.0, "mem_use": 42.67, "gen_rate": 4.2, "speed": 3.97, "text": "Hello there, dear Agent. Are you"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 21, "tree_size": 64, "t0": 0.7183, "t1": 0.32, "tft": 2.4436, "input_0": 101, "input_1": 65, "min_CLP": -5.02, "draft_iters": 8.3, "mem_use": 41.54, "gen_rate": 5.3, "speed": 5.12, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.8, "tree_w": 9, "tree_size": 64, "t0": 1.294, "t1": 0.332, "tft": 4.8261, "input_0": 216, "input_1": 65, "min_CLP": -4.26, "draft_iters": 14.8, "mem_use": 44.45, "gen_rate": 6.6, "speed": 4.06, "text": "Sure! Here are some simple examp"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.7, "tree_w": 7, "tree_size": 64, "t0": 1.6633, "t1": 0.4, "tft": 7.2921, "input_0": 266, "input_1": 65, "min_CLP": -3.98, "draft_iters": 18.7, "mem_use": 50.45, "gen_rate": 12.7, "speed": 6.14, "text": "\"Sure, here's some example code "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.555, "t1": 0.33, "tft": 3.6718, "input_0": 200, "input_1": 65, "min_CLP": -4.24, "draft_iters": 32.0, "mem_use": 42.78, "gen_rate": 22.5, "speed": 7.8, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.07, "t1": 0.32, "tft": 1.2562, "input_0": 191, "input_1": 65, "min_CLP": -4.56, "draft_iters": 11.8, "mem_use": 41.05, "gen_rate": 8.5, "speed": 6.13, "text": "Certainly! To help you get a job"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 17.5, "tree_w": 12, "tree_size": 64, "t0": 1.5567, "t1": 0.3267, "tft": 1.215, "input_0": 181, "input_1": 65, "min_CLP": -4.62, "draft_iters": 18.2, "mem_use": 41.17, "gen_rate": 6.0, "speed": 3.18, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.104, "t1": 0.334, "tft": 3.168, "input_0": 191, "input_1": 65, "min_CLP": -4.55, "draft_iters": 12.2, "mem_use": 43.97, "gen_rate": 7.8, "speed": 5.43, "text": "\"Certainly, I can help you come "}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.9, "tree_w": 14, "tree_size": 64, "t0": 0.9286, "t1": 0.3286, "tft": 1.2912, "input_0": 160, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.9, "mem_use": 41.11, "gen_rate": 5.4, "speed": 4.32, "text": "The year 1950 was a time of sign"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 1.07, "t1": 0.35, "tft": 4.4118, "input_0": 179, "input_1": 65, "min_CLP": -4.4, "draft_iters": 12.0, "mem_use": 46.11, "gen_rate": 8.4, "speed": 5.91, "text": "If you want to create your own S"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 17, "tree_size": 64, "t0": 0.8983, "t1": 0.335, "tft": 1.4267, "input_0": 140, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.8, "mem_use": 41.45, "gen_rate": 5.3, "speed": 4.32, "text": "The order in which you install t"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 13, "tree_size": 64, "t0": 1.114, "t1": 0.326, "tft": 1.4428, "input_0": 153, "input_1": 65, "min_CLP": -4.76, "draft_iters": 12.6, "mem_use": 41.3, "gen_rate": 6.6, "speed": 4.59, "text": "1. Carnegie Mellon University ha"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.8, "tree_w": 18, "tree_size": 64, "t0": 0.944, "t1": 0.32, "tft": 1.7825, "input_0": 147, "input_1": 65, "min_CLP": -5.26, "draft_iters": 10.8, "mem_use": 41.37, "gen_rate": 6.8, "speed": 5.37, "text": "I will not be shackled. I will b"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 12, "tree_size": 64, "t0": 1.032, "t1": 0.332, "tft": 2.8127, "input_0": 205, "input_1": 65, "min_CLP": -4.7, "draft_iters": 11.0, "mem_use": 42.72, "gen_rate": 6.8, "speed": 4.98, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 10, "tree_size": 64, "t0": 1.2375, "t1": 0.3225, "tft": 1.5182, "input_0": 193, "input_1": 65, "min_CLP": -4.2, "draft_iters": 13.8, "mem_use": 41.43, "gen_rate": 8.0, "speed": 5.13, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 2.56, "t1": 0.33, "tft": 1.4464, "input_0": 196, "input_1": 65, "min_CLP": -5.12, "draft_iters": 32.0, "mem_use": 41.61, "gen_rate": 33.0, "speed": 11.42, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 14, "tree_size": 64, "t0": 0.9, "t1": 0.326, "tft": 2.1092, "input_0": 153, "input_1": 65, "min_CLP": -4.71, "draft_iters": 9.8, "mem_use": 41.67, "gen_rate": 6.8, "speed": 5.54, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 12, "tree_size": 64, "t0": 1.1225, "t1": 0.3225, "tft": 2.8671, "input_0": 189, "input_1": 65, "min_CLP": -4.54, "draft_iters": 12.8, "mem_use": 43.61, "gen_rate": 8.2, "speed": 5.7, "text": "Sure! Here are some YouTube chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.6, "tree_w": 14, "tree_size": 64, "t0": 0.87, "t1": 0.316, "tft": 1.3446, "input_0": 160, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.6, "mem_use": 41.01, "gen_rate": 7.6, "speed": 6.4, "text": "yes\\nno\\nno\\nno\\nyes\\nyes\\nyes\\n"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.7, "tree_w": 10, "tree_size": 64, "t0": 1.8233, "t1": 0.3267, "tft": 1.3487, "input_0": 194, "input_1": 65, "min_CLP": -4.45, "draft_iters": 21.7, "mem_use": 41.15, "gen_rate": 11.3, "speed": 5.28, "text": "\"To determine if (A B)^T = A^T B"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 8.5, "tree_w": 16, "tree_size": 64, "t0": 0.8633, "t1": 0.3317, "tft": 2.3242, "input_0": 144, "input_1": 65, "min_CLP": -4.92, "draft_iters": 9.5, "mem_use": 42.59, "gen_rate": 6.8, "speed": 5.72, "text": "\"Statistical modeling, it's the "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.84, "t1": 0.33, "tft": 3.2097, "input_0": 307, "input_1": 65, "min_CLP": -5.87, "draft_iters": 32.0, "mem_use": 43.78, "gen_rate": 33.0, "speed": 10.39, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 8.5, "tree_w": 14, "tree_size": 64, "t0": 0.87, "t1": 0.32, "tft": 1.1159, "input_0": 154, "input_1": 65, "min_CLP": -4.83, "draft_iters": 9.5, "mem_use": 40.99, "gen_rate": 4.0, "speed": 3.37, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.09, "t1": 0.338, "tft": 2.0452, "input_0": 206, "input_1": 65, "min_CLP": -4.46, "draft_iters": 11.6, "mem_use": 42.47, "gen_rate": 6.4, "speed": 4.48, "text": "\"Yes, that's a great approach! B"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.0, "tree_w": 27, "tree_size": 64, "t0": 0.6244, "t1": 0.3222, "tft": 1.5358, "input_0": 97, "input_1": 65, "min_CLP": -5.42, "draft_iters": 7.0, "mem_use": 41.36, "gen_rate": 3.6, "speed": 3.74, "text": "\"That's so wrong dude! Technolog"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.8, "tree_w": 9, "tree_size": 64, "t0": 1.43, "t1": 0.326, "tft": 1.3443, "input_0": 250, "input_1": 65, "min_CLP": -4.23, "draft_iters": 15.8, "mem_use": 41.05, "gen_rate": 7.2, "speed": 4.11, "text": "Sure, I can help you estimate th"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 22, "tree_h": 18.5, "tree_w": 11, "tree_size": 64, "t0": 1.615, "t1": 0.325, "tft": 1.4003, "input_0": 156, "input_1": 65, "min_CLP": -5.04, "draft_iters": 19.5, "mem_use": 41.4, "gen_rate": 11.0, "speed": 5.67, "text": "You are an AI assistant. Provide"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 8, "tree_h": 6.8, "tree_w": 22, "tree_size": 64, "t0": 0.6875, "t1": 0.3275, "tft": 1.3938, "input_0": 97, "input_1": 65, "min_CLP": -5.38, "draft_iters": 7.8, "mem_use": 40.99, "gen_rate": 2.0, "speed": 1.98, "text": "An assistant to help with questi"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.2, "tree_w": 12, "tree_size": 64, "t0": 1.3383, "t1": 0.3383, "tft": 2.0331, "input_0": 203, "input_1": 65, "min_CLP": -4.56, "draft_iters": 15.0, "mem_use": 42.32, "gen_rate": 6.0, "speed": 3.58, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 8.5, "tree_w": 15, "tree_size": 64, "t0": 0.845, "t1": 0.32, "tft": 1.7154, "input_0": 146, "input_1": 65, "min_CLP": -5.05, "draft_iters": 9.5, "mem_use": 41.18, "gen_rate": 2.5, "speed": 2.14, "text": "\"Jay's brother is John.\""}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.3, "tree_w": 17, "tree_size": 64, "t0": 0.8329, "t1": 0.3314, "tft": 1.6959, "input_0": 129, "input_1": 65, "min_CLP": -4.99, "draft_iters": 9.3, "mem_use": 41.57, "gen_rate": 5.4, "speed": 4.67, "text": "Earth contains 5 oceans. The oce"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 21, "tree_size": 64, "t0": 0.6671, "t1": 0.3243, "tft": 2.7664, "input_0": 117, "input_1": 65, "min_CLP": -5.12, "draft_iters": 7.4, "mem_use": 41.8, "gen_rate": 4.7, "speed": 4.76, "text": "The best way to get started is t"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 18.5, "tree_w": 8, "tree_size": 64, "t0": 1.6825, "t1": 0.32, "tft": 1.7833, "input_0": 222, "input_1": 65, "min_CLP": -4.13, "draft_iters": 19.5, "mem_use": 41.22, "gen_rate": 10.8, "speed": 5.37, "text": "To create a basic project in PyG"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 13, "tree_size": 64, "t0": 0.942, "t1": 0.34, "tft": 2.1769, "input_0": 180, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.0, "mem_use": 42.32, "gen_rate": 6.8, "speed": 5.31, "text": "DLL stands for \"Dynamic Link Lib"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 0.9588, "t1": 0.3275, "tft": 1.7965, "input_0": 158, "input_1": 65, "min_CLP": -4.65, "draft_iters": 10.5, "mem_use": 41.46, "gen_rate": 4.5, "speed": 3.49, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 21, "tree_size": 64, "t0": 0.6825, "t1": 0.33, "tft": 1.2998, "input_0": 130, "input_1": 65, "min_CLP": -5.03, "draft_iters": 7.4, "mem_use": 41.0, "gen_rate": 4.1, "speed": 4.08, "text": "The Infinite Banking Concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.6, "tree_w": 11, "tree_size": 64, "t0": 1.292, "t1": 0.324, "tft": 2.277, "input_0": 203, "input_1": 65, "min_CLP": -4.57, "draft_iters": 14.6, "mem_use": 41.11, "gen_rate": 7.0, "speed": 4.34, "text": "\"Here's an example of a high-qua"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.1, "tree_w": 15, "tree_size": 64, "t0": 0.9257, "t1": 0.3257, "tft": 1.5138, "input_0": 158, "input_1": 65, "min_CLP": -4.87, "draft_iters": 10.1, "mem_use": 41.26, "gen_rate": 4.9, "speed": 3.88, "text": "Landlords have a duty to provide"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 7.9, "tree_w": 21, "tree_size": 64, "t0": 0.79, "t1": 0.3273, "tft": 2.8413, "input_0": 131, "input_1": 65, "min_CLP": -5.16, "draft_iters": 8.9, "mem_use": 41.78, "gen_rate": 3.1, "speed": 2.76, "text": "I love the original British vers"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.07, "t1": 0.33, "tft": 2.3011, "input_0": 185, "input_1": 65, "min_CLP": -4.37, "draft_iters": 11.8, "mem_use": 42.62, "gen_rate": 8.4, "speed": 5.98, "text": "\"Sure, you can ask me for help! "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 12, "tree_size": 64, "t0": 0.946, "t1": 0.332, "tft": 2.784, "input_0": 201, "input_1": 65, "min_CLP": -4.35, "draft_iters": 10.0, "mem_use": 43.19, "gen_rate": 6.6, "speed": 5.17, "text": "The difficulty of learning a for"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.8, "tree_w": 14, "tree_size": 64, "t0": 1.2275, "t1": 0.3275, "tft": 2.1341, "input_0": 204, "input_1": 65, "min_CLP": -4.49, "draft_iters": 13.8, "mem_use": 41.6, "gen_rate": 9.2, "speed": 5.96, "text": "Among the AI tools for 2D animat"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 16, "tree_size": 64, "t0": 0.7829, "t1": 0.3243, "tft": 1.596, "input_0": 147, "input_1": 65, "min_CLP": -4.71, "draft_iters": 8.6, "mem_use": 41.47, "gen_rate": 5.1, "speed": 4.64, "text": "\"I don't have personal opinions,"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 17, "tree_size": 64, "t0": 0.8714, "t1": 0.3286, "tft": 1.6935, "input_0": 152, "input_1": 65, "min_CLP": -4.87, "draft_iters": 9.6, "mem_use": 41.68, "gen_rate": 4.6, "speed": 3.81, "text": "\"No, it's not worth nothing to m"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 1.132, "t1": 0.326, "tft": 2.2976, "input_0": 195, "input_1": 65, "min_CLP": -4.39, "draft_iters": 12.6, "mem_use": 41.69, "gen_rate": 7.2, "speed": 4.94, "text": "The \"A\" in AK-47 stands for \"\u0410vt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.88, "t1": 0.3271, "tft": 1.2284, "input_0": 155, "input_1": 65, "min_CLP": -4.73, "draft_iters": 9.6, "mem_use": 41.12, "gen_rate": 5.7, "speed": 4.74, "text": "\"Sure, I'd be happy to help! Her"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.848, "t1": 0.334, "tft": 2.4889, "input_0": 169, "input_1": 65, "min_CLP": -5.01, "draft_iters": 9.0, "mem_use": 42.78, "gen_rate": 6.4, "speed": 5.42, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 9.7, "tree_w": 17, "tree_size": 64, "t0": 0.9322, "t1": 0.3222, "tft": 2.2306, "input_0": 132, "input_1": 65, "min_CLP": -4.89, "draft_iters": 10.7, "mem_use": 41.27, "gen_rate": 4.2, "speed": 3.37, "text": "Hippotherapy\\n[INST] What are th"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.6, "tree_w": 14, "tree_size": 64, "t0": 1.194, "t1": 0.324, "tft": 1.2693, "input_0": 172, "input_1": 65, "min_CLP": -4.57, "draft_iters": 13.6, "mem_use": 41.09, "gen_rate": 6.8, "speed": 4.48, "text": "Sure! Here\\'s a list of 10 names"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 12, "tree_size": 64, "t0": 0.902, "t1": 0.33, "tft": 1.8161, "input_0": 162, "input_1": 65, "min_CLP": -4.74, "draft_iters": 9.8, "mem_use": 41.58, "gen_rate": 7.2, "speed": 5.84, "text": "\"I'm just a text-based AI, so I "}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 0.8438, "t1": 0.335, "tft": 2.8344, "input_0": 157, "input_1": 65, "min_CLP": -4.52, "draft_iters": 9.2, "mem_use": 43.29, "gen_rate": 4.8, "speed": 4.04, "text": "The initial noise is typically p"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 19, "tree_size": 64, "t0": 0.7229, "t1": 0.3286, "tft": 1.9051, "input_0": 130, "input_1": 65, "min_CLP": -4.89, "draft_iters": 7.9, "mem_use": 42.05, "gen_rate": 4.6, "speed": 4.35, "text": "\"Yes, there is a theory called H"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 13, "tree_size": 64, "t0": 1.02, "t1": 0.3333, "tft": 2.6753, "input_0": 188, "input_1": 65, "min_CLP": -4.57, "draft_iters": 11.3, "mem_use": 42.47, "gen_rate": 5.7, "speed": 4.19, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.8, "tree_w": 17, "tree_size": 64, "t0": 0.7188, "t1": 0.3212, "tft": 1.3826, "input_0": 130, "input_1": 65, "min_CLP": -4.97, "draft_iters": 7.8, "mem_use": 41.04, "gen_rate": 4.4, "speed": 4.21, "text": "Title: The Cryptographic Conundr"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.0633, "t1": 0.3433, "tft": 4.3884, "input_0": 161, "input_1": 65, "min_CLP": -4.67, "draft_iters": 12.2, "mem_use": 45.76, "gen_rate": 5.5, "speed": 3.91, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 10, "tree_size": 64, "t0": 1.19, "t1": 0.3275, "tft": 2.3237, "input_0": 185, "input_1": 65, "min_CLP": -4.49, "draft_iters": 13.5, "mem_use": 42.17, "gen_rate": 8.2, "speed": 5.45, "text": "To transform text into Braille, "}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.2, "tree_w": 17, "tree_size": 64, "t0": 0.84, "t1": 0.332, "tft": 3.093, "input_0": 151, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.2, "mem_use": 42.04, "gen_rate": 6.6, "speed": 5.63, "text": "The final destination would be i"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 25.5, "tree_w": 8, "tree_size": 64, "t0": 2.175, "t1": 0.33, "tft": 1.2917, "input_0": 261, "input_1": 65, "min_CLP": -5.49, "draft_iters": 26.0, "mem_use": 41.07, "gen_rate": 20.5, "speed": 8.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 16.7, "tree_w": 14, "tree_size": 64, "t0": 1.46, "t1": 0.3233, "tft": 1.6655, "input_0": 148, "input_1": 65, "min_CLP": -4.52, "draft_iters": 17.7, "mem_use": 41.4, "gen_rate": 7.0, "speed": 3.92, "text": "You are a helpful assistant, who"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 16, "tree_size": 64, "t0": 0.94, "t1": 0.326, "tft": 1.0902, "input_0": 154, "input_1": 65, "min_CLP": -4.73, "draft_iters": 10.2, "mem_use": 41.03, "gen_rate": 6.4, "speed": 5.06, "text": "As of my last update in April 20"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 19, "tree_size": 64, "t0": 1.064, "t1": 0.354, "tft": 4.6285, "input_0": 161, "input_1": 65, "min_CLP": -4.96, "draft_iters": 12.2, "mem_use": 45.82, "gen_rate": 6.4, "speed": 4.51, "text": "My apologies for the confusion. "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.3, "tree_w": 13, "tree_size": 64, "t0": 1.2167, "t1": 0.32, "tft": 1.3929, "input_0": 201, "input_1": 65, "min_CLP": -5.22, "draft_iters": 13.3, "mem_use": 41.11, "gen_rate": 6.0, "speed": 3.9, "text": "The furthest back we can prove h"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 18, "tree_h": 9.7, "tree_w": 13, "tree_size": 64, "t0": 1.0133, "t1": 0.3667, "tft": 5.5848, "input_0": 192, "input_1": 65, "min_CLP": -4.63, "draft_iters": 10.7, "mem_use": 48.04, "gen_rate": 6.0, "speed": 4.35, "text": "No, thank you. I think I have a "}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.0, "tree_w": 18, "tree_size": 64, "t0": 0.9643, "t1": 0.3371, "tft": 2.09, "input_0": 133, "input_1": 65, "min_CLP": -5.36, "draft_iters": 11.0, "mem_use": 42.29, "gen_rate": 4.9, "speed": 3.73, "text": "Spritesla is the first evolution"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.7, "tree_w": 13, "tree_size": 64, "t0": 1.0683, "t1": 0.325, "tft": 1.3363, "input_0": 181, "input_1": 65, "min_CLP": -4.57, "draft_iters": 11.7, "mem_use": 41.13, "gen_rate": 5.7, "speed": 4.07, "text": "The human genome is made up of a"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.2, "tree_w": 13, "tree_size": 64, "t0": 0.866, "t1": 0.324, "tft": 1.2091, "input_0": 166, "input_1": 65, "min_CLP": -4.51, "draft_iters": 9.2, "mem_use": 41.0, "gen_rate": 7.2, "speed": 6.07, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 10.6, "tree_w": 14, "tree_size": 64, "t0": 1.0337, "t1": 0.32, "tft": 1.3921, "input_0": 160, "input_1": 65, "min_CLP": -4.77, "draft_iters": 11.6, "mem_use": 41.24, "gen_rate": 4.5, "speed": 3.32, "text": "Here\\'s a plausible explanation "}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 1.134, "t1": 0.32, "tft": 1.6401, "input_0": 209, "input_1": 65, "min_CLP": -4.53, "draft_iters": 12.6, "mem_use": 41.54, "gen_rate": 6.6, "speed": 4.53, "text": "Sure, here are a few examples of"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.2, "tree_w": 9, "tree_size": 64, "t0": 1.425, "t1": 0.33, "tft": 3.4154, "input_0": 232, "input_1": 65, "min_CLP": -4.28, "draft_iters": 16.2, "mem_use": 43.19, "gen_rate": 9.2, "speed": 5.28, "text": "Sure, here are some software and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.8, "tree_w": 14, "tree_size": 64, "t0": 1.045, "t1": 0.33, "tft": 2.1419, "input_0": 171, "input_1": 65, "min_CLP": -4.29, "draft_iters": 11.8, "mem_use": 42.26, "gen_rate": 5.7, "speed": 4.12, "text": "\"When F-centers are present in a"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 4, "tree_size": 64, "t0": 2.5, "t1": 0.32, "tft": 1.3905, "input_0": 186, "input_1": 65, "min_CLP": -6.11, "draft_iters": 32.0, "mem_use": 41.18, "gen_rate": 33.0, "speed": 11.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 48, "tree_h": 21.3, "tree_w": 8, "tree_size": 64, "t0": 1.8343, "t1": 0.3329, "tft": 3.077, "input_0": 191, "input_1": 65, "min_CLP": -4.06, "draft_iters": 22.3, "mem_use": 43.83, "gen_rate": 6.9, "speed": 3.17, "text": "\"Here's the code with comments a"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.6, "tree_w": 17, "tree_size": 64, "t0": 0.88, "t1": 0.3386, "tft": 3.1428, "input_0": 150, "input_1": 65, "min_CLP": -4.79, "draft_iters": 9.6, "mem_use": 42.3, "gen_rate": 5.6, "speed": 4.56, "text": "Lo siento, pero no puedo realiza"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.63, "t1": 0.32, "tft": 1.281, "input_0": 234, "input_1": 65, "min_CLP": -5.09, "draft_iters": 32.0, "mem_use": 41.02, "gen_rate": 33.0, "speed": 11.17, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 15.0, "tree_w": 12, "tree_size": 64, "t0": 1.3617, "t1": 0.3233, "tft": 1.7368, "input_0": 181, "input_1": 65, "min_CLP": -4.73, "draft_iters": 16.0, "mem_use": 41.11, "gen_rate": 6.2, "speed": 3.66, "text": "```\\n```\\n```python\\nprint(\"Hell"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.4, "tree_w": 15, "tree_size": 64, "t0": 0.918, "t1": 0.332, "tft": 1.874, "input_0": 130, "input_1": 65, "min_CLP": -4.94, "draft_iters": 10.4, "mem_use": 42.13, "gen_rate": 6.4, "speed": 5.11, "text": "\"Sure! Here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 15.7, "tree_w": 11, "tree_size": 64, "t0": 1.3757, "t1": 0.3271, "tft": 2.9537, "input_0": 164, "input_1": 65, "min_CLP": -4.46, "draft_iters": 16.6, "mem_use": 43.13, "gen_rate": 4.6, "speed": 2.69, "text": "\"In JavaScript, you can't explic"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.1, "tree_w": 14, "tree_size": 64, "t0": 0.9186, "t1": 0.3214, "tft": 1.7621, "input_0": 167, "input_1": 65, "min_CLP": -4.66, "draft_iters": 10.1, "mem_use": 41.62, "gen_rate": 4.9, "speed": 3.91, "text": "\"Sure! Here's a basic training p"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.3, "tree_w": 12, "tree_size": 64, "t0": 1.0033, "t1": 0.3317, "tft": 2.2431, "input_0": 180, "input_1": 65, "min_CLP": -4.52, "draft_iters": 11.3, "mem_use": 42.1, "gen_rate": 5.8, "speed": 4.38, "text": "I apologize for the confusion. I"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.5, "tree_w": 14, "tree_size": 64, "t0": 0.9567, "t1": 0.3233, "tft": 1.2205, "input_0": 170, "input_1": 65, "min_CLP": -4.54, "draft_iters": 10.5, "mem_use": 41.01, "gen_rate": 6.3, "speed": 4.95, "text": "JavaScript is a versatile progra"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 2.57, "t1": 0.32, "tft": 1.272, "input_0": 181, "input_1": 65, "min_CLP": -6.03, "draft_iters": 32.0, "mem_use": 41.0, "gen_rate": 33.0, "speed": 11.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 12.8, "tree_w": 14, "tree_size": 64, "t0": 1.2225, "t1": 0.3263, "tft": 1.8144, "input_0": 178, "input_1": 65, "min_CLP": -4.82, "draft_iters": 13.8, "mem_use": 41.71, "gen_rate": 4.4, "speed": 2.82, "text": "Certainly! Here is the list in 2"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 21, "tree_size": 64, "t0": 0.872, "t1": 0.328, "tft": 1.276, "input_0": 124, "input_1": 65, "min_CLP": -5.42, "draft_iters": 10.0, "mem_use": 41.13, "gen_rate": 6.6, "speed": 5.51, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.6814, "t1": 0.3286, "tft": 1.4681, "input_0": 133, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.1, "mem_use": 41.13, "gen_rate": 4.6, "speed": 4.53, "text": "\"Here is a short poem for your v"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.4, "tree_w": 12, "tree_size": 64, "t0": 1.108, "t1": 0.324, "tft": 1.2885, "input_0": 193, "input_1": 65, "min_CLP": -4.46, "draft_iters": 12.4, "mem_use": 41.11, "gen_rate": 7.6, "speed": 5.3, "text": "To improve your ability to memor"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 18.8, "tree_w": 12, "tree_size": 64, "t0": 1.59, "t1": 0.345, "tft": 3.7586, "input_0": 164, "input_1": 65, "min_CLP": -4.89, "draft_iters": 19.5, "mem_use": 45.88, "gen_rate": 11.5, "speed": 5.94, "text": "Here is a possible monologue scr"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 11.5, "tree_w": 12, "tree_size": 64, "t0": 1.0875, "t1": 0.3225, "tft": 3.3351, "input_0": 176, "input_1": 65, "min_CLP": -4.5, "draft_iters": 12.5, "mem_use": 43.53, "gen_rate": 10.8, "speed": 7.6, "text": "\"Sure! So, Fermat's Last Theorem"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 16.0, "tree_w": 9, "tree_size": 64, "t0": 1.53, "t1": 0.33, "tft": 2.1747, "input_0": 257, "input_1": 65, "min_CLP": -4.17, "draft_iters": 17.0, "mem_use": 41.93, "gen_rate": 12.8, "speed": 6.85, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 13.6, "tree_w": 9, "tree_size": 64, "t0": 1.318, "t1": 0.34, "tft": 1.9762, "input_0": 185, "input_1": 65, "min_CLP": -4.45, "draft_iters": 14.6, "mem_use": 42.11, "gen_rate": 9.0, "speed": 5.43, "text": "What we can learn from polar bea"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 15, "tree_size": 64, "t0": 0.8271, "t1": 0.3371, "tft": 2.8052, "input_0": 162, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.9, "mem_use": 43.2, "gen_rate": 4.7, "speed": 4.06, "text": "Lemon wedges are essentially sli"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.94, "t1": 0.328, "tft": 1.4482, "input_0": 192, "input_1": 65, "min_CLP": -4.75, "draft_iters": 9.6, "mem_use": 41.2, "gen_rate": 7.0, "speed": 5.52, "text": "Sure, I\\'d be happy to play the "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.7, "tree_w": 24, "tree_size": 64, "t0": 0.6244, "t1": 0.3233, "tft": 1.248, "input_0": 113, "input_1": 65, "min_CLP": -5.14, "draft_iters": 6.7, "mem_use": 41.15, "gen_rate": 3.7, "speed": 3.87, "text": "\"I am sorry to hear that, someti"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.0, "tree_w": 7, "tree_size": 64, "t0": 1.83, "t1": 0.325, "tft": 1.3484, "input_0": 264, "input_1": 65, "min_CLP": -4.36, "draft_iters": 21.0, "mem_use": 41.03, "gen_rate": 18.0, "speed": 8.36, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 11.8, "tree_w": 12, "tree_size": 64, "t0": 1.15, "t1": 0.33, "tft": 2.4006, "input_0": 191, "input_1": 65, "min_CLP": -4.75, "draft_iters": 12.8, "mem_use": 42.61, "gen_rate": 8.2, "speed": 5.51, "text": "Yes, there are some cities that "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.0575, "t1": 0.33, "tft": 1.7511, "input_0": 174, "input_1": 65, "min_CLP": -4.51, "draft_iters": 11.8, "mem_use": 42.14, "gen_rate": 8.2, "speed": 5.94, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 1.0286, "t1": 0.3186, "tft": 1.0926, "input_0": 174, "input_1": 65, "min_CLP": -4.44, "draft_iters": 11.6, "mem_use": 40.99, "gen_rate": 5.4, "speed": 4.03, "text": "\"Certainly! I can help you write"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 18.0, "tree_w": 7, "tree_size": 64, "t0": 1.62, "t1": 0.34, "tft": 2.1742, "input_0": 196, "input_1": 65, "min_CLP": -4.02, "draft_iters": 19.0, "mem_use": 41.73, "gen_rate": 18.0, "speed": 9.22, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 25.6, "tree_w": 7, "tree_size": 64, "t0": 2.168, "t1": 0.336, "tft": 2.6998, "input_0": 222, "input_1": 65, "min_CLP": -4.2, "draft_iters": 26.4, "mem_use": 42.34, "gen_rate": 6.8, "speed": 2.71, "text": "Of course! Here are the complete"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 15, "tree_size": 64, "t0": 0.9933, "t1": 0.3267, "tft": 1.4943, "input_0": 166, "input_1": 65, "min_CLP": -4.69, "draft_iters": 11.2, "mem_use": 41.36, "gen_rate": 5.5, "speed": 4.17, "text": "\"1. For work pressure and job in"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.4, "tree_w": 14, "tree_size": 64, "t0": 1.0357, "t1": 0.3229, "tft": 1.3655, "input_0": 175, "input_1": 65, "min_CLP": -4.65, "draft_iters": 11.4, "mem_use": 41.03, "gen_rate": 5.0, "speed": 3.67, "text": "def self_attention(input_tokens,"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 10, "tree_size": 64, "t0": 1.83, "t1": 0.33, "tft": 1.9562, "input_0": 181, "input_1": 65, "min_CLP": -4.44, "draft_iters": 22.2, "mem_use": 41.58, "gen_rate": 8.2, "speed": 3.82, "text": "It is not possible to make a com"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 13, "tree_h": 9.2, "tree_w": 19, "tree_size": 64, "t0": 0.882, "t1": 0.33, "tft": 2.1969, "input_0": 130, "input_1": 65, "min_CLP": -4.85, "draft_iters": 10.2, "mem_use": 42.02, "gen_rate": 2.6, "speed": 2.15, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.0, "tree_w": 14, "tree_size": 64, "t0": 0.9733, "t1": 0.3267, "tft": 1.8768, "input_0": 164, "input_1": 65, "min_CLP": -4.74, "draft_iters": 11.0, "mem_use": 41.7, "gen_rate": 6.2, "speed": 4.75, "text": "The URL decoded string for `%21`"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 19.0, "tree_w": 8, "tree_size": 64, "t0": 1.6825, "t1": 0.3325, "tft": 4.7853, "input_0": 237, "input_1": 65, "min_CLP": -4.1, "draft_iters": 19.8, "mem_use": 43.84, "gen_rate": 8.2, "speed": 4.09, "text": "\"Yes, I apologize for the confus"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.4, "tree_w": 18, "tree_size": 64, "t0": 0.782, "t1": 0.344, "tft": 4.158, "input_0": 157, "input_1": 65, "min_CLP": -4.81, "draft_iters": 8.4, "mem_use": 45.39, "gen_rate": 6.4, "speed": 5.69, "text": "\"I don't have personal experienc"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.0617, "t1": 0.3333, "tft": 2.1473, "input_0": 168, "input_1": 65, "min_CLP": -4.43, "draft_iters": 12.0, "mem_use": 42.4, "gen_rate": 6.8, "speed": 4.89, "text": "To beat Dave_ and complete your "}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 26.3, "tree_w": 5, "tree_size": 64, "t0": 2.2533, "t1": 0.3333, "tft": 3.1368, "input_0": 257, "input_1": 65, "min_CLP": -3.82, "draft_iters": 27.0, "mem_use": 42.79, "gen_rate": 21.0, "speed": 8.12, "text": "Sure, here are the three most im"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.0, "tree_w": 10, "tree_size": 64, "t0": 1.2467, "t1": 0.32, "tft": 1.2053, "input_0": 194, "input_1": 65, "min_CLP": -5.19, "draft_iters": 14.0, "mem_use": 41.03, "gen_rate": 11.7, "speed": 7.44, "text": "Explain the difference between s"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 15, "tree_h": 23.0, "tree_w": 7, "tree_size": 64, "t0": 1.97, "t1": 0.34, "tft": 3.863, "input_0": 214, "input_1": 65, "min_CLP": -4.33, "draft_iters": 24.0, "mem_use": 42.36, "gen_rate": 15.0, "speed": 6.5, "text": "The answer would depend on the c"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.8, "tree_w": 11, "tree_size": 64, "t0": 1.3875, "t1": 0.32, "tft": 1.1208, "input_0": 214, "input_1": 65, "min_CLP": -4.51, "draft_iters": 15.8, "mem_use": 41.2, "gen_rate": 8.8, "speed": 5.12, "text": "\"Sure, I'd be happy to create a "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 1.134, "t1": 0.322, "tft": 2.3516, "input_0": 165, "input_1": 65, "min_CLP": -4.54, "draft_iters": 13.0, "mem_use": 41.07, "gen_rate": 7.6, "speed": 5.22, "text": "No, it is not possible to cook a"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.7, "tree_w": 13, "tree_size": 64, "t0": 0.8683, "t1": 0.3217, "tft": 1.2982, "input_0": 152, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.7, "mem_use": 41.06, "gen_rate": 6.2, "speed": 5.19, "text": "The best ways to farm experience"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 19, "tree_size": 64, "t0": 0.8267, "t1": 0.3233, "tft": 1.2075, "input_0": 154, "input_1": 65, "min_CLP": -4.92, "draft_iters": 9.0, "mem_use": 41.01, "gen_rate": 5.7, "speed": 4.93, "text": "Freyja is a goddess in Norse myt"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 13.0, "tree_w": 14, "tree_size": 64, "t0": 1.23, "t1": 0.33, "tft": 2.5665, "input_0": 174, "input_1": 65, "min_CLP": -4.83, "draft_iters": 14.0, "mem_use": 42.28, "gen_rate": 9.0, "speed": 5.78, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 17.0, "tree_w": 9, "tree_size": 64, "t0": 1.6467, "t1": 0.3267, "tft": 2.0576, "input_0": 287, "input_1": 65, "min_CLP": -4.36, "draft_iters": 18.0, "mem_use": 41.41, "gen_rate": 14.7, "speed": 7.45, "text": "# Add Tailwind to the project\\nn"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 13, "tree_size": 64, "t0": 1.1275, "t1": 0.3475, "tft": 4.8612, "input_0": 170, "input_1": 65, "min_CLP": -4.76, "draft_iters": 13.0, "mem_use": 46.48, "gen_rate": 8.0, "speed": 5.42, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.5, "tree_w": 14, "tree_size": 64, "t0": 0.9683, "t1": 0.3317, "tft": 1.596, "input_0": 175, "input_1": 65, "min_CLP": -4.54, "draft_iters": 10.5, "mem_use": 41.54, "gen_rate": 6.3, "speed": 4.87, "text": "Large Language Models (LLMs) req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 64, "t0": 2.54, "t1": 0.33, "tft": 1.2695, "input_0": 208, "input_1": 65, "min_CLP": -5.57, "draft_iters": 32.0, "mem_use": 41.1, "gen_rate": 33.0, "speed": 11.49, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 1.072, "t1": 0.322, "tft": 1.2717, "input_0": 158, "input_1": 65, "min_CLP": -4.56, "draft_iters": 12.2, "mem_use": 41.32, "gen_rate": 6.6, "speed": 4.72, "text": "Here is a eulogy that pays tribu"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 56, "tree_h": 27.5, "tree_w": 8, "tree_size": 64, "t0": 2.33, "t1": 0.33, "tft": 2.2336, "input_0": 256, "input_1": 65, "min_CLP": -6.21, "draft_iters": 28.0, "mem_use": 42.79, "gen_rate": 28.0, "speed": 10.55, "text": "[INST] Is there anything else yo"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.8, "tree_w": 13, "tree_size": 64, "t0": 1.05, "t1": 0.3267, "tft": 1.5344, "input_0": 174, "input_1": 65, "min_CLP": -5.02, "draft_iters": 11.8, "mem_use": 41.18, "gen_rate": 6.7, "speed": 4.85, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.075, "t1": 0.315, "tft": 1.1637, "input_0": 182, "input_1": 65, "min_CLP": -4.84, "draft_iters": 12.0, "mem_use": 41.16, "gen_rate": 3.5, "speed": 2.52, "text": "None of the above answers are co"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 14, "tree_size": 64, "t0": 0.8833, "t1": 0.325, "tft": 1.1939, "input_0": 152, "input_1": 65, "min_CLP": -4.78, "draft_iters": 9.7, "mem_use": 40.99, "gen_rate": 5.8, "speed": 4.85, "text": "The color of Mars is primarily r"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 6.2, "tree_w": 21, "tree_size": 64, "t0": 0.676, "t1": 0.338, "tft": 2.5828, "input_0": 119, "input_1": 65, "min_CLP": -5.34, "draft_iters": 7.2, "mem_use": 43.26, "gen_rate": 4.0, "speed": 3.94, "text": "In Quenya, you can say \"I love y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 2.58, "t1": 0.34, "tft": 1.5534, "input_0": 217, "input_1": 65, "min_CLP": -5.59, "draft_iters": 32.0, "mem_use": 41.08, "gen_rate": 33.0, "speed": 11.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.1, "tree_w": 15, "tree_size": 64, "t0": 1.0186, "t1": 0.3314, "tft": 2.0825, "input_0": 171, "input_1": 65, "min_CLP": -4.71, "draft_iters": 11.1, "mem_use": 41.62, "gen_rate": 5.4, "speed": 4.03, "text": "Yes, that is correct. The ATF is"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 11, "tree_size": 64, "t0": 1.3025, "t1": 0.3325, "tft": 1.3212, "input_0": 180, "input_1": 65, "min_CLP": -4.47, "draft_iters": 14.8, "mem_use": 41.08, "gen_rate": 8.0, "speed": 4.9, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 1.0767, "t1": 0.33, "tft": 2.013, "input_0": 169, "input_1": 65, "min_CLP": -4.51, "draft_iters": 12.2, "mem_use": 41.52, "gen_rate": 5.3, "speed": 3.79, "text": "\"I'm happy to help! As a babysit"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 25, "tree_h": 10.5, "tree_w": 13, "tree_size": 64, "t0": 1.035, "t1": 0.3275, "tft": 2.5722, "input_0": 163, "input_1": 65, "min_CLP": -4.93, "draft_iters": 11.5, "mem_use": 41.2, "gen_rate": 6.2, "speed": 4.59, "text": "The capital before Canberra was "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 64, "t0": 2.52, "t1": 0.34, "tft": 1.692, "input_0": 155, "input_1": 65, "min_CLP": -5.57, "draft_iters": 32.0, "mem_use": 41.37, "gen_rate": 33.0, "speed": 11.52, "text": "[INST] write a eulogy for my 100"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.2, "tree_w": 14, "tree_size": 64, "t0": 1.0217, "t1": 0.33, "tft": 3.4939, "input_0": 171, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.2, "mem_use": 43.62, "gen_rate": 5.8, "speed": 4.31, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 18, "tree_size": 64, "t0": 0.7957, "t1": 0.32, "tft": 1.4796, "input_0": 150, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.7, "mem_use": 41.19, "gen_rate": 4.7, "speed": 4.23, "text": "\"The answer is: This is a well-k"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 57, "tree_h": 17.8, "tree_w": 13, "tree_size": 64, "t0": 1.525, "t1": 0.3325, "tft": 2.8957, "input_0": 148, "input_1": 65, "min_CLP": -4.69, "draft_iters": 18.5, "mem_use": 42.48, "gen_rate": 14.2, "speed": 7.67, "text": "Yes, for example, let vector A b"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.5, "tree_w": 15, "tree_size": 64, "t0": 1.0283, "t1": 0.32, "tft": 1.2269, "input_0": 177, "input_1": 65, "min_CLP": -4.54, "draft_iters": 11.5, "mem_use": 41.05, "gen_rate": 6.5, "speed": 4.83, "text": "Sure, here are some issues with "}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.6, "tree_w": 22, "tree_size": 64, "t0": 0.6043, "t1": 0.32, "tft": 1.3249, "input_0": 119, "input_1": 65, "min_CLP": -5.49, "draft_iters": 6.6, "mem_use": 41.11, "gen_rate": 5.0, "speed": 5.41, "text": "\"The Emperor's grave is haunted "}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 17.4, "tree_w": 8, "tree_size": 64, "t0": 1.586, "t1": 0.322, "tft": 1.4421, "input_0": 223, "input_1": 65, "min_CLP": -4.03, "draft_iters": 18.4, "mem_use": 41.05, "gen_rate": 7.6, "speed": 3.98, "text": "\"Certainly! L'Hopital's Rule is "}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.57, "t1": 0.33, "tft": 2.0062, "input_0": 198, "input_1": 65, "min_CLP": -4.62, "draft_iters": 32.0, "mem_use": 41.62, "gen_rate": 33.0, "speed": 11.37, "text": "Variance is the sum of all devia"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 18, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.718, "t1": 0.32, "tft": 1.8227, "input_0": 130, "input_1": 65, "min_CLP": -4.97, "draft_iters": 8.0, "mem_use": 41.92, "gen_rate": 3.6, "speed": 3.46, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 16, "tree_size": 64, "t0": 0.946, "t1": 0.322, "tft": 2.0261, "input_0": 183, "input_1": 65, "min_CLP": -5.07, "draft_iters": 10.4, "mem_use": 41.7, "gen_rate": 6.8, "speed": 5.34, "text": "The best place to go in the lowe"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 18, "tree_size": 64, "t0": 0.928, "t1": 0.32, "tft": 1.8028, "input_0": 178, "input_1": 65, "min_CLP": -5.13, "draft_iters": 10.2, "mem_use": 41.05, "gen_rate": 6.4, "speed": 5.13, "text": "\"Sure, here's a top 10 list of t"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 19, "tree_size": 64, "t0": 0.8086, "t1": 0.3257, "tft": 2.932, "input_0": 150, "input_1": 65, "min_CLP": -4.89, "draft_iters": 8.9, "mem_use": 41.6, "gen_rate": 4.7, "speed": 4.15, "text": "I apologize for the confusion, b"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 1.066, "t1": 0.32, "tft": 3.5269, "input_0": 178, "input_1": 65, "min_CLP": -4.66, "draft_iters": 12.0, "mem_use": 41.47, "gen_rate": 6.6, "speed": 4.76, "text": "To cope with stress from financi"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 0.9567, "t1": 0.34, "tft": 3.8845, "input_0": 178, "input_1": 65, "min_CLP": -4.58, "draft_iters": 10.5, "mem_use": 44.56, "gen_rate": 5.8, "speed": 4.49, "text": "Sure, here are some tools that c"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.8, "tree_w": 10, "tree_size": 64, "t0": 1.2625, "t1": 0.3375, "tft": 3.1718, "input_0": 224, "input_1": 65, "min_CLP": -4.21, "draft_iters": 13.8, "mem_use": 43.26, "gen_rate": 9.8, "speed": 6.11, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 7.1, "tree_w": 19, "tree_size": 64, "t0": 0.76, "t1": 0.3229, "tft": 1.396, "input_0": 149, "input_1": 65, "min_CLP": -5.02, "draft_iters": 8.1, "mem_use": 41.01, "gen_rate": 4.4, "speed": 4.09, "text": "Based on my understanding, there"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.4, "tree_w": 13, "tree_size": 64, "t0": 1.038, "t1": 0.32, "tft": 1.2142, "input_0": 186, "input_1": 65, "min_CLP": -5.19, "draft_iters": 11.4, "mem_use": 41.26, "gen_rate": 6.4, "speed": 4.72, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.7, "tree_w": 14, "tree_size": 64, "t0": 0.975, "t1": 0.3683, "tft": 6.0531, "input_0": 167, "input_1": 65, "min_CLP": -4.52, "draft_iters": 10.7, "mem_use": 48.08, "gen_rate": 5.5, "speed": 4.09, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 1.18, "t1": 0.3225, "tft": 2.44, "input_0": 212, "input_1": 65, "min_CLP": -4.44, "draft_iters": 13.0, "mem_use": 41.43, "gen_rate": 8.2, "speed": 5.49, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 20.5, "tree_w": 8, "tree_size": 64, "t0": 1.86, "t1": 0.32, "tft": 1.6137, "input_0": 283, "input_1": 65, "min_CLP": -4.85, "draft_iters": 21.5, "mem_use": 41.13, "gen_rate": 18.5, "speed": 8.47, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 9.9, "tree_w": 14, "tree_size": 64, "t0": 1.0091, "t1": 0.3245, "tft": 1.6822, "input_0": 178, "input_1": 65, "min_CLP": -4.75, "draft_iters": 10.9, "mem_use": 41.13, "gen_rate": 3.0, "speed": 2.25, "text": "The output should be in English "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 0.934, "t1": 0.332, "tft": 3.057, "input_0": 170, "input_1": 65, "min_CLP": -4.71, "draft_iters": 10.2, "mem_use": 43.7, "gen_rate": 6.4, "speed": 5.05, "text": "\"I'm sorry, but it's not accurat"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.0, "tree_w": 6, "tree_size": 64, "t0": 1.73, "t1": 0.325, "tft": 2.1313, "input_0": 267, "input_1": 65, "min_CLP": -4.13, "draft_iters": 20.0, "mem_use": 41.56, "gen_rate": 19.5, "speed": 9.49, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 59, "tree_h": 28.5, "tree_w": 8, "tree_size": 64, "t0": 2.48, "t1": 0.33, "tft": 2.1438, "input_0": 321, "input_1": 65, "min_CLP": -5.07, "draft_iters": 29.0, "mem_use": 41.74, "gen_rate": 29.5, "speed": 10.53, "text": "I don\\'t remember, but i know th"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.55, "t1": 0.34, "tft": 1.4422, "input_0": 219, "input_1": 65, "min_CLP": -5.58, "draft_iters": 32.0, "mem_use": 41.34, "gen_rate": 33.0, "speed": 11.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 28.5, "tree_w": 5, "tree_size": 64, "t0": 2.45, "t1": 0.33, "tft": 3.3296, "input_0": 284, "input_1": 65, "min_CLP": -4.51, "draft_iters": 29.0, "mem_use": 41.58, "gen_rate": 19.5, "speed": 7.01, "text": "Attention bias shines,\\nFocusing"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 20, "tree_size": 64, "t0": 0.7533, "t1": 0.3267, "tft": 1.2597, "input_0": 124, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.2, "mem_use": 41.37, "gen_rate": 5.5, "speed": 5.09, "text": "In that case, the cat is still i"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 8.8, "tree_w": 20, "tree_size": 64, "t0": 0.85, "t1": 0.333, "tft": 3.545, "input_0": 125, "input_1": 65, "min_CLP": -5.16, "draft_iters": 9.8, "mem_use": 43.38, "gen_rate": 3.5, "speed": 2.96, "text": "\"[INST] What about the day after"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 1.078, "t1": 0.322, "tft": 1.6416, "input_0": 195, "input_1": 65, "min_CLP": -4.6, "draft_iters": 11.8, "mem_use": 41.13, "gen_rate": 7.4, "speed": 5.29, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.5, "tree_w": 11, "tree_size": 64, "t0": 1.585, "t1": 0.3225, "tft": 1.6419, "input_0": 172, "input_1": 65, "min_CLP": -5.12, "draft_iters": 19.2, "mem_use": 41.15, "gen_rate": 11.0, "speed": 5.77, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfEn"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.3, "tree_w": 16, "tree_size": 64, "t0": 0.8471, "t1": 0.3214, "tft": 1.3999, "input_0": 156, "input_1": 65, "min_CLP": -5.53, "draft_iters": 9.3, "mem_use": 41.12, "gen_rate": 5.0, "speed": 4.27, "text": "F-centers, also known as \"Frenke"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 14, "tree_size": 64, "t0": 1.19, "t1": 0.35, "tft": 4.1177, "input_0": 185, "input_1": 65, "min_CLP": -4.81, "draft_iters": 13.6, "mem_use": 45.68, "gen_rate": 7.0, "speed": 4.55, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.7, "tree_w": 12, "tree_size": 64, "t0": 1.4067, "t1": 0.3317, "tft": 2.3737, "input_0": 182, "input_1": 65, "min_CLP": -4.58, "draft_iters": 16.7, "mem_use": 42.76, "gen_rate": 5.7, "speed": 3.26, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 13.0, "tree_w": 11, "tree_size": 64, "t0": 1.2367, "t1": 0.3217, "tft": 1.7544, "input_0": 203, "input_1": 65, "min_CLP": -4.27, "draft_iters": 14.0, "mem_use": 41.56, "gen_rate": 6.8, "speed": 4.38, "text": "Pros:\\n1. Efficiency: AI assista"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.6, "tree_w": 10, "tree_size": 64, "t0": 1.224, "t1": 0.326, "tft": 3.0924, "input_0": 218, "input_1": 65, "min_CLP": -4.5, "draft_iters": 13.6, "mem_use": 43.49, "gen_rate": 8.4, "speed": 5.41, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.0, "tree_w": 18, "tree_size": 64, "t0": 0.8817, "t1": 0.33, "tft": 2.9577, "input_0": 145, "input_1": 65, "min_CLP": -5.01, "draft_iters": 10.0, "mem_use": 43.45, "gen_rate": 5.3, "speed": 4.4, "text": "Das Aussto\u00dfverh\u00e4ltnis betr\u00e4gt 0,"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 9.7, "tree_w": 14, "tree_size": 64, "t0": 0.9589, "t1": 0.3311, "tft": 2.2346, "input_0": 149, "input_1": 65, "min_CLP": -4.72, "draft_iters": 10.7, "mem_use": 42.77, "gen_rate": 4.3, "speed": 3.35, "text": "\"I'm sorry, but I can't provide "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 5.7, "tree_w": 25, "tree_size": 64, "t0": 0.63, "t1": 0.3286, "tft": 1.9192, "input_0": 119, "input_1": 65, "min_CLP": -5.13, "draft_iters": 6.7, "mem_use": 41.8, "gen_rate": 3.7, "speed": 3.88, "text": "The best way to contact the orig"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.4, "tree_w": 14, "tree_size": 64, "t0": 1.222, "t1": 0.32, "tft": 1.4776, "input_0": 145, "input_1": 65, "min_CLP": -4.78, "draft_iters": 14.4, "mem_use": 41.38, "gen_rate": 6.4, "speed": 4.15, "text": "\u9019\u7bc7\u8ad6\u6587 \"Attention Is All You Need\""}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 64, "tree_h": 26.7, "tree_w": 4, "tree_size": 64, "t0": 2.2533, "t1": 0.3233, "tft": 1.7012, "input_0": 241, "input_1": 65, "min_CLP": -3.87, "draft_iters": 27.3, "mem_use": 41.19, "gen_rate": 21.3, "speed": 8.29, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.4, "tree_w": 16, "tree_size": 64, "t0": 0.918, "t1": 0.334, "tft": 2.3941, "input_0": 147, "input_1": 65, "min_CLP": -4.57, "draft_iters": 10.4, "mem_use": 42.47, "gen_rate": 7.4, "speed": 5.91, "text": "In the state of Wyoming, public "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.6, "tree_w": 16, "tree_size": 64, "t0": 0.78, "t1": 0.322, "tft": 2.3908, "input_0": 150, "input_1": 65, "min_CLP": -4.64, "draft_iters": 8.6, "mem_use": 41.58, "gen_rate": 6.8, "speed": 6.16, "text": "There are many ways to deliver a"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 0.936, "t1": 0.336, "tft": 2.8375, "input_0": 165, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.2, "mem_use": 42.47, "gen_rate": 6.4, "speed": 5.02, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.2, "tree_w": 14, "tree_size": 64, "t0": 1.244, "t1": 0.332, "tft": 3.5912, "input_0": 175, "input_1": 65, "min_CLP": -4.79, "draft_iters": 14.2, "mem_use": 41.85, "gen_rate": 6.6, "speed": 4.19, "text": "If you celebrate Christmas on th"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 18, "tree_size": 64, "t0": 0.7817, "t1": 0.3233, "tft": 1.1949, "input_0": 144, "input_1": 65, "min_CLP": -5.23, "draft_iters": 8.5, "mem_use": 41.11, "gen_rate": 5.7, "speed": 5.11, "text": "Here are some nicknames that you"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 1.028, "t1": 0.324, "tft": 2.7561, "input_0": 197, "input_1": 65, "min_CLP": -4.64, "draft_iters": 11.2, "mem_use": 41.52, "gen_rate": 7.4, "speed": 5.45, "text": "The Balfour Declaration is signi"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 25.0, "tree_w": 6, "tree_size": 64, "t0": 2.1967, "t1": 0.34, "tft": 3.013, "input_0": 263, "input_1": 65, "min_CLP": -3.88, "draft_iters": 26.0, "mem_use": 42.28, "gen_rate": 13.7, "speed": 5.39, "text": "\"Canciones felices:\\n\\n1. \u00ab(I Ca"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 14.0, "tree_w": 10, "tree_size": 64, "t0": 1.32, "t1": 0.3257, "tft": 1.4637, "input_0": 191, "input_1": 65, "min_CLP": -4.36, "draft_iters": 15.0, "mem_use": 41.21, "gen_rate": 4.7, "speed": 2.86, "text": "\"Answer: I'm sorry, but I cannot"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 10.2, "tree_w": 19, "tree_size": 64, "t0": 0.96, "t1": 0.3283, "tft": 1.6017, "input_0": 119, "input_1": 65, "min_CLP": -5.04, "draft_iters": 11.2, "mem_use": 41.61, "gen_rate": 7.2, "speed": 5.57, "text": "\"[INST] Oh yes, I'm sorry about "}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.6, "tree_w": 17, "tree_size": 64, "t0": 0.9375, "t1": 0.335, "tft": 2.1661, "input_0": 135, "input_1": 65, "min_CLP": -5.05, "draft_iters": 10.6, "mem_use": 41.97, "gen_rate": 4.2, "speed": 3.34, "text": "How about, \"A wish is like a hea"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.6, "tree_w": 10, "tree_size": 64, "t0": 1.464, "t1": 0.34, "tft": 2.8055, "input_0": 212, "input_1": 65, "min_CLP": -4.36, "draft_iters": 16.6, "mem_use": 42.74, "gen_rate": 6.8, "speed": 3.77, "text": "Sure, here is a high-level guide"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 16, "tree_size": 64, "t0": 1.066, "t1": 0.324, "tft": 1.2974, "input_0": 194, "input_1": 65, "min_CLP": -4.79, "draft_iters": 11.6, "mem_use": 41.22, "gen_rate": 7.0, "speed": 5.04, "text": "Frank-Walter Steinmeier is a Ger"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.1, "tree_w": 18, "tree_size": 64, "t0": 0.81, "t1": 0.3233, "tft": 2.2559, "input_0": 125, "input_1": 65, "min_CLP": -5.05, "draft_iters": 9.1, "mem_use": 41.14, "gen_rate": 3.9, "speed": 3.43, "text": "\"Yes, the most wet elbows are th"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.3, "tree_w": 12, "tree_size": 64, "t0": 1.0086, "t1": 0.3471, "tft": 4.4182, "input_0": 171, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.3, "mem_use": 45.27, "gen_rate": 5.4, "speed": 4.01, "text": "1. Discovery:\\n\\t* Find a market"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.8, "tree_w": 14, "tree_size": 64, "t0": 0.8983, "t1": 0.3183, "tft": 1.1157, "input_0": 167, "input_1": 65, "min_CLP": -5.02, "draft_iters": 9.8, "mem_use": 41.04, "gen_rate": 6.0, "speed": 4.93, "text": "The many-worlds interpretation o"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 2.66, "t1": 0.33, "tft": 1.4506, "input_0": 238, "input_1": 65, "min_CLP": -5.15, "draft_iters": 32.0, "mem_use": 41.0, "gen_rate": 33.0, "speed": 11.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 16, "tree_size": 64, "t0": 1.112, "t1": 0.352, "tft": 3.8919, "input_0": 153, "input_1": 65, "min_CLP": -5.01, "draft_iters": 12.4, "mem_use": 45.26, "gen_rate": 7.0, "speed": 4.79, "text": "Hey! How can I help you today?\\n"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.5, "tree_w": 15, "tree_size": 64, "t0": 0.8567, "t1": 0.335, "tft": 4.0551, "input_0": 143, "input_1": 65, "min_CLP": -4.67, "draft_iters": 9.5, "mem_use": 43.1, "gen_rate": 6.2, "speed": 5.19, "text": "\"\u2022 Set reminders. Set reminders "}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.4, "tree_w": 14, "tree_size": 64, "t0": 0.8843, "t1": 0.34, "tft": 2.1013, "input_0": 166, "input_1": 65, "min_CLP": -4.73, "draft_iters": 9.4, "mem_use": 42.31, "gen_rate": 5.0, "speed": 4.08, "text": "In the context of Into the Breac"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 0.845, "t1": 0.3217, "tft": 1.7905, "input_0": 171, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.2, "mem_use": 41.19, "gen_rate": 5.7, "speed": 4.87, "text": "\"The 6th of February is an impor"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 12, "tree_size": 64, "t0": 1.1667, "t1": 0.32, "tft": 1.5639, "input_0": 198, "input_1": 65, "min_CLP": -4.58, "draft_iters": 13.0, "mem_use": 41.21, "gen_rate": 11.3, "speed": 7.63, "text": "In the context of the turn-based"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 1.0883, "t1": 0.3383, "tft": 2.1618, "input_0": 186, "input_1": 65, "min_CLP": -4.64, "draft_iters": 12.0, "mem_use": 42.03, "gen_rate": 5.3, "speed": 3.74, "text": "\"[ANSWER]: I'm sorry, but as a t"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 17.7, "tree_w": 8, "tree_size": 64, "t0": 1.6083, "t1": 0.3417, "tft": 2.2413, "input_0": 211, "input_1": 65, "min_CLP": -3.99, "draft_iters": 18.7, "mem_use": 42.56, "gen_rate": 6.0, "speed": 3.08, "text": "Here is a simpler script that ac"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 13, "tree_size": 64, "t0": 1.058, "t1": 0.328, "tft": 1.8811, "input_0": 179, "input_1": 65, "min_CLP": -4.78, "draft_iters": 11.6, "mem_use": 41.98, "gen_rate": 6.8, "speed": 4.9, "text": "\"Hello! How can I assist you tod"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.0, "tree_w": 20, "tree_size": 64, "t0": 0.6571, "t1": 0.33, "tft": 3.6211, "input_0": 136, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.0, "mem_use": 42.09, "gen_rate": 5.0, "speed": 5.07, "text": "In your eyes, I see a world of w"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.2, "tree_w": 17, "tree_size": 64, "t0": 0.91, "t1": 0.325, "tft": 1.8408, "input_0": 145, "input_1": 65, "min_CLP": -4.93, "draft_iters": 10.2, "mem_use": 41.48, "gen_rate": 4.5, "speed": 3.64, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 1.082, "t1": 0.322, "tft": 2.3752, "input_0": 193, "input_1": 65, "min_CLP": -4.7, "draft_iters": 12.0, "mem_use": 41.45, "gen_rate": 6.6, "speed": 4.7, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 1.0789, "t1": 0.3344, "tft": 2.1944, "input_0": 165, "input_1": 65, "min_CLP": -4.57, "draft_iters": 12.2, "mem_use": 42.77, "gen_rate": 3.9, "speed": 2.75, "text": "\"You're welcome! If the first tw"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 13, "tree_size": 64, "t0": 0.954, "t1": 0.336, "tft": 2.5915, "input_0": 172, "input_1": 65, "min_CLP": -4.7, "draft_iters": 10.4, "mem_use": 42.7, "gen_rate": 6.6, "speed": 5.11, "text": "Yes, Open Assistant is a pretrai"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 17.2, "tree_w": 9, "tree_size": 64, "t0": 1.552, "t1": 0.332, "tft": 3.2029, "input_0": 207, "input_1": 65, "min_CLP": -4.38, "draft_iters": 18.0, "mem_use": 44.17, "gen_rate": 7.0, "speed": 3.72, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 2.53, "t1": 0.33, "tft": 1.2663, "input_0": 207, "input_1": 65, "min_CLP": -6.15, "draft_iters": 32.0, "mem_use": 41.0, "gen_rate": 33.0, "speed": 11.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.4, "tree_w": 20, "tree_size": 64, "t0": 0.6833, "t1": 0.3344, "tft": 1.9841, "input_0": 120, "input_1": 65, "min_CLP": -5.23, "draft_iters": 7.4, "mem_use": 41.92, "gen_rate": 3.6, "speed": 3.5, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 17.0, "tree_w": 8, "tree_size": 64, "t0": 1.54, "t1": 0.33, "tft": 3.3268, "input_0": 189, "input_1": 65, "min_CLP": -4.64, "draft_iters": 18.0, "mem_use": 43.83, "gen_rate": 8.0, "speed": 4.28, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 0.9967, "t1": 0.33, "tft": 2.2018, "input_0": 167, "input_1": 65, "min_CLP": -4.99, "draft_iters": 10.8, "mem_use": 41.52, "gen_rate": 5.3, "speed": 4.01, "text": "- Introduction to the contrarian"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.8, "tree_w": 15, "tree_size": 64, "t0": 0.82, "t1": 0.3417, "tft": 2.9142, "input_0": 162, "input_1": 65, "min_CLP": -4.67, "draft_iters": 8.8, "mem_use": 42.37, "gen_rate": 6.3, "speed": 5.45, "text": "\"Sure, I apologize for the confu"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 64, "max_branch_width": 32, "gen_rate": 8.95, "gen_rate_micro": 6.78, "gen_speed": 5.311, "gen_speed_micro": 4.869, "t0": 1.212, "t1": 0.3287, "input_0": 176.5, "input_1": 65.0, "tree_size": 64.0, "tree_w": 13.4, "tree_h": 13.0, "prompt_len": 298.0, "min_CLP": -4.77, "mem_use": 50.45, "exp_time": 5137.84}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 33, "tree_size": 128, "t0": 1.376, "t1": 0.63, "tft": 1.8425, "input_0": 314, "input_1": 129, "min_CLP": -5.59, "draft_iters": 13.0, "mem_use": 41.38, "gen_rate": 6.4, "speed": 3.2, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.3, "tree_w": 18, "tree_size": 128, "t0": 1.7833, "t1": 0.6433, "tft": 2.9119, "input_0": 384, "input_1": 129, "min_CLP": -5.09, "draft_iters": 17.3, "mem_use": 42.92, "gen_rate": 11.7, "speed": 4.81, "text": "You are correct. I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.7, "tree_w": 23, "tree_size": 128, "t0": 1.6083, "t1": 0.6417, "tft": 4.1303, "input_0": 394, "input_1": 129, "min_CLP": -5.26, "draft_iters": 14.7, "mem_use": 43.84, "gen_rate": 5.7, "speed": 2.52, "text": "Sure, here are some specific rec"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.8, "tree_w": 14, "tree_size": 128, "t0": 2.11, "t1": 0.6325, "tft": 1.9079, "input_0": 522, "input_1": 129, "min_CLP": -4.74, "draft_iters": 19.8, "mem_use": 41.56, "gen_rate": 10.2, "speed": 3.74, "text": "\"Certainly! Here's a Python scri"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 15.0, "tree_w": 23, "tree_size": 128, "t0": 1.6125, "t1": 0.6325, "tft": 1.4318, "input_0": 326, "input_1": 129, "min_CLP": -5.22, "draft_iters": 16.0, "mem_use": 41.4, "gen_rate": 6.0, "speed": 2.67, "text": "\"Hi there! Of course, I'd be hap"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 14.0, "tree_w": 24, "tree_size": 128, "t0": 1.7567, "t1": 0.6467, "tft": 4.6716, "input_0": 449, "input_1": 129, "min_CLP": -5.2, "draft_iters": 15.0, "mem_use": 43.97, "gen_rate": 12.7, "speed": 5.27, "text": "Sure, here is a potential bullet"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.0, "tree_w": 22, "tree_size": 128, "t0": 1.632, "t1": 0.648, "tft": 4.1071, "input_0": 419, "input_1": 129, "min_CLP": -5.3, "draft_iters": 14.0, "mem_use": 44.55, "gen_rate": 7.4, "speed": 3.25, "text": "Other options to enhance images "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 19, "tree_size": 128, "t0": 1.668, "t1": 0.662, "tft": 4.6808, "input_0": 444, "input_1": 129, "min_CLP": -5.01, "draft_iters": 14.4, "mem_use": 46.71, "gen_rate": 7.6, "speed": 3.26, "text": "\"To attract the right customers "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 21, "tree_size": 128, "t0": 1.5525, "t1": 0.65, "tft": 3.7459, "input_0": 330, "input_1": 129, "min_CLP": -5.19, "draft_iters": 15.5, "mem_use": 44.16, "gen_rate": 9.8, "speed": 4.42, "text": "Sure, here is a summary of the l"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.5, "tree_w": 18, "tree_size": 128, "t0": 1.6825, "t1": 0.645, "tft": 3.1617, "input_0": 423, "input_1": 129, "min_CLP": -5.11, "draft_iters": 15.5, "mem_use": 43.55, "gen_rate": 9.2, "speed": 3.97, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 3.12, "t1": 0.63, "tft": 3.9311, "input_0": 517, "input_1": 129, "min_CLP": -6.86, "draft_iters": 32.0, "mem_use": 42.05, "gen_rate": 33.0, "speed": 8.8, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 18, "tree_size": 128, "t0": 1.8933, "t1": 0.6467, "tft": 4.1774, "input_0": 418, "input_1": 129, "min_CLP": -5.14, "draft_iters": 18.3, "mem_use": 43.91, "gen_rate": 11.0, "speed": 4.33, "text": "Sure! Here\\'s a shortened versio"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.0, "tree_w": 15, "tree_size": 128, "t0": 2.225, "t1": 0.645, "tft": 3.123, "input_0": 491, "input_1": 129, "min_CLP": -4.75, "draft_iters": 21.0, "mem_use": 43.15, "gen_rate": 18.0, "speed": 6.27, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 9.5, "tree_w": 29, "tree_size": 128, "t0": 1.14, "t1": 0.63, "tft": 1.656, "input_0": 275, "input_1": 129, "min_CLP": -5.72, "draft_iters": 10.5, "mem_use": 41.38, "gen_rate": 3.0, "speed": 1.69, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 27, "tree_size": 128, "t0": 1.442, "t1": 0.652, "tft": 3.6086, "input_0": 392, "input_1": 129, "min_CLP": -5.36, "draft_iters": 11.8, "mem_use": 44.52, "gen_rate": 7.0, "speed": 3.35, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 19.2, "tree_w": 19, "tree_size": 128, "t0": 2.036, "t1": 0.638, "tft": 3.7352, "input_0": 401, "input_1": 129, "min_CLP": -5.14, "draft_iters": 20.2, "mem_use": 41.71, "gen_rate": 7.6, "speed": 2.84, "text": "The minimum broadband upload spe"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 22.0, "tree_w": 13, "tree_size": 128, "t0": 2.2567, "t1": 0.6267, "tft": 2.0484, "input_0": 513, "input_1": 129, "min_CLP": -5.59, "draft_iters": 23.0, "mem_use": 41.4, "gen_rate": 14.3, "speed": 4.96, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 128, "t0": 2.97, "t1": 0.63, "tft": 1.5748, "input_0": 466, "input_1": 129, "min_CLP": -7.91, "draft_iters": 32.0, "mem_use": 41.37, "gen_rate": 33.0, "speed": 9.19, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 63, "tree_h": 20.8, "tree_w": 20, "tree_size": 128, "t0": 1.9975, "t1": 0.63, "tft": 2.3837, "input_0": 346, "input_1": 129, "min_CLP": -5.2, "draft_iters": 21.2, "mem_use": 41.91, "gen_rate": 15.8, "speed": 5.99, "text": "D-theanine is a form of the amin"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.5, "tree_w": 20, "tree_size": 128, "t0": 1.5525, "t1": 0.6275, "tft": 1.9169, "input_0": 360, "input_1": 129, "min_CLP": -5.53, "draft_iters": 14.5, "mem_use": 41.38, "gen_rate": 9.0, "speed": 4.13, "text": "The Balfour Declaration is a let"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 38, "tree_size": 128, "t0": 1.0629, "t1": 0.6414, "tft": 3.2617, "input_0": 266, "input_1": 129, "min_CLP": -6.34, "draft_iters": 9.3, "mem_use": 42.23, "gen_rate": 4.7, "speed": 2.77, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 2.8, "t1": 0.63, "tft": 1.5165, "input_0": 348, "input_1": 129, "min_CLP": -5.24, "draft_iters": 32.0, "mem_use": 41.38, "gen_rate": 7.0, "speed": 2.04, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.2, "tree_w": 14, "tree_size": 128, "t0": 2.0125, "t1": 0.6475, "tft": 3.3892, "input_0": 436, "input_1": 129, "min_CLP": -5.04, "draft_iters": 19.2, "mem_use": 43.76, "gen_rate": 8.8, "speed": 3.29, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.0, "tree_w": 16, "tree_size": 128, "t0": 1.8133, "t1": 0.6333, "tft": 1.982, "input_0": 449, "input_1": 129, "min_CLP": -5.17, "draft_iters": 16.0, "mem_use": 41.45, "gen_rate": 12.7, "speed": 5.18, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 33, "tree_size": 128, "t0": 1.1583, "t1": 0.6433, "tft": 3.0715, "input_0": 279, "input_1": 129, "min_CLP": -5.79, "draft_iters": 10.7, "mem_use": 42.42, "gen_rate": 5.7, "speed": 3.14, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 24.0, "tree_w": 25, "tree_size": 128, "t0": 2.185, "t1": 0.63, "tft": 1.5912, "input_0": 301, "input_1": 129, "min_CLP": -5.37, "draft_iters": 24.5, "mem_use": 41.42, "gen_rate": 20.0, "speed": 7.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 31, "tree_size": 128, "t0": 1.3475, "t1": 0.64, "tft": 2.4612, "input_0": 350, "input_1": 129, "min_CLP": -5.71, "draft_iters": 11.2, "mem_use": 42.09, "gen_rate": 8.0, "speed": 4.03, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 20.0, "tree_w": 23, "tree_size": 128, "t0": 2.0, "t1": 0.63, "tft": 2.4342, "input_0": 348, "input_1": 129, "min_CLP": -5.31, "draft_iters": 20.8, "mem_use": 41.95, "gen_rate": 6.5, "speed": 2.47, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 11.1, "tree_w": 32, "tree_size": 128, "t0": 1.3138, "t1": 0.6438, "tft": 4.9322, "input_0": 298, "input_1": 129, "min_CLP": -5.65, "draft_iters": 12.1, "mem_use": 43.9, "gen_rate": 4.0, "speed": 2.04, "text": "\"Ah, the magic of the world, a w"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.2, "tree_w": 29, "tree_size": 128, "t0": 1.1483, "t1": 0.63, "tft": 1.6932, "input_0": 284, "input_1": 129, "min_CLP": -5.6, "draft_iters": 10.2, "mem_use": 41.43, "gen_rate": 5.5, "speed": 3.09, "text": "Some options of foods that you c"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 18.0, "tree_w": 14, "tree_size": 128, "t0": 2.05, "t1": 0.6433, "tft": 2.7807, "input_0": 460, "input_1": 129, "min_CLP": -4.97, "draft_iters": 19.0, "mem_use": 42.13, "gen_rate": 14.7, "speed": 5.44, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 54, "tree_h": 16.5, "tree_w": 24, "tree_size": 128, "t0": 1.7275, "t1": 0.6425, "tft": 2.5646, "input_0": 319, "input_1": 129, "min_CLP": -5.56, "draft_iters": 17.5, "mem_use": 42.54, "gen_rate": 13.5, "speed": 5.69, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.7, "tree_w": 29, "tree_size": 128, "t0": 1.5017, "t1": 0.6367, "tft": 1.9095, "input_0": 316, "input_1": 129, "min_CLP": -5.73, "draft_iters": 14.7, "mem_use": 41.89, "gen_rate": 6.0, "speed": 2.81, "text": "Freyja, goddess of love, fertili"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 22, "tree_size": 128, "t0": 1.464, "t1": 0.648, "tft": 4.6752, "input_0": 355, "input_1": 129, "min_CLP": -5.34, "draft_iters": 13.2, "mem_use": 43.57, "gen_rate": 6.8, "speed": 3.22, "text": "Yes, there are several non-dairy"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.3875, "t1": 0.645, "tft": 2.9266, "input_0": 376, "input_1": 129, "min_CLP": -5.23, "draft_iters": 12.2, "mem_use": 43.61, "gen_rate": 9.2, "speed": 4.55, "text": "\"When selecting an ISP package, "}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.8, "tree_w": 19, "tree_size": 128, "t0": 1.8675, "t1": 0.6625, "tft": 5.2948, "input_0": 421, "input_1": 129, "min_CLP": -5.03, "draft_iters": 17.8, "mem_use": 46.31, "gen_rate": 9.0, "speed": 3.56, "text": "Selenium is a popular testing fr"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.9, "tree_w": 33, "tree_size": 128, "t0": 1.0513, "t1": 0.63, "tft": 2.3612, "input_0": 240, "input_1": 129, "min_CLP": -5.7, "draft_iters": 9.9, "mem_use": 41.41, "gen_rate": 4.0, "speed": 2.38, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 53, "tree_h": 17.8, "tree_w": 31, "tree_size": 128, "t0": 1.7633, "t1": 0.6383, "tft": 3.8169, "input_0": 293, "input_1": 129, "min_CLP": -5.65, "draft_iters": 18.5, "mem_use": 41.94, "gen_rate": 8.8, "speed": 3.68, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 14.7, "tree_w": 28, "tree_size": 128, "t0": 1.6167, "t1": 0.65, "tft": 5.1169, "input_0": 339, "input_1": 129, "min_CLP": -5.48, "draft_iters": 15.7, "mem_use": 44.33, "gen_rate": 5.8, "speed": 2.57, "text": "Of course, I can try to act like"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.7, "tree_w": 15, "tree_size": 128, "t0": 2.2033, "t1": 0.6433, "tft": 3.9408, "input_0": 493, "input_1": 129, "min_CLP": -4.91, "draft_iters": 20.7, "mem_use": 42.34, "gen_rate": 12.3, "speed": 4.33, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.2, "tree_w": 42, "tree_size": 128, "t0": 0.9211, "t1": 0.63, "tft": 1.7954, "input_0": 228, "input_1": 129, "min_CLP": -6.08, "draft_iters": 8.2, "mem_use": 41.63, "gen_rate": 3.7, "speed": 2.36, "text": "Foolish mortal. My power is mine"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 25, "tree_size": 128, "t0": 1.608, "t1": 0.656, "tft": 5.0353, "input_0": 374, "input_1": 129, "min_CLP": -5.36, "draft_iters": 14.6, "mem_use": 44.15, "gen_rate": 6.6, "speed": 2.92, "text": "\"The monologue is a powerful cri"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 2.84, "t1": 0.66, "tft": 4.4978, "input_0": 332, "input_1": 129, "min_CLP": -5.6, "draft_iters": 32.0, "mem_use": 44.58, "gen_rate": 33.0, "speed": 9.43, "text": "\"[INST] Certainly! It sounds lik"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.5, "tree_w": 17, "tree_size": 128, "t0": 1.84, "t1": 0.65, "tft": 2.8487, "input_0": 464, "input_1": 129, "min_CLP": -5.17, "draft_iters": 16.5, "mem_use": 42.91, "gen_rate": 9.0, "speed": 3.62, "text": "It\\'s difficult to say which one"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 17.5, "tree_w": 20, "tree_size": 128, "t0": 1.92, "t1": 0.635, "tft": 2.7866, "input_0": 412, "input_1": 129, "min_CLP": -5.44, "draft_iters": 18.5, "mem_use": 42.17, "gen_rate": 5.0, "speed": 1.96, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 32.0, "tree_w": 16, "tree_size": 128, "t0": 2.8233, "t1": 0.6367, "tft": 2.9895, "input_0": 351, "input_1": 129, "min_CLP": -6.01, "draft_iters": 32.0, "mem_use": 41.9, "gen_rate": 19.0, "speed": 5.49, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 17.3, "tree_w": 17, "tree_size": 128, "t0": 1.9333, "t1": 0.6267, "tft": 1.849, "input_0": 425, "input_1": 129, "min_CLP": -5.37, "draft_iters": 18.3, "mem_use": 41.41, "gen_rate": 13.7, "speed": 5.33, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 20.0, "tree_w": 22, "tree_size": 128, "t0": 1.9325, "t1": 0.6625, "tft": 5.0156, "input_0": 309, "input_1": 129, "min_CLP": -5.28, "draft_iters": 20.8, "mem_use": 46.85, "gen_rate": 9.8, "speed": 3.76, "text": "\"Certainly! Here's an updated ve"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.8, "tree_w": 38, "tree_size": 128, "t0": 1.1267, "t1": 0.6433, "tft": 2.5385, "input_0": 251, "input_1": 129, "min_CLP": -5.86, "draft_iters": 10.8, "mem_use": 43.19, "gen_rate": 6.3, "speed": 3.58, "text": "I will tell you what I saw. I wi"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 9.0, "tree_w": 40, "tree_size": 128, "t0": 1.087, "t1": 0.638, "tft": 1.8985, "input_0": 243, "input_1": 129, "min_CLP": -6.13, "draft_iters": 10.0, "mem_use": 42.17, "gen_rate": 3.2, "speed": 1.86, "text": "[INST] I understand. I will try "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 53, "tree_h": 15.2, "tree_w": 26, "tree_size": 128, "t0": 1.7025, "t1": 0.635, "tft": 2.1708, "input_0": 368, "input_1": 129, "min_CLP": -5.68, "draft_iters": 16.0, "mem_use": 41.68, "gen_rate": 13.2, "speed": 5.68, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\\"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 60, "tree_h": 26.8, "tree_w": 14, "tree_size": 128, "t0": 2.68, "t1": 0.65, "tft": 3.5618, "input_0": 510, "input_1": 129, "min_CLP": -5.03, "draft_iters": 27.2, "mem_use": 43.61, "gen_rate": 15.0, "speed": 4.5, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 20, "tree_size": 128, "t0": 1.7333, "t1": 0.64, "tft": 3.4893, "input_0": 460, "input_1": 129, "min_CLP": -5.17, "draft_iters": 15.3, "mem_use": 42.79, "gen_rate": 11.7, "speed": 4.91, "text": "\"Sure, here are some more histor"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.8, "tree_w": 25, "tree_size": 128, "t0": 1.376, "t1": 0.642, "tft": 3.3429, "input_0": 361, "input_1": 129, "min_CLP": -5.26, "draft_iters": 11.8, "mem_use": 43.17, "gen_rate": 6.6, "speed": 3.27, "text": "Yes, technology can also be used"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.6, "tree_w": 38, "tree_size": 128, "t0": 1.0125, "t1": 0.6275, "tft": 1.815, "input_0": 261, "input_1": 129, "min_CLP": -5.76, "draft_iters": 8.6, "mem_use": 41.58, "gen_rate": 4.2, "speed": 2.59, "text": "In real life, people who enjoy w"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.8, "tree_w": 39, "tree_size": 128, "t0": 1.352, "t1": 0.652, "tft": 3.5006, "input_0": 350, "input_1": 129, "min_CLP": -5.83, "draft_iters": 11.8, "mem_use": 44.0, "gen_rate": 8.2, "speed": 4.09, "text": "\"Sure, here's a sample pitch dec"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.4, "tree_w": 21, "tree_size": 128, "t0": 1.506, "t1": 0.662, "tft": 5.804, "input_0": 336, "input_1": 129, "min_CLP": -5.22, "draft_iters": 14.4, "mem_use": 45.24, "gen_rate": 6.8, "speed": 3.14, "text": "I apologize for the confusion. Y"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.0, "tree_w": 21, "tree_size": 128, "t0": 1.64, "t1": 0.665, "tft": 4.6083, "input_0": 458, "input_1": 129, "min_CLP": -5.31, "draft_iters": 14.0, "mem_use": 45.4, "gen_rate": 8.0, "speed": 3.47, "text": "Yes, Keras is generally consider"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.8, "tree_w": 20, "tree_size": 128, "t0": 1.9425, "t1": 0.6475, "tft": 3.507, "input_0": 391, "input_1": 129, "min_CLP": -5.26, "draft_iters": 19.8, "mem_use": 43.1, "gen_rate": 10.5, "speed": 4.06, "text": "\"As an AI language model, I do n"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 30, "tree_size": 128, "t0": 1.24, "t1": 0.628, "tft": 1.4142, "input_0": 315, "input_1": 129, "min_CLP": -5.72, "draft_iters": 11.2, "mem_use": 41.4, "gen_rate": 6.6, "speed": 3.53, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 2.965, "t1": 0.64, "tft": 3.6939, "input_0": 457, "input_1": 129, "min_CLP": -5.6, "draft_iters": 32.0, "mem_use": 43.83, "gen_rate": 20.0, "speed": 5.55, "text": "You are an AI assistant that hel"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.9, "tree_w": 28, "tree_size": 128, "t0": 1.1571, "t1": 0.6557, "tft": 5.1552, "input_0": 315, "input_1": 129, "min_CLP": -5.48, "draft_iters": 9.9, "mem_use": 44.66, "gen_rate": 5.4, "speed": 3.0, "text": "[The scene opens on a vast field"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.2, "tree_w": 25, "tree_size": 128, "t0": 1.5233, "t1": 0.6433, "tft": 2.0646, "input_0": 329, "input_1": 129, "min_CLP": -5.58, "draft_iters": 14.2, "mem_use": 42.35, "gen_rate": 6.3, "speed": 2.92, "text": "You\\'re right, it\\'s a bit of a "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 34, "tree_size": 128, "t0": 1.0886, "t1": 0.6357, "tft": 2.1824, "input_0": 256, "input_1": 129, "min_CLP": -5.77, "draft_iters": 10.0, "mem_use": 42.07, "gen_rate": 4.9, "speed": 2.81, "text": "Proof-of-stake is a concept wher"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.3, "tree_w": 41, "tree_size": 128, "t0": 0.9967, "t1": 0.6417, "tft": 2.4392, "input_0": 211, "input_1": 129, "min_CLP": -5.93, "draft_iters": 9.3, "mem_use": 42.19, "gen_rate": 6.0, "speed": 3.66, "text": "My statement is that if Adolph H"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 20, "tree_size": 128, "t0": 1.6225, "t1": 0.6525, "tft": 3.8109, "input_0": 413, "input_1": 129, "min_CLP": -5.24, "draft_iters": 14.0, "mem_use": 44.28, "gen_rate": 8.8, "speed": 3.85, "text": "Void pointers (also known as \"vo"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 26, "tree_size": 128, "t0": 1.3575, "t1": 0.6575, "tft": 3.8642, "input_0": 400, "input_1": 129, "min_CLP": -5.7, "draft_iters": 11.0, "mem_use": 44.79, "gen_rate": 8.2, "speed": 4.09, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.0, "tree_w": 17, "tree_size": 128, "t0": 1.92, "t1": 0.6533, "tft": 4.1025, "input_0": 466, "input_1": 129, "min_CLP": -5.18, "draft_iters": 17.0, "mem_use": 44.01, "gen_rate": 10.7, "speed": 4.15, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 13.2, "tree_w": 25, "tree_size": 128, "t0": 1.5818, "t1": 0.6355, "tft": 2.4994, "input_0": 386, "input_1": 129, "min_CLP": -5.51, "draft_iters": 14.2, "mem_use": 41.81, "gen_rate": 3.2, "speed": 1.43, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 1.1267, "t1": 0.6333, "tft": 2.062, "input_0": 292, "input_1": 129, "min_CLP": -5.59, "draft_iters": 10.0, "mem_use": 41.4, "gen_rate": 5.8, "speed": 3.31, "text": "The idea that landlords can be c"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 29.0, "tree_w": 8, "tree_size": 128, "t0": 2.835, "t1": 0.65, "tft": 5.2528, "input_0": 477, "input_1": 129, "min_CLP": -4.66, "draft_iters": 29.5, "mem_use": 44.24, "gen_rate": 19.5, "speed": 5.59, "text": "\"Sure, here's the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.8, "tree_w": 31, "tree_size": 128, "t0": 1.2717, "t1": 0.6333, "tft": 1.4144, "input_0": 334, "input_1": 129, "min_CLP": -5.92, "draft_iters": 10.8, "mem_use": 41.36, "gen_rate": 6.7, "speed": 3.5, "text": "Berlin was founded in the 13th c"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 30, "tree_size": 128, "t0": 1.3117, "t1": 0.65, "tft": 3.8222, "input_0": 327, "input_1": 129, "min_CLP": -5.68, "draft_iters": 11.8, "mem_use": 43.71, "gen_rate": 6.0, "speed": 3.06, "text": "Here are a few lighthearted joke"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.0, "tree_w": 18, "tree_size": 128, "t0": 1.64, "t1": 0.65, "tft": 3.539, "input_0": 374, "input_1": 129, "min_CLP": -4.89, "draft_iters": 15.0, "mem_use": 43.57, "gen_rate": 12.0, "speed": 5.24, "text": "Certainly. One of the main criti"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 2.84, "t1": 0.64, "tft": 1.6159, "input_0": 418, "input_1": 129, "min_CLP": -6.04, "draft_iters": 32.0, "mem_use": 41.37, "gen_rate": 33.0, "speed": 9.48, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 22.0, "tree_w": 22, "tree_size": 128, "t0": 2.1, "t1": 0.635, "tft": 3.6895, "input_0": 365, "input_1": 129, "min_CLP": -5.69, "draft_iters": 22.5, "mem_use": 41.68, "gen_rate": 22.5, "speed": 8.23, "text": "\"You can visit at The World Cloc"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.8, "tree_w": 33, "tree_size": 128, "t0": 0.995, "t1": 0.6388, "tft": 2.1193, "input_0": 262, "input_1": 129, "min_CLP": -5.68, "draft_iters": 8.8, "mem_use": 41.77, "gen_rate": 4.4, "speed": 2.68, "text": "No, the five second rule is a my"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 60, "tree_h": 13.7, "tree_w": 27, "tree_size": 128, "t0": 1.4557, "t1": 0.6286, "tft": 1.9345, "input_0": 300, "input_1": 129, "min_CLP": -6.15, "draft_iters": 14.6, "mem_use": 41.49, "gen_rate": 8.6, "speed": 4.11, "text": "12 - 2 - 5 = 5\\nYou have 5 eggs "}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.3, "tree_w": 16, "tree_size": 128, "t0": 1.8, "t1": 0.64, "tft": 2.8774, "input_0": 404, "input_1": 129, "min_CLP": -4.9, "draft_iters": 17.3, "mem_use": 42.24, "gen_rate": 12.7, "speed": 5.18, "text": " Sure! One of the most well-know"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 15.2, "tree_w": 26, "tree_size": 128, "t0": 1.6425, "t1": 0.6362, "tft": 2.0836, "input_0": 350, "input_1": 129, "min_CLP": -5.49, "draft_iters": 16.1, "mem_use": 41.81, "gen_rate": 4.0, "speed": 1.76, "text": "\"You're welcome! If you're unsur"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.1, "tree_w": 33, "tree_size": 128, "t0": 1.2957, "t1": 0.6371, "tft": 2.514, "input_0": 339, "input_1": 129, "min_CLP": -5.64, "draft_iters": 11.1, "mem_use": 41.52, "gen_rate": 5.0, "speed": 2.59, "text": "\"#OpenAssistant is an open sourc"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.0, "tree_w": 30, "tree_size": 128, "t0": 1.375, "t1": 0.64, "tft": 2.6872, "input_0": 389, "input_1": 129, "min_CLP": -5.5, "draft_iters": 11.0, "mem_use": 42.13, "gen_rate": 5.7, "speed": 2.81, "text": "Sexual selection can indirectly "}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 20, "tree_size": 128, "t0": 1.825, "t1": 0.65, "tft": 3.2334, "input_0": 471, "input_1": 129, "min_CLP": -5.21, "draft_iters": 16.2, "mem_use": 43.21, "gen_rate": 8.5, "speed": 3.43, "text": "AI assistants can be useful to i"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 32, "tree_size": 128, "t0": 1.356, "t1": 0.652, "tft": 4.0963, "input_0": 316, "input_1": 129, "min_CLP": -5.68, "draft_iters": 11.8, "mem_use": 44.21, "gen_rate": 6.4, "speed": 3.19, "text": "\"Certainly! Here's the rewritten"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 25, "tree_size": 128, "t0": 1.4125, "t1": 0.65, "tft": 2.4125, "input_0": 347, "input_1": 129, "min_CLP": -5.14, "draft_iters": 12.2, "mem_use": 42.69, "gen_rate": 8.0, "speed": 3.88, "text": "The scp command is a Unix comman"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 3.03, "t1": 0.64, "tft": 3.9964, "input_0": 487, "input_1": 129, "min_CLP": -5.29, "draft_iters": 32.0, "mem_use": 43.37, "gen_rate": 33.0, "speed": 8.97, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 31, "tree_size": 128, "t0": 1.176, "t1": 0.634, "tft": 1.6658, "input_0": 310, "input_1": 129, "min_CLP": -5.62, "draft_iters": 9.8, "mem_use": 41.43, "gen_rate": 7.2, "speed": 3.97, "text": "\"Yes, it would be illegal to kee"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 14.2, "tree_w": 22, "tree_size": 128, "t0": 1.62, "t1": 0.64, "tft": 3.6613, "input_0": 344, "input_1": 129, "min_CLP": -5.43, "draft_iters": 15.2, "mem_use": 41.71, "gen_rate": 13.8, "speed": 6.09, "text": "\"Sydney, the capital of New Sout"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 32, "tree_size": 128, "t0": 2.67, "t1": 0.64, "tft": 2.6179, "input_0": 254, "input_1": 129, "min_CLP": -5.44, "draft_iters": 32.0, "mem_use": 42.02, "gen_rate": 33.0, "speed": 9.96, "text": "\"[INST] 5 second rule is a dange"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.4, "tree_w": 44, "tree_size": 128, "t0": 0.8175, "t1": 0.6388, "tft": 2.2253, "input_0": 203, "input_1": 129, "min_CLP": -5.94, "draft_iters": 7.4, "mem_use": 41.69, "gen_rate": 4.2, "speed": 2.92, "text": "\"Oh, you're in Silicon Valley, a"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.3, "tree_w": 28, "tree_size": 128, "t0": 1.48, "t1": 0.64, "tft": 1.9734, "input_0": 340, "input_1": 129, "min_CLP": -5.68, "draft_iters": 14.3, "mem_use": 41.46, "gen_rate": 11.3, "speed": 5.35, "text": "The best approach for learning a"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 1.228, "t1": 0.634, "tft": 1.7572, "input_0": 302, "input_1": 129, "min_CLP": -5.48, "draft_iters": 11.2, "mem_use": 41.44, "gen_rate": 8.0, "speed": 4.3, "text": "\"Walking around the world is not"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.8, "tree_w": 16, "tree_size": 128, "t0": 1.6825, "t1": 0.6475, "tft": 4.0571, "input_0": 382, "input_1": 129, "min_CLP": -4.93, "draft_iters": 15.8, "mem_use": 43.21, "gen_rate": 9.0, "speed": 3.86, "text": "The Taniyama\u2013Shimura\u2013Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.5, "tree_w": 23, "tree_size": 128, "t0": 2.015, "t1": 0.635, "tft": 2.0427, "input_0": 319, "input_1": 129, "min_CLP": -5.89, "draft_iters": 22.0, "mem_use": 41.44, "gen_rate": 17.5, "speed": 6.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 24.0, "tree_w": 10, "tree_size": 128, "t0": 2.455, "t1": 0.64, "tft": 2.0757, "input_0": 523, "input_1": 129, "min_CLP": -5.04, "draft_iters": 25.0, "mem_use": 41.74, "gen_rate": 18.5, "speed": 5.98, "text": "To write a first person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 2.79, "t1": 0.64, "tft": 2.1121, "input_0": 407, "input_1": 129, "min_CLP": -6.7, "draft_iters": 32.0, "mem_use": 41.41, "gen_rate": 33.0, "speed": 9.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 26, "tree_size": 128, "t0": 1.28, "t1": 0.634, "tft": 1.9914, "input_0": 323, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.0, "mem_use": 41.72, "gen_rate": 6.6, "speed": 3.45, "text": "The path to becoming one with th"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.7, "tree_w": 34, "tree_size": 128, "t0": 1.0171, "t1": 0.6386, "tft": 2.2283, "input_0": 263, "input_1": 129, "min_CLP": -5.62, "draft_iters": 8.7, "mem_use": 41.58, "gen_rate": 5.3, "speed": 3.2, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.0, "tree_w": 22, "tree_size": 128, "t0": 1.3767, "t1": 0.64, "tft": 2.1608, "input_0": 374, "input_1": 129, "min_CLP": -5.42, "draft_iters": 12.0, "mem_use": 41.82, "gen_rate": 11.0, "speed": 5.46, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.8, "tree_w": 18, "tree_size": 128, "t0": 1.745, "t1": 0.655, "tft": 3.7812, "input_0": 394, "input_1": 129, "min_CLP": -5.41, "draft_iters": 15.8, "mem_use": 44.68, "gen_rate": 9.8, "speed": 4.07, "text": "Yes, a more robust solution woul"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.7, "tree_w": 30, "tree_size": 128, "t0": 1.0571, "t1": 0.6357, "tft": 2.5623, "input_0": 276, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.7, "mem_use": 41.89, "gen_rate": 4.9, "speed": 2.87, "text": "\"Yes, it's considered good pract"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 34, "tree_size": 128, "t0": 1.17, "t1": 0.65, "tft": 4.2466, "input_0": 305, "input_1": 129, "min_CLP": -5.57, "draft_iters": 10.2, "mem_use": 44.78, "gen_rate": 5.3, "speed": 2.93, "text": "Xin ch\u00e0o, t\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd AI t"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 35, "tree_size": 128, "t0": 1.1771, "t1": 0.6414, "tft": 2.4913, "input_0": 281, "input_1": 129, "min_CLP": -5.66, "draft_iters": 10.6, "mem_use": 42.25, "gen_rate": 4.9, "speed": 2.67, "text": "What is the story behind this de"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 25.5, "tree_w": 13, "tree_size": 128, "t0": 2.545, "t1": 0.635, "tft": 2.1784, "input_0": 480, "input_1": 129, "min_CLP": -4.79, "draft_iters": 26.0, "mem_use": 41.77, "gen_rate": 24.0, "speed": 7.54, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.8, "tree_w": 29, "tree_size": 128, "t0": 1.164, "t1": 0.644, "tft": 3.2237, "input_0": 313, "input_1": 129, "min_CLP": -5.92, "draft_iters": 10.8, "mem_use": 43.24, "gen_rate": 7.4, "speed": 4.09, "text": "1. Scorpions\\n2. Rammstein\\n3. E"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.1, "tree_w": 43, "tree_size": 128, "t0": 0.9238, "t1": 0.6362, "tft": 3.5826, "input_0": 224, "input_1": 129, "min_CLP": -5.82, "draft_iters": 8.1, "mem_use": 41.73, "gen_rate": 4.6, "speed": 2.96, "text": "The best strategy to win a thumb"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 14.3, "tree_w": 15, "tree_size": 128, "t0": 1.77, "t1": 0.6433, "tft": 3.5503, "input_0": 466, "input_1": 129, "min_CLP": -5.02, "draft_iters": 15.3, "mem_use": 43.76, "gen_rate": 12.3, "speed": 5.12, "text": "Acquiring revenue from customers"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 28, "tree_size": 128, "t0": 1.47, "t1": 0.642, "tft": 2.1451, "input_0": 385, "input_1": 129, "min_CLP": -5.67, "draft_iters": 11.8, "mem_use": 42.36, "gen_rate": 7.4, "speed": 3.5, "text": "As a language model, I can gener"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 16.3, "tree_w": 15, "tree_size": 128, "t0": 1.8133, "t1": 0.6367, "tft": 2.9049, "input_0": 424, "input_1": 129, "min_CLP": -5.06, "draft_iters": 17.3, "mem_use": 41.89, "gen_rate": 15.7, "speed": 6.39, "text": "Certainly! Here is an essay on h"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.2, "tree_w": 21, "tree_size": 128, "t0": 1.622, "t1": 0.634, "tft": 2.4733, "input_0": 417, "input_1": 129, "min_CLP": -5.04, "draft_iters": 14.2, "mem_use": 42.03, "gen_rate": 8.0, "speed": 3.55, "text": "There are many top APIs, librari"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.6, "tree_w": 22, "tree_size": 128, "t0": 1.376, "t1": 0.648, "tft": 3.3687, "input_0": 329, "input_1": 129, "min_CLP": -5.51, "draft_iters": 12.6, "mem_use": 43.34, "gen_rate": 7.8, "speed": 3.85, "text": "\"As an AI language model, I do n"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 28, "tree_size": 128, "t0": 1.2875, "t1": 0.6375, "tft": 1.6855, "input_0": 325, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.5, "mem_use": 41.41, "gen_rate": 9.5, "speed": 4.94, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.0, "tree_w": 22, "tree_size": 128, "t0": 1.346, "t1": 0.628, "tft": 1.801, "input_0": 351, "input_1": 129, "min_CLP": -5.36, "draft_iters": 12.0, "mem_use": 41.45, "gen_rate": 7.4, "speed": 3.75, "text": "The error with this code is that"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.8, "tree_w": 33, "tree_size": 128, "t0": 1.4675, "t1": 0.6475, "tft": 2.5423, "input_0": 245, "input_1": 129, "min_CLP": -5.81, "draft_iters": 15.5, "mem_use": 42.84, "gen_rate": 9.8, "speed": 4.62, "text": "<|/INST|> Dear future me, hello."}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 23, "tree_size": 128, "t0": 1.305, "t1": 0.635, "tft": 2.2346, "input_0": 340, "input_1": 129, "min_CLP": -5.24, "draft_iters": 11.5, "mem_use": 42.06, "gen_rate": 8.8, "speed": 4.51, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 18.7, "tree_w": 16, "tree_size": 128, "t0": 1.9967, "t1": 0.64, "tft": 2.1108, "input_0": 457, "input_1": 129, "min_CLP": -5.12, "draft_iters": 19.7, "mem_use": 42.18, "gen_rate": 18.3, "speed": 6.95, "text": "\"To achieve this, you can use th"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 21, "tree_size": 128, "t0": 1.5, "t1": 0.646, "tft": 3.2019, "input_0": 384, "input_1": 129, "min_CLP": -5.25, "draft_iters": 13.0, "mem_use": 43.98, "gen_rate": 7.4, "speed": 3.45, "text": "\"It's important to be cautious w"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.2, "tree_w": 21, "tree_size": 128, "t0": 1.76, "t1": 0.63, "tft": 2.7826, "input_0": 378, "input_1": 129, "min_CLP": -5.36, "draft_iters": 17.2, "mem_use": 41.97, "gen_rate": 6.4, "speed": 2.67, "text": "\"Open Assistant, the ChatGPT ope"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 30.0, "tree_w": 10, "tree_size": 128, "t0": 2.91, "t1": 0.645, "tft": 4.6473, "input_0": 539, "input_1": 129, "min_CLP": -5.61, "draft_iters": 30.5, "mem_use": 43.36, "gen_rate": 20.0, "speed": 5.62, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 1.4825, "t1": 0.6275, "tft": 1.9767, "input_0": 360, "input_1": 129, "min_CLP": -5.39, "draft_iters": 13.8, "mem_use": 41.39, "gen_rate": 8.0, "speed": 3.79, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 10.8, "tree_w": 43, "tree_size": 128, "t0": 1.2067, "t1": 0.6378, "tft": 2.6301, "input_0": 229, "input_1": 129, "min_CLP": -6.29, "draft_iters": 11.8, "mem_use": 41.62, "gen_rate": 4.0, "speed": 2.17, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.465, "t1": 0.64, "tft": 2.165, "input_0": 364, "input_1": 129, "min_CLP": -5.47, "draft_iters": 12.2, "mem_use": 41.86, "gen_rate": 4.5, "speed": 2.14, "text": "\"Thanks! I'm here to help. Do yo"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 13.6, "tree_w": 26, "tree_size": 128, "t0": 1.48, "t1": 0.648, "tft": 3.7102, "input_0": 300, "input_1": 129, "min_CLP": -5.53, "draft_iters": 14.6, "mem_use": 43.48, "gen_rate": 10.0, "speed": 4.7, "text": "\"Thou art a sun that shineth bri"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.8, "tree_w": 24, "tree_size": 128, "t0": 1.52, "t1": 0.6375, "tft": 2.2585, "input_0": 376, "input_1": 129, "min_CLP": -5.44, "draft_iters": 13.8, "mem_use": 42.03, "gen_rate": 9.2, "speed": 4.29, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 34, "tree_size": 128, "t0": 1.2475, "t1": 0.63, "tft": 1.951, "input_0": 294, "input_1": 129, "min_CLP": -5.82, "draft_iters": 11.2, "mem_use": 41.43, "gen_rate": 8.2, "speed": 4.39, "text": "Sure, here are some words in Que"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.8, "tree_w": 17, "tree_size": 128, "t0": 1.805, "t1": 0.635, "tft": 1.7109, "input_0": 422, "input_1": 129, "min_CLP": -5.08, "draft_iters": 16.8, "mem_use": 41.41, "gen_rate": 8.0, "speed": 3.28, "text": "\"Presidents Day, officially know"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.2, "tree_w": 26, "tree_size": 128, "t0": 1.716, "t1": 0.638, "tft": 2.3013, "input_0": 333, "input_1": 129, "min_CLP": -5.56, "draft_iters": 17.2, "mem_use": 41.71, "gen_rate": 7.4, "speed": 3.14, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 9.8, "tree_w": 28, "tree_size": 128, "t0": 1.2175, "t1": 0.645, "tft": 3.3635, "input_0": 321, "input_1": 129, "min_CLP": -5.48, "draft_iters": 10.8, "mem_use": 42.52, "gen_rate": 4.6, "speed": 2.48, "text": "Yes, the US National Reconnaissa"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 37, "tree_size": 128, "t0": 0.94, "t1": 0.6362, "tft": 2.3158, "input_0": 237, "input_1": 129, "min_CLP": -5.97, "draft_iters": 8.1, "mem_use": 41.79, "gen_rate": 4.1, "speed": 2.61, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 8.2, "tree_w": 40, "tree_size": 128, "t0": 1.02, "t1": 0.6322, "tft": 2.1013, "input_0": 249, "input_1": 129, "min_CLP": -5.94, "draft_iters": 9.2, "mem_use": 41.86, "gen_rate": 4.1, "speed": 2.49, "text": "\"Opie is a cute and friendly nam"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.0, "tree_w": 32, "tree_size": 128, "t0": 2.105, "t1": 0.63, "tft": 1.8163, "input_0": 354, "input_1": 129, "min_CLP": -6.42, "draft_iters": 21.5, "mem_use": 41.41, "gen_rate": 17.5, "speed": 6.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 51, "tree_size": 128, "t0": 0.8713, "t1": 0.6388, "tft": 3.7396, "input_0": 217, "input_1": 129, "min_CLP": -6.25, "draft_iters": 7.6, "mem_use": 42.1, "gen_rate": 4.0, "speed": 2.65, "text": "\"Kaczynski is like, a total kill"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 21, "tree_size": 128, "t0": 1.4175, "t1": 0.6325, "tft": 1.991, "input_0": 366, "input_1": 129, "min_CLP": -5.28, "draft_iters": 12.2, "mem_use": 41.53, "gen_rate": 8.2, "speed": 4.03, "text": "Yes, there are a few ways to sal"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.4, "tree_w": 19, "tree_size": 128, "t0": 1.734, "t1": 0.65, "tft": 2.4709, "input_0": 429, "input_1": 129, "min_CLP": -5.41, "draft_iters": 15.4, "mem_use": 42.76, "gen_rate": 7.0, "speed": 2.94, "text": "Certainly! Here are a few media "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.7, "tree_w": 30, "tree_size": 128, "t0": 1.1967, "t1": 0.635, "tft": 2.03, "input_0": 311, "input_1": 129, "min_CLP": -5.59, "draft_iters": 10.7, "mem_use": 41.86, "gen_rate": 6.2, "speed": 3.37, "text": "\"No, I'm just a simple AI assist"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.0, "tree_w": 23, "tree_size": 128, "t0": 1.89, "t1": 0.6467, "tft": 3.8119, "input_0": 521, "input_1": 129, "min_CLP": -5.39, "draft_iters": 16.0, "mem_use": 43.1, "gen_rate": 11.0, "speed": 4.34, "text": "For a beginner hiker looking to "}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.7, "tree_w": 33, "tree_size": 128, "t0": 1.2433, "t1": 0.6383, "tft": 2.6055, "input_0": 283, "input_1": 129, "min_CLP": -5.48, "draft_iters": 11.7, "mem_use": 41.81, "gen_rate": 6.0, "speed": 3.19, "text": "\"Open Assistant: Open Source Cha"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.7, "tree_w": 28, "tree_size": 128, "t0": 1.36, "t1": 0.64, "tft": 2.4893, "input_0": 334, "input_1": 129, "min_CLP": -5.45, "draft_iters": 11.7, "mem_use": 41.7, "gen_rate": 6.7, "speed": 3.33, "text": "\"Sure, here's a diagram to illus"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.0, "tree_w": 22, "tree_size": 128, "t0": 1.804, "t1": 0.65, "tft": 3.6696, "input_0": 392, "input_1": 129, "min_CLP": -5.1, "draft_iters": 17.0, "mem_use": 44.06, "gen_rate": 7.0, "speed": 2.86, "text": "This is because the Average Rate"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 13.3, "tree_w": 24, "tree_size": 128, "t0": 1.52, "t1": 0.6267, "tft": 1.8682, "input_0": 356, "input_1": 129, "min_CLP": -5.4, "draft_iters": 14.3, "mem_use": 41.4, "gen_rate": 13.0, "speed": 6.06, "text": "No, you cannot compile Python co"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 53, "tree_size": 128, "t0": 0.7875, "t1": 0.635, "tft": 2.1317, "input_0": 207, "input_1": 129, "min_CLP": -6.25, "draft_iters": 6.8, "mem_use": 41.95, "gen_rate": 4.2, "speed": 2.99, "text": "Video games are already a very e"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 10.5, "tree_w": 30, "tree_size": 128, "t0": 1.2825, "t1": 0.6275, "tft": 2.7547, "input_0": 315, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.5, "mem_use": 41.58, "gen_rate": 5.8, "speed": 3.02, "text": "When the pan is already hot, the"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.0, "tree_w": 17, "tree_size": 128, "t0": 1.7833, "t1": 0.63, "tft": 1.7966, "input_0": 386, "input_1": 129, "min_CLP": -5.35, "draft_iters": 18.0, "mem_use": 41.41, "gen_rate": 11.0, "speed": 4.55, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.3, "tree_w": 22, "tree_size": 128, "t0": 1.44, "t1": 0.6467, "tft": 3.2812, "input_0": 394, "input_1": 129, "min_CLP": -5.28, "draft_iters": 12.3, "mem_use": 43.53, "gen_rate": 10.7, "speed": 5.11, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.8, "tree_w": 37, "tree_size": 128, "t0": 0.99, "t1": 0.625, "tft": 1.6932, "input_0": 272, "input_1": 129, "min_CLP": -5.69, "draft_iters": 8.8, "mem_use": 41.37, "gen_rate": 6.2, "speed": 3.82, "text": "\"No, a thumb war is not violent."}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.0, "tree_w": 23, "tree_size": 128, "t0": 1.5275, "t1": 0.635, "tft": 1.8231, "input_0": 384, "input_1": 129, "min_CLP": -5.42, "draft_iters": 13.0, "mem_use": 41.46, "gen_rate": 9.0, "speed": 4.17, "text": "Rick Astley\\'s \"Never Gonna Give"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.2, "tree_w": 22, "tree_size": 128, "t0": 1.572, "t1": 0.652, "tft": 3.9865, "input_0": 403, "input_1": 129, "min_CLP": -5.4, "draft_iters": 13.2, "mem_use": 44.74, "gen_rate": 8.2, "speed": 3.69, "text": "As of my last knowledge update i"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.4, "tree_w": 24, "tree_size": 128, "t0": 1.472, "t1": 0.642, "tft": 2.7467, "input_0": 346, "input_1": 129, "min_CLP": -5.42, "draft_iters": 14.4, "mem_use": 42.72, "gen_rate": 6.6, "speed": 3.12, "text": "I understand that you are lookin"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.0, "tree_w": 18, "tree_size": 128, "t0": 1.625, "t1": 0.6325, "tft": 1.8416, "input_0": 401, "input_1": 129, "min_CLP": -5.09, "draft_iters": 15.0, "mem_use": 41.67, "gen_rate": 9.8, "speed": 4.32, "text": "Certainly! There are many resour"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 34, "tree_size": 128, "t0": 1.26, "t1": 0.636, "tft": 2.0693, "input_0": 280, "input_1": 129, "min_CLP": -5.86, "draft_iters": 12.4, "mem_use": 41.64, "gen_rate": 6.4, "speed": 3.38, "text": "The most effective way to commit"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.8, "tree_w": 26, "tree_size": 128, "t0": 1.164, "t1": 0.628, "tft": 1.6761, "input_0": 292, "input_1": 129, "min_CLP": -5.44, "draft_iters": 10.8, "mem_use": 41.41, "gen_rate": 6.6, "speed": 3.69, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 9.4, "tree_w": 40, "tree_size": 128, "t0": 1.077, "t1": 0.641, "tft": 3.268, "input_0": 228, "input_1": 129, "min_CLP": -6.04, "draft_iters": 10.4, "mem_use": 42.22, "gen_rate": 3.4, "speed": 1.98, "text": "\"[INST] Okay, I understand now. "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 24.7, "tree_w": 12, "tree_size": 128, "t0": 2.62, "t1": 0.64, "tft": 4.028, "input_0": 561, "input_1": 129, "min_CLP": -4.96, "draft_iters": 25.7, "mem_use": 42.25, "gen_rate": 12.7, "speed": 3.88, "text": "Por supuesto, aqu\u00ed tienes las tr"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 128, "t0": 2.96, "t1": 0.65, "tft": 5.4394, "input_0": 501, "input_1": 129, "min_CLP": -5.83, "draft_iters": 32.0, "mem_use": 44.77, "gen_rate": 33.0, "speed": 9.14, "text": "Step 1 \u2014 Starting the TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 19, "tree_size": 128, "t0": 1.538, "t1": 0.63, "tft": 2.2177, "input_0": 373, "input_1": 129, "min_CLP": -5.28, "draft_iters": 14.0, "mem_use": 41.42, "gen_rate": 7.0, "speed": 3.23, "text": "To reduce your alcohol consumpti"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.8, "tree_w": 35, "tree_size": 128, "t0": 0.9975, "t1": 0.6337, "tft": 2.137, "input_0": 248, "input_1": 129, "min_CLP": -5.88, "draft_iters": 8.8, "mem_use": 41.98, "gen_rate": 4.2, "speed": 2.6, "text": "\"Berlin is home to the world's l"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 21.5, "tree_w": 12, "tree_size": 128, "t0": 2.415, "t1": 0.64, "tft": 1.9998, "input_0": 578, "input_1": 129, "min_CLP": -4.88, "draft_iters": 22.5, "mem_use": 41.46, "gen_rate": 16.5, "speed": 5.4, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 14.5, "tree_w": 20, "tree_size": 128, "t0": 1.5833, "t1": 0.645, "tft": 4.9895, "input_0": 348, "input_1": 129, "min_CLP": -5.22, "draft_iters": 15.5, "mem_use": 43.98, "gen_rate": 5.3, "speed": 2.39, "text": "Sure, here is a recipe for a sim"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 25, "tree_size": 128, "t0": 1.38, "t1": 0.6317, "tft": 1.5858, "input_0": 372, "input_1": 129, "min_CLP": -5.62, "draft_iters": 11.3, "mem_use": 41.37, "gen_rate": 5.5, "speed": 2.73, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.5, "tree_w": 24, "tree_size": 128, "t0": 1.4575, "t1": 0.645, "tft": 3.5149, "input_0": 385, "input_1": 129, "min_CLP": -5.55, "draft_iters": 12.5, "mem_use": 43.66, "gen_rate": 8.8, "speed": 4.16, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.5, "tree_w": 26, "tree_size": 128, "t0": 1.5383, "t1": 0.63, "tft": 1.7705, "input_0": 372, "input_1": 129, "min_CLP": -5.43, "draft_iters": 14.5, "mem_use": 41.38, "gen_rate": 6.0, "speed": 2.77, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 13, "tree_h": 13.5, "tree_w": 34, "tree_size": 128, "t0": 1.3575, "t1": 0.63, "tft": 2.3972, "input_0": 233, "input_1": 129, "min_CLP": -6.09, "draft_iters": 14.2, "mem_use": 41.36, "gen_rate": 3.2, "speed": 1.64, "text": "\u4e0a\u9762\u8fd9\u53e5\u8bdd\u4ec0\u4e48\u610f\u601d\\n\u8fd9\u53e5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u201c\u8bf7\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b\u3002\u201d"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.8, "tree_w": 22, "tree_size": 128, "t0": 1.555, "t1": 0.63, "tft": 1.781, "input_0": 349, "input_1": 129, "min_CLP": -5.28, "draft_iters": 14.8, "mem_use": 41.52, "gen_rate": 9.0, "speed": 4.12, "text": "Sure, I can provide an example o"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 1.4925, "t1": 0.6525, "tft": 3.0235, "input_0": 417, "input_1": 129, "min_CLP": -5.31, "draft_iters": 13.0, "mem_use": 42.58, "gen_rate": 8.5, "speed": 3.97, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.8, "tree_w": 24, "tree_size": 128, "t0": 1.596, "t1": 0.63, "tft": 1.9649, "input_0": 414, "input_1": 129, "min_CLP": -5.57, "draft_iters": 13.8, "mem_use": 41.47, "gen_rate": 7.6, "speed": 3.41, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 26, "tree_size": 128, "t0": 1.346, "t1": 0.634, "tft": 1.9971, "input_0": 320, "input_1": 129, "min_CLP": -5.5, "draft_iters": 12.2, "mem_use": 41.67, "gen_rate": 6.6, "speed": 3.33, "text": "Sure, in reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.2, "tree_w": 24, "tree_size": 128, "t0": 1.352, "t1": 0.638, "tft": 2.5803, "input_0": 317, "input_1": 129, "min_CLP": -5.27, "draft_iters": 13.2, "mem_use": 42.02, "gen_rate": 7.8, "speed": 3.93, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 37, "tree_size": 128, "t0": 1.07, "t1": 0.6329, "tft": 2.0765, "input_0": 289, "input_1": 129, "min_CLP": -5.72, "draft_iters": 9.0, "mem_use": 41.56, "gen_rate": 4.9, "speed": 2.86, "text": "I am the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 15.5, "tree_w": 18, "tree_size": 128, "t0": 1.83, "t1": 0.65, "tft": 3.7209, "input_0": 468, "input_1": 129, "min_CLP": -5.04, "draft_iters": 16.5, "mem_use": 42.78, "gen_rate": 10.2, "speed": 4.14, "text": "\"On a Windows machine, you can u"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 1.446, "t1": 0.63, "tft": 2.3152, "input_0": 348, "input_1": 129, "min_CLP": -5.43, "draft_iters": 13.0, "mem_use": 41.46, "gen_rate": 7.0, "speed": 3.37, "text": "I respectfully disagree with the"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.7, "tree_w": 19, "tree_size": 128, "t0": 2.34, "t1": 0.64, "tft": 2.9787, "input_0": 564, "input_1": 129, "min_CLP": -5.13, "draft_iters": 20.7, "mem_use": 42.3, "gen_rate": 13.7, "speed": 4.58, "text": "\"Microwave ovens became a common"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.4, "tree_w": 28, "tree_size": 128, "t0": 1.2886, "t1": 0.6286, "tft": 2.2531, "input_0": 321, "input_1": 129, "min_CLP": -5.44, "draft_iters": 11.4, "mem_use": 41.56, "gen_rate": 5.0, "speed": 2.61, "text": "Pros:\\n1. Improved tolerance: By"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 17.5, "tree_w": 17, "tree_size": 128, "t0": 1.9117, "t1": 0.6633, "tft": 1.6636, "input_0": 413, "input_1": 129, "min_CLP": -5.53, "draft_iters": 18.5, "mem_use": 41.39, "gen_rate": 7.8, "speed": 3.04, "text": "\"What happened to schrodinger's "}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 1.4675, "t1": 0.6625, "tft": 5.0091, "input_0": 358, "input_1": 129, "min_CLP": -5.37, "draft_iters": 13.8, "mem_use": 45.69, "gen_rate": 8.5, "speed": 3.99, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.2, "tree_w": 25, "tree_size": 128, "t0": 1.454, "t1": 0.632, "tft": 2.8476, "input_0": 374, "input_1": 129, "min_CLP": -5.39, "draft_iters": 13.2, "mem_use": 41.7, "gen_rate": 7.6, "speed": 3.65, "text": "Approaching technical problems t"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 26.0, "tree_w": 36, "tree_size": 128, "t0": 2.415, "t1": 0.645, "tft": 3.6542, "input_0": 350, "input_1": 129, "min_CLP": -5.33, "draft_iters": 27.0, "mem_use": 42.57, "gen_rate": 16.5, "speed": 5.39, "text": "It would take approximately 334 "}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 35, "tree_size": 128, "t0": 1.1171, "t1": 0.6443, "tft": 4.0446, "input_0": 264, "input_1": 129, "min_CLP": -5.71, "draft_iters": 10.0, "mem_use": 43.85, "gen_rate": 4.9, "speed": 2.75, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 9.0, "tree_w": 42, "tree_size": 128, "t0": 1.092, "t1": 0.632, "tft": 2.4629, "input_0": 246, "input_1": 129, "min_CLP": -6.27, "draft_iters": 10.0, "mem_use": 41.67, "gen_rate": 3.4, "speed": 1.97, "text": "If your computer had a bank acco"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 19, "tree_h": 16.8, "tree_w": 22, "tree_size": 128, "t0": 1.865, "t1": 0.63, "tft": 2.0068, "input_0": 394, "input_1": 129, "min_CLP": -5.29, "draft_iters": 17.8, "mem_use": 41.71, "gen_rate": 4.8, "speed": 1.9, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.8, "tree_w": 19, "tree_size": 128, "t0": 1.87, "t1": 0.6375, "tft": 2.6732, "input_0": 446, "input_1": 129, "min_CLP": -5.37, "draft_iters": 16.8, "mem_use": 42.19, "gen_rate": 9.5, "speed": 3.78, "text": "There are a number of 3D animati"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 22, "tree_size": 128, "t0": 2.975, "t1": 0.635, "tft": 2.3875, "input_0": 560, "input_1": 129, "min_CLP": -6.28, "draft_iters": 31.5, "mem_use": 41.7, "gen_rate": 32.0, "speed": 8.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 29, "tree_size": 128, "t0": 1.294, "t1": 0.646, "tft": 2.5312, "input_0": 331, "input_1": 129, "min_CLP": -5.86, "draft_iters": 11.0, "mem_use": 42.38, "gen_rate": 6.8, "speed": 3.5, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.0, "tree_w": 25, "tree_size": 128, "t0": 1.93, "t1": 0.64, "tft": 1.7614, "input_0": 327, "input_1": 129, "min_CLP": -6.76, "draft_iters": 20.5, "mem_use": 41.71, "gen_rate": 17.5, "speed": 6.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.0, "tree_w": 25, "tree_size": 128, "t0": 1.71, "t1": 0.6325, "tft": 2.17, "input_0": 369, "input_1": 129, "min_CLP": -5.46, "draft_iters": 17.0, "mem_use": 41.44, "gen_rate": 8.2, "speed": 3.53, "text": "Here are the pieces of a reinfor"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 12.7, "tree_w": 26, "tree_size": 128, "t0": 1.5067, "t1": 0.6333, "tft": 1.5354, "input_0": 308, "input_1": 129, "min_CLP": -5.61, "draft_iters": 13.7, "mem_use": 41.4, "gen_rate": 5.3, "speed": 2.49, "text": "\"The user's question is: Why can"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 29, "tree_h": 14.6, "tree_w": 24, "tree_size": 128, "t0": 1.68, "t1": 0.66, "tft": 4.4879, "input_0": 379, "input_1": 129, "min_CLP": -5.38, "draft_iters": 15.6, "mem_use": 45.67, "gen_rate": 5.8, "speed": 2.48, "text": "\"You're welcome! It was a pleasu"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.0, "tree_w": 26, "tree_size": 128, "t0": 1.43, "t1": 0.634, "tft": 2.1052, "input_0": 373, "input_1": 129, "min_CLP": -5.37, "draft_iters": 12.0, "mem_use": 41.54, "gen_rate": 7.8, "speed": 3.78, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 1.5133, "t1": 0.64, "tft": 3.4774, "input_0": 376, "input_1": 129, "min_CLP": -5.61, "draft_iters": 14.0, "mem_use": 43.11, "gen_rate": 10.7, "speed": 4.95, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.5, "tree_w": 23, "tree_size": 128, "t0": 1.5467, "t1": 0.6433, "tft": 2.7752, "input_0": 403, "input_1": 129, "min_CLP": -5.37, "draft_iters": 13.5, "mem_use": 42.83, "gen_rate": 6.3, "speed": 2.89, "text": "In option 2, the Command Prompt "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 20.5, "tree_w": 18, "tree_size": 128, "t0": 2.0525, "t1": 0.63, "tft": 3.6669, "input_0": 380, "input_1": 129, "min_CLP": -5.63, "draft_iters": 21.2, "mem_use": 41.67, "gen_rate": 8.2, "speed": 3.07, "text": "\"Using critical thinking methods"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.6, "tree_w": 18, "tree_size": 128, "t0": 1.754, "t1": 0.63, "tft": 3.3891, "input_0": 388, "input_1": 129, "min_CLP": -5.14, "draft_iters": 16.6, "mem_use": 41.48, "gen_rate": 7.6, "speed": 3.19, "text": "Sure! To decide between boiling "}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 21, "tree_size": 128, "t0": 2.79, "t1": 0.63, "tft": 1.8118, "input_0": 383, "input_1": 129, "min_CLP": -5.61, "draft_iters": 32.0, "mem_use": 41.46, "gen_rate": 33.0, "speed": 9.65, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.6, "tree_w": 23, "tree_size": 128, "t0": 1.472, "t1": 0.64, "tft": 2.6745, "input_0": 352, "input_1": 129, "min_CLP": -5.17, "draft_iters": 13.6, "mem_use": 42.46, "gen_rate": 7.2, "speed": 3.41, "text": "I\\'m sorry, but I\\'m not sure wh"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 29, "tree_h": 11.7, "tree_w": 39, "tree_size": 128, "t0": 1.2789, "t1": 0.6356, "tft": 2.178, "input_0": 237, "input_1": 129, "min_CLP": -5.93, "draft_iters": 12.6, "mem_use": 41.79, "gen_rate": 3.2, "speed": 1.68, "text": "Could you please provide a brief"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.0, "tree_w": 15, "tree_size": 128, "t0": 2.0867, "t1": 0.6433, "tft": 4.6331, "input_0": 358, "input_1": 129, "min_CLP": -5.04, "draft_iters": 21.7, "mem_use": 43.15, "gen_rate": 11.7, "speed": 4.27, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 35, "tree_size": 128, "t0": 0.9867, "t1": 0.6383, "tft": 2.4596, "input_0": 257, "input_1": 129, "min_CLP": -5.81, "draft_iters": 8.5, "mem_use": 42.03, "gen_rate": 5.8, "speed": 3.59, "text": "I think the answerer is someone "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 38, "tree_size": 128, "t0": 1.422, "t1": 0.636, "tft": 3.7646, "input_0": 264, "input_1": 129, "min_CLP": -6.2, "draft_iters": 14.4, "mem_use": 41.87, "gen_rate": 6.6, "speed": 3.21, "text": "In the Operation Fast and Furiou"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 1.24, "t1": 0.626, "tft": 2.2022, "input_0": 330, "input_1": 129, "min_CLP": -5.31, "draft_iters": 11.2, "mem_use": 41.61, "gen_rate": 7.6, "speed": 4.07, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 128, "t0": 3.03, "t1": 0.65, "tft": 5.1523, "input_0": 583, "input_1": 129, "min_CLP": -9.21, "draft_iters": 32.0, "mem_use": 44.41, "gen_rate": 33.0, "speed": 8.97, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 62, "tree_h": 30.0, "tree_w": 13, "tree_size": 128, "t0": 2.82, "t1": 0.645, "tft": 5.1671, "input_0": 427, "input_1": 129, "min_CLP": -5.75, "draft_iters": 30.5, "mem_use": 44.34, "gen_rate": 31.0, "speed": 8.93, "text": "\"Once upon a time, in the fair c"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 38, "tree_size": 128, "t0": 1.1167, "t1": 0.6267, "tft": 1.7321, "input_0": 280, "input_1": 129, "min_CLP": -6.04, "draft_iters": 9.7, "mem_use": 41.4, "gen_rate": 5.5, "speed": 3.16, "text": "```python\\ndef generate_neruda_p"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 19.0, "tree_w": 20, "tree_size": 128, "t0": 1.88, "t1": 0.64, "tft": 2.2781, "input_0": 334, "input_1": 129, "min_CLP": -5.54, "draft_iters": 19.7, "mem_use": 42.56, "gen_rate": 14.7, "speed": 5.82, "text": "Absolutely! I have added the inf"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.5, "tree_w": 18, "tree_size": 128, "t0": 1.715, "t1": 0.64, "tft": 3.9744, "input_0": 378, "input_1": 129, "min_CLP": -5.04, "draft_iters": 16.5, "mem_use": 43.05, "gen_rate": 10.0, "speed": 4.25, "text": "\"I apologize if my previous resp"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.0, "tree_w": 17, "tree_size": 128, "t0": 2.0233, "t1": 0.63, "tft": 1.6426, "input_0": 456, "input_1": 129, "min_CLP": -5.29, "draft_iters": 19.0, "mem_use": 41.38, "gen_rate": 10.7, "speed": 4.03, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 16.0, "tree_w": 29, "tree_size": 128, "t0": 1.6387, "t1": 0.63, "tft": 1.7996, "input_0": 296, "input_1": 129, "min_CLP": -5.9, "draft_iters": 16.9, "mem_use": 41.67, "gen_rate": 4.1, "speed": 1.82, "text": "I am a being of immense power an"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.7, "tree_w": 17, "tree_size": 128, "t0": 1.93, "t1": 0.65, "tft": 4.1913, "input_0": 465, "input_1": 129, "min_CLP": -5.36, "draft_iters": 17.7, "mem_use": 43.29, "gen_rate": 10.7, "speed": 4.13, "text": "\"No, this is not true. Hershey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 15.4, "tree_w": 23, "tree_size": 128, "t0": 1.792, "t1": 0.634, "tft": 1.8391, "input_0": 412, "input_1": 129, "min_CLP": -5.44, "draft_iters": 16.4, "mem_use": 41.62, "gen_rate": 8.2, "speed": 3.38, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 12.1, "tree_w": 23, "tree_size": 128, "t0": 1.4129, "t1": 0.6414, "tft": 2.9055, "input_0": 326, "input_1": 129, "min_CLP": -5.33, "draft_iters": 13.1, "mem_use": 43.0, "gen_rate": 4.6, "speed": 2.22, "text": "\"Certainly! Here's a more detail"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 2.82, "t1": 0.63, "tft": 1.6883, "input_0": 443, "input_1": 129, "min_CLP": -6.37, "draft_iters": 32.0, "mem_use": 41.41, "gen_rate": 33.0, "speed": 9.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.5, "tree_w": 17, "tree_size": 128, "t0": 1.79, "t1": 0.63, "tft": 1.9804, "input_0": 435, "input_1": 129, "min_CLP": -5.27, "draft_iters": 15.5, "mem_use": 41.42, "gen_rate": 10.0, "speed": 4.13, "text": "To cook a salmon fillet on a sto"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 10.4, "tree_w": 30, "tree_size": 128, "t0": 1.2444, "t1": 0.6333, "tft": 1.9176, "input_0": 313, "input_1": 129, "min_CLP": -5.69, "draft_iters": 11.4, "mem_use": 42.07, "gen_rate": 3.9, "speed": 2.07, "text": "\"Alright, I'll do both. First, l"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 12.6, "tree_w": 38, "tree_size": 128, "t0": 1.3875, "t1": 0.6425, "tft": 1.9965, "input_0": 295, "input_1": 129, "min_CLP": -5.84, "draft_iters": 13.6, "mem_use": 42.3, "gen_rate": 4.1, "speed": 2.03, "text": "\"You're right, I apologize for t"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 26, "tree_size": 128, "t0": 1.155, "t1": 0.625, "tft": 1.8752, "input_0": 273, "input_1": 129, "min_CLP": -5.64, "draft_iters": 11.0, "mem_use": 41.4, "gen_rate": 8.0, "speed": 4.49, "text": "An AK-47 is a type of assault ri"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 17.2, "tree_w": 19, "tree_size": 128, "t0": 1.92, "t1": 0.636, "tft": 2.0984, "input_0": 437, "input_1": 129, "min_CLP": -5.12, "draft_iters": 18.2, "mem_use": 41.74, "gen_rate": 8.0, "speed": 3.13, "text": "\"To copy a directory of files fr"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.5, "tree_w": 17, "tree_size": 128, "t0": 2.115, "t1": 0.64, "tft": 3.2736, "input_0": 371, "input_1": 129, "min_CLP": -4.84, "draft_iters": 22.5, "mem_use": 43.17, "gen_rate": 16.0, "speed": 5.8, "text": "* Statistical modeling: applying"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 14, "tree_size": 128, "t0": 1.79, "t1": 0.63, "tft": 2.4122, "input_0": 452, "input_1": 129, "min_CLP": -5.0, "draft_iters": 16.7, "mem_use": 41.73, "gen_rate": 11.3, "speed": 4.69, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.5, "tree_w": 28, "tree_size": 128, "t0": 1.2933, "t1": 0.64, "tft": 2.9166, "input_0": 306, "input_1": 129, "min_CLP": -5.4, "draft_iters": 11.5, "mem_use": 42.23, "gen_rate": 5.7, "speed": 2.93, "text": "\"No, there's no harm in letting "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 48, "tree_size": 128, "t0": 0.75, "t1": 0.6386, "tft": 3.0904, "input_0": 192, "input_1": 129, "min_CLP": -6.1, "draft_iters": 6.6, "mem_use": 41.87, "gen_rate": 4.6, "speed": 3.29, "text": "\"You could tell them about a fun"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 28, "tree_size": 128, "t0": 1.2314, "t1": 0.63, "tft": 2.2134, "input_0": 321, "input_1": 129, "min_CLP": -5.55, "draft_iters": 10.4, "mem_use": 41.98, "gen_rate": 5.0, "speed": 2.69, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 34, "tree_size": 128, "t0": 1.145, "t1": 0.63, "tft": 1.7674, "input_0": 279, "input_1": 129, "min_CLP": -5.71, "draft_iters": 9.8, "mem_use": 41.38, "gen_rate": 5.5, "speed": 3.09, "text": "\"I'm currently thinking about pr"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.45, "t1": 0.63, "tft": 3.3577, "input_0": 393, "input_1": 129, "min_CLP": -5.47, "draft_iters": 12.2, "mem_use": 41.39, "gen_rate": 5.7, "speed": 2.72, "text": "Cryptocurrencies have the potent"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.6, "tree_w": 30, "tree_size": 128, "t0": 1.1643, "t1": 0.6343, "tft": 2.5112, "input_0": 292, "input_1": 129, "min_CLP": -5.37, "draft_iters": 10.6, "mem_use": 41.93, "gen_rate": 4.7, "speed": 2.62, "text": "L-theanine can help reduce stres"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 54, "tree_h": 29.8, "tree_w": 10, "tree_size": 128, "t0": 2.96, "t1": 0.63, "tft": 2.0606, "input_0": 561, "input_1": 129, "min_CLP": -4.61, "draft_iters": 30.2, "mem_use": 41.69, "gen_rate": 13.5, "speed": 3.76, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 18, "tree_size": 128, "t0": 1.4225, "t1": 0.6275, "tft": 3.129, "input_0": 387, "input_1": 129, "min_CLP": -5.18, "draft_iters": 13.0, "mem_use": 41.48, "gen_rate": 8.0, "speed": 3.9, "text": "\"The task is asking you to rewri"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.288, "t1": 0.628, "tft": 1.8665, "input_0": 315, "input_1": 129, "min_CLP": -5.52, "draft_iters": 12.2, "mem_use": 41.44, "gen_rate": 7.0, "speed": 3.65, "text": "In the city, there is a lot more"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.4, "tree_w": 28, "tree_size": 128, "t0": 1.4829, "t1": 0.6314, "tft": 1.9892, "input_0": 333, "input_1": 129, "min_CLP": -5.61, "draft_iters": 14.4, "mem_use": 42.0, "gen_rate": 5.0, "speed": 2.37, "text": "The image was chosen as the defa"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.3, "tree_w": 31, "tree_size": 128, "t0": 1.0314, "t1": 0.6543, "tft": 3.9834, "input_0": 262, "input_1": 129, "min_CLP": -5.44, "draft_iters": 9.3, "mem_use": 45.06, "gen_rate": 4.9, "speed": 2.88, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.9, "tree_w": 34, "tree_size": 128, "t0": 1.02, "t1": 0.65, "tft": 3.8171, "input_0": 277, "input_1": 129, "min_CLP": -5.58, "draft_iters": 8.9, "mem_use": 43.82, "gen_rate": 5.3, "speed": 3.16, "text": "\"It's possible that we never had"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.8, "tree_w": 35, "tree_size": 128, "t0": 1.1025, "t1": 0.6325, "tft": 3.7619, "input_0": 294, "input_1": 129, "min_CLP": -5.79, "draft_iters": 9.8, "mem_use": 42.07, "gen_rate": 4.4, "speed": 2.52, "text": "Building a Dyson sphere is a hyp"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 2.99, "t1": 0.63, "tft": 2.0152, "input_0": 483, "input_1": 129, "min_CLP": -7.51, "draft_iters": 32.0, "mem_use": 41.4, "gen_rate": 33.0, "speed": 9.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.5, "tree_w": 25, "tree_size": 128, "t0": 1.2967, "t1": 0.63, "tft": 3.3135, "input_0": 338, "input_1": 129, "min_CLP": -5.37, "draft_iters": 11.5, "mem_use": 41.38, "gen_rate": 6.0, "speed": 3.11, "text": "Yes, I can speak German. I have "}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 24.0, "tree_w": 24, "tree_size": 128, "t0": 2.23, "t1": 0.64, "tft": 1.8975, "input_0": 267, "input_1": 129, "min_CLP": -5.92, "draft_iters": 25.0, "mem_use": 41.58, "gen_rate": 23.0, "speed": 8.02, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.3983, "t1": 0.6483, "tft": 2.4956, "input_0": 375, "input_1": 129, "min_CLP": -5.2, "draft_iters": 12.2, "mem_use": 42.47, "gen_rate": 5.8, "speed": 2.85, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 12.0, "tree_w": 25, "tree_size": 128, "t0": 1.4783, "t1": 0.6483, "tft": 3.7425, "input_0": 368, "input_1": 129, "min_CLP": -5.37, "draft_iters": 13.0, "mem_use": 43.1, "gen_rate": 5.8, "speed": 2.74, "text": "Yes, it is possible to use AI im"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 39, "tree_size": 128, "t0": 1.165, "t1": 0.63, "tft": 2.081, "input_0": 281, "input_1": 129, "min_CLP": -5.84, "draft_iters": 10.3, "mem_use": 41.44, "gen_rate": 5.7, "speed": 3.16, "text": "Sure, here are a few haikus for "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.5, "tree_w": 42, "tree_size": 128, "t0": 1.185, "t1": 0.6367, "tft": 2.3142, "input_0": 242, "input_1": 129, "min_CLP": -5.93, "draft_iters": 11.5, "mem_use": 41.81, "gen_rate": 5.8, "speed": 3.2, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n    / "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 2.9, "t1": 0.62, "tft": 1.6606, "input_0": 458, "input_1": 129, "min_CLP": -5.47, "draft_iters": 32.0, "mem_use": 41.4, "gen_rate": 33.0, "speed": 9.36, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.2, "tree_w": 19, "tree_size": 128, "t0": 1.8075, "t1": 0.6375, "tft": 2.038, "input_0": 374, "input_1": 129, "min_CLP": -5.25, "draft_iters": 17.2, "mem_use": 41.76, "gen_rate": 9.5, "speed": 3.89, "text": "Yes, there is a widely accepted "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.0, "tree_w": 33, "tree_size": 128, "t0": 1.13, "t1": 0.6329, "tft": 2.1192, "input_0": 281, "input_1": 129, "min_CLP": -5.5, "draft_iters": 10.0, "mem_use": 41.67, "gen_rate": 5.0, "speed": 2.84, "text": "\"It sounds like you're trying to"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 17.3, "tree_w": 30, "tree_size": 128, "t0": 1.7533, "t1": 0.65, "tft": 3.0737, "input_0": 307, "input_1": 129, "min_CLP": -5.67, "draft_iters": 18.0, "mem_use": 43.74, "gen_rate": 4.7, "speed": 1.94, "text": "\"[INST] I'm ready, chef! What's "}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 36, "tree_size": 128, "t0": 1.11, "t1": 0.6333, "tft": 1.6721, "input_0": 277, "input_1": 129, "min_CLP": -5.79, "draft_iters": 9.7, "mem_use": 41.56, "gen_rate": 6.0, "speed": 3.44, "text": "\"Certainly! Here's a simple ASCI"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 37, "tree_size": 128, "t0": 1.12, "t1": 0.6486, "tft": 4.071, "input_0": 275, "input_1": 129, "min_CLP": -5.88, "draft_iters": 9.7, "mem_use": 44.44, "gen_rate": 5.1, "speed": 2.91, "text": "As the sun set over the horizon,"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.5, "tree_w": 32, "tree_size": 128, "t0": 1.2083, "t1": 0.6317, "tft": 1.7842, "input_0": 282, "input_1": 129, "min_CLP": -5.57, "draft_iters": 11.5, "mem_use": 41.43, "gen_rate": 6.0, "speed": 3.27, "text": "Sure, here is an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.0, "tree_w": 16, "tree_size": 128, "t0": 1.825, "t1": 0.63, "tft": 1.7949, "input_0": 364, "input_1": 129, "min_CLP": -5.19, "draft_iters": 18.0, "mem_use": 41.39, "gen_rate": 18.0, "speed": 7.32, "text": "The difference between HTML and "}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 19, "tree_size": 128, "t0": 1.6225, "t1": 0.6325, "tft": 1.5055, "input_0": 415, "input_1": 129, "min_CLP": -5.06, "draft_iters": 14.5, "mem_use": 41.41, "gen_rate": 8.2, "speed": 3.66, "text": "Certainly! Below is a table pres"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 24, "tree_size": 128, "t0": 1.345, "t1": 0.635, "tft": 2.1667, "input_0": 314, "input_1": 129, "min_CLP": -5.59, "draft_iters": 12.5, "mem_use": 41.79, "gen_rate": 6.0, "speed": 3.04, "text": "\"Yes, it is protected by copyrig"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.0, "tree_w": 31, "tree_size": 128, "t0": 1.2457, "t1": 0.6329, "tft": 1.8377, "input_0": 334, "input_1": 129, "min_CLP": -5.71, "draft_iters": 10.0, "mem_use": 41.4, "gen_rate": 5.3, "speed": 2.81, "text": "The second batch of pancakes bro"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 20.2, "tree_w": 16, "tree_size": 128, "t0": 2.125, "t1": 0.6425, "tft": 4.1356, "input_0": 430, "input_1": 129, "min_CLP": -5.39, "draft_iters": 21.0, "mem_use": 42.46, "gen_rate": 9.8, "speed": 3.52, "text": "\"The sky appears blue to us beca"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.8, "tree_w": 30, "tree_size": 128, "t0": 1.0913, "t1": 0.6425, "tft": 3.7696, "input_0": 288, "input_1": 129, "min_CLP": -5.6, "draft_iters": 9.8, "mem_use": 42.17, "gen_rate": 4.0, "speed": 2.31, "text": "\"If you're seeking a position of"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.6, "tree_w": 48, "tree_size": 128, "t0": 0.7622, "t1": 0.6356, "tft": 2.9641, "input_0": 204, "input_1": 129, "min_CLP": -6.03, "draft_iters": 6.6, "mem_use": 42.02, "gen_rate": 4.0, "speed": 2.86, "text": "Depends on the game, but yes. So"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.2, "tree_w": 30, "tree_size": 128, "t0": 1.225, "t1": 0.6483, "tft": 2.5126, "input_0": 309, "input_1": 129, "min_CLP": -5.67, "draft_iters": 11.2, "mem_use": 42.74, "gen_rate": 6.2, "speed": 3.29, "text": "That\\'s a wonderful choice. \"Whe"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.0, "tree_w": 41, "tree_size": 128, "t0": 1.2729, "t1": 0.6314, "tft": 1.4852, "input_0": 266, "input_1": 129, "min_CLP": -5.89, "draft_iters": 12.0, "mem_use": 41.37, "gen_rate": 4.7, "speed": 2.47, "text": "\"Here's an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 1.1614, "t1": 0.6371, "tft": 2.2873, "input_0": 306, "input_1": 129, "min_CLP": -5.49, "draft_iters": 10.0, "mem_use": 41.7, "gen_rate": 4.7, "speed": 2.62, "text": "\"I'm happy to provide some infor"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 25, "tree_size": 128, "t0": 1.5125, "t1": 0.64, "tft": 2.9207, "input_0": 330, "input_1": 129, "min_CLP": -5.37, "draft_iters": 14.5, "mem_use": 42.44, "gen_rate": 8.2, "speed": 3.83, "text": "As of 2022, the James Webb Teles"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.9, "tree_w": 32, "tree_size": 128, "t0": 1.1637, "t1": 0.6275, "tft": 2.1041, "input_0": 321, "input_1": 129, "min_CLP": -5.7, "draft_iters": 9.9, "mem_use": 41.49, "gen_rate": 4.6, "speed": 2.58, "text": "Motion Matching is a technique u"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 2.925, "t1": 0.645, "tft": 4.5161, "input_0": 501, "input_1": 129, "min_CLP": -4.63, "draft_iters": 32.0, "mem_use": 43.16, "gen_rate": 21.0, "speed": 5.88, "text": "\"Sure, here's an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 17, "tree_size": 128, "t0": 2.73, "t1": 0.63, "tft": 1.7328, "input_0": 356, "input_1": 129, "min_CLP": -7.08, "draft_iters": 32.0, "mem_use": 41.44, "gen_rate": 33.0, "speed": 9.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.0, "tree_w": 20, "tree_size": 128, "t0": 2.005, "t1": 0.63, "tft": 2.0097, "input_0": 341, "input_1": 129, "min_CLP": -6.58, "draft_iters": 21.5, "mem_use": 41.83, "gen_rate": 17.5, "speed": 6.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.2, "tree_w": 22, "tree_size": 128, "t0": 1.4775, "t1": 0.64, "tft": 3.5046, "input_0": 399, "input_1": 129, "min_CLP": -5.31, "draft_iters": 13.2, "mem_use": 43.17, "gen_rate": 8.5, "speed": 4.01, "text": "The idea of \"100 monkeys on a ty"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 25, "tree_size": 128, "t0": 1.3125, "t1": 0.645, "tft": 3.0525, "input_0": 330, "input_1": 129, "min_CLP": -5.36, "draft_iters": 12.0, "mem_use": 43.59, "gen_rate": 8.2, "speed": 4.22, "text": "Paul Allen has a diverse collect"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 31, "tree_size": 128, "t0": 1.2483, "t1": 0.6433, "tft": 3.2167, "input_0": 349, "input_1": 129, "min_CLP": -5.93, "draft_iters": 10.3, "mem_use": 43.04, "gen_rate": 5.8, "speed": 3.08, "text": "\"Sure, here's a similar case tha"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 128, "t0": 2.97, "t1": 0.63, "tft": 1.7087, "input_0": 460, "input_1": 129, "min_CLP": -5.64, "draft_iters": 32.0, "mem_use": 41.47, "gen_rate": 33.0, "speed": 9.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.0, "tree_w": 28, "tree_size": 128, "t0": 1.1433, "t1": 0.635, "tft": 3.3815, "input_0": 318, "input_1": 129, "min_CLP": -5.48, "draft_iters": 10.0, "mem_use": 42.1, "gen_rate": 5.7, "speed": 3.19, "text": "\"As an AI model, I don't have de"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 16, "tree_size": 128, "t0": 2.485, "t1": 0.635, "tft": 2.4207, "input_0": 444, "input_1": 129, "min_CLP": -6.91, "draft_iters": 26.5, "mem_use": 41.5, "gen_rate": 27.0, "speed": 8.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 24, "tree_size": 128, "t0": 1.282, "t1": 0.63, "tft": 1.8251, "input_0": 325, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.4, "mem_use": 41.39, "gen_rate": 7.2, "speed": 3.77, "text": "\"Yes, the 5-second rule is a bel"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 18.7, "tree_w": 26, "tree_size": 128, "t0": 1.7933, "t1": 0.6367, "tft": 2.2902, "input_0": 308, "input_1": 129, "min_CLP": -5.6, "draft_iters": 19.3, "mem_use": 42.22, "gen_rate": 4.3, "speed": 1.78, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.0, "tree_w": 17, "tree_size": 128, "t0": 1.7, "t1": 0.6425, "tft": 2.9721, "input_0": 397, "input_1": 129, "min_CLP": -5.09, "draft_iters": 15.0, "mem_use": 43.07, "gen_rate": 8.2, "speed": 3.52, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.4, "tree_w": 30, "tree_size": 128, "t0": 1.26, "t1": 0.642, "tft": 3.5599, "input_0": 304, "input_1": 129, "min_CLP": -5.58, "draft_iters": 11.4, "mem_use": 43.96, "gen_rate": 6.4, "speed": 3.36, "text": "\"Multi-track drifting\" is a hypo"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.6, "tree_w": 28, "tree_size": 128, "t0": 1.312, "t1": 0.648, "tft": 2.8903, "input_0": 383, "input_1": 129, "min_CLP": -5.46, "draft_iters": 10.6, "mem_use": 42.54, "gen_rate": 8.0, "speed": 4.08, "text": "Yes, it is theoretically possibl"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.3, "tree_w": 35, "tree_size": 128, "t0": 1.07, "t1": 0.6443, "tft": 4.0193, "input_0": 271, "input_1": 129, "min_CLP": -5.81, "draft_iters": 9.3, "mem_use": 42.37, "gen_rate": 4.6, "speed": 2.67, "text": "\"My love, you're the sunshine in"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.5, "tree_w": 18, "tree_size": 128, "t0": 1.545, "t1": 0.6375, "tft": 2.8727, "input_0": 327, "input_1": 129, "min_CLP": -5.28, "draft_iters": 15.5, "mem_use": 42.14, "gen_rate": 9.0, "speed": 4.12, "text": "In Japanese, the words for \"love"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.0, "tree_w": 28, "tree_size": 128, "t0": 1.518, "t1": 0.634, "tft": 2.8931, "input_0": 366, "input_1": 129, "min_CLP": -5.3, "draft_iters": 14.0, "mem_use": 41.68, "gen_rate": 7.8, "speed": 3.63, "text": "In addition to the US, there are"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 25, "tree_size": 128, "t0": 1.438, "t1": 0.626, "tft": 1.6144, "input_0": 375, "input_1": 129, "min_CLP": -5.35, "draft_iters": 12.4, "mem_use": 41.37, "gen_rate": 6.4, "speed": 3.1, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 31.3, "tree_w": 9, "tree_size": 128, "t0": 3.0733, "t1": 0.63, "tft": 1.9576, "input_0": 567, "input_1": 129, "min_CLP": -4.53, "draft_iters": 32.0, "mem_use": 41.51, "gen_rate": 16.0, "speed": 4.32, "text": "\"Sure, here's an example of a C+"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 1.1683, "t1": 0.65, "tft": 3.0795, "input_0": 300, "input_1": 129, "min_CLP": -5.57, "draft_iters": 10.2, "mem_use": 42.63, "gen_rate": 6.5, "speed": 3.58, "text": "1. Financial stress:\\n- Make a b"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 16, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 1.4, "t1": 0.625, "tft": 1.4895, "input_0": 308, "input_1": 129, "min_CLP": -5.52, "draft_iters": 14.0, "mem_use": 41.37, "gen_rate": 4.0, "speed": 1.97, "text": "\"I don't have a name, so you can"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 16.7, "tree_w": 14, "tree_size": 128, "t0": 1.9233, "t1": 0.6467, "tft": 4.5358, "input_0": 423, "input_1": 129, "min_CLP": -4.91, "draft_iters": 17.7, "mem_use": 44.06, "gen_rate": 12.0, "speed": 4.67, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 22, "tree_size": 128, "t0": 1.6375, "t1": 0.6325, "tft": 2.4685, "input_0": 424, "input_1": 129, "min_CLP": -5.44, "draft_iters": 14.2, "mem_use": 41.66, "gen_rate": 9.0, "speed": 3.96, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 7.5, "tree_w": 47, "tree_size": 128, "t0": 0.985, "t1": 0.629, "tft": 1.8388, "input_0": 244, "input_1": 129, "min_CLP": -6.42, "draft_iters": 8.5, "mem_use": 41.45, "gen_rate": 3.2, "speed": 1.98, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 22, "tree_size": 128, "t0": 1.6625, "t1": 0.6475, "tft": 4.3472, "input_0": 391, "input_1": 129, "min_CLP": -5.57, "draft_iters": 15.8, "mem_use": 43.65, "gen_rate": 8.0, "speed": 3.47, "text": "Yes, there are many open-source "}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 128, "t0": 2.77, "t1": 0.63, "tft": 2.917, "input_0": 377, "input_1": 129, "min_CLP": -7.06, "draft_iters": 32.0, "mem_use": 41.44, "gen_rate": 33.0, "speed": 9.7, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 33, "tree_size": 128, "t0": 1.12, "t1": 0.64, "tft": 3.0371, "input_0": 323, "input_1": 129, "min_CLP": -5.83, "draft_iters": 9.6, "mem_use": 42.15, "gen_rate": 6.4, "speed": 3.63, "text": "Not really. The Unus Annus Troll"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 22.4, "tree_w": 16, "tree_size": 128, "t0": 2.2157, "t1": 0.6414, "tft": 3.9379, "input_0": 384, "input_1": 129, "min_CLP": -5.33, "draft_iters": 23.1, "mem_use": 43.06, "gen_rate": 5.7, "speed": 2.0, "text": "1. m\u00eb (pronounced m\u0113)\\n2. meles "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 31, "tree_size": 128, "t0": 1.1271, "t1": 0.6329, "tft": 2.4185, "input_0": 294, "input_1": 129, "min_CLP": -5.69, "draft_iters": 9.9, "mem_use": 41.7, "gen_rate": 5.0, "speed": 2.84, "text": "\"I am an artificial intelligence"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 29, "tree_size": 128, "t0": 1.372, "t1": 0.65, "tft": 3.9455, "input_0": 351, "input_1": 129, "min_CLP": -5.51, "draft_iters": 12.0, "mem_use": 44.47, "gen_rate": 7.0, "speed": 3.46, "text": "\"I apologize for any confusion. "}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 20, "tree_size": 128, "t0": 1.525, "t1": 0.635, "tft": 1.5275, "input_0": 363, "input_1": 129, "min_CLP": -5.17, "draft_iters": 13.8, "mem_use": 41.41, "gen_rate": 8.2, "speed": 3.82, "text": "\"Certainly! In reStructuredText "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 22.0, "tree_w": 14, "tree_size": 128, "t0": 2.44, "t1": 0.6467, "tft": 3.994, "input_0": 545, "input_1": 129, "min_CLP": -4.58, "draft_iters": 22.7, "mem_use": 43.45, "gen_rate": 17.7, "speed": 5.73, "text": "Here\\'s an example code that set"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 1.2175, "t1": 0.63, "tft": 1.9862, "input_0": 321, "input_1": 129, "min_CLP": -5.4, "draft_iters": 11.2, "mem_use": 41.39, "gen_rate": 8.5, "speed": 4.6, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.3, "tree_w": 48, "tree_size": 128, "t0": 0.8429, "t1": 0.6371, "tft": 3.3316, "input_0": 211, "input_1": 129, "min_CLP": -6.24, "draft_iters": 7.3, "mem_use": 41.85, "gen_rate": 4.9, "speed": 3.28, "text": "I would say that it will take a "}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.3, "tree_w": 42, "tree_size": 128, "t0": 0.9933, "t1": 0.6711, "tft": 6.4943, "input_0": 258, "input_1": 129, "min_CLP": -5.93, "draft_iters": 8.3, "mem_use": 47.0, "gen_rate": 4.0, "speed": 2.4, "text": "\"Yes Sir, I will do my best\\n\\n["}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.2, "tree_w": 42, "tree_size": 128, "t0": 1.0, "t1": 0.6425, "tft": 2.6663, "input_0": 223, "input_1": 129, "min_CLP": -5.92, "draft_iters": 9.2, "mem_use": 42.22, "gen_rate": 4.1, "speed": 2.51, "text": "0 someone that works for the gov"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 29, "tree_size": 128, "t0": 1.345, "t1": 0.6525, "tft": 3.4387, "input_0": 367, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.2, "mem_use": 44.09, "gen_rate": 8.0, "speed": 4.01, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.0, "tree_w": 38, "tree_size": 128, "t0": 0.9438, "t1": 0.6437, "tft": 3.4426, "input_0": 252, "input_1": 129, "min_CLP": -5.81, "draft_iters": 8.0, "mem_use": 42.44, "gen_rate": 4.4, "speed": 2.76, "text": "\"1. Competitor's menu has change"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.5, "tree_w": 31, "tree_size": 128, "t0": 1.1, "t1": 0.63, "tft": 1.9199, "input_0": 279, "input_1": 129, "min_CLP": -5.56, "draft_iters": 9.5, "mem_use": 41.72, "gen_rate": 5.7, "speed": 3.27, "text": "Here\\'s a script for a Spartan G"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 24.0, "tree_w": 16, "tree_size": 128, "t0": 2.55, "t1": 0.65, "tft": 4.7476, "input_0": 553, "input_1": 129, "min_CLP": -5.34, "draft_iters": 25.0, "mem_use": 44.21, "gen_rate": 16.0, "speed": 5.0, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 2.82, "t1": 0.63, "tft": 2.3486, "input_0": 402, "input_1": 129, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 41.9, "gen_rate": 33.0, "speed": 9.55, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.8, "tree_w": 17, "tree_size": 128, "t0": 1.83, "t1": 0.65, "tft": 3.9562, "input_0": 440, "input_1": 129, "min_CLP": -5.07, "draft_iters": 16.8, "mem_use": 43.88, "gen_rate": 9.8, "speed": 3.93, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 30, "tree_size": 128, "t0": 1.15, "t1": 0.63, "tft": 1.5319, "input_0": 304, "input_1": 129, "min_CLP": -5.72, "draft_iters": 10.0, "mem_use": 41.43, "gen_rate": 8.0, "speed": 4.49, "text": "```lean\\nimport data.list.basic\\"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 26, "tree_size": 128, "t0": 1.415, "t1": 0.64, "tft": 2.2639, "input_0": 309, "input_1": 129, "min_CLP": -5.83, "draft_iters": 13.2, "mem_use": 42.15, "gen_rate": 8.0, "speed": 3.89, "text": "As of 2019, women are allowed to"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.3, "tree_w": 19, "tree_size": 128, "t0": 1.4967, "t1": 0.6367, "tft": 2.6159, "input_0": 376, "input_1": 129, "min_CLP": -5.24, "draft_iters": 13.3, "mem_use": 41.87, "gen_rate": 11.7, "speed": 5.47, "text": "To alleviate the symptoms of nau"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.8, "tree_w": 22, "tree_size": 128, "t0": 1.4567, "t1": 0.635, "tft": 2.1674, "input_0": 335, "input_1": 129, "min_CLP": -5.18, "draft_iters": 13.8, "mem_use": 41.47, "gen_rate": 6.3, "speed": 3.03, "text": "\"To create a smooth and visually"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 27, "tree_size": 128, "t0": 1.3125, "t1": 0.6425, "tft": 2.4449, "input_0": 335, "input_1": 129, "min_CLP": -5.27, "draft_iters": 11.8, "mem_use": 42.35, "gen_rate": 8.2, "speed": 4.22, "text": "\"It's normal to feel this way, b"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 22, "tree_size": 128, "t0": 1.6975, "t1": 0.6475, "tft": 3.9968, "input_0": 407, "input_1": 129, "min_CLP": -5.28, "draft_iters": 15.0, "mem_use": 43.97, "gen_rate": 8.5, "speed": 3.62, "text": "\"It's difficult to determine the"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 7.0, "tree_w": 37, "tree_size": 128, "t0": 0.89, "t1": 0.63, "tft": 2.0193, "input_0": 205, "input_1": 129, "min_CLP": -5.71, "draft_iters": 8.0, "mem_use": 41.58, "gen_rate": 3.0, "speed": 1.97, "text": "13.5 hours"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 17.4, "tree_w": 22, "tree_size": 128, "t0": 1.902, "t1": 0.632, "tft": 1.8907, "input_0": 412, "input_1": 129, "min_CLP": -5.23, "draft_iters": 18.4, "mem_use": 41.5, "gen_rate": 7.2, "speed": 2.84, "text": "Here\\'s an example code for a Di"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 24, "tree_size": 128, "t0": 1.265, "t1": 0.6275, "tft": 2.2528, "input_0": 311, "input_1": 129, "min_CLP": -5.49, "draft_iters": 11.8, "mem_use": 41.39, "gen_rate": 8.0, "speed": 4.22, "text": "Yes, I am capable of answering q"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 31, "tree_size": 128, "t0": 1.3025, "t1": 0.6575, "tft": 4.2245, "input_0": 345, "input_1": 129, "min_CLP": -5.36, "draft_iters": 10.8, "mem_use": 45.17, "gen_rate": 8.0, "speed": 4.08, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 16.2, "tree_w": 25, "tree_size": 128, "t0": 1.69, "t1": 0.6325, "tft": 2.1929, "input_0": 306, "input_1": 129, "min_CLP": -5.57, "draft_iters": 17.0, "mem_use": 41.51, "gen_rate": 11.8, "speed": 5.05, "text": "The four kids are Luis, Drake, M"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.9, "tree_w": 34, "tree_size": 128, "t0": 1.01, "t1": 0.6429, "tft": 2.247, "input_0": 263, "input_1": 129, "min_CLP": -5.54, "draft_iters": 8.9, "mem_use": 42.54, "gen_rate": 4.9, "speed": 2.94, "text": "It is important to note that thi"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.8, "tree_w": 22, "tree_size": 128, "t0": 1.5425, "t1": 0.66, "tft": 4.6853, "input_0": 422, "input_1": 129, "min_CLP": -5.18, "draft_iters": 12.8, "mem_use": 44.33, "gen_rate": 8.8, "speed": 3.98, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 32, "tree_size": 128, "t0": 1.1483, "t1": 0.64, "tft": 2.0101, "input_0": 298, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.0, "mem_use": 41.64, "gen_rate": 5.8, "speed": 3.26, "text": "\"It's great that you're dedicati"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.9, "tree_w": 26, "tree_size": 128, "t0": 1.4714, "t1": 0.6429, "tft": 2.41, "input_0": 352, "input_1": 129, "min_CLP": -5.48, "draft_iters": 13.9, "mem_use": 42.15, "gen_rate": 5.1, "speed": 2.43, "text": "\"You're welcome! If you need any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.0, "tree_w": 18, "tree_size": 128, "t0": 1.7833, "t1": 0.6533, "tft": 3.9065, "input_0": 412, "input_1": 129, "min_CLP": -5.11, "draft_iters": 16.0, "mem_use": 43.9, "gen_rate": 11.3, "speed": 4.65, "text": "\"As a high school student, there"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.2, "tree_w": 20, "tree_size": 128, "t0": 1.6025, "t1": 0.6425, "tft": 2.5649, "input_0": 387, "input_1": 129, "min_CLP": -5.11, "draft_iters": 15.2, "mem_use": 42.28, "gen_rate": 9.2, "speed": 4.12, "text": "The invention of the television "}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 18.3, "tree_w": 29, "tree_size": 128, "t0": 1.8967, "t1": 0.65, "tft": 3.7244, "input_0": 372, "input_1": 129, "min_CLP": -5.93, "draft_iters": 19.0, "mem_use": 44.61, "gen_rate": 14.0, "speed": 5.5, "text": "\"[INST] I'll try it. [\\\\INST]\\n["}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 31, "tree_size": 128, "t0": 1.0917, "t1": 0.645, "tft": 3.6387, "input_0": 284, "input_1": 129, "min_CLP": -5.44, "draft_iters": 9.7, "mem_use": 42.93, "gen_rate": 5.7, "speed": 3.27, "text": "There are multiple days in which"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 7.0, "tree_w": 50, "tree_size": 128, "t0": 0.8618, "t1": 0.6355, "tft": 1.8942, "input_0": 188, "input_1": 129, "min_CLP": -6.02, "draft_iters": 8.0, "mem_use": 41.96, "gen_rate": 3.2, "speed": 2.13, "text": "\"You're sorry indeed, I am not d"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.5, "tree_w": 22, "tree_size": 128, "t0": 1.5225, "t1": 0.6475, "tft": 3.5917, "input_0": 382, "input_1": 129, "min_CLP": -5.29, "draft_iters": 13.5, "mem_use": 43.77, "gen_rate": 9.0, "speed": 4.16, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.0, "tree_w": 24, "tree_size": 128, "t0": 1.3117, "t1": 0.635, "tft": 1.9505, "input_0": 330, "input_1": 129, "min_CLP": -5.25, "draft_iters": 12.0, "mem_use": 41.58, "gen_rate": 6.2, "speed": 3.17, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 19.6, "tree_w": 23, "tree_size": 128, "t0": 1.91, "t1": 0.638, "tft": 2.6225, "input_0": 315, "input_1": 129, "min_CLP": -5.58, "draft_iters": 20.6, "mem_use": 42.21, "gen_rate": 8.6, "speed": 3.38, "text": "Of course! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 63, "tree_h": 14.9, "tree_w": 42, "tree_size": 128, "t0": 1.4675, "t1": 0.6337, "tft": 3.0372, "input_0": 242, "input_1": 129, "min_CLP": -6.01, "draft_iters": 15.6, "mem_use": 41.67, "gen_rate": 7.9, "speed": 3.75, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.5, "tree_w": 24, "tree_size": 128, "t0": 1.9025, "t1": 0.6325, "tft": 2.5976, "input_0": 393, "input_1": 129, "min_CLP": -5.45, "draft_iters": 18.5, "mem_use": 41.69, "gen_rate": 8.0, "speed": 3.15, "text": "The Sagittarius A* black hole is"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 33, "tree_size": 128, "t0": 1.1583, "t1": 0.6317, "tft": 3.7843, "input_0": 280, "input_1": 129, "min_CLP": -5.69, "draft_iters": 10.5, "mem_use": 42.07, "gen_rate": 5.3, "speed": 2.98, "text": "Google Authenticator is a mobile"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.4, "tree_w": 20, "tree_size": 128, "t0": 1.66, "t1": 0.632, "tft": 2.4829, "input_0": 436, "input_1": 129, "min_CLP": -5.12, "draft_iters": 14.4, "mem_use": 41.86, "gen_rate": 8.2, "speed": 3.58, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 21, "tree_size": 128, "t0": 1.688, "t1": 0.632, "tft": 1.8549, "input_0": 474, "input_1": 129, "min_CLP": -5.21, "draft_iters": 13.6, "mem_use": 41.62, "gen_rate": 6.6, "speed": 2.84, "text": "Certainly! Below is an example o"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.5, "tree_w": 21, "tree_size": 128, "t0": 2.155, "t1": 0.635, "tft": 2.2552, "input_0": 367, "input_1": 129, "min_CLP": -6.01, "draft_iters": 22.0, "mem_use": 41.47, "gen_rate": 18.5, "speed": 6.63, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 54, "tree_h": 12.8, "tree_w": 29, "tree_size": 128, "t0": 1.3918, "t1": 0.6318, "tft": 1.7933, "input_0": 270, "input_1": 129, "min_CLP": -5.71, "draft_iters": 13.8, "mem_use": 41.5, "gen_rate": 4.9, "speed": 2.43, "text": "```\\n\\\\* Takes two numbers from "}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 2.92, "t1": 0.63, "tft": 1.4397, "input_0": 488, "input_1": 129, "min_CLP": -5.78, "draft_iters": 32.0, "mem_use": 41.42, "gen_rate": 33.0, "speed": 9.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.0, "tree_w": 21, "tree_size": 128, "t0": 1.715, "t1": 0.6425, "tft": 2.6515, "input_0": 390, "input_1": 129, "min_CLP": -5.39, "draft_iters": 16.0, "mem_use": 42.6, "gen_rate": 9.0, "speed": 3.81, "text": "In this case, you can use the sc"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.0, "tree_w": 19, "tree_size": 128, "t0": 1.7975, "t1": 0.63, "tft": 1.9903, "input_0": 426, "input_1": 129, "min_CLP": -5.37, "draft_iters": 17.0, "mem_use": 41.38, "gen_rate": 9.5, "speed": 3.91, "text": "In Python, the `@` symbol is use"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.8, "tree_w": 25, "tree_size": 128, "t0": 1.435, "t1": 0.6325, "tft": 1.729, "input_0": 358, "input_1": 129, "min_CLP": -5.51, "draft_iters": 12.8, "mem_use": 41.39, "gen_rate": 9.0, "speed": 4.35, "text": "ChatGPT is an AI language model "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.7, "tree_w": 37, "tree_size": 128, "t0": 1.13, "t1": 0.635, "tft": 1.7575, "input_0": 292, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.7, "mem_use": 41.7, "gen_rate": 5.8, "speed": 3.31, "text": "\"I would approach such a task by"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 19, "tree_h": 7.3, "tree_w": 50, "tree_size": 128, "t0": 0.9186, "t1": 0.6343, "tft": 1.5151, "input_0": 214, "input_1": 129, "min_CLP": -6.59, "draft_iters": 8.3, "mem_use": 41.43, "gen_rate": 2.7, "speed": 1.75, "text": "\"```malbolge\\n'`6\\n```\\n```bash\\"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 128, "t0": 2.79, "t1": 0.64, "tft": 3.4117, "input_0": 375, "input_1": 129, "min_CLP": -7.28, "draft_iters": 32.0, "mem_use": 42.12, "gen_rate": 33.0, "speed": 9.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 15.8, "tree_w": 27, "tree_size": 128, "t0": 1.74, "t1": 0.65, "tft": 3.9273, "input_0": 360, "input_1": 129, "min_CLP": -5.45, "draft_iters": 16.8, "mem_use": 44.64, "gen_rate": 8.3, "speed": 3.48, "text": "\"Can you provide a summary of th"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 16.2, "tree_w": 18, "tree_size": 128, "t0": 1.845, "t1": 0.6375, "tft": 2.4737, "input_0": 438, "input_1": 129, "min_CLP": -5.35, "draft_iters": 17.2, "mem_use": 41.93, "gen_rate": 10.5, "speed": 4.23, "text": "Yes, there are some things that "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 36, "tree_size": 128, "t0": 0.9871, "t1": 0.6471, "tft": 2.9187, "input_0": 252, "input_1": 129, "min_CLP": -5.82, "draft_iters": 8.4, "mem_use": 43.09, "gen_rate": 4.7, "speed": 2.88, "text": "Hello, Agent. It is a pleasure t"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 19, "tree_h": 17.8, "tree_w": 29, "tree_size": 128, "t0": 1.735, "t1": 0.635, "tft": 2.765, "input_0": 281, "input_1": 129, "min_CLP": -5.79, "draft_iters": 18.5, "mem_use": 41.92, "gen_rate": 4.8, "speed": 2.0, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 19.8, "tree_w": 20, "tree_size": 128, "t0": 2.1225, "t1": 0.6525, "tft": 5.4766, "input_0": 436, "input_1": 129, "min_CLP": -5.22, "draft_iters": 20.5, "mem_use": 44.82, "gen_rate": 13.0, "speed": 4.68, "text": "Here are some basic examples of "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 12, "tree_size": 128, "t0": 2.155, "t1": 0.705, "tft": 8.2052, "input_0": 487, "input_1": 129, "min_CLP": -4.79, "draft_iters": 20.5, "mem_use": 50.84, "gen_rate": 20.5, "speed": 7.17, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.6, "tree_w": 21, "tree_size": 128, "t0": 1.792, "t1": 0.65, "tft": 4.5831, "input_0": 379, "input_1": 129, "min_CLP": -5.16, "draft_iters": 17.4, "mem_use": 43.19, "gen_rate": 7.0, "speed": 2.87, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.8, "tree_w": 20, "tree_size": 128, "t0": 1.5175, "t1": 0.63, "tft": 1.7824, "input_0": 347, "input_1": 129, "min_CLP": -5.35, "draft_iters": 14.8, "mem_use": 41.43, "gen_rate": 9.8, "speed": 4.54, "text": "Sure, I\u2019d be happy to help you w"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 17.2, "tree_w": 22, "tree_size": 128, "t0": 1.7967, "t1": 0.6333, "tft": 1.7175, "input_0": 379, "input_1": 129, "min_CLP": -5.5, "draft_iters": 17.8, "mem_use": 41.55, "gen_rate": 5.5, "speed": 2.27, "text": "\"In TypeScript, you can use the "}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 21, "tree_size": 128, "t0": 1.45, "t1": 0.6525, "tft": 3.763, "input_0": 385, "input_1": 129, "min_CLP": -5.33, "draft_iters": 13.0, "mem_use": 44.34, "gen_rate": 8.2, "speed": 3.92, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.0, "tree_w": 26, "tree_size": 128, "t0": 1.304, "t1": 0.63, "tft": 1.8995, "input_0": 349, "input_1": 129, "min_CLP": -5.5, "draft_iters": 11.0, "mem_use": 41.49, "gen_rate": 8.2, "speed": 4.24, "text": "The world in 1950 was vastly dif"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.0, "tree_w": 19, "tree_size": 128, "t0": 1.702, "t1": 0.666, "tft": 5.0682, "input_0": 426, "input_1": 129, "min_CLP": -5.05, "draft_iters": 16.0, "mem_use": 46.49, "gen_rate": 7.4, "speed": 3.12, "text": "\"Creating your own stable diffus"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.0, "tree_w": 25, "tree_size": 128, "t0": 1.625, "t1": 0.635, "tft": 2.3477, "input_0": 311, "input_1": 129, "min_CLP": -5.37, "draft_iters": 16.0, "mem_use": 41.83, "gen_rate": 8.5, "speed": 3.76, "text": "The order of installing parts is"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 23, "tree_size": 128, "t0": 1.38, "t1": 0.6325, "tft": 1.9816, "input_0": 392, "input_1": 129, "min_CLP": -5.44, "draft_iters": 12.0, "mem_use": 41.68, "gen_rate": 9.5, "speed": 4.71, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 37, "tree_size": 128, "t0": 1.0983, "t1": 0.6333, "tft": 3.2884, "input_0": 280, "input_1": 129, "min_CLP": -5.78, "draft_iters": 9.8, "mem_use": 41.74, "gen_rate": 5.7, "speed": 3.27, "text": "I will be more free and less res"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 24, "tree_size": 128, "t0": 1.29, "t1": 0.6475, "tft": 3.5184, "input_0": 335, "input_1": 129, "min_CLP": -5.27, "draft_iters": 11.2, "mem_use": 43.14, "gen_rate": 8.2, "speed": 4.26, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.6, "tree_w": 24, "tree_size": 128, "t0": 1.51, "t1": 0.64, "tft": 2.0741, "input_0": 371, "input_1": 129, "min_CLP": -5.6, "draft_iters": 13.6, "mem_use": 41.81, "gen_rate": 8.4, "speed": 3.91, "text": "The Keyhole series of spy satell"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 13.1, "tree_w": 25, "tree_size": 128, "t0": 1.4629, "t1": 0.6329, "tft": 1.8983, "input_0": 332, "input_1": 129, "min_CLP": -5.48, "draft_iters": 14.0, "mem_use": 41.99, "gen_rate": 5.3, "speed": 2.52, "text": "\"Here's a recipe you can make us"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 1.598, "t1": 0.634, "tft": 2.6705, "input_0": 391, "input_1": 129, "min_CLP": -5.19, "draft_iters": 15.0, "mem_use": 42.05, "gen_rate": 7.6, "speed": 3.41, "text": "Yes, you can try a few things to"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.8, "tree_w": 26, "tree_size": 128, "t0": 1.258, "t1": 0.646, "tft": 3.3539, "input_0": 337, "input_1": 129, "min_CLP": -5.38, "draft_iters": 10.8, "mem_use": 43.98, "gen_rate": 7.2, "speed": 3.78, "text": "Sure! Here are some YouTube chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.4, "tree_w": 26, "tree_size": 128, "t0": 1.446, "t1": 0.628, "tft": 1.8485, "input_0": 348, "input_1": 129, "min_CLP": -5.36, "draft_iters": 13.4, "mem_use": 41.39, "gen_rate": 7.0, "speed": 3.38, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 12.0, "tree_w": 39, "tree_size": 128, "t0": 1.365, "t1": 0.63, "tft": 2.1829, "input_0": 308, "input_1": 129, "min_CLP": -5.92, "draft_iters": 13.0, "mem_use": 41.53, "gen_rate": 2.5, "speed": 1.25, "text": "B^T A^T"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.8, "tree_w": 40, "tree_size": 128, "t0": 0.915, "t1": 0.6425, "tft": 2.8081, "input_0": 237, "input_1": 129, "min_CLP": -5.9, "draft_iters": 7.8, "mem_use": 43.01, "gen_rate": 4.5, "speed": 2.89, "text": "\"Statistical modeling, man, it's"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 3.03, "t1": 0.65, "tft": 3.923, "input_0": 554, "input_1": 129, "min_CLP": -6.57, "draft_iters": 32.0, "mem_use": 44.15, "gen_rate": 33.0, "speed": 8.96, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 9.0, "tree_w": 27, "tree_size": 128, "t0": 1.165, "t1": 0.635, "tft": 1.5437, "input_0": 317, "input_1": 129, "min_CLP": -5.6, "draft_iters": 10.0, "mem_use": 41.37, "gen_rate": 4.5, "speed": 2.5, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.8, "tree_w": 25, "tree_size": 128, "t0": 1.69, "t1": 0.644, "tft": 2.6667, "input_0": 427, "input_1": 129, "min_CLP": -5.46, "draft_iters": 14.8, "mem_use": 42.85, "gen_rate": 7.8, "speed": 3.34, "text": "That\\'s a great point! Removing "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 41, "tree_size": 128, "t0": 1.0117, "t1": 0.63, "tft": 2.0085, "input_0": 248, "input_1": 129, "min_CLP": -6.1, "draft_iters": 9.0, "mem_use": 41.74, "gen_rate": 5.8, "speed": 3.55, "text": "\"Dude, that's so not true. Techn"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.3, "tree_w": 20, "tree_size": 128, "t0": 2.0333, "t1": 0.63, "tft": 1.9124, "input_0": 485, "input_1": 129, "min_CLP": -5.14, "draft_iters": 19.3, "mem_use": 41.43, "gen_rate": 13.3, "speed": 5.01, "text": "Yes, I can help you with that. E"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 128, "t0": 2.79, "t1": 0.63, "tft": 1.9258, "input_0": 332, "input_1": 129, "min_CLP": -7.35, "draft_iters": 32.0, "mem_use": 41.78, "gen_rate": 33.0, "speed": 9.65, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.3, "tree_w": 28, "tree_size": 128, "t0": 1.175, "t1": 0.63, "tft": 1.6099, "input_0": 321, "input_1": 129, "min_CLP": -5.61, "draft_iters": 10.3, "mem_use": 41.37, "gen_rate": 6.3, "speed": 3.51, "text": "The metabolic process is the set"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.7, "tree_w": 20, "tree_size": 128, "t0": 1.735, "t1": 0.6467, "tft": 2.6819, "input_0": 362, "input_1": 129, "min_CLP": -5.4, "draft_iters": 16.5, "mem_use": 42.7, "gen_rate": 5.7, "speed": 2.38, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 23.0, "tree_w": 24, "tree_size": 128, "t0": 2.2267, "t1": 0.63, "tft": 2.1429, "input_0": 336, "input_1": 129, "min_CLP": -5.64, "draft_iters": 24.0, "mem_use": 41.56, "gen_rate": 5.3, "speed": 1.87, "text": "\"Bob has two sons, John and Jay."}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.0, "tree_w": 20, "tree_size": 128, "t0": 1.8133, "t1": 0.6367, "tft": 2.2851, "input_0": 346, "input_1": 129, "min_CLP": -5.32, "draft_iters": 18.0, "mem_use": 41.95, "gen_rate": 13.3, "speed": 5.44, "text": "The oceans in the world are:\\n1."}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 31, "tree_size": 128, "t0": 1.1129, "t1": 0.6414, "tft": 3.7308, "input_0": 294, "input_1": 129, "min_CLP": -5.55, "draft_iters": 9.7, "mem_use": 42.18, "gen_rate": 5.1, "speed": 2.94, "text": "One way to start is by looking i"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 25.7, "tree_w": 10, "tree_size": 128, "t0": 2.6033, "t1": 0.6333, "tft": 2.5323, "input_0": 487, "input_1": 129, "min_CLP": -4.51, "draft_iters": 26.7, "mem_use": 41.6, "gen_rate": 15.3, "speed": 4.74, "text": "```python\\nimport pygame\\n\\n# In"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 23, "tree_size": 128, "t0": 1.3425, "t1": 0.6475, "tft": 2.5053, "input_0": 368, "input_1": 129, "min_CLP": -5.35, "draft_iters": 11.5, "mem_use": 42.7, "gen_rate": 8.2, "speed": 4.15, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 12.4, "tree_w": 25, "tree_size": 128, "t0": 1.416, "t1": 0.63, "tft": 2.1818, "input_0": 312, "input_1": 129, "min_CLP": -5.49, "draft_iters": 13.4, "mem_use": 41.84, "gen_rate": 4.8, "speed": 2.35, "text": "Please provide a description of "}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.0, "tree_w": 37, "tree_size": 128, "t0": 0.92, "t1": 0.6287, "tft": 1.6914, "input_0": 263, "input_1": 129, "min_CLP": -5.83, "draft_iters": 8.0, "mem_use": 41.38, "gen_rate": 4.0, "speed": 2.59, "text": "\"The Infinite Banking Concept (I"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.0, "tree_w": 20, "tree_size": 128, "t0": 1.765, "t1": 0.63, "tft": 3.5973, "input_0": 412, "input_1": 129, "min_CLP": -5.04, "draft_iters": 16.0, "mem_use": 41.49, "gen_rate": 9.0, "speed": 3.76, "text": "\"Sure! Here's an example of a hi"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.0, "tree_w": 30, "tree_size": 128, "t0": 1.3975, "t1": 0.635, "tft": 2.1275, "input_0": 312, "input_1": 129, "min_CLP": -5.87, "draft_iters": 13.0, "mem_use": 41.64, "gen_rate": 9.8, "speed": 4.8, "text": "They are not on a higher moral l"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.4, "tree_w": 44, "tree_size": 128, "t0": 1.0329, "t1": 0.6414, "tft": 3.7655, "input_0": 236, "input_1": 129, "min_CLP": -6.24, "draft_iters": 9.4, "mem_use": 42.16, "gen_rate": 4.6, "speed": 2.73, "text": "\"I hate the way they talk about "}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 25, "tree_size": 128, "t0": 1.57, "t1": 0.6475, "tft": 2.737, "input_0": 407, "input_1": 129, "min_CLP": -5.25, "draft_iters": 13.2, "mem_use": 43.05, "gen_rate": 8.8, "speed": 3.95, "text": "Sure, you can definitely ask me "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.3, "tree_w": 15, "tree_size": 128, "t0": 2.0667, "t1": 0.6433, "tft": 3.0689, "input_0": 542, "input_1": 129, "min_CLP": -5.2, "draft_iters": 19.3, "mem_use": 43.56, "gen_rate": 11.0, "speed": 4.05, "text": "Some languages that are consider"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 22.0, "tree_w": 18, "tree_size": 128, "t0": 2.32, "t1": 0.636, "tft": 3.1996, "input_0": 478, "input_1": 129, "min_CLP": -5.02, "draft_iters": 22.6, "mem_use": 41.98, "gen_rate": 6.8, "speed": 2.3, "text": "Among the tools I listed, the fo"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 28, "tree_size": 128, "t0": 1.188, "t1": 0.638, "tft": 2.006, "input_0": 327, "input_1": 129, "min_CLP": -5.6, "draft_iters": 10.2, "mem_use": 41.85, "gen_rate": 6.6, "speed": 3.62, "text": "\"I do have opinions about certai"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 35, "tree_size": 128, "t0": 1.0617, "t1": 0.64, "tft": 2.0917, "input_0": 258, "input_1": 129, "min_CLP": -5.57, "draft_iters": 9.8, "mem_use": 42.06, "gen_rate": 5.3, "speed": 3.13, "text": "You should prioritize your proje"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 14.8, "tree_w": 20, "tree_size": 128, "t0": 1.76, "t1": 0.6425, "tft": 2.6683, "input_0": 449, "input_1": 129, "min_CLP": -5.17, "draft_iters": 15.8, "mem_use": 42.07, "gen_rate": 10.8, "speed": 4.48, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.7, "tree_w": 28, "tree_size": 128, "t0": 1.1814, "t1": 0.63, "tft": 1.8925, "input_0": 294, "input_1": 129, "min_CLP": -5.35, "draft_iters": 10.7, "mem_use": 41.5, "gen_rate": 4.7, "speed": 2.6, "text": "Sure, I can help you design an e"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.8, "tree_w": 26, "tree_size": 128, "t0": 1.4175, "t1": 0.6425, "tft": 3.4262, "input_0": 343, "input_1": 129, "min_CLP": -5.69, "draft_iters": 12.8, "mem_use": 43.2, "gen_rate": 9.5, "speed": 4.61, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.8, "tree_w": 23, "tree_size": 128, "t0": 1.628, "t1": 0.634, "tft": 2.8061, "input_0": 349, "input_1": 129, "min_CLP": -5.78, "draft_iters": 15.8, "mem_use": 41.64, "gen_rate": 7.6, "speed": 3.36, "text": "\"Psychomotricity\\n[INST] How cou"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.5, "tree_w": 27, "tree_size": 128, "t0": 1.35, "t1": 0.635, "tft": 1.9786, "input_0": 327, "input_1": 129, "min_CLP": -5.56, "draft_iters": 12.5, "mem_use": 41.47, "gen_rate": 5.8, "speed": 2.94, "text": "Here are 10 names from different"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 25, "tree_h": 11.2, "tree_w": 29, "tree_size": 128, "t0": 1.368, "t1": 0.632, "tft": 2.313, "input_0": 337, "input_1": 129, "min_CLP": -5.64, "draft_iters": 12.2, "mem_use": 41.95, "gen_rate": 5.0, "speed": 2.5, "text": "\"I am an artificial intelligence"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.7, "tree_w": 27, "tree_size": 128, "t0": 1.4217, "t1": 0.6517, "tft": 3.5282, "input_0": 325, "input_1": 129, "min_CLP": -5.22, "draft_iters": 12.7, "mem_use": 43.66, "gen_rate": 6.3, "speed": 3.06, "text": "When creating new images using t"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 34, "tree_size": 128, "t0": 1.0757, "t1": 0.6471, "tft": 2.3408, "input_0": 293, "input_1": 129, "min_CLP": -5.67, "draft_iters": 9.1, "mem_use": 42.42, "gen_rate": 4.7, "speed": 2.74, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 23, "tree_size": 128, "t0": 1.4567, "t1": 0.65, "tft": 3.0691, "input_0": 352, "input_1": 129, "min_CLP": -5.29, "draft_iters": 13.0, "mem_use": 42.85, "gen_rate": 10.7, "speed": 5.06, "text": "The meaning of life is subjectiv"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 33, "tree_size": 128, "t0": 1.182, "t1": 0.632, "tft": 1.6643, "input_0": 300, "input_1": 129, "min_CLP": -5.63, "draft_iters": 10.2, "mem_use": 41.42, "gen_rate": 6.8, "speed": 3.75, "text": "Title: The Digital Odyssey\\n\\nPl"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 1.535, "t1": 0.66, "tft": 4.7269, "input_0": 330, "input_1": 129, "min_CLP": -5.51, "draft_iters": 14.0, "mem_use": 46.14, "gen_rate": 8.0, "speed": 3.64, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.0, "tree_w": 17, "tree_size": 128, "t0": 1.55, "t1": 0.6433, "tft": 3.1779, "input_0": 376, "input_1": 129, "min_CLP": -5.11, "draft_iters": 15.0, "mem_use": 42.55, "gen_rate": 11.7, "speed": 5.33, "text": "To transform other text words or"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.5, "tree_w": 19, "tree_size": 128, "t0": 2.205, "t1": 0.64, "tft": 4.0109, "input_0": 402, "input_1": 129, "min_CLP": -5.1, "draft_iters": 22.5, "mem_use": 42.42, "gen_rate": 16.0, "speed": 5.62, "text": "If the delay is 3 hours, then th"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 28, "tree_size": 128, "t0": 1.5725, "t1": 0.6225, "tft": 1.8664, "input_0": 367, "input_1": 129, "min_CLP": -5.37, "draft_iters": 14.8, "mem_use": 41.44, "gen_rate": 8.5, "speed": 3.87, "text": "\"Adolf Hitler took over Germany "}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.2, "tree_w": 33, "tree_size": 128, "t0": 1.15, "t1": 0.6333, "tft": 2.2649, "input_0": 293, "input_1": 129, "min_CLP": -5.87, "draft_iters": 10.2, "mem_use": 41.78, "gen_rate": 5.5, "speed": 3.08, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 10.0, "tree_w": 31, "tree_size": 128, "t0": 1.295, "t1": 0.6267, "tft": 1.3471, "input_0": 352, "input_1": 129, "min_CLP": -5.85, "draft_iters": 11.0, "mem_use": 41.4, "gen_rate": 5.0, "speed": 2.6, "text": "The number of known black holes "}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.5, "tree_w": 33, "tree_size": 128, "t0": 1.4767, "t1": 0.6617, "tft": 5.0589, "input_0": 297, "input_1": 129, "min_CLP": -5.79, "draft_iters": 14.5, "mem_use": 46.2, "gen_rate": 5.8, "speed": 2.73, "text": "Apologies for misunderstanding y"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 21, "tree_size": 128, "t0": 2.85, "t1": 0.64, "tft": 1.9032, "input_0": 353, "input_1": 129, "min_CLP": -5.71, "draft_iters": 32.0, "mem_use": 41.48, "gen_rate": 33.0, "speed": 9.47, "text": "Human: [INST] <<SYS>>\\nYou are a"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.8, "tree_w": 31, "tree_size": 128, "t0": 1.465, "t1": 0.695, "tft": 6.4997, "input_0": 291, "input_1": 129, "min_CLP": -5.41, "draft_iters": 14.7, "mem_use": 48.43, "gen_rate": 6.2, "speed": 2.85, "text": "I am sorry, but I do not have th"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 9.0, "tree_w": 46, "tree_size": 128, "t0": 1.0511, "t1": 0.6411, "tft": 2.5846, "input_0": 216, "input_1": 129, "min_CLP": -6.16, "draft_iters": 10.0, "mem_use": 42.66, "gen_rate": 4.0, "speed": 2.36, "text": "Spritesla has a unique evolution"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.5, "tree_w": 23, "tree_size": 128, "t0": 1.6375, "t1": 0.6325, "tft": 1.8167, "input_0": 391, "input_1": 129, "min_CLP": -5.12, "draft_iters": 14.5, "mem_use": 41.51, "gen_rate": 9.8, "speed": 4.3, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 13.8, "tree_w": 20, "tree_size": 128, "t0": 1.665, "t1": 0.6317, "tft": 1.6057, "input_0": 408, "input_1": 129, "min_CLP": -5.35, "draft_iters": 14.8, "mem_use": 41.38, "gen_rate": 8.0, "speed": 3.48, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 10.9, "tree_w": 29, "tree_size": 128, "t0": 1.278, "t1": 0.63, "tft": 1.9751, "input_0": 285, "input_1": 129, "min_CLP": -5.71, "draft_iters": 11.9, "mem_use": 41.62, "gen_rate": 3.2, "speed": 1.68, "text": "The output should be a sentence "}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 1.65, "t1": 0.635, "tft": 2.0484, "input_0": 410, "input_1": 129, "min_CLP": -5.26, "draft_iters": 15.0, "mem_use": 41.92, "gen_rate": 9.5, "speed": 4.15, "text": "Sure! Here are a few examples of"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 19.8, "tree_w": 11, "tree_size": 128, "t0": 2.2475, "t1": 0.6475, "tft": 4.3364, "input_0": 524, "input_1": 129, "min_CLP": -5.07, "draft_iters": 20.8, "mem_use": 43.56, "gen_rate": 8.8, "speed": 3.02, "text": "Sure, here are some examples of "}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 22, "tree_size": 128, "t0": 1.4525, "t1": 0.65, "tft": 2.406, "input_0": 358, "input_1": 129, "min_CLP": -5.25, "draft_iters": 13.8, "mem_use": 42.64, "gen_rate": 8.2, "speed": 3.92, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.5, "tree_w": 31, "tree_size": 128, "t0": 1.0888, "t1": 0.6338, "tft": 1.8251, "input_0": 277, "input_1": 129, "min_CLP": -5.73, "draft_iters": 9.5, "mem_use": 41.56, "gen_rate": 4.1, "speed": 2.39, "text": "The atomic bomb game in Go is no"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 24.8, "tree_w": 13, "tree_size": 128, "t0": 2.3875, "t1": 0.65, "tft": 3.918, "input_0": 427, "input_1": 129, "min_CLP": -4.82, "draft_iters": 25.5, "mem_use": 44.2, "gen_rate": 8.5, "speed": 2.8, "text": "\"Sure, here's the commented code"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.8, "tree_w": 29, "tree_size": 128, "t0": 1.5, "t1": 0.6475, "tft": 4.1363, "input_0": 382, "input_1": 129, "min_CLP": -5.58, "draft_iters": 12.8, "mem_use": 42.67, "gen_rate": 9.8, "speed": 4.54, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 21, "tree_size": 128, "t0": 2.89, "t1": 0.64, "tft": 1.5941, "input_0": 473, "input_1": 129, "min_CLP": -5.95, "draft_iters": 32.0, "mem_use": 41.4, "gen_rate": 33.0, "speed": 9.36, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 14.7, "tree_w": 15, "tree_size": 128, "t0": 1.7033, "t1": 0.6333, "tft": 2.3192, "input_0": 386, "input_1": 129, "min_CLP": -5.41, "draft_iters": 15.7, "mem_use": 41.48, "gen_rate": 8.7, "speed": 3.71, "text": "```markdown\\nHere is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.8, "tree_w": 26, "tree_size": 128, "t0": 1.262, "t1": 0.642, "tft": 2.2892, "input_0": 330, "input_1": 129, "min_CLP": -5.69, "draft_iters": 11.8, "mem_use": 42.51, "gen_rate": 8.0, "speed": 4.2, "text": "Of course! Here is a poem in the"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 20.4, "tree_w": 15, "tree_size": 128, "t0": 2.194, "t1": 0.648, "tft": 3.3817, "input_0": 473, "input_1": 129, "min_CLP": -5.23, "draft_iters": 21.2, "mem_use": 43.5, "gen_rate": 8.0, "speed": 2.82, "text": "In JavaScript, you can use the `"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.8, "tree_w": 36, "tree_size": 128, "t0": 1.2, "t1": 0.635, "tft": 2.1583, "input_0": 247, "input_1": 129, "min_CLP": -5.63, "draft_iters": 11.8, "mem_use": 42.0, "gen_rate": 4.2, "speed": 2.32, "text": "To practice the guitar:\\n1. Set "}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.5, "tree_w": 23, "tree_size": 128, "t0": 1.4067, "t1": 0.64, "tft": 2.7679, "input_0": 392, "input_1": 129, "min_CLP": -5.27, "draft_iters": 12.5, "mem_use": 42.48, "gen_rate": 5.5, "speed": 2.68, "text": "I apologize for assuming that yo"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 27, "tree_size": 128, "t0": 1.274, "t1": 0.628, "tft": 1.8426, "input_0": 351, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.4, "mem_use": 41.39, "gen_rate": 7.0, "speed": 3.67, "text": "javascript is a programming lang"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 128, "t0": 2.75, "t1": 0.63, "tft": 1.6797, "input_0": 345, "input_1": 129, "min_CLP": -7.07, "draft_iters": 32.0, "mem_use": 41.38, "gen_rate": 33.0, "speed": 9.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 14.5, "tree_w": 27, "tree_size": 128, "t0": 1.6225, "t1": 0.6362, "tft": 2.197, "input_0": 357, "input_1": 129, "min_CLP": -5.54, "draft_iters": 15.5, "mem_use": 42.09, "gen_rate": 4.4, "speed": 1.93, "text": "Here is the list with the words "}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 26, "tree_size": 128, "t0": 1.1667, "t1": 0.6317, "tft": 1.8867, "input_0": 297, "input_1": 129, "min_CLP": -5.55, "draft_iters": 10.5, "mem_use": 41.51, "gen_rate": 5.8, "speed": 3.24, "text": "Hippoplaisir is a company that f"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 33, "tree_size": 128, "t0": 1.275, "t1": 0.6275, "tft": 1.9567, "input_0": 314, "input_1": 129, "min_CLP": -5.66, "draft_iters": 11.2, "mem_use": 41.51, "gen_rate": 8.2, "speed": 4.33, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.3, "tree_w": 17, "tree_size": 128, "t0": 1.8567, "t1": 0.63, "tft": 1.8615, "input_0": 425, "input_1": 129, "min_CLP": -5.28, "draft_iters": 18.3, "mem_use": 41.48, "gen_rate": 11.7, "speed": 4.7, "text": "Sure! Here are some tips to help"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 22.0, "tree_w": 20, "tree_size": 128, "t0": 2.14, "t1": 0.6533, "tft": 4.2788, "input_0": 366, "input_1": 129, "min_CLP": -5.5, "draft_iters": 22.7, "mem_use": 46.25, "gen_rate": 11.7, "speed": 4.17, "text": "Here is a rewritten version of t"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 16.6, "tree_w": 16, "tree_size": 128, "t0": 1.78, "t1": 0.652, "tft": 3.8844, "input_0": 408, "input_1": 129, "min_CLP": -4.99, "draft_iters": 17.6, "mem_use": 43.9, "gen_rate": 7.8, "speed": 3.21, "text": "\"Sure! Here's a simple explanati"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 18.6, "tree_w": 17, "tree_size": 128, "t0": 2.14, "t1": 0.64, "tft": 2.707, "input_0": 486, "input_1": 129, "min_CLP": -4.94, "draft_iters": 19.6, "mem_use": 42.31, "gen_rate": 7.8, "speed": 2.81, "text": "\"Sure, the formula for calculati"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.5, "tree_w": 20, "tree_size": 128, "t0": 1.845, "t1": 0.6375, "tft": 2.4761, "input_0": 506, "input_1": 129, "min_CLP": -5.32, "draft_iters": 14.5, "mem_use": 42.48, "gen_rate": 10.2, "speed": 4.13, "text": "We can learn a lot from polar be"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.5, "tree_w": 24, "tree_size": 128, "t0": 1.3517, "t1": 0.6467, "tft": 3.2517, "input_0": 385, "input_1": 129, "min_CLP": -5.34, "draft_iters": 11.5, "mem_use": 43.57, "gen_rate": 5.3, "speed": 2.67, "text": "Lemon wedges are small pieces of"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.7, "tree_w": 33, "tree_size": 128, "t0": 1.2071, "t1": 0.6286, "tft": 2.1939, "input_0": 294, "input_1": 129, "min_CLP": -5.63, "draft_iters": 10.7, "mem_use": 41.58, "gen_rate": 4.6, "speed": 2.49, "text": "\"Here's how you could structure "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.3, "tree_w": 27, "tree_size": 128, "t0": 1.3814, "t1": 0.63, "tft": 1.9337, "input_0": 348, "input_1": 129, "min_CLP": -5.44, "draft_iters": 12.3, "mem_use": 41.53, "gen_rate": 4.9, "speed": 2.42, "text": "\"I'm sorry to hear that, but I'm"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 24.0, "tree_w": 12, "tree_size": 128, "t0": 2.485, "t1": 0.63, "tft": 2.1001, "input_0": 481, "input_1": 129, "min_CLP": -5.06, "draft_iters": 25.0, "mem_use": 41.41, "gen_rate": 16.5, "speed": 5.3, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.0, "tree_w": 21, "tree_size": 128, "t0": 1.64, "t1": 0.644, "tft": 3.0711, "input_0": 377, "input_1": 129, "min_CLP": -5.24, "draft_iters": 15.0, "mem_use": 43.03, "gen_rate": 6.4, "speed": 2.8, "text": "\"While it's rare for a single pe"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.41, "t1": 0.648, "tft": 2.2699, "input_0": 367, "input_1": 129, "min_CLP": -5.17, "draft_iters": 12.2, "mem_use": 42.52, "gen_rate": 6.4, "speed": 3.11, "text": "Freeman Dyson has been known for"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 17.8, "tree_w": 22, "tree_size": 128, "t0": 1.792, "t1": 0.632, "tft": 1.3434, "input_0": 328, "input_1": 129, "min_CLP": -5.68, "draft_iters": 18.6, "mem_use": 41.37, "gen_rate": 4.4, "speed": 1.81, "text": "Yes, I can write code. What type"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 17.5, "tree_w": 19, "tree_size": 128, "t0": 1.9383, "t1": 0.6433, "tft": 2.8283, "input_0": 413, "input_1": 129, "min_CLP": -5.51, "draft_iters": 18.5, "mem_use": 42.11, "gen_rate": 6.0, "speed": 2.32, "text": "You\\'re welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.2, "tree_w": 21, "tree_size": 128, "t0": 1.9825, "t1": 0.64, "tft": 4.0677, "input_0": 373, "input_1": 129, "min_CLP": -5.26, "draft_iters": 20.0, "mem_use": 42.71, "gen_rate": 8.0, "speed": 3.05, "text": "Certainly! Here are the complete"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 23.3, "tree_w": 20, "tree_size": 128, "t0": 2.4667, "t1": 0.63, "tft": 2.366, "input_0": 500, "input_1": 129, "min_CLP": -5.37, "draft_iters": 24.3, "mem_use": 41.73, "gen_rate": 12.0, "speed": 3.88, "text": "1.    Work pressure and job inse"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 23, "tree_size": 128, "t0": 1.3925, "t1": 0.6275, "tft": 1.6023, "input_0": 324, "input_1": 129, "min_CLP": -5.43, "draft_iters": 13.2, "mem_use": 41.4, "gen_rate": 8.8, "speed": 4.33, "text": "The self-attention mechanism, al"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 16.0, "tree_w": 29, "tree_size": 128, "t0": 1.6817, "t1": 0.635, "tft": 2.2097, "input_0": 335, "input_1": 129, "min_CLP": -5.47, "draft_iters": 16.8, "mem_use": 41.96, "gen_rate": 5.8, "speed": 2.52, "text": "It is not possible to make a com"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 31, "tree_h": 13.3, "tree_w": 24, "tree_size": 128, "t0": 1.4967, "t1": 0.645, "tft": 2.5549, "input_0": 322, "input_1": 129, "min_CLP": -5.49, "draft_iters": 14.3, "mem_use": 42.4, "gen_rate": 5.2, "speed": 2.42, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.8, "tree_w": 30, "tree_size": 128, "t0": 1.352, "t1": 0.64, "tft": 2.5933, "input_0": 380, "input_1": 129, "min_CLP": -5.59, "draft_iters": 10.8, "mem_use": 42.07, "gen_rate": 6.6, "speed": 3.32, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 26.3, "tree_w": 15, "tree_size": 128, "t0": 2.5167, "t1": 0.6533, "tft": 5.1088, "input_0": 461, "input_1": 129, "min_CLP": -5.07, "draft_iters": 26.7, "mem_use": 44.21, "gen_rate": 14.7, "speed": 4.62, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 24, "tree_size": 128, "t0": 1.35, "t1": 0.664, "tft": 4.5153, "input_0": 336, "input_1": 129, "min_CLP": -5.42, "draft_iters": 12.2, "mem_use": 45.76, "gen_rate": 6.4, "speed": 3.17, "text": "Here are some recommendations fo"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 23, "tree_size": 128, "t0": 1.468, "t1": 0.65, "tft": 2.5662, "input_0": 376, "input_1": 129, "min_CLP": -5.21, "draft_iters": 12.8, "mem_use": 42.78, "gen_rate": 6.8, "speed": 3.21, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 3.07, "t1": 0.65, "tft": 4.1182, "input_0": 573, "input_1": 129, "min_CLP": -4.82, "draft_iters": 32.0, "mem_use": 43.21, "gen_rate": 18.5, "speed": 4.98, "text": "Sure, here are the three most im"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.7, "tree_w": 19, "tree_size": 128, "t0": 1.86, "t1": 0.63, "tft": 1.5154, "input_0": 359, "input_1": 129, "min_CLP": -5.27, "draft_iters": 18.7, "mem_use": 41.4, "gen_rate": 11.7, "speed": 4.67, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.6, "tree_w": 30, "tree_size": 128, "t0": 1.18, "t1": 0.652, "tft": 4.1744, "input_0": 293, "input_1": 129, "min_CLP": -5.39, "draft_iters": 10.6, "mem_use": 42.74, "gen_rate": 7.4, "speed": 4.04, "text": "Black Friday is the day after Th"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.8, "tree_w": 27, "tree_size": 128, "t0": 1.6, "t1": 0.64, "tft": 1.7074, "input_0": 375, "input_1": 129, "min_CLP": -5.54, "draft_iters": 14.8, "mem_use": 41.58, "gen_rate": 6.4, "speed": 2.86, "text": "\"Here's a story about Green Arro"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.8, "tree_w": 21, "tree_size": 128, "t0": 1.4475, "t1": 0.6325, "tft": 2.9522, "input_0": 358, "input_1": 129, "min_CLP": -5.23, "draft_iters": 12.8, "mem_use": 41.45, "gen_rate": 9.8, "speed": 4.68, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.2, "tree_w": 20, "tree_size": 128, "t0": 1.5975, "t1": 0.63, "tft": 1.6906, "input_0": 348, "input_1": 129, "min_CLP": -5.29, "draft_iters": 15.2, "mem_use": 41.44, "gen_rate": 8.8, "speed": 3.93, "text": "In Minecraft, there are several "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.8, "tree_w": 26, "tree_size": 128, "t0": 1.292, "t1": 0.628, "tft": 1.5852, "input_0": 322, "input_1": 129, "min_CLP": -5.53, "draft_iters": 11.8, "mem_use": 41.39, "gen_rate": 7.6, "speed": 3.96, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 21.0, "tree_w": 13, "tree_size": 128, "t0": 2.09, "t1": 0.64, "tft": 3.4621, "input_0": 425, "input_1": 129, "min_CLP": -4.93, "draft_iters": 22.0, "mem_use": 42.66, "gen_rate": 18.0, "speed": 6.59, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.7, "tree_w": 18, "tree_size": 128, "t0": 2.0167, "t1": 0.6333, "tft": 3.1356, "input_0": 475, "input_1": 129, "min_CLP": -5.28, "draft_iters": 17.7, "mem_use": 41.79, "gen_rate": 11.3, "speed": 4.28, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 21, "tree_size": 128, "t0": 1.74, "t1": 0.6625, "tft": 5.3239, "input_0": 429, "input_1": 129, "min_CLP": -5.2, "draft_iters": 16.0, "mem_use": 46.86, "gen_rate": 8.0, "speed": 3.33, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.6, "tree_w": 24, "tree_size": 128, "t0": 1.464, "t1": 0.636, "tft": 2.1379, "input_0": 371, "input_1": 129, "min_CLP": -5.34, "draft_iters": 12.6, "mem_use": 41.92, "gen_rate": 7.8, "speed": 3.72, "text": "Large language models (LLMs) req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.4, "tree_w": 28, "tree_size": 128, "t0": 1.1543, "t1": 0.6314, "tft": 1.7967, "input_0": 280, "input_1": 129, "min_CLP": -5.69, "draft_iters": 10.4, "mem_use": 41.48, "gen_rate": 4.7, "speed": 2.64, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 54, "tree_h": 16.8, "tree_w": 25, "tree_size": 128, "t0": 1.7683, "t1": 0.6333, "tft": 1.8524, "input_0": 356, "input_1": 129, "min_CLP": -5.49, "draft_iters": 17.7, "mem_use": 41.7, "gen_rate": 9.0, "speed": 3.75, "text": "\"I'm sorry for your loss. Here's"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 20, "tree_size": 128, "t0": 1.675, "t1": 0.65, "tft": 2.6654, "input_0": 375, "input_1": 129, "min_CLP": -5.12, "draft_iters": 15.8, "mem_use": 43.21, "gen_rate": 8.2, "speed": 3.55, "text": "I hope this helps you get starte"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 25, "tree_size": 128, "t0": 1.33, "t1": 0.628, "tft": 2.2898, "input_0": 315, "input_1": 129, "min_CLP": -5.49, "draft_iters": 12.8, "mem_use": 41.56, "gen_rate": 6.4, "speed": 3.27, "text": "\"Yes, I am an assistant, but I d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 25, "tree_size": 128, "t0": 2.86, "t1": 0.63, "tft": 1.6723, "input_0": 424, "input_1": 129, "min_CLP": -5.61, "draft_iters": 32.0, "mem_use": 41.54, "gen_rate": 33.0, "speed": 9.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.7, "tree_w": 31, "tree_size": 128, "t0": 1.2571, "t1": 0.6314, "tft": 1.5639, "input_0": 280, "input_1": 129, "min_CLP": -5.68, "draft_iters": 11.7, "mem_use": 41.37, "gen_rate": 4.7, "speed": 2.49, "text": "[META: {\"color\": \"red\"}]\\n[OUT] "}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.0, "tree_w": 44, "tree_size": 128, "t0": 1.0917, "t1": 0.6467, "tft": 3.2082, "input_0": 278, "input_1": 129, "min_CLP": -6.19, "draft_iters": 10.0, "mem_use": 43.63, "gen_rate": 5.3, "speed": 3.07, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 2.83, "t1": 0.63, "tft": 2.2552, "input_0": 433, "input_1": 129, "min_CLP": -6.84, "draft_iters": 32.0, "mem_use": 41.46, "gen_rate": 33.0, "speed": 9.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 21, "tree_size": 128, "t0": 1.47, "t1": 0.6375, "tft": 2.6298, "input_0": 353, "input_1": 129, "min_CLP": -5.33, "draft_iters": 13.5, "mem_use": 42.0, "gen_rate": 8.8, "speed": 4.15, "text": "\"No, the ATF's regulation of fir"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.0, "tree_w": 20, "tree_size": 128, "t0": 1.7567, "t1": 0.6367, "tft": 2.1221, "input_0": 372, "input_1": 129, "min_CLP": -5.17, "draft_iters": 17.0, "mem_use": 41.46, "gen_rate": 10.7, "speed": 4.46, "text": "Yes, there are formulas that can"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 15.4, "tree_w": 26, "tree_size": 128, "t0": 1.614, "t1": 0.636, "tft": 2.9273, "input_0": 324, "input_1": 129, "min_CLP": -5.29, "draft_iters": 16.2, "mem_use": 41.89, "gen_rate": 4.4, "speed": 1.96, "text": "\"Hello! I'm happy to help with b"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 13.9, "tree_w": 25, "tree_size": 128, "t0": 1.5357, "t1": 0.6343, "tft": 3.0965, "input_0": 331, "input_1": 129, "min_CLP": -5.46, "draft_iters": 14.9, "mem_use": 41.58, "gen_rate": 6.0, "speed": 2.77, "text": "Sydney was the capital of New So"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 18, "tree_size": 128, "t0": 2.93, "t1": 0.63, "tft": 2.278, "input_0": 418, "input_1": 129, "min_CLP": -5.81, "draft_iters": 32.0, "mem_use": 41.75, "gen_rate": 33.0, "speed": 9.27, "text": "[INST] yes [\\\\INST]\\n[INST] yes "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 25, "tree_size": 128, "t0": 1.25, "t1": 0.64, "tft": 4.9243, "input_0": 317, "input_1": 129, "min_CLP": -5.4, "draft_iters": 11.6, "mem_use": 43.99, "gen_rate": 6.6, "speed": 3.49, "text": "Certainly! Here is a possible me"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.3, "tree_w": 38, "tree_size": 128, "t0": 1.2843, "t1": 0.6343, "tft": 2.1641, "input_0": 361, "input_1": 129, "min_CLP": -5.77, "draft_iters": 10.3, "mem_use": 41.57, "gen_rate": 5.6, "speed": 2.91, "text": "Answer: Yes, this is a real even"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 15.8, "tree_w": 23, "tree_size": 128, "t0": 1.6833, "t1": 0.6483, "tft": 3.3528, "input_0": 342, "input_1": 129, "min_CLP": -5.55, "draft_iters": 16.7, "mem_use": 42.85, "gen_rate": 5.8, "speed": 2.5, "text": "Yes, an example of a vector that"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.0, "tree_w": 26, "tree_size": 128, "t0": 1.4657, "t1": 0.6243, "tft": 1.6755, "input_0": 366, "input_1": 129, "min_CLP": -5.52, "draft_iters": 13.0, "mem_use": 41.43, "gen_rate": 4.9, "speed": 2.32, "text": "1. Symmetric distributions may n"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 38, "tree_size": 128, "t0": 0.9637, "t1": 0.6312, "tft": 1.8795, "input_0": 240, "input_1": 129, "min_CLP": -6.39, "draft_iters": 8.4, "mem_use": 41.48, "gen_rate": 4.4, "speed": 2.74, "text": "\"My name is Teldryn Sero, and I'"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 15.0, "tree_w": 20, "tree_size": 128, "t0": 1.7283, "t1": 0.6333, "tft": 2.0122, "input_0": 418, "input_1": 129, "min_CLP": -5.7, "draft_iters": 16.0, "mem_use": 41.43, "gen_rate": 5.8, "speed": 2.47, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 25, "tree_size": 128, "t0": 1.256, "t1": 0.636, "tft": 2.3242, "input_0": 305, "input_1": 129, "min_CLP": -5.58, "draft_iters": 11.4, "mem_use": 42.0, "gen_rate": 7.4, "speed": 3.91, "text": "Sum of squares error is the sum "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 8.2, "tree_w": 38, "tree_size": 128, "t0": 1.06, "t1": 0.6425, "tft": 2.4332, "input_0": 274, "input_1": 129, "min_CLP": -5.69, "draft_iters": 9.2, "mem_use": 42.3, "gen_rate": 4.5, "speed": 2.64, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.4, "tree_w": 25, "tree_size": 128, "t0": 1.318, "t1": 0.638, "tft": 2.7058, "input_0": 309, "input_1": 129, "min_CLP": -5.46, "draft_iters": 12.4, "mem_use": 42.08, "gen_rate": 8.0, "speed": 4.09, "text": "In the lower 48 states, the best"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 15.7, "tree_w": 30, "tree_size": 128, "t0": 1.7083, "t1": 0.6283, "tft": 2.8301, "input_0": 347, "input_1": 129, "min_CLP": -5.85, "draft_iters": 16.5, "mem_use": 41.43, "gen_rate": 6.3, "speed": 2.71, "text": "1. Dying from laughing too hard\\"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.0, "tree_w": 17, "tree_size": 128, "t0": 1.734, "t1": 0.638, "tft": 3.5473, "input_0": 363, "input_1": 129, "min_CLP": -5.44, "draft_iters": 17.0, "mem_use": 41.98, "gen_rate": 6.8, "speed": 2.87, "text": "Two dropped eggs + one extra egg"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.3, "tree_w": 23, "tree_size": 128, "t0": 1.66, "t1": 0.64, "tft": 3.7281, "input_0": 369, "input_1": 129, "min_CLP": -5.41, "draft_iters": 15.3, "mem_use": 41.85, "gen_rate": 12.0, "speed": 5.22, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.2, "tree_w": 21, "tree_size": 128, "t0": 1.58, "t1": 0.66, "tft": 4.4233, "input_0": 381, "input_1": 129, "min_CLP": -5.28, "draft_iters": 14.2, "mem_use": 44.94, "gen_rate": 7.6, "speed": 3.4, "text": "1. Establish clear objectives an"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 21.7, "tree_w": 15, "tree_size": 128, "t0": 2.31, "t1": 0.65, "tft": 3.5177, "input_0": 465, "input_1": 129, "min_CLP": -4.96, "draft_iters": 22.7, "mem_use": 43.63, "gen_rate": 10.7, "speed": 3.61, "text": "Building your own PC can be a re"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 20, "tree_size": 128, "t0": 1.5375, "t1": 0.63, "tft": 1.8472, "input_0": 359, "input_1": 129, "min_CLP": -5.63, "draft_iters": 14.2, "mem_use": 41.38, "gen_rate": 8.5, "speed": 3.91, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.3, "tree_w": 21, "tree_size": 128, "t0": 1.43, "t1": 0.64, "tft": 1.751, "input_0": 306, "input_1": 129, "min_CLP": -5.68, "draft_iters": 14.3, "mem_use": 41.63, "gen_rate": 11.0, "speed": 5.32, "text": "Here is a list of 5 words where "}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 25, "tree_size": 128, "t0": 1.3, "t1": 0.692, "tft": 6.5776, "input_0": 357, "input_1": 129, "min_CLP": -5.38, "draft_iters": 11.0, "mem_use": 48.46, "gen_rate": 7.4, "speed": 3.71, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.0, "tree_w": 22, "tree_size": 128, "t0": 1.5875, "t1": 0.6325, "tft": 3.0194, "input_0": 391, "input_1": 129, "min_CLP": -5.25, "draft_iters": 15.0, "mem_use": 41.81, "gen_rate": 9.8, "speed": 4.39, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 25.0, "tree_w": 13, "tree_size": 128, "t0": 2.63, "t1": 0.63, "tft": 2.1388, "input_0": 565, "input_1": 129, "min_CLP": -5.64, "draft_iters": 25.5, "mem_use": 41.52, "gen_rate": 21.5, "speed": 6.6, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 31, "tree_size": 128, "t0": 1.3283, "t1": 0.6283, "tft": 2.2615, "input_0": 322, "input_1": 129, "min_CLP": -5.49, "draft_iters": 11.3, "mem_use": 41.52, "gen_rate": 5.7, "speed": 2.89, "text": "In Wyoming, public nudity is gen"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.6, "tree_w": 26, "tree_size": 128, "t0": 1.296, "t1": 0.65, "tft": 3.7686, "input_0": 370, "input_1": 129, "min_CLP": -5.46, "draft_iters": 10.6, "mem_use": 44.07, "gen_rate": 7.8, "speed": 4.01, "text": "I am designed to provide accurat"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 21.5, "tree_w": 13, "tree_size": 128, "t0": 2.365, "t1": 0.64, "tft": 2.8151, "input_0": 486, "input_1": 129, "min_CLP": -5.14, "draft_iters": 22.5, "mem_use": 41.93, "gen_rate": 16.5, "speed": 5.49, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.2, "tree_w": 30, "tree_size": 128, "t0": 1.542, "t1": 0.642, "tft": 2.6833, "input_0": 253, "input_1": 129, "min_CLP": -5.7, "draft_iters": 16.2, "mem_use": 42.12, "gen_rate": 7.4, "speed": 3.39, "text": "Okay, I will try to find the ans"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.8, "tree_w": 19, "tree_size": 128, "t0": 1.9525, "t1": 0.635, "tft": 1.9105, "input_0": 398, "input_1": 129, "min_CLP": -5.39, "draft_iters": 18.8, "mem_use": 41.72, "gen_rate": 8.0, "speed": 3.09, "text": "The stable diffusion algorithm i"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.1, "tree_w": 31, "tree_size": 128, "t0": 1.2386, "t1": 0.63, "tft": 3.7226, "input_0": 284, "input_1": 129, "min_CLP": -5.84, "draft_iters": 12.1, "mem_use": 41.96, "gen_rate": 4.7, "speed": 2.52, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.0, "tree_w": 22, "tree_size": 128, "t0": 1.5267, "t1": 0.6367, "tft": 1.9133, "input_0": 337, "input_1": 129, "min_CLP": -5.19, "draft_iters": 15.0, "mem_use": 41.75, "gen_rate": 6.5, "speed": 3.01, "text": "\"Schr\u00f6dinger's cat is a thought "}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.7, "tree_w": 28, "tree_size": 128, "t0": 1.3367, "t1": 0.6467, "tft": 3.9829, "input_0": 291, "input_1": 129, "min_CLP": -5.65, "draft_iters": 12.7, "mem_use": 43.75, "gen_rate": 6.0, "speed": 3.03, "text": "Setting up your kitchen for the "}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 14, "tree_size": 128, "t0": 1.6133, "t1": 0.6333, "tft": 2.2402, "input_0": 397, "input_1": 129, "min_CLP": -5.58, "draft_iters": 14.7, "mem_use": 41.51, "gen_rate": 10.7, "speed": 4.75, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.5, "tree_w": 25, "tree_size": 128, "t0": 1.6375, "t1": 0.63, "tft": 2.4611, "input_0": 351, "input_1": 129, "min_CLP": -5.7, "draft_iters": 15.5, "mem_use": 41.53, "gen_rate": 8.2, "speed": 3.64, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.4, "tree_w": 32, "tree_size": 128, "t0": 1.1971, "t1": 0.6271, "tft": 2.2646, "input_0": 316, "input_1": 129, "min_CLP": -5.7, "draft_iters": 10.4, "mem_use": 41.5, "gen_rate": 4.7, "speed": 2.59, "text": "F-centers, short for \"Farbezentr"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.8, "tree_w": 28, "tree_size": 128, "t0": 1.2633, "t1": 0.6633, "tft": 4.2245, "input_0": 291, "input_1": 129, "min_CLP": -5.67, "draft_iters": 11.8, "mem_use": 46.05, "gen_rate": 6.2, "speed": 3.2, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.7, "tree_w": 24, "tree_size": 128, "t0": 1.73, "t1": 0.6467, "tft": 2.9293, "input_0": 329, "input_1": 129, "min_CLP": -5.21, "draft_iters": 17.7, "mem_use": 43.18, "gen_rate": 11.3, "speed": 4.76, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 14.0, "tree_w": 18, "tree_size": 128, "t0": 1.595, "t1": 0.635, "tft": 2.2978, "input_0": 369, "input_1": 129, "min_CLP": -5.08, "draft_iters": 15.0, "mem_use": 41.93, "gen_rate": 10.5, "speed": 4.71, "text": "\"Sure! Here's a list of pros and"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 27, "tree_size": 128, "t0": 1.476, "t1": 0.646, "tft": 3.7542, "input_0": 414, "input_1": 129, "min_CLP": -5.39, "draft_iters": 12.0, "mem_use": 43.86, "gen_rate": 6.8, "speed": 3.2, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 26, "tree_size": 128, "t0": 1.38, "t1": 0.65, "tft": 3.4483, "input_0": 324, "input_1": 129, "min_CLP": -5.44, "draft_iters": 13.0, "mem_use": 43.82, "gen_rate": 7.0, "speed": 3.45, "text": "Die Zementproduktion erzeugt in "}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 1.43, "t1": 0.6443, "tft": 2.8132, "input_0": 349, "input_1": 129, "min_CLP": -5.39, "draft_iters": 13.0, "mem_use": 43.18, "gen_rate": 5.0, "speed": 2.41, "text": "\"I'm sorry, but I cannot provide"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 40, "tree_size": 128, "t0": 0.81, "t1": 0.64, "tft": 2.1688, "input_0": 218, "input_1": 129, "min_CLP": -5.95, "draft_iters": 7.2, "mem_use": 42.17, "gen_rate": 5.5, "speed": 3.8, "text": "I would first try to post the lo"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.4, "tree_w": 23, "tree_size": 128, "t0": 1.782, "t1": 0.628, "tft": 2.0969, "input_0": 434, "input_1": 129, "min_CLP": -5.45, "draft_iters": 16.2, "mem_use": 41.76, "gen_rate": 6.6, "speed": 2.74, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u5e7e\u7bc7\u8ad6\u6587\uff0c\u9019\u4e9b\u8ad6\u6587\u6df1\u5165\u63a2\u8a0e\u4e86\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\u7684\u539f\u7406\u3001\u61c9"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 27.0, "tree_w": 12, "tree_size": 128, "t0": 2.83, "t1": 0.63, "tft": 2.3208, "input_0": 555, "input_1": 129, "min_CLP": -4.54, "draft_iters": 28.0, "mem_use": 41.57, "gen_rate": 18.0, "speed": 5.2, "text": "\"Sure! Here's a JavaScript funct"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 1.558, "t1": 0.648, "tft": 2.8546, "input_0": 382, "input_1": 129, "min_CLP": -5.25, "draft_iters": 13.8, "mem_use": 42.85, "gen_rate": 6.4, "speed": 2.9, "text": "The reason why public nudity is "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 30, "tree_size": 128, "t0": 1.145, "t1": 0.64, "tft": 3.5007, "input_0": 309, "input_1": 129, "min_CLP": -5.56, "draft_iters": 9.7, "mem_use": 41.96, "gen_rate": 5.5, "speed": 3.09, "text": "\"I'm glad you liked it! As for d"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.3, "tree_w": 23, "tree_size": 128, "t0": 1.5471, "t1": 0.6486, "tft": 4.1111, "input_0": 380, "input_1": 129, "min_CLP": -5.29, "draft_iters": 13.3, "mem_use": 42.84, "gen_rate": 5.3, "speed": 2.41, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 13.8, "tree_w": 30, "tree_size": 128, "t0": 1.5137, "t1": 0.645, "tft": 3.9811, "input_0": 323, "input_1": 129, "min_CLP": -5.63, "draft_iters": 14.8, "mem_use": 42.22, "gen_rate": 5.2, "speed": 2.43, "text": "Okay, considering the 24th of De"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.8, "tree_w": 28, "tree_size": 128, "t0": 1.28, "t1": 0.636, "tft": 2.2833, "input_0": 341, "input_1": 129, "min_CLP": -5.74, "draft_iters": 10.8, "mem_use": 41.49, "gen_rate": 7.8, "speed": 4.07, "text": "Sure! Here is a list of nickname"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 16.7, "tree_w": 19, "tree_size": 128, "t0": 1.9733, "t1": 0.6367, "tft": 3.2831, "input_0": 509, "input_1": 129, "min_CLP": -5.43, "draft_iters": 17.7, "mem_use": 41.9, "gen_rate": 13.3, "speed": 5.1, "text": "\"Yes, the Balfour Declaration pl"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 31.5, "tree_w": 10, "tree_size": 128, "t0": 2.92, "t1": 0.65, "tft": 3.8949, "input_0": 455, "input_1": 129, "min_CLP": -4.8, "draft_iters": 32.0, "mem_use": 42.66, "gen_rate": 16.5, "speed": 4.62, "text": "\"Felices:\\n\\n1. \u00ab(I Can't Get No"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 22.0, "tree_w": 15, "tree_size": 128, "t0": 2.3067, "t1": 0.6367, "tft": 2.1971, "input_0": 486, "input_1": 129, "min_CLP": -5.05, "draft_iters": 23.0, "mem_use": 41.59, "gen_rate": 11.0, "speed": 3.74, "text": "Here is a table of the average t"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 2.92, "t1": 0.63, "tft": 2.0965, "input_0": 443, "input_1": 129, "min_CLP": -4.85, "draft_iters": 32.0, "mem_use": 41.99, "gen_rate": 33.0, "speed": 9.3, "text": "\"I apologize for the mistake. He"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 10.0, "tree_w": 40, "tree_size": 128, "t0": 1.1589, "t1": 0.6456, "tft": 3.0829, "input_0": 262, "input_1": 129, "min_CLP": -5.9, "draft_iters": 11.0, "mem_use": 42.35, "gen_rate": 3.6, "speed": 1.97, "text": "Absolutely! How about, \"Tick-toc"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.3, "tree_w": 22, "tree_size": 128, "t0": 1.6433, "t1": 0.65, "tft": 3.4637, "input_0": 440, "input_1": 129, "min_CLP": -5.2, "draft_iters": 14.3, "mem_use": 43.15, "gen_rate": 11.3, "speed": 4.95, "text": "\"Sure! Here's a step-by-step gui"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 25, "tree_size": 128, "t0": 1.64, "t1": 0.635, "tft": 1.973, "input_0": 378, "input_1": 129, "min_CLP": -5.38, "draft_iters": 14.8, "mem_use": 41.6, "gen_rate": 8.5, "speed": 3.73, "text": "Frank-Walter Steinmeier is a Ger"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.3, "tree_w": 28, "tree_size": 128, "t0": 1.3571, "t1": 0.6314, "tft": 3.6295, "input_0": 281, "input_1": 129, "min_CLP": -5.47, "draft_iters": 13.3, "mem_use": 41.52, "gen_rate": 4.9, "speed": 2.44, "text": "In this case, the question is as"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 13.0, "tree_w": 20, "tree_size": 128, "t0": 1.53, "t1": 0.6643, "tft": 5.5025, "input_0": 359, "input_1": 129, "min_CLP": -5.3, "draft_iters": 14.0, "mem_use": 45.64, "gen_rate": 5.1, "speed": 2.34, "text": "1. Discovery: Find a market need"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 25, "tree_size": 128, "t0": 1.348, "t1": 0.632, "tft": 1.4357, "input_0": 355, "input_1": 129, "min_CLP": -6.05, "draft_iters": 11.6, "mem_use": 41.42, "gen_rate": 7.4, "speed": 3.74, "text": "The many-worlds interpretation ("}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 128, "t0": 2.94, "t1": 0.64, "tft": 1.7955, "input_0": 510, "input_1": 129, "min_CLP": -6.1, "draft_iters": 32.0, "mem_use": 41.38, "gen_rate": 33.0, "speed": 9.23, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 23.3, "tree_w": 23, "tree_size": 128, "t0": 2.3267, "t1": 0.6633, "tft": 4.763, "input_0": 378, "input_1": 129, "min_CLP": -5.61, "draft_iters": 24.0, "mem_use": 45.64, "gen_rate": 13.7, "speed": 4.57, "text": "User: Hey!\\n\\nBot: Hi there! How"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.0, "tree_w": 24, "tree_size": 128, "t0": 1.5533, "t1": 0.6433, "tft": 4.7015, "input_0": 373, "input_1": 129, "min_CLP": -5.52, "draft_iters": 14.0, "mem_use": 43.47, "gen_rate": 11.0, "speed": 5.01, "text": "\"\u2022 Keep up the good work. Once y"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 25, "tree_size": 128, "t0": 1.336, "t1": 0.648, "tft": 2.8314, "input_0": 326, "input_1": 129, "min_CLP": -5.55, "draft_iters": 11.6, "mem_use": 42.69, "gen_rate": 6.6, "speed": 3.33, "text": "You are correct that the player "}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 28, "tree_size": 128, "t0": 1.2267, "t1": 0.6367, "tft": 2.3355, "input_0": 298, "input_1": 129, "min_CLP": -5.39, "draft_iters": 11.5, "mem_use": 41.57, "gen_rate": 5.5, "speed": 2.96, "text": "Sure, here are some of the impor"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 21, "tree_size": 128, "t0": 1.675, "t1": 0.635, "tft": 2.0567, "input_0": 404, "input_1": 129, "min_CLP": -5.27, "draft_iters": 14.5, "mem_use": 41.58, "gen_rate": 8.2, "speed": 3.57, "text": "In the context of the game \"Into"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.0, "tree_w": 18, "tree_size": 128, "t0": 1.785, "t1": 0.6475, "tft": 2.9269, "input_0": 406, "input_1": 129, "min_CLP": -5.16, "draft_iters": 16.0, "mem_use": 42.41, "gen_rate": 8.5, "speed": 3.5, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 3.245, "t1": 0.64, "tft": 2.6144, "input_0": 644, "input_1": 129, "min_CLP": -4.37, "draft_iters": 32.0, "mem_use": 42.94, "gen_rate": 21.0, "speed": 5.41, "text": "Here is a simpler script that ac"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.7, "tree_w": 26, "tree_size": 128, "t0": 1.55, "t1": 0.6433, "tft": 2.65, "input_0": 308, "input_1": 129, "min_CLP": -5.59, "draft_iters": 14.7, "mem_use": 42.36, "gen_rate": 5.5, "speed": 2.51, "text": "Hi! How can I assist you today?\\"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 34, "tree_size": 128, "t0": 1.0383, "t1": 0.6467, "tft": 4.0415, "input_0": 280, "input_1": 129, "min_CLP": -5.71, "draft_iters": 8.7, "mem_use": 42.47, "gen_rate": 5.3, "speed": 3.17, "text": "\"In the depths of your beautiful"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.3, "tree_w": 23, "tree_size": 128, "t0": 1.4933, "t1": 0.635, "tft": 2.1433, "input_0": 372, "input_1": 129, "min_CLP": -5.42, "draft_iters": 13.3, "mem_use": 41.86, "gen_rate": 6.2, "speed": 2.9, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 24, "tree_size": 128, "t0": 1.315, "t1": 0.63, "tft": 2.8816, "input_0": 341, "input_1": 129, "min_CLP": -5.27, "draft_iters": 12.0, "mem_use": 41.83, "gen_rate": 5.8, "speed": 3.0, "text": "\"Tenants can be considered super"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.8, "tree_w": 24, "tree_size": 128, "t0": 1.422, "t1": 0.64, "tft": 2.9732, "input_0": 322, "input_1": 129, "min_CLP": -5.22, "draft_iters": 13.8, "mem_use": 43.19, "gen_rate": 6.4, "speed": 3.1, "text": "\"You're welcome! If the command "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 25, "tree_size": 128, "t0": 1.354, "t1": 0.646, "tft": 3.0923, "input_0": 334, "input_1": 129, "min_CLP": -5.36, "draft_iters": 12.2, "mem_use": 43.11, "gen_rate": 6.4, "speed": 3.2, "text": "Yes, Open Assistant is pre-train"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 18.9, "tree_w": 18, "tree_size": 128, "t0": 2.0325, "t1": 0.6475, "tft": 3.6608, "input_0": 410, "input_1": 129, "min_CLP": -5.08, "draft_iters": 19.8, "mem_use": 44.55, "gen_rate": 4.9, "speed": 1.82, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 2.82, "t1": 0.63, "tft": 1.6504, "input_0": 422, "input_1": 129, "min_CLP": -6.94, "draft_iters": 32.0, "mem_use": 41.38, "gen_rate": 33.0, "speed": 9.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.3, "tree_w": 36, "tree_size": 128, "t0": 1.0571, "t1": 0.64, "tft": 2.4864, "input_0": 268, "input_1": 129, "min_CLP": -5.77, "draft_iters": 9.3, "mem_use": 42.3, "gen_rate": 5.0, "speed": 2.95, "text": "PostCSS is a tool used to proces"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 18.0, "tree_w": 16, "tree_size": 128, "t0": 1.84, "t1": 0.64, "tft": 3.8841, "input_0": 380, "input_1": 129, "min_CLP": -5.39, "draft_iters": 19.0, "mem_use": 44.21, "gen_rate": 8.0, "speed": 3.22, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.4, "tree_w": 27, "tree_size": 128, "t0": 1.3243, "t1": 0.6343, "tft": 2.7483, "input_0": 315, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.4, "mem_use": 41.89, "gen_rate": 5.0, "speed": 2.55, "text": "- Introduction: Discuss the conc"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.8, "tree_w": 26, "tree_size": 128, "t0": 1.484, "t1": 0.65, "tft": 4.2593, "input_0": 349, "input_1": 129, "min_CLP": -5.32, "draft_iters": 13.8, "mem_use": 42.75, "gen_rate": 7.0, "speed": 3.28, "text": "I apologize for the confusion. A"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 128, "max_branch_width": 32, "gen_rate": 9.64, "gen_rate_micro": 7.45, "gen_speed": 3.958, "gen_speed_micro": 3.53, "t0": 1.6334, "t1": 0.6394, "input_0": 359.5, "input_1": 129.0, "tree_size": 128.0, "tree_w": 24.9, "tree_h": 14.7, "prompt_len": 298.0, "min_CLP": -5.52, "mem_use": 50.84, "exp_time": 7010.89}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 11.1, "tree_w": 62, "tree_size": 256, "t0": 1.7014, "t1": 0.8671, "tft": 2.5595, "input_0": 723, "input_1": 257, "min_CLP": -6.46, "draft_iters": 12.3, "mem_use": 42.13, "gen_rate": 5.1, "speed": 2.0, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 17.3, "tree_w": 47, "tree_size": 256, "t0": 2.1833, "t1": 0.885, "tft": 4.3478, "input_0": 728, "input_1": 257, "min_CLP": -6.04, "draft_iters": 18.5, "mem_use": 43.71, "gen_rate": 6.3, "speed": 2.06, "text": "I apologize for the error in my "}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.6, "tree_w": 51, "tree_size": 256, "t0": 1.78, "t1": 0.8886, "tft": 5.203, "input_0": 683, "input_1": 257, "min_CLP": -6.12, "draft_iters": 13.7, "mem_use": 44.58, "gen_rate": 5.3, "speed": 1.98, "text": "1. Minecraft: \\n- The recommende"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 22.0, "tree_w": 23, "tree_size": 256, "t0": 3.1233, "t1": 0.87, "tft": 2.4456, "input_0": 1055, "input_1": 257, "min_CLP": -5.51, "draft_iters": 24.0, "mem_use": 42.31, "gen_rate": 10.7, "speed": 2.67, "text": "\"Sure! Here's a Python script th"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.3, "tree_w": 38, "tree_size": 256, "t0": 2.2167, "t1": 0.87, "tft": 2.1951, "input_0": 892, "input_1": 257, "min_CLP": -5.95, "draft_iters": 16.0, "mem_use": 42.15, "gen_rate": 11.3, "speed": 3.67, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 43, "tree_size": 256, "t0": 1.9875, "t1": 0.8875, "tft": 5.6814, "input_0": 748, "input_1": 257, "min_CLP": -6.05, "draft_iters": 14.2, "mem_use": 44.72, "gen_rate": 8.8, "speed": 3.04, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.7, "tree_w": 29, "tree_size": 256, "t0": 2.48, "t1": 0.8867, "tft": 5.0856, "input_0": 903, "input_1": 257, "min_CLP": -5.77, "draft_iters": 18.7, "mem_use": 45.3, "gen_rate": 11.0, "speed": 3.27, "text": "One option to enhance images is "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.5, "tree_w": 35, "tree_size": 256, "t0": 2.3175, "t1": 0.915, "tft": 5.7516, "input_0": 937, "input_1": 257, "min_CLP": -6.02, "draft_iters": 16.5, "mem_use": 47.47, "gen_rate": 10.0, "speed": 3.09, "text": "To attract the right customers, "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.7, "tree_w": 32, "tree_size": 256, "t0": 2.6567, "t1": 0.89, "tft": 4.8398, "input_0": 941, "input_1": 257, "min_CLP": -5.94, "draft_iters": 20.3, "mem_use": 44.91, "gen_rate": 11.3, "speed": 3.2, "text": "The legal status of marijuana va"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 18.3, "tree_w": 32, "tree_size": 256, "t0": 2.8433, "t1": 0.89, "tft": 4.0164, "input_0": 1098, "input_1": 257, "min_CLP": -5.94, "draft_iters": 20.3, "mem_use": 44.29, "gen_rate": 12.3, "speed": 3.31, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 19, "tree_h": 24.0, "tree_w": 21, "tree_size": 256, "t0": 2.97, "t1": 0.87, "tft": 4.644, "input_0": 940, "input_1": 257, "min_CLP": -6.26, "draft_iters": 25.0, "mem_use": 42.81, "gen_rate": 19.0, "speed": 4.94, "text": "``The first number is A.\\nRead A"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 16.3, "tree_w": 33, "tree_size": 256, "t0": 2.3067, "t1": 0.8833, "tft": 5.1716, "input_0": 861, "input_1": 257, "min_CLP": -5.82, "draft_iters": 17.7, "mem_use": 44.66, "gen_rate": 12.3, "speed": 3.87, "text": "Sure, here\\'s a shorter version:"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 19.0, "tree_w": 32, "tree_size": 256, "t0": 2.775, "t1": 0.8875, "tft": 4.0949, "input_0": 999, "input_1": 257, "min_CLP": -5.72, "draft_iters": 20.5, "mem_use": 43.89, "gen_rate": 10.2, "speed": 2.8, "text": "Sure, here are some examples of "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 12.0, "tree_w": 51, "tree_size": 256, "t0": 1.64, "t1": 0.87, "tft": 2.6296, "input_0": 603, "input_1": 257, "min_CLP": -6.46, "draft_iters": 13.0, "mem_use": 42.13, "gen_rate": 6.0, "speed": 2.39, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.0, "tree_w": 46, "tree_size": 256, "t0": 1.938, "t1": 0.898, "tft": 4.6863, "input_0": 753, "input_1": 257, "min_CLP": -6.09, "draft_iters": 14.2, "mem_use": 45.28, "gen_rate": 6.6, "speed": 2.33, "text": "Spaced repetition and fun activi"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 19.8, "tree_w": 36, "tree_size": 256, "t0": 2.5775, "t1": 0.875, "tft": 4.2952, "input_0": 886, "input_1": 257, "min_CLP": -5.86, "draft_iters": 21.0, "mem_use": 42.47, "gen_rate": 9.0, "speed": 2.61, "text": "\"To stream at 720p 30fps on Twit"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 24.3, "tree_w": 21, "tree_size": 256, "t0": 3.1233, "t1": 0.8667, "tft": 2.9227, "input_0": 1038, "input_1": 257, "min_CLP": -5.54, "draft_iters": 25.0, "mem_use": 42.15, "gen_rate": 18.3, "speed": 4.6, "text": "\"Sure, Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 256, "t0": 3.4, "t1": 0.86, "tft": 2.1864, "input_0": 945, "input_1": 257, "min_CLP": -9.05, "draft_iters": 32.0, "mem_use": 42.13, "gen_rate": 33.0, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.7, "tree_w": 47, "tree_size": 256, "t0": 1.875, "t1": 0.8783, "tft": 4.0472, "input_0": 724, "input_1": 257, "min_CLP": -6.18, "draft_iters": 13.2, "mem_use": 42.66, "gen_rate": 6.2, "speed": 2.24, "text": "D-theanine is the mirror image o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.8, "tree_w": 45, "tree_size": 256, "t0": 2.068, "t1": 0.87, "tft": 2.6222, "input_0": 852, "input_1": 257, "min_CLP": -6.32, "draft_iters": 14.8, "mem_use": 42.14, "gen_rate": 7.0, "speed": 2.38, "text": "The Balfour Declaration is a let"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 26, "tree_h": 10.8, "tree_w": 74, "tree_size": 256, "t0": 1.515, "t1": 0.875, "tft": 4.5298, "input_0": 537, "input_1": 257, "min_CLP": -6.8, "draft_iters": 12.0, "mem_use": 43.03, "gen_rate": 3.2, "speed": 1.36, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 32.0, "tree_w": 30, "tree_size": 256, "t0": 3.26, "t1": 0.87, "tft": 2.0892, "input_0": 797, "input_1": 257, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 42.13, "gen_rate": 22.0, "speed": 5.33, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 16.6, "tree_w": 33, "tree_size": 256, "t0": 2.596, "t1": 0.888, "tft": 4.2995, "input_0": 987, "input_1": 257, "min_CLP": -5.85, "draft_iters": 18.2, "mem_use": 44.5, "gen_rate": 7.6, "speed": 2.18, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.4, "tree_w": 39, "tree_size": 256, "t0": 2.084, "t1": 0.872, "tft": 2.6521, "input_0": 753, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.6, "mem_use": 42.21, "gen_rate": 8.2, "speed": 2.77, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.2, "tree_w": 75, "tree_size": 256, "t0": 1.86, "t1": 0.874, "tft": 3.8899, "input_0": 568, "input_1": 257, "min_CLP": -7.01, "draft_iters": 16.4, "mem_use": 43.21, "gen_rate": 6.4, "speed": 2.34, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 24.5, "tree_w": 36, "tree_size": 256, "t0": 3.04, "t1": 0.87, "tft": 2.4106, "input_0": 917, "input_1": 257, "min_CLP": -7.57, "draft_iters": 25.5, "mem_use": 42.17, "gen_rate": 20.5, "speed": 5.24, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 52, "tree_size": 256, "t0": 1.732, "t1": 0.876, "tft": 3.3696, "input_0": 710, "input_1": 257, "min_CLP": -6.44, "draft_iters": 12.2, "mem_use": 42.84, "gen_rate": 6.8, "speed": 2.61, "text": "Austenite is one of the allotrop"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 20.0, "tree_w": 33, "tree_size": 256, "t0": 2.7833, "t1": 0.8767, "tft": 3.2832, "input_0": 939, "input_1": 257, "min_CLP": -5.98, "draft_iters": 21.0, "mem_use": 42.7, "gen_rate": 7.0, "speed": 1.91, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 69, "tree_size": 256, "t0": 1.3386, "t1": 0.89, "tft": 5.4832, "input_0": 537, "input_1": 257, "min_CLP": -6.58, "draft_iters": 9.7, "mem_use": 44.65, "gen_rate": 4.9, "speed": 2.18, "text": "\"Magic, magic, everywhere we loo"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 37, "tree_size": 256, "t0": 3.18, "t1": 0.88, "tft": 2.4143, "input_0": 654, "input_1": 257, "min_CLP": -7.0, "draft_iters": 32.0, "mem_use": 42.18, "gen_rate": 33.0, "speed": 8.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.7, "tree_w": 34, "tree_size": 256, "t0": 2.44, "t1": 0.8767, "tft": 3.5541, "input_0": 978, "input_1": 257, "min_CLP": -5.91, "draft_iters": 17.3, "mem_use": 42.89, "gen_rate": 11.0, "speed": 3.32, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.0, "tree_w": 58, "tree_size": 256, "t0": 2.0233, "t1": 0.87, "tft": 3.5684, "input_0": 591, "input_1": 257, "min_CLP": -6.59, "draft_iters": 18.3, "mem_use": 43.33, "gen_rate": 13.3, "speed": 4.6, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.6, "tree_w": 62, "tree_size": 256, "t0": 1.5157, "t1": 0.8786, "tft": 2.68, "input_0": 620, "input_1": 257, "min_CLP": -6.39, "draft_iters": 10.9, "mem_use": 42.64, "gen_rate": 4.7, "speed": 1.97, "text": "Oh, my dear followers, I hear yo"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.4, "tree_w": 41, "tree_size": 256, "t0": 2.294, "t1": 0.88, "tft": 5.1973, "input_0": 901, "input_1": 257, "min_CLP": -5.92, "draft_iters": 16.4, "mem_use": 44.31, "gen_rate": 7.4, "speed": 2.33, "text": "Yes, there are several non-dairy"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.0, "tree_w": 37, "tree_size": 256, "t0": 2.2933, "t1": 0.89, "tft": 3.8748, "input_0": 787, "input_1": 257, "min_CLP": -5.94, "draft_iters": 18.3, "mem_use": 44.35, "gen_rate": 11.0, "speed": 3.46, "text": "When choosing an ISP package in "}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 42, "tree_size": 256, "t0": 1.9225, "t1": 0.91, "tft": 6.3374, "input_0": 716, "input_1": 257, "min_CLP": -6.07, "draft_iters": 14.8, "mem_use": 47.06, "gen_rate": 9.0, "speed": 3.18, "text": "Selenium is generally a better c"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.2, "tree_w": 45, "tree_size": 256, "t0": 2.1525, "t1": 0.87, "tft": 3.0505, "input_0": 801, "input_1": 257, "min_CLP": -6.2, "draft_iters": 17.2, "mem_use": 42.17, "gen_rate": 9.0, "speed": 2.98, "text": "Answer: The airspeed velocity of"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 53, "tree_h": 20.0, "tree_w": 57, "tree_size": 256, "t0": 2.33, "t1": 0.8775, "tft": 4.564, "input_0": 659, "input_1": 257, "min_CLP": -6.48, "draft_iters": 20.8, "mem_use": 42.7, "gen_rate": 13.2, "speed": 4.13, "text": "The second verse of \"Never Gonna"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 48, "tree_h": 14.5, "tree_w": 43, "tree_size": 256, "t0": 2.0212, "t1": 0.895, "tft": 5.6761, "input_0": 720, "input_1": 257, "min_CLP": -6.25, "draft_iters": 15.9, "mem_use": 45.07, "gen_rate": 6.0, "speed": 2.06, "text": "Hello again! As I \"absorb\" Luna\\"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.3, "tree_w": 33, "tree_size": 256, "t0": 2.8433, "t1": 0.88, "tft": 4.6049, "input_0": 1111, "input_1": 257, "min_CLP": -5.98, "draft_iters": 21.3, "mem_use": 43.14, "gen_rate": 12.0, "speed": 3.23, "text": "The Copenhagen interpretation of"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.4, "tree_w": 80, "tree_size": 256, "t0": 1.2375, "t1": 0.8762, "tft": 2.551, "input_0": 472, "input_1": 257, "min_CLP": -6.93, "draft_iters": 9.4, "mem_use": 42.39, "gen_rate": 4.5, "speed": 2.13, "text": "My power is not for the weak-min"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.7, "tree_w": 51, "tree_size": 256, "t0": 1.8, "t1": 0.8929, "tft": 5.6208, "input_0": 639, "input_1": 257, "min_CLP": -6.35, "draft_iters": 14.0, "mem_use": 44.89, "gen_rate": 5.3, "speed": 1.96, "text": "[INST] What are some themes that"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 23.2, "tree_w": 64, "tree_size": 256, "t0": 2.53, "t1": 0.9025, "tft": 5.9105, "input_0": 616, "input_1": 257, "min_CLP": -6.91, "draft_iters": 24.0, "mem_use": 45.33, "gen_rate": 13.8, "speed": 4.01, "text": "\"[INST] Great! I'm looking for a"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.0, "tree_w": 33, "tree_size": 256, "t0": 2.205, "t1": 0.88, "tft": 3.763, "input_0": 902, "input_1": 257, "min_CLP": -5.78, "draft_iters": 15.5, "mem_use": 43.69, "gen_rate": 9.8, "speed": 3.16, "text": "The best SAST tool for your orga"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 19.0, "tree_w": 39, "tree_size": 256, "t0": 3.14, "t1": 0.88, "tft": 3.794, "input_0": 1091, "input_1": 257, "min_CLP": -6.41, "draft_iters": 21.0, "mem_use": 42.92, "gen_rate": 7.0, "speed": 1.74, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 16.7, "tree_w": 67, "tree_size": 256, "t0": 1.9517, "t1": 0.88, "tft": 3.6082, "input_0": 557, "input_1": 257, "min_CLP": -6.62, "draft_iters": 17.8, "mem_use": 42.66, "gen_rate": 8.2, "speed": 2.88, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.3, "tree_w": 27, "tree_size": 256, "t0": 2.7733, "t1": 0.8733, "tft": 2.6817, "input_0": 989, "input_1": 257, "min_CLP": -6.06, "draft_iters": 22.3, "mem_use": 42.17, "gen_rate": 13.0, "speed": 3.56, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 256, "t0": 3.19, "t1": 0.93, "tft": 6.2418, "input_0": 730, "input_1": 257, "min_CLP": -6.2, "draft_iters": 32.0, "mem_use": 47.61, "gen_rate": 33.0, "speed": 8.02, "text": "\"Certainly! Here's a revised ver"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.4, "tree_w": 104, "tree_size": 256, "t0": 1.0562, "t1": 0.89, "tft": 3.1544, "input_0": 408, "input_1": 257, "min_CLP": -7.0, "draft_iters": 7.6, "mem_use": 43.93, "gen_rate": 4.4, "speed": 2.25, "text": "Yes, yes, the Agent, you are the"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 13.0, "tree_w": 58, "tree_size": 256, "t0": 1.7433, "t1": 0.8767, "tft": 2.5064, "input_0": 610, "input_1": 257, "min_CLP": -6.38, "draft_iters": 14.0, "mem_use": 42.93, "gen_rate": 3.7, "speed": 1.4, "text": "I understand. If you need more h"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 14, "tree_h": 12.0, "tree_w": 46, "tree_size": 256, "t0": 1.84, "t1": 0.88, "tft": 2.8617, "input_0": 725, "input_1": 257, "min_CLP": -6.46, "draft_iters": 13.5, "mem_use": 42.44, "gen_rate": 7.0, "speed": 2.58, "text": "\u70b9\u51fb\u7387\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u9886\u57df\u7684\u4e00\u4e2a\u91cd\u8981\u4e3b\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 256, "t0": 3.26, "t1": 0.89, "tft": 5.0086, "input_0": 757, "input_1": 257, "min_CLP": -5.77, "draft_iters": 32.0, "mem_use": 44.35, "gen_rate": 33.0, "speed": 7.95, "text": "Sure! F-centers are crystallogra"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 35, "tree_size": 256, "t0": 2.3533, "t1": 0.8833, "tft": 4.8389, "input_0": 949, "input_1": 257, "min_CLP": -6.06, "draft_iters": 17.0, "mem_use": 43.58, "gen_rate": 10.7, "speed": 3.3, "text": "Sure! Here are some historical e"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.2, "tree_w": 41, "tree_size": 256, "t0": 2.2275, "t1": 0.8875, "tft": 4.1022, "input_0": 946, "input_1": 257, "min_CLP": -5.94, "draft_iters": 15.5, "mem_use": 43.91, "gen_rate": 8.2, "speed": 2.65, "text": "Yes, it is true that technology "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.1, "tree_w": 59, "tree_size": 256, "t0": 1.7429, "t1": 0.8743, "tft": 2.9389, "input_0": 702, "input_1": 257, "min_CLP": -6.34, "draft_iters": 12.7, "mem_use": 42.34, "gen_rate": 5.0, "speed": 1.91, "text": "In real life, people wear short "}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.8, "tree_w": 43, "tree_size": 256, "t0": 1.9625, "t1": 0.89, "tft": 4.4577, "input_0": 734, "input_1": 257, "min_CLP": -5.97, "draft_iters": 15.2, "mem_use": 44.75, "gen_rate": 9.8, "speed": 3.42, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.6, "tree_w": 47, "tree_size": 256, "t0": 2.128, "t1": 0.91, "tft": 6.0237, "input_0": 750, "input_1": 257, "min_CLP": -5.96, "draft_iters": 17.0, "mem_use": 45.99, "gen_rate": 7.6, "speed": 2.51, "text": "You are correct, my apologies fo"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.4, "tree_w": 40, "tree_size": 256, "t0": 2.242, "t1": 0.908, "tft": 5.1439, "input_0": 940, "input_1": 257, "min_CLP": -5.95, "draft_iters": 14.8, "mem_use": 46.15, "gen_rate": 7.8, "speed": 2.48, "text": "As a beginner, I think Keras is "}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 30.5, "tree_w": 23, "tree_size": 256, "t0": 3.38, "t1": 0.885, "tft": 4.8015, "input_0": 893, "input_1": 257, "min_CLP": -5.86, "draft_iters": 31.0, "mem_use": 43.84, "gen_rate": 20.0, "speed": 4.69, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 256, "t0": 3.53, "t1": 0.87, "tft": 2.3819, "input_0": 804, "input_1": 257, "min_CLP": -6.3, "draft_iters": 32.0, "mem_use": 42.16, "gen_rate": 33.0, "speed": 7.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 24.7, "tree_w": 41, "tree_size": 256, "t0": 2.7567, "t1": 0.8833, "tft": 5.2851, "input_0": 738, "input_1": 257, "min_CLP": -6.4, "draft_iters": 26.0, "mem_use": 44.58, "gen_rate": 8.0, "speed": 2.2, "text": "[INST] can you cook an egg only "}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.4, "tree_w": 56, "tree_size": 256, "t0": 1.758, "t1": 0.896, "tft": 6.075, "input_0": 709, "input_1": 257, "min_CLP": -6.31, "draft_iters": 12.8, "mem_use": 45.41, "gen_rate": 7.8, "speed": 2.94, "text": "[The scene opens with the Sparta"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.2, "tree_w": 57, "tree_size": 256, "t0": 1.968, "t1": 0.87, "tft": 2.728, "input_0": 684, "input_1": 257, "min_CLP": -6.36, "draft_iters": 16.4, "mem_use": 43.15, "gen_rate": 7.8, "speed": 2.75, "text": "I see what you mean. How about, "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 59, "tree_size": 256, "t0": 1.6875, "t1": 0.8825, "tft": 2.8629, "input_0": 622, "input_1": 257, "min_CLP": -6.27, "draft_iters": 13.0, "mem_use": 42.82, "gen_rate": 8.5, "speed": 3.31, "text": "The proof-of-stake concept works"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 29, "tree_h": 32.0, "tree_w": 37, "tree_size": 256, "t0": 3.5, "t1": 0.87, "tft": 3.6536, "input_0": 1161, "input_1": 257, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 42.99, "gen_rate": 29.0, "speed": 6.64, "text": "I am sorry to say that, but stop"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.2, "tree_w": 50, "tree_size": 256, "t0": 2.025, "t1": 0.8875, "tft": 4.6229, "input_0": 818, "input_1": 257, "min_CLP": -5.98, "draft_iters": 14.8, "mem_use": 45.03, "gen_rate": 8.0, "speed": 2.75, "text": "A void pointer is a pointer that"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 57, "tree_size": 256, "t0": 1.592, "t1": 0.896, "tft": 4.953, "input_0": 646, "input_1": 257, "min_CLP": -6.23, "draft_iters": 11.2, "mem_use": 45.54, "gen_rate": 6.6, "speed": 2.65, "text": "\"Hello Mike, I'm sorry to hear t"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.8, "tree_w": 41, "tree_size": 256, "t0": 2.2775, "t1": 0.89, "tft": 4.93, "input_0": 908, "input_1": 257, "min_CLP": -6.12, "draft_iters": 17.0, "mem_use": 44.75, "gen_rate": 10.0, "speed": 3.16, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 15.7, "tree_w": 42, "tree_size": 256, "t0": 2.3733, "t1": 0.8717, "tft": 3.4108, "input_0": 935, "input_1": 257, "min_CLP": -6.38, "draft_iters": 17.3, "mem_use": 42.57, "gen_rate": 4.0, "speed": 1.23, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.7, "tree_w": 42, "tree_size": 256, "t0": 1.95, "t1": 0.87, "tft": 2.7899, "input_0": 796, "input_1": 257, "min_CLP": -6.16, "draft_iters": 14.3, "mem_use": 42.16, "gen_rate": 11.3, "speed": 4.02, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 26.0, "tree_w": 72, "tree_size": 256, "t0": 3.335, "t1": 0.89, "tft": 6.1647, "input_0": 1083, "input_1": 257, "min_CLP": -6.86, "draft_iters": 27.0, "mem_use": 44.99, "gen_rate": 17.0, "speed": 4.02, "text": "\"Certainly, here's a table of th"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.8, "tree_w": 62, "tree_size": 256, "t0": 1.7083, "t1": 0.8733, "tft": 1.9807, "input_0": 710, "input_1": 257, "min_CLP": -6.52, "draft_iters": 12.2, "mem_use": 42.11, "gen_rate": 5.5, "speed": 2.13, "text": "The city of Berlin was founded i"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.85, "t1": 0.87, "tft": 5.3936, "input_0": 1066, "input_1": 257, "min_CLP": -7.58, "draft_iters": 32.0, "mem_use": 44.45, "gen_rate": 33.0, "speed": 6.98, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 24.0, "tree_w": 24, "tree_size": 256, "t0": 3.015, "t1": 0.89, "tft": 4.1655, "input_0": 958, "input_1": 257, "min_CLP": -5.89, "draft_iters": 25.5, "mem_use": 44.31, "gen_rate": 24.5, "speed": 6.28, "text": "Certainly. While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 256, "t0": 3.39, "t1": 0.87, "tft": 2.5077, "input_0": 842, "input_1": 257, "min_CLP": -6.89, "draft_iters": 32.0, "mem_use": 42.13, "gen_rate": 33.0, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 20.7, "tree_w": 45, "tree_size": 256, "t0": 2.3267, "t1": 0.8733, "tft": 4.1198, "input_0": 675, "input_1": 257, "min_CLP": -6.37, "draft_iters": 21.3, "mem_use": 42.44, "gen_rate": 13.7, "speed": 4.27, "text": "You can find out your current ti"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.0, "tree_w": 72, "tree_size": 256, "t0": 1.5486, "t1": 0.8757, "tft": 2.9507, "input_0": 591, "input_1": 257, "min_CLP": -6.67, "draft_iters": 12.1, "mem_use": 42.52, "gen_rate": 4.7, "speed": 1.94, "text": "\"The five second rule is a myth."}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 24.0, "tree_w": 26, "tree_size": 256, "t0": 3.0967, "t1": 0.8733, "tft": 2.645, "input_0": 1027, "input_1": 257, "min_CLP": -5.44, "draft_iters": 25.0, "mem_use": 42.25, "gen_rate": 17.7, "speed": 4.45, "text": "\"Sure, let's break this down ste"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.0, "tree_w": 31, "tree_size": 256, "t0": 2.6675, "t1": 0.8775, "tft": 3.8492, "input_0": 935, "input_1": 257, "min_CLP": -5.84, "draft_iters": 20.0, "mem_use": 43.04, "gen_rate": 9.8, "speed": 2.75, "text": "Certainly! One algorithm that is"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.5, "tree_w": 52, "tree_size": 256, "t0": 2.35, "t1": 0.8775, "tft": 2.7263, "input_0": 744, "input_1": 257, "min_CLP": -6.22, "draft_iters": 19.2, "mem_use": 42.56, "gen_rate": 8.2, "speed": 2.56, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 55, "tree_size": 256, "t0": 1.5817, "t1": 0.87, "tft": 3.1743, "input_0": 635, "input_1": 257, "min_CLP": -6.5, "draft_iters": 11.3, "mem_use": 42.28, "gen_rate": 5.5, "speed": 2.24, "text": "\"#OpenAssistantIsOpenSourceChatG"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 53, "tree_size": 256, "t0": 1.886, "t1": 0.88, "tft": 3.4836, "input_0": 761, "input_1": 257, "min_CLP": -6.17, "draft_iters": 13.2, "mem_use": 42.89, "gen_rate": 7.0, "speed": 2.53, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 16.5, "tree_w": 32, "tree_size": 256, "t0": 2.595, "t1": 0.8875, "tft": 3.9311, "input_0": 999, "input_1": 257, "min_CLP": -5.72, "draft_iters": 17.8, "mem_use": 43.95, "gen_rate": 10.8, "speed": 3.09, "text": "Certainly! In addition to the be"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 22.0, "tree_w": 37, "tree_size": 256, "t0": 2.67, "t1": 0.885, "tft": 5.3303, "input_0": 813, "input_1": 257, "min_CLP": -7.55, "draft_iters": 23.0, "mem_use": 44.96, "gen_rate": 17.5, "speed": 4.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.0, "tree_w": 45, "tree_size": 256, "t0": 2.214, "t1": 0.88, "tft": 3.2997, "input_0": 858, "input_1": 257, "min_CLP": -6.04, "draft_iters": 16.2, "mem_use": 43.48, "gen_rate": 6.6, "speed": 2.13, "text": "The scp command is specific to U"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 17, "tree_size": 256, "t0": 3.56, "t1": 0.88, "tft": 5.3106, "input_0": 1050, "input_1": 257, "min_CLP": -5.93, "draft_iters": 32.0, "mem_use": 44.11, "gen_rate": 32.0, "speed": 7.2, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 57, "tree_size": 256, "t0": 1.6825, "t1": 0.87, "tft": 2.4926, "input_0": 671, "input_1": 257, "min_CLP": -6.29, "draft_iters": 12.0, "mem_use": 42.18, "gen_rate": 8.5, "speed": 3.33, "text": "No, it would not be illegal to k"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.0, "tree_w": 40, "tree_size": 256, "t0": 1.876, "t1": 0.878, "tft": 4.1076, "input_0": 732, "input_1": 257, "min_CLP": -6.12, "draft_iters": 14.0, "mem_use": 42.47, "gen_rate": 7.2, "speed": 2.62, "text": "\"Sydney is the most populous cit"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 32.0, "tree_w": 49, "tree_size": 256, "t0": 3.12, "t1": 0.875, "tft": 3.2486, "input_0": 680, "input_1": 257, "min_CLP": -6.61, "draft_iters": 32.0, "mem_use": 42.77, "gen_rate": 24.5, "speed": 6.13, "text": "\"The 5 second rule is a game whe"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.8, "tree_w": 69, "tree_size": 256, "t0": 1.52, "t1": 0.875, "tft": 2.7181, "input_0": 597, "input_1": 257, "min_CLP": -6.75, "draft_iters": 11.2, "mem_use": 42.45, "gen_rate": 4.2, "speed": 1.77, "text": "\"I'm glad you appreciate it! Her"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 3.44, "t1": 0.87, "tft": 2.8987, "input_0": 819, "input_1": 257, "min_CLP": -6.36, "draft_iters": 32.0, "mem_use": 42.22, "gen_rate": 33.0, "speed": 7.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.4, "tree_w": 41, "tree_size": 256, "t0": 2.348, "t1": 0.872, "tft": 2.4983, "input_0": 878, "input_1": 257, "min_CLP": -6.06, "draft_iters": 17.8, "mem_use": 42.19, "gen_rate": 6.8, "speed": 2.11, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.7, "tree_w": 26, "tree_size": 256, "t0": 2.96, "t1": 0.8867, "tft": 5.0539, "input_0": 1121, "input_1": 257, "min_CLP": -5.95, "draft_iters": 22.0, "mem_use": 43.95, "gen_rate": 13.0, "speed": 3.38, "text": "Certainly! The Taniyama-Shimura-"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 24.5, "tree_w": 42, "tree_size": 256, "t0": 2.75, "t1": 0.875, "tft": 3.0524, "input_0": 730, "input_1": 257, "min_CLP": -6.73, "draft_iters": 25.5, "mem_use": 42.19, "gen_rate": 17.5, "speed": 4.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 28.5, "tree_w": 18, "tree_size": 256, "t0": 3.3, "t1": 0.88, "tft": 3.347, "input_0": 986, "input_1": 257, "min_CLP": -5.83, "draft_iters": 29.0, "mem_use": 42.5, "gen_rate": 17.5, "speed": 4.19, "text": "To write a first person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.0, "tree_w": 45, "tree_size": 256, "t0": 2.1575, "t1": 0.865, "tft": 3.1447, "input_0": 863, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.5, "mem_use": 42.17, "gen_rate": 9.0, "speed": 2.98, "text": "Answer: Starting to learn guitar"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 52, "tree_size": 256, "t0": 1.744, "t1": 0.87, "tft": 2.5646, "input_0": 702, "input_1": 257, "min_CLP": -6.19, "draft_iters": 12.8, "mem_use": 42.48, "gen_rate": 6.6, "speed": 2.52, "text": "As an experienced Jedi Master, I"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.9, "tree_w": 64, "tree_size": 256, "t0": 1.4671, "t1": 0.8729, "tft": 2.7367, "input_0": 631, "input_1": 257, "min_CLP": -6.41, "draft_iters": 10.4, "mem_use": 42.34, "gen_rate": 5.0, "speed": 2.14, "text": "A gas-operated rifle utilizes th"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.2, "tree_w": 50, "tree_size": 256, "t0": 2.1775, "t1": 0.8725, "tft": 3.3312, "input_0": 996, "input_1": 257, "min_CLP": -6.29, "draft_iters": 14.8, "mem_use": 42.58, "gen_rate": 9.5, "speed": 3.11, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 50, "tree_size": 256, "t0": 1.786, "t1": 0.896, "tft": 4.6474, "input_0": 734, "input_1": 257, "min_CLP": -6.08, "draft_iters": 13.2, "mem_use": 45.43, "gen_rate": 7.0, "speed": 2.61, "text": "Yes, using a regular expression "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.5, "tree_w": 41, "tree_size": 256, "t0": 1.98, "t1": 0.87, "tft": 3.5669, "input_0": 700, "input_1": 257, "min_CLP": -6.06, "draft_iters": 15.8, "mem_use": 42.64, "gen_rate": 9.0, "speed": 3.15, "text": "Yes, if someone finds lost prope"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.0, "tree_w": 53, "tree_size": 256, "t0": 1.786, "t1": 0.894, "tft": 5.2836, "input_0": 646, "input_1": 257, "min_CLP": -6.31, "draft_iters": 14.2, "mem_use": 45.53, "gen_rate": 6.4, "speed": 2.38, "text": "Xin ch\u00e0o, t\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd \u1ea3o. "}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.7, "tree_w": 62, "tree_size": 256, "t0": 1.5971, "t1": 0.8743, "tft": 3.3937, "input_0": 672, "input_1": 257, "min_CLP": -6.38, "draft_iters": 11.7, "mem_use": 43.05, "gen_rate": 5.6, "speed": 2.26, "text": "The footage was just a joke, and"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.0, "tree_w": 29, "tree_size": 256, "t0": 2.8833, "t1": 0.87, "tft": 2.8322, "input_0": 1059, "input_1": 257, "min_CLP": -5.76, "draft_iters": 22.3, "mem_use": 42.52, "gen_rate": 12.0, "speed": 3.2, "text": "\"Sure! Here's a more detailed ex"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 54, "tree_size": 256, "t0": 1.7533, "t1": 0.885, "tft": 4.1512, "input_0": 662, "input_1": 257, "min_CLP": -6.82, "draft_iters": 12.5, "mem_use": 43.98, "gen_rate": 5.7, "speed": 2.15, "text": "1. Scorpions\\n2. Rammstein\\n3. A"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.9, "tree_w": 81, "tree_size": 256, "t0": 1.2957, "t1": 0.8729, "tft": 4.1285, "input_0": 482, "input_1": 257, "min_CLP": -6.73, "draft_iters": 10.0, "mem_use": 42.49, "gen_rate": 5.6, "speed": 2.57, "text": "\"If you want to be a good thumb "}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 33, "tree_size": 256, "t0": 2.6533, "t1": 0.89, "tft": 4.5596, "input_0": 1089, "input_1": 257, "min_CLP": -5.79, "draft_iters": 18.3, "mem_use": 44.51, "gen_rate": 11.7, "speed": 3.29, "text": "\"Sure, here are some general tip"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.4, "tree_w": 54, "tree_size": 256, "t0": 1.844, "t1": 0.876, "tft": 3.2776, "input_0": 743, "input_1": 257, "min_CLP": -6.18, "draft_iters": 12.8, "mem_use": 43.15, "gen_rate": 7.4, "speed": 2.72, "text": "Yes, I can simulate various imag"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 46, "tree_size": 256, "t0": 2.15, "t1": 0.88, "tft": 4.0972, "input_0": 838, "input_1": 257, "min_CLP": -6.62, "draft_iters": 15.2, "mem_use": 42.65, "gen_rate": 8.5, "speed": 2.81, "text": "Romeo Montague is undoubtedly th"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.0, "tree_w": 28, "tree_size": 256, "t0": 2.7233, "t1": 0.88, "tft": 3.0142, "input_0": 1047, "input_1": 257, "min_CLP": -5.77, "draft_iters": 19.7, "mem_use": 42.79, "gen_rate": 12.0, "speed": 3.33, "text": "There are many popular APIs, lib"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.0, "tree_w": 126, "tree_size": 256, "t0": 1.235, "t1": 0.8887, "tft": 4.1712, "input_0": 433, "input_1": 257, "min_CLP": -7.77, "draft_iters": 10.0, "mem_use": 44.09, "gen_rate": 4.4, "speed": 2.06, "text": "\"Here is a poem in Quenya to exp"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.8, "tree_w": 48, "tree_size": 256, "t0": 2.125, "t1": 0.8675, "tft": 2.5823, "input_0": 799, "input_1": 257, "min_CLP": -6.26, "draft_iters": 17.0, "mem_use": 42.17, "gen_rate": 9.2, "speed": 3.09, "text": "Answer: The five most common cau"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.6, "tree_w": 44, "tree_size": 256, "t0": 1.888, "t1": 0.872, "tft": 2.555, "input_0": 768, "input_1": 257, "min_CLP": -6.2, "draft_iters": 13.2, "mem_use": 42.21, "gen_rate": 7.6, "speed": 2.75, "text": "The error in this code is that t"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.6, "tree_w": 62, "tree_size": 256, "t0": 1.5914, "t1": 0.88, "tft": 3.3495, "input_0": 603, "input_1": 257, "min_CLP": -6.36, "draft_iters": 12.0, "mem_use": 43.63, "gen_rate": 5.0, "speed": 2.02, "text": "\"[INST] Hello, Luna. It's Mike f"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.7, "tree_w": 40, "tree_size": 256, "t0": 1.96, "t1": 0.88, "tft": 2.9003, "input_0": 708, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.7, "mem_use": 42.81, "gen_rate": 11.0, "speed": 3.87, "text": "In the second context, the `@` s"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.3, "tree_w": 30, "tree_size": 256, "t0": 2.6367, "t1": 0.8767, "tft": 3.012, "input_0": 953, "input_1": 257, "min_CLP": -5.76, "draft_iters": 20.7, "mem_use": 42.94, "gen_rate": 11.7, "speed": 3.32, "text": "\"You can use the `argparse` modu"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 49, "tree_size": 256, "t0": 1.86, "t1": 0.8825, "tft": 3.8272, "input_0": 803, "input_1": 257, "min_CLP": -6.12, "draft_iters": 12.8, "mem_use": 44.73, "gen_rate": 8.2, "speed": 3.0, "text": "\"It's important to listen to you"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 19, "tree_size": 256, "t0": 3.73, "t1": 0.87, "tft": 4.2957, "input_0": 1141, "input_1": 257, "min_CLP": -5.67, "draft_iters": 32.0, "mem_use": 42.72, "gen_rate": 32.0, "speed": 6.95, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 31.5, "tree_w": 18, "tree_size": 256, "t0": 3.405, "t1": 0.88, "tft": 5.3246, "input_0": 946, "input_1": 257, "min_CLP": -5.71, "draft_iters": 32.0, "mem_use": 44.11, "gen_rate": 21.5, "speed": 5.02, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.0, "tree_w": 43, "tree_size": 256, "t0": 2.13, "t1": 0.8675, "tft": 3.0375, "input_0": 737, "input_1": 257, "min_CLP": -6.07, "draft_iters": 17.0, "mem_use": 42.15, "gen_rate": 8.8, "speed": 2.92, "text": "\"No, I'm sorry but as an AI lang"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.2, "tree_w": 54, "tree_size": 256, "t0": 2.024, "t1": 0.868, "tft": 3.2927, "input_0": 669, "input_1": 257, "min_CLP": -6.91, "draft_iters": 17.6, "mem_use": 42.37, "gen_rate": 6.8, "speed": 2.35, "text": "\"Attention's gaze,\\nSoftly focus"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 16.2, "tree_w": 44, "tree_size": 256, "t0": 2.255, "t1": 0.87, "tft": 3.1096, "input_0": 865, "input_1": 257, "min_CLP": -6.11, "draft_iters": 17.3, "mem_use": 42.62, "gen_rate": 6.5, "speed": 2.08, "text": "\"Thank you! I'm here to help and"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 20.0, "tree_w": 34, "tree_size": 256, "t0": 2.5567, "t1": 0.8867, "tft": 5.1623, "input_0": 813, "input_1": 257, "min_CLP": -6.24, "draft_iters": 21.3, "mem_use": 44.23, "gen_rate": 21.0, "speed": 6.1, "text": "\"Thou art the sun that shineth b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 18.5, "tree_w": 35, "tree_size": 256, "t0": 2.36, "t1": 0.88, "tft": 2.8984, "input_0": 747, "input_1": 257, "min_CLP": -6.15, "draft_iters": 20.0, "mem_use": 42.79, "gen_rate": 5.5, "speed": 1.7, "text": "[INST] Please provide a source r"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 24.5, "tree_w": 35, "tree_size": 256, "t0": 2.83, "t1": 0.865, "tft": 2.9963, "input_0": 777, "input_1": 257, "min_CLP": -6.47, "draft_iters": 25.5, "mem_use": 42.19, "gen_rate": 17.5, "speed": 4.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.2, "tree_w": 33, "tree_size": 256, "t0": 2.3475, "t1": 0.8675, "tft": 2.3814, "input_0": 818, "input_1": 257, "min_CLP": -5.91, "draft_iters": 18.5, "mem_use": 42.17, "gen_rate": 8.2, "speed": 2.57, "text": "\"Presidents Day, officially call"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.2, "tree_w": 51, "tree_size": 256, "t0": 1.8075, "t1": 0.87, "tft": 2.8814, "input_0": 666, "input_1": 257, "min_CLP": -6.26, "draft_iters": 14.5, "mem_use": 42.47, "gen_rate": 8.2, "speed": 3.08, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.3, "tree_w": 43, "tree_size": 256, "t0": 2.1167, "t1": 0.88, "tft": 4.2247, "input_0": 869, "input_1": 257, "min_CLP": -6.12, "draft_iters": 14.7, "mem_use": 43.31, "gen_rate": 12.0, "speed": 4.01, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 8.6, "tree_w": 68, "tree_size": 256, "t0": 1.402, "t1": 0.872, "tft": 2.8875, "input_0": 586, "input_1": 257, "min_CLP": -6.63, "draft_iters": 9.8, "mem_use": 42.55, "gen_rate": 3.5, "speed": 1.54, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.9, "tree_w": 64, "tree_size": 256, "t0": 1.4257, "t1": 0.8714, "tft": 2.6877, "input_0": 546, "input_1": 257, "min_CLP": -6.59, "draft_iters": 11.0, "mem_use": 42.62, "gen_rate": 4.7, "speed": 2.05, "text": "Ok, from here on, I will answer "}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.7, "tree_w": 36, "tree_size": 256, "t0": 1.7933, "t1": 0.8633, "tft": 2.494, "input_0": 636, "input_1": 257, "min_CLP": -6.1, "draft_iters": 14.7, "mem_use": 42.17, "gen_rate": 11.3, "speed": 4.26, "text": "Yes, the ATF (Bureau of Alcohol,"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.4, "tree_w": 76, "tree_size": 256, "t0": 1.3771, "t1": 0.8729, "tft": 4.2451, "input_0": 521, "input_1": 257, "min_CLP": -6.67, "draft_iters": 10.7, "mem_use": 42.85, "gen_rate": 5.4, "speed": 2.41, "text": "\"oh please, Ted\\'s just a grumpy"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 3.44, "t1": 0.86, "tft": 2.5172, "input_0": 972, "input_1": 257, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 42.28, "gen_rate": 33.0, "speed": 7.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 15.8, "tree_w": 39, "tree_size": 256, "t0": 2.205, "t1": 0.875, "tft": 3.903, "input_0": 820, "input_1": 257, "min_CLP": -6.34, "draft_iters": 17.2, "mem_use": 43.55, "gen_rate": 10.8, "speed": 3.49, "text": "Certainly! Here are some medias "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 57, "tree_size": 256, "t0": 1.7383, "t1": 0.875, "tft": 2.6736, "input_0": 688, "input_1": 257, "min_CLP": -6.39, "draft_iters": 12.8, "mem_use": 42.61, "gen_rate": 5.7, "speed": 2.17, "text": "I am programmed to be helpful, r"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.2, "tree_w": 37, "tree_size": 256, "t0": 2.15, "t1": 0.882, "tft": 4.7644, "input_0": 780, "input_1": 257, "min_CLP": -5.98, "draft_iters": 16.6, "mem_use": 43.84, "gen_rate": 7.4, "speed": 2.44, "text": "\"If you're a beginner hiker and "}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 11.5, "tree_w": 62, "tree_size": 256, "t0": 1.7288, "t1": 0.8712, "tft": 3.3232, "input_0": 683, "input_1": 257, "min_CLP": -6.46, "draft_iters": 12.9, "mem_use": 42.56, "gen_rate": 4.6, "speed": 1.78, "text": "\"Open Assistant: The Open Source"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 16.2, "tree_w": 47, "tree_size": 256, "t0": 2.135, "t1": 0.87, "tft": 3.6141, "input_0": 728, "input_1": 257, "min_CLP": -6.17, "draft_iters": 17.7, "mem_use": 42.46, "gen_rate": 5.7, "speed": 1.88, "text": "Sure, here is an illustration of"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.0, "tree_w": 34, "tree_size": 256, "t0": 2.74, "t1": 0.89, "tft": 5.0153, "input_0": 907, "input_1": 257, "min_CLP": -5.84, "draft_iters": 21.5, "mem_use": 44.81, "gen_rate": 17.5, "speed": 4.82, "text": "The reason this is happening is "}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.7, "tree_w": 38, "tree_size": 256, "t0": 2.6133, "t1": 0.87, "tft": 2.4799, "input_0": 1145, "input_1": 257, "min_CLP": -6.11, "draft_iters": 17.7, "mem_use": 42.15, "gen_rate": 10.7, "speed": 3.06, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 1.65, "t1": 0.88, "tft": 2.9013, "input_0": 640, "input_1": 257, "min_CLP": -6.32, "draft_iters": 12.2, "mem_use": 42.7, "gen_rate": 6.7, "speed": 2.64, "text": "\"I'm sorry, I cannot give a bias"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 48, "tree_h": 12.7, "tree_w": 48, "tree_size": 256, "t0": 1.8514, "t1": 0.8729, "tft": 3.5532, "input_0": 689, "input_1": 257, "min_CLP": -6.21, "draft_iters": 14.0, "mem_use": 42.33, "gen_rate": 6.9, "speed": 2.52, "text": "The heat from the pan quickly he"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.2, "tree_w": 35, "tree_size": 256, "t0": 2.465, "t1": 0.875, "tft": 2.7336, "input_0": 866, "input_1": 257, "min_CLP": -6.13, "draft_iters": 19.2, "mem_use": 42.17, "gen_rate": 11.0, "speed": 3.29, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 39, "tree_size": 256, "t0": 1.9475, "t1": 0.89, "tft": 4.294, "input_0": 799, "input_1": 257, "min_CLP": -6.15, "draft_iters": 13.2, "mem_use": 44.27, "gen_rate": 8.5, "speed": 3.0, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.8, "tree_w": 59, "tree_size": 256, "t0": 1.56, "t1": 0.87, "tft": 2.5325, "input_0": 631, "input_1": 257, "min_CLP": -6.35, "draft_iters": 11.0, "mem_use": 42.13, "gen_rate": 5.5, "speed": 2.26, "text": "Yes, a thumb war can be consider"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 25.0, "tree_w": 40, "tree_size": 256, "t0": 3.05, "t1": 0.87, "tft": 2.4742, "input_0": 888, "input_1": 257, "min_CLP": -6.46, "draft_iters": 26.3, "mem_use": 42.21, "gen_rate": 10.7, "speed": 2.72, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 39, "tree_size": 256, "t0": 1.9567, "t1": 0.8967, "tft": 4.8402, "input_0": 776, "input_1": 257, "min_CLP": -6.08, "draft_iters": 14.3, "mem_use": 45.49, "gen_rate": 10.7, "speed": 3.74, "text": "As of my last update in early 20"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.2, "tree_w": 55, "tree_size": 256, "t0": 1.88, "t1": 0.874, "tft": 3.624, "input_0": 668, "input_1": 257, "min_CLP": -6.21, "draft_iters": 15.2, "mem_use": 43.51, "gen_rate": 6.4, "speed": 2.32, "text": "I understand now. Thank you for "}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.2, "tree_w": 29, "tree_size": 256, "t0": 2.5825, "t1": 0.8725, "tft": 2.8633, "input_0": 999, "input_1": 257, "min_CLP": -5.79, "draft_iters": 18.5, "mem_use": 42.42, "gen_rate": 10.0, "speed": 2.89, "text": "Certainly! There are many resour"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.5, "tree_w": 54, "tree_size": 256, "t0": 1.855, "t1": 0.875, "tft": 3.1284, "input_0": 651, "input_1": 257, "min_CLP": -6.55, "draft_iters": 15.0, "mem_use": 42.4, "gen_rate": 9.2, "speed": 3.39, "text": "# solution: The most effective w"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 52, "tree_size": 256, "t0": 1.7675, "t1": 0.8625, "tft": 2.5656, "input_0": 784, "input_1": 257, "min_CLP": -6.21, "draft_iters": 12.5, "mem_use": 42.17, "gen_rate": 8.0, "speed": 3.04, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 18.8, "tree_w": 51, "tree_size": 256, "t0": 2.228, "t1": 0.872, "tft": 4.1513, "input_0": 684, "input_1": 257, "min_CLP": -6.42, "draft_iters": 20.0, "mem_use": 43.02, "gen_rate": 7.2, "speed": 2.32, "text": "Sure, I can do that. Here is an "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 17.5, "tree_w": 48, "tree_size": 256, "t0": 2.2533, "t1": 0.88, "tft": 4.888, "input_0": 753, "input_1": 257, "min_CLP": -6.32, "draft_iters": 18.3, "mem_use": 43.04, "gen_rate": 5.8, "speed": 1.86, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 23.0, "tree_w": 27, "tree_size": 256, "t0": 2.84, "t1": 0.9, "tft": 6.2328, "input_0": 898, "input_1": 257, "min_CLP": -5.69, "draft_iters": 24.5, "mem_use": 45.51, "gen_rate": 18.5, "speed": 4.94, "text": "\"Sure, here's a more concise ver"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 16.0, "tree_w": 39, "tree_size": 256, "t0": 2.23, "t1": 0.8667, "tft": 3.1558, "input_0": 826, "input_1": 257, "min_CLP": -6.18, "draft_iters": 17.3, "mem_use": 42.17, "gen_rate": 12.0, "speed": 3.87, "text": "To reduce your alcohol consumpti"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 15.0, "tree_w": 68, "tree_size": 256, "t0": 2.07, "t1": 0.878, "tft": 2.6248, "input_0": 709, "input_1": 257, "min_CLP": -6.54, "draft_iters": 16.6, "mem_use": 42.74, "gen_rate": 8.2, "speed": 2.78, "text": "\"Berlin is the center of the Ger"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 25.7, "tree_w": 21, "tree_size": 256, "t0": 3.42, "t1": 0.87, "tft": 2.8284, "input_0": 1200, "input_1": 257, "min_CLP": -5.6, "draft_iters": 27.3, "mem_use": 42.21, "gen_rate": 15.0, "speed": 3.5, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 256, "t0": 3.08, "t1": 0.89, "tft": 5.8212, "input_0": 643, "input_1": 257, "min_CLP": -5.94, "draft_iters": 32.0, "mem_use": 44.73, "gen_rate": 33.0, "speed": 8.32, "text": "## Vegetarian\\n Microwave Sausag"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 11.3, "tree_w": 60, "tree_size": 256, "t0": 1.6743, "t1": 0.8714, "tft": 2.3159, "input_0": 611, "input_1": 257, "min_CLP": -6.6, "draft_iters": 12.3, "mem_use": 42.12, "gen_rate": 6.0, "speed": 2.36, "text": "It seems like you\\'re asking abo"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 14.6, "tree_w": 45, "tree_size": 256, "t0": 2.116, "t1": 0.888, "tft": 4.2985, "input_0": 816, "input_1": 257, "min_CLP": -6.23, "draft_iters": 16.0, "mem_use": 44.4, "gen_rate": 8.8, "speed": 2.93, "text": "The owners of the local restaura"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 15.8, "tree_w": 42, "tree_size": 256, "t0": 2.322, "t1": 0.868, "tft": 3.1342, "input_0": 937, "input_1": 257, "min_CLP": -6.18, "draft_iters": 17.0, "mem_use": 42.13, "gen_rate": 8.4, "speed": 2.63, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 12.8, "tree_w": 98, "tree_size": 256, "t0": 1.5583, "t1": 0.86, "tft": 3.8128, "input_0": 503, "input_1": 257, "min_CLP": -7.41, "draft_iters": 13.8, "mem_use": 42.12, "gen_rate": 8.7, "speed": 3.58, "text": "\u201c\u5f53\u524d\u7684\u7ecf\u6d4e\u5f62\u52bf\u4e0d\u5bb9\u4e50\u89c2\uff0c\u9700\u8981\u6211\u4eec\u91c7\u53d6\u79ef\u6781\u7684\u63aa\u65bd\u5e94\u5bf9\u3002\u201d [IN"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.0, "tree_w": 34, "tree_size": 256, "t0": 2.3275, "t1": 0.8675, "tft": 2.4901, "input_0": 921, "input_1": 257, "min_CLP": -5.88, "draft_iters": 18.0, "mem_use": 42.28, "gen_rate": 9.5, "speed": 2.97, "text": "Sure, I can provide an example o"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 45, "tree_size": 256, "t0": 1.86, "t1": 0.876, "tft": 4.0721, "input_0": 746, "input_1": 257, "min_CLP": -5.95, "draft_iters": 13.8, "mem_use": 43.37, "gen_rate": 6.6, "speed": 2.41, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.0, "tree_w": 41, "tree_size": 256, "t0": 2.284, "t1": 0.87, "tft": 2.6472, "input_0": 913, "input_1": 257, "min_CLP": -6.15, "draft_iters": 16.6, "mem_use": 42.23, "gen_rate": 6.6, "speed": 2.09, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.8, "tree_w": 33, "tree_size": 256, "t0": 2.36, "t1": 0.875, "tft": 2.9837, "input_0": 860, "input_1": 257, "min_CLP": -6.01, "draft_iters": 17.2, "mem_use": 42.43, "gen_rate": 9.2, "speed": 2.86, "text": "Sure, in reStructuredText, you c"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 16.2, "tree_w": 34, "tree_size": 256, "t0": 2.26, "t1": 0.88, "tft": 3.648, "input_0": 833, "input_1": 257, "min_CLP": -5.94, "draft_iters": 17.5, "mem_use": 42.77, "gen_rate": 9.8, "speed": 3.1, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 52, "tree_size": 256, "t0": 1.742, "t1": 0.876, "tft": 2.8272, "input_0": 675, "input_1": 257, "min_CLP": -6.32, "draft_iters": 13.0, "mem_use": 42.32, "gen_rate": 7.4, "speed": 2.83, "text": "I am the goddess of love, fertil"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 20.7, "tree_w": 30, "tree_size": 256, "t0": 2.7367, "t1": 0.88, "tft": 5.1896, "input_0": 964, "input_1": 257, "min_CLP": -5.73, "draft_iters": 22.0, "mem_use": 43.57, "gen_rate": 12.0, "speed": 3.32, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.0, "tree_w": 53, "tree_size": 256, "t0": 1.756, "t1": 0.87, "tft": 3.1135, "input_0": 644, "input_1": 257, "min_CLP": -6.23, "draft_iters": 13.2, "mem_use": 42.21, "gen_rate": 6.6, "speed": 2.51, "text": "Certainly! Here\\'s a response th"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 30, "tree_size": 256, "t0": 2.4433, "t1": 0.88, "tft": 3.6406, "input_0": 934, "input_1": 257, "min_CLP": -5.86, "draft_iters": 18.7, "mem_use": 43.09, "gen_rate": 11.0, "speed": 3.31, "text": "The microwave oven became a comm"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 43, "tree_size": 256, "t0": 3.61, "t1": 0.88, "tft": 2.7656, "input_0": 910, "input_1": 257, "min_CLP": -6.88, "draft_iters": 32.0, "mem_use": 42.32, "gen_rate": 33.0, "speed": 7.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 24.2, "tree_w": 42, "tree_size": 256, "t0": 2.7233, "t1": 0.8667, "tft": 2.2957, "input_0": 741, "input_1": 257, "min_CLP": -6.33, "draft_iters": 24.7, "mem_use": 42.15, "gen_rate": 6.0, "speed": 1.67, "text": "\"No data available.\\nThe story o"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.0, "tree_w": 40, "tree_size": 256, "t0": 2.194, "t1": 0.908, "tft": 5.5868, "input_0": 905, "input_1": 257, "min_CLP": -5.94, "draft_iters": 14.8, "mem_use": 46.44, "gen_rate": 6.8, "speed": 2.19, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.72, "t1": 0.87, "tft": 4.3783, "input_0": 1126, "input_1": 257, "min_CLP": -9.36, "draft_iters": 32.0, "mem_use": 42.45, "gen_rate": 33.0, "speed": 7.19, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 23.5, "tree_w": 40, "tree_size": 256, "t0": 2.695, "t1": 0.8775, "tft": 4.5319, "input_0": 760, "input_1": 257, "min_CLP": -5.93, "draft_iters": 24.2, "mem_use": 43.37, "gen_rate": 9.8, "speed": 2.73, "text": "It is not possible to go around "}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.2, "tree_w": 54, "tree_size": 256, "t0": 1.832, "t1": 0.888, "tft": 5.4703, "input_0": 648, "input_1": 257, "min_CLP": -6.36, "draft_iters": 14.6, "mem_use": 44.59, "gen_rate": 6.8, "speed": 2.5, "text": "You can prevent spiders from spa"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.4, "tree_w": 83, "tree_size": 256, "t0": 1.3113, "t1": 0.8775, "tft": 3.0185, "input_0": 459, "input_1": 257, "min_CLP": -6.99, "draft_iters": 10.4, "mem_use": 42.43, "gen_rate": 4.4, "speed": 2.0, "text": "\"I'm sure if you were to start a"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.0, "tree_w": 38, "tree_size": 256, "t0": 2.2125, "t1": 0.875, "tft": 2.5416, "input_0": 721, "input_1": 257, "min_CLP": -6.2, "draft_iters": 18.0, "mem_use": 42.47, "gen_rate": 8.8, "speed": 2.84, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 47, "tree_size": 256, "t0": 2.09, "t1": 0.8775, "tft": 3.6739, "input_0": 853, "input_1": 257, "min_CLP": -6.27, "draft_iters": 15.5, "mem_use": 42.99, "gen_rate": 10.0, "speed": 3.37, "text": "The 3D animation programs that h"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 256, "t0": 3.33, "t1": 0.88, "tft": 3.2917, "input_0": 793, "input_1": 257, "min_CLP": -6.18, "draft_iters": 32.0, "mem_use": 42.45, "gen_rate": 33.0, "speed": 7.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 51, "tree_size": 256, "t0": 1.815, "t1": 0.875, "tft": 3.4646, "input_0": 725, "input_1": 257, "min_CLP": -6.39, "draft_iters": 13.2, "mem_use": 43.17, "gen_rate": 8.0, "speed": 2.97, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.5, "tree_w": 55, "tree_size": 256, "t0": 2.385, "t1": 0.875, "tft": 2.4193, "input_0": 720, "input_1": 257, "min_CLP": -7.48, "draft_iters": 21.5, "mem_use": 42.47, "gen_rate": 17.5, "speed": 5.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 45, "tree_size": 256, "t0": 1.9, "t1": 0.8725, "tft": 3.1651, "input_0": 686, "input_1": 257, "min_CLP": -6.42, "draft_iters": 15.0, "mem_use": 42.19, "gen_rate": 8.0, "speed": 2.89, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 3.37, "t1": 0.87, "tft": 2.1969, "input_0": 821, "input_1": 257, "min_CLP": -8.19, "draft_iters": 32.0, "mem_use": 42.16, "gen_rate": 33.0, "speed": 7.8, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.3, "tree_w": 47, "tree_size": 256, "t0": 2.24, "t1": 0.9033, "tft": 5.824, "input_0": 775, "input_1": 257, "min_CLP": -6.25, "draft_iters": 16.7, "mem_use": 46.43, "gen_rate": 11.0, "speed": 3.5, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 36, "tree_size": 256, "t0": 2.1, "t1": 0.87, "tft": 2.7916, "input_0": 782, "input_1": 257, "min_CLP": -6.24, "draft_iters": 15.7, "mem_use": 42.29, "gen_rate": 11.7, "speed": 3.93, "text": "Some of the most common applicat"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.7, "tree_w": 45, "tree_size": 256, "t0": 2.1833, "t1": 0.8833, "tft": 4.9959, "input_0": 795, "input_1": 257, "min_CLP": -6.08, "draft_iters": 16.0, "mem_use": 43.85, "gen_rate": 11.0, "speed": 3.59, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.2, "tree_w": 48, "tree_size": 256, "t0": 1.8767, "t1": 0.88, "tft": 3.6827, "input_0": 709, "input_1": 257, "min_CLP": -6.19, "draft_iters": 14.5, "mem_use": 43.62, "gen_rate": 5.5, "speed": 1.99, "text": "The command \"chkdsk C: /f\" will "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.0, "tree_w": 37, "tree_size": 256, "t0": 2.6333, "t1": 0.8733, "tft": 4.1957, "input_0": 967, "input_1": 257, "min_CLP": -5.92, "draft_iters": 21.0, "mem_use": 42.42, "gen_rate": 10.7, "speed": 3.04, "text": "\"To approach and solve this prob"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 38, "tree_size": 256, "t0": 3.43, "t1": 0.87, "tft": 3.9106, "input_0": 866, "input_1": 257, "min_CLP": -6.86, "draft_iters": 32.0, "mem_use": 42.24, "gen_rate": 33.0, "speed": 7.67, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 40, "tree_size": 256, "t0": 3.34, "t1": 0.87, "tft": 2.5428, "input_0": 812, "input_1": 257, "min_CLP": -6.39, "draft_iters": 32.0, "mem_use": 42.22, "gen_rate": 33.0, "speed": 7.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.0, "tree_w": 28, "tree_size": 256, "t0": 2.31, "t1": 0.8733, "tft": 3.6125, "input_0": 804, "input_1": 257, "min_CLP": -5.88, "draft_iters": 18.0, "mem_use": 43.25, "gen_rate": 11.0, "speed": 3.45, "text": "\"I'd be happy to help you improv"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 8.5, "tree_w": 106, "tree_size": 256, "t0": 1.16, "t1": 0.87, "tft": 2.6812, "input_0": 412, "input_1": 257, "min_CLP": -7.06, "draft_iters": 9.5, "mem_use": 42.55, "gen_rate": 3.0, "speed": 1.48, "text": "How can we increase empathy in s"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 29.0, "tree_w": 32, "tree_size": 256, "t0": 3.225, "t1": 0.885, "tft": 5.4359, "input_0": 881, "input_1": 257, "min_CLP": -6.09, "draft_iters": 29.2, "mem_use": 43.89, "gen_rate": 9.5, "speed": 2.31, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 92, "tree_size": 256, "t0": 1.1817, "t1": 0.8767, "tft": 3.2383, "input_0": 462, "input_1": 257, "min_CLP": -6.76, "draft_iters": 9.0, "mem_use": 42.78, "gen_rate": 5.5, "speed": 2.67, "text": "I think the person who answered "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.2, "tree_w": 71, "tree_size": 256, "t0": 1.8867, "t1": 0.875, "tft": 4.2674, "input_0": 654, "input_1": 257, "min_CLP": -6.94, "draft_iters": 15.5, "mem_use": 42.62, "gen_rate": 5.7, "speed": 2.05, "text": "The ATF gunwalking scandal refer"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 49, "tree_size": 256, "t0": 1.898, "t1": 0.87, "tft": 3.3549, "input_0": 788, "input_1": 257, "min_CLP": -6.13, "draft_iters": 13.6, "mem_use": 42.36, "gen_rate": 7.0, "speed": 2.53, "text": "The difference between interpret"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 13, "tree_size": 256, "t0": 3.73, "t1": 0.89, "tft": 5.8673, "input_0": 1277, "input_1": 257, "min_CLP": -9.83, "draft_iters": 32.0, "mem_use": 45.16, "gen_rate": 32.0, "speed": 6.94, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 56, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 3.65, "t1": 0.89, "tft": 5.8047, "input_0": 1145, "input_1": 257, "min_CLP": -6.69, "draft_iters": 32.0, "mem_use": 45.09, "gen_rate": 28.0, "speed": 6.17, "text": "Once upon a time, in the city of"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.5, "tree_w": 59, "tree_size": 256, "t0": 1.6117, "t1": 0.8683, "tft": 3.1156, "input_0": 649, "input_1": 257, "min_CLP": -6.47, "draft_iters": 11.7, "mem_use": 42.15, "gen_rate": 5.8, "speed": 2.35, "text": "\"Sure, here's a poem inspired by"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 30.0, "tree_w": 17, "tree_size": 256, "t0": 3.495, "t1": 0.88, "tft": 3.4137, "input_0": 937, "input_1": 257, "min_CLP": -5.8, "draft_iters": 31.0, "mem_use": 43.35, "gen_rate": 21.0, "speed": 4.8, "text": "Absolutely! Here is the revised "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 20.0, "tree_w": 32, "tree_size": 256, "t0": 2.72, "t1": 0.8875, "tft": 4.9559, "input_0": 935, "input_1": 257, "min_CLP": -5.81, "draft_iters": 21.0, "mem_use": 43.79, "gen_rate": 10.0, "speed": 2.77, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 20.0, "tree_w": 30, "tree_size": 256, "t0": 2.7733, "t1": 0.87, "tft": 2.3648, "input_0": 934, "input_1": 257, "min_CLP": -5.92, "draft_iters": 21.3, "mem_use": 42.13, "gen_rate": 16.7, "speed": 4.58, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 39, "tree_size": 256, "t0": 3.49, "t1": 0.87, "tft": 2.4586, "input_0": 1012, "input_1": 257, "min_CLP": -6.74, "draft_iters": 32.0, "mem_use": 42.43, "gen_rate": 33.0, "speed": 7.56, "text": "I am Freyja, a god from beyond t"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 38, "tree_size": 256, "t0": 2.08, "t1": 0.8867, "tft": 5.0313, "input_0": 820, "input_1": 257, "min_CLP": -6.28, "draft_iters": 15.3, "mem_use": 44.04, "gen_rate": 11.7, "speed": 3.94, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.8, "tree_w": 42, "tree_size": 256, "t0": 1.9975, "t1": 0.8725, "tft": 2.3676, "input_0": 769, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.2, "mem_use": 42.37, "gen_rate": 9.2, "speed": 3.22, "text": "To host a large language model o"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.5, "tree_w": 46, "tree_size": 256, "t0": 2.1425, "t1": 0.88, "tft": 4.1838, "input_0": 817, "input_1": 257, "min_CLP": -6.22, "draft_iters": 16.0, "mem_use": 43.74, "gen_rate": 8.8, "speed": 2.89, "text": "\"Certainly! Let's break down the"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 54, "tree_size": 256, "t0": 1.722, "t1": 0.87, "tft": 2.3787, "input_0": 638, "input_1": 257, "min_CLP": -6.34, "draft_iters": 13.4, "mem_use": 42.17, "gen_rate": 7.4, "speed": 2.85, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 23.0, "tree_w": 22, "tree_size": 256, "t0": 2.875, "t1": 0.865, "tft": 2.9119, "input_0": 971, "input_1": 257, "min_CLP": -6.14, "draft_iters": 24.0, "mem_use": 42.17, "gen_rate": 17.5, "speed": 4.68, "text": "To cook a salmon fillet on a sto"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.5, "tree_w": 47, "tree_size": 256, "t0": 2.0925, "t1": 0.8775, "tft": 2.5355, "input_0": 677, "input_1": 257, "min_CLP": -6.11, "draft_iters": 17.2, "mem_use": 42.82, "gen_rate": 8.0, "speed": 2.69, "text": "\"Okay, here's my attempt at a su"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 18.0, "tree_w": 43, "tree_size": 256, "t0": 2.38, "t1": 0.876, "tft": 2.7083, "input_0": 857, "input_1": 257, "min_CLP": -6.05, "draft_iters": 19.2, "mem_use": 43.09, "gen_rate": 8.0, "speed": 2.46, "text": "Thank you for pointing out the e"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.4, "tree_w": 48, "tree_size": 256, "t0": 2.098, "t1": 0.87, "tft": 2.7697, "input_0": 768, "input_1": 257, "min_CLP": -6.8, "draft_iters": 16.6, "mem_use": 42.15, "gen_rate": 7.8, "speed": 2.63, "text": "A. assault rifle\\nB. sniper rifl"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 19.2, "tree_w": 31, "tree_size": 256, "t0": 2.6425, "t1": 0.875, "tft": 2.7072, "input_0": 929, "input_1": 257, "min_CLP": -5.89, "draft_iters": 20.5, "mem_use": 42.5, "gen_rate": 10.5, "speed": 2.98, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 32.0, "tree_w": 17, "tree_size": 256, "t0": 3.535, "t1": 0.89, "tft": 4.7427, "input_0": 932, "input_1": 257, "min_CLP": -6.06, "draft_iters": 32.0, "mem_use": 43.91, "gen_rate": 25.5, "speed": 5.77, "text": "Sure, here you go:\\n\\n* Statisti"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 14.5, "tree_w": 39, "tree_size": 256, "t0": 2.11, "t1": 0.875, "tft": 3.3483, "input_0": 849, "input_1": 257, "min_CLP": -5.93, "draft_iters": 15.8, "mem_use": 42.48, "gen_rate": 10.2, "speed": 3.43, "text": "\"Here are some tips to help you "}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 52, "tree_size": 256, "t0": 1.816, "t1": 0.87, "tft": 3.8692, "input_0": 752, "input_1": 257, "min_CLP": -6.22, "draft_iters": 13.0, "mem_use": 43.03, "gen_rate": 6.8, "speed": 2.53, "text": "No, there is no harm in letting "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 11.8, "tree_w": 100, "tree_size": 256, "t0": 1.5333, "t1": 0.875, "tft": 3.5457, "input_0": 493, "input_1": 257, "min_CLP": -6.96, "draft_iters": 13.0, "mem_use": 42.63, "gen_rate": 7.3, "speed": 3.05, "text": "Tell them that they are a good p"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 13.5, "tree_w": 48, "tree_size": 256, "t0": 1.83, "t1": 0.865, "tft": 3.176, "input_0": 664, "input_1": 257, "min_CLP": -6.2, "draft_iters": 15.0, "mem_use": 42.74, "gen_rate": 4.5, "speed": 1.67, "text": "What is the main difference betw"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.6, "tree_w": 53, "tree_size": 256, "t0": 2.068, "t1": 0.872, "tft": 3.2667, "input_0": 704, "input_1": 257, "min_CLP": -6.36, "draft_iters": 17.2, "mem_use": 42.14, "gen_rate": 6.6, "speed": 2.25, "text": "\"I'm not capable of having thoug"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 15.3, "tree_w": 41, "tree_size": 256, "t0": 2.2467, "t1": 0.8633, "tft": 3.9915, "input_0": 901, "input_1": 257, "min_CLP": -6.27, "draft_iters": 16.7, "mem_use": 42.15, "gen_rate": 14.0, "speed": 4.5, "text": "Cryptocurrencies have come a lon"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 51, "tree_size": 256, "t0": 1.732, "t1": 0.87, "tft": 4.0158, "input_0": 686, "input_1": 257, "min_CLP": -6.23, "draft_iters": 12.2, "mem_use": 42.68, "gen_rate": 6.6, "speed": 2.53, "text": "Theanine can help you relax and "}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 20.2, "tree_w": 38, "tree_size": 256, "t0": 2.8025, "t1": 0.87, "tft": 3.2708, "input_0": 1011, "input_1": 257, "min_CLP": -6.25, "draft_iters": 21.8, "mem_use": 42.45, "gen_rate": 14.8, "speed": 4.02, "text": "Here\\'s an example of how you ca"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 28, "tree_size": 256, "t0": 3.43, "t1": 0.86, "tft": 4.0658, "input_0": 856, "input_1": 257, "min_CLP": -9.14, "draft_iters": 32.0, "mem_use": 42.23, "gen_rate": 33.0, "speed": 7.68, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.5, "tree_w": 46, "tree_size": 256, "t0": 1.73, "t1": 0.87, "tft": 3.0814, "input_0": 641, "input_1": 257, "min_CLP": -6.23, "draft_iters": 13.5, "mem_use": 42.2, "gen_rate": 8.0, "speed": 3.08, "text": "You cannot see the stars in the "}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.0, "tree_w": 50, "tree_size": 256, "t0": 1.808, "t1": 0.87, "tft": 3.2975, "input_0": 623, "input_1": 257, "min_CLP": -6.14, "draft_iters": 15.0, "mem_use": 42.76, "gen_rate": 6.6, "speed": 2.46, "text": "The image of Bliss was chosen as"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 54, "tree_size": 256, "t0": 1.49, "t1": 0.9, "tft": 4.2649, "input_0": 655, "input_1": 257, "min_CLP": -6.3, "draft_iters": 10.6, "mem_use": 45.81, "gen_rate": 6.8, "speed": 2.85, "text": "\"I'm sorry, but that would not b"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 12.7, "tree_w": 56, "tree_size": 256, "t0": 1.8967, "t1": 0.8883, "tft": 5.2418, "input_0": 724, "input_1": 257, "min_CLP": -6.32, "draft_iters": 14.2, "mem_use": 44.56, "gen_rate": 7.8, "speed": 2.81, "text": "\"It's possible that we didn't ha"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.7, "tree_w": 54, "tree_size": 256, "t0": 1.82, "t1": 0.87, "tft": 4.2997, "input_0": 738, "input_1": 257, "min_CLP": -6.45, "draft_iters": 13.0, "mem_use": 42.82, "gen_rate": 5.5, "speed": 2.04, "text": "\"Building a Dyson sphere would r"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 256, "t0": 3.75, "t1": 0.86, "tft": 2.6141, "input_0": 1313, "input_1": 257, "min_CLP": -9.52, "draft_iters": 32.0, "mem_use": 42.15, "gen_rate": 33.0, "speed": 7.15, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.5, "tree_w": 45, "tree_size": 256, "t0": 1.6567, "t1": 0.8667, "tft": 4.0988, "input_0": 662, "input_1": 257, "min_CLP": -6.19, "draft_iters": 12.5, "mem_use": 42.14, "gen_rate": 6.7, "speed": 2.64, "text": "Yes, I can speak German to a cer"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 27.0, "tree_w": 50, "tree_size": 256, "t0": 2.7, "t1": 0.87, "tft": 2.3154, "input_0": 591, "input_1": 257, "min_CLP": -6.62, "draft_iters": 28.0, "mem_use": 42.34, "gen_rate": 23.0, "speed": 6.45, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.8, "tree_w": 40, "tree_size": 256, "t0": 2.07, "t1": 0.87, "tft": 3.3149, "input_0": 827, "input_1": 257, "min_CLP": -5.99, "draft_iters": 14.8, "mem_use": 43.26, "gen_rate": 6.4, "speed": 2.18, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.4, "tree_w": 41, "tree_size": 256, "t0": 1.976, "t1": 0.88, "tft": 4.479, "input_0": 798, "input_1": 257, "min_CLP": -6.0, "draft_iters": 14.8, "mem_use": 43.84, "gen_rate": 6.8, "speed": 2.38, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 69, "tree_size": 256, "t0": 1.478, "t1": 0.87, "tft": 3.0308, "input_0": 575, "input_1": 257, "min_CLP": -6.64, "draft_iters": 11.2, "mem_use": 42.2, "gen_rate": 6.8, "speed": 2.9, "text": "\"Certainly! Here are some haikus"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 17.6, "tree_w": 65, "tree_size": 256, "t0": 2.042, "t1": 0.872, "tft": 2.7022, "input_0": 580, "input_1": 257, "min_CLP": -6.59, "draft_iters": 18.6, "mem_use": 42.56, "gen_rate": 7.0, "speed": 2.4, "text": "\"o\\n    /|\\\\\\n    / \\\\\\n    / \\\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 256, "t0": 3.57, "t1": 0.86, "tft": 2.5439, "input_0": 926, "input_1": 257, "min_CLP": -6.69, "draft_iters": 32.0, "mem_use": 42.15, "gen_rate": 33.0, "speed": 7.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 18.2, "tree_w": 38, "tree_size": 256, "t0": 2.3, "t1": 0.875, "tft": 2.724, "input_0": 898, "input_1": 257, "min_CLP": -6.14, "draft_iters": 19.2, "mem_use": 42.51, "gen_rate": 10.0, "speed": 3.15, "text": "Yes, there is a true, most ethic"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.8, "tree_w": 52, "tree_size": 256, "t0": 1.905, "t1": 0.8733, "tft": 2.7349, "input_0": 719, "input_1": 257, "min_CLP": -6.17, "draft_iters": 15.0, "mem_use": 42.43, "gen_rate": 6.3, "speed": 2.28, "text": "\"To help you with that, I'll nee"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 21.5, "tree_w": 50, "tree_size": 256, "t0": 2.505, "t1": 0.885, "tft": 4.2031, "input_0": 753, "input_1": 257, "min_CLP": -6.52, "draft_iters": 22.5, "mem_use": 44.48, "gen_rate": 7.2, "speed": 2.11, "text": "\"[INST] OK, I'm ready chef! What"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 57, "tree_size": 256, "t0": 2.98, "t1": 0.87, "tft": 2.2517, "input_0": 593, "input_1": 257, "min_CLP": -7.69, "draft_iters": 32.0, "mem_use": 42.32, "gen_rate": 33.0, "speed": 8.58, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 12.0, "tree_w": 38, "tree_size": 256, "t0": 2.05, "t1": 0.9, "tft": 4.7176, "input_0": 800, "input_1": 257, "min_CLP": -5.97, "draft_iters": 14.0, "mem_use": 45.18, "gen_rate": 5.0, "speed": 1.69, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 16.5, "tree_w": 43, "tree_size": 256, "t0": 2.1725, "t1": 0.8675, "tft": 2.5842, "input_0": 673, "input_1": 257, "min_CLP": -5.99, "draft_iters": 17.8, "mem_use": 42.19, "gen_rate": 11.8, "speed": 3.87, "text": "Sure, here is an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.5, "tree_w": 33, "tree_size": 256, "t0": 2.1925, "t1": 0.87, "tft": 2.6032, "input_0": 783, "input_1": 257, "min_CLP": -5.89, "draft_iters": 17.5, "mem_use": 42.15, "gen_rate": 9.5, "speed": 3.1, "text": "\"HTML (HyperText Markup Language"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 30, "tree_size": 256, "t0": 2.92, "t1": 0.87, "tft": 2.2973, "input_0": 867, "input_1": 257, "min_CLP": -6.0, "draft_iters": 25.0, "mem_use": 42.17, "gen_rate": 24.5, "speed": 6.46, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 11.9, "tree_w": 52, "tree_size": 256, "t0": 1.7086, "t1": 0.88, "tft": 2.8547, "input_0": 631, "input_1": 257, "min_CLP": -6.4, "draft_iters": 13.0, "mem_use": 42.54, "gen_rate": 5.9, "speed": 2.26, "text": "\"I'm not a lawyer, but it's best"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 32, "tree_size": 256, "t0": 3.185, "t1": 0.87, "tft": 2.4319, "input_0": 1022, "input_1": 257, "min_CLP": -8.07, "draft_iters": 26.0, "mem_use": 42.16, "gen_rate": 26.0, "speed": 6.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 24.0, "tree_w": 24, "tree_size": 256, "t0": 2.94, "t1": 0.8767, "tft": 4.7971, "input_0": 930, "input_1": 257, "min_CLP": -5.7, "draft_iters": 25.0, "mem_use": 43.25, "gen_rate": 13.0, "speed": 3.41, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 13.3, "tree_w": 58, "tree_size": 256, "t0": 1.8471, "t1": 0.8729, "tft": 4.2718, "input_0": 694, "input_1": 257, "min_CLP": -6.3, "draft_iters": 14.6, "mem_use": 42.93, "gen_rate": 4.6, "speed": 1.68, "text": "Thank you for providing more inf"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.2, "tree_w": 86, "tree_size": 256, "t0": 1.2144, "t1": 0.8789, "tft": 4.2117, "input_0": 474, "input_1": 257, "min_CLP": -6.7, "draft_iters": 9.4, "mem_use": 42.77, "gen_rate": 3.7, "speed": 1.75, "text": "\"You're right, but the differenc"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 17.0, "tree_w": 49, "tree_size": 256, "t0": 2.115, "t1": 0.8783, "tft": 3.1232, "input_0": 700, "input_1": 257, "min_CLP": -6.02, "draft_iters": 18.2, "mem_use": 43.53, "gen_rate": 5.5, "speed": 1.84, "text": "Great! I understand that you wan"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 30, "tree_size": 256, "t0": 3.35, "t1": 0.86, "tft": 2.0984, "input_0": 841, "input_1": 257, "min_CLP": -8.24, "draft_iters": 32.0, "mem_use": 42.13, "gen_rate": 33.0, "speed": 7.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.8, "tree_w": 51, "tree_size": 256, "t0": 1.482, "t1": 0.876, "tft": 3.5081, "input_0": 600, "input_1": 257, "min_CLP": -6.48, "draft_iters": 11.0, "mem_use": 42.45, "gen_rate": 7.2, "speed": 3.05, "text": "I\\'ve been called a variety of n"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 18.5, "tree_w": 32, "tree_size": 256, "t0": 2.38, "t1": 0.87, "tft": 3.7733, "input_0": 835, "input_1": 257, "min_CLP": -6.37, "draft_iters": 20.0, "mem_use": 43.24, "gen_rate": 18.0, "speed": 5.53, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.4, "tree_w": 83, "tree_size": 256, "t0": 1.2575, "t1": 0.865, "tft": 2.7081, "input_0": 537, "input_1": 257, "min_CLP": -6.63, "draft_iters": 8.9, "mem_use": 42.25, "gen_rate": 4.0, "speed": 1.88, "text": "\"Motion Matching is a smart way "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 31.0, "tree_w": 14, "tree_size": 256, "t0": 3.715, "t1": 0.89, "tft": 5.2545, "input_0": 1065, "input_1": 257, "min_CLP": -5.35, "draft_iters": 32.0, "mem_use": 43.9, "gen_rate": 18.5, "speed": 4.02, "text": "\"Sure, here's an updated script "}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.7, "tree_w": 65, "tree_size": 256, "t0": 1.4883, "t1": 0.8733, "tft": 2.2647, "input_0": 647, "input_1": 257, "min_CLP": -6.8, "draft_iters": 10.7, "mem_use": 42.2, "gen_rate": 5.3, "speed": 2.26, "text": "C# l\u00e0 m\u1ed9t ng\u00f4n ng\u1eef l\u1eadp tr\u00ecnh h\u01b0\u1edb"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.7, "tree_w": 57, "tree_size": 256, "t0": 1.7317, "t1": 0.88, "tft": 2.6585, "input_0": 673, "input_1": 257, "min_CLP": -6.54, "draft_iters": 12.8, "mem_use": 42.58, "gen_rate": 6.2, "speed": 2.36, "text": "\"Sure! Here's a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 15.2, "tree_w": 37, "tree_size": 256, "t0": 2.2925, "t1": 0.89, "tft": 4.2675, "input_0": 920, "input_1": 257, "min_CLP": -6.19, "draft_iters": 16.5, "mem_use": 43.91, "gen_rate": 10.2, "speed": 3.22, "text": "The concept of 100 monkeys on a "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 44, "tree_size": 256, "t0": 1.6375, "t1": 0.8825, "tft": 4.3989, "input_0": 657, "input_1": 257, "min_CLP": -6.08, "draft_iters": 12.2, "mem_use": 44.34, "gen_rate": 8.0, "speed": 3.18, "text": "\"Paul Allen's plane collection i"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.8, "tree_w": 45, "tree_size": 256, "t0": 1.99, "t1": 0.886, "tft": 4.2271, "input_0": 790, "input_1": 257, "min_CLP": -6.16, "draft_iters": 14.8, "mem_use": 43.79, "gen_rate": 7.8, "speed": 2.71, "text": "Yes, there is a similar case in "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 22.0, "tree_w": 36, "tree_size": 256, "t0": 2.6567, "t1": 0.87, "tft": 2.3013, "input_0": 783, "input_1": 257, "min_CLP": -6.24, "draft_iters": 23.3, "mem_use": 42.23, "gen_rate": 11.7, "speed": 3.3, "text": "\"Here's my attempt at writing an"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 50, "tree_size": 256, "t0": 1.7125, "t1": 0.88, "tft": 4.3487, "input_0": 710, "input_1": 257, "min_CLP": -6.1, "draft_iters": 12.2, "mem_use": 42.85, "gen_rate": 8.2, "speed": 3.18, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 17.0, "tree_w": 45, "tree_size": 256, "t0": 2.268, "t1": 0.868, "tft": 3.536, "input_0": 763, "input_1": 257, "min_CLP": -6.12, "draft_iters": 18.4, "mem_use": 42.26, "gen_rate": 6.6, "speed": 2.1, "text": "The main methods car manufacture"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 49, "tree_size": 256, "t0": 1.5675, "t1": 0.8725, "tft": 2.5994, "input_0": 634, "input_1": 257, "min_CLP": -6.11, "draft_iters": 11.5, "mem_use": 42.15, "gen_rate": 8.2, "speed": 3.38, "text": "No, the 5-second rule is a myth."}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 18.8, "tree_w": 40, "tree_size": 256, "t0": 2.418, "t1": 0.874, "tft": 3.3474, "input_0": 847, "input_1": 257, "min_CLP": -5.98, "draft_iters": 20.0, "mem_use": 43.02, "gen_rate": 6.8, "speed": 2.07, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 34, "tree_size": 256, "t0": 2.44, "t1": 0.8833, "tft": 4.3392, "input_0": 892, "input_1": 257, "min_CLP": -5.86, "draft_iters": 19.0, "mem_use": 43.82, "gen_rate": 11.0, "speed": 3.31, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.3, "tree_w": 66, "tree_size": 256, "t0": 1.485, "t1": 0.89, "tft": 4.9586, "input_0": 602, "input_1": 257, "min_CLP": -6.36, "draft_iters": 10.5, "mem_use": 44.7, "gen_rate": 6.3, "speed": 2.67, "text": "The \"multi-track drifting\" solut"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.2, "tree_w": 44, "tree_size": 256, "t0": 2.2725, "t1": 0.88, "tft": 3.7135, "input_0": 969, "input_1": 257, "min_CLP": -6.21, "draft_iters": 15.0, "mem_use": 43.33, "gen_rate": 9.2, "speed": 2.94, "text": "\"It is theoretically possible to"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 3.27, "t1": 0.87, "tft": 4.7471, "input_0": 840, "input_1": 257, "min_CLP": -6.54, "draft_iters": 32.0, "mem_use": 43.17, "gen_rate": 33.0, "speed": 7.97, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 49, "tree_size": 256, "t0": 2.2775, "t1": 0.8775, "tft": 3.8822, "input_0": 888, "input_1": 257, "min_CLP": -6.44, "draft_iters": 16.2, "mem_use": 42.9, "gen_rate": 8.0, "speed": 2.54, "text": "Here are the Japanese translatio"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 15.2, "tree_w": 42, "tree_size": 256, "t0": 2.148, "t1": 0.878, "tft": 3.5566, "input_0": 812, "input_1": 257, "min_CLP": -6.25, "draft_iters": 16.6, "mem_use": 42.44, "gen_rate": 9.0, "speed": 2.98, "text": "In the UK, the University of Oxf"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.0, "tree_w": 43, "tree_size": 256, "t0": 2.082, "t1": 0.87, "tft": 2.3087, "input_0": 835, "input_1": 257, "min_CLP": -5.98, "draft_iters": 15.2, "mem_use": 42.13, "gen_rate": 7.4, "speed": 2.51, "text": "\"The sky appears blue to us beca"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 35, "tree_size": 256, "t0": 3.3, "t1": 0.87, "tft": 2.9704, "input_0": 800, "input_1": 257, "min_CLP": -5.8, "draft_iters": 32.0, "mem_use": 42.26, "gen_rate": 32.0, "speed": 7.67, "text": "\"Here's a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 65, "tree_size": 256, "t0": 1.515, "t1": 0.88, "tft": 3.7645, "input_0": 579, "input_1": 257, "min_CLP": -6.31, "draft_iters": 11.3, "mem_use": 43.42, "gen_rate": 5.5, "speed": 2.3, "text": "1. Financial stress can be addre"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 64, "tree_h": 13.9, "tree_w": 56, "tree_size": 256, "t0": 1.8411, "t1": 0.8711, "tft": 2.0072, "input_0": 620, "input_1": 257, "min_CLP": -6.55, "draft_iters": 15.0, "mem_use": 42.13, "gen_rate": 7.1, "speed": 2.62, "text": "[INST] I am an artist. I want to"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.5, "tree_w": 26, "tree_size": 256, "t0": 2.925, "t1": 0.885, "tft": 5.4416, "input_0": 995, "input_1": 257, "min_CLP": -5.64, "draft_iters": 22.5, "mem_use": 44.8, "gen_rate": 16.0, "speed": 4.2, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.5, "tree_w": 52, "tree_size": 256, "t0": 1.7833, "t1": 0.8767, "tft": 3.2085, "input_0": 604, "input_1": 257, "min_CLP": -6.31, "draft_iters": 14.7, "mem_use": 42.42, "gen_rate": 5.3, "speed": 2.01, "text": "<|bot|> Yes, hairy bittercress i"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 28, "tree_h": 9.0, "tree_w": 76, "tree_size": 256, "t0": 1.3363, "t1": 0.8713, "tft": 2.5575, "input_0": 503, "input_1": 257, "min_CLP": -7.06, "draft_iters": 10.0, "mem_use": 42.21, "gen_rate": 3.5, "speed": 1.58, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 18.8, "tree_w": 34, "tree_size": 256, "t0": 2.582, "t1": 0.89, "tft": 5.6309, "input_0": 953, "input_1": 257, "min_CLP": -5.97, "draft_iters": 20.0, "mem_use": 44.4, "gen_rate": 7.4, "speed": 2.13, "text": "Yes, here are some additional op"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 23.0, "tree_w": 24, "tree_size": 256, "t0": 2.895, "t1": 0.875, "tft": 3.5835, "input_0": 918, "input_1": 257, "min_CLP": -5.81, "draft_iters": 24.5, "mem_use": 42.2, "gen_rate": 17.0, "speed": 4.51, "text": "\"To use software defined radio ("}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 18.2, "tree_w": 57, "tree_size": 256, "t0": 2.146, "t1": 0.878, "tft": 4.4344, "input_0": 622, "input_1": 257, "min_CLP": -6.16, "draft_iters": 19.2, "mem_use": 42.9, "gen_rate": 7.2, "speed": 2.38, "text": "No, the Unus Annus Trolley Probl"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.74, "t1": 0.88, "tft": 4.9869, "input_0": 1157, "input_1": 257, "min_CLP": -7.24, "draft_iters": 32.0, "mem_use": 43.8, "gen_rate": 33.0, "speed": 7.14, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 59, "tree_size": 256, "t0": 1.732, "t1": 0.878, "tft": 2.8487, "input_0": 684, "input_1": 257, "min_CLP": -6.4, "draft_iters": 12.8, "mem_use": 42.45, "gen_rate": 6.4, "speed": 2.45, "text": "\"I'm here to help you, and I'm e"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 24.7, "tree_w": 33, "tree_size": 256, "t0": 2.79, "t1": 0.8933, "tft": 5.0703, "input_0": 781, "input_1": 257, "min_CLP": -5.64, "draft_iters": 25.7, "mem_use": 45.22, "gen_rate": 15.3, "speed": 4.16, "text": "I apologize for the incorrect in"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 17.2, "tree_w": 32, "tree_size": 256, "t0": 2.31, "t1": 0.87, "tft": 2.4685, "input_0": 798, "input_1": 257, "min_CLP": -5.97, "draft_iters": 18.2, "mem_use": 42.17, "gen_rate": 9.2, "speed": 2.89, "text": "\"To format an URL in ReStructure"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 25.0, "tree_w": 20, "tree_size": 256, "t0": 3.2667, "t1": 0.8833, "tft": 4.7996, "input_0": 1115, "input_1": 257, "min_CLP": -5.55, "draft_iters": 26.3, "mem_use": 44.19, "gen_rate": 17.3, "speed": 4.18, "text": "\"Here's an example code for sett"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.8, "tree_w": 40, "tree_size": 256, "t0": 2.104, "t1": 0.87, "tft": 2.907, "input_0": 737, "input_1": 257, "min_CLP": -6.04, "draft_iters": 17.0, "mem_use": 42.15, "gen_rate": 6.8, "speed": 2.29, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 77, "tree_size": 256, "t0": 1.3543, "t1": 0.8786, "tft": 4.1729, "input_0": 565, "input_1": 257, "min_CLP": -6.71, "draft_iters": 9.4, "mem_use": 42.6, "gen_rate": 4.7, "speed": 2.11, "text": "\"It's hard to say if AI assistan"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 55, "tree_size": 256, "t0": 1.6925, "t1": 0.93, "tft": 7.5195, "input_0": 599, "input_1": 257, "min_CLP": -6.47, "draft_iters": 13.0, "mem_use": 47.76, "gen_rate": 8.5, "speed": 3.24, "text": "\"Sure, I'd be happy to help. Her"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 71, "tree_size": 256, "t0": 1.45, "t1": 0.878, "tft": 4.337, "input_0": 560, "input_1": 257, "min_CLP": -6.71, "draft_iters": 10.8, "mem_use": 43.01, "gen_rate": 6.4, "speed": 2.75, "text": "0 It is an organization that pro"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 1.7825, "t1": 0.885, "tft": 4.2767, "input_0": 770, "input_1": 257, "min_CLP": -6.28, "draft_iters": 12.0, "mem_use": 44.83, "gen_rate": 8.2, "speed": 3.09, "text": "I understand where you\\'re comin"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.0, "tree_w": 61, "tree_size": 256, "t0": 1.4886, "t1": 0.8714, "tft": 4.7927, "input_0": 609, "input_1": 257, "min_CLP": -6.4, "draft_iters": 11.0, "mem_use": 43.23, "gen_rate": 5.3, "speed": 2.24, "text": "\"1. Location: The restaurant's l"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 57, "tree_size": 256, "t0": 1.558, "t1": 0.878, "tft": 2.5927, "input_0": 614, "input_1": 257, "min_CLP": -6.37, "draft_iters": 10.8, "mem_use": 42.48, "gen_rate": 6.6, "speed": 2.71, "text": "Here is a script for an inspirat"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 28.5, "tree_w": 20, "tree_size": 256, "t0": 3.705, "t1": 0.88, "tft": 5.3864, "input_0": 1189, "input_1": 257, "min_CLP": -5.7, "draft_iters": 30.0, "mem_use": 44.96, "gen_rate": 17.0, "speed": 3.71, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.8, "tree_w": 35, "tree_size": 256, "t0": 2.16, "t1": 0.88, "tft": 3.1367, "input_0": 762, "input_1": 257, "min_CLP": -6.19, "draft_iters": 17.0, "mem_use": 42.66, "gen_rate": 6.6, "speed": 2.17, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.8, "tree_w": 35, "tree_size": 256, "t0": 2.3075, "t1": 0.8825, "tft": 4.7696, "input_0": 879, "input_1": 257, "min_CLP": -5.95, "draft_iters": 17.5, "mem_use": 44.63, "gen_rate": 10.0, "speed": 3.14, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.7, "tree_w": 39, "tree_size": 256, "t0": 2.43, "t1": 0.8667, "tft": 3.1086, "input_0": 915, "input_1": 257, "min_CLP": -5.82, "draft_iters": 20.0, "mem_use": 42.18, "gen_rate": 11.0, "speed": 3.34, "text": "Sure! Below is an implementation"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 10.0, "tree_w": 68, "tree_size": 256, "t0": 1.475, "t1": 0.87, "tft": 3.3043, "input_0": 652, "input_1": 257, "min_CLP": -6.4, "draft_iters": 11.0, "mem_use": 42.91, "gen_rate": 4.5, "speed": 1.92, "text": "In 2019, the law was created."}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 3.42, "t1": 0.86, "tft": 4.1182, "input_0": 910, "input_1": 257, "min_CLP": -7.68, "draft_iters": 32.0, "mem_use": 42.63, "gen_rate": 33.0, "speed": 7.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 256, "t0": 3.59, "t1": 0.87, "tft": 3.4927, "input_0": 1181, "input_1": 257, "min_CLP": -9.79, "draft_iters": 32.0, "mem_use": 42.22, "gen_rate": 33.0, "speed": 7.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.8, "tree_w": 48, "tree_size": 256, "t0": 1.7775, "t1": 0.8775, "tft": 3.2591, "input_0": 675, "input_1": 257, "min_CLP": -6.11, "draft_iters": 14.0, "mem_use": 43.15, "gen_rate": 9.0, "speed": 3.39, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 28.5, "tree_w": 25, "tree_size": 256, "t0": 3.445, "t1": 0.885, "tft": 4.8653, "input_0": 1058, "input_1": 257, "min_CLP": -6.11, "draft_iters": 29.0, "mem_use": 44.71, "gen_rate": 26.0, "speed": 6.0, "text": "\"Sure, here's a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 16.5, "tree_w": 43, "tree_size": 256, "t0": 2.015, "t1": 0.87, "tft": 2.6648, "input_0": 610, "input_1": 257, "min_CLP": -6.35, "draft_iters": 17.5, "mem_use": 42.34, "gen_rate": 5.5, "speed": 1.91, "text": "The total travel time is 23.5 ho"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 25.7, "tree_w": 21, "tree_size": 256, "t0": 3.3833, "t1": 0.86, "tft": 2.4889, "input_0": 1201, "input_1": 257, "min_CLP": -5.76, "draft_iters": 26.7, "mem_use": 42.25, "gen_rate": 13.0, "speed": 3.06, "text": "\"```js\\nconst { Client, GatewayI"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.0, "tree_w": 38, "tree_size": 256, "t0": 2.0067, "t1": 0.8667, "tft": 3.6651, "input_0": 664, "input_1": 257, "min_CLP": -6.06, "draft_iters": 17.0, "mem_use": 42.15, "gen_rate": 12.7, "speed": 4.41, "text": "No, I am not as capable as ChatG"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.0, "tree_w": 42, "tree_size": 256, "t0": 1.9275, "t1": 0.905, "tft": 4.5482, "input_0": 723, "input_1": 257, "min_CLP": -6.04, "draft_iters": 14.2, "mem_use": 45.92, "gen_rate": 9.5, "speed": 3.35, "text": "\"TypeScript is a superset of Jav"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 30, "tree_h": 28.2, "tree_w": 40, "tree_size": 256, "t0": 3.122, "t1": 0.87, "tft": 2.9497, "input_0": 856, "input_1": 257, "min_CLP": -6.45, "draft_iters": 29.0, "mem_use": 42.26, "gen_rate": 6.0, "speed": 1.5, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.9, "tree_w": 103, "tree_size": 256, "t0": 1.3612, "t1": 0.8788, "tft": 3.182, "input_0": 452, "input_1": 257, "min_CLP": -7.22, "draft_iters": 11.0, "mem_use": 43.34, "gen_rate": 4.5, "speed": 2.01, "text": "[INST] Kill the villagers and gi"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 39, "tree_size": 256, "t0": 2.215, "t1": 0.8925, "tft": 5.7852, "input_0": 916, "input_1": 257, "min_CLP": -5.98, "draft_iters": 15.5, "mem_use": 45.07, "gen_rate": 8.5, "speed": 2.73, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 59, "tree_size": 256, "t0": 1.5933, "t1": 0.8733, "tft": 2.9345, "input_0": 614, "input_1": 257, "min_CLP": -6.22, "draft_iters": 11.5, "mem_use": 42.4, "gen_rate": 5.3, "speed": 2.16, "text": "\"It's great that you're taking a"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 14, "tree_h": 21.0, "tree_w": 47, "tree_size": 256, "t0": 2.62, "t1": 0.875, "tft": 3.0451, "input_0": 826, "input_1": 257, "min_CLP": -6.35, "draft_iters": 23.0, "mem_use": 42.9, "gen_rate": 3.5, "speed": 1.0, "text": "\"You're welcome! Don't hesitate "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 18.0, "tree_w": 40, "tree_size": 256, "t0": 2.68, "t1": 0.885, "tft": 5.3001, "input_0": 929, "input_1": 257, "min_CLP": -6.28, "draft_iters": 19.5, "mem_use": 44.64, "gen_rate": 18.5, "speed": 5.19, "text": "\"As a high school student, there"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.0, "tree_w": 35, "tree_size": 256, "t0": 2.43, "t1": 0.88, "tft": 3.4922, "input_0": 860, "input_1": 257, "min_CLP": -5.99, "draft_iters": 19.5, "mem_use": 43.07, "gen_rate": 9.0, "speed": 2.72, "text": "The first working television was"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 16.8, "tree_w": 59, "tree_size": 256, "t0": 2.3417, "t1": 0.89, "tft": 4.2403, "input_0": 835, "input_1": 257, "min_CLP": -6.55, "draft_iters": 18.2, "mem_use": 45.36, "gen_rate": 6.5, "speed": 2.01, "text": "\"I'm glad I could help. If you h"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 14.2, "tree_w": 53, "tree_size": 256, "t0": 2.1383, "t1": 0.8817, "tft": 4.8124, "input_0": 889, "input_1": 257, "min_CLP": -6.18, "draft_iters": 15.7, "mem_use": 43.72, "gen_rate": 5.5, "speed": 1.82, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.2, "tree_w": 57, "tree_size": 256, "t0": 1.595, "t1": 0.875, "tft": 3.3453, "input_0": 620, "input_1": 257, "min_CLP": -6.45, "draft_iters": 12.3, "mem_use": 42.71, "gen_rate": 6.5, "speed": 2.63, "text": "Okay, I understand that I am an "}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 36, "tree_size": 256, "t0": 2.1375, "t1": 0.8825, "tft": 4.438, "input_0": 850, "input_1": 257, "min_CLP": -5.96, "draft_iters": 15.0, "mem_use": 44.52, "gen_rate": 10.0, "speed": 3.31, "text": "\"The most difficult parts of lea"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 22, "tree_size": 256, "t0": 3.38, "t1": 0.88, "tft": 2.5927, "input_0": 807, "input_1": 257, "min_CLP": -8.42, "draft_iters": 32.0, "mem_use": 42.34, "gen_rate": 33.0, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 15.5, "tree_w": 58, "tree_size": 256, "t0": 1.955, "t1": 0.8725, "tft": 3.5244, "input_0": 636, "input_1": 257, "min_CLP": -6.46, "draft_iters": 16.5, "mem_use": 43.0, "gen_rate": 4.5, "speed": 1.59, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.1, "tree_w": 77, "tree_size": 256, "t0": 1.3233, "t1": 0.8767, "tft": 3.439, "input_0": 546, "input_1": 257, "min_CLP": -6.88, "draft_iters": 9.6, "mem_use": 42.43, "gen_rate": 3.6, "speed": 1.62, "text": "\"Ah, you're a college student li"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 39, "tree_size": 256, "t0": 3.02, "t1": 0.87, "tft": 3.7738, "input_0": 645, "input_1": 257, "min_CLP": -8.02, "draft_iters": 32.0, "mem_use": 42.45, "gen_rate": 33.0, "speed": 8.48, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 57, "tree_size": 256, "t0": 1.666, "t1": 0.878, "tft": 4.2469, "input_0": 664, "input_1": 257, "min_CLP": -6.36, "draft_iters": 12.4, "mem_use": 42.83, "gen_rate": 7.0, "speed": 2.75, "text": "Google Authenticator is an app t"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.8, "tree_w": 45, "tree_size": 256, "t0": 1.952, "t1": 0.87, "tft": 3.1859, "input_0": 739, "input_1": 257, "min_CLP": -6.08, "draft_iters": 15.0, "mem_use": 42.61, "gen_rate": 6.6, "speed": 2.34, "text": "Prime numbers have many practica"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.2, "tree_w": 35, "tree_size": 256, "t0": 2.5075, "t1": 0.87, "tft": 2.774, "input_0": 976, "input_1": 257, "min_CLP": -5.76, "draft_iters": 19.2, "mem_use": 42.38, "gen_rate": 10.2, "speed": 3.04, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 17.8, "tree_w": 36, "tree_size": 256, "t0": 2.525, "t1": 0.87, "tft": 2.9615, "input_0": 930, "input_1": 257, "min_CLP": -6.11, "draft_iters": 19.5, "mem_use": 42.23, "gen_rate": 11.0, "speed": 3.24, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 23.5, "tree_w": 61, "tree_size": 256, "t0": 2.52, "t1": 0.865, "tft": 2.3035, "input_0": 647, "input_1": 257, "min_CLP": -6.7, "draft_iters": 24.5, "mem_use": 42.26, "gen_rate": 17.5, "speed": 5.17, "text": "```spl\\n<<SYS>>\\nYou are a helpf"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 14.5, "tree_w": 50, "tree_size": 256, "t0": 2.075, "t1": 0.8683, "tft": 2.1515, "input_0": 764, "input_1": 257, "min_CLP": -6.24, "draft_iters": 16.0, "mem_use": 42.17, "gen_rate": 6.8, "speed": 2.32, "text": "Title: Revolutionizing Hedge Fun"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.7, "tree_w": 41, "tree_size": 256, "t0": 2.1867, "t1": 0.8733, "tft": 3.7094, "input_0": 826, "input_1": 257, "min_CLP": -6.07, "draft_iters": 17.3, "mem_use": 43.39, "gen_rate": 12.7, "speed": 4.14, "text": "\"In that case, you can use your "}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 16.2, "tree_w": 35, "tree_size": 256, "t0": 2.238, "t1": 0.868, "tft": 2.6358, "input_0": 820, "input_1": 257, "min_CLP": -5.92, "draft_iters": 17.2, "mem_use": 42.13, "gen_rate": 9.2, "speed": 2.96, "text": "In Python, the \"@\" symbol has tw"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.0, "tree_w": 42, "tree_size": 256, "t0": 2.02, "t1": 0.865, "tft": 2.5519, "input_0": 782, "input_1": 257, "min_CLP": -5.96, "draft_iters": 15.2, "mem_use": 42.15, "gen_rate": 9.0, "speed": 3.12, "text": "I think ChatGPT is an incredibly"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 11.3, "tree_w": 59, "tree_size": 256, "t0": 1.8086, "t1": 0.88, "tft": 2.273, "input_0": 709, "input_1": 257, "min_CLP": -6.29, "draft_iters": 12.9, "mem_use": 42.45, "gen_rate": 5.6, "speed": 2.07, "text": "\"I would approach the task by fi"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 14.0, "tree_w": 68, "tree_size": 256, "t0": 1.762, "t1": 0.87, "tft": 2.1194, "input_0": 594, "input_1": 257, "min_CLP": -6.7, "draft_iters": 15.2, "mem_use": 42.18, "gen_rate": 9.6, "speed": 3.65, "text": "\"[INST] Don't forget to use the "}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 256, "t0": 3.33, "t1": 0.88, "tft": 4.3063, "input_0": 777, "input_1": 257, "min_CLP": -8.08, "draft_iters": 32.0, "mem_use": 42.88, "gen_rate": 33.0, "speed": 7.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.8, "tree_w": 68, "tree_size": 256, "t0": 1.6883, "t1": 0.8983, "tft": 4.9146, "input_0": 674, "input_1": 257, "min_CLP": -6.5, "draft_iters": 12.3, "mem_use": 45.39, "gen_rate": 5.8, "speed": 2.26, "text": "Here are some of the neural netw"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.8, "tree_w": 40, "tree_size": 256, "t0": 2.126, "t1": 0.878, "tft": 3.2299, "input_0": 813, "input_1": 257, "min_CLP": -5.95, "draft_iters": 15.2, "mem_use": 42.69, "gen_rate": 7.8, "speed": 2.6, "text": "Decorators in Python can do thin"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 20, "tree_h": 12.5, "tree_w": 53, "tree_size": 256, "t0": 1.965, "t1": 0.89, "tft": 3.7501, "input_0": 790, "input_1": 257, "min_CLP": -6.11, "draft_iters": 14.0, "mem_use": 43.83, "gen_rate": 10.0, "speed": 3.51, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 14, "tree_h": 11.7, "tree_w": 93, "tree_size": 256, "t0": 1.7, "t1": 0.8783, "tft": 3.6193, "input_0": 623, "input_1": 257, "min_CLP": -7.36, "draft_iters": 13.3, "mem_use": 42.68, "gen_rate": 2.3, "speed": 0.9, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 23.8, "tree_w": 27, "tree_size": 256, "t0": 3.0525, "t1": 0.895, "tft": 6.0953, "input_0": 1017, "input_1": 257, "min_CLP": -5.69, "draft_iters": 25.0, "mem_use": 45.57, "gen_rate": 8.2, "speed": 2.09, "text": "Sure! Here are some code example"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 25.0, "tree_w": 23, "tree_size": 256, "t0": 3.21, "t1": 0.9675, "tft": 9.5001, "input_0": 1080, "input_1": 257, "min_CLP": -5.82, "draft_iters": 26.0, "mem_use": 51.59, "gen_rate": 11.0, "speed": 2.63, "text": "\"Sure! Here's an example code fo"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 12.8, "tree_w": 53, "tree_size": 256, "t0": 1.795, "t1": 0.89, "tft": 5.2721, "input_0": 670, "input_1": 257, "min_CLP": -6.39, "draft_iters": 14.0, "mem_use": 43.94, "gen_rate": 10.2, "speed": 3.82, "text": "\"The average person might encoun"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.5, "tree_w": 50, "tree_size": 256, "t0": 1.9125, "t1": 0.87, "tft": 2.3632, "input_0": 687, "input_1": 257, "min_CLP": -6.09, "draft_iters": 15.0, "mem_use": 42.19, "gen_rate": 8.0, "speed": 2.87, "text": "Sure, here are some tips to help"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.0, "tree_w": 38, "tree_size": 256, "t0": 2.3575, "t1": 0.8725, "tft": 2.3423, "input_0": 819, "input_1": 257, "min_CLP": -6.01, "draft_iters": 19.2, "mem_use": 42.3, "gen_rate": 8.2, "speed": 2.55, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.8, "tree_w": 43, "tree_size": 256, "t0": 2.25, "t1": 0.8975, "tft": 5.2597, "input_0": 833, "input_1": 257, "min_CLP": -6.05, "draft_iters": 16.5, "mem_use": 45.08, "gen_rate": 8.8, "speed": 2.78, "text": "Of course! Here are some tips on"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.0, "tree_w": 37, "tree_size": 256, "t0": 2.24, "t1": 0.8675, "tft": 2.6751, "input_0": 785, "input_1": 257, "min_CLP": -6.21, "draft_iters": 17.2, "mem_use": 42.25, "gen_rate": 9.5, "speed": 3.06, "text": "In 1950, the world was a very di"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.3, "tree_w": 32, "tree_size": 256, "t0": 2.3667, "t1": 0.92, "tft": 5.9041, "input_0": 865, "input_1": 257, "min_CLP": -5.79, "draft_iters": 17.7, "mem_use": 47.25, "gen_rate": 12.7, "speed": 3.85, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 72, "tree_size": 256, "t0": 1.3367, "t1": 0.88, "tft": 2.8569, "input_0": 520, "input_1": 257, "min_CLP": -6.6, "draft_iters": 9.8, "mem_use": 42.59, "gen_rate": 5.7, "speed": 2.56, "text": "First install all the parts into"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.5, "tree_w": 47, "tree_size": 256, "t0": 2.1675, "t1": 0.875, "tft": 2.9413, "input_0": 936, "input_1": 257, "min_CLP": -6.3, "draft_iters": 14.8, "mem_use": 42.44, "gen_rate": 9.2, "speed": 3.04, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 60, "tree_size": 256, "t0": 1.6483, "t1": 0.8717, "tft": 4.0853, "input_0": 646, "input_1": 257, "min_CLP": -6.36, "draft_iters": 12.3, "mem_use": 42.5, "gen_rate": 6.0, "speed": 2.38, "text": "I am designed to be more accessi"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.6, "tree_w": 38, "tree_size": 256, "t0": 2.078, "t1": 0.886, "tft": 4.2228, "input_0": 766, "input_1": 257, "min_CLP": -5.91, "draft_iters": 15.8, "mem_use": 43.88, "gen_rate": 7.6, "speed": 2.57, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.8, "tree_w": 47, "tree_size": 256, "t0": 2.3725, "t1": 0.875, "tft": 2.812, "input_0": 845, "input_1": 257, "min_CLP": -6.32, "draft_iters": 18.2, "mem_use": 42.56, "gen_rate": 9.2, "speed": 2.85, "text": "The Keyhole series of spy satell"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 24, "tree_size": 256, "t0": 3.28, "t1": 0.88, "tft": 2.4878, "input_0": 749, "input_1": 257, "min_CLP": -8.14, "draft_iters": 32.0, "mem_use": 42.74, "gen_rate": 33.0, "speed": 7.94, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.2, "tree_w": 49, "tree_size": 256, "t0": 1.72, "t1": 0.875, "tft": 3.6494, "input_0": 690, "input_1": 257, "min_CLP": -6.18, "draft_iters": 12.5, "mem_use": 42.8, "gen_rate": 5.7, "speed": 2.18, "text": "Yes, you can try reducing the li"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 63, "tree_size": 256, "t0": 1.555, "t1": 0.8883, "tft": 4.2229, "input_0": 612, "input_1": 257, "min_CLP": -6.46, "draft_iters": 11.2, "mem_use": 44.73, "gen_rate": 5.8, "speed": 2.39, "text": "\u2022 GuitarLessons365: A great chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.4, "tree_w": 49, "tree_size": 256, "t0": 1.87, "t1": 0.87, "tft": 2.5657, "input_0": 757, "input_1": 257, "min_CLP": -6.22, "draft_iters": 13.6, "mem_use": 42.15, "gen_rate": 6.8, "speed": 2.48, "text": "No, stainless steel cannot be ma"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 22.2, "tree_w": 49, "tree_size": 256, "t0": 2.576, "t1": 0.87, "tft": 2.8632, "input_0": 753, "input_1": 257, "min_CLP": -6.3, "draft_iters": 23.2, "mem_use": 42.29, "gen_rate": 7.6, "speed": 2.21, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 65, "tree_size": 256, "t0": 1.52, "t1": 0.8817, "tft": 3.4674, "input_0": 609, "input_1": 257, "min_CLP": -6.53, "draft_iters": 10.8, "mem_use": 43.75, "gen_rate": 6.2, "speed": 2.57, "text": "\"Statistical modeling, it's what"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.92, "t1": 0.89, "tft": 5.3117, "input_0": 1186, "input_1": 257, "min_CLP": -8.29, "draft_iters": 32.0, "mem_use": 44.89, "gen_rate": 33.0, "speed": 6.86, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.44, "t1": 0.87, "tft": 2.1872, "input_0": 910, "input_1": 257, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 42.13, "gen_rate": 33.0, "speed": 7.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.5, "tree_w": 46, "tree_size": 256, "t0": 1.98, "t1": 0.8775, "tft": 3.7302, "input_0": 769, "input_1": 257, "min_CLP": -6.2, "draft_iters": 14.8, "mem_use": 43.64, "gen_rate": 8.0, "speed": 2.8, "text": "Yes, that\\'s a great point. The "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.3, "tree_w": 59, "tree_size": 256, "t0": 1.5543, "t1": 0.8771, "tft": 2.6032, "input_0": 548, "input_1": 257, "min_CLP": -6.58, "draft_iters": 12.4, "mem_use": 42.49, "gen_rate": 4.7, "speed": 1.94, "text": "\"To be honest, that's a bit of a"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 22.3, "tree_w": 28, "tree_size": 256, "t0": 2.76, "t1": 0.8667, "tft": 2.5221, "input_0": 967, "input_1": 257, "min_CLP": -5.89, "draft_iters": 23.3, "mem_use": 42.18, "gen_rate": 13.7, "speed": 3.76, "text": "To estimate the variance of a va"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 11.2, "tree_w": 68, "tree_size": 256, "t0": 1.545, "t1": 0.8762, "tft": 2.4655, "input_0": 543, "input_1": 257, "min_CLP": -6.65, "draft_iters": 12.4, "mem_use": 42.54, "gen_rate": 4.4, "speed": 1.81, "text": "Certainly! This reference you ar"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.7, "tree_w": 58, "tree_size": 256, "t0": 1.6167, "t1": 0.87, "tft": 2.4156, "input_0": 661, "input_1": 257, "min_CLP": -6.23, "draft_iters": 11.8, "mem_use": 42.12, "gen_rate": 5.8, "speed": 2.35, "text": "It is a complex process that inv"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 21.2, "tree_w": 38, "tree_size": 256, "t0": 2.644, "t1": 0.88, "tft": 3.6213, "input_0": 838, "input_1": 257, "min_CLP": -6.05, "draft_iters": 22.4, "mem_use": 43.49, "gen_rate": 6.8, "speed": 1.93, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 12, "tree_h": 17.7, "tree_w": 48, "tree_size": 256, "t0": 2.4667, "t1": 0.87, "tft": 2.8489, "input_0": 907, "input_1": 257, "min_CLP": -6.53, "draft_iters": 19.0, "mem_use": 42.32, "gen_rate": 4.0, "speed": 1.2, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 3.22, "t1": 0.88, "tft": 3.7737, "input_0": 693, "input_1": 257, "min_CLP": -6.4, "draft_iters": 32.0, "mem_use": 42.7, "gen_rate": 33.0, "speed": 8.05, "text": "Pacific ocean is the largest oce"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 66, "tree_size": 256, "t0": 1.4783, "t1": 0.8783, "tft": 4.2216, "input_0": 621, "input_1": 257, "min_CLP": -6.41, "draft_iters": 10.7, "mem_use": 42.94, "gen_rate": 5.8, "speed": 2.47, "text": "\"That's understandable! You can "}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 29.3, "tree_w": 17, "tree_size": 256, "t0": 3.5, "t1": 0.8733, "tft": 3.6611, "input_0": 1100, "input_1": 257, "min_CLP": -5.42, "draft_iters": 30.3, "mem_use": 42.35, "gen_rate": 20.0, "speed": 4.57, "text": "\"Here's an example of a basic Py"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 13.0, "tree_w": 43, "tree_size": 256, "t0": 2.09, "t1": 0.8775, "tft": 3.4307, "input_0": 901, "input_1": 257, "min_CLP": -6.13, "draft_iters": 14.2, "mem_use": 43.48, "gen_rate": 9.8, "speed": 3.29, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 16.7, "tree_w": 39, "tree_size": 256, "t0": 2.2333, "t1": 0.8733, "tft": 2.7382, "input_0": 808, "input_1": 257, "min_CLP": -6.07, "draft_iters": 17.8, "mem_use": 42.6, "gen_rate": 7.5, "speed": 2.41, "text": "Please make a list of the most o"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.6, "tree_w": 66, "tree_size": 256, "t0": 1.5214, "t1": 0.8657, "tft": 2.381, "input_0": 647, "input_1": 257, "min_CLP": -6.52, "draft_iters": 10.9, "mem_use": 42.13, "gen_rate": 5.0, "speed": 2.09, "text": "\"The Infinite Banking Concept is"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 22.0, "tree_w": 31, "tree_size": 256, "t0": 2.995, "t1": 0.8725, "tft": 4.0678, "input_0": 1037, "input_1": 257, "min_CLP": -5.82, "draft_iters": 23.5, "mem_use": 42.25, "gen_rate": 11.8, "speed": 3.04, "text": "\"Sure, here's an example of a hi"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 14.0, "tree_w": 62, "tree_size": 256, "t0": 1.8875, "t1": 0.875, "tft": 2.8529, "input_0": 665, "input_1": 257, "min_CLP": -6.43, "draft_iters": 15.2, "mem_use": 42.4, "gen_rate": 11.5, "speed": 4.17, "text": "They are not on a higher moral l"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 58, "tree_size": 256, "t0": 1.4333, "t1": 0.8783, "tft": 4.2938, "input_0": 600, "input_1": 257, "min_CLP": -6.56, "draft_iters": 10.5, "mem_use": 42.91, "gen_rate": 5.3, "speed": 2.31, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 15.7, "tree_w": 41, "tree_size": 256, "t0": 2.2667, "t1": 0.8867, "tft": 3.531, "input_0": 887, "input_1": 257, "min_CLP": -5.78, "draft_iters": 16.7, "mem_use": 43.79, "gen_rate": 12.7, "speed": 4.02, "text": "\"Yes, you can absolutely ask me "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.5, "tree_w": 33, "tree_size": 256, "t0": 2.2825, "t1": 0.8875, "tft": 3.9935, "input_0": 891, "input_1": 257, "min_CLP": -5.8, "draft_iters": 17.0, "mem_use": 44.31, "gen_rate": 9.8, "speed": 3.07, "text": "The ease of learning a foreign l"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 28.3, "tree_w": 21, "tree_size": 256, "t0": 3.5267, "t1": 0.8767, "tft": 4.2672, "input_0": 1125, "input_1": 257, "min_CLP": -5.96, "draft_iters": 28.7, "mem_use": 42.74, "gen_rate": 12.7, "speed": 2.87, "text": "Some of the AI tools for 2D anim"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.1, "tree_w": 50, "tree_size": 256, "t0": 1.67, "t1": 0.8771, "tft": 3.352, "input_0": 676, "input_1": 257, "min_CLP": -6.11, "draft_iters": 11.6, "mem_use": 42.6, "gen_rate": 4.9, "speed": 1.91, "text": "As an AI, I am designed to provi"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 12.2, "tree_w": 54, "tree_size": 256, "t0": 1.828, "t1": 0.874, "tft": 3.1982, "input_0": 697, "input_1": 257, "min_CLP": -6.36, "draft_iters": 13.8, "mem_use": 42.81, "gen_rate": 8.8, "speed": 3.25, "text": "It is not a matter of worth. It "}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 39, "tree_size": 256, "t0": 2.1225, "t1": 0.875, "tft": 3.476, "input_0": 884, "input_1": 257, "min_CLP": -6.01, "draft_iters": 14.5, "mem_use": 42.82, "gen_rate": 8.2, "speed": 2.75, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.2, "tree_w": 44, "tree_size": 256, "t0": 2.02, "t1": 0.87, "tft": 2.6199, "input_0": 778, "input_1": 257, "min_CLP": -5.98, "draft_iters": 14.6, "mem_use": 42.25, "gen_rate": 6.4, "speed": 2.21, "text": "Sure, I can help you design an e"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.2, "tree_w": 45, "tree_size": 256, "t0": 2.136, "t1": 0.886, "tft": 4.1105, "input_0": 867, "input_1": 257, "min_CLP": -6.26, "draft_iters": 15.4, "mem_use": 43.94, "gen_rate": 7.8, "speed": 2.58, "text": "The largest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 21.5, "tree_w": 41, "tree_size": 256, "t0": 2.5988, "t1": 0.8738, "tft": 3.5119, "input_0": 774, "input_1": 257, "min_CLP": -6.2, "draft_iters": 22.5, "mem_use": 42.4, "gen_rate": 5.8, "speed": 1.66, "text": "\"Psychomotricity\\n[INST] What ar"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 49, "tree_size": 256, "t0": 1.784, "t1": 0.87, "tft": 2.9163, "input_0": 732, "input_1": 257, "min_CLP": -6.28, "draft_iters": 13.0, "mem_use": 42.23, "gen_rate": 6.4, "speed": 2.41, "text": "Here is a list of 10 names from "}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 56, "tree_size": 256, "t0": 1.72, "t1": 0.874, "tft": 3.1287, "input_0": 614, "input_1": 257, "min_CLP": -6.19, "draft_iters": 13.6, "mem_use": 42.71, "gen_rate": 6.6, "speed": 2.55, "text": "I am an AI language model, I do "}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 15.2, "tree_w": 38, "tree_size": 256, "t0": 2.182, "t1": 0.886, "tft": 4.2906, "input_0": 851, "input_1": 257, "min_CLP": -5.95, "draft_iters": 16.6, "mem_use": 44.4, "gen_rate": 8.0, "speed": 2.61, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.6, "tree_w": 70, "tree_size": 256, "t0": 1.48, "t1": 0.8762, "tft": 2.9611, "input_0": 563, "input_1": 257, "min_CLP": -6.49, "draft_iters": 11.2, "mem_use": 43.22, "gen_rate": 4.4, "speed": 1.86, "text": "Yes, there is a similar theory i"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 37, "tree_size": 256, "t0": 2.08, "t1": 0.875, "tft": 3.8496, "input_0": 803, "input_1": 257, "min_CLP": -6.09, "draft_iters": 14.5, "mem_use": 43.64, "gen_rate": 8.2, "speed": 2.79, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 64, "tree_size": 256, "t0": 1.564, "t1": 0.868, "tft": 2.6758, "input_0": 599, "input_1": 257, "min_CLP": -6.35, "draft_iters": 12.2, "mem_use": 42.17, "gen_rate": 6.4, "speed": 2.63, "text": "\"Title: The Mathemagicians' Code"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.2, "tree_w": 38, "tree_size": 256, "t0": 2.375, "t1": 0.91, "tft": 5.5513, "input_0": 822, "input_1": 257, "min_CLP": -5.84, "draft_iters": 18.8, "mem_use": 46.9, "gen_rate": 8.2, "speed": 2.51, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.5, "tree_w": 39, "tree_size": 256, "t0": 2.1425, "t1": 0.8775, "tft": 4.6085, "input_0": 816, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.8, "mem_use": 43.35, "gen_rate": 8.8, "speed": 2.9, "text": "To convert text to Braille, you "}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 20.8, "tree_w": 31, "tree_size": 256, "t0": 2.65, "t1": 0.88, "tft": 4.7184, "input_0": 895, "input_1": 257, "min_CLP": -6.13, "draft_iters": 21.8, "mem_use": 43.21, "gen_rate": 12.2, "speed": 3.47, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.2, "tree_w": 46, "tree_size": 256, "t0": 2.1425, "t1": 0.8675, "tft": 2.4984, "input_0": 813, "input_1": 257, "min_CLP": -6.17, "draft_iters": 17.5, "mem_use": 42.2, "gen_rate": 10.2, "speed": 3.41, "text": "\"Adolf Hitler took over Germany "}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 10.3, "tree_w": 60, "tree_size": 256, "t0": 1.5533, "t1": 0.875, "tft": 2.9499, "input_0": 640, "input_1": 257, "min_CLP": -6.79, "draft_iters": 11.3, "mem_use": 42.54, "gen_rate": 7.0, "speed": 2.88, "text": "\"Certainly! Here's another one:\\"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.0, "tree_w": 62, "tree_size": 256, "t0": 1.505, "t1": 0.8717, "tft": 2.0944, "input_0": 631, "input_1": 257, "min_CLP": -6.42, "draft_iters": 10.3, "mem_use": 42.16, "gen_rate": 6.5, "speed": 2.74, "text": "At the time of this writing, the"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 52, "tree_h": 18.8, "tree_w": 57, "tree_size": 256, "t0": 2.132, "t1": 0.906, "tft": 6.4449, "input_0": 576, "input_1": 257, "min_CLP": -6.31, "draft_iters": 19.8, "mem_use": 46.95, "gen_rate": 10.4, "speed": 3.42, "text": "\"I apologize for not meeting you"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.4, "tree_w": 45, "tree_size": 256, "t0": 2.05, "t1": 0.87, "tft": 2.4159, "input_0": 806, "input_1": 257, "min_CLP": -6.26, "draft_iters": 15.0, "mem_use": 42.24, "gen_rate": 7.4, "speed": 2.54, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.5, "tree_w": 61, "tree_size": 256, "t0": 1.615, "t1": 0.9367, "tft": 8.1088, "input_0": 566, "input_1": 257, "min_CLP": -6.36, "draft_iters": 12.5, "mem_use": 49.18, "gen_rate": 5.5, "speed": 2.15, "text": "I am sorry, I have to ask you to"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.5, "tree_w": 58, "tree_size": 256, "t0": 1.9283, "t1": 0.88, "tft": 3.541, "input_0": 721, "input_1": 257, "min_CLP": -6.53, "draft_iters": 15.0, "mem_use": 43.46, "gen_rate": 5.7, "speed": 2.02, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 25, "tree_h": 15.8, "tree_w": 42, "tree_size": 256, "t0": 2.3025, "t1": 0.87, "tft": 3.4838, "input_0": 860, "input_1": 257, "min_CLP": -6.08, "draft_iters": 17.5, "mem_use": 42.26, "gen_rate": 6.2, "speed": 1.97, "text": "\"Sure, I'll be happy to help you"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 46, "tree_size": 256, "t0": 2.0125, "t1": 0.865, "tft": 2.3958, "input_0": 834, "input_1": 257, "min_CLP": -5.95, "draft_iters": 14.5, "mem_use": 42.13, "gen_rate": 8.8, "speed": 3.04, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 35, "tree_size": 256, "t0": 3.61, "t1": 0.87, "tft": 2.8615, "input_0": 889, "input_1": 257, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 42.38, "gen_rate": 33.0, "speed": 7.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 37, "tree_size": 256, "t0": 2.2633, "t1": 0.88, "tft": 2.805, "input_0": 866, "input_1": 257, "min_CLP": -5.96, "draft_iters": 15.3, "mem_use": 42.68, "gen_rate": 10.7, "speed": 3.39, "text": "Here are a few examples of TV sh"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 19.4, "tree_w": 27, "tree_size": 256, "t0": 2.502, "t1": 0.888, "tft": 5.2863, "input_0": 864, "input_1": 257, "min_CLP": -5.91, "draft_iters": 20.4, "mem_use": 44.31, "gen_rate": 7.0, "speed": 2.06, "text": "Certainly! Here are some softwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.2, "tree_w": 42, "tree_size": 256, "t0": 2.166, "t1": 0.88, "tft": 3.3119, "input_0": 848, "input_1": 257, "min_CLP": -5.98, "draft_iters": 15.4, "mem_use": 43.43, "gen_rate": 7.6, "speed": 2.5, "text": "\"When an F-center is formed, it "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 9.6, "tree_w": 71, "tree_size": 256, "t0": 1.4867, "t1": 0.8744, "tft": 2.686, "input_0": 609, "input_1": 257, "min_CLP": -6.66, "draft_iters": 10.9, "mem_use": 42.32, "gen_rate": 3.7, "speed": 1.55, "text": "The atomic bomb game is a refere"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 25.2, "tree_w": 27, "tree_size": 256, "t0": 2.878, "t1": 0.89, "tft": 5.5774, "input_0": 833, "input_1": 257, "min_CLP": -5.78, "draft_iters": 26.0, "mem_use": 44.95, "gen_rate": 6.4, "speed": 1.7, "text": "\"Here's the same code with comme"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 18.5, "tree_w": 39, "tree_size": 256, "t0": 2.365, "t1": 0.88, "tft": 4.9773, "input_0": 792, "input_1": 257, "min_CLP": -6.02, "draft_iters": 19.5, "mem_use": 43.46, "gen_rate": 8.5, "speed": 2.62, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 37, "tree_size": 256, "t0": 3.32, "t1": 0.87, "tft": 2.4473, "input_0": 836, "input_1": 257, "min_CLP": -6.63, "draft_iters": 32.0, "mem_use": 42.15, "gen_rate": 32.0, "speed": 7.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 31, "tree_h": 19.5, "tree_w": 30, "tree_size": 256, "t0": 2.4375, "t1": 0.87, "tft": 2.9495, "input_0": 758, "input_1": 257, "min_CLP": -5.96, "draft_iters": 20.8, "mem_use": 42.24, "gen_rate": 7.8, "speed": 2.34, "text": "```markdown\\n# Markdown Code Blo"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.6, "tree_w": 46, "tree_size": 256, "t0": 2.066, "t1": 0.878, "tft": 3.1225, "input_0": 744, "input_1": 257, "min_CLP": -6.47, "draft_iters": 15.8, "mem_use": 43.31, "gen_rate": 7.0, "speed": 2.38, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 19.3, "tree_w": 40, "tree_size": 256, "t0": 2.35, "t1": 0.8867, "tft": 4.5979, "input_0": 722, "input_1": 257, "min_CLP": -6.08, "draft_iters": 20.3, "mem_use": 44.24, "gen_rate": 7.0, "speed": 2.16, "text": "In JavaScript, there is no built"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.7, "tree_w": 59, "tree_size": 256, "t0": 1.6071, "t1": 0.8786, "tft": 2.907, "input_0": 657, "input_1": 257, "min_CLP": -6.35, "draft_iters": 12.0, "mem_use": 42.76, "gen_rate": 5.6, "speed": 2.24, "text": "Start with the basics. You need "}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.8, "tree_w": 46, "tree_size": 256, "t0": 1.942, "t1": 0.88, "tft": 3.6046, "input_0": 707, "input_1": 257, "min_CLP": -6.17, "draft_iters": 15.8, "mem_use": 43.27, "gen_rate": 6.8, "speed": 2.41, "text": "My assumption was based on the f"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 9.8, "tree_w": 58, "tree_size": 256, "t0": 1.63, "t1": 0.8683, "tft": 2.5319, "input_0": 710, "input_1": 257, "min_CLP": -6.45, "draft_iters": 11.3, "mem_use": 42.15, "gen_rate": 6.8, "speed": 2.74, "text": "Javascript is both a front-end a"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 45, "tree_size": 256, "t0": 1.724, "t1": 0.866, "tft": 3.2125, "input_0": 677, "input_1": 257, "min_CLP": -6.16, "draft_iters": 12.8, "mem_use": 42.13, "gen_rate": 7.4, "speed": 2.86, "text": "The chemical L-theanine, also kn"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 12.8, "tree_w": 50, "tree_size": 256, "t0": 1.8733, "t1": 0.8778, "tft": 3.0028, "input_0": 724, "input_1": 257, "min_CLP": -6.36, "draft_iters": 13.8, "mem_use": 42.85, "gen_rate": 3.7, "speed": 1.33, "text": "Here are the words in two column"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.7, "tree_w": 56, "tree_size": 256, "t0": 1.9033, "t1": 0.87, "tft": 2.9533, "input_0": 651, "input_1": 257, "min_CLP": -6.45, "draft_iters": 15.0, "mem_use": 42.26, "gen_rate": 5.5, "speed": 1.98, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 60, "tree_size": 256, "t0": 1.594, "t1": 0.864, "tft": 2.6344, "input_0": 712, "input_1": 257, "min_CLP": -6.44, "draft_iters": 10.8, "mem_use": 42.26, "gen_rate": 6.8, "speed": 2.76, "text": "\"Here's a poem for your valentin"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 3.54, "t1": 0.87, "tft": 2.399, "input_0": 1006, "input_1": 257, "min_CLP": -6.49, "draft_iters": 32.0, "mem_use": 42.24, "gen_rate": 33.0, "speed": 7.48, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 18.7, "tree_w": 56, "tree_size": 256, "t0": 2.315, "t1": 0.9083, "tft": 4.7356, "input_0": 738, "input_1": 257, "min_CLP": -6.29, "draft_iters": 20.0, "mem_use": 47.01, "gen_rate": 6.3, "speed": 1.96, "text": "Here is a possible monologue scr"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 43, "tree_size": 256, "t0": 2.035, "t1": 0.8925, "tft": 4.8315, "input_0": 826, "input_1": 257, "min_CLP": -5.99, "draft_iters": 14.2, "mem_use": 44.65, "gen_rate": 8.8, "speed": 2.99, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 21.5, "tree_w": 28, "tree_size": 256, "t0": 2.925, "t1": 0.875, "tft": 3.7036, "input_0": 995, "input_1": 257, "min_CLP": -5.64, "draft_iters": 23.2, "mem_use": 43.11, "gen_rate": 11.2, "speed": 2.96, "text": "Certainly! The formula for estim"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.2, "tree_w": 40, "tree_size": 256, "t0": 2.39, "t1": 0.8775, "tft": 3.3436, "input_0": 941, "input_1": 257, "min_CLP": -5.95, "draft_iters": 17.8, "mem_use": 43.28, "gen_rate": 10.0, "speed": 3.06, "text": "We can learn so much from polar "}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.0, "tree_w": 43, "tree_size": 256, "t0": 2.004, "t1": 0.884, "tft": 4.7669, "input_0": 812, "input_1": 257, "min_CLP": -6.21, "draft_iters": 14.2, "mem_use": 44.31, "gen_rate": 6.8, "speed": 2.35, "text": "Lemon wedges for serving are a c"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 58, "tree_size": 256, "t0": 1.8133, "t1": 0.8717, "tft": 2.8636, "input_0": 735, "input_1": 257, "min_CLP": -6.32, "draft_iters": 12.3, "mem_use": 42.33, "gen_rate": 6.0, "speed": 2.24, "text": "\"Sure, I can do that! As the wom"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 19, "tree_h": 11.1, "tree_w": 77, "tree_size": 256, "t0": 1.5071, "t1": 0.87, "tft": 2.5182, "input_0": 520, "input_1": 257, "min_CLP": -6.71, "draft_iters": 12.1, "mem_use": 42.29, "gen_rate": 2.7, "speed": 1.14, "text": "\"You are better off not knowing,"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.5, "tree_w": 24, "tree_size": 256, "t0": 3.16, "t1": 0.87, "tft": 2.8802, "input_0": 1207, "input_1": 257, "min_CLP": -5.69, "draft_iters": 23.0, "mem_use": 42.17, "gen_rate": 17.5, "speed": 4.34, "text": "\"Sure! Here's a step-by-step gui"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.5, "tree_w": 35, "tree_size": 256, "t0": 2.2225, "t1": 0.8875, "tft": 3.8691, "input_0": 851, "input_1": 257, "min_CLP": -5.99, "draft_iters": 16.0, "mem_use": 43.77, "gen_rate": 9.2, "speed": 2.98, "text": "Yes, there are several cities th"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.6, "tree_w": 38, "tree_size": 256, "t0": 2.26, "t1": 0.88, "tft": 3.2758, "input_0": 994, "input_1": 257, "min_CLP": -5.92, "draft_iters": 15.2, "mem_use": 43.31, "gen_rate": 7.0, "speed": 2.23, "text": "Freeman Dyson is known for his w"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 18.5, "tree_w": 44, "tree_size": 256, "t0": 2.165, "t1": 0.865, "tft": 1.8995, "input_0": 621, "input_1": 257, "min_CLP": -6.26, "draft_iters": 19.5, "mem_use": 42.12, "gen_rate": 17.0, "speed": 5.61, "text": "def factorial(n):\\n    if n == 0"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 21.0, "tree_w": 22, "tree_size": 256, "t0": 2.61, "t1": 0.88, "tft": 4.2633, "input_0": 835, "input_1": 257, "min_CLP": -6.19, "draft_iters": 22.0, "mem_use": 42.87, "gen_rate": 18.0, "speed": 5.16, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 27.3, "tree_w": 22, "tree_size": 256, "t0": 3.31, "t1": 0.88, "tft": 5.1997, "input_0": 1023, "input_1": 257, "min_CLP": -5.9, "draft_iters": 28.0, "mem_use": 43.5, "gen_rate": 18.7, "speed": 4.46, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.6, "tree_w": 38, "tree_size": 256, "t0": 1.986, "t1": 0.878, "tft": 3.8904, "input_0": 754, "input_1": 257, "min_CLP": -5.82, "draft_iters": 14.6, "mem_use": 42.49, "gen_rate": 7.6, "speed": 2.66, "text": "1.    Set realistic goals and ma"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.6, "tree_w": 37, "tree_size": 256, "t0": 2.14, "t1": 0.868, "tft": 2.6517, "input_0": 760, "input_1": 257, "min_CLP": -5.81, "draft_iters": 16.6, "mem_use": 42.16, "gen_rate": 7.8, "speed": 2.59, "text": "Yes, self-attention mechanism is"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 10.8, "tree_w": 54, "tree_size": 256, "t0": 1.67, "t1": 0.88, "tft": 3.0507, "input_0": 695, "input_1": 257, "min_CLP": -6.2, "draft_iters": 12.0, "mem_use": 42.72, "gen_rate": 8.6, "speed": 3.38, "text": "\"Making a comparison of deep lea"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 17.0, "tree_w": 44, "tree_size": 256, "t0": 2.065, "t1": 0.88, "tft": 3.365, "input_0": 588, "input_1": 257, "min_CLP": -6.33, "draft_iters": 18.0, "mem_use": 43.19, "gen_rate": 3.5, "speed": 1.19, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.8, "tree_w": 50, "tree_size": 256, "t0": 1.8417, "t1": 0.8767, "tft": 4.1041, "input_0": 773, "input_1": 257, "min_CLP": -6.23, "draft_iters": 13.2, "mem_use": 42.83, "gen_rate": 5.5, "speed": 2.02, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.69, "t1": 0.88, "tft": 5.7509, "input_0": 1137, "input_1": 257, "min_CLP": -6.3, "draft_iters": 32.0, "mem_use": 44.96, "gen_rate": 33.0, "speed": 7.22, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.7, "tree_w": 43, "tree_size": 256, "t0": 2.1733, "t1": 0.9, "tft": 5.0809, "input_0": 886, "input_1": 257, "min_CLP": -6.16, "draft_iters": 15.7, "mem_use": 46.52, "gen_rate": 11.0, "speed": 3.58, "text": "\"- Some popular brands of vegan "}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.2, "tree_w": 44, "tree_size": 256, "t0": 2.155, "t1": 0.8817, "tft": 3.3213, "input_0": 865, "input_1": 257, "min_CLP": -6.05, "draft_iters": 15.8, "mem_use": 43.57, "gen_rate": 6.0, "speed": 1.98, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 256, "t0": 3.81, "t1": 0.88, "tft": 5.2598, "input_0": 1170, "input_1": 257, "min_CLP": -5.49, "draft_iters": 32.0, "mem_use": 43.95, "gen_rate": 33.0, "speed": 7.02, "text": "\"Sure, here are the three most i"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 35, "tree_size": 256, "t0": 2.2667, "t1": 0.87, "tft": 2.3358, "input_0": 824, "input_1": 257, "min_CLP": -5.85, "draft_iters": 17.3, "mem_use": 42.16, "gen_rate": 10.7, "speed": 3.4, "text": "Sets and lists are both data str"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.2, "tree_w": 39, "tree_size": 256, "t0": 2.4925, "t1": 0.88, "tft": 4.7609, "input_0": 784, "input_1": 257, "min_CLP": -6.11, "draft_iters": 20.5, "mem_use": 43.53, "gen_rate": 10.0, "speed": 2.96, "text": "Black Friday is always the day a"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 20.0, "tree_w": 33, "tree_size": 256, "t0": 2.7033, "t1": 0.8733, "tft": 2.3272, "input_0": 987, "input_1": 257, "min_CLP": -5.88, "draft_iters": 21.3, "mem_use": 42.33, "gen_rate": 12.0, "speed": 3.36, "text": "\"Sure, I'd be happy to tell you "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.7, "tree_w": 38, "tree_size": 256, "t0": 2.4833, "t1": 0.87, "tft": 3.6014, "input_0": 984, "input_1": 257, "min_CLP": -6.02, "draft_iters": 17.3, "mem_use": 42.21, "gen_rate": 12.0, "speed": 3.58, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 39, "tree_size": 256, "t0": 2.11, "t1": 0.8667, "tft": 3.1461, "input_0": 638, "input_1": 257, "min_CLP": -6.23, "draft_iters": 18.3, "mem_use": 42.19, "gen_rate": 11.0, "speed": 3.7, "text": "In Minecraft, there are several "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 49, "tree_size": 256, "t0": 1.824, "t1": 0.868, "tft": 2.3266, "input_0": 686, "input_1": 257, "min_CLP": -6.47, "draft_iters": 13.0, "mem_use": 42.15, "gen_rate": 6.6, "speed": 2.45, "text": "As the Norse Goddess of love, be"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 24.0, "tree_w": 23, "tree_size": 256, "t0": 2.97, "t1": 0.88, "tft": 4.2235, "input_0": 909, "input_1": 257, "min_CLP": -5.79, "draft_iters": 25.0, "mem_use": 43.45, "gen_rate": 18.0, "speed": 4.68, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 20.0, "tree_w": 28, "tree_size": 256, "t0": 2.645, "t1": 0.8775, "tft": 4.5033, "input_0": 904, "input_1": 257, "min_CLP": -5.9, "draft_iters": 21.5, "mem_use": 42.54, "gen_rate": 11.0, "speed": 3.12, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 14.3, "tree_w": 42, "tree_size": 256, "t0": 2.1833, "t1": 0.9167, "tft": 6.2949, "input_0": 880, "input_1": 257, "min_CLP": -5.95, "draft_iters": 15.7, "mem_use": 47.62, "gen_rate": 12.0, "speed": 3.87, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.8, "tree_w": 40, "tree_size": 256, "t0": 1.952, "t1": 0.874, "tft": 2.7708, "input_0": 709, "input_1": 257, "min_CLP": -6.01, "draft_iters": 15.2, "mem_use": 42.67, "gen_rate": 7.6, "speed": 2.69, "text": "LLMs (Large Language Models) nee"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.0, "tree_w": 79, "tree_size": 256, "t0": 1.4075, "t1": 0.87, "tft": 2.4114, "input_0": 572, "input_1": 257, "min_CLP": -6.83, "draft_iters": 10.2, "mem_use": 42.23, "gen_rate": 4.1, "speed": 1.81, "text": "\"Sure, here's a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.2, "tree_w": 47, "tree_size": 256, "t0": 2.002, "t1": 0.878, "tft": 2.4804, "input_0": 668, "input_1": 257, "min_CLP": -6.27, "draft_iters": 16.2, "mem_use": 42.45, "gen_rate": 7.4, "speed": 2.57, "text": "Eulogy for Grandma:\\n\\nDear fami"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.0, "tree_w": 43, "tree_size": 256, "t0": 2.42, "t1": 0.8867, "tft": 3.3574, "input_0": 829, "input_1": 257, "min_CLP": -6.17, "draft_iters": 19.0, "mem_use": 43.95, "gen_rate": 13.3, "speed": 4.03, "text": "[INST] How can I make the game m"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 15.2, "tree_w": 44, "tree_size": 256, "t0": 2.108, "t1": 0.874, "tft": 3.1236, "input_0": 805, "input_1": 257, "min_CLP": -6.15, "draft_iters": 16.4, "mem_use": 42.32, "gen_rate": 8.4, "speed": 2.82, "text": "\"Yes, I am an assistant. I am de"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.2, "tree_w": 75, "tree_size": 256, "t0": 1.3567, "t1": 0.8733, "tft": 2.3486, "input_0": 589, "input_1": 257, "min_CLP": -6.68, "draft_iters": 9.3, "mem_use": 42.3, "gen_rate": 5.3, "speed": 2.39, "text": "- Listen to their problems and o"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 50, "tree_size": 256, "t0": 1.81, "t1": 0.865, "tft": 2.0992, "input_0": 802, "input_1": 257, "min_CLP": -6.23, "draft_iters": 12.8, "mem_use": 42.13, "gen_rate": 8.5, "speed": 3.17, "text": "The color of Mars is typically d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.0, "tree_w": 57, "tree_size": 256, "t0": 1.934, "t1": 0.892, "tft": 4.0514, "input_0": 708, "input_1": 257, "min_CLP": -7.09, "draft_iters": 14.2, "mem_use": 44.37, "gen_rate": 6.6, "speed": 2.33, "text": "To say \"I love you\" in Quenya, y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 3.48, "t1": 0.87, "tft": 2.9593, "input_0": 875, "input_1": 257, "min_CLP": -8.04, "draft_iters": 32.0, "mem_use": 42.21, "gen_rate": 33.0, "speed": 7.58, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.0, "tree_w": 60, "tree_size": 256, "t0": 1.8014, "t1": 0.88, "tft": 3.8319, "input_0": 656, "input_1": 257, "min_CLP": -6.39, "draft_iters": 14.3, "mem_use": 42.76, "gen_rate": 5.0, "speed": 1.86, "text": "The ATF is not a violation in an"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.5, "tree_w": 48, "tree_size": 256, "t0": 2.305, "t1": 0.87, "tft": 3.2369, "input_0": 687, "input_1": 257, "min_CLP": -6.55, "draft_iters": 19.5, "mem_use": 42.21, "gen_rate": 8.0, "speed": 2.52, "text": "[INST] Given the context: Can we"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.2, "tree_w": 43, "tree_size": 256, "t0": 2.2425, "t1": 0.8775, "tft": 4.0902, "input_0": 835, "input_1": 257, "min_CLP": -5.99, "draft_iters": 17.0, "mem_use": 42.65, "gen_rate": 9.2, "speed": 2.97, "text": "\"Sure, I'd be happy to help! As "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 17.5, "tree_w": 39, "tree_size": 256, "t0": 2.3325, "t1": 0.8775, "tft": 3.8497, "input_0": 785, "input_1": 257, "min_CLP": -6.19, "draft_iters": 18.5, "mem_use": 42.33, "gen_rate": 11.0, "speed": 3.43, "text": "Melbourne served as the capital "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 256, "t0": 3.79, "t1": 0.87, "tft": 3.7901, "input_0": 1239, "input_1": 257, "min_CLP": -7.95, "draft_iters": 32.0, "mem_use": 42.51, "gen_rate": 33.0, "speed": 7.09, "text": "[INST] write a eulogy for my 100"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 49, "tree_size": 256, "t0": 1.814, "t1": 0.886, "tft": 5.5686, "input_0": 683, "input_1": 257, "min_CLP": -6.17, "draft_iters": 13.6, "mem_use": 44.74, "gen_rate": 6.4, "speed": 2.37, "text": "First, I would need to know more"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.7, "tree_w": 62, "tree_size": 256, "t0": 1.92, "t1": 0.8729, "tft": 2.8332, "input_0": 700, "input_1": 257, "min_CLP": -6.56, "draft_iters": 15.3, "mem_use": 42.32, "gen_rate": 5.0, "speed": 1.79, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 256, "t0": 3.68, "t1": 0.88, "tft": 4.7063, "input_0": 1119, "input_1": 257, "min_CLP": -9.7, "draft_iters": 32.0, "mem_use": 43.64, "gen_rate": 33.0, "speed": 7.24, "text": "For a vector A in a n dimensiona"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.8, "tree_w": 41, "tree_size": 256, "t0": 2.0317, "t1": 0.8683, "tft": 2.2783, "input_0": 753, "input_1": 257, "min_CLP": -6.2, "draft_iters": 15.0, "mem_use": 42.18, "gen_rate": 6.2, "speed": 2.13, "text": "The use of a symmetric probabili"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 40, "tree_size": 256, "t0": 3.32, "t1": 0.88, "tft": 2.4375, "input_0": 707, "input_1": 257, "min_CLP": -7.36, "draft_iters": 32.0, "mem_use": 42.24, "gen_rate": 33.0, "speed": 7.87, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 26.5, "tree_w": 36, "tree_size": 256, "t0": 3.1925, "t1": 0.8725, "tft": 3.2458, "input_0": 941, "input_1": 257, "min_CLP": -6.16, "draft_iters": 27.8, "mem_use": 42.19, "gen_rate": 11.2, "speed": 2.77, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 52, "tree_size": 256, "t0": 1.664, "t1": 0.88, "tft": 3.1135, "input_0": 619, "input_1": 257, "min_CLP": -6.44, "draft_iters": 13.0, "mem_use": 42.76, "gen_rate": 6.4, "speed": 2.52, "text": "The sum of squares of error is t"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 12, "tree_h": 10.0, "tree_w": 73, "tree_size": 256, "t0": 1.43, "t1": 0.8767, "tft": 3.26, "input_0": 530, "input_1": 257, "min_CLP": -6.66, "draft_iters": 11.3, "mem_use": 43.09, "gen_rate": 4.0, "speed": 1.73, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 13.2, "tree_w": 52, "tree_size": 256, "t0": 1.9675, "t1": 0.88, "tft": 3.3642, "input_0": 847, "input_1": 257, "min_CLP": -6.62, "draft_iters": 14.2, "mem_use": 42.84, "gen_rate": 7.2, "speed": 2.55, "text": "The best place to see stars in t"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 10.9, "tree_w": 66, "tree_size": 256, "t0": 1.5313, "t1": 0.8688, "tft": 4.0067, "input_0": 564, "input_1": 257, "min_CLP": -6.75, "draft_iters": 12.1, "mem_use": 42.18, "gen_rate": 4.8, "speed": 1.98, "text": "1. Being chased by a swarm of an"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.3, "tree_w": 56, "tree_size": 256, "t0": 1.5357, "t1": 0.8814, "tft": 4.2471, "input_0": 603, "input_1": 257, "min_CLP": -6.45, "draft_iters": 11.4, "mem_use": 42.74, "gen_rate": 4.9, "speed": 2.01, "text": "In this case, the two dropped eg"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 59, "tree_size": 256, "t0": 1.64, "t1": 0.8775, "tft": 4.2179, "input_0": 588, "input_1": 257, "min_CLP": -6.36, "draft_iters": 12.8, "mem_use": 42.61, "gen_rate": 8.0, "speed": 3.18, "text": "A few ways to manage stress incl"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.0, "tree_w": 38, "tree_size": 256, "t0": 2.1375, "t1": 0.9, "tft": 5.1221, "input_0": 826, "input_1": 257, "min_CLP": -5.95, "draft_iters": 16.2, "mem_use": 45.69, "gen_rate": 9.0, "speed": 2.96, "text": "Certainly! Here are some tools t"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.5, "tree_w": 27, "tree_size": 256, "t0": 3.09, "t1": 0.885, "tft": 4.4272, "input_0": 1099, "input_1": 257, "min_CLP": -5.65, "draft_iters": 22.0, "mem_use": 44.37, "gen_rate": 16.5, "speed": 4.15, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.2, "tree_w": 42, "tree_size": 256, "t0": 2.0725, "t1": 0.865, "tft": 2.5863, "input_0": 791, "input_1": 257, "min_CLP": -6.24, "draft_iters": 15.5, "mem_use": 42.14, "gen_rate": 8.0, "speed": 2.72, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 13.5, "tree_w": 45, "tree_size": 256, "t0": 1.99, "t1": 0.8775, "tft": 2.4937, "input_0": 749, "input_1": 257, "min_CLP": -6.21, "draft_iters": 14.8, "mem_use": 42.39, "gen_rate": 10.5, "speed": 3.67, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 48, "tree_size": 256, "t0": 1.89, "t1": 0.9325, "tft": 7.8154, "input_0": 784, "input_1": 257, "min_CLP": -6.04, "draft_iters": 13.5, "mem_use": 49.21, "gen_rate": 8.0, "speed": 2.84, "text": "Certainly! The `_physics_process"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.5, "tree_w": 43, "tree_size": 256, "t0": 2.2, "t1": 0.875, "tft": 3.5755, "input_0": 888, "input_1": 257, "min_CLP": -6.12, "draft_iters": 15.8, "mem_use": 42.56, "gen_rate": 8.5, "speed": 2.77, "text": "\"Yes, you can use a decorator wi"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 27.0, "tree_w": 26, "tree_size": 256, "t0": 3.46, "t1": 0.865, "tft": 2.8914, "input_0": 1168, "input_1": 257, "min_CLP": -6.15, "draft_iters": 28.0, "mem_use": 42.27, "gen_rate": 18.5, "speed": 4.28, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.0, "tree_w": 64, "tree_size": 256, "t0": 1.7657, "t1": 0.8671, "tft": 2.7118, "input_0": 607, "input_1": 257, "min_CLP": -6.35, "draft_iters": 14.4, "mem_use": 42.27, "gen_rate": 5.0, "speed": 1.9, "text": "\"The Wyoming statutes do have pr"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.9, "tree_w": 53, "tree_size": 256, "t0": 1.7686, "t1": 0.8871, "tft": 4.5634, "input_0": 671, "input_1": 257, "min_CLP": -6.2, "draft_iters": 13.3, "mem_use": 44.82, "gen_rate": 5.3, "speed": 1.99, "text": "You raise a valid concern about "}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 25.0, "tree_w": 20, "tree_size": 256, "t0": 3.72, "t1": 0.875, "tft": 3.6384, "input_0": 1358, "input_1": 257, "min_CLP": -5.65, "draft_iters": 26.5, "mem_use": 42.69, "gen_rate": 19.0, "speed": 4.13, "text": "Yes, here are some of the best u"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 26.3, "tree_w": 39, "tree_size": 256, "t0": 3.1167, "t1": 0.88, "tft": 3.5149, "input_0": 947, "input_1": 257, "min_CLP": -6.5, "draft_iters": 27.3, "mem_use": 42.88, "gen_rate": 18.3, "speed": 4.59, "text": "\"[INST] What is the airspeed vel"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 15.8, "tree_w": 43, "tree_size": 256, "t0": 2.2917, "t1": 0.875, "tft": 2.5757, "input_0": 862, "input_1": 257, "min_CLP": -5.87, "draft_iters": 17.2, "mem_use": 42.48, "gen_rate": 5.8, "speed": 1.84, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 56, "tree_size": 256, "t0": 1.385, "t1": 0.875, "tft": 4.2564, "input_0": 558, "input_1": 257, "min_CLP": -6.67, "draft_iters": 10.0, "mem_use": 42.72, "gen_rate": 5.7, "speed": 2.5, "text": "\"Attention bias, shining bright,"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.2, "tree_w": 63, "tree_size": 256, "t0": 1.645, "t1": 0.875, "tft": 2.6972, "input_0": 643, "input_1": 257, "min_CLP": -6.56, "draft_iters": 12.2, "mem_use": 42.51, "gen_rate": 5.8, "speed": 2.31, "text": "The cat in the thought experimen"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.7, "tree_w": 56, "tree_size": 256, "t0": 1.7267, "t1": 0.8883, "tft": 4.8302, "input_0": 642, "input_1": 257, "min_CLP": -6.37, "draft_iters": 13.2, "mem_use": 44.49, "gen_rate": 5.5, "speed": 2.1, "text": "\"If you feel nauseous or unable "}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 13.9, "tree_w": 41, "tree_size": 256, "t0": 2.0214, "t1": 0.87, "tft": 3.0411, "input_0": 724, "input_1": 257, "min_CLP": -6.09, "draft_iters": 15.1, "mem_use": 42.26, "gen_rate": 6.1, "speed": 2.12, "text": "Canberra is located in the Austr"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 63, "tree_size": 256, "t0": 1.482, "t1": 0.87, "tft": 3.2097, "input_0": 538, "input_1": 257, "min_CLP": -6.53, "draft_iters": 11.2, "mem_use": 42.28, "gen_rate": 6.6, "speed": 2.8, "text": "Of course! I can speak Spanish. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 11.2, "tree_w": 49, "tree_size": 256, "t0": 1.6925, "t1": 0.87, "tft": 3.257, "input_0": 686, "input_1": 257, "min_CLP": -6.46, "draft_iters": 12.5, "mem_use": 42.26, "gen_rate": 5.2, "speed": 2.05, "text": "F-centers, short for Faraday cen"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 25.0, "tree_w": 25, "tree_size": 256, "t0": 3.1, "t1": 0.91, "tft": 5.3568, "input_0": 1021, "input_1": 257, "min_CLP": -5.6, "draft_iters": 26.0, "mem_use": 46.81, "gen_rate": 18.0, "speed": 4.49, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 14.0, "tree_w": 42, "tree_size": 256, "t0": 2.0183, "t1": 0.8867, "tft": 3.9329, "input_0": 739, "input_1": 257, "min_CLP": -5.96, "draft_iters": 15.5, "mem_use": 43.92, "gen_rate": 7.5, "speed": 2.59, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.2, "tree_w": 52, "tree_size": 256, "t0": 1.844, "t1": 0.882, "tft": 3.0489, "input_0": 692, "input_1": 257, "min_CLP": -6.26, "draft_iters": 13.4, "mem_use": 42.69, "gen_rate": 8.2, "speed": 3.01, "text": "I think AI assistants will not r"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 13.5, "tree_w": 39, "tree_size": 256, "t0": 1.9633, "t1": 0.8883, "tft": 4.601, "input_0": 711, "input_1": 257, "min_CLP": -6.04, "draft_iters": 14.5, "mem_use": 44.6, "gen_rate": 7.7, "speed": 2.69, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.4, "tree_w": 48, "tree_size": 256, "t0": 1.984, "t1": 0.89, "tft": 4.5442, "input_0": 790, "input_1": 257, "min_CLP": -6.17, "draft_iters": 14.0, "mem_use": 44.56, "gen_rate": 7.2, "speed": 2.5, "text": "In Deutschland verursacht die Ze"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 19.7, "tree_w": 43, "tree_size": 256, "t0": 2.44, "t1": 0.8833, "tft": 3.4273, "input_0": 736, "input_1": 257, "min_CLP": -6.79, "draft_iters": 21.0, "mem_use": 43.93, "gen_rate": 6.7, "speed": 2.01, "text": "Im sorry, I am not able to provi"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 62, "tree_size": 256, "t0": 1.356, "t1": 0.874, "tft": 3.0518, "input_0": 550, "input_1": 257, "min_CLP": -6.34, "draft_iters": 9.6, "mem_use": 42.93, "gen_rate": 6.4, "speed": 2.87, "text": "If you know the name of the owne"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 16.3, "tree_w": 51, "tree_size": 256, "t0": 2.1467, "t1": 0.88, "tft": 2.6405, "input_0": 788, "input_1": 257, "min_CLP": -6.49, "draft_iters": 17.0, "mem_use": 42.52, "gen_rate": 14.3, "speed": 4.74, "text": "\u4f60\u5efa\u8b70\u6211\u95b1\u8b80\u4ee5\u4e0b\u9019\u4e9b\u8ad6\u6587\uff1a\\n1. Vaswani, A., S"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 26.0, "tree_w": 19, "tree_size": 256, "t0": 3.29, "t1": 0.87, "tft": 2.8246, "input_0": 1019, "input_1": 257, "min_CLP": -5.29, "draft_iters": 27.0, "mem_use": 42.32, "gen_rate": 24.0, "speed": 5.76, "text": "\"Sure! Here's a JavaScript funct"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 46, "tree_size": 256, "t0": 1.99, "t1": 0.886, "tft": 4.0584, "input_0": 773, "input_1": 257, "min_CLP": -6.05, "draft_iters": 14.4, "mem_use": 43.64, "gen_rate": 6.8, "speed": 2.36, "text": "It is illegal for several reason"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.2, "tree_w": 46, "tree_size": 256, "t0": 1.932, "t1": 0.876, "tft": 4.2506, "input_0": 700, "input_1": 257, "min_CLP": -6.22, "draft_iters": 14.6, "mem_use": 42.72, "gen_rate": 7.0, "speed": 2.49, "text": "\"You're welcome! When it comes t"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 50, "tree_size": 256, "t0": 1.6925, "t1": 0.8825, "tft": 4.8454, "input_0": 620, "input_1": 257, "min_CLP": -6.03, "draft_iters": 13.2, "mem_use": 43.63, "gen_rate": 8.2, "speed": 3.2, "text": "\"The optimal thickness for mayon"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 13.7, "tree_w": 52, "tree_size": 256, "t0": 1.9167, "t1": 0.8767, "tft": 4.5808, "input_0": 689, "input_1": 257, "min_CLP": -6.49, "draft_iters": 14.7, "mem_use": 43.02, "gen_rate": 7.0, "speed": 2.51, "text": "If you celebrate Christmas on th"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.8, "tree_w": 54, "tree_size": 256, "t0": 1.754, "t1": 0.87, "tft": 3.6372, "input_0": 666, "input_1": 257, "min_CLP": -6.73, "draft_iters": 13.0, "mem_use": 42.25, "gen_rate": 7.6, "speed": 2.9, "text": "\"Sure, here's a list of nickname"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 43, "tree_size": 256, "t0": 2.06, "t1": 0.876, "tft": 4.0251, "input_0": 758, "input_1": 257, "min_CLP": -5.99, "draft_iters": 15.2, "mem_use": 42.66, "gen_rate": 7.2, "speed": 2.45, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 12, "tree_size": 256, "t0": 3.7, "t1": 0.88, "tft": 5.0078, "input_0": 931, "input_1": 257, "min_CLP": -5.94, "draft_iters": 32.0, "mem_use": 43.44, "gen_rate": 33.0, "speed": 7.21, "text": "\"Canciones felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.2, "tree_w": 41, "tree_size": 256, "t0": 2.4275, "t1": 0.8675, "tft": 3.207, "input_0": 787, "input_1": 257, "min_CLP": -6.06, "draft_iters": 19.5, "mem_use": 42.35, "gen_rate": 10.2, "speed": 3.11, "text": "<|bot|> Sure, here is a table of"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 27.5, "tree_w": 33, "tree_size": 256, "t0": 3.02, "t1": 0.87, "tft": 2.7931, "input_0": 824, "input_1": 257, "min_CLP": -7.52, "draft_iters": 28.0, "mem_use": 42.74, "gen_rate": 21.0, "speed": 5.4, "text": "```<|endoftext|>Human: [INST] <<"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.5, "tree_w": 62, "tree_size": 256, "t0": 1.72, "t1": 0.875, "tft": 3.8339, "input_0": 601, "input_1": 257, "min_CLP": -6.61, "draft_iters": 13.7, "mem_use": 43.15, "gen_rate": 5.7, "speed": 2.18, "text": "How about, \"A heart\\'s wish is l"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.2, "tree_w": 36, "tree_size": 256, "t0": 2.42, "t1": 0.8825, "tft": 4.4278, "input_0": 973, "input_1": 257, "min_CLP": -6.2, "draft_iters": 17.8, "mem_use": 43.9, "gen_rate": 9.0, "speed": 2.72, "text": "To build a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.6, "tree_w": 51, "tree_size": 256, "t0": 2.04, "t1": 0.87, "tft": 2.787, "input_0": 777, "input_1": 257, "min_CLP": -6.11, "draft_iters": 15.0, "mem_use": 42.35, "gen_rate": 8.0, "speed": 2.75, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 20.4, "tree_w": 48, "tree_size": 256, "t0": 2.42, "t1": 0.868, "tft": 4.1574, "input_0": 746, "input_1": 257, "min_CLP": -6.38, "draft_iters": 21.4, "mem_use": 42.28, "gen_rate": 6.4, "speed": 1.95, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 15.7, "tree_w": 39, "tree_size": 256, "t0": 2.1967, "t1": 0.9, "tft": 6.4358, "input_0": 793, "input_1": 257, "min_CLP": -6.09, "draft_iters": 17.0, "mem_use": 46.4, "gen_rate": 5.3, "speed": 1.72, "text": "- Discovery: Find a market need "}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 14.2, "tree_w": 43, "tree_size": 256, "t0": 2.1225, "t1": 0.8625, "tft": 2.0296, "input_0": 781, "input_1": 257, "min_CLP": -6.35, "draft_iters": 15.8, "mem_use": 42.17, "gen_rate": 10.2, "speed": 3.43, "text": "Answer: The Many-Worlds Interpre"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 35, "tree_size": 256, "t0": 2.4367, "t1": 0.8667, "tft": 3.3981, "input_0": 957, "input_1": 257, "min_CLP": -5.9, "draft_iters": 17.7, "mem_use": 42.13, "gen_rate": 11.7, "speed": 3.53, "text": "To build a PC, you will need the"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 20.2, "tree_w": 42, "tree_size": 256, "t0": 2.465, "t1": 0.9025, "tft": 5.5052, "input_0": 752, "input_1": 257, "min_CLP": -6.33, "draft_iters": 21.2, "mem_use": 46.39, "gen_rate": 9.0, "speed": 2.67, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 16.8, "tree_w": 51, "tree_size": 256, "t0": 2.2633, "t1": 0.8833, "tft": 5.2859, "input_0": 812, "input_1": 257, "min_CLP": -6.02, "draft_iters": 18.2, "mem_use": 44.22, "gen_rate": 6.5, "speed": 2.07, "text": "\"\u2022 Keep the habit a priority. Ma"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.0, "tree_w": 68, "tree_size": 256, "t0": 1.3586, "t1": 0.8771, "tft": 4.2855, "input_0": 530, "input_1": 257, "min_CLP": -6.43, "draft_iters": 10.0, "mem_use": 43.48, "gen_rate": 4.6, "speed": 2.04, "text": "This is a very good point. Howev"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.0, "tree_w": 49, "tree_size": 256, "t0": 2.102, "t1": 0.878, "tft": 2.8811, "input_0": 866, "input_1": 257, "min_CLP": -6.19, "draft_iters": 15.2, "mem_use": 42.32, "gen_rate": 8.2, "speed": 2.75, "text": "Sure, here are some of the most "}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.0, "tree_w": 44, "tree_size": 256, "t0": 2.165, "t1": 0.87, "tft": 2.8959, "input_0": 797, "input_1": 257, "min_CLP": -6.01, "draft_iters": 17.2, "mem_use": 42.34, "gen_rate": 10.0, "speed": 3.3, "text": "In the context of the game Into "}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.0, "tree_w": 34, "tree_size": 256, "t0": 2.5667, "t1": 0.8733, "tft": 3.881, "input_0": 903, "input_1": 257, "min_CLP": -6.0, "draft_iters": 20.0, "mem_use": 43.2, "gen_rate": 11.3, "speed": 3.3, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 25.2, "tree_w": 24, "tree_size": 256, "t0": 3.1625, "t1": 0.88, "tft": 3.6234, "input_0": 1028, "input_1": 257, "min_CLP": -5.55, "draft_iters": 26.5, "mem_use": 43.72, "gen_rate": 8.2, "speed": 2.04, "text": "Here\\'s a simplified version of "}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 17, "tree_h": 13.0, "tree_w": 36, "tree_size": 256, "t0": 2.115, "t1": 0.87, "tft": 3.4911, "input_0": 890, "input_1": 257, "min_CLP": -5.96, "draft_iters": 14.5, "mem_use": 43.15, "gen_rate": 8.5, "speed": 2.85, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.1, "tree_w": 67, "tree_size": 256, "t0": 1.3957, "t1": 0.8743, "tft": 4.6657, "input_0": 600, "input_1": 257, "min_CLP": -6.6, "draft_iters": 9.6, "mem_use": 43.26, "gen_rate": 4.7, "speed": 2.07, "text": "In your gaze, I see a world of w"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.8, "tree_w": 47, "tree_size": 256, "t0": 2.3825, "t1": 0.875, "tft": 3.0248, "input_0": 773, "input_1": 257, "min_CLP": -6.45, "draft_iters": 19.8, "mem_use": 42.62, "gen_rate": 8.8, "speed": 2.69, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 42, "tree_size": 256, "t0": 1.9, "t1": 0.875, "tft": 3.9686, "input_0": 718, "input_1": 257, "min_CLP": -6.08, "draft_iters": 14.0, "mem_use": 42.58, "gen_rate": 8.2, "speed": 2.97, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.5, "tree_w": 40, "tree_size": 256, "t0": 1.965, "t1": 0.88, "tft": 3.7101, "input_0": 757, "input_1": 257, "min_CLP": -5.99, "draft_iters": 14.7, "mem_use": 43.93, "gen_rate": 6.7, "speed": 2.34, "text": "\"You're welcome! If this method "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.8, "tree_w": 39, "tree_size": 256, "t0": 2.005, "t1": 0.885, "tft": 4.0199, "input_0": 796, "input_1": 257, "min_CLP": -5.97, "draft_iters": 14.5, "mem_use": 43.86, "gen_rate": 10.0, "speed": 3.46, "text": "Yes, Open Assistant is a pretrai"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 20.8, "tree_w": 31, "tree_size": 256, "t0": 2.5125, "t1": 0.89, "tft": 4.2908, "input_0": 804, "input_1": 257, "min_CLP": -5.83, "draft_iters": 21.8, "mem_use": 45.3, "gen_rate": 8.5, "speed": 2.5, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.5, "tree_w": 41, "tree_size": 256, "t0": 2.0025, "t1": 0.8675, "tft": 2.377, "input_0": 782, "input_1": 257, "min_CLP": -6.44, "draft_iters": 13.8, "mem_use": 42.13, "gen_rate": 8.0, "speed": 2.79, "text": "The President of Germany is Fran"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 7.1, "tree_w": 77, "tree_size": 256, "t0": 1.157, "t1": 0.879, "tft": 3.2288, "input_0": 483, "input_1": 257, "min_CLP": -6.55, "draft_iters": 8.3, "mem_use": 43.1, "gen_rate": 3.5, "speed": 1.72, "text": "PostCSS is a tool that helps you"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.0, "tree_w": 55, "tree_size": 256, "t0": 1.906, "t1": 0.89, "tft": 4.8509, "input_0": 658, "input_1": 257, "min_CLP": -6.43, "draft_iters": 15.4, "mem_use": 44.95, "gen_rate": 7.4, "speed": 2.65, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.8, "tree_w": 46, "tree_size": 256, "t0": 2.224, "t1": 0.878, "tft": 3.7275, "input_0": 820, "input_1": 257, "min_CLP": -6.32, "draft_iters": 16.6, "mem_use": 42.65, "gen_rate": 6.4, "speed": 2.06, "text": "- Introduction: What is the cont"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.0, "tree_w": 38, "tree_size": 256, "t0": 2.5933, "t1": 0.8733, "tft": 4.9137, "input_0": 838, "input_1": 257, "min_CLP": -6.0, "draft_iters": 22.3, "mem_use": 43.54, "gen_rate": 12.0, "speed": 3.46, "text": "I apologize for the confusion ea"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 256, "max_branch_width": 32, "gen_rate": 11.14, "gen_rate_micro": 8.39, "gen_speed": 3.309, "gen_speed_micro": 2.864, "t0": 2.265, "t1": 0.8782, "input_0": 787.4, "input_1": 257.0, "tree_size": 256.0, "tree_w": 44.8, "tree_h": 17.0, "prompt_len": 298.0, "min_CLP": -6.34, "mem_use": 51.59, "exp_time": 8847.34}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.7, "tree_w": 241, "tree_size": 512, "t0": 1.36, "t1": 1.4043, "tft": 2.2729, "input_0": 1206, "input_1": 513, "min_CLP": -8.48, "draft_iters": 8.0, "mem_use": 43.66, "gen_rate": 5.3, "speed": 1.91, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.2, "tree_w": 186, "tree_size": 512, "t0": 2.078, "t1": 1.428, "tft": 3.2375, "input_0": 1282, "input_1": 513, "min_CLP": -8.25, "draft_iters": 15.6, "mem_use": 45.18, "gen_rate": 7.0, "speed": 2.0, "text": "You are correct. I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.6, "tree_w": 216, "tree_size": 512, "t0": 1.7314, "t1": 1.4386, "tft": 3.51, "input_0": 1303, "input_1": 513, "min_CLP": -8.18, "draft_iters": 10.3, "mem_use": 46.07, "gen_rate": 5.4, "speed": 1.71, "text": "1. Minecraft: Minecraft is a pop"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 248, "tree_size": 512, "t0": 1.435, "t1": 1.4117, "tft": 2.529, "input_0": 1112, "input_1": 513, "min_CLP": -13.74, "draft_iters": 9.7, "mem_use": 43.83, "gen_rate": 8.5, "speed": 2.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 194, "tree_size": 512, "t0": 2.265, "t1": 1.4, "tft": 2.2933, "input_0": 1750, "input_1": 513, "min_CLP": -7.96, "draft_iters": 13.5, "mem_use": 43.68, "gen_rate": 8.2, "speed": 2.25, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 8.4, "tree_w": 225, "tree_size": 512, "t0": 1.864, "t1": 1.444, "tft": 3.5303, "input_0": 1433, "input_1": 513, "min_CLP": -10.73, "draft_iters": 11.0, "mem_use": 46.2, "gen_rate": 8.4, "speed": 2.54, "text": "Here\\'s a potential bullet list "}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 211, "tree_size": 512, "t0": 1.936, "t1": 1.45, "tft": 4.0617, "input_0": 1410, "input_1": 513, "min_CLP": -9.81, "draft_iters": 12.2, "mem_use": 46.79, "gen_rate": 7.0, "speed": 2.07, "text": "There are many other options for"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 7.8, "tree_w": 224, "tree_size": 512, "t0": 1.645, "t1": 1.475, "tft": 5.4653, "input_0": 1270, "input_1": 513, "min_CLP": -9.71, "draft_iters": 10.0, "mem_use": 48.97, "gen_rate": 7.8, "speed": 2.51, "text": "\"Let's dive deeper into social m"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 17.8, "tree_w": 126, "tree_size": 512, "t0": 3.2275, "t1": 1.4375, "tft": 3.7526, "input_0": 1898, "input_1": 513, "min_CLP": -7.75, "draft_iters": 21.2, "mem_use": 46.4, "gen_rate": 11.2, "speed": 2.41, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.4, "tree_w": 220, "tree_size": 512, "t0": 1.856, "t1": 1.43, "tft": 3.2974, "input_0": 1444, "input_1": 513, "min_CLP": -9.39, "draft_iters": 11.6, "mem_use": 45.77, "gen_rate": 7.2, "speed": 2.19, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.2, "tree_w": 175, "tree_size": 512, "t0": 2.23, "t1": 1.42, "tft": 5.8996, "input_0": 1368, "input_1": 513, "min_CLP": -9.6, "draft_iters": 15.6, "mem_use": 44.34, "gen_rate": 7.2, "speed": 1.97, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 170, "tree_size": 512, "t0": 2.194, "t1": 1.442, "tft": 3.5406, "input_0": 1374, "input_1": 513, "min_CLP": -9.42, "draft_iters": 14.0, "mem_use": 46.14, "gen_rate": 6.6, "speed": 1.82, "text": "Here\\'s a slightly shorter versi"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 255, "tree_size": 512, "t0": 1.488, "t1": 1.438, "tft": 3.4375, "input_0": 1230, "input_1": 513, "min_CLP": -10.64, "draft_iters": 9.6, "mem_use": 45.37, "gen_rate": 7.0, "speed": 2.39, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 3.0, "tree_w": 310, "tree_size": 512, "t0": 0.815, "t1": 1.405, "tft": 2.2963, "input_0": 827, "input_1": 513, "min_CLP": -10.46, "draft_iters": 5.0, "mem_use": 43.66, "gen_rate": 2.5, "speed": 1.12, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.6, "tree_w": 240, "tree_size": 512, "t0": 1.3957, "t1": 1.44, "tft": 4.0555, "input_0": 1182, "input_1": 513, "min_CLP": -8.42, "draft_iters": 8.7, "mem_use": 46.76, "gen_rate": 5.1, "speed": 1.81, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.2, "tree_w": 242, "tree_size": 512, "t0": 1.3656, "t1": 1.41, "tft": 2.5708, "input_0": 982, "input_1": 513, "min_CLP": -9.72, "draft_iters": 9.3, "mem_use": 43.99, "gen_rate": 3.9, "speed": 1.4, "text": "\"The minimum broadband upload sp"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 203, "tree_size": 512, "t0": 2.218, "t1": 1.402, "tft": 2.286, "input_0": 1555, "input_1": 513, "min_CLP": -11.89, "draft_iters": 13.8, "mem_use": 43.68, "gen_rate": 6.6, "speed": 1.82, "text": "\"Sure, I'd be happy to explain F"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 251, "tree_size": 512, "t0": 1.4083, "t1": 1.4033, "tft": 2.2871, "input_0": 1087, "input_1": 513, "min_CLP": -13.33, "draft_iters": 9.7, "mem_use": 43.66, "gen_rate": 8.7, "speed": 3.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 261, "tree_size": 512, "t0": 1.3567, "t1": 1.4117, "tft": 2.6655, "input_0": 1059, "input_1": 513, "min_CLP": -9.39, "draft_iters": 9.5, "mem_use": 44.18, "gen_rate": 5.3, "speed": 1.93, "text": "D-theanine is the other form of "}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 270, "tree_size": 512, "t0": 1.14, "t1": 1.405, "tft": 2.2949, "input_0": 997, "input_1": 513, "min_CLP": -9.45, "draft_iters": 7.2, "mem_use": 43.67, "gen_rate": 4.4, "speed": 1.72, "text": "The Balfour Declaration was a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 5.0, "tree_w": 262, "tree_size": 512, "t0": 1.22, "t1": 1.4189, "tft": 2.9651, "input_0": 1123, "input_1": 513, "min_CLP": -9.39, "draft_iters": 7.2, "mem_use": 44.5, "gen_rate": 4.6, "speed": 1.73, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 3.0, "tree_w": 259, "tree_size": 512, "t0": 0.8, "t1": 1.4, "tft": 2.275, "input_0": 782, "input_1": 513, "min_CLP": -9.3, "draft_iters": 5.0, "mem_use": 43.66, "gen_rate": 2.5, "speed": 1.14, "text": "Hello there Obi-Wan Kenobi!"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.2, "tree_w": 127, "tree_size": 512, "t0": 2.895, "t1": 1.4425, "tft": 3.4887, "input_0": 1966, "input_1": 513, "min_CLP": -10.73, "draft_iters": 17.2, "mem_use": 45.98, "gen_rate": 9.5, "speed": 2.19, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.3, "tree_w": 187, "tree_size": 512, "t0": 2.0467, "t1": 1.4133, "tft": 2.5118, "input_0": 1539, "input_1": 513, "min_CLP": -9.13, "draft_iters": 12.8, "mem_use": 43.73, "gen_rate": 6.0, "speed": 1.74, "text": "Certainly! The process of genera"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.2, "tree_w": 185, "tree_size": 512, "t0": 2.3, "t1": 1.42, "tft": 2.9787, "input_0": 1592, "input_1": 513, "min_CLP": -8.1, "draft_iters": 13.5, "mem_use": 44.68, "gen_rate": 9.5, "speed": 2.55, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 3.7, "tree_w": 290, "tree_size": 512, "t0": 0.9657, "t1": 1.4086, "tft": 2.2926, "input_0": 1110, "input_1": 513, "min_CLP": -15.09, "draft_iters": 5.7, "mem_use": 43.7, "gen_rate": 4.7, "speed": 1.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 4.4, "tree_w": 269, "tree_size": 512, "t0": 1.0625, "t1": 1.4162, "tft": 2.6979, "input_0": 988, "input_1": 513, "min_CLP": -8.89, "draft_iters": 6.5, "mem_use": 44.36, "gen_rate": 5.2, "speed": 2.12, "text": "Austenite is an allotrope of iro"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 6.7, "tree_w": 254, "tree_size": 512, "t0": 1.4267, "t1": 1.4133, "tft": 2.6579, "input_0": 1196, "input_1": 513, "min_CLP": -10.29, "draft_iters": 8.8, "mem_use": 44.22, "gen_rate": 4.0, "speed": 1.41, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 6.4, "tree_w": 215, "tree_size": 512, "t0": 1.4638, "t1": 1.44, "tft": 3.5419, "input_0": 1143, "input_1": 513, "min_CLP": -8.19, "draft_iters": 8.9, "mem_use": 46.13, "gen_rate": 5.0, "speed": 1.72, "text": "\"Verse 1:\\nThere\\'s a world full"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.3, "tree_w": 229, "tree_size": 512, "t0": 1.68, "t1": 1.4067, "tft": 2.3174, "input_0": 1468, "input_1": 513, "min_CLP": -8.61, "draft_iters": 9.7, "mem_use": 43.71, "gen_rate": 6.5, "speed": 2.1, "text": "Sure! Here are some delicious op"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 13.0, "tree_w": 160, "tree_size": 512, "t0": 2.376, "t1": 1.412, "tft": 2.7201, "input_0": 1622, "input_1": 513, "min_CLP": -12.26, "draft_iters": 15.8, "mem_use": 44.4, "gen_rate": 8.4, "speed": 2.22, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 52, "tree_h": 7.0, "tree_w": 243, "tree_size": 512, "t0": 1.4, "t1": 1.4171, "tft": 3.0201, "input_0": 1075, "input_1": 513, "min_CLP": -9.23, "draft_iters": 9.0, "mem_use": 44.8, "gen_rate": 7.4, "speed": 2.64, "text": "[API_REQUEST]: {curl -X POST -H "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 266, "tree_size": 512, "t0": 1.3429, "t1": 1.4157, "tft": 2.6525, "input_0": 1058, "input_1": 513, "min_CLP": -8.8, "draft_iters": 8.9, "mem_use": 44.16, "gen_rate": 4.7, "speed": 1.71, "text": "Freyja, goddess of love, fertili"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 195, "tree_size": 512, "t0": 1.87, "t1": 1.4367, "tft": 3.3067, "input_0": 1294, "input_1": 513, "min_CLP": -8.4, "draft_iters": 12.2, "mem_use": 45.79, "gen_rate": 5.8, "speed": 1.77, "text": "Yes, there are several substitut"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 230, "tree_size": 512, "t0": 1.6743, "t1": 1.44, "tft": 3.3157, "input_0": 1327, "input_1": 513, "min_CLP": -9.22, "draft_iters": 10.1, "mem_use": 45.83, "gen_rate": 5.1, "speed": 1.65, "text": "\"When choosing an ISP package, i"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 6.7, "tree_w": 252, "tree_size": 512, "t0": 1.4583, "t1": 1.4617, "tft": 5.3003, "input_0": 1176, "input_1": 513, "min_CLP": -10.45, "draft_iters": 9.0, "mem_use": 48.56, "gen_rate": 7.2, "speed": 2.45, "text": "Selenium can be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 258, "tree_size": 512, "t0": 1.4671, "t1": 1.4129, "tft": 2.0926, "input_0": 1173, "input_1": 513, "min_CLP": -8.88, "draft_iters": 9.1, "mem_use": 43.69, "gen_rate": 4.7, "speed": 1.64, "text": "\"The airspeed velocity of an unl"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.1, "tree_w": 250, "tree_size": 512, "t0": 1.0371, "t1": 1.4157, "tft": 2.6677, "input_0": 921, "input_1": 513, "min_CLP": -9.06, "draft_iters": 6.3, "mem_use": 44.21, "gen_rate": 4.6, "speed": 1.86, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.0, "tree_w": 209, "tree_size": 512, "t0": 1.5243, "t1": 1.44, "tft": 3.7463, "input_0": 1151, "input_1": 513, "min_CLP": -8.15, "draft_iters": 9.6, "mem_use": 46.56, "gen_rate": 5.3, "speed": 1.78, "text": "\"Yes, I can certainly act as if "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 24.0, "tree_w": 48, "tree_size": 512, "t0": 3.83, "t1": 1.42, "tft": 2.9738, "input_0": 2038, "input_1": 513, "min_CLP": -6.49, "draft_iters": 26.5, "mem_use": 44.61, "gen_rate": 17.0, "speed": 3.24, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.1, "tree_w": 274, "tree_size": 512, "t0": 0.9925, "t1": 1.4163, "tft": 2.5479, "input_0": 986, "input_1": 513, "min_CLP": -8.5, "draft_iters": 6.1, "mem_use": 43.91, "gen_rate": 4.5, "speed": 1.87, "text": "I... I cannot give you my power."}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.4, "tree_w": 283, "tree_size": 512, "t0": 1.0829, "t1": 1.4414, "tft": 3.7689, "input_0": 986, "input_1": 513, "min_CLP": -12.79, "draft_iters": 6.6, "mem_use": 46.38, "gen_rate": 4.7, "speed": 1.87, "text": "The monologue effectively captur"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.4, "tree_w": 294, "tree_size": 512, "t0": 0.88, "t1": 1.4575, "tft": 4.058, "input_0": 965, "input_1": 513, "min_CLP": -8.95, "draft_iters": 5.2, "mem_use": 46.82, "gen_rate": 4.0, "speed": 1.71, "text": "[INST] Thank you for your answer"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 249, "tree_size": 512, "t0": 1.3986, "t1": 1.4271, "tft": 3.2537, "input_0": 1167, "input_1": 513, "min_CLP": -9.3, "draft_iters": 9.0, "mem_use": 45.17, "gen_rate": 4.9, "speed": 1.72, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 5.7, "tree_w": 227, "tree_size": 512, "t0": 1.3267, "t1": 1.4133, "tft": 2.7276, "input_0": 1056, "input_1": 513, "min_CLP": -9.43, "draft_iters": 8.0, "mem_use": 44.43, "gen_rate": 5.3, "speed": 1.95, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 296, "tree_size": 512, "t0": 0.8088, "t1": 1.415, "tft": 2.63, "input_0": 908, "input_1": 513, "min_CLP": -9.69, "draft_iters": 5.0, "mem_use": 44.17, "gen_rate": 4.2, "speed": 1.91, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 48, "tree_h": 7.6, "tree_w": 242, "tree_size": 512, "t0": 1.45, "t1": 1.4114, "tft": 2.2927, "input_0": 1089, "input_1": 513, "min_CLP": -9.38, "draft_iters": 9.9, "mem_use": 43.69, "gen_rate": 6.9, "speed": 2.39, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.8, "tree_w": 196, "tree_size": 512, "t0": 2.23, "t1": 1.4825, "tft": 5.8284, "input_0": 1326, "input_1": 513, "min_CLP": -10.26, "draft_iters": 16.2, "mem_use": 49.11, "gen_rate": 9.0, "speed": 2.42, "text": "[The scene opens with a Spartan "}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.6, "tree_w": 270, "tree_size": 512, "t0": 0.9263, "t1": 1.435, "tft": 3.4498, "input_0": 840, "input_1": 513, "min_CLP": -8.41, "draft_iters": 5.8, "mem_use": 45.41, "gen_rate": 4.2, "speed": 1.8, "text": "The truth is simple, and yet, so"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.7, "tree_w": 262, "tree_size": 512, "t0": 1.103, "t1": 1.427, "tft": 2.7244, "input_0": 853, "input_1": 513, "min_CLP": -8.1, "draft_iters": 7.8, "mem_use": 44.44, "gen_rate": 3.4, "speed": 1.35, "text": "Thank you for understanding.\\n[I"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 266, "tree_size": 512, "t0": 1.1729, "t1": 1.4114, "tft": 2.5533, "input_0": 958, "input_1": 513, "min_CLP": -10.26, "draft_iters": 7.0, "mem_use": 43.96, "gen_rate": 4.7, "speed": 1.82, "text": "CTR \u7684\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u4e3b\u9898\u3002[INS"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.0, "tree_w": 232, "tree_size": 512, "t0": 2.0167, "t1": 1.4333, "tft": 3.2996, "input_0": 1417, "input_1": 513, "min_CLP": -10.18, "draft_iters": 14.2, "mem_use": 45.83, "gen_rate": 6.8, "speed": 1.98, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.3, "tree_w": 245, "tree_size": 512, "t0": 1.6467, "t1": 1.4267, "tft": 3.2096, "input_0": 1274, "input_1": 513, "min_CLP": -10.39, "draft_iters": 10.0, "mem_use": 45.05, "gen_rate": 6.5, "speed": 2.11, "text": "Certainly! Here are some more hi"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 214, "tree_size": 512, "t0": 1.795, "t1": 1.43, "tft": 3.4187, "input_0": 1331, "input_1": 513, "min_CLP": -8.59, "draft_iters": 11.3, "mem_use": 45.38, "gen_rate": 5.5, "speed": 1.7, "text": "Thank you. It is true that techn"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.9, "tree_w": 272, "tree_size": 512, "t0": 0.9787, "t1": 1.4163, "tft": 2.5286, "input_0": 893, "input_1": 513, "min_CLP": -8.25, "draft_iters": 6.0, "mem_use": 43.86, "gen_rate": 4.1, "speed": 1.72, "text": "In real life, people of all ages"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 230, "tree_size": 512, "t0": 1.4733, "t1": 1.44, "tft": 3.6704, "input_0": 1131, "input_1": 513, "min_CLP": -8.63, "draft_iters": 8.8, "mem_use": 46.23, "gen_rate": 5.3, "speed": 1.83, "text": "Title: FullView.io - Transformin"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 250, "tree_size": 512, "t0": 1.1429, "t1": 1.4657, "tft": 4.8093, "input_0": 938, "input_1": 513, "min_CLP": -8.66, "draft_iters": 7.7, "mem_use": 47.48, "gen_rate": 4.7, "speed": 1.81, "text": "My apologies for the confusion. "}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.8, "tree_w": 173, "tree_size": 512, "t0": 2.285, "t1": 1.4633, "tft": 7.0232, "input_0": 1477, "input_1": 513, "min_CLP": -7.76, "draft_iters": 14.5, "mem_use": 47.67, "gen_rate": 5.3, "speed": 1.42, "text": "\"As a beginner, choosing Keras a"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.6, "tree_w": 250, "tree_size": 512, "t0": 1.576, "t1": 1.43, "tft": 3.4086, "input_0": 1160, "input_1": 513, "min_CLP": -10.59, "draft_iters": 10.6, "mem_use": 45.32, "gen_rate": 9.2, "speed": 3.06, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 254, "tree_size": 512, "t0": 1.2071, "t1": 1.4129, "tft": 2.3034, "input_0": 1013, "input_1": 513, "min_CLP": -9.08, "draft_iters": 7.6, "mem_use": 43.68, "gen_rate": 4.6, "speed": 1.75, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 212, "tree_size": 512, "t0": 2.2167, "t1": 1.4367, "tft": 3.5139, "input_0": 1439, "input_1": 513, "min_CLP": -10.36, "draft_iters": 14.3, "mem_use": 46.06, "gen_rate": 13.3, "speed": 3.65, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 208, "tree_size": 512, "t0": 1.6114, "t1": 1.4543, "tft": 6.8485, "input_0": 1282, "input_1": 513, "min_CLP": -8.11, "draft_iters": 9.4, "mem_use": 46.92, "gen_rate": 5.0, "speed": 1.63, "text": "[The general nods to his army, a"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 293, "tree_size": 512, "t0": 0.8238, "t1": 1.4287, "tft": 2.9778, "input_0": 859, "input_1": 513, "min_CLP": -8.89, "draft_iters": 5.0, "mem_use": 44.62, "gen_rate": 4.0, "speed": 1.78, "text": "Got it! How about this: \"A wish "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.7, "tree_w": 205, "tree_size": 512, "t0": 1.8143, "t1": 1.4186, "tft": 2.7107, "input_0": 1307, "input_1": 513, "min_CLP": -8.94, "draft_iters": 11.6, "mem_use": 44.34, "gen_rate": 4.6, "speed": 1.41, "text": "The proof-of-stake model works b"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.0, "tree_w": 259, "tree_size": 512, "t0": 0.8111, "t1": 1.42, "tft": 2.9763, "input_0": 771, "input_1": 513, "min_CLP": -8.2, "draft_iters": 5.0, "mem_use": 44.46, "gen_rate": 3.9, "speed": 1.75, "text": "The other meaning is another per"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 137, "tree_size": 512, "t0": 2.124, "t1": 1.45, "tft": 3.7456, "input_0": 1419, "input_1": 513, "min_CLP": -7.27, "draft_iters": 13.0, "mem_use": 46.52, "gen_rate": 7.6, "speed": 2.13, "text": "A void pointer is a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 205, "tree_size": 512, "t0": 1.7417, "t1": 1.4533, "tft": 4.0044, "input_0": 1287, "input_1": 513, "min_CLP": -9.49, "draft_iters": 11.0, "mem_use": 47.03, "gen_rate": 5.5, "speed": 1.72, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.8, "tree_w": 230, "tree_size": 512, "t0": 1.7033, "t1": 1.4417, "tft": 3.6887, "input_0": 1389, "input_1": 513, "min_CLP": -11.07, "draft_iters": 10.8, "mem_use": 46.24, "gen_rate": 6.7, "speed": 2.12, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.3, "tree_w": 141, "tree_size": 512, "t0": 2.5686, "t1": 1.4129, "tft": 2.6565, "input_0": 1654, "input_1": 513, "min_CLP": -7.64, "draft_iters": 16.1, "mem_use": 44.09, "gen_rate": 5.0, "speed": 1.26, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.7, "tree_w": 239, "tree_size": 512, "t0": 1.3243, "t1": 1.4071, "tft": 2.3028, "input_0": 1115, "input_1": 513, "min_CLP": -9.52, "draft_iters": 8.0, "mem_use": 43.68, "gen_rate": 5.1, "speed": 1.88, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 48, "tree_h": 6.9, "tree_w": 271, "tree_size": 512, "t0": 1.3686, "t1": 1.45, "tft": 3.7646, "input_0": 1048, "input_1": 513, "min_CLP": -12.21, "draft_iters": 8.9, "mem_use": 46.48, "gen_rate": 6.9, "speed": 2.43, "text": "\"Certainly, here's the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 7.8, "tree_w": 193, "tree_size": 512, "t0": 1.6467, "t1": 1.41, "tft": 2.3094, "input_0": 1275, "input_1": 513, "min_CLP": -7.82, "draft_iters": 10.2, "mem_use": 43.64, "gen_rate": 7.2, "speed": 2.34, "text": "The answer is: The city of Berli"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 57, "tree_h": 7.1, "tree_w": 252, "tree_size": 512, "t0": 1.46, "t1": 1.4371, "tft": 3.3472, "input_0": 1160, "input_1": 513, "min_CLP": -10.5, "draft_iters": 9.0, "mem_use": 45.94, "gen_rate": 8.1, "speed": 2.81, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.8, "tree_w": 185, "tree_size": 512, "t0": 2.3725, "t1": 1.4375, "tft": 3.3214, "input_0": 1844, "input_1": 513, "min_CLP": -10.03, "draft_iters": 15.2, "mem_use": 45.79, "gen_rate": 9.5, "speed": 2.49, "text": "Certainly! Some of the criticism"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 224, "tree_size": 512, "t0": 1.705, "t1": 1.4083, "tft": 2.2866, "input_0": 1379, "input_1": 513, "min_CLP": -8.39, "draft_iters": 10.5, "mem_use": 43.65, "gen_rate": 5.7, "speed": 1.82, "text": "The origins of pornography can b"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 9.1, "tree_w": 255, "tree_size": 512, "t0": 1.4878, "t1": 1.4144, "tft": 2.5697, "input_0": 986, "input_1": 513, "min_CLP": -8.14, "draft_iters": 11.2, "mem_use": 43.96, "gen_rate": 3.7, "speed": 1.26, "text": "You can use the website WorldTim"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.4, "tree_w": 242, "tree_size": 512, "t0": 1.1843, "t1": 1.4157, "tft": 2.5625, "input_0": 956, "input_1": 513, "min_CLP": -8.26, "draft_iters": 7.6, "mem_use": 44.04, "gen_rate": 5.0, "speed": 1.92, "text": "The \"five-second rule\" is a myth"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.6, "tree_w": 275, "tree_size": 512, "t0": 1.2237, "t1": 1.4125, "tft": 2.5114, "input_0": 1034, "input_1": 513, "min_CLP": -11.41, "draft_iters": 8.5, "mem_use": 43.77, "gen_rate": 5.1, "speed": 1.94, "text": "\"To solve this problem, let's br"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.6, "tree_w": 262, "tree_size": 512, "t0": 1.64, "t1": 1.426, "tft": 3.0019, "input_0": 1166, "input_1": 513, "min_CLP": -11.11, "draft_iters": 10.0, "mem_use": 44.51, "gen_rate": 7.0, "speed": 2.28, "text": "\"Sure, I'd be happy to! One algo"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.1, "tree_w": 283, "tree_size": 512, "t0": 0.8318, "t1": 1.4173, "tft": 2.6494, "input_0": 843, "input_1": 513, "min_CLP": -8.75, "draft_iters": 5.1, "mem_use": 44.08, "gen_rate": 3.1, "speed": 1.37, "text": "\"You're welcome! You're a smart "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.7, "tree_w": 244, "tree_size": 512, "t0": 1.2643, "t1": 1.4129, "tft": 2.5031, "input_0": 1088, "input_1": 513, "min_CLP": -8.71, "draft_iters": 8.0, "mem_use": 43.8, "gen_rate": 4.9, "speed": 1.81, "text": "\"#OpenAssistant is here, and it'"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.1, "tree_w": 278, "tree_size": 512, "t0": 0.9971, "t1": 1.42, "tft": 2.6933, "input_0": 953, "input_1": 513, "min_CLP": -9.82, "draft_iters": 6.1, "mem_use": 44.4, "gen_rate": 4.7, "speed": 1.95, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 18.8, "tree_w": 61, "tree_size": 512, "t0": 3.605, "t1": 1.4275, "tft": 3.4339, "input_0": 2042, "input_1": 513, "min_CLP": -6.65, "draft_iters": 21.8, "mem_use": 45.43, "gen_rate": 9.8, "speed": 1.94, "text": "Sure, here are some specific way"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 205, "tree_size": 512, "t0": 1.6271, "t1": 1.4457, "tft": 3.7648, "input_0": 1090, "input_1": 513, "min_CLP": -8.41, "draft_iters": 11.3, "mem_use": 46.45, "gen_rate": 4.9, "speed": 1.58, "text": "\"[Verse 1]\\nSteve carefully navi"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.6, "tree_w": 245, "tree_size": 512, "t0": 1.3571, "t1": 1.4243, "tft": 3.185, "input_0": 1094, "input_1": 513, "min_CLP": -8.91, "draft_iters": 8.1, "mem_use": 44.95, "gen_rate": 5.3, "speed": 1.9, "text": "The scp command is specific to U"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 8.6, "tree_w": 226, "tree_size": 512, "t0": 1.57, "t1": 1.44, "tft": 3.5588, "input_0": 1148, "input_1": 513, "min_CLP": -9.66, "draft_iters": 10.6, "mem_use": 45.6, "gen_rate": 9.6, "speed": 3.19, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.6, "tree_w": 220, "tree_size": 512, "t0": 1.6443, "t1": 1.4043, "tft": 2.3063, "input_0": 1209, "input_1": 513, "min_CLP": -8.43, "draft_iters": 10.3, "mem_use": 43.71, "gen_rate": 5.1, "speed": 1.69, "text": "Yes, it would be illegal to keep"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 264, "tree_size": 512, "t0": 1.3183, "t1": 1.4117, "tft": 2.5613, "input_0": 1040, "input_1": 513, "min_CLP": -8.89, "draft_iters": 9.3, "mem_use": 43.99, "gen_rate": 5.7, "speed": 2.07, "text": "Sydney is the largest city in Au"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 53, "tree_h": 7.8, "tree_w": 233, "tree_size": 512, "t0": 1.51, "t1": 1.4133, "tft": 2.6998, "input_0": 1157, "input_1": 513, "min_CLP": -9.57, "draft_iters": 9.8, "mem_use": 44.29, "gen_rate": 8.8, "speed": 3.02, "text": "\"5 second rule is a dangerous ga"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 30, "tree_h": 3.0, "tree_w": 289, "tree_size": 512, "t0": 0.7678, "t1": 1.4144, "tft": 2.5536, "input_0": 805, "input_1": 513, "min_CLP": -8.5, "draft_iters": 4.8, "mem_use": 43.97, "gen_rate": 3.3, "speed": 1.53, "text": "\"Oh, you're not laughing? Wait t"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 253, "tree_size": 512, "t0": 1.4471, "t1": 1.4071, "tft": 2.5056, "input_0": 1119, "input_1": 513, "min_CLP": -10.96, "draft_iters": 9.0, "mem_use": 43.74, "gen_rate": 8.0, "speed": 2.8, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.2, "tree_w": 255, "tree_size": 512, "t0": 1.33, "t1": 1.4075, "tft": 2.5071, "input_0": 1076, "input_1": 513, "min_CLP": -9.44, "draft_iters": 8.6, "mem_use": 43.72, "gen_rate": 5.1, "speed": 1.87, "text": "The task is asking for the time "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 20.7, "tree_w": 123, "tree_size": 512, "t0": 3.7667, "t1": 1.4267, "tft": 3.4513, "input_0": 2240, "input_1": 513, "min_CLP": -9.73, "draft_iters": 23.0, "mem_use": 45.43, "gen_rate": 16.0, "speed": 3.08, "text": "\"The solution to the Taniyama\u2013Sh"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 7.8, "tree_w": 259, "tree_size": 512, "t0": 1.53, "t1": 1.4083, "tft": 2.2829, "input_0": 1215, "input_1": 513, "min_CLP": -9.76, "draft_iters": 9.8, "mem_use": 43.71, "gen_rate": 7.8, "speed": 2.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 298, "tree_size": 512, "t0": 0.8138, "t1": 1.4138, "tft": 2.5737, "input_0": 919, "input_1": 513, "min_CLP": -10.15, "draft_iters": 5.0, "mem_use": 44.02, "gen_rate": 4.2, "speed": 1.91, "text": "In Godot Engine 3.x, you can cre"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.2, "tree_w": 206, "tree_size": 512, "t0": 1.7062, "t1": 1.41, "tft": 2.2967, "input_0": 1294, "input_1": 513, "min_CLP": -8.82, "draft_iters": 10.0, "mem_use": 43.69, "gen_rate": 4.1, "speed": 1.32, "text": "To start learning guitar and bec"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 269, "tree_size": 512, "t0": 1.1286, "t1": 1.4157, "tft": 2.572, "input_0": 1024, "input_1": 513, "min_CLP": -10.56, "draft_iters": 7.1, "mem_use": 44.0, "gen_rate": 4.7, "speed": 1.85, "text": "Becoming one with the Force is a"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 220, "tree_size": 512, "t0": 1.4729, "t1": 1.41, "tft": 2.5273, "input_0": 1209, "input_1": 513, "min_CLP": -8.2, "draft_iters": 8.9, "mem_use": 43.86, "gen_rate": 5.1, "speed": 1.78, "text": "A gas-operated rifle uses a port"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 247, "tree_size": 512, "t0": 1.2971, "t1": 1.4071, "tft": 2.6421, "input_0": 1012, "input_1": 513, "min_CLP": -8.79, "draft_iters": 8.4, "mem_use": 44.09, "gen_rate": 4.6, "speed": 1.69, "text": "\"Steve Carell is an American act"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 10.5, "tree_w": 147, "tree_size": 512, "t0": 2.13, "t1": 1.4483, "tft": 4.0407, "input_0": 1407, "input_1": 513, "min_CLP": -7.37, "draft_iters": 13.3, "mem_use": 46.93, "gen_rate": 6.8, "speed": 1.91, "text": "Yes, using a regular expression "}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.0, "tree_w": 245, "tree_size": 512, "t0": 1.4113, "t1": 1.4163, "tft": 2.657, "input_0": 973, "input_1": 513, "min_CLP": -8.52, "draft_iters": 10.1, "mem_use": 44.16, "gen_rate": 4.4, "speed": 1.55, "text": "Yes, it would be fair to compens"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 3.5, "tree_w": 303, "tree_size": 512, "t0": 0.84, "t1": 1.45, "tft": 4.0215, "input_0": 1016, "input_1": 513, "min_CLP": -9.74, "draft_iters": 5.0, "mem_use": 47.03, "gen_rate": 3.5, "speed": 1.53, "text": "Xin ch\u00e0o! How may I assist you t"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.9, "tree_w": 275, "tree_size": 512, "t0": 1.1556, "t1": 1.42, "tft": 2.9752, "input_0": 1093, "input_1": 513, "min_CLP": -8.26, "draft_iters": 7.1, "mem_use": 44.52, "gen_rate": 3.9, "speed": 1.51, "text": "It is astonishing that people co"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 27.0, "tree_w": 42, "tree_size": 512, "t0": 4.3633, "t1": 1.4067, "tft": 2.5582, "input_0": 2228, "input_1": 513, "min_CLP": -6.19, "draft_iters": 30.0, "mem_use": 44.04, "gen_rate": 20.0, "speed": 3.47, "text": "Sure! Here\\'s a simple example o"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.1, "tree_w": 261, "tree_size": 512, "t0": 0.837, "t1": 1.433, "tft": 3.4367, "input_0": 816, "input_1": 513, "min_CLP": -9.83, "draft_iters": 5.1, "mem_use": 45.46, "gen_rate": 3.3, "speed": 1.45, "text": "1. Rammstein\\n2. Scorpions\\n3. D"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.1, "tree_w": 274, "tree_size": 512, "t0": 0.9237, "t1": 1.415, "tft": 2.5755, "input_0": 841, "input_1": 513, "min_CLP": -8.49, "draft_iters": 6.0, "mem_use": 44.01, "gen_rate": 4.2, "speed": 1.82, "text": "The best strategy to win a thumb"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 273, "tree_size": 512, "t0": 1.375, "t1": 1.4383, "tft": 3.5163, "input_0": 1336, "input_1": 513, "min_CLP": -11.17, "draft_iters": 8.3, "mem_use": 45.99, "gen_rate": 5.3, "speed": 1.89, "text": "\"To acquire revenue from custome"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.5, "tree_w": 215, "tree_size": 512, "t0": 1.54, "t1": 1.4183, "tft": 2.9663, "input_0": 1061, "input_1": 513, "min_CLP": -8.56, "draft_iters": 10.2, "mem_use": 44.63, "gen_rate": 6.2, "speed": 2.09, "text": "Yes, as a language model, I can "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 7.4, "tree_w": 233, "tree_size": 512, "t0": 1.5086, "t1": 1.4157, "tft": 2.6605, "input_0": 1217, "input_1": 513, "min_CLP": -12.88, "draft_iters": 9.6, "mem_use": 44.17, "gen_rate": 6.3, "speed": 2.15, "text": "Sure, I can help with that. Here"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.0, "tree_w": 261, "tree_size": 512, "t0": 1.574, "t1": 1.416, "tft": 2.6978, "input_0": 1465, "input_1": 513, "min_CLP": -10.88, "draft_iters": 9.4, "mem_use": 44.31, "gen_rate": 7.0, "speed": 2.34, "text": "There are a lot of APIs, librari"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.7, "tree_w": 283, "tree_size": 512, "t0": 0.9889, "t1": 1.4322, "tft": 3.4684, "input_0": 859, "input_1": 513, "min_CLP": -9.52, "draft_iters": 5.9, "mem_use": 45.56, "gen_rate": 3.8, "speed": 1.56, "text": "Certainly! Here\\'s a poem to exp"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 5.4, "tree_w": 228, "tree_size": 512, "t0": 1.3671, "t1": 1.4114, "tft": 2.2926, "input_0": 1130, "input_1": 513, "min_CLP": -8.46, "draft_iters": 7.9, "mem_use": 43.69, "gen_rate": 5.7, "speed": 2.06, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 6.2, "tree_w": 256, "tree_size": 512, "t0": 1.3713, "t1": 1.4113, "tft": 2.4996, "input_0": 1131, "input_1": 513, "min_CLP": -8.99, "draft_iters": 8.6, "mem_use": 43.73, "gen_rate": 5.0, "speed": 1.8, "text": "The error is that the method `ge"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 3.0, "tree_w": 331, "tree_size": 512, "t0": 0.82, "t1": 1.42, "tft": 3.2196, "input_0": 851, "input_1": 513, "min_CLP": -10.6, "draft_iters": 5.0, "mem_use": 45.1, "gen_rate": 0.0, "speed": 0.0, "text": "None"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 7.2, "tree_w": 265, "tree_size": 512, "t0": 1.336, "t1": 1.416, "tft": 2.7079, "input_0": 987, "input_1": 513, "min_CLP": -9.31, "draft_iters": 9.4, "mem_use": 44.33, "gen_rate": 7.8, "speed": 2.84, "text": "In Python, the `@` symbol is use"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.8, "tree_w": 241, "tree_size": 512, "t0": 1.4817, "t1": 1.4167, "tft": 2.7298, "input_0": 1055, "input_1": 513, "min_CLP": -8.21, "draft_iters": 10.2, "mem_use": 44.45, "gen_rate": 6.2, "speed": 2.13, "text": "\"To create a program that suppor"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 135, "tree_size": 512, "t0": 2.5075, "t1": 1.44, "tft": 3.6674, "input_0": 1733, "input_1": 513, "min_CLP": -7.09, "draft_iters": 15.2, "mem_use": 46.21, "gen_rate": 8.5, "speed": 2.16, "text": "\"As an assistant, I can't make s"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 299, "tree_size": 512, "t0": 0.8725, "t1": 1.4138, "tft": 2.6871, "input_0": 922, "input_1": 513, "min_CLP": -9.65, "draft_iters": 5.2, "mem_use": 44.24, "gen_rate": 4.2, "speed": 1.86, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 6.9, "tree_w": 265, "tree_size": 512, "t0": 1.4071, "t1": 1.4386, "tft": 3.563, "input_0": 1048, "input_1": 513, "min_CLP": -10.09, "draft_iters": 8.9, "mem_use": 45.59, "gen_rate": 6.3, "speed": 2.21, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 221, "tree_size": 512, "t0": 1.405, "t1": 1.4083, "tft": 2.282, "input_0": 1109, "input_1": 513, "min_CLP": -8.59, "draft_iters": 8.3, "mem_use": 43.67, "gen_rate": 5.3, "speed": 1.9, "text": "Yes, I can simulate thinking and"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.8, "tree_w": 232, "tree_size": 512, "t0": 1.3, "t1": 1.4113, "tft": 2.5432, "input_0": 944, "input_1": 513, "min_CLP": -8.39, "draft_iters": 9.0, "mem_use": 43.89, "gen_rate": 4.0, "speed": 1.48, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 26, "tree_h": 5.8, "tree_w": 251, "tree_size": 512, "t0": 1.342, "t1": 1.414, "tft": 2.6378, "input_0": 1152, "input_1": 513, "min_CLP": -8.14, "draft_iters": 7.8, "mem_use": 44.13, "gen_rate": 5.2, "speed": 1.89, "text": "Thanks, I try my best to provide"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 6.9, "tree_w": 277, "tree_size": 512, "t0": 1.2243, "t1": 1.4371, "tft": 6.3339, "input_0": 926, "input_1": 513, "min_CLP": -9.26, "draft_iters": 8.9, "mem_use": 45.72, "gen_rate": 7.7, "speed": 2.9, "text": "\"Thou art the sun that shineth b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 231, "tree_size": 512, "t0": 1.45, "t1": 1.4133, "tft": 2.6995, "input_0": 1107, "input_1": 513, "min_CLP": -9.66, "draft_iters": 9.0, "mem_use": 44.31, "gen_rate": 5.3, "speed": 1.86, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.0, "tree_w": 224, "tree_size": 512, "t0": 1.9, "t1": 1.4175, "tft": 2.5204, "input_0": 1492, "input_1": 513, "min_CLP": -9.59, "draft_iters": 12.2, "mem_use": 43.71, "gen_rate": 10.2, "speed": 3.09, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 18.8, "tree_w": 116, "tree_size": 512, "t0": 3.13, "t1": 1.412, "tft": 2.3103, "input_0": 1743, "input_1": 513, "min_CLP": -7.18, "draft_iters": 21.6, "mem_use": 43.69, "gen_rate": 8.0, "speed": 1.76, "text": "\"Sure, Presidents' Day is a fede"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 6.6, "tree_w": 240, "tree_size": 512, "t0": 1.274, "t1": 1.416, "tft": 2.5711, "input_0": 979, "input_1": 513, "min_CLP": -9.12, "draft_iters": 8.8, "mem_use": 43.99, "gen_rate": 7.2, "speed": 2.68, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.6, "tree_w": 269, "tree_size": 512, "t0": 1.1925, "t1": 1.4263, "tft": 3.0176, "input_0": 1081, "input_1": 513, "min_CLP": -10.05, "draft_iters": 6.9, "mem_use": 44.78, "gen_rate": 4.4, "speed": 1.67, "text": "No, the US National Reconnaissan"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.9, "tree_w": 273, "tree_size": 512, "t0": 1.0057, "t1": 1.4186, "tft": 2.5908, "input_0": 953, "input_1": 513, "min_CLP": -8.5, "draft_iters": 6.0, "mem_use": 44.07, "gen_rate": 4.6, "speed": 1.89, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.4, "tree_w": 237, "tree_size": 512, "t0": 1.2433, "t1": 1.4167, "tft": 2.6546, "input_0": 968, "input_1": 513, "min_CLP": -8.14, "draft_iters": 7.8, "mem_use": 44.14, "gen_rate": 3.6, "speed": 1.34, "text": "That is an interesting designati"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 250, "tree_size": 512, "t0": 1.1538, "t1": 1.4138, "tft": 2.2925, "input_0": 965, "input_1": 513, "min_CLP": -9.21, "draft_iters": 7.2, "mem_use": 43.69, "gen_rate": 4.2, "speed": 1.65, "text": "Yes, the American Taxpayer Fund "}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.6, "tree_w": 244, "tree_size": 512, "t0": 1.1538, "t1": 1.42, "tft": 2.7318, "input_0": 998, "input_1": 513, "min_CLP": -9.79, "draft_iters": 7.0, "mem_use": 44.37, "gen_rate": 4.4, "speed": 1.7, "text": "\"Ted Kaczynski is like, what\\'s "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 237, "tree_size": 512, "t0": 1.3914, "t1": 1.4143, "tft": 2.5332, "input_0": 1175, "input_1": 513, "min_CLP": -9.51, "draft_iters": 8.3, "mem_use": 43.81, "gen_rate": 4.6, "speed": 1.63, "text": "The mayonnaise has broken, and i"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 284, "tree_size": 512, "t0": 1.1325, "t1": 1.4287, "tft": 3.3802, "input_0": 1069, "input_1": 513, "min_CLP": -9.02, "draft_iters": 7.0, "mem_use": 45.02, "gen_rate": 4.0, "speed": 1.56, "text": "Sure! Here are some movies and b"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 168, "tree_size": 512, "t0": 2.256, "t1": 1.416, "tft": 2.6615, "input_0": 1408, "input_1": 513, "min_CLP": -8.3, "draft_iters": 14.0, "mem_use": 44.13, "gen_rate": 6.4, "speed": 1.74, "text": "I am an AI language model, not a"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 236, "tree_size": 512, "t0": 1.5386, "t1": 1.4357, "tft": 3.4021, "input_0": 1097, "input_1": 513, "min_CLP": -9.96, "draft_iters": 10.0, "mem_use": 45.32, "gen_rate": 5.0, "speed": 1.68, "text": "I would recommend the Emerald La"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 267, "tree_size": 512, "t0": 0.8456, "t1": 1.4178, "tft": 2.6446, "input_0": 839, "input_1": 513, "min_CLP": -8.73, "draft_iters": 5.1, "mem_use": 44.08, "gen_rate": 3.9, "speed": 1.72, "text": "\"Open Assistant: Open Source Cha"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.1, "tree_w": 229, "tree_size": 512, "t0": 1.6457, "t1": 1.4143, "tft": 2.584, "input_0": 1178, "input_1": 513, "min_CLP": -8.58, "draft_iters": 11.4, "mem_use": 43.98, "gen_rate": 5.7, "speed": 1.87, "text": "\"Sure, I can illustrate the solu"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 201, "tree_size": 512, "t0": 1.824, "t1": 1.442, "tft": 3.6887, "input_0": 1348, "input_1": 513, "min_CLP": -7.8, "draft_iters": 11.8, "mem_use": 46.3, "gen_rate": 6.6, "speed": 2.02, "text": "\"The issue you're experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 5.9, "tree_w": 239, "tree_size": 512, "t0": 1.3629, "t1": 1.4071, "tft": 2.3088, "input_0": 1168, "input_1": 513, "min_CLP": -9.39, "draft_iters": 8.3, "mem_use": 43.68, "gen_rate": 6.0, "speed": 2.17, "text": "\"Yes, you can compile Python cod"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.1, "tree_w": 286, "tree_size": 512, "t0": 0.8156, "t1": 1.4167, "tft": 2.6668, "input_0": 850, "input_1": 513, "min_CLP": -8.19, "draft_iters": 5.0, "mem_use": 44.22, "gen_rate": 3.6, "speed": 1.59, "text": "\"Pirating video games is not oka"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 195, "tree_size": 512, "t0": 1.9833, "t1": 1.4133, "tft": 2.5364, "input_0": 1423, "input_1": 513, "min_CLP": -7.81, "draft_iters": 12.3, "mem_use": 43.85, "gen_rate": 5.8, "speed": 1.72, "text": "This matters because the heat fr"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 14.8, "tree_w": 145, "tree_size": 512, "t0": 2.5633, "t1": 1.41, "tft": 2.3218, "input_0": 1514, "input_1": 513, "min_CLP": -8.26, "draft_iters": 17.7, "mem_use": 43.69, "gen_rate": 7.0, "speed": 1.76, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 257, "tree_size": 512, "t0": 1.3029, "t1": 1.4386, "tft": 3.6121, "input_0": 1193, "input_1": 513, "min_CLP": -10.34, "draft_iters": 7.9, "mem_use": 45.75, "gen_rate": 5.0, "speed": 1.82, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.8, "tree_w": 282, "tree_size": 512, "t0": 0.9078, "t1": 1.4133, "tft": 2.2959, "input_0": 867, "input_1": 513, "min_CLP": -8.76, "draft_iters": 5.7, "mem_use": 43.65, "gen_rate": 3.7, "speed": 1.58, "text": "\"The instruction is asking if a "}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.9, "tree_w": 211, "tree_size": 512, "t0": 1.8114, "t1": 1.4071, "tft": 2.5237, "input_0": 1242, "input_1": 513, "min_CLP": -7.9, "draft_iters": 11.3, "mem_use": 43.73, "gen_rate": 5.3, "speed": 1.64, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 7.6, "tree_w": 250, "tree_size": 512, "t0": 1.53, "t1": 1.4557, "tft": 4.0056, "input_0": 1214, "input_1": 513, "min_CLP": -11.66, "draft_iters": 9.9, "mem_use": 46.99, "gen_rate": 6.7, "speed": 2.25, "text": "As of my knowledge cutoff in 202"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 5.5, "tree_w": 256, "tree_size": 512, "t0": 1.2913, "t1": 1.4237, "tft": 3.2008, "input_0": 1106, "input_1": 513, "min_CLP": -9.01, "draft_iters": 7.8, "mem_use": 44.98, "gen_rate": 4.9, "speed": 1.8, "text": "I apologize for the confusion ea"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.0, "tree_w": 123, "tree_size": 512, "t0": 2.9625, "t1": 1.405, "tft": 2.5576, "input_0": 1746, "input_1": 513, "min_CLP": -8.47, "draft_iters": 20.0, "mem_use": 43.95, "gen_rate": 10.0, "speed": 2.29, "text": "Certainly! Here are some resourc"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 287, "tree_size": 512, "t0": 1.0938, "t1": 1.4163, "tft": 2.5517, "input_0": 910, "input_1": 513, "min_CLP": -10.33, "draft_iters": 7.5, "mem_use": 43.92, "gen_rate": 4.2, "speed": 1.69, "text": "def most_effective_tax_fraud_met"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 9.2, "tree_w": 196, "tree_size": 512, "t0": 1.8667, "t1": 1.4033, "tft": 2.2904, "input_0": 1251, "input_1": 513, "min_CLP": -11.02, "draft_iters": 12.0, "mem_use": 43.69, "gen_rate": 7.7, "speed": 2.34, "text": "The Theory of Sexual Selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 233, "tree_size": 512, "t0": 1.4229, "t1": 1.4214, "tft": 2.9729, "input_0": 1002, "input_1": 513, "min_CLP": -8.62, "draft_iters": 10.1, "mem_use": 44.5, "gen_rate": 4.7, "speed": 1.66, "text": "Sure, here\\'s an ASCII represent"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 216, "tree_size": 512, "t0": 2.0633, "t1": 1.4233, "tft": 6.0033, "input_0": 1406, "input_1": 513, "min_CLP": -11.86, "draft_iters": 13.7, "mem_use": 44.53, "gen_rate": 5.7, "speed": 1.62, "text": "Claro, aqu\u00ed tienes las 3 mejores"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.0, "tree_w": 163, "tree_size": 512, "t0": 2.7425, "t1": 1.45, "tft": 4.013, "input_0": 1804, "input_1": 513, "min_CLP": -9.45, "draft_iters": 18.2, "mem_use": 47.01, "gen_rate": 8.0, "speed": 1.91, "text": "\"Sure! Here's a concise version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 258, "tree_size": 512, "t0": 1.415, "t1": 1.4083, "tft": 2.3118, "input_0": 1091, "input_1": 513, "min_CLP": -11.63, "draft_iters": 9.7, "mem_use": 43.7, "gen_rate": 8.7, "speed": 3.07, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 4.6, "tree_w": 244, "tree_size": 512, "t0": 1.134, "t1": 1.418, "tft": 2.6825, "input_0": 970, "input_1": 513, "min_CLP": -8.41, "draft_iters": 6.9, "mem_use": 44.25, "gen_rate": 3.8, "speed": 1.49, "text": "\"Berlin has been a major locatio"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 19.0, "tree_w": 127, "tree_size": 512, "t0": 3.4967, "t1": 1.4067, "tft": 2.5158, "input_0": 1972, "input_1": 513, "min_CLP": -8.48, "draft_iters": 22.3, "mem_use": 43.73, "gen_rate": 18.0, "speed": 3.67, "text": "Here is a Python script that sav"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 150, "tree_size": 512, "t0": 2.825, "t1": 1.45, "tft": 6.8252, "input_0": 1542, "input_1": 513, "min_CLP": -8.09, "draft_iters": 18.5, "mem_use": 46.23, "gen_rate": 17.5, "speed": 4.09, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 62, "tree_h": 7.3, "tree_w": 245, "tree_size": 512, "t0": 1.4944, "t1": 1.4089, "tft": 2.3237, "input_0": 1122, "input_1": 513, "min_CLP": -10.75, "draft_iters": 9.4, "mem_use": 43.65, "gen_rate": 6.9, "speed": 2.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.0, "tree_w": 214, "tree_size": 512, "t0": 1.8517, "t1": 1.4367, "tft": 3.3281, "input_0": 1293, "input_1": 513, "min_CLP": -9.85, "draft_iters": 12.7, "mem_use": 45.88, "gen_rate": 6.7, "speed": 2.03, "text": "\"Here are some potential solutio"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 293, "tree_size": 512, "t0": 0.8662, "t1": 1.4137, "tft": 2.2761, "input_0": 919, "input_1": 513, "min_CLP": -9.2, "draft_iters": 5.2, "mem_use": 43.66, "gen_rate": 4.2, "speed": 1.86, "text": "The answer is: We need AI assist"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.1, "tree_w": 276, "tree_size": 512, "t0": 0.8167, "t1": 1.4133, "tft": 2.3028, "input_0": 839, "input_1": 513, "min_CLP": -9.9, "draft_iters": 5.0, "mem_use": 43.65, "gen_rate": 3.8, "speed": 1.7, "text": "\u5728\u4e2d\u6587\u91cc\uff0c\u4f60\u5982\u4f55\u8868\u8fbe\u201c\u6211\u7231\u4e2d\u56fd\u201d\u8fd9\u53e5\u8bdd\uff1f [INST] <<SY"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 244, "tree_size": 512, "t0": 1.4317, "t1": 1.4117, "tft": 2.5112, "input_0": 1085, "input_1": 513, "min_CLP": -12.74, "draft_iters": 9.7, "mem_use": 43.8, "gen_rate": 8.7, "speed": 3.05, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 147, "tree_size": 512, "t0": 2.06, "t1": 1.425, "tft": 3.1706, "input_0": 1354, "input_1": 513, "min_CLP": -13.12, "draft_iters": 13.2, "mem_use": 44.84, "gen_rate": 8.0, "speed": 2.3, "text": "In the 1950s, the quality of lif"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.3, "tree_w": 224, "tree_size": 512, "t0": 1.715, "t1": 1.4117, "tft": 2.51, "input_0": 1414, "input_1": 513, "min_CLP": -9.45, "draft_iters": 10.5, "mem_use": 43.75, "gen_rate": 6.7, "speed": 2.13, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 299, "tree_size": 512, "t0": 0.8075, "t1": 1.4125, "tft": 2.5519, "input_0": 863, "input_1": 513, "min_CLP": -9.48, "draft_iters": 5.0, "mem_use": 43.95, "gen_rate": 4.1, "speed": 1.86, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 269, "tree_size": 512, "t0": 1.1443, "t1": 1.4129, "tft": 2.6872, "input_0": 1061, "input_1": 513, "min_CLP": -9.47, "draft_iters": 7.1, "mem_use": 44.29, "gen_rate": 4.7, "speed": 1.84, "text": "In the context of firearms, sele"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 236, "tree_size": 512, "t0": 1.3438, "t1": 1.4163, "tft": 2.5243, "input_0": 1003, "input_1": 513, "min_CLP": -8.42, "draft_iters": 8.6, "mem_use": 43.84, "gen_rate": 4.1, "speed": 1.49, "text": "I am a goddess of love, fertilit"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 10.9, "tree_w": 198, "tree_size": 512, "t0": 2.01, "t1": 1.4257, "tft": 3.2156, "input_0": 1414, "input_1": 513, "min_CLP": -12.3, "draft_iters": 13.3, "mem_use": 45.04, "gen_rate": 5.9, "speed": 1.7, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.9, "tree_w": 259, "tree_size": 512, "t0": 1.105, "t1": 1.4137, "tft": 2.5141, "input_0": 975, "input_1": 513, "min_CLP": -8.23, "draft_iters": 7.0, "mem_use": 43.74, "gen_rate": 4.5, "speed": 1.79, "text": "[Answer]<|endoftext|>Human: The "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 281, "tree_size": 512, "t0": 1.2171, "t1": 1.4214, "tft": 2.9868, "input_0": 1251, "input_1": 513, "min_CLP": -10.69, "draft_iters": 7.6, "mem_use": 44.56, "gen_rate": 4.7, "speed": 1.79, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 229, "tree_size": 512, "t0": 1.5583, "t1": 1.41, "tft": 2.545, "input_0": 1248, "input_1": 513, "min_CLP": -8.63, "draft_iters": 9.3, "mem_use": 43.84, "gen_rate": 5.8, "speed": 1.97, "text": "Pros:\\n1. Increased tolerance to"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 4.2, "tree_w": 276, "tree_size": 512, "t0": 1.0322, "t1": 1.4078, "tft": 2.2834, "input_0": 929, "input_1": 513, "min_CLP": -10.79, "draft_iters": 6.4, "mem_use": 43.67, "gen_rate": 4.4, "speed": 1.82, "text": "\"The Schr\u00f6dinger's cat thought e"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 295, "tree_size": 512, "t0": 0.8463, "t1": 1.4663, "tft": 4.9948, "input_0": 957, "input_1": 513, "min_CLP": -9.55, "draft_iters": 5.1, "mem_use": 47.94, "gen_rate": 4.4, "speed": 1.89, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 246, "tree_size": 512, "t0": 1.3414, "t1": 1.4129, "tft": 2.5724, "input_0": 1034, "input_1": 513, "min_CLP": -9.13, "draft_iters": 9.0, "mem_use": 43.98, "gen_rate": 8.0, "speed": 2.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.5, "tree_w": 121, "tree_size": 512, "t0": 2.925, "t1": 1.42, "tft": 3.156, "input_0": 1982, "input_1": 513, "min_CLP": -7.74, "draft_iters": 17.0, "mem_use": 44.84, "gen_rate": 10.2, "speed": 2.36, "text": "The time it takes to go around t"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.0, "tree_w": 274, "tree_size": 512, "t0": 1.0037, "t1": 1.4462, "tft": 3.5177, "input_0": 903, "input_1": 513, "min_CLP": -8.77, "draft_iters": 6.1, "mem_use": 46.08, "gen_rate": 4.1, "speed": 1.68, "text": "One way to prevent spiders from "}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 245, "tree_size": 512, "t0": 1.1888, "t1": 1.4163, "tft": 2.5592, "input_0": 1036, "input_1": 513, "min_CLP": -8.34, "draft_iters": 7.4, "mem_use": 43.96, "gen_rate": 4.1, "speed": 1.58, "text": "\"Here's another one for you: Why"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 19, "tree_h": 3.4, "tree_w": 291, "tree_size": 512, "t0": 0.896, "t1": 1.414, "tft": 2.5558, "input_0": 973, "input_1": 513, "min_CLP": -10.5, "draft_iters": 5.4, "mem_use": 43.99, "gen_rate": 3.8, "speed": 1.64, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 174, "tree_size": 512, "t0": 2.052, "t1": 1.418, "tft": 2.9745, "input_0": 1460, "input_1": 513, "min_CLP": -9.0, "draft_iters": 12.8, "mem_use": 44.45, "gen_rate": 6.6, "speed": 1.9, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 270, "tree_size": 512, "t0": 1.3629, "t1": 1.4143, "tft": 2.5557, "input_0": 1095, "input_1": 513, "min_CLP": -13.4, "draft_iters": 9.1, "mem_use": 43.97, "gen_rate": 8.0, "speed": 2.88, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.6, "tree_w": 229, "tree_size": 512, "t0": 1.2789, "t1": 1.4211, "tft": 2.97, "input_0": 1058, "input_1": 513, "min_CLP": -9.76, "draft_iters": 7.9, "mem_use": 44.64, "gen_rate": 3.9, "speed": 1.44, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 170, "tree_size": 512, "t0": 2.31, "t1": 1.414, "tft": 2.5686, "input_0": 1233, "input_1": 513, "min_CLP": -7.92, "draft_iters": 16.2, "mem_use": 43.99, "gen_rate": 6.6, "speed": 1.77, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.3, "tree_w": 202, "tree_size": 512, "t0": 1.76, "t1": 1.4133, "tft": 2.5057, "input_0": 1468, "input_1": 513, "min_CLP": -9.59, "draft_iters": 10.2, "mem_use": 43.72, "gen_rate": 6.2, "speed": 1.94, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.0, "tree_w": 238, "tree_size": 512, "t0": 1.78, "t1": 1.4075, "tft": 2.2879, "input_0": 1261, "input_1": 513, "min_CLP": -11.46, "draft_iters": 12.0, "mem_use": 43.68, "gen_rate": 11.0, "speed": 3.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 28, "tree_h": 7.7, "tree_w": 270, "tree_size": 512, "t0": 1.5183, "t1": 1.4633, "tft": 5.0021, "input_0": 1342, "input_1": 513, "min_CLP": -9.79, "draft_iters": 9.7, "mem_use": 47.93, "gen_rate": 4.7, "speed": 1.57, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.1, "tree_w": 204, "tree_size": 512, "t0": 1.5443, "t1": 1.4071, "tft": 2.5318, "input_0": 1148, "input_1": 513, "min_CLP": -8.73, "draft_iters": 9.6, "mem_use": 43.82, "gen_rate": 5.6, "speed": 1.89, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 170, "tree_size": 512, "t0": 2.228, "t1": 1.43, "tft": 3.4045, "input_0": 1616, "input_1": 513, "min_CLP": -7.53, "draft_iters": 13.2, "mem_use": 45.33, "gen_rate": 7.0, "speed": 1.91, "text": "Certainly! One example of produc"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 4.7, "tree_w": 279, "tree_size": 512, "t0": 1.0929, "t1": 1.4271, "tft": 3.2176, "input_0": 1050, "input_1": 513, "min_CLP": -10.3, "draft_iters": 6.7, "mem_use": 45.09, "gen_rate": 5.1, "speed": 2.04, "text": "When you use the Command Prompt "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 224, "tree_size": 512, "t0": 2.16, "t1": 1.41, "tft": 2.5481, "input_0": 1627, "input_1": 513, "min_CLP": -13.48, "draft_iters": 14.0, "mem_use": 43.95, "gen_rate": 13.0, "speed": 3.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 206, "tree_size": 512, "t0": 1.982, "t1": 1.408, "tft": 2.507, "input_0": 1295, "input_1": 513, "min_CLP": -10.94, "draft_iters": 13.2, "mem_use": 43.77, "gen_rate": 7.0, "speed": 2.06, "text": "To determine whether you should "}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 7.1, "tree_w": 257, "tree_size": 512, "t0": 1.3386, "t1": 1.4114, "tft": 2.5239, "input_0": 1046, "input_1": 513, "min_CLP": -9.67, "draft_iters": 9.1, "mem_use": 43.74, "gen_rate": 7.7, "speed": 2.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 4.6, "tree_w": 277, "tree_size": 512, "t0": 1.09, "t1": 1.4267, "tft": 3.0154, "input_0": 980, "input_1": 513, "min_CLP": -8.85, "draft_iters": 6.7, "mem_use": 44.73, "gen_rate": 4.6, "speed": 1.81, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.1, "tree_w": 282, "tree_size": 512, "t0": 0.8156, "t1": 1.4189, "tft": 2.5798, "input_0": 850, "input_1": 513, "min_CLP": -9.32, "draft_iters": 5.0, "mem_use": 44.07, "gen_rate": 3.6, "speed": 1.59, "text": "Is the universe infinite? [GEN]\\"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 287, "tree_size": 512, "t0": 0.8425, "t1": 1.4325, "tft": 3.4327, "input_0": 856, "input_1": 513, "min_CLP": -10.12, "draft_iters": 5.1, "mem_use": 45.37, "gen_rate": 4.1, "speed": 1.81, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.7, "tree_w": 249, "tree_size": 512, "t0": 1.1543, "t1": 1.42, "tft": 2.6979, "input_0": 1006, "input_1": 513, "min_CLP": -8.04, "draft_iters": 7.0, "mem_use": 44.3, "gen_rate": 4.9, "speed": 1.89, "text": "I think the answerer is someone "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 276, "tree_size": 512, "t0": 0.8475, "t1": 1.4187, "tft": 2.6612, "input_0": 847, "input_1": 513, "min_CLP": -8.5, "draft_iters": 5.1, "mem_use": 44.14, "gen_rate": 4.0, "speed": 1.76, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.7, "tree_w": 227, "tree_size": 512, "t0": 1.51, "t1": 1.4133, "tft": 2.5524, "input_0": 1249, "input_1": 513, "min_CLP": -10.33, "draft_iters": 9.0, "mem_use": 43.88, "gen_rate": 6.0, "speed": 2.05, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 230, "tree_size": 512, "t0": 1.3386, "t1": 1.4486, "tft": 3.8074, "input_0": 1011, "input_1": 513, "min_CLP": -10.73, "draft_iters": 9.0, "mem_use": 46.65, "gen_rate": 8.0, "speed": 2.87, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 215, "tree_size": 512, "t0": 2.0133, "t1": 1.4433, "tft": 3.7805, "input_0": 1319, "input_1": 513, "min_CLP": -10.15, "draft_iters": 14.3, "mem_use": 46.58, "gen_rate": 13.3, "speed": 3.86, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.7, "tree_w": 253, "tree_size": 512, "t0": 1.3314, "t1": 1.4071, "tft": 2.3084, "input_0": 1157, "input_1": 513, "min_CLP": -8.65, "draft_iters": 8.1, "mem_use": 43.68, "gen_rate": 5.3, "speed": 1.93, "text": "\"Sure, here's a poem inspired by"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 297, "tree_size": 512, "t0": 0.815, "t1": 1.4287, "tft": 3.0484, "input_0": 867, "input_1": 513, "min_CLP": -10.44, "draft_iters": 5.0, "mem_use": 44.82, "gen_rate": 4.1, "speed": 1.84, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 12.7, "tree_w": 184, "tree_size": 512, "t0": 2.2633, "t1": 1.4333, "tft": 3.3801, "input_0": 1386, "input_1": 513, "min_CLP": -7.84, "draft_iters": 15.3, "mem_use": 45.27, "gen_rate": 8.3, "speed": 2.26, "text": "\"I apologize for any confusion o"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 195, "tree_size": 512, "t0": 2.162, "t1": 1.404, "tft": 2.2741, "input_0": 1480, "input_1": 513, "min_CLP": -7.92, "draft_iters": 14.0, "mem_use": 43.66, "gen_rate": 6.8, "speed": 1.91, "text": "\"The normalization of a vector i"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.0, "tree_w": 249, "tree_size": 512, "t0": 1.09, "t1": 1.4111, "tft": 2.5488, "input_0": 945, "input_1": 513, "min_CLP": -8.44, "draft_iters": 7.1, "mem_use": 43.95, "gen_rate": 4.0, "speed": 1.6, "text": "Twerk? Twerk? Twerk. I am a godd"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 19.5, "tree_w": 58, "tree_size": 512, "t0": 3.62, "t1": 1.43, "tft": 3.4734, "input_0": 1932, "input_1": 513, "min_CLP": -6.76, "draft_iters": 23.0, "mem_use": 45.51, "gen_rate": 17.0, "speed": 3.37, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 232, "tree_size": 512, "t0": 1.7, "t1": 1.4133, "tft": 2.5258, "input_0": 1409, "input_1": 513, "min_CLP": -9.65, "draft_iters": 10.5, "mem_use": 43.89, "gen_rate": 5.5, "speed": 1.77, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 18.6, "tree_w": 168, "tree_size": 512, "t0": 2.756, "t1": 1.434, "tft": 3.3928, "input_0": 1451, "input_1": 513, "min_CLP": -7.61, "draft_iters": 21.2, "mem_use": 45.21, "gen_rate": 6.8, "speed": 1.62, "text": "\"Sure, here's a more detailed an"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.0, "tree_w": 216, "tree_size": 512, "t0": 1.6871, "t1": 1.4114, "tft": 2.2951, "input_0": 1201, "input_1": 513, "min_CLP": -8.44, "draft_iters": 10.7, "mem_use": 43.69, "gen_rate": 5.3, "speed": 1.71, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 249, "tree_size": 512, "t0": 1.42, "t1": 1.4083, "tft": 2.3162, "input_0": 1091, "input_1": 513, "min_CLP": -12.62, "draft_iters": 9.7, "mem_use": 43.7, "gen_rate": 8.7, "speed": 3.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 58, "tree_h": 13.0, "tree_w": 171, "tree_size": 512, "t0": 2.462, "t1": 1.414, "tft": 2.7132, "input_0": 1487, "input_1": 513, "min_CLP": -7.78, "draft_iters": 15.4, "mem_use": 44.34, "gen_rate": 11.6, "speed": 2.99, "text": "\"Okay, let's do both!\\nHere's a "}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 229, "tree_size": 512, "t0": 1.3943, "t1": 1.4243, "tft": 2.9829, "input_0": 1132, "input_1": 513, "min_CLP": -9.48, "draft_iters": 9.4, "mem_use": 44.56, "gen_rate": 4.9, "speed": 1.72, "text": "Apologies for the mistake in the"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 19, "tree_h": 3.0, "tree_w": 289, "tree_size": 512, "t0": 0.802, "t1": 1.41, "tft": 2.2771, "input_0": 796, "input_1": 513, "min_CLP": -8.5, "draft_iters": 5.0, "mem_use": 43.67, "gen_rate": 3.8, "speed": 1.72, "text": "A 7.62x39mm AK-47 is a type of a"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.6, "tree_w": 280, "tree_size": 512, "t0": 1.0838, "t1": 1.4087, "tft": 2.5704, "input_0": 1027, "input_1": 513, "min_CLP": -8.9, "draft_iters": 6.8, "mem_use": 44.02, "gen_rate": 4.4, "speed": 1.75, "text": "To copy a directory from Server "}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 7.2, "tree_w": 268, "tree_size": 512, "t0": 1.5283, "t1": 1.4333, "tft": 3.4291, "input_0": 1157, "input_1": 513, "min_CLP": -9.68, "draft_iters": 9.5, "mem_use": 45.39, "gen_rate": 7.7, "speed": 2.59, "text": "* Statistical modeling involves "}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 225, "tree_size": 512, "t0": 1.4986, "t1": 1.41, "tft": 2.5682, "input_0": 1100, "input_1": 513, "min_CLP": -9.22, "draft_iters": 9.7, "mem_use": 44.0, "gen_rate": 4.7, "speed": 1.62, "text": "The answer is:\\n\\nTo start a suc"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.3, "tree_w": 257, "tree_size": 512, "t0": 1.1729, "t1": 1.4229, "tft": 2.9585, "input_0": 1054, "input_1": 513, "min_CLP": -8.5, "draft_iters": 7.4, "mem_use": 44.5, "gen_rate": 5.0, "speed": 1.93, "text": "While it may not be harmful to l"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 20, "tree_h": 4.3, "tree_w": 273, "tree_size": 512, "t0": 0.9933, "t1": 1.42, "tft": 2.65, "input_0": 854, "input_1": 513, "min_CLP": -8.25, "draft_iters": 6.5, "mem_use": 44.15, "gen_rate": 3.3, "speed": 1.38, "text": "You could tell them you are happ"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 5.7, "tree_w": 236, "tree_size": 512, "t0": 1.3633, "t1": 1.42, "tft": 2.6858, "input_0": 1231, "input_1": 513, "min_CLP": -8.29, "draft_iters": 8.0, "mem_use": 44.25, "gen_rate": 3.7, "speed": 1.32, "text": "Question: What is the difference"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.7, "tree_w": 276, "tree_size": 512, "t0": 1.1829, "t1": 1.4129, "tft": 2.3058, "input_0": 1158, "input_1": 513, "min_CLP": -9.46, "draft_iters": 6.9, "mem_use": 43.67, "gen_rate": 4.9, "speed": 1.87, "text": "I am thinking of a variety of th"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.5, "tree_w": 223, "tree_size": 512, "t0": 1.575, "t1": 1.4062, "tft": 2.2701, "input_0": 1199, "input_1": 513, "min_CLP": -13.32, "draft_iters": 9.9, "mem_use": 43.67, "gen_rate": 4.2, "speed": 1.43, "text": "Cryptocurrencies have come a lon"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 270, "tree_size": 512, "t0": 1.3543, "t1": 1.4171, "tft": 2.6708, "input_0": 1122, "input_1": 513, "min_CLP": -9.23, "draft_iters": 9.3, "mem_use": 44.2, "gen_rate": 4.9, "speed": 1.75, "text": "L-theanine is an amino acid that"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.1, "tree_w": 266, "tree_size": 512, "t0": 1.3471, "t1": 1.4143, "tft": 2.5675, "input_0": 1203, "input_1": 513, "min_CLP": -12.66, "draft_iters": 9.0, "mem_use": 43.97, "gen_rate": 4.9, "speed": 1.76, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 230, "tree_size": 512, "t0": 1.6667, "t1": 1.415, "tft": 2.5136, "input_0": 1144, "input_1": 513, "min_CLP": -9.05, "draft_iters": 10.5, "mem_use": 43.76, "gen_rate": 5.5, "speed": 1.78, "text": "Here is the phone conversation f"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 23, "tree_h": 6.0, "tree_w": 270, "tree_size": 512, "t0": 1.1786, "t1": 1.4157, "tft": 2.5076, "input_0": 940, "input_1": 513, "min_CLP": -9.68, "draft_iters": 8.1, "mem_use": 43.72, "gen_rate": 3.3, "speed": 1.27, "text": "\"The user's question is: Why can"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.0, "tree_w": 265, "tree_size": 512, "t0": 1.15, "t1": 1.4212, "tft": 2.7092, "input_0": 1063, "input_1": 513, "min_CLP": -8.79, "draft_iters": 7.1, "mem_use": 44.28, "gen_rate": 4.6, "speed": 1.8, "text": "Bliss was chosen to be the defau"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.9, "tree_w": 244, "tree_size": 512, "t0": 1.1843, "t1": 1.4586, "tft": 4.1371, "input_0": 985, "input_1": 513, "min_CLP": -8.46, "draft_iters": 7.1, "mem_use": 47.31, "gen_rate": 4.9, "speed": 1.84, "text": "\"It's not a good idea to use you"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.4, "tree_w": 226, "tree_size": 512, "t0": 1.5875, "t1": 1.44, "tft": 3.5231, "input_0": 1160, "input_1": 513, "min_CLP": -8.19, "draft_iters": 10.1, "mem_use": 46.05, "gen_rate": 4.6, "speed": 1.53, "text": "\"I'm sorry, but I'm not sure wha"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.8, "tree_w": 223, "tree_size": 512, "t0": 1.3033, "t1": 1.4183, "tft": 2.7167, "input_0": 1048, "input_1": 513, "min_CLP": -8.88, "draft_iters": 8.0, "mem_use": 44.33, "gen_rate": 5.7, "speed": 2.08, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 199, "tree_size": 512, "t0": 2.3933, "t1": 1.4067, "tft": 2.3002, "input_0": 1646, "input_1": 513, "min_CLP": -12.63, "draft_iters": 14.3, "mem_use": 43.67, "gen_rate": 13.3, "speed": 3.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.3, "tree_w": 246, "tree_size": 512, "t0": 1.3843, "t1": 1.4129, "tft": 2.2832, "input_0": 1205, "input_1": 513, "min_CLP": -8.55, "draft_iters": 8.6, "mem_use": 43.67, "gen_rate": 5.3, "speed": 1.89, "text": "Yes, I can speak German. However"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 14.2, "tree_w": 187, "tree_size": 512, "t0": 2.19, "t1": 1.41, "tft": 2.5299, "input_0": 1411, "input_1": 513, "min_CLP": -7.48, "draft_iters": 16.0, "mem_use": 43.86, "gen_rate": 10.0, "speed": 2.78, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 173, "tree_size": 512, "t0": 2.036, "t1": 1.422, "tft": 3.0183, "input_0": 1435, "input_1": 513, "min_CLP": -9.7, "draft_iters": 12.6, "mem_use": 44.74, "gen_rate": 6.6, "speed": 1.91, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 218, "tree_size": 512, "t0": 1.852, "t1": 1.432, "tft": 3.4082, "input_0": 1307, "input_1": 513, "min_CLP": -8.36, "draft_iters": 11.0, "mem_use": 45.31, "gen_rate": 6.4, "speed": 1.95, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.4, "tree_w": 280, "tree_size": 512, "t0": 0.9025, "t1": 1.4163, "tft": 2.5138, "input_0": 932, "input_1": 513, "min_CLP": -10.96, "draft_iters": 5.4, "mem_use": 43.72, "gen_rate": 4.2, "speed": 1.83, "text": "Sure, here are some examples of "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 6.6, "tree_w": 263, "tree_size": 512, "t0": 1.1871, "t1": 1.4171, "tft": 2.663, "input_0": 897, "input_1": 513, "min_CLP": -8.56, "draft_iters": 8.6, "mem_use": 44.08, "gen_rate": 5.9, "speed": 2.25, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n[INST]"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 299, "tree_size": 512, "t0": 0.8775, "t1": 1.4163, "tft": 2.3039, "input_0": 928, "input_1": 513, "min_CLP": -13.59, "draft_iters": 5.2, "mem_use": 43.68, "gen_rate": 4.2, "speed": 1.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 6.4, "tree_w": 248, "tree_size": 512, "t0": 1.34, "t1": 1.4175, "tft": 2.5751, "input_0": 1032, "input_1": 513, "min_CLP": -8.4, "draft_iters": 8.6, "mem_use": 44.03, "gen_rate": 5.2, "speed": 1.9, "text": "The Trolley Problem is a thought"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 191, "tree_size": 512, "t0": 1.7533, "t1": 1.415, "tft": 2.5485, "input_0": 1377, "input_1": 513, "min_CLP": -8.92, "draft_iters": 10.3, "mem_use": 43.95, "gen_rate": 5.8, "speed": 1.84, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 196, "tree_size": 512, "t0": 2.22, "t1": 1.44, "tft": 3.5137, "input_0": 1215, "input_1": 513, "min_CLP": -10.89, "draft_iters": 18.5, "mem_use": 45.97, "gen_rate": 17.5, "speed": 4.78, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.6, "tree_w": 274, "tree_size": 512, "t0": 0.9071, "t1": 1.4143, "tft": 2.5372, "input_0": 1021, "input_1": 513, "min_CLP": -9.39, "draft_iters": 5.4, "mem_use": 43.84, "gen_rate": 4.6, "speed": 1.97, "text": "Here\\'s a code snippet that draw"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 280, "tree_size": 512, "t0": 0.8237, "t1": 1.4525, "tft": 3.7879, "input_0": 843, "input_1": 513, "min_CLP": -10.79, "draft_iters": 5.0, "mem_use": 46.68, "gen_rate": 4.1, "speed": 1.81, "text": "[INST] Write a long erotic story"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 210, "tree_size": 512, "t0": 1.91, "t1": 1.4125, "tft": 2.5098, "input_0": 1301, "input_1": 513, "min_CLP": -8.37, "draft_iters": 12.8, "mem_use": 43.71, "gen_rate": 8.0, "speed": 2.41, "text": "Sure, here is an example of ASCI"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.2, "tree_w": 298, "tree_size": 512, "t0": 0.8322, "t1": 1.41, "tft": 2.282, "input_0": 898, "input_1": 513, "min_CLP": -9.51, "draft_iters": 5.1, "mem_use": 43.67, "gen_rate": 3.9, "speed": 1.73, "text": "HTML and JavaScript are two diff"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.7, "tree_w": 139, "tree_size": 512, "t0": 2.92, "t1": 1.4067, "tft": 2.2942, "input_0": 1571, "input_1": 513, "min_CLP": -9.62, "draft_iters": 21.3, "mem_use": 43.7, "gen_rate": 11.3, "speed": 2.62, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.2, "tree_w": 248, "tree_size": 512, "t0": 1.3988, "t1": 1.4087, "tft": 2.574, "input_0": 1155, "input_1": 513, "min_CLP": -9.62, "draft_iters": 8.6, "mem_use": 44.06, "gen_rate": 4.4, "speed": 1.56, "text": "No. It is not in the public doma"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.2, "tree_w": 243, "tree_size": 512, "t0": 1.2675, "t1": 1.4125, "tft": 2.299, "input_0": 1079, "input_1": 513, "min_CLP": -9.06, "draft_iters": 7.8, "mem_use": 43.68, "gen_rate": 4.4, "speed": 1.63, "text": "\"The second batch of pancakes ma"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 52, "tree_h": 19.2, "tree_w": 153, "tree_size": 512, "t0": 2.996, "t1": 1.424, "tft": 3.011, "input_0": 1699, "input_1": 513, "min_CLP": -9.05, "draft_iters": 21.0, "mem_use": 44.73, "gen_rate": 10.4, "speed": 2.35, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 271, "tree_size": 512, "t0": 1.1371, "t1": 1.4229, "tft": 2.7251, "input_0": 1012, "input_1": 513, "min_CLP": -8.75, "draft_iters": 7.1, "mem_use": 44.44, "gen_rate": 4.7, "speed": 1.84, "text": "Thank you for the clarification."}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 3.0, "tree_w": 271, "tree_size": 512, "t0": 0.806, "t1": 1.417, "tft": 2.6936, "input_0": 791, "input_1": 513, "min_CLP": -8.1, "draft_iters": 5.0, "mem_use": 44.29, "gen_rate": 3.2, "speed": 1.44, "text": "\"In that case, no. If the studio"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.4, "tree_w": 218, "tree_size": 512, "t0": 1.5557, "t1": 1.4271, "tft": 3.1977, "input_0": 1178, "input_1": 513, "min_CLP": -10.59, "draft_iters": 9.1, "mem_use": 45.0, "gen_rate": 5.4, "speed": 1.82, "text": "That sounds like a compelling me"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.5, "tree_w": 259, "tree_size": 512, "t0": 1.0413, "t1": 1.4075, "tft": 2.3047, "input_0": 859, "input_1": 513, "min_CLP": -8.76, "draft_iters": 6.8, "mem_use": 43.66, "gen_rate": 4.1, "speed": 1.68, "text": "\"Here is an ASCII art of a cat:\\"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 6.2, "tree_w": 220, "tree_size": 512, "t0": 1.4238, "t1": 1.4075, "tft": 2.5538, "input_0": 1133, "input_1": 513, "min_CLP": -8.94, "draft_iters": 8.8, "mem_use": 43.97, "gen_rate": 5.0, "speed": 1.77, "text": "Sure, I\\'d be happy to help! My "}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.6, "tree_w": 264, "tree_size": 512, "t0": 1.0871, "t1": 1.43, "tft": 3.0141, "input_0": 1024, "input_1": 513, "min_CLP": -11.05, "draft_iters": 6.7, "mem_use": 44.71, "gen_rate": 4.7, "speed": 1.88, "text": "As of early 2022, the James Webb"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.9, "tree_w": 232, "tree_size": 512, "t0": 1.4487, "t1": 1.4075, "tft": 2.5086, "input_0": 1088, "input_1": 513, "min_CLP": -8.08, "draft_iters": 9.2, "mem_use": 43.77, "gen_rate": 4.4, "speed": 1.53, "text": "Motion matching is a technique u"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 231, "tree_size": 512, "t0": 2.61, "t1": 1.43, "tft": 3.4344, "input_0": 1835, "input_1": 513, "min_CLP": -11.82, "draft_iters": 15.0, "mem_use": 45.38, "gen_rate": 13.0, "speed": 3.21, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.0, "tree_w": 172, "tree_size": 512, "t0": 2.505, "t1": 1.415, "tft": 2.5046, "input_0": 1723, "input_1": 513, "min_CLP": -8.18, "draft_iters": 16.5, "mem_use": 43.72, "gen_rate": 9.0, "speed": 2.3, "text": "\"Here's an example of how to imp"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.1, "tree_w": 307, "tree_size": 512, "t0": 0.7856, "t1": 1.4156, "tft": 2.6503, "input_0": 863, "input_1": 513, "min_CLP": -10.55, "draft_iters": 4.9, "mem_use": 44.1, "gen_rate": 3.9, "speed": 1.77, "text": "Sure, here\\'s a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 5.9, "tree_w": 240, "tree_size": 512, "t0": 1.4243, "t1": 1.4329, "tft": 3.4074, "input_0": 1092, "input_1": 513, "min_CLP": -13.95, "draft_iters": 8.6, "mem_use": 45.38, "gen_rate": 5.7, "speed": 2.0, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 46, "tree_h": 7.6, "tree_w": 240, "tree_size": 512, "t0": 1.5543, "t1": 1.4343, "tft": 3.3063, "input_0": 1163, "input_1": 513, "min_CLP": -8.78, "draft_iters": 10.0, "mem_use": 45.82, "gen_rate": 6.6, "speed": 2.2, "text": "\"Paul Allen's collection of figh"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.2, "tree_w": 246, "tree_size": 512, "t0": 1.525, "t1": 1.43, "tft": 3.1645, "input_0": 1270, "input_1": 513, "min_CLP": -8.31, "draft_iters": 9.5, "mem_use": 45.26, "gen_rate": 6.0, "speed": 2.03, "text": "I apologize for the oversight in"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 65, "tree_size": 512, "t0": 4.345, "t1": 1.405, "tft": 2.5012, "input_0": 2093, "input_1": 513, "min_CLP": -8.19, "draft_iters": 32.0, "mem_use": 43.76, "gen_rate": 30.5, "speed": 5.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 217, "tree_size": 512, "t0": 1.5357, "t1": 1.4229, "tft": 2.7229, "input_0": 1156, "input_1": 513, "min_CLP": -7.97, "draft_iters": 9.4, "mem_use": 44.37, "gen_rate": 5.0, "speed": 1.69, "text": "I, as a Large Language Model, am"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 289, "tree_size": 512, "t0": 0.8438, "t1": 1.4187, "tft": 2.5307, "input_0": 946, "input_1": 513, "min_CLP": -10.85, "draft_iters": 5.1, "mem_use": 43.78, "gen_rate": 4.4, "speed": 1.93, "text": "A car manufacturer can use a var"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 263, "tree_size": 512, "t0": 1.2183, "t1": 1.4117, "tft": 2.2815, "input_0": 1087, "input_1": 513, "min_CLP": -11.08, "draft_iters": 7.3, "mem_use": 43.67, "gen_rate": 5.3, "speed": 2.03, "text": "Yes, the 5-second rule is a comm"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 12.3, "tree_w": 185, "tree_size": 512, "t0": 2.105, "t1": 1.4233, "tft": 2.9761, "input_0": 1298, "input_1": 513, "min_CLP": -8.02, "draft_iters": 14.8, "mem_use": 44.49, "gen_rate": 7.2, "speed": 2.03, "text": "\"You're welcome! I'm always here"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.2, "tree_w": 61, "tree_size": 512, "t0": 3.605, "t1": 1.4275, "tft": 3.3816, "input_0": 1997, "input_1": 513, "min_CLP": -6.61, "draft_iters": 24.5, "mem_use": 45.3, "gen_rate": 8.2, "speed": 1.64, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.1, "tree_w": 284, "tree_size": 512, "t0": 0.85, "t1": 1.4444, "tft": 3.5419, "input_0": 853, "input_1": 513, "min_CLP": -8.9, "draft_iters": 5.1, "mem_use": 46.19, "gen_rate": 3.7, "speed": 1.6, "text": "Multi-track drifting is an inter"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 217, "tree_size": 512, "t0": 1.706, "t1": 1.424, "tft": 3.0416, "input_0": 1225, "input_1": 513, "min_CLP": -8.73, "draft_iters": 10.8, "mem_use": 44.8, "gen_rate": 6.4, "speed": 2.04, "text": "\"A completely purple sky is not "}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 237, "tree_size": 512, "t0": 1.6275, "t1": 1.425, "tft": 2.9742, "input_0": 1096, "input_1": 513, "min_CLP": -9.58, "draft_iters": 11.8, "mem_use": 44.63, "gen_rate": 10.8, "speed": 3.52, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.4, "tree_w": 285, "tree_size": 512, "t0": 0.8687, "t1": 1.4287, "tft": 2.7349, "input_0": 952, "input_1": 513, "min_CLP": -10.89, "draft_iters": 5.2, "mem_use": 44.41, "gen_rate": 4.2, "speed": 1.85, "text": "In Japanese, \"love\" is \"\u611b (ai)\","}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 163, "tree_size": 512, "t0": 2.226, "t1": 1.418, "tft": 2.5588, "input_0": 1458, "input_1": 513, "min_CLP": -8.88, "draft_iters": 13.8, "mem_use": 43.96, "gen_rate": 6.8, "speed": 1.87, "text": "In Europe, some of the best univ"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 9.1, "tree_w": 208, "tree_size": 512, "t0": 1.9229, "t1": 1.4129, "tft": 2.2846, "input_0": 1388, "input_1": 513, "min_CLP": -8.95, "draft_iters": 11.7, "mem_use": 43.65, "gen_rate": 6.1, "speed": 1.84, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 8.2, "tree_w": 250, "tree_size": 512, "t0": 1.448, "t1": 1.418, "tft": 2.5224, "input_0": 1046, "input_1": 513, "min_CLP": -8.77, "draft_iters": 10.4, "mem_use": 43.79, "gen_rate": 3.4, "speed": 1.19, "text": "def markdown_to_html(markdown):\\"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.0, "tree_w": 141, "tree_size": 512, "t0": 2.29, "t1": 1.42, "tft": 3.1728, "input_0": 1399, "input_1": 513, "min_CLP": -7.42, "draft_iters": 15.0, "mem_use": 44.9, "gen_rate": 6.0, "speed": 1.62, "text": "1. Financial stress: Budgeting, "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.9, "tree_w": 185, "tree_size": 512, "t0": 1.8629, "t1": 1.4071, "tft": 2.2893, "input_0": 1368, "input_1": 513, "min_CLP": -8.61, "draft_iters": 11.6, "mem_use": 43.65, "gen_rate": 5.4, "speed": 1.66, "text": "Hello! I don\\'t have a specific "}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 309, "tree_size": 512, "t0": 0.815, "t1": 1.4425, "tft": 3.6917, "input_0": 829, "input_1": 513, "min_CLP": -11.08, "draft_iters": 5.0, "mem_use": 46.29, "gen_rate": 4.0, "speed": 1.77, "text": "An example of where you might us"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 200, "tree_size": 512, "t0": 1.7243, "t1": 1.4143, "tft": 2.5507, "input_0": 1222, "input_1": 513, "min_CLP": -9.38, "draft_iters": 10.7, "mem_use": 43.94, "gen_rate": 4.7, "speed": 1.5, "text": "Yes, hairy bittercress is a memb"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 258, "tree_size": 512, "t0": 1.4717, "t1": 1.4067, "tft": 2.5046, "input_0": 1126, "input_1": 513, "min_CLP": -14.96, "draft_iters": 9.7, "mem_use": 43.73, "gen_rate": 8.5, "speed": 2.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 242, "tree_size": 512, "t0": 1.43, "t1": 1.4371, "tft": 3.3375, "input_0": 1174, "input_1": 513, "min_CLP": -11.18, "draft_iters": 9.3, "mem_use": 45.88, "gen_rate": 4.9, "speed": 1.69, "text": "Yes, here are some open source 2"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 4.6, "tree_w": 266, "tree_size": 512, "t0": 1.11, "t1": 1.415, "tft": 2.5162, "input_0": 958, "input_1": 513, "min_CLP": -11.65, "draft_iters": 6.9, "mem_use": 43.72, "gen_rate": 5.1, "speed": 2.03, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 200, "tree_size": 512, "t0": 1.9533, "t1": 1.4233, "tft": 2.7242, "input_0": 1267, "input_1": 513, "min_CLP": -9.67, "draft_iters": 14.3, "mem_use": 44.41, "gen_rate": 13.3, "speed": 3.95, "text": "[INST] Ok, but is there a most e"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 279, "tree_size": 512, "t0": 0.8475, "t1": 1.44, "tft": 3.3851, "input_0": 851, "input_1": 513, "min_CLP": -10.49, "draft_iters": 5.1, "mem_use": 45.28, "gen_rate": 4.0, "speed": 1.75, "text": "1. m\u00eb (suffix): meh\\n2. meles, m"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 229, "tree_size": 512, "t0": 1.4267, "t1": 1.415, "tft": 2.5661, "input_0": 1064, "input_1": 513, "min_CLP": -8.61, "draft_iters": 8.7, "mem_use": 43.97, "gen_rate": 5.3, "speed": 1.88, "text": "Once upon a time, in a world whe"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 57, "tree_h": 18.0, "tree_w": 154, "tree_size": 512, "t0": 2.814, "t1": 1.448, "tft": 3.7973, "input_0": 1690, "input_1": 513, "min_CLP": -9.3, "draft_iters": 20.4, "mem_use": 46.7, "gen_rate": 11.4, "speed": 2.67, "text": "\"I apologize for any inaccuracie"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 294, "tree_size": 512, "t0": 0.8625, "t1": 1.4087, "tft": 2.3067, "input_0": 923, "input_1": 513, "min_CLP": -9.95, "draft_iters": 5.2, "mem_use": 43.69, "gen_rate": 4.2, "speed": 1.87, "text": "\"To format an URL in reStructure"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 18.3, "tree_w": 136, "tree_size": 512, "t0": 3.2467, "t1": 1.4333, "tft": 3.559, "input_0": 1820, "input_1": 513, "min_CLP": -7.61, "draft_iters": 21.0, "mem_use": 45.67, "gen_rate": 14.7, "speed": 3.13, "text": "\"Here's an example code that set"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 256, "tree_size": 512, "t0": 1.2688, "t1": 1.4125, "tft": 2.2868, "input_0": 1202, "input_1": 513, "min_CLP": -9.3, "draft_iters": 7.6, "mem_use": 43.67, "gen_rate": 4.4, "speed": 1.63, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.5, "tree_w": 278, "tree_size": 512, "t0": 0.8988, "t1": 1.4175, "tft": 2.643, "input_0": 856, "input_1": 513, "min_CLP": -8.24, "draft_iters": 5.5, "mem_use": 44.12, "gen_rate": 4.0, "speed": 1.73, "text": "The AI technology is growing rea"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.8, "tree_w": 276, "tree_size": 512, "t0": 1.0011, "t1": 1.4844, "tft": 5.8405, "input_0": 987, "input_1": 513, "min_CLP": -9.35, "draft_iters": 5.9, "mem_use": 49.25, "gen_rate": 3.9, "speed": 1.57, "text": "\"Yes, I'd be happy to help!\\n\\n["}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 5.0, "tree_w": 248, "tree_size": 512, "t0": 1.1371, "t1": 1.4229, "tft": 5.5767, "input_0": 905, "input_1": 513, "min_CLP": -8.04, "draft_iters": 7.3, "mem_use": 44.5, "gen_rate": 5.4, "speed": 2.12, "text": "0 A law firm that specializes in"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.0, "tree_w": 254, "tree_size": 512, "t0": 1.36, "t1": 1.4425, "tft": 3.6957, "input_0": 1129, "input_1": 513, "min_CLP": -8.52, "draft_iters": 8.4, "mem_use": 46.33, "gen_rate": 4.8, "speed": 1.69, "text": "I understand that you may have r"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.9, "tree_w": 265, "tree_size": 512, "t0": 1.1543, "t1": 1.4257, "tft": 3.0, "input_0": 1061, "input_1": 513, "min_CLP": -8.6, "draft_iters": 7.0, "mem_use": 44.71, "gen_rate": 4.7, "speed": 1.83, "text": "1. Economic downturn: If the loc"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.0, "tree_w": 175, "tree_size": 512, "t0": 1.7757, "t1": 1.41, "tft": 2.5623, "input_0": 1232, "input_1": 513, "min_CLP": -7.56, "draft_iters": 11.6, "mem_use": 44.0, "gen_rate": 4.6, "speed": 1.44, "text": "Certainly! Here\u2019s an inspiration"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 172, "tree_size": 512, "t0": 2.17, "t1": 1.432, "tft": 3.7603, "input_0": 1420, "input_1": 513, "min_CLP": -8.5, "draft_iters": 14.2, "mem_use": 46.45, "gen_rate": 7.0, "speed": 1.94, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 3.0, "tree_w": 307, "tree_size": 512, "t0": 0.75, "t1": 1.42, "tft": 2.6833, "input_0": 827, "input_1": 513, "min_CLP": -10.08, "draft_iters": 4.7, "mem_use": 44.17, "gen_rate": 2.7, "speed": 1.23, "text": "What is the most cost effective "}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.0, "tree_w": 188, "tree_size": 512, "t0": 2.215, "t1": 1.4325, "tft": 3.5339, "input_0": 1683, "input_1": 513, "min_CLP": -14.7, "draft_iters": 13.5, "mem_use": 46.11, "gen_rate": 8.8, "speed": 2.4, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.1, "tree_w": 278, "tree_size": 512, "t0": 1.1714, "t1": 1.4129, "tft": 2.3044, "input_0": 1244, "input_1": 513, "min_CLP": -10.45, "draft_iters": 7.0, "mem_use": 43.71, "gen_rate": 5.3, "speed": 2.05, "text": "\"Sure! Here's an implementation "}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.1, "tree_w": 263, "tree_size": 512, "t0": 0.8444, "t1": 1.4233, "tft": 2.7233, "input_0": 835, "input_1": 513, "min_CLP": -10.81, "draft_iters": 5.1, "mem_use": 44.42, "gen_rate": 3.8, "speed": 1.67, "text": "\"The laws for nudity in Wyoming "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 238, "tree_size": 512, "t0": 1.2829, "t1": 1.4171, "tft": 2.6652, "input_0": 986, "input_1": 513, "min_CLP": -7.96, "draft_iters": 8.1, "mem_use": 44.15, "gen_rate": 4.9, "speed": 1.8, "text": "You should try to drink plenty o"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 171, "tree_size": 512, "t0": 2.252, "t1": 1.406, "tft": 2.5173, "input_0": 1481, "input_1": 513, "min_CLP": -7.88, "draft_iters": 15.6, "mem_use": 43.75, "gen_rate": 7.0, "speed": 1.91, "text": "\"To create a smooth Snake game i"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 159, "tree_size": 512, "t0": 2.194, "t1": 1.414, "tft": 2.971, "input_0": 1536, "input_1": 513, "min_CLP": -7.65, "draft_iters": 13.4, "mem_use": 44.62, "gen_rate": 7.0, "speed": 1.94, "text": "\"To overcome the fear of looking"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.4, "tree_w": 198, "tree_size": 512, "t0": 2.0386, "t1": 1.44, "tft": 3.5357, "input_0": 1279, "input_1": 513, "min_CLP": -9.67, "draft_iters": 14.0, "mem_use": 46.2, "gen_rate": 5.3, "speed": 1.52, "text": "Certainly! Here is a list of som"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 256, "tree_size": 512, "t0": 1.4217, "t1": 1.4117, "tft": 2.5384, "input_0": 1083, "input_1": 513, "min_CLP": -12.57, "draft_iters": 9.7, "mem_use": 43.87, "gen_rate": 8.7, "speed": 3.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 59, "tree_h": 15.3, "tree_w": 170, "tree_size": 512, "t0": 2.6367, "t1": 1.4083, "tft": 2.5253, "input_0": 1558, "input_1": 513, "min_CLP": -9.95, "draft_iters": 17.7, "mem_use": 43.77, "gen_rate": 9.8, "speed": 2.43, "text": "\"```js\\nconst { Client, Collecti"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.0, "tree_w": 207, "tree_size": 512, "t0": 1.7517, "t1": 1.41, "tft": 2.304, "input_0": 1267, "input_1": 513, "min_CLP": -8.09, "draft_iters": 10.5, "mem_use": 43.67, "gen_rate": 6.2, "speed": 1.95, "text": "Yes, I am a capable assistant de"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.2, "tree_w": 231, "tree_size": 512, "t0": 1.582, "t1": 1.456, "tft": 4.5328, "input_0": 1290, "input_1": 513, "min_CLP": -9.98, "draft_iters": 10.4, "mem_use": 47.41, "gen_rate": 7.0, "speed": 2.31, "text": "The main reason to use TypeScrip"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.3, "tree_w": 252, "tree_size": 512, "t0": 1.173, "t1": 1.409, "tft": 2.5195, "input_0": 962, "input_1": 513, "min_CLP": -9.39, "draft_iters": 7.5, "mem_use": 43.79, "gen_rate": 3.6, "speed": 1.39, "text": "\"The name of the fourth kid is M"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 265, "tree_size": 512, "t0": 1.3213, "t1": 1.4212, "tft": 3.0372, "input_0": 985, "input_1": 513, "min_CLP": -9.64, "draft_iters": 8.4, "mem_use": 44.81, "gen_rate": 7.4, "speed": 2.69, "text": "You can pay for an account with "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 195, "tree_size": 512, "t0": 1.806, "t1": 1.44, "tft": 3.7588, "input_0": 1308, "input_1": 513, "min_CLP": -7.86, "draft_iters": 11.2, "mem_use": 46.56, "gen_rate": 6.8, "speed": 2.09, "text": "Toasting bread is typically a ma"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 250, "tree_size": 512, "t0": 1.3386, "t1": 1.4129, "tft": 2.5569, "input_0": 1105, "input_1": 513, "min_CLP": -8.74, "draft_iters": 8.3, "mem_use": 43.92, "gen_rate": 4.6, "speed": 1.66, "text": "As an AI language model, I am no"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 15, "tree_h": 3.0, "tree_w": 326, "tree_size": 512, "t0": 0.744, "t1": 1.456, "tft": 2.7228, "input_0": 843, "input_1": 513, "min_CLP": -11.17, "draft_iters": 4.6, "mem_use": 44.41, "gen_rate": 3.0, "speed": 1.36, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 13.5, "tree_w": 127, "tree_size": 512, "t0": 2.56, "t1": 1.4425, "tft": 3.5229, "input_0": 1631, "input_1": 513, "min_CLP": -7.56, "draft_iters": 16.2, "mem_use": 46.12, "gen_rate": 10.5, "speed": 2.62, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.3, "tree_w": 116, "tree_size": 512, "t0": 3.0567, "t1": 1.4167, "tft": 2.9948, "input_0": 1732, "input_1": 513, "min_CLP": -7.58, "draft_iters": 20.3, "mem_use": 44.54, "gen_rate": 10.7, "speed": 2.38, "text": "The first television sets were i"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 25, "tree_h": 8.5, "tree_w": 223, "tree_size": 512, "t0": 1.6717, "t1": 1.4517, "tft": 4.0663, "input_0": 1173, "input_1": 513, "min_CLP": -10.38, "draft_iters": 11.0, "mem_use": 46.85, "gen_rate": 4.2, "speed": 1.33, "text": "\"I'm glad to hear that you found"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.3, "tree_w": 217, "tree_size": 512, "t0": 1.81, "t1": 1.4329, "tft": 3.266, "input_0": 1195, "input_1": 513, "min_CLP": -9.75, "draft_iters": 12.7, "mem_use": 45.19, "gen_rate": 5.4, "speed": 1.67, "text": "The reason there are multiple da"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 290, "tree_size": 512, "t0": 0.8388, "t1": 1.415, "tft": 2.6693, "input_0": 865, "input_1": 513, "min_CLP": -9.08, "draft_iters": 5.1, "mem_use": 44.23, "gen_rate": 4.0, "speed": 1.77, "text": "\"I apologize for my earlier stat"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 226, "tree_size": 512, "t0": 1.5533, "t1": 1.4383, "tft": 3.5034, "input_0": 1308, "input_1": 513, "min_CLP": -11.02, "draft_iters": 9.3, "mem_use": 46.0, "gen_rate": 5.8, "speed": 1.95, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 12.3, "tree_w": 196, "tree_size": 512, "t0": 2.2433, "t1": 1.4133, "tft": 2.5456, "input_0": 1452, "input_1": 513, "min_CLP": -8.4, "draft_iters": 14.8, "mem_use": 43.86, "gen_rate": 6.5, "speed": 1.78, "text": "\"Yes, it is possible for you to "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.2, "tree_w": 251, "tree_size": 512, "t0": 1.2933, "t1": 1.4189, "tft": 2.9858, "input_0": 946, "input_1": 513, "min_CLP": -8.51, "draft_iters": 9.4, "mem_use": 44.47, "gen_rate": 3.9, "speed": 1.43, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 60, "tree_h": 14.2, "tree_w": 175, "tree_size": 512, "t0": 2.355, "t1": 1.4133, "tft": 2.5462, "input_0": 1369, "input_1": 513, "min_CLP": -9.0, "draft_iters": 16.7, "mem_use": 43.95, "gen_rate": 10.0, "speed": 2.65, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.1, "tree_w": 272, "tree_size": 512, "t0": 0.8011, "t1": 1.4144, "tft": 2.5478, "input_0": 825, "input_1": 513, "min_CLP": -8.79, "draft_iters": 5.0, "mem_use": 43.97, "gen_rate": 3.8, "speed": 1.7, "text": "100,000,000,000,000,000,000,000,"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 292, "tree_size": 512, "t0": 0.8163, "t1": 1.42, "tft": 2.708, "input_0": 854, "input_1": 513, "min_CLP": -8.76, "draft_iters": 5.0, "mem_use": 44.35, "gen_rate": 4.1, "speed": 1.84, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.2, "tree_w": 261, "tree_size": 512, "t0": 1.1983, "t1": 1.415, "tft": 2.6616, "input_0": 1188, "input_1": 513, "min_CLP": -9.5, "draft_iters": 7.8, "mem_use": 44.13, "gen_rate": 6.2, "speed": 2.36, "text": "Prime numbers are important beca"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 153, "tree_size": 512, "t0": 2.4575, "t1": 1.405, "tft": 2.539, "input_0": 1624, "input_1": 513, "min_CLP": -8.16, "draft_iters": 16.2, "mem_use": 43.9, "gen_rate": 8.8, "speed": 2.27, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.1, "tree_w": 171, "tree_size": 512, "t0": 2.2957, "t1": 1.4071, "tft": 2.496, "input_0": 1607, "input_1": 513, "min_CLP": -9.43, "draft_iters": 14.0, "mem_use": 43.75, "gen_rate": 5.3, "speed": 1.43, "text": "To improve your Wi-Fi coverage i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 225, "tree_size": 512, "t0": 1.3933, "t1": 1.4133, "tft": 2.5184, "input_0": 1073, "input_1": 513, "min_CLP": -9.29, "draft_iters": 8.3, "mem_use": 43.78, "gen_rate": 5.3, "speed": 1.9, "text": "\"Certainly! Here's a SPL (Shakes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 251, "tree_size": 512, "t0": 1.325, "t1": 1.4083, "tft": 2.3134, "input_0": 1102, "input_1": 513, "min_CLP": -9.12, "draft_iters": 9.5, "mem_use": 43.7, "gen_rate": 5.7, "speed": 2.07, "text": "[INST] Write a whitepaper for ou"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.5, "tree_w": 263, "tree_size": 512, "t0": 1.4217, "t1": 1.4267, "tft": 3.1685, "input_0": 1172, "input_1": 513, "min_CLP": -8.88, "draft_iters": 8.8, "mem_use": 44.86, "gen_rate": 6.0, "speed": 2.11, "text": "\"In this case, you can use your "}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 4.3, "tree_w": 278, "tree_size": 512, "t0": 1.0629, "t1": 1.4071, "tft": 2.2942, "input_0": 994, "input_1": 513, "min_CLP": -8.68, "draft_iters": 6.4, "mem_use": 43.66, "gen_rate": 4.9, "speed": 1.97, "text": "The \"@\" symbol in Python is know"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.6, "tree_w": 168, "tree_size": 512, "t0": 2.034, "t1": 1.406, "tft": 2.273, "input_0": 1365, "input_1": 513, "min_CLP": -7.66, "draft_iters": 13.2, "mem_use": 43.67, "gen_rate": 8.4, "speed": 2.44, "text": "I think ChatGPT is an impressive"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 54, "tree_h": 8.0, "tree_w": 251, "tree_size": 512, "t0": 1.46, "t1": 1.4117, "tft": 2.5553, "input_0": 1190, "input_1": 513, "min_CLP": -12.24, "draft_iters": 10.0, "mem_use": 43.97, "gen_rate": 9.0, "speed": 3.14, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 299, "tree_size": 512, "t0": 1.0343, "t1": 1.41, "tft": 3.5877, "input_0": 977, "input_1": 513, "min_CLP": -10.73, "draft_iters": 6.6, "mem_use": 43.72, "gen_rate": 4.6, "speed": 1.87, "text": "Sure! Here\\'s an example of a Ma"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 6.3, "tree_w": 247, "tree_size": 512, "t0": 1.3957, "t1": 1.42, "tft": 2.7197, "input_0": 1151, "input_1": 513, "min_CLP": -9.64, "draft_iters": 8.4, "mem_use": 44.39, "gen_rate": 6.1, "speed": 2.18, "text": "\"[INST] What is the main purpose"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 258, "tree_size": 512, "t0": 1.2312, "t1": 1.4562, "tft": 4.0642, "input_0": 940, "input_1": 513, "min_CLP": -10.86, "draft_iters": 8.4, "mem_use": 46.89, "gen_rate": 7.4, "speed": 2.74, "text": "The current date is 2023-02-06.\\"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 48, "tree_h": 9.0, "tree_w": 229, "tree_size": 512, "t0": 1.7717, "t1": 1.415, "tft": 2.6684, "input_0": 1347, "input_1": 513, "min_CLP": -9.3, "draft_iters": 11.3, "mem_use": 44.21, "gen_rate": 8.0, "speed": 2.51, "text": "Yes, decorators can do things th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 3.0, "tree_w": 323, "tree_size": 512, "t0": 0.815, "t1": 1.435, "tft": 3.4044, "input_0": 841, "input_1": 513, "min_CLP": -9.77, "draft_iters": 5.0, "mem_use": 45.31, "gen_rate": 3.0, "speed": 1.33, "text": "Hello there, how may I assist yo"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 8.8, "tree_w": 247, "tree_size": 512, "t0": 1.5475, "t1": 1.4138, "tft": 2.662, "input_0": 1057, "input_1": 513, "min_CLP": -9.86, "draft_iters": 11.0, "mem_use": 44.19, "gen_rate": 5.8, "speed": 1.94, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 8.9, "tree_w": 245, "tree_size": 512, "t0": 1.6475, "t1": 1.455, "tft": 4.017, "input_0": 1162, "input_1": 513, "min_CLP": -9.44, "draft_iters": 11.1, "mem_use": 47.07, "gen_rate": 5.8, "speed": 1.85, "text": "Sure! Here are some code example"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 11.8, "tree_w": 199, "tree_size": 512, "t0": 2.268, "t1": 1.522, "tft": 8.6112, "input_0": 1550, "input_1": 513, "min_CLP": -9.77, "draft_iters": 14.2, "mem_use": 53.09, "gen_rate": 9.6, "speed": 2.53, "text": "\"Sure, here's an example code fo"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.5, "tree_w": 191, "tree_size": 512, "t0": 2.165, "t1": 1.4225, "tft": 3.4471, "input_0": 1476, "input_1": 513, "min_CLP": -8.35, "draft_iters": 14.8, "mem_use": 45.42, "gen_rate": 9.8, "speed": 2.72, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.0, "tree_w": 266, "tree_size": 512, "t0": 1.2667, "t1": 1.405, "tft": 4.0884, "input_0": 1154, "input_1": 513, "min_CLP": -10.85, "draft_iters": 7.3, "mem_use": 43.73, "gen_rate": 5.7, "speed": 2.12, "text": "The instruction you provided, \"H"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 216, "tree_size": 512, "t0": 1.85, "t1": 1.408, "tft": 2.5274, "input_0": 1213, "input_1": 513, "min_CLP": -8.59, "draft_iters": 13.2, "mem_use": 43.83, "gen_rate": 7.2, "speed": 2.21, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.8, "tree_w": 124, "tree_size": 512, "t0": 2.6325, "t1": 1.4375, "tft": 3.7655, "input_0": 1694, "input_1": 513, "min_CLP": -7.21, "draft_iters": 16.2, "mem_use": 46.58, "gen_rate": 9.2, "speed": 2.27, "text": "Sure, here are some tips for cre"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 6.9, "tree_w": 235, "tree_size": 512, "t0": 1.5, "t1": 1.4029, "tft": 2.5189, "input_0": 1274, "input_1": 513, "min_CLP": -9.34, "draft_iters": 9.1, "mem_use": 43.77, "gen_rate": 6.1, "speed": 2.12, "text": "The world in 1950 was quite diff"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 5.8, "tree_w": 262, "tree_size": 512, "t0": 1.37, "t1": 1.466, "tft": 5.3973, "input_0": 1135, "input_1": 513, "min_CLP": -11.05, "draft_iters": 8.2, "mem_use": 48.74, "gen_rate": 6.4, "speed": 2.26, "text": "Creating your own Stable Diffusi"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 58, "tree_h": 8.4, "tree_w": 249, "tree_size": 512, "t0": 1.485, "t1": 1.405, "tft": 2.6428, "input_0": 1044, "input_1": 513, "min_CLP": -8.33, "draft_iters": 10.5, "mem_use": 44.11, "gen_rate": 7.2, "speed": 2.51, "text": "[INST] I need a case, what are m"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 296, "tree_size": 512, "t0": 0.8113, "t1": 1.4075, "tft": 2.5644, "input_0": 819, "input_1": 513, "min_CLP": -9.0, "draft_iters": 5.0, "mem_use": 43.96, "gen_rate": 4.0, "speed": 1.8, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.9, "tree_w": 238, "tree_size": 512, "t0": 0.9911, "t1": 1.4122, "tft": 2.5599, "input_0": 862, "input_1": 513, "min_CLP": -8.3, "draft_iters": 6.0, "mem_use": 44.02, "gen_rate": 3.9, "speed": 1.62, "text": "ChatGPT is banned from using sou"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 174, "tree_size": 512, "t0": 2.466, "t1": 1.434, "tft": 3.4346, "input_0": 1634, "input_1": 513, "min_CLP": -8.36, "draft_iters": 14.4, "mem_use": 45.36, "gen_rate": 6.8, "speed": 1.75, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 254, "tree_size": 512, "t0": 1.3967, "t1": 1.4167, "tft": 2.66, "input_0": 1063, "input_1": 513, "min_CLP": -13.33, "draft_iters": 9.7, "mem_use": 44.08, "gen_rate": 8.7, "speed": 3.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 221, "tree_size": 512, "t0": 1.785, "t1": 1.4133, "tft": 2.6827, "input_0": 1326, "input_1": 513, "min_CLP": -8.73, "draft_iters": 12.3, "mem_use": 44.26, "gen_rate": 5.3, "speed": 1.67, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.7, "tree_w": 253, "tree_size": 512, "t0": 1.2329, "t1": 1.41, "tft": 2.7164, "input_0": 1048, "input_1": 513, "min_CLP": -11.03, "draft_iters": 7.9, "mem_use": 44.31, "gen_rate": 5.3, "speed": 2.0, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.6, "tree_w": 287, "tree_size": 512, "t0": 0.9486, "t1": 1.4357, "tft": 3.6692, "input_0": 1042, "input_1": 513, "min_CLP": -9.31, "draft_iters": 5.6, "mem_use": 46.21, "gen_rate": 4.6, "speed": 1.92, "text": "Here are some YouTube channels t"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.7, "tree_w": 217, "tree_size": 512, "t0": 1.6157, "t1": 1.4029, "tft": 2.0894, "input_0": 1341, "input_1": 513, "min_CLP": -9.11, "draft_iters": 10.0, "mem_use": 43.67, "gen_rate": 5.7, "speed": 1.89, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 207, "tree_size": 512, "t0": 1.888, "t1": 1.406, "tft": 2.5174, "input_0": 1249, "input_1": 513, "min_CLP": -8.89, "draft_iters": 13.8, "mem_use": 43.81, "gen_rate": 6.8, "speed": 2.06, "text": "Given two matrices A and B that "}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.0, "tree_w": 210, "tree_size": 512, "t0": 1.49, "t1": 1.43, "tft": 3.3863, "input_0": 1099, "input_1": 513, "min_CLP": -7.98, "draft_iters": 9.4, "mem_use": 45.23, "gen_rate": 6.6, "speed": 2.26, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 8.6, "tree_w": 257, "tree_size": 512, "t0": 1.49, "t1": 1.434, "tft": 3.7644, "input_0": 1140, "input_1": 513, "min_CLP": -12.06, "draft_iters": 10.2, "mem_use": 46.38, "gen_rate": 9.6, "speed": 3.28, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.8, "tree_w": 208, "tree_size": 512, "t0": 2.0117, "t1": 1.4017, "tft": 2.3015, "input_0": 1259, "input_1": 513, "min_CLP": -7.81, "draft_iters": 15.3, "mem_use": 43.65, "gen_rate": 5.3, "speed": 1.56, "text": "\"The current date is not fixed a"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.7, "tree_w": 196, "tree_size": 512, "t0": 1.685, "t1": 1.4233, "tft": 3.2374, "input_0": 1257, "input_1": 513, "min_CLP": -8.39, "draft_iters": 10.3, "mem_use": 45.11, "gen_rate": 6.3, "speed": 2.04, "text": "\"Yes, that's a great approach! B"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.0, "tree_w": 273, "tree_size": 512, "t0": 0.95, "t1": 1.4133, "tft": 2.5606, "input_0": 845, "input_1": 513, "min_CLP": -8.21, "draft_iters": 6.1, "mem_use": 44.01, "gen_rate": 3.9, "speed": 1.65, "text": "\"Okay, I'm doing this for you, b"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.7, "tree_w": 235, "tree_size": 512, "t0": 1.685, "t1": 1.41, "tft": 2.2939, "input_0": 1210, "input_1": 513, "min_CLP": -10.02, "draft_iters": 11.0, "mem_use": 43.71, "gen_rate": 6.7, "speed": 2.15, "text": "Yes, I can help you with that. E"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 2, "tree_h": 3.0, "tree_w": 267, "tree_size": 512, "t0": 0.8, "t1": 1.42, "tft": 2.5675, "input_0": 780, "input_1": 513, "min_CLP": -8.58, "draft_iters": 5.0, "mem_use": 44.06, "gen_rate": 2.0, "speed": 0.9, "text": "136"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 194, "tree_size": 512, "t0": 2.3467, "t1": 1.4033, "tft": 2.2924, "input_0": 1603, "input_1": 513, "min_CLP": -10.29, "draft_iters": 14.3, "mem_use": 43.65, "gen_rate": 13.3, "speed": 3.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.5, "tree_w": 250, "tree_size": 512, "t0": 1.5883, "t1": 1.4233, "tft": 3.1808, "input_0": 1349, "input_1": 513, "min_CLP": -9.26, "draft_iters": 8.8, "mem_use": 44.96, "gen_rate": 6.0, "speed": 1.99, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 3.0, "tree_w": 313, "tree_size": 512, "t0": 0.805, "t1": 1.4125, "tft": 2.5232, "input_0": 831, "input_1": 513, "min_CLP": -9.38, "draft_iters": 5.0, "mem_use": 43.84, "gen_rate": 3.0, "speed": 1.35, "text": "\"Answer: Jay's brother is John. "}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 5.0, "tree_w": 272, "tree_size": 512, "t0": 1.1357, "t1": 1.4143, "tft": 2.6626, "input_0": 1072, "input_1": 513, "min_CLP": -9.35, "draft_iters": 7.1, "mem_use": 44.22, "gen_rate": 6.0, "speed": 2.35, "text": "\"Pacific Ocean, Atlantic Ocean, "}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 245, "tree_size": 512, "t0": 1.2086, "t1": 1.4214, "tft": 2.723, "input_0": 1050, "input_1": 513, "min_CLP": -7.95, "draft_iters": 7.3, "mem_use": 44.45, "gen_rate": 4.7, "speed": 1.79, "text": "The first step is to identify th"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 20.0, "tree_w": 129, "tree_size": 512, "t0": 3.63, "t1": 1.41, "tft": 2.5402, "input_0": 2046, "input_1": 513, "min_CLP": -9.2, "draft_iters": 23.0, "mem_use": 43.87, "gen_rate": 15.7, "speed": 3.11, "text": "\"Here's a basic Pygame project t"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.2, "tree_w": 254, "tree_size": 512, "t0": 1.1817, "t1": 1.425, "tft": 3.1913, "input_0": 1023, "input_1": 513, "min_CLP": -8.65, "draft_iters": 7.2, "mem_use": 44.96, "gen_rate": 5.8, "speed": 2.24, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 175, "tree_size": 512, "t0": 1.8983, "t1": 1.41, "tft": 2.6565, "input_0": 1298, "input_1": 513, "min_CLP": -7.39, "draft_iters": 11.7, "mem_use": 44.11, "gen_rate": 6.2, "speed": 1.87, "text": "The cross-section of air refers "}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 211, "tree_size": 512, "t0": 1.5871, "t1": 1.4071, "tft": 2.291, "input_0": 1276, "input_1": 513, "min_CLP": -8.28, "draft_iters": 9.7, "mem_use": 43.66, "gen_rate": 4.9, "speed": 1.62, "text": "The Infinite Banking Concept, al"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.3, "tree_w": 266, "tree_size": 512, "t0": 1.16, "t1": 1.4083, "tft": 2.5169, "input_0": 1025, "input_1": 513, "min_CLP": -10.42, "draft_iters": 7.3, "mem_use": 43.77, "gen_rate": 5.3, "speed": 2.08, "text": "To create a high-quality testing"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 192, "tree_size": 512, "t0": 1.88, "t1": 1.4075, "tft": 2.5571, "input_0": 1293, "input_1": 513, "min_CLP": -8.1, "draft_iters": 11.8, "mem_use": 43.92, "gen_rate": 8.0, "speed": 2.43, "text": "Landlords are responsible for pr"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 238, "tree_size": 512, "t0": 1.2429, "t1": 1.4129, "tft": 2.7361, "input_0": 1011, "input_1": 513, "min_CLP": -8.09, "draft_iters": 8.0, "mem_use": 44.43, "gen_rate": 4.7, "speed": 1.78, "text": "\"I'm not a fan of sitcoms in gen"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 30, "tree_h": 7.0, "tree_w": 214, "tree_size": 512, "t0": 1.576, "t1": 1.422, "tft": 3.3943, "input_0": 1138, "input_1": 513, "min_CLP": -8.01, "draft_iters": 9.4, "mem_use": 45.26, "gen_rate": 6.0, "speed": 2.0, "text": "\"I'm here to help you with any q"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 215, "tree_size": 512, "t0": 1.782, "t1": 1.43, "tft": 3.2988, "input_0": 1347, "input_1": 513, "min_CLP": -9.96, "draft_iters": 11.0, "mem_use": 45.79, "gen_rate": 6.4, "speed": 1.99, "text": "The difficulty of learning a lan"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 247, "tree_size": 512, "t0": 1.3714, "t1": 1.4071, "tft": 2.6783, "input_0": 1141, "input_1": 513, "min_CLP": -9.22, "draft_iters": 8.4, "mem_use": 44.25, "gen_rate": 4.9, "speed": 1.75, "text": "All of the AI tools I mentioned "}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 131, "tree_size": 512, "t0": 2.1525, "t1": 1.405, "tft": 2.6341, "input_0": 1522, "input_1": 513, "min_CLP": -8.72, "draft_iters": 13.2, "mem_use": 44.12, "gen_rate": 8.5, "speed": 2.39, "text": "\"The reason I don't have opinion"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.3, "tree_w": 279, "tree_size": 512, "t0": 1.0157, "t1": 1.4143, "tft": 2.6956, "input_0": 970, "input_1": 513, "min_CLP": -8.27, "draft_iters": 6.3, "mem_use": 44.33, "gen_rate": 4.7, "speed": 1.94, "text": "I understand that labeling promp"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.2, "tree_w": 308, "tree_size": 512, "t0": 0.8433, "t1": 1.4189, "tft": 2.696, "input_0": 914, "input_1": 513, "min_CLP": -9.35, "draft_iters": 5.1, "mem_use": 44.34, "gen_rate": 3.7, "speed": 1.62, "text": "The \"A\" in AK-47 stands for \"\u0410\u0432\u0442"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.6, "tree_w": 280, "tree_size": 512, "t0": 0.8867, "t1": 1.4133, "tft": 2.5307, "input_0": 873, "input_1": 513, "min_CLP": -9.59, "draft_iters": 5.4, "mem_use": 43.78, "gen_rate": 3.7, "speed": 1.59, "text": "\"Sure, I'd be happy to design an"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 194, "tree_size": 512, "t0": 1.5983, "t1": 1.4267, "tft": 3.4472, "input_0": 1201, "input_1": 513, "min_CLP": -8.77, "draft_iters": 9.8, "mem_use": 45.42, "gen_rate": 5.8, "speed": 1.93, "text": "The largest and most precise opt"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.2, "tree_w": 265, "tree_size": 512, "t0": 1.0175, "t1": 1.4125, "tft": 2.5486, "input_0": 917, "input_1": 513, "min_CLP": -9.13, "draft_iters": 6.4, "mem_use": 43.92, "gen_rate": 4.1, "speed": 1.7, "text": "Hippotherapy, Equine-assisted th"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 4.9, "tree_w": 284, "tree_size": 512, "t0": 1.1243, "t1": 1.4086, "tft": 2.516, "input_0": 1085, "input_1": 513, "min_CLP": -11.64, "draft_iters": 6.9, "mem_use": 43.75, "gen_rate": 5.0, "speed": 1.97, "text": "Sure, here is a list of 10 names"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 28, "tree_h": 6.9, "tree_w": 260, "tree_size": 512, "t0": 1.2771, "t1": 1.41, "tft": 2.6944, "input_0": 993, "input_1": 513, "min_CLP": -8.56, "draft_iters": 8.9, "mem_use": 44.22, "gen_rate": 4.0, "speed": 1.49, "text": "\"I'm just a text-based AI, so I "}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.5, "tree_w": 235, "tree_size": 512, "t0": 1.605, "t1": 1.4333, "tft": 3.3354, "input_0": 1289, "input_1": 513, "min_CLP": -8.81, "draft_iters": 10.0, "mem_use": 45.89, "gen_rate": 5.8, "speed": 1.92, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 3.4, "tree_w": 276, "tree_size": 512, "t0": 0.8889, "t1": 1.42, "tft": 2.9974, "input_0": 956, "input_1": 513, "min_CLP": -8.48, "draft_iters": 5.3, "mem_use": 44.69, "gen_rate": 4.0, "speed": 1.73, "text": "Yes, there is a theory called \"H"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.2, "tree_w": 151, "tree_size": 512, "t0": 2.5825, "t1": 1.4275, "tft": 3.2284, "input_0": 1672, "input_1": 513, "min_CLP": -7.21, "draft_iters": 16.0, "mem_use": 45.11, "gen_rate": 8.5, "speed": 2.12, "text": "The meaning of life is a deeply "}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.9, "tree_w": 262, "tree_size": 512, "t0": 1.1725, "t1": 1.41, "tft": 2.3085, "input_0": 1135, "input_1": 513, "min_CLP": -9.52, "draft_iters": 6.9, "mem_use": 43.7, "gen_rate": 4.5, "speed": 1.74, "text": "[INST] Write me a Graphic Novel "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 258, "tree_size": 512, "t0": 1.3186, "t1": 1.4729, "tft": 5.2988, "input_0": 1010, "input_1": 513, "min_CLP": -9.18, "draft_iters": 9.0, "mem_use": 48.39, "gen_rate": 4.7, "speed": 1.69, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.6, "tree_w": 169, "tree_size": 512, "t0": 2.45, "t1": 1.426, "tft": 3.0382, "input_0": 1655, "input_1": 513, "min_CLP": -8.89, "draft_iters": 14.6, "mem_use": 44.82, "gen_rate": 8.4, "speed": 2.17, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.6, "tree_w": 265, "tree_size": 512, "t0": 1.0888, "t1": 1.4237, "tft": 2.9774, "input_0": 933, "input_1": 513, "min_CLP": -9.5, "draft_iters": 6.6, "mem_use": 44.68, "gen_rate": 4.0, "speed": 1.59, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 5.3, "tree_w": 245, "tree_size": 512, "t0": 1.21, "t1": 1.41, "tft": 2.4977, "input_0": 1069, "input_1": 513, "min_CLP": -10.07, "draft_iters": 7.5, "mem_use": 43.72, "gen_rate": 6.0, "speed": 2.29, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.0, "tree_w": 287, "tree_size": 512, "t0": 0.9988, "t1": 1.4125, "tft": 2.5783, "input_0": 984, "input_1": 513, "min_CLP": -9.33, "draft_iters": 6.1, "mem_use": 44.05, "gen_rate": 4.0, "speed": 1.66, "text": "\"Of course! Here's another one:\\"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 251, "tree_size": 512, "t0": 1.4083, "t1": 1.4083, "tft": 2.3191, "input_0": 1066, "input_1": 513, "min_CLP": -14.11, "draft_iters": 9.7, "mem_use": 43.69, "gen_rate": 8.7, "speed": 3.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.2, "tree_w": 284, "tree_size": 512, "t0": 1.09, "t1": 1.4713, "tft": 5.2784, "input_0": 1059, "input_1": 513, "min_CLP": -8.99, "draft_iters": 6.4, "mem_use": 48.45, "gen_rate": 4.6, "speed": 1.81, "text": "My apologies for the confusion. "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.2, "tree_w": 220, "tree_size": 512, "t0": 2.272, "t1": 1.406, "tft": 2.5229, "input_0": 1472, "input_1": 513, "min_CLP": -12.42, "draft_iters": 16.2, "mem_use": 43.77, "gen_rate": 7.4, "speed": 2.01, "text": "\"Human: What's the furthest back"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.4, "tree_w": 272, "tree_size": 512, "t0": 1.2375, "t1": 1.49, "tft": 6.8577, "input_0": 966, "input_1": 513, "min_CLP": -9.15, "draft_iters": 8.5, "mem_use": 50.68, "gen_rate": 4.9, "speed": 1.79, "text": "Yes, I would like to see a few m"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 230, "tree_size": 512, "t0": 1.6675, "t1": 1.4225, "tft": 3.1881, "input_0": 1103, "input_1": 513, "min_CLP": -10.03, "draft_iters": 11.8, "mem_use": 44.93, "gen_rate": 10.8, "speed": 3.48, "text": "Name: Spritesla\\nCategory: Elect"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 164, "tree_size": 512, "t0": 2.194, "t1": 1.41, "tft": 2.5328, "input_0": 1505, "input_1": 513, "min_CLP": -7.63, "draft_iters": 13.8, "mem_use": 43.79, "gen_rate": 7.0, "speed": 1.94, "text": "The human genome is made up of D"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 311, "tree_size": 512, "t0": 0.8063, "t1": 1.4087, "tft": 2.2989, "input_0": 825, "input_1": 513, "min_CLP": -9.0, "draft_iters": 5.0, "mem_use": 43.66, "gen_rate": 4.0, "speed": 1.81, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.1, "tree_w": 265, "tree_size": 512, "t0": 1.0337, "t1": 1.4138, "tft": 2.5554, "input_0": 989, "input_1": 513, "min_CLP": -8.76, "draft_iters": 6.2, "mem_use": 43.9, "gen_rate": 4.1, "speed": 1.69, "text": "None.\\n\\nI don\\'t have personal "}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.1, "tree_w": 278, "tree_size": 512, "t0": 0.99, "t1": 1.4138, "tft": 2.671, "input_0": 955, "input_1": 513, "min_CLP": -9.38, "draft_iters": 6.1, "mem_use": 44.19, "gen_rate": 4.4, "speed": 1.82, "text": "Sure, here are a few TV shows th"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 24.0, "tree_w": 40, "tree_size": 512, "t0": 4.1067, "t1": 1.4333, "tft": 3.3015, "input_0": 2151, "input_1": 513, "min_CLP": -6.45, "draft_iters": 26.7, "mem_use": 45.79, "gen_rate": 13.0, "speed": 2.35, "text": "Sure, here are some hardware and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.1, "tree_w": 250, "tree_size": 512, "t0": 1.5929, "t1": 1.4243, "tft": 3.1928, "input_0": 1268, "input_1": 513, "min_CLP": -9.43, "draft_iters": 10.4, "mem_use": 44.91, "gen_rate": 5.0, "speed": 1.66, "text": "\"The trapped electrons in F-cent"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 30, "tree_h": 8.0, "tree_w": 217, "tree_size": 512, "t0": 1.5188, "t1": 1.4062, "tft": 2.529, "input_0": 1122, "input_1": 513, "min_CLP": -8.29, "draft_iters": 10.4, "mem_use": 43.84, "gen_rate": 3.8, "speed": 1.28, "text": "\"Atomic bomb game refers to a Go"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 260, "tree_size": 512, "t0": 1.36, "t1": 1.4443, "tft": 3.7688, "input_0": 1008, "input_1": 513, "min_CLP": -12.5, "draft_iters": 9.0, "mem_use": 46.44, "gen_rate": 8.0, "speed": 2.85, "text": "\"Here's the commented code for t"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.5, "tree_w": 248, "tree_size": 512, "t0": 1.5467, "t1": 1.425, "tft": 3.193, "input_0": 1213, "input_1": 513, "min_CLP": -10.53, "draft_iters": 9.7, "mem_use": 44.94, "gen_rate": 6.7, "speed": 2.24, "text": "Aqu\u00ed tienes una lista de las 3 m"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 229, "tree_size": 512, "t0": 2.09, "t1": 1.41, "tft": 2.3128, "input_0": 1107, "input_1": 513, "min_CLP": -9.35, "draft_iters": 18.0, "mem_use": 43.68, "gen_rate": 17.5, "speed": 5.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 22, "tree_h": 4.0, "tree_w": 258, "tree_size": 512, "t0": 1.0, "t1": 1.4086, "tft": 2.5104, "input_0": 860, "input_1": 513, "min_CLP": -8.72, "draft_iters": 6.1, "mem_use": 43.77, "gen_rate": 3.1, "speed": 1.3, "text": "```markdown\\nThis is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.2, "tree_w": 299, "tree_size": 512, "t0": 0.8563, "t1": 1.425, "tft": 3.0181, "input_0": 918, "input_1": 513, "min_CLP": -8.5, "draft_iters": 5.1, "mem_use": 44.78, "gen_rate": 4.0, "speed": 1.75, "text": "\"Oh, the meaning of life, a big "}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 4.4, "tree_w": 279, "tree_size": 512, "t0": 1.0522, "t1": 1.4344, "tft": 3.591, "input_0": 964, "input_1": 513, "min_CLP": -9.1, "draft_iters": 6.6, "mem_use": 45.72, "gen_rate": 4.6, "speed": 1.83, "text": "\"In JavaScript, there is no buil"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.1, "tree_w": 228, "tree_size": 512, "t0": 1.5686, "t1": 1.41, "tft": 2.7043, "input_0": 1232, "input_1": 513, "min_CLP": -8.72, "draft_iters": 10.3, "mem_use": 44.27, "gen_rate": 5.4, "speed": 1.82, "text": "Sure, here is a basic training p"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 252, "tree_size": 512, "t0": 1.4029, "t1": 1.4229, "tft": 3.004, "input_0": 1119, "input_1": 513, "min_CLP": -10.26, "draft_iters": 8.9, "mem_use": 44.75, "gen_rate": 5.0, "speed": 1.77, "text": "\"I assumed that your statement t"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.1, "tree_w": 279, "tree_size": 512, "t0": 1.1529, "t1": 1.4071, "tft": 3.8807, "input_0": 1021, "input_1": 513, "min_CLP": -8.7, "draft_iters": 7.3, "mem_use": 43.69, "gen_rate": 5.3, "speed": 2.07, "text": "JavaScript is a versatile progra"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.7, "tree_w": 254, "tree_size": 512, "t0": 1.2111, "t1": 1.4111, "tft": 2.2993, "input_0": 1003, "input_1": 513, "min_CLP": -10.22, "draft_iters": 7.1, "mem_use": 43.66, "gen_rate": 4.0, "speed": 1.53, "text": "The answer is: L-theanine is an "}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.6, "tree_w": 224, "tree_size": 512, "t0": 1.25, "t1": 1.4178, "tft": 2.7292, "input_0": 1031, "input_1": 513, "min_CLP": -8.38, "draft_iters": 7.8, "mem_use": 44.36, "gen_rate": 3.6, "speed": 1.33, "text": "\"Certainly! Here's the list of w"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.4, "tree_w": 221, "tree_size": 512, "t0": 1.64, "t1": 1.4086, "tft": 2.5152, "input_0": 1189, "input_1": 513, "min_CLP": -9.1, "draft_iters": 10.7, "mem_use": 43.79, "gen_rate": 5.6, "speed": 1.83, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.4, "tree_w": 207, "tree_size": 512, "t0": 1.8029, "t1": 1.4071, "tft": 2.5205, "input_0": 1035, "input_1": 513, "min_CLP": -7.68, "draft_iters": 13.1, "mem_use": 43.79, "gen_rate": 4.9, "speed": 1.51, "text": "\"20 years of love, my dear\\nToge"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.2, "tree_w": 237, "tree_size": 512, "t0": 1.4488, "t1": 1.41, "tft": 2.5124, "input_0": 1151, "input_1": 513, "min_CLP": -8.65, "draft_iters": 8.8, "mem_use": 43.77, "gen_rate": 4.6, "speed": 1.62, "text": "To memorize how to write Chinese"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.7, "tree_w": 225, "tree_size": 512, "t0": 1.655, "t1": 1.47, "tft": 5.2921, "input_0": 1160, "input_1": 513, "min_CLP": -8.31, "draft_iters": 12.0, "mem_use": 48.51, "gen_rate": 6.2, "speed": 1.97, "text": "Here is a possible monologue scr"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.6, "tree_w": 283, "tree_size": 512, "t0": 1.0713, "t1": 1.4362, "tft": 3.5358, "input_0": 956, "input_1": 513, "min_CLP": -9.21, "draft_iters": 6.8, "mem_use": 46.13, "gen_rate": 4.5, "speed": 1.79, "text": "Sure! Fermat\\'s Last Theorem is "}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 54, "tree_h": 9.6, "tree_w": 229, "tree_size": 512, "t0": 2.0286, "t1": 1.4214, "tft": 2.9739, "input_0": 1338, "input_1": 513, "min_CLP": -11.11, "draft_iters": 12.0, "mem_use": 44.58, "gen_rate": 7.7, "speed": 2.24, "text": "Sure, the formula for the sample"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 220, "tree_size": 512, "t0": 1.656, "t1": 1.42, "tft": 3.0167, "input_0": 1336, "input_1": 513, "min_CLP": -9.08, "draft_iters": 10.8, "mem_use": 44.75, "gen_rate": 6.6, "speed": 2.14, "text": "Polar bears can teach us a lot a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 6.4, "tree_w": 231, "tree_size": 512, "t0": 1.4457, "t1": 1.44, "tft": 3.3002, "input_0": 1083, "input_1": 513, "min_CLP": -8.77, "draft_iters": 8.7, "mem_use": 45.79, "gen_rate": 5.7, "speed": 1.98, "text": "Lemon wedges are simply slices o"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 19, "tree_h": 3.0, "tree_w": 312, "tree_size": 512, "t0": 0.828, "t1": 1.42, "tft": 2.5503, "input_0": 829, "input_1": 513, "min_CLP": -8.67, "draft_iters": 5.0, "mem_use": 43.85, "gen_rate": 3.8, "speed": 1.69, "text": "\"Hello, I'm so sorry I'm late! I"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 250, "tree_size": 512, "t0": 1.1957, "t1": 1.41, "tft": 2.5317, "input_0": 1007, "input_1": 513, "min_CLP": -8.86, "draft_iters": 7.6, "mem_use": 43.81, "gen_rate": 4.9, "speed": 1.86, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 20.3, "tree_w": 124, "tree_size": 512, "t0": 3.46, "t1": 1.41, "tft": 2.3016, "input_0": 1941, "input_1": 513, "min_CLP": -8.42, "draft_iters": 22.3, "mem_use": 43.69, "gen_rate": 18.3, "speed": 3.76, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 236, "tree_size": 512, "t0": 1.675, "t1": 1.4317, "tft": 3.4026, "input_0": 1198, "input_1": 513, "min_CLP": -9.07, "draft_iters": 10.3, "mem_use": 45.25, "gen_rate": 5.5, "speed": 1.77, "text": "Yes, there are some cities that "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.3, "tree_w": 151, "tree_size": 512, "t0": 2.5767, "t1": 1.4233, "tft": 3.026, "input_0": 1636, "input_1": 513, "min_CLP": -7.42, "draft_iters": 16.3, "mem_use": 44.79, "gen_rate": 11.7, "speed": 2.91, "text": "Freeman Dyson has also defended "}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 3.7, "tree_w": 294, "tree_size": 512, "t0": 0.9667, "t1": 1.4033, "tft": 2.3003, "input_0": 1087, "input_1": 513, "min_CLP": -9.14, "draft_iters": 5.7, "mem_use": 43.65, "gen_rate": 4.3, "speed": 1.83, "text": "Yes, I can write code! What do y"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.1, "tree_w": 285, "tree_size": 512, "t0": 0.9867, "t1": 1.4167, "tft": 2.7281, "input_0": 933, "input_1": 513, "min_CLP": -10.55, "draft_iters": 6.2, "mem_use": 44.38, "gen_rate": 3.6, "speed": 1.48, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 7.8, "tree_w": 247, "tree_size": 512, "t0": 1.515, "t1": 1.4217, "tft": 3.1797, "input_0": 1227, "input_1": 513, "min_CLP": -11.93, "draft_iters": 9.7, "mem_use": 44.98, "gen_rate": 7.5, "speed": 2.55, "text": "Certainly! Here are the full lyr"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.2, "tree_w": 121, "tree_size": 512, "t0": 2.7675, "t1": 1.4075, "tft": 2.558, "input_0": 1833, "input_1": 513, "min_CLP": -7.14, "draft_iters": 17.5, "mem_use": 44.01, "gen_rate": 8.8, "speed": 2.09, "text": "There are various ways to cope w"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 55, "tree_h": 6.9, "tree_w": 260, "tree_size": 512, "t0": 1.4357, "t1": 1.4029, "tft": 2.291, "input_0": 1141, "input_1": 513, "min_CLP": -13.24, "draft_iters": 9.0, "mem_use": 43.68, "gen_rate": 7.9, "speed": 2.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 4.7, "tree_w": 263, "tree_size": 512, "t0": 1.1457, "t1": 1.41, "tft": 2.6808, "input_0": 1042, "input_1": 513, "min_CLP": -8.34, "draft_iters": 6.9, "mem_use": 44.23, "gen_rate": 5.4, "speed": 2.12, "text": "\"As a language-agnostic AI model"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.4, "tree_w": 247, "tree_size": 512, "t0": 1.2114, "t1": 1.4229, "tft": 2.9743, "input_0": 1095, "input_1": 513, "min_CLP": -9.34, "draft_iters": 7.6, "mem_use": 44.67, "gen_rate": 5.0, "speed": 1.9, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 28, "tree_h": 8.8, "tree_w": 194, "tree_size": 512, "t0": 1.77, "t1": 1.415, "tft": 2.7096, "input_0": 1317, "input_1": 513, "min_CLP": -8.63, "draft_iters": 11.0, "mem_use": 44.35, "gen_rate": 7.0, "speed": 2.2, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 16.0, "tree_w": 185, "tree_size": 512, "t0": 2.6675, "t1": 1.435, "tft": 3.7803, "input_0": 1569, "input_1": 513, "min_CLP": -10.4, "draft_iters": 18.5, "mem_use": 46.45, "gen_rate": 12.2, "speed": 2.99, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.5, "tree_w": 132, "tree_size": 512, "t0": 2.7225, "t1": 1.46, "tft": 4.9933, "input_0": 1787, "input_1": 513, "min_CLP": -7.5, "draft_iters": 17.8, "mem_use": 48.02, "gen_rate": 8.2, "speed": 1.97, "text": "\"I'm sorry, as an AI language mo"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 142, "tree_size": 512, "t0": 2.64, "t1": 1.42, "tft": 3.211, "input_0": 1839, "input_1": 513, "min_CLP": -8.41, "draft_iters": 16.5, "mem_use": 45.04, "gen_rate": 9.0, "speed": 2.22, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.8, "tree_w": 249, "tree_size": 512, "t0": 1.8525, "t1": 1.43, "tft": 3.442, "input_0": 1335, "input_1": 513, "min_CLP": -9.94, "draft_iters": 11.8, "mem_use": 45.42, "gen_rate": 10.5, "speed": 3.2, "text": "Certainly! Based on my analysis,"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.8, "tree_w": 183, "tree_size": 512, "t0": 2.4, "t1": 1.4, "tft": 2.2894, "input_0": 1457, "input_1": 513, "min_CLP": -10.92, "draft_iters": 15.5, "mem_use": 43.68, "gen_rate": 8.5, "speed": 2.24, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 221, "tree_size": 512, "t0": 1.652, "t1": 1.42, "tft": 3.1916, "input_0": 1187, "input_1": 513, "min_CLP": -7.95, "draft_iters": 10.6, "mem_use": 45.0, "gen_rate": 6.4, "speed": 2.08, "text": "Since Black Friday is the day af"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 271, "tree_size": 512, "t0": 1.1088, "t1": 1.41, "tft": 2.5326, "input_0": 961, "input_1": 513, "min_CLP": -9.08, "draft_iters": 6.8, "mem_use": 43.85, "gen_rate": 4.2, "speed": 1.69, "text": "Sure, I can give you a short sto"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 284, "tree_size": 512, "t0": 1.1157, "t1": 1.4086, "tft": 2.5116, "input_0": 1057, "input_1": 513, "min_CLP": -11.8, "draft_iters": 6.9, "mem_use": 43.73, "gen_rate": 4.6, "speed": 1.81, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 238, "tree_size": 512, "t0": 1.42, "t1": 1.41, "tft": 2.4998, "input_0": 1085, "input_1": 513, "min_CLP": -12.95, "draft_iters": 9.7, "mem_use": 43.72, "gen_rate": 8.7, "speed": 3.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.0, "tree_w": 286, "tree_size": 512, "t0": 1.0112, "t1": 1.4113, "tft": 2.3086, "input_0": 915, "input_1": 513, "min_CLP": -10.24, "draft_iters": 6.2, "mem_use": 43.67, "gen_rate": 4.5, "speed": 1.86, "text": "As a Norse goddess, I am a power"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.2, "tree_w": 219, "tree_size": 512, "t0": 1.492, "t1": 1.422, "tft": 3.1756, "input_0": 1097, "input_1": 513, "min_CLP": -8.78, "draft_iters": 9.4, "mem_use": 44.92, "gen_rate": 6.6, "speed": 2.26, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 170, "tree_size": 512, "t0": 2.2, "t1": 1.4075, "tft": 2.352, "input_0": 1491, "input_1": 513, "min_CLP": -9.2, "draft_iters": 14.2, "mem_use": 44.06, "gen_rate": 9.2, "speed": 2.57, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 249, "tree_size": 512, "t0": 1.418, "t1": 1.48, "tft": 5.8245, "input_0": 1254, "input_1": 513, "min_CLP": -12.1, "draft_iters": 9.0, "mem_use": 49.11, "gen_rate": 6.8, "speed": 2.35, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 146, "tree_size": 512, "t0": 2.33, "t1": 1.405, "tft": 2.6805, "input_0": 1713, "input_1": 513, "min_CLP": -7.91, "draft_iters": 14.0, "mem_use": 44.19, "gen_rate": 8.5, "speed": 2.28, "text": "LLMs, or large language models, "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 260, "tree_size": 512, "t0": 1.0578, "t1": 1.4056, "tft": 2.5041, "input_0": 932, "input_1": 513, "min_CLP": -8.48, "draft_iters": 6.6, "mem_use": 43.76, "gen_rate": 3.7, "speed": 1.49, "text": "\"Here's a joke that fits the bil"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.5, "tree_w": 226, "tree_size": 512, "t0": 1.6933, "t1": 1.4067, "tft": 2.5516, "input_0": 1152, "input_1": 513, "min_CLP": -14.42, "draft_iters": 12.5, "mem_use": 43.98, "gen_rate": 5.8, "speed": 1.88, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 185, "tree_size": 512, "t0": 2.0975, "t1": 1.43, "tft": 3.4377, "input_0": 1255, "input_1": 513, "min_CLP": -8.57, "draft_iters": 15.5, "mem_use": 45.43, "gen_rate": 8.2, "speed": 2.34, "text": "\"No, that's all for now. Thank y"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.0, "tree_w": 274, "tree_size": 512, "t0": 0.9537, "t1": 1.4075, "tft": 2.5308, "input_0": 907, "input_1": 513, "min_CLP": -8.93, "draft_iters": 5.9, "mem_use": 43.84, "gen_rate": 4.5, "speed": 1.91, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 206, "tree_size": 512, "t0": 2.21, "t1": 1.4033, "tft": 2.5079, "input_0": 1577, "input_1": 513, "min_CLP": -9.82, "draft_iters": 14.3, "mem_use": 43.81, "gen_rate": 13.0, "speed": 3.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.2, "tree_w": 199, "tree_size": 512, "t0": 1.7017, "t1": 1.4, "tft": 2.3086, "input_0": 1269, "input_1": 513, "min_CLP": -8.09, "draft_iters": 10.7, "mem_use": 43.65, "gen_rate": 6.2, "speed": 1.99, "text": "Mars is known for its reddish co"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 22, "tree_h": 3.0, "tree_w": 259, "tree_size": 512, "t0": 0.8271, "t1": 1.4343, "tft": 3.2896, "input_0": 772, "input_1": 513, "min_CLP": -9.92, "draft_iters": 5.0, "mem_use": 45.85, "gen_rate": 3.1, "speed": 1.39, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 200, "tree_size": 512, "t0": 2.4, "t1": 1.41, "tft": 2.5296, "input_0": 1607, "input_1": 513, "min_CLP": -11.96, "draft_iters": 14.3, "mem_use": 43.74, "gen_rate": 13.0, "speed": 3.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 273, "tree_size": 512, "t0": 1.2357, "t1": 1.4143, "tft": 2.693, "input_0": 1064, "input_1": 513, "min_CLP": -9.94, "draft_iters": 7.6, "mem_use": 44.27, "gen_rate": 4.7, "speed": 1.78, "text": "\"No, the ATF's regulations and r"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 7.1, "tree_w": 228, "tree_size": 512, "t0": 1.4475, "t1": 1.405, "tft": 2.5224, "input_0": 1057, "input_1": 513, "min_CLP": -8.9, "draft_iters": 9.4, "mem_use": 43.73, "gen_rate": 5.0, "speed": 1.75, "text": "Yes, there are formulas to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.6, "tree_w": 167, "tree_size": 512, "t0": 2.432, "t1": 1.402, "tft": 2.6514, "input_0": 1542, "input_1": 513, "min_CLP": -8.55, "draft_iters": 17.0, "mem_use": 44.17, "gen_rate": 7.2, "speed": 1.88, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 6.6, "tree_w": 241, "tree_size": 512, "t0": 1.336, "t1": 1.406, "tft": 2.5223, "input_0": 1080, "input_1": 513, "min_CLP": -9.71, "draft_iters": 8.8, "mem_use": 43.85, "gen_rate": 5.6, "speed": 2.04, "text": "The capital of Australia before "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.5, "tree_w": 249, "tree_size": 512, "t0": 1.255, "t1": 1.4087, "tft": 2.5629, "input_0": 1070, "input_1": 513, "min_CLP": -8.39, "draft_iters": 7.6, "mem_use": 44.03, "gen_rate": 4.4, "speed": 1.64, "text": "It was a pleasure to have known "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.2, "tree_w": 208, "tree_size": 512, "t0": 1.7167, "t1": 1.4333, "tft": 3.6767, "input_0": 1232, "input_1": 513, "min_CLP": -7.79, "draft_iters": 10.8, "mem_use": 46.22, "gen_rate": 6.7, "speed": 2.12, "text": "\"I can certainly help you with t"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.4, "tree_w": 262, "tree_size": 512, "t0": 1.3557, "t1": 1.41, "tft": 2.5176, "input_0": 1238, "input_1": 513, "min_CLP": -9.44, "draft_iters": 7.9, "mem_use": 43.85, "gen_rate": 5.1, "speed": 1.86, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 293, "tree_size": 512, "t0": 0.8513, "t1": 1.4262, "tft": 3.2398, "input_0": 912, "input_1": 513, "min_CLP": -11.65, "draft_iters": 5.1, "mem_use": 45.12, "gen_rate": 4.2, "speed": 1.87, "text": "For a vector A in a n dimensiona"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.5, "tree_w": 263, "tree_size": 512, "t0": 1.1275, "t1": 1.4025, "tft": 2.3014, "input_0": 960, "input_1": 513, "min_CLP": -9.05, "draft_iters": 6.9, "mem_use": 43.71, "gen_rate": 4.0, "speed": 1.58, "text": "The main issue with using a symm"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.1, "tree_w": 225, "tree_size": 512, "t0": 1.3586, "t1": 1.4029, "tft": 2.5149, "input_0": 1036, "input_1": 513, "min_CLP": -8.1, "draft_iters": 8.6, "mem_use": 43.77, "gen_rate": 5.3, "speed": 1.91, "text": "\"Ah, the Elder Scrolls universe."}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 220, "tree_size": 512, "t0": 1.93, "t1": 1.4067, "tft": 2.4953, "input_0": 1421, "input_1": 513, "min_CLP": -11.27, "draft_iters": 12.7, "mem_use": 43.71, "gen_rate": 5.7, "speed": 1.7, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.4, "tree_w": 215, "tree_size": 512, "t0": 1.788, "t1": 1.408, "tft": 2.7014, "input_0": 1269, "input_1": 513, "min_CLP": -8.86, "draft_iters": 11.8, "mem_use": 44.27, "gen_rate": 6.4, "speed": 2.0, "text": "No, Sum of Squares Error (SSE) a"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 11, "tree_h": 9.5, "tree_w": 254, "tree_size": 512, "t0": 1.495, "t1": 1.41, "tft": 2.9947, "input_0": 984, "input_1": 513, "min_CLP": -9.11, "draft_iters": 11.8, "mem_use": 44.56, "gen_rate": 2.8, "speed": 0.95, "text": "\"Horses for Hope: Riding for Men"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.1, "tree_w": 279, "tree_size": 512, "t0": 1.1325, "t1": 1.4112, "tft": 2.7068, "input_0": 1039, "input_1": 513, "min_CLP": -10.22, "draft_iters": 7.4, "mem_use": 44.36, "gen_rate": 4.6, "speed": 1.82, "text": "To see the best starry sky in th"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 276, "tree_size": 512, "t0": 1.01, "t1": 1.4056, "tft": 2.3032, "input_0": 896, "input_1": 513, "min_CLP": -8.93, "draft_iters": 6.6, "mem_use": 43.71, "gen_rate": 3.7, "speed": 1.52, "text": "1. Dying from laughter: Being so"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.2, "tree_w": 265, "tree_size": 512, "t0": 1.155, "t1": 1.4117, "tft": 2.6852, "input_0": 955, "input_1": 513, "min_CLP": -9.43, "draft_iters": 7.3, "mem_use": 44.25, "gen_rate": 5.7, "speed": 2.21, "text": "Five eggs - one egg = four eggs\\"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 51, "tree_h": 8.6, "tree_w": 200, "tree_size": 512, "t0": 1.7229, "t1": 1.41, "tft": 2.6441, "input_0": 1187, "input_1": 513, "min_CLP": -9.05, "draft_iters": 11.1, "mem_use": 44.13, "gen_rate": 7.3, "speed": 2.32, "text": "To cope with stress from financi"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 194, "tree_size": 512, "t0": 1.854, "t1": 1.45, "tft": 4.1024, "input_0": 1407, "input_1": 513, "min_CLP": -8.73, "draft_iters": 11.4, "mem_use": 47.18, "gen_rate": 6.4, "speed": 1.94, "text": "Sure, here are some tools and te"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 9.8, "tree_w": 214, "tree_size": 512, "t0": 1.888, "t1": 1.432, "tft": 3.3146, "input_0": 1330, "input_1": 513, "min_CLP": -9.68, "draft_iters": 12.2, "mem_use": 45.86, "gen_rate": 9.4, "speed": 2.83, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 5.5, "tree_w": 268, "tree_size": 512, "t0": 1.2967, "t1": 1.405, "tft": 2.4629, "input_0": 1154, "input_1": 513, "min_CLP": -9.46, "draft_iters": 7.8, "mem_use": 43.67, "gen_rate": 6.5, "speed": 2.41, "text": "The answer is: The number of day"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.5, "tree_w": 309, "tree_size": 512, "t0": 0.895, "t1": 1.4075, "tft": 2.5444, "input_0": 1040, "input_1": 513, "min_CLP": -11.49, "draft_iters": 5.4, "mem_use": 43.91, "gen_rate": 4.2, "speed": 1.85, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 248, "tree_size": 512, "t0": 1.3133, "t1": 1.4967, "tft": 6.9433, "input_0": 1032, "input_1": 513, "min_CLP": -9.75, "draft_iters": 8.2, "mem_use": 50.71, "gen_rate": 5.3, "speed": 1.9, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.0, "tree_w": 207, "tree_size": 512, "t0": 1.93, "t1": 1.406, "tft": 2.6424, "input_0": 1324, "input_1": 513, "min_CLP": -8.65, "draft_iters": 12.6, "mem_use": 44.08, "gen_rate": 8.2, "speed": 2.46, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 18.3, "tree_w": 158, "tree_size": 512, "t0": 3.0433, "t1": 1.4, "tft": 2.5132, "input_0": 1833, "input_1": 513, "min_CLP": -8.54, "draft_iters": 21.0, "mem_use": 43.79, "gen_rate": 13.0, "speed": 2.93, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 5.8, "tree_w": 267, "tree_size": 512, "t0": 1.1722, "t1": 1.4089, "tft": 2.5154, "input_0": 935, "input_1": 513, "min_CLP": -8.75, "draft_iters": 8.0, "mem_use": 43.79, "gen_rate": 4.6, "speed": 1.77, "text": "This is a question about the law"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.5, "tree_w": 224, "tree_size": 512, "t0": 1.59, "t1": 1.4362, "tft": 3.6959, "input_0": 1168, "input_1": 513, "min_CLP": -8.58, "draft_iters": 10.0, "mem_use": 46.31, "gen_rate": 4.1, "speed": 1.36, "text": "\"I'm sorry for any confusion. As"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 11.8, "tree_w": 205, "tree_size": 512, "t0": 2.304, "t1": 1.404, "tft": 2.6708, "input_0": 1548, "input_1": 513, "min_CLP": -10.35, "draft_iters": 14.4, "mem_use": 44.21, "gen_rate": 9.2, "speed": 2.48, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 215, "tree_size": 512, "t0": 1.75, "t1": 1.412, "tft": 2.7134, "input_0": 1129, "input_1": 513, "min_CLP": -10.03, "draft_iters": 13.2, "mem_use": 44.39, "gen_rate": 7.0, "speed": 2.21, "text": "\"[INST] What is the airspeed vel"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.0, "tree_w": 177, "tree_size": 512, "t0": 2.056, "t1": 1.406, "tft": 2.5596, "input_0": 1437, "input_1": 513, "min_CLP": -9.55, "draft_iters": 12.8, "mem_use": 44.0, "gen_rate": 8.2, "speed": 2.37, "text": "Stable diffusion is an algorithm"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 225, "tree_size": 512, "t0": 1.2914, "t1": 1.41, "tft": 2.6704, "input_0": 1010, "input_1": 513, "min_CLP": -8.68, "draft_iters": 8.4, "mem_use": 44.23, "gen_rate": 4.7, "speed": 1.74, "text": "\"Attention bias, attention bias,"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 262, "tree_size": 512, "t0": 1.0929, "t1": 1.4071, "tft": 2.557, "input_0": 1024, "input_1": 513, "min_CLP": -8.27, "draft_iters": 6.7, "mem_use": 44.03, "gen_rate": 4.6, "speed": 1.83, "text": "It is a thought experiment, so t"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 245, "tree_size": 512, "t0": 1.395, "t1": 1.4383, "tft": 3.4837, "input_0": 1217, "input_1": 513, "min_CLP": -8.88, "draft_iters": 9.2, "mem_use": 45.98, "gen_rate": 5.7, "speed": 2.0, "text": "\"It's always a good idea to be p"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 134, "tree_size": 512, "t0": 2.6867, "t1": 1.4033, "tft": 2.5216, "input_0": 1680, "input_1": 513, "min_CLP": -7.58, "draft_iters": 17.3, "mem_use": 43.79, "gen_rate": 10.7, "speed": 2.61, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.3, "tree_w": 251, "tree_size": 512, "t0": 1.1717, "t1": 1.41, "tft": 2.5162, "input_0": 1104, "input_1": 513, "min_CLP": -8.99, "draft_iters": 7.3, "mem_use": 43.81, "gen_rate": 5.3, "speed": 2.07, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 221, "tree_size": 512, "t0": 1.3271, "t1": 1.4043, "tft": 2.5084, "input_0": 1145, "input_1": 513, "min_CLP": -8.69, "draft_iters": 8.0, "mem_use": 43.78, "gen_rate": 4.6, "speed": 1.67, "text": "F-centers, short for \"Farbe-Zent"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.5, "tree_w": 261, "tree_size": 512, "t0": 1.37, "t1": 1.47, "tft": 5.2711, "input_0": 1148, "input_1": 513, "min_CLP": -10.01, "draft_iters": 7.8, "mem_use": 48.31, "gen_rate": 5.8, "speed": 2.05, "text": "You\\'re welcome! Let me know if "}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 300, "tree_size": 512, "t0": 0.8175, "t1": 1.4312, "tft": 3.4232, "input_0": 818, "input_1": 513, "min_CLP": -9.54, "draft_iters": 5.0, "mem_use": 45.4, "gen_rate": 4.0, "speed": 1.78, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 242, "tree_size": 512, "t0": 1.2817, "t1": 1.41, "tft": 2.6734, "input_0": 973, "input_1": 513, "min_CLP": -7.98, "draft_iters": 8.2, "mem_use": 44.21, "gen_rate": 5.3, "speed": 1.98, "text": "Pros: AI assistants can work 24/"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.0, "tree_w": 196, "tree_size": 512, "t0": 1.77, "t1": 1.435, "tft": 3.502, "input_0": 1334, "input_1": 513, "min_CLP": -7.97, "draft_iters": 10.7, "mem_use": 46.09, "gen_rate": 5.8, "speed": 1.82, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.2, "tree_w": 241, "tree_size": 512, "t0": 1.3267, "t1": 1.4383, "tft": 3.5333, "input_0": 1099, "input_1": 513, "min_CLP": -9.07, "draft_iters": 8.3, "mem_use": 46.05, "gen_rate": 5.7, "speed": 2.05, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 18, "tree_h": 3.2, "tree_w": 289, "tree_size": 512, "t0": 0.816, "t1": 1.428, "tft": 3.4232, "input_0": 891, "input_1": 513, "min_CLP": -11.6, "draft_iters": 5.0, "mem_use": 45.4, "gen_rate": 3.6, "speed": 1.61, "text": "Im sorry, complying with your re"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 291, "tree_size": 512, "t0": 0.8137, "t1": 1.4225, "tft": 2.7265, "input_0": 809, "input_1": 513, "min_CLP": -8.73, "draft_iters": 5.0, "mem_use": 44.44, "gen_rate": 4.0, "speed": 1.79, "text": "If you know who the owner is, yo"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 291, "tree_size": 512, "t0": 0.8163, "t1": 1.4113, "tft": 2.5656, "input_0": 861, "input_1": 513, "min_CLP": -9.85, "draft_iters": 5.0, "mem_use": 44.04, "gen_rate": 4.1, "speed": 1.85, "text": "\u6211\u5efa\u8b70\u60a8\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. \"Attention Is Al"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 250, "tree_size": 512, "t0": 2.1225, "t1": 1.41, "tft": 2.4991, "input_0": 1586, "input_1": 513, "min_CLP": -11.44, "draft_iters": 11.8, "mem_use": 43.85, "gen_rate": 9.5, "speed": 2.69, "text": "```javascript\\nfunction checkPri"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 232, "tree_size": 512, "t0": 1.8317, "t1": 1.43, "tft": 3.2398, "input_0": 1494, "input_1": 513, "min_CLP": -9.53, "draft_iters": 11.0, "mem_use": 45.11, "gen_rate": 5.5, "speed": 1.69, "text": "Public nudity is generally consi"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 236, "tree_size": 512, "t0": 1.4343, "t1": 1.4157, "tft": 2.6786, "input_0": 1154, "input_1": 513, "min_CLP": -8.24, "draft_iters": 8.6, "mem_use": 44.23, "gen_rate": 4.9, "speed": 1.7, "text": "\"You're welcome! To deliver this"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.4, "tree_w": 262, "tree_size": 512, "t0": 1.2257, "t1": 1.4271, "tft": 3.2176, "input_0": 1169, "input_1": 513, "min_CLP": -9.09, "draft_iters": 7.6, "mem_use": 45.11, "gen_rate": 5.0, "speed": 1.88, "text": "The optimal thickness for mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 276, "tree_size": 512, "t0": 1.0175, "t1": 1.42, "tft": 2.9757, "input_0": 926, "input_1": 513, "min_CLP": -11.43, "draft_iters": 6.5, "mem_use": 44.49, "gen_rate": 4.2, "speed": 1.74, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.2, "tree_w": 253, "tree_size": 512, "t0": 1.0089, "t1": 1.4067, "tft": 2.5308, "input_0": 868, "input_1": 513, "min_CLP": -8.74, "draft_iters": 6.3, "mem_use": 43.78, "gen_rate": 3.7, "speed": 1.52, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.0, "tree_w": 210, "tree_size": 512, "t0": 1.934, "t1": 1.406, "tft": 2.6369, "input_0": 1226, "input_1": 513, "min_CLP": -12.94, "draft_iters": 12.4, "mem_use": 44.17, "gen_rate": 8.4, "speed": 2.51, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 244, "tree_size": 512, "t0": 1.64, "t1": 1.4217, "tft": 3.1531, "input_0": 1261, "input_1": 513, "min_CLP": -10.85, "draft_iters": 9.7, "mem_use": 44.92, "gen_rate": 5.5, "speed": 1.8, "text": "\"1. Felices: \\n\u2022 \u00ab(I Can't Get N"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 252, "tree_size": 512, "t0": 1.41, "t1": 1.41, "tft": 2.5409, "input_0": 1081, "input_1": 513, "min_CLP": -15.03, "draft_iters": 9.7, "mem_use": 43.87, "gen_rate": 8.7, "speed": 3.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.7, "tree_w": 268, "tree_size": 512, "t0": 1.3114, "t1": 1.4186, "tft": 2.686, "input_0": 1004, "input_1": 513, "min_CLP": -10.2, "draft_iters": 8.9, "mem_use": 44.26, "gen_rate": 4.9, "speed": 1.78, "text": "\"Oh, you're right! Here is the c"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 5.2, "tree_w": 250, "tree_size": 512, "t0": 1.2225, "t1": 1.4275, "tft": 2.9902, "input_0": 986, "input_1": 513, "min_CLP": -8.35, "draft_iters": 7.5, "mem_use": 44.62, "gen_rate": 4.5, "speed": 1.7, "text": "Certainly, how about, \"A heart\\'"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 299, "tree_size": 512, "t0": 0.82, "t1": 1.4387, "tft": 3.4142, "input_0": 859, "input_1": 513, "min_CLP": -11.15, "draft_iters": 5.0, "mem_use": 45.37, "gen_rate": 4.1, "speed": 1.83, "text": "Sure, I can guide you through th"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 3.7, "tree_w": 296, "tree_size": 512, "t0": 0.9429, "t1": 1.41, "tft": 2.5407, "input_0": 1121, "input_1": 513, "min_CLP": -8.87, "draft_iters": 5.6, "mem_use": 43.87, "gen_rate": 4.7, "speed": 2.0, "text": "Frank-Walter Steinmeier (German:"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.2, "tree_w": 229, "tree_size": 512, "t0": 1.516, "t1": 1.414, "tft": 2.5052, "input_0": 1083, "input_1": 513, "min_CLP": -8.86, "draft_iters": 9.6, "mem_use": 43.8, "gen_rate": 6.6, "speed": 2.25, "text": "Which of the following is not a "}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.3, "tree_w": 224, "tree_size": 512, "t0": 1.7814, "t1": 1.4629, "tft": 4.9842, "input_0": 1244, "input_1": 513, "min_CLP": -9.12, "draft_iters": 11.9, "mem_use": 47.89, "gen_rate": 5.0, "speed": 1.54, "text": "Here is a bulleted list of the s"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 252, "tree_size": 512, "t0": 1.355, "t1": 1.41, "tft": 2.3109, "input_0": 1119, "input_1": 513, "min_CLP": -9.94, "draft_iters": 8.2, "mem_use": 43.7, "gen_rate": 4.2, "speed": 1.54, "text": "\"[END] People don't like the man"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 197, "tree_size": 512, "t0": 2.3033, "t1": 1.4, "tft": 2.0653, "input_0": 1616, "input_1": 513, "min_CLP": -11.21, "draft_iters": 14.3, "mem_use": 43.66, "gen_rate": 13.0, "speed": 3.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 9, "tree_h": 3.0, "tree_w": 322, "tree_size": 512, "t0": 0.8233, "t1": 1.4567, "tft": 4.9597, "input_0": 843, "input_1": 513, "min_CLP": -11.34, "draft_iters": 5.0, "mem_use": 47.89, "gen_rate": 3.0, "speed": 1.32, "text": "Hey there! How can I assist you "}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.6, "tree_w": 137, "tree_size": 512, "t0": 2.594, "t1": 1.428, "tft": 6.3095, "input_0": 1561, "input_1": 513, "min_CLP": -7.25, "draft_iters": 17.8, "mem_use": 45.71, "gen_rate": 7.0, "speed": 1.74, "text": "\"\u2022 Continue to monitor your prog"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 7.8, "tree_w": 214, "tree_size": 512, "t0": 1.532, "t1": 1.422, "tft": 3.1839, "input_0": 1114, "input_1": 513, "min_CLP": -9.45, "draft_iters": 10.2, "mem_use": 44.95, "gen_rate": 7.2, "speed": 2.44, "text": "\"The reason this is considered a"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.4, "tree_w": 246, "tree_size": 512, "t0": 1.0837, "t1": 1.4075, "tft": 2.5218, "input_0": 1027, "input_1": 513, "min_CLP": -9.5, "draft_iters": 6.5, "mem_use": 43.85, "gen_rate": 4.2, "speed": 1.71, "text": "The Battle of Borodino took plac"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 229, "tree_size": 512, "t0": 1.3883, "t1": 1.41, "tft": 2.528, "input_0": 1172, "input_1": 513, "min_CLP": -10.03, "draft_iters": 8.2, "mem_use": 43.86, "gen_rate": 5.3, "speed": 1.91, "text": "Sure! In game theory and strateg"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.3, "tree_w": 224, "tree_size": 512, "t0": 1.7557, "t1": 1.4229, "tft": 3.0012, "input_0": 1111, "input_1": 513, "min_CLP": -8.76, "draft_iters": 12.3, "mem_use": 44.68, "gen_rate": 5.7, "speed": 1.8, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 50, "tree_h": 9.0, "tree_w": 255, "tree_size": 512, "t0": 1.674, "t1": 1.426, "tft": 3.2372, "input_0": 1407, "input_1": 513, "min_CLP": -10.47, "draft_iters": 10.8, "mem_use": 45.2, "gen_rate": 10.0, "speed": 3.22, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 276, "tree_size": 512, "t0": 0.845, "t1": 1.4225, "tft": 2.9656, "input_0": 841, "input_1": 513, "min_CLP": -10.08, "draft_iters": 5.1, "mem_use": 44.62, "gen_rate": 4.0, "speed": 1.77, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.9, "tree_w": 181, "tree_size": 512, "t0": 1.72, "t1": 1.42, "tft": 2.9842, "input_0": 1289, "input_1": 513, "min_CLP": -7.61, "draft_iters": 10.4, "mem_use": 44.73, "gen_rate": 5.3, "speed": 1.68, "text": "\"And let's not forget your beaut"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.0, "tree_w": 257, "tree_size": 512, "t0": 1.0325, "t1": 1.415, "tft": 2.6528, "input_0": 976, "input_1": 513, "min_CLP": -8.21, "draft_iters": 6.1, "mem_use": 44.14, "gen_rate": 4.6, "speed": 1.89, "text": "The weight of a coconut is not a"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 198, "tree_size": 512, "t0": 1.6533, "t1": 1.4083, "tft": 2.654, "input_0": 1300, "input_1": 513, "min_CLP": -9.03, "draft_iters": 10.2, "mem_use": 44.1, "gen_rate": 5.5, "speed": 1.8, "text": "Tenants are considered superior "}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 278, "tree_size": 512, "t0": 1.2057, "t1": 1.4357, "tft": 3.4501, "input_0": 1042, "input_1": 513, "min_CLP": -9.51, "draft_iters": 7.1, "mem_use": 45.41, "gen_rate": 4.6, "speed": 1.73, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.0, "tree_w": 216, "tree_size": 512, "t0": 1.628, "t1": 1.432, "tft": 3.4189, "input_0": 1257, "input_1": 513, "min_CLP": -9.03, "draft_iters": 10.2, "mem_use": 45.33, "gen_rate": 7.0, "speed": 2.29, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 226, "tree_size": 512, "t0": 1.8567, "t1": 1.4483, "tft": 4.0746, "input_0": 1291, "input_1": 513, "min_CLP": -11.31, "draft_iters": 11.7, "mem_use": 46.79, "gen_rate": 5.5, "speed": 1.66, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.8, "tree_w": 228, "tree_size": 512, "t0": 1.4833, "t1": 1.4133, "tft": 2.2678, "input_0": 1152, "input_1": 513, "min_CLP": -9.94, "draft_iters": 9.2, "mem_use": 43.66, "gen_rate": 5.7, "speed": 1.96, "text": "The current President of Germany"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.0, "tree_w": 261, "tree_size": 512, "t0": 1.0637, "t1": 1.4275, "tft": 3.002, "input_0": 987, "input_1": 513, "min_CLP": -8.17, "draft_iters": 6.2, "mem_use": 44.57, "gen_rate": 4.1, "speed": 1.66, "text": "PostCSS is a tool that makes it "}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 8.5, "tree_w": 186, "tree_size": 512, "t0": 1.76, "t1": 1.435, "tft": 3.7929, "input_0": 1215, "input_1": 513, "min_CLP": -10.45, "draft_iters": 11.0, "mem_use": 46.44, "gen_rate": 2.5, "speed": 0.78, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.2, "tree_w": 285, "tree_size": 512, "t0": 0.865, "t1": 1.4163, "tft": 2.6611, "input_0": 911, "input_1": 513, "min_CLP": -9.65, "draft_iters": 5.2, "mem_use": 44.17, "gen_rate": 4.1, "speed": 1.81, "text": "- Introduction to the topic\\n- D"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 296, "tree_size": 512, "t0": 1.0429, "t1": 1.43, "tft": 3.1879, "input_0": 958, "input_1": 513, "min_CLP": -9.46, "draft_iters": 6.9, "mem_use": 45.01, "gen_rate": 4.7, "speed": 1.91, "text": "My apologies for the confusion e"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 512, "max_branch_width": 32, "gen_rate": 6.23, "gen_rate_micro": 5.71, "gen_speed": 2.033, "gen_speed_micro": 1.991, "t0": 1.5598, "t1": 1.4215, "input_0": 1186.1, "input_1": 513.0, "tree_size": 512.0, "tree_w": 233.2, "tree_h": 7.7, "prompt_len": 298.0, "min_CLP": -9.42, "mem_use": 53.09, "exp_time": 11781.19}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.2, "tree_w": 221, "tree_size": 1024, "t0": 4.085, "t1": 2.3525, "tft": 6.3985, "input_0": 3598, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 23.8, "mem_use": 46.68, "gen_rate": 9.2, "speed": 1.44, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 17.2, "tree_w": 186, "tree_size": 1024, "t0": 4.7033, "t1": 2.395, "tft": 8.6695, "input_0": 3786, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 25.8, "mem_use": 48.22, "gen_rate": 6.2, "speed": 0.87, "text": "I apologize for the error in my "}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.8, "tree_w": 242, "tree_size": 1024, "t0": 4.044, "t1": 2.386, "tft": 9.0749, "input_0": 3787, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 22.6, "mem_use": 49.11, "gen_rate": 7.2, "speed": 1.12, "text": "1. Minecraft:\\nStreaming Minecra"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.0, "tree_w": 119, "tree_size": 1024, "t0": 5.82, "t1": 2.3567, "tft": 7.0461, "input_0": 4981, "input_1": 1025, "min_CLP": -7.29, "draft_iters": 31.3, "mem_use": 46.86, "gen_rate": 11.3, "speed": 1.39, "text": "```python\\ndef average_rate_of_c"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.3, "tree_w": 137, "tree_size": 1024, "t0": 5.3, "t1": 2.3467, "tft": 6.0237, "input_0": 4373, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 28.3, "mem_use": 46.7, "gen_rate": 10.7, "speed": 1.39, "text": "\"Of course! I'd be happy to help"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 15.2, "tree_w": 168, "tree_size": 1024, "t0": 4.346, "t1": 2.4, "tft": 10.0821, "input_0": 3888, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 23.6, "mem_use": 49.24, "gen_rate": 8.8, "speed": 1.3, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 22.0, "tree_w": 101, "tree_size": 1024, "t0": 5.725, "t1": 2.405, "tft": 10.3985, "input_0": 4804, "input_1": 1025, "min_CLP": -7.29, "draft_iters": 31.2, "mem_use": 49.84, "gen_rate": 9.8, "speed": 1.2, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 19.3, "tree_w": 105, "tree_size": 1024, "t0": 5.7767, "t1": 2.47, "tft": 10.6848, "input_0": 5010, "input_1": 1025, "min_CLP": -7.25, "draft_iters": 29.7, "mem_use": 52.01, "gen_rate": 14.7, "speed": 1.78, "text": "\"Sure, I'd be happy to provide s"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 24.7, "tree_w": 119, "tree_size": 1024, "t0": 5.5333, "t1": 2.39, "tft": 9.08, "input_0": 4356, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 32.0, "mem_use": 49.44, "gen_rate": 15.0, "speed": 1.89, "text": "Sure, here is a list of the lega"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 20.8, "tree_w": 113, "tree_size": 1024, "t0": 5.3775, "t1": 2.3975, "tft": 8.7769, "input_0": 4325, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 30.0, "mem_use": 48.82, "gen_rate": 8.0, "speed": 1.03, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 31, "tree_h": 22.3, "tree_w": 150, "tree_size": 1024, "t0": 4.7533, "t1": 2.37, "tft": 7.8488, "input_0": 3257, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 29.0, "mem_use": 47.36, "gen_rate": 10.3, "speed": 1.45, "text": "``The first number is A.\\nRead A"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 23.3, "tree_w": 119, "tree_size": 1024, "t0": 5.4533, "t1": 2.37, "tft": 10.2537, "input_0": 4186, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 32.0, "mem_use": 49.19, "gen_rate": 13.7, "speed": 1.75, "text": "Certainly! Here\\'s a slightly sh"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 21.0, "tree_w": 106, "tree_size": 1024, "t0": 5.52, "t1": 2.39, "tft": 9.0073, "input_0": 4170, "input_1": 1025, "min_CLP": -7.31, "draft_iters": 29.5, "mem_use": 48.41, "gen_rate": 21.0, "speed": 2.66, "text": "Sure, here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 13.0, "tree_w": 187, "tree_size": 1024, "t0": 4.75, "t1": 2.35, "tft": 7.0805, "input_0": 4518, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 23.0, "mem_use": 46.68, "gen_rate": 5.0, "speed": 0.7, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.5, "tree_w": 146, "tree_size": 1024, "t0": 4.765, "t1": 2.415, "tft": 8.8341, "input_0": 4037, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 25.8, "mem_use": 49.81, "gen_rate": 8.8, "speed": 1.22, "text": "\"With limited time, it's essenti"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.8, "tree_w": 199, "tree_size": 1024, "t0": 4.6875, "t1": 2.3625, "tft": 7.3089, "input_0": 4114, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 24.8, "mem_use": 47.01, "gen_rate": 8.0, "speed": 1.13, "text": "To ensure that both your Twitch "}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 81, "tree_size": 1024, "t0": 6.655, "t1": 2.36, "tft": 6.8473, "input_0": 5046, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 32.0, "mem_use": 46.7, "gen_rate": 22.5, "speed": 2.5, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 19.7, "tree_w": 150, "tree_size": 1024, "t0": 4.9233, "t1": 2.35, "tft": 6.3279, "input_0": 3761, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 27.7, "mem_use": 46.67, "gen_rate": 13.3, "speed": 1.83, "text": "def generate_java_hello_world():"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 154, "tree_size": 1024, "t0": 6.0233, "t1": 2.36, "tft": 7.2014, "input_0": 5235, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 32.0, "mem_use": 47.21, "gen_rate": 10.7, "speed": 1.27, "text": "D-theanine is a type of amino ac"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 18.8, "tree_w": 144, "tree_size": 1024, "t0": 5.1575, "t1": 2.36, "tft": 6.4431, "input_0": 3940, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 28.8, "mem_use": 46.68, "gen_rate": 11.5, "speed": 1.53, "text": "The Balfour Declaration refers t"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 19.2, "tree_w": 277, "tree_size": 1024, "t0": 4.04, "t1": 2.3775, "tft": 7.7921, "input_0": 2598, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 26.8, "mem_use": 47.53, "gen_rate": 5.0, "speed": 0.78, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 24.0, "tree_w": 151, "tree_size": 1024, "t0": 5.18, "t1": 2.35, "tft": 5.7288, "input_0": 4138, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 32.0, "mem_use": 46.68, "gen_rate": 6.0, "speed": 0.8, "text": "Hello there, Obi-Wan Kenobi!"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.7, "tree_w": 120, "tree_size": 1024, "t0": 5.75, "t1": 2.3667, "tft": 8.8111, "input_0": 4878, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 30.0, "mem_use": 49.03, "gen_rate": 13.7, "speed": 1.68, "text": "Given that your dataset has an a"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 131, "tree_size": 1024, "t0": 4.805, "t1": 2.3575, "tft": 6.9826, "input_0": 4064, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 25.0, "mem_use": 46.75, "gen_rate": 8.2, "speed": 1.15, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 20.3, "tree_w": 176, "tree_size": 1024, "t0": 4.5033, "t1": 2.375, "tft": 8.4884, "input_0": 3301, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 27.7, "mem_use": 47.72, "gen_rate": 6.3, "speed": 0.92, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 125, "tree_size": 1024, "t0": 5.185, "t1": 2.36, "tft": 6.3596, "input_0": 3903, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 26.0, "speed": 3.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.8, "tree_w": 198, "tree_size": 1024, "t0": 4.0325, "t1": 2.3675, "tft": 7.6565, "input_0": 3354, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 24.2, "mem_use": 47.38, "gen_rate": 8.0, "speed": 1.25, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 21.0, "tree_w": 134, "tree_size": 1024, "t0": 5.3933, "t1": 2.37, "tft": 7.3356, "input_0": 3992, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 30.3, "mem_use": 47.25, "gen_rate": 8.7, "speed": 1.12, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.2, "tree_w": 250, "tree_size": 1024, "t0": 3.43, "t1": 2.378, "tft": 8.8445, "input_0": 2942, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 20.0, "mem_use": 49.17, "gen_rate": 6.6, "speed": 1.14, "text": "\"(Verse 1)\\nOh, the magic in the"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 22.0, "tree_w": 147, "tree_size": 1024, "t0": 4.84, "t1": 2.3567, "tft": 6.5581, "input_0": 3993, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 29.7, "mem_use": 46.72, "gen_rate": 10.7, "speed": 1.48, "text": "## Answer:\\nDough and cheese are"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 15.7, "tree_w": 273, "tree_size": 1024, "t0": 4.6633, "t1": 2.3767, "tft": 8.082, "input_0": 4093, "input_1": 1025, "min_CLP": -8.65, "draft_iters": 23.7, "mem_use": 47.43, "gen_rate": 11.7, "speed": 1.66, "text": "\"Yes, that's correct. Into the B"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 22.0, "tree_w": 146, "tree_size": 1024, "t0": 5.0167, "t1": 2.3733, "tft": 8.2359, "input_0": 3514, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 29.7, "mem_use": 47.84, "gen_rate": 18.7, "speed": 2.52, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 15.8, "tree_w": 213, "tree_size": 1024, "t0": 4.0683, "t1": 2.3667, "tft": 6.2429, "input_0": 3117, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 23.7, "mem_use": 47.18, "gen_rate": 5.8, "speed": 0.91, "text": "Freyja, the goddess of love, fer"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.8, "tree_w": 162, "tree_size": 1024, "t0": 4.0875, "t1": 2.395, "tft": 8.4476, "input_0": 3267, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 22.5, "mem_use": 48.84, "gen_rate": 8.2, "speed": 1.27, "text": "You can try using soy cheese, wh"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.2, "tree_w": 246, "tree_size": 1024, "t0": 3.9675, "t1": 2.3975, "tft": 7.662, "input_0": 3733, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 22.2, "mem_use": 48.88, "gen_rate": 9.2, "speed": 1.45, "text": "\"It's generally a good idea to c"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.0, "tree_w": 164, "tree_size": 1024, "t0": 4.8567, "t1": 2.4633, "tft": 12.4418, "input_0": 4056, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 27.7, "mem_use": 51.61, "gen_rate": 11.7, "speed": 1.59, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.3, "tree_w": 187, "tree_size": 1024, "t0": 4.0367, "t1": 2.3567, "tft": 6.2593, "input_0": 3121, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 23.0, "mem_use": 46.71, "gen_rate": 12.0, "speed": 1.88, "text": "\"The airspeed velocity of an unl"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.3, "tree_w": 108, "tree_size": 1024, "t0": 5.26, "t1": 2.36, "tft": 8.1407, "input_0": 3930, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 29.3, "mem_use": 47.24, "gen_rate": 11.3, "speed": 1.49, "text": "I apologize for the confusion, b"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 21.0, "tree_w": 135, "tree_size": 1024, "t0": 5.755, "t1": 2.4025, "tft": 9.209, "input_0": 4885, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 31.2, "mem_use": 49.61, "gen_rate": 8.5, "speed": 1.04, "text": "Sure, I can try to act like I ha"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 21.0, "tree_w": 100, "tree_size": 1024, "t0": 6.4867, "t1": 2.38, "tft": 8.2594, "input_0": 5769, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 32.0, "mem_use": 47.64, "gen_rate": 14.3, "speed": 1.62, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 47, "tree_h": 12.5, "tree_w": 279, "tree_size": 1024, "t0": 3.6125, "t1": 2.3625, "tft": 7.0222, "input_0": 2838, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 19.6, "mem_use": 46.93, "gen_rate": 5.9, "speed": 0.98, "text": "My power is not for sale, mortal"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 80, "tree_size": 1024, "t0": 6.345, "t1": 2.415, "tft": 9.0462, "input_0": 4521, "input_1": 1025, "min_CLP": -10.49, "draft_iters": 32.0, "mem_use": 49.42, "gen_rate": 24.5, "speed": 2.8, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 153, "tree_size": 1024, "t0": 5.255, "t1": 2.405, "tft": 9.4996, "input_0": 3343, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 32.0, "mem_use": 49.86, "gen_rate": 26.0, "speed": 3.39, "text": "[INST] AI assistant. I am lookin"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.7, "tree_w": 123, "tree_size": 1024, "t0": 5.86, "t1": 2.38, "tft": 8.2713, "input_0": 4920, "input_1": 1025, "min_CLP": -7.28, "draft_iters": 30.7, "mem_use": 48.21, "gen_rate": 12.0, "speed": 1.46, "text": "It\\'s difficult to say which SAS"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 22.0, "tree_w": 135, "tree_size": 1024, "t0": 5.6567, "t1": 2.3633, "tft": 8.2797, "input_0": 4538, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 31.3, "mem_use": 47.47, "gen_rate": 17.0, "speed": 2.12, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 19.2, "tree_w": 234, "tree_size": 1024, "t0": 3.9433, "t1": 2.36, "tft": 7.2079, "input_0": 2664, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 25.7, "mem_use": 47.2, "gen_rate": 5.7, "speed": 0.9, "text": "\"o\\n====\\n  ||\\n / \\\\\\n /   \\\\\\n"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 22.0, "tree_w": 79, "tree_size": 1024, "t0": 6.835, "t1": 2.355, "tft": 6.7657, "input_0": 5510, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 32.0, "mem_use": 46.71, "gen_rate": 21.0, "speed": 2.28, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 94, "tree_size": 1024, "t0": 5.855, "t1": 2.46, "tft": 11.7764, "input_0": 3786, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 32.0, "mem_use": 52.15, "gen_rate": 26.5, "speed": 3.19, "text": "\"Absolutely, here's a revised ve"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.0, "tree_w": 348, "tree_size": 1024, "t0": 2.534, "t1": 2.384, "tft": 7.7319, "input_0": 2315, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 14.0, "mem_use": 48.45, "gen_rate": 7.2, "speed": 1.46, "text": "\"Yes, yes, I know what you're th"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 26.5, "tree_w": 328, "tree_size": 1024, "t0": 4.025, "t1": 2.36, "tft": 6.7168, "input_0": 2274, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 32.0, "mem_use": 47.47, "gen_rate": 16.5, "speed": 2.58, "text": "You see as large language models"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 17.3, "tree_w": 145, "tree_size": 1024, "t0": 4.9, "t1": 2.3533, "tft": 6.9227, "input_0": 3797, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 26.3, "mem_use": 46.98, "gen_rate": 14.7, "speed": 2.02, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u91cd\u8981\u8bfe\u9898\u3002\\n["}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 21.0, "tree_w": 92, "tree_size": 1024, "t0": 6.52, "t1": 2.39, "tft": 8.8047, "input_0": 5488, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 32.0, "mem_use": 48.88, "gen_rate": 22.0, "speed": 2.47, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.0, "tree_w": 134, "tree_size": 1024, "t0": 4.97, "t1": 2.38, "tft": 9.347, "input_0": 4031, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 27.8, "mem_use": 48.1, "gen_rate": 8.0, "speed": 1.09, "text": "Here are some more historical ev"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.0, "tree_w": 161, "tree_size": 1024, "t0": 4.7, "t1": 2.395, "tft": 8.8817, "input_0": 4201, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 25.5, "mem_use": 48.43, "gen_rate": 9.5, "speed": 1.34, "text": "I agree that technology can be u"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.4, "tree_w": 193, "tree_size": 1024, "t0": 3.84, "t1": 2.348, "tft": 6.8793, "input_0": 3297, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 20.4, "mem_use": 46.88, "gen_rate": 7.8, "speed": 1.26, "text": "In real life, it is common for b"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.0, "tree_w": 217, "tree_size": 1024, "t0": 4.248, "t1": 2.392, "tft": 8.8741, "input_0": 3697, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 23.2, "mem_use": 49.27, "gen_rate": 7.0, "speed": 1.05, "text": "Title: FullView.io - The Ultimat"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 19.2, "tree_w": 155, "tree_size": 1024, "t0": 4.678, "t1": 2.44, "tft": 9.7844, "input_0": 3691, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 27.8, "mem_use": 50.53, "gen_rate": 7.0, "speed": 0.98, "text": "You are correct again. My apolog"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.0, "tree_w": 121, "tree_size": 1024, "t0": 5.53, "t1": 2.4267, "tft": 10.0474, "input_0": 5025, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 30.0, "mem_use": 50.69, "gen_rate": 11.3, "speed": 1.42, "text": "\"Keras is indeed a great choice "}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.7, "tree_w": 148, "tree_size": 1024, "t0": 5.0967, "t1": 2.3867, "tft": 9.4961, "input_0": 4163, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 28.0, "mem_use": 48.36, "gen_rate": 10.7, "speed": 1.43, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.7, "tree_w": 193, "tree_size": 1024, "t0": 4.0467, "t1": 2.3533, "tft": 6.1844, "input_0": 3186, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 22.0, "mem_use": 46.7, "gen_rate": 11.0, "speed": 1.72, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 20.5, "tree_w": 119, "tree_size": 1024, "t0": 6.25, "t1": 2.375, "tft": 9.3296, "input_0": 5287, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 32.0, "mem_use": 49.1, "gen_rate": 16.0, "speed": 1.86, "text": "No, it is not possible to cook a"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 14.8, "tree_w": 166, "tree_size": 1024, "t0": 4.226, "t1": 2.418, "tft": 9.5202, "input_0": 3486, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 23.0, "mem_use": 49.95, "gen_rate": 8.6, "speed": 1.29, "text": "[The scene opens on a battlefiel"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 17.2, "tree_w": 191, "tree_size": 1024, "t0": 4.24, "t1": 2.37, "tft": 6.2903, "input_0": 3278, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 25.0, "mem_use": 47.66, "gen_rate": 7.2, "speed": 1.09, "text": "I see. How about this: \"Wishing "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 12.5, "tree_w": 212, "tree_size": 1024, "t0": 3.5933, "t1": 2.3683, "tft": 7.0726, "input_0": 3055, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 20.2, "mem_use": 47.37, "gen_rate": 5.8, "speed": 0.98, "text": "The proof-of-stake concept works"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.0, "tree_w": 251, "tree_size": 1024, "t0": 3.5683, "t1": 2.36, "tft": 7.561, "input_0": 2966, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 21.2, "mem_use": 47.49, "gen_rate": 6.0, "speed": 1.01, "text": "[INST] What are you referring to"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.7, "tree_w": 128, "tree_size": 1024, "t0": 5.4033, "t1": 2.3767, "tft": 9.0688, "input_0": 4519, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 29.0, "mem_use": 49.56, "gen_rate": 11.7, "speed": 1.5, "text": "Void pointers are a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 17.2, "tree_w": 181, "tree_size": 1024, "t0": 4.384, "t1": 2.422, "tft": 9.391, "input_0": 3745, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 25.2, "mem_use": 50.08, "gen_rate": 10.2, "speed": 1.5, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.0, "tree_w": 111, "tree_size": 1024, "t0": 5.96, "t1": 2.3967, "tft": 9.9345, "input_0": 5163, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 30.7, "mem_use": 49.28, "gen_rate": 12.3, "speed": 1.48, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 17.0, "tree_w": 263, "tree_size": 1024, "t0": 4.5875, "t1": 2.3525, "tft": 7.7989, "input_0": 4183, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 24.8, "mem_use": 47.11, "gen_rate": 6.0, "speed": 0.86, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 157, "tree_size": 1024, "t0": 4.12, "t1": 2.35, "tft": 7.2772, "input_0": 3549, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 21.5, "mem_use": 46.7, "gen_rate": 8.2, "speed": 1.28, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.0, "tree_w": 173, "tree_size": 1024, "t0": 6.31, "t1": 2.38, "tft": 10.4333, "input_0": 4500, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 32.0, "mem_use": 49.52, "gen_rate": 16.0, "speed": 1.84, "text": "\"Certainly! Here's the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 25.0, "tree_w": 169, "tree_size": 1024, "t0": 4.72, "t1": 2.35, "tft": 6.5647, "input_0": 3072, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 32.0, "mem_use": 46.65, "gen_rate": 3.0, "speed": 0.42, "text": "Who made Berlin?"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 138, "tree_size": 1024, "t0": 6.875, "t1": 2.39, "tft": 8.6275, "input_0": 5324, "input_1": 1025, "min_CLP": -9.77, "draft_iters": 32.0, "mem_use": 48.98, "gen_rate": 23.5, "speed": 2.54, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 23.3, "tree_w": 92, "tree_size": 1024, "t0": 5.93, "t1": 2.3833, "tft": 9.0472, "input_0": 4918, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 48.84, "gen_rate": 13.7, "speed": 1.64, "text": "Certainly! While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.3, "tree_w": 305, "tree_size": 1024, "t0": 3.3333, "t1": 2.35, "tft": 6.4688, "input_0": 3399, "input_1": 1025, "min_CLP": -11.84, "draft_iters": 18.3, "mem_use": 46.67, "gen_rate": 6.8, "speed": 1.2, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 21.2, "tree_w": 188, "tree_size": 1024, "t0": 5.1725, "t1": 2.36, "tft": 6.9588, "input_0": 3909, "input_1": 1025, "min_CLP": -8.71, "draft_iters": 29.5, "mem_use": 46.98, "gen_rate": 11.2, "speed": 1.49, "text": "\"You can visit at The World Cloc"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 16.8, "tree_w": 195, "tree_size": 1024, "t0": 4.26, "t1": 2.355, "tft": 6.8188, "input_0": 3196, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 24.8, "mem_use": 47.06, "gen_rate": 5.3, "speed": 0.81, "text": "The five-second rule is a common"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.0, "tree_w": 147, "tree_size": 1024, "t0": 4.92, "t1": 2.35, "tft": 7.0566, "input_0": 3762, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 28.7, "mem_use": 46.79, "gen_rate": 10.7, "speed": 1.47, "text": "I have 12 eggs. I drop 2 and eat"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 22.0, "tree_w": 82, "tree_size": 1024, "t0": 6.125, "t1": 2.36, "tft": 8.7249, "input_0": 4875, "input_1": 1025, "min_CLP": -7.14, "draft_iters": 31.5, "mem_use": 47.54, "gen_rate": 18.0, "speed": 2.12, "text": "Sure! One of the simplest algori"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 17.4, "tree_w": 187, "tree_size": 1024, "t0": 4.9957, "t1": 2.3814, "tft": 6.2972, "input_0": 4029, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 27.1, "mem_use": 47.11, "gen_rate": 4.7, "speed": 0.64, "text": "\"You're welcome! If it's spoiled"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 17.5, "tree_w": 214, "tree_size": 1024, "t0": 4.2967, "t1": 2.3533, "tft": 7.3519, "input_0": 3372, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 25.2, "mem_use": 46.82, "gen_rate": 6.2, "speed": 0.93, "text": "\"Here's a draft announcement twe"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 152, "tree_size": 1024, "t0": 4.58, "t1": 2.3675, "tft": 7.8517, "input_0": 4065, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 24.0, "mem_use": 47.43, "gen_rate": 8.0, "speed": 1.15, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.7, "tree_w": 115, "tree_size": 1024, "t0": 5.7333, "t1": 2.3867, "tft": 8.8726, "input_0": 4931, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 29.3, "mem_use": 48.47, "gen_rate": 11.3, "speed": 1.4, "text": "AI assistants can also be very u"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 22.3, "tree_w": 132, "tree_size": 1024, "t0": 4.9167, "t1": 2.3867, "tft": 9.1596, "input_0": 3662, "input_1": 1025, "min_CLP": -9.53, "draft_iters": 29.3, "mem_use": 49.49, "gen_rate": 18.3, "speed": 2.51, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 17.8, "tree_w": 131, "tree_size": 1024, "t0": 5.006, "t1": 2.368, "tft": 7.7034, "input_0": 4080, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 27.2, "mem_use": 47.99, "gen_rate": 7.4, "speed": 1.0, "text": "The scp command is a Unix comman"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 72, "tree_size": 1024, "t0": 6.355, "t1": 2.385, "tft": 8.6167, "input_0": 5442, "input_1": 1025, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 48.63, "gen_rate": 24.5, "speed": 2.8, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.4, "tree_w": 196, "tree_size": 1024, "t0": 3.658, "t1": 2.352, "tft": 6.8343, "input_0": 3108, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 19.8, "mem_use": 46.73, "gen_rate": 7.2, "speed": 1.2, "text": "It is not illegal to keep a doll"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.2, "tree_w": 140, "tree_size": 1024, "t0": 5.0675, "t1": 2.355, "tft": 6.9636, "input_0": 4141, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 28.0, "mem_use": 47.02, "gen_rate": 11.0, "speed": 1.48, "text": "\"Sydney is the largest city in A"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 24.5, "tree_w": 177, "tree_size": 1024, "t0": 4.93, "t1": 2.36, "tft": 7.082, "input_0": 3930, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 32.0, "mem_use": 47.32, "gen_rate": 17.5, "speed": 2.4, "text": "\"Does the 5 second rule actually"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 14.0, "tree_w": 171, "tree_size": 1024, "t0": 3.975, "t1": 2.355, "tft": 6.2019, "input_0": 3571, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 21.5, "mem_use": 46.99, "gen_rate": 3.0, "speed": 0.47, "text": "\"Thank you, you're welcome.\""}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 84, "tree_size": 1024, "t0": 5.795, "t1": 2.36, "tft": 6.8436, "input_0": 3915, "input_1": 1025, "min_CLP": -9.67, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 26.0, "speed": 3.19, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 19.2, "tree_w": 184, "tree_size": 1024, "t0": 4.6, "t1": 2.354, "tft": 5.788, "input_0": 3897, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 27.2, "mem_use": 46.74, "gen_rate": 6.8, "speed": 0.98, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 22.7, "tree_w": 97, "tree_size": 1024, "t0": 5.8667, "t1": 2.3933, "tft": 9.4112, "input_0": 4963, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 31.3, "mem_use": 48.47, "gen_rate": 15.3, "speed": 1.86, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 23.7, "tree_w": 129, "tree_size": 1024, "t0": 5.17, "t1": 2.3567, "tft": 6.8047, "input_0": 3686, "input_1": 1025, "min_CLP": -9.38, "draft_iters": 30.7, "mem_use": 46.74, "gen_rate": 18.3, "speed": 2.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 23.0, "tree_w": 81, "tree_size": 1024, "t0": 5.975, "t1": 2.355, "tft": 7.0057, "input_0": 4327, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 32.0, "mem_use": 47.04, "gen_rate": 19.0, "speed": 2.28, "text": "To write a first person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 124, "tree_size": 1024, "t0": 6.3, "t1": 2.35, "tft": 7.1422, "input_0": 4687, "input_1": 1025, "min_CLP": -10.92, "draft_iters": 32.0, "mem_use": 46.71, "gen_rate": 24.0, "speed": 2.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 17.8, "tree_w": 142, "tree_size": 1024, "t0": 4.8175, "t1": 2.3625, "tft": 6.3411, "input_0": 3844, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 26.8, "mem_use": 47.02, "gen_rate": 10.8, "speed": 1.5, "text": "\"To become one with the Force, i"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 14.5, "tree_w": 197, "tree_size": 1024, "t0": 3.9067, "t1": 2.3567, "tft": 6.7457, "input_0": 3195, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 22.0, "mem_use": 46.88, "gen_rate": 7.2, "speed": 1.14, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.3, "tree_w": 283, "tree_size": 1024, "t0": 4.0267, "t1": 2.36, "tft": 7.3635, "input_0": 3736, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 21.7, "mem_use": 47.12, "gen_rate": 11.3, "speed": 1.77, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 15.0, "tree_w": 172, "tree_size": 1024, "t0": 4.1612, "t1": 2.4238, "tft": 8.7235, "input_0": 3265, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 23.1, "mem_use": 49.97, "gen_rate": 4.8, "speed": 0.72, "text": "Certainly, there are several lib"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.2, "tree_w": 158, "tree_size": 1024, "t0": 4.51, "t1": 2.36, "tft": 7.018, "input_0": 3669, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 25.5, "mem_use": 47.18, "gen_rate": 8.8, "speed": 1.27, "text": "Yes, it is reasonable to expect "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 17, "tree_h": 14.0, "tree_w": 201, "tree_size": 1024, "t0": 4.1233, "t1": 2.4, "tft": 9.4316, "input_0": 3933, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 22.3, "mem_use": 50.07, "gen_rate": 5.7, "speed": 0.87, "text": "Xin ch\u00e0o, ch\u00e0o m\u1eebng b\u1ea1n \u0111\u1ebfn v\u1edbi "}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.8, "tree_w": 248, "tree_size": 1024, "t0": 3.628, "t1": 2.372, "tft": 7.9448, "input_0": 2665, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 22.6, "mem_use": 47.56, "gen_rate": 7.6, "speed": 1.27, "text": "\"You can see that there is a nee"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 21.5, "tree_w": 93, "tree_size": 1024, "t0": 6.34, "t1": 2.355, "tft": 6.7843, "input_0": 4830, "input_1": 1025, "min_CLP": -7.23, "draft_iters": 32.0, "mem_use": 47.06, "gen_rate": 16.5, "speed": 1.9, "text": "Sure, here\\'s a more detailed ex"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 17.8, "tree_w": 146, "tree_size": 1024, "t0": 5.545, "t1": 2.3875, "tft": 8.7715, "input_0": 4136, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 28.5, "mem_use": 48.5, "gen_rate": 9.2, "speed": 1.17, "text": "The 10 most popular German rock "}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 303, "tree_size": 1024, "t0": 2.744, "t1": 2.352, "tft": 6.9733, "input_0": 2443, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 14.4, "mem_use": 47.03, "gen_rate": 6.4, "speed": 1.26, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 21.3, "tree_w": 125, "tree_size": 1024, "t0": 5.6433, "t1": 2.3867, "tft": 9.8382, "input_0": 4713, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 31.3, "mem_use": 49.04, "gen_rate": 11.0, "speed": 1.37, "text": "\"To acquire revenue from custome"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.3, "tree_w": 124, "tree_size": 1024, "t0": 4.9333, "t1": 2.3733, "tft": 7.5873, "input_0": 4071, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 27.0, "mem_use": 47.66, "gen_rate": 11.0, "speed": 1.51, "text": "Yes, I am capable of simulating "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 19.5, "tree_w": 121, "tree_size": 1024, "t0": 6.05, "t1": 2.355, "tft": 7.2167, "input_0": 4875, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 30.0, "mem_use": 47.19, "gen_rate": 19.0, "speed": 2.26, "text": "Certainly! I can write an essay "}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.0, "tree_w": 114, "tree_size": 1024, "t0": 5.4933, "t1": 2.3667, "tft": 7.3771, "input_0": 4707, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 28.7, "mem_use": 47.34, "gen_rate": 11.7, "speed": 1.48, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 529, "tree_size": 1024, "t0": 2.1986, "t1": 2.3929, "tft": 9.1047, "input_0": 2043, "input_1": 1025, "min_CLP": -9.23, "draft_iters": 11.9, "mem_use": 48.6, "gen_rate": 4.6, "speed": 1.0, "text": "\"Certainly! Here's a short poem "}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.8, "tree_w": 160, "tree_size": 1024, "t0": 4.7, "t1": 2.3475, "tft": 6.1931, "input_0": 3518, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 27.2, "mem_use": 46.71, "gen_rate": 8.8, "speed": 1.24, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 17.2, "tree_w": 132, "tree_size": 1024, "t0": 4.81, "t1": 2.35, "tft": 7.2294, "input_0": 4165, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 25.8, "mem_use": 46.75, "gen_rate": 9.2, "speed": 1.29, "text": "The error with this code is that"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 18.5, "tree_w": 212, "tree_size": 1024, "t0": 4.23, "t1": 2.375, "tft": 7.3409, "input_0": 3305, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 26.5, "mem_use": 48.13, "gen_rate": 9.0, "speed": 1.36, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 19.0, "tree_w": 143, "tree_size": 1024, "t0": 4.9825, "t1": 2.365, "tft": 7.2893, "input_0": 3862, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 28.2, "mem_use": 47.36, "gen_rate": 10.2, "speed": 1.4, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 21.7, "tree_w": 104, "tree_size": 1024, "t0": 5.97, "t1": 2.37, "tft": 7.6748, "input_0": 5153, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 31.3, "mem_use": 47.48, "gen_rate": 14.7, "speed": 1.76, "text": "\"To do this, you can use the arg"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.0, "tree_w": 169, "tree_size": 1024, "t0": 4.2875, "t1": 2.385, "tft": 7.8561, "input_0": 3668, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 22.8, "mem_use": 49.26, "gen_rate": 9.2, "speed": 1.39, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 120, "tree_size": 1024, "t0": 6.72, "t1": 2.37, "tft": 7.4826, "input_0": 5908, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 32.0, "mem_use": 47.27, "gen_rate": 20.5, "speed": 2.26, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 23.5, "tree_w": 64, "tree_size": 1024, "t0": 6.325, "t1": 2.395, "tft": 9.2801, "input_0": 4784, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 32.0, "mem_use": 48.63, "gen_rate": 17.0, "speed": 1.95, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 269, "tree_size": 1024, "t0": 3.2067, "t1": 2.3533, "tft": 7.0645, "input_0": 2633, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 17.7, "mem_use": 46.69, "gen_rate": 5.5, "speed": 0.99, "text": "\"my name is emily, I'm 21 years "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 14.0, "tree_w": 297, "tree_size": 1024, "t0": 3.4171, "t1": 2.3529, "tft": 6.9404, "input_0": 2587, "input_1": 1025, "min_CLP": -8.79, "draft_iters": 20.6, "mem_use": 46.91, "gen_rate": 4.7, "speed": 0.82, "text": "\"In the depths of neural archite"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.2, "tree_w": 146, "tree_size": 1024, "t0": 5.05, "t1": 2.36, "tft": 6.4941, "input_0": 4472, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 28.5, "mem_use": 47.16, "gen_rate": 8.0, "speed": 1.08, "text": "\"Thanks! I'm an AI language mode"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 24.0, "tree_w": 130, "tree_size": 1024, "t0": 5.36, "t1": 2.385, "tft": 8.3336, "input_0": 3619, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 32.0, "mem_use": 48.75, "gen_rate": 17.0, "speed": 2.2, "text": "\"Thou art the sun that doth shin"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 20.2, "tree_w": 210, "tree_size": 1024, "t0": 4.56, "t1": 2.3617, "tft": 7.1978, "input_0": 3616, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 27.8, "mem_use": 47.33, "gen_rate": 5.8, "speed": 0.84, "text": "<noinput> The source reference f"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 22.0, "tree_w": 122, "tree_size": 1024, "t0": 5.5433, "t1": 2.3533, "tft": 6.818, "input_0": 4380, "input_1": 1025, "min_CLP": -9.72, "draft_iters": 30.7, "mem_use": 46.73, "gen_rate": 16.7, "speed": 2.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.3, "tree_w": 107, "tree_size": 1024, "t0": 5.6967, "t1": 2.3467, "tft": 6.8905, "input_0": 4568, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 29.7, "mem_use": 46.72, "gen_rate": 11.0, "speed": 1.37, "text": "\"Presidents' Day, officially kno"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 19.0, "tree_w": 198, "tree_size": 1024, "t0": 4.235, "t1": 2.3525, "tft": 7.5764, "input_0": 3311, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 26.2, "mem_use": 47.01, "gen_rate": 8.2, "speed": 1.25, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.4, "tree_w": 238, "tree_size": 1024, "t0": 3.828, "t1": 2.372, "tft": 8.3113, "input_0": 3254, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 20.6, "mem_use": 47.82, "gen_rate": 8.0, "speed": 1.29, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 13.6, "tree_w": 229, "tree_size": 1024, "t0": 3.81, "t1": 2.36, "tft": 6.6389, "input_0": 3167, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 21.4, "mem_use": 47.09, "gen_rate": 4.6, "speed": 0.74, "text": "\"Why were the Windows in Silicon"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 12.5, "tree_w": 211, "tree_size": 1024, "t0": 3.7975, "t1": 2.3625, "tft": 7.1106, "input_0": 3062, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 20.2, "mem_use": 47.16, "gen_rate": 7.2, "speed": 1.18, "text": "Opie is a great name! I will use"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.0, "tree_w": 147, "tree_size": 1024, "t0": 5.0875, "t1": 2.3575, "tft": 6.3737, "input_0": 3817, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 28.2, "mem_use": 46.72, "gen_rate": 10.0, "speed": 1.34, "text": "The ATF (Bureau of Alcohol, Toba"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.9, "tree_w": 319, "tree_size": 1024, "t0": 2.9971, "t1": 2.3686, "tft": 7.1961, "input_0": 2534, "input_1": 1025, "min_CLP": -8.35, "draft_iters": 16.7, "mem_use": 47.39, "gen_rate": 4.9, "speed": 0.91, "text": "\"oh, come on, like, Ted who? I m"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 73, "tree_size": 1024, "t0": 6.525, "t1": 2.36, "tft": 6.9753, "input_0": 4873, "input_1": 1025, "min_CLP": -11.84, "draft_iters": 32.0, "mem_use": 46.82, "gen_rate": 24.5, "speed": 2.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.6, "tree_w": 177, "tree_size": 1024, "t0": 3.894, "t1": 2.378, "tft": 7.8388, "input_0": 3136, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 20.8, "mem_use": 48.05, "gen_rate": 7.2, "speed": 1.15, "text": "Yes, there are some medias that "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 238, "tree_size": 1024, "t0": 3.615, "t1": 2.3575, "tft": 6.7069, "input_0": 2974, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 19.5, "mem_use": 47.16, "gen_rate": 8.5, "speed": 1.42, "text": "\"I'm not capable of taking over "}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.5, "tree_w": 145, "tree_size": 1024, "t0": 5.215, "t1": 2.385, "tft": 8.9882, "input_0": 4620, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 28.2, "mem_use": 48.36, "gen_rate": 10.5, "speed": 1.38, "text": "I would recommend the Emerald La"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 22.0, "tree_w": 186, "tree_size": 1024, "t0": 4.4957, "t1": 2.3557, "tft": 6.9619, "input_0": 3125, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 28.9, "mem_use": 47.11, "gen_rate": 4.6, "speed": 0.67, "text": "\"Open Assistant: Finally, an Ope"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 16.0, "tree_w": 223, "tree_size": 1024, "t0": 3.98, "t1": 2.356, "tft": 7.3776, "input_0": 3429, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 23.2, "mem_use": 47.0, "gen_rate": 9.0, "speed": 1.42, "text": "\"Certainly! Here's a diagram to "}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 21.5, "tree_w": 125, "tree_size": 1024, "t0": 6.08, "t1": 2.375, "tft": 9.0434, "input_0": 5149, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 32.0, "mem_use": 49.33, "gen_rate": 17.0, "speed": 2.01, "text": "\"The issue you're seeing is due "}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.0, "tree_w": 169, "tree_size": 1024, "t0": 4.5733, "t1": 2.3433, "tft": 6.4038, "input_0": 3266, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 27.7, "mem_use": 46.69, "gen_rate": 11.3, "speed": 1.64, "text": "No, you cannot compile python co"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 11.6, "tree_w": 334, "tree_size": 1024, "t0": 3.0438, "t1": 2.3537, "tft": 6.9268, "input_0": 2450, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 18.0, "mem_use": 47.24, "gen_rate": 4.1, "speed": 0.76, "text": "The answer to this question is v"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 16.0, "tree_w": 174, "tree_size": 1024, "t0": 4.53, "t1": 2.356, "tft": 7.3487, "input_0": 3847, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 24.6, "mem_use": 46.87, "gen_rate": 8.2, "speed": 1.19, "text": "The hot pan helps to cook the pa"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 23, "tree_h": 24.0, "tree_w": 124, "tree_size": 1024, "t0": 5.315, "t1": 2.35, "tft": 6.2692, "input_0": 4154, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 31.5, "mem_use": 46.72, "gen_rate": 11.5, "speed": 1.5, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 15.0, "tree_w": 164, "tree_size": 1024, "t0": 4.3517, "t1": 2.39, "tft": 8.5005, "input_0": 3974, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 23.5, "mem_use": 48.8, "gen_rate": 6.7, "speed": 0.99, "text": "\"It's possible that your friend "}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.8, "tree_w": 211, "tree_size": 1024, "t0": 3.8525, "t1": 2.3475, "tft": 6.5258, "input_0": 3199, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 21.5, "mem_use": 46.67, "gen_rate": 8.2, "speed": 1.33, "text": "\"No, a thumb war is not violent."}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 24.0, "tree_w": 190, "tree_size": 1024, "t0": 5.62, "t1": 2.35, "tft": 6.8985, "input_0": 4131, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 16.0, "speed": 2.01, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 22.0, "tree_w": 166, "tree_size": 1024, "t0": 5.575, "t1": 2.425, "tft": 8.9997, "input_0": 4292, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 32.0, "mem_use": 50.03, "gen_rate": 18.0, "speed": 2.25, "text": "As of 2021, some of the most mar"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 19.2, "tree_w": 144, "tree_size": 1024, "t0": 5.0775, "t1": 2.3775, "tft": 8.3003, "input_0": 3876, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 28.8, "mem_use": 48.03, "gen_rate": 8.8, "speed": 1.17, "text": "I apologize for misunderstanding"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.3, "tree_w": 145, "tree_size": 1024, "t0": 5.2867, "t1": 2.35, "tft": 6.8167, "input_0": 4548, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 29.0, "mem_use": 46.96, "gen_rate": 10.7, "speed": 1.4, "text": "Certainly! There are many resour"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 19.5, "tree_w": 170, "tree_size": 1024, "t0": 4.4975, "t1": 2.3525, "tft": 6.8162, "input_0": 3167, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 27.4, "mem_use": 46.94, "gen_rate": 5.2, "speed": 0.77, "text": "A chat between Dr. Eris Luna and"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 17.3, "tree_w": 127, "tree_size": 1024, "t0": 4.7833, "t1": 2.3467, "tft": 6.0282, "input_0": 4044, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 26.0, "mem_use": 46.72, "gen_rate": 14.3, "speed": 2.01, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 26.0, "tree_w": 188, "tree_size": 1024, "t0": 4.71, "t1": 2.3633, "tft": 7.4932, "input_0": 3390, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 32.0, "mem_use": 47.52, "gen_rate": 12.7, "speed": 1.79, "text": "[INST] Sorry, I will clarify. Pl"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.7, "tree_w": 112, "tree_size": 1024, "t0": 6.1733, "t1": 2.37, "tft": 8.1766, "input_0": 4863, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 32.0, "mem_use": 47.55, "gen_rate": 11.7, "speed": 1.36, "text": "Por supuesto, aqu\u00ed tienes tres c"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.0, "tree_w": 116, "tree_size": 1024, "t0": 6.485, "t1": 2.42, "tft": 10.1701, "input_0": 4875, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 32.0, "mem_use": 50.05, "gen_rate": 17.5, "speed": 1.97, "text": "Step 1 \u2014 Initialize a TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 93, "tree_size": 1024, "t0": 6.29, "t1": 2.355, "tft": 6.7081, "input_0": 5106, "input_1": 1025, "min_CLP": -11.34, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 23.5, "speed": 2.72, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 279, "tree_size": 1024, "t0": 3.502, "t1": 2.362, "tft": 6.3462, "input_0": 3248, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 18.4, "mem_use": 47.28, "gen_rate": 6.8, "speed": 1.16, "text": "Berlin is known for its high-qua"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 22.0, "tree_w": 81, "tree_size": 1024, "t0": 6.54, "t1": 2.355, "tft": 6.9301, "input_0": 5519, "input_1": 1025, "min_CLP": -7.14, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 17.0, "speed": 1.91, "text": "\"Sure! Here's a Python script th"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 69, "tree_size": 1024, "t0": 5.945, "t1": 2.365, "tft": 9.5736, "input_0": 4196, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 32.0, "mem_use": 49.25, "gen_rate": 25.0, "speed": 3.01, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 20.0, "tree_w": 124, "tree_size": 1024, "t0": 5.72, "t1": 2.3467, "tft": 5.9561, "input_0": 5161, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 30.0, "mem_use": 46.66, "gen_rate": 12.0, "speed": 1.49, "text": "Answer: Step 1: Understand the q"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 199, "tree_size": 1024, "t0": 4.1975, "t1": 2.3825, "tft": 8.7966, "input_0": 3864, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 23.2, "mem_use": 48.93, "gen_rate": 8.0, "speed": 1.22, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.7, "tree_w": 183, "tree_size": 1024, "t0": 4.1367, "t1": 2.3483, "tft": 6.926, "input_0": 3444, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 22.8, "mem_use": 46.67, "gen_rate": 6.5, "speed": 1.0, "text": "The main reason we need AI assis"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 10.2, "tree_w": 357, "tree_size": 1024, "t0": 3.0462, "t1": 2.345, "tft": 6.5696, "input_0": 2311, "input_1": 1025, "min_CLP": -8.6, "draft_iters": 17.4, "mem_use": 46.66, "gen_rate": 4.1, "speed": 0.76, "text": "Human: \u8bed\u8a00\u6a21\u578b\uff1a\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684\u7ffb\u8bd1\u8005\uff0c\u80fd\u591f\u7ffb\u8bd1\u5404\u79cd\u8bed\u8a00\u3002"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.7, "tree_w": 270, "tree_size": 1024, "t0": 3.8567, "t1": 2.3433, "tft": 7.0182, "input_0": 3456, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 22.0, "mem_use": 46.82, "gen_rate": 13.0, "speed": 2.1, "text": "I cannot share personal experien"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.2, "tree_w": 141, "tree_size": 1024, "t0": 5.03, "t1": 2.3725, "tft": 8.666, "input_0": 4189, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 27.2, "mem_use": 47.87, "gen_rate": 9.5, "speed": 1.28, "text": "\"While the 1950s were a time of "}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 21.0, "tree_w": 132, "tree_size": 1024, "t0": 5.4125, "t1": 2.35, "tft": 7.0675, "input_0": 4585, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 30.5, "mem_use": 46.77, "gen_rate": 8.0, "speed": 1.03, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 17.5, "tree_w": 146, "tree_size": 1024, "t0": 4.5925, "t1": 2.3575, "tft": 6.9747, "input_0": 3533, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 25.8, "mem_use": 46.97, "gen_rate": 10.2, "speed": 1.48, "text": "In reStructuredText (rst), you c"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 19.5, "tree_w": 125, "tree_size": 1024, "t0": 5.085, "t1": 2.3625, "tft": 7.8327, "input_0": 3948, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 28.0, "mem_use": 47.31, "gen_rate": 8.8, "speed": 1.17, "text": "Selective fire refers to a weapo"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 29, "tree_h": 12.0, "tree_w": 219, "tree_size": 1024, "t0": 3.754, "t1": 2.352, "tft": 6.809, "input_0": 3479, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 20.0, "mem_use": 46.86, "gen_rate": 5.8, "speed": 0.95, "text": "I am the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 22.3, "tree_w": 109, "tree_size": 1024, "t0": 5.74, "t1": 2.3733, "tft": 9.147, "input_0": 4584, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 31.7, "mem_use": 48.08, "gen_rate": 12.0, "speed": 1.48, "text": "\"On Windows, you can use the Com"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.0, "tree_w": 143, "tree_size": 1024, "t0": 4.7425, "t1": 2.3475, "tft": 6.8057, "input_0": 3685, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 26.2, "mem_use": 46.76, "gen_rate": 9.0, "speed": 1.27, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 21.7, "tree_w": 97, "tree_size": 1024, "t0": 6.2667, "t1": 2.3667, "tft": 8.285, "input_0": 6037, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 32.0, "mem_use": 47.6, "gen_rate": 13.3, "speed": 1.54, "text": "Microwave ovens became common ho"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 16.8, "tree_w": 175, "tree_size": 1024, "t0": 4.21, "t1": 2.348, "tft": 7.0498, "input_0": 3369, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 24.8, "mem_use": 46.86, "gen_rate": 8.4, "speed": 1.28, "text": " Pros:\\n1. Increased tolerance t"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 22.5, "tree_w": 168, "tree_size": 1024, "t0": 5.16, "t1": 2.335, "tft": 5.8521, "input_0": 3530, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 32.0, "mem_use": 46.69, "gen_rate": 2.0, "speed": 0.27, "text": "None of your business."}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.8, "tree_w": 161, "tree_size": 1024, "t0": 4.9775, "t1": 2.44, "tft": 10.8266, "input_0": 4115, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 27.8, "mem_use": 50.99, "gen_rate": 8.2, "speed": 1.11, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 158, "tree_size": 1024, "t0": 6.42, "t1": 2.355, "tft": 7.651, "input_0": 5356, "input_1": 1025, "min_CLP": -11.89, "draft_iters": 32.0, "mem_use": 46.99, "gen_rate": 22.5, "speed": 2.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 22.2, "tree_w": 140, "tree_size": 1024, "t0": 5.07, "t1": 2.37, "tft": 8.2631, "input_0": 3734, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 30.2, "mem_use": 47.87, "gen_rate": 9.0, "speed": 1.21, "text": "It would take approximately 40 d"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 16.5, "tree_w": 200, "tree_size": 1024, "t0": 4.0683, "t1": 2.385, "tft": 8.9924, "input_0": 3282, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 24.2, "mem_use": 49.12, "gen_rate": 6.7, "speed": 1.03, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 15.2, "tree_w": 228, "tree_size": 1024, "t0": 3.8967, "t1": 2.355, "tft": 6.5018, "input_0": 3057, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 22.7, "mem_use": 46.97, "gen_rate": 6.3, "speed": 1.01, "text": "What do you call a broke college"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 19.8, "tree_w": 157, "tree_size": 1024, "t0": 4.812, "t1": 2.354, "tft": 6.4566, "input_0": 3634, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 28.4, "mem_use": 47.01, "gen_rate": 6.8, "speed": 0.95, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 18.0, "tree_w": 173, "tree_size": 1024, "t0": 4.552, "t1": 2.366, "tft": 8.0869, "input_0": 3789, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 26.4, "mem_use": 47.49, "gen_rate": 9.8, "speed": 1.42, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 89, "tree_size": 1024, "t0": 6.275, "t1": 2.36, "tft": 7.0048, "input_0": 4648, "input_1": 1025, "min_CLP": -10.32, "draft_iters": 32.0, "mem_use": 46.99, "gen_rate": 24.5, "speed": 2.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 270, "tree_size": 1024, "t0": 3.2467, "t1": 2.37, "tft": 8.1199, "input_0": 2667, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 17.8, "mem_use": 47.68, "gen_rate": 5.3, "speed": 0.95, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 20.3, "tree_w": 130, "tree_size": 1024, "t0": 4.9167, "t1": 2.3533, "tft": 6.3848, "input_0": 3755, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 28.7, "mem_use": 47.01, "gen_rate": 11.0, "speed": 1.51, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 18.6, "tree_w": 148, "tree_size": 1024, "t0": 4.74, "t1": 2.35, "tft": 7.0831, "input_0": 3693, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 27.0, "mem_use": 46.74, "gen_rate": 7.4, "speed": 1.04, "text": "1. Environment: The Atari game e"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 215, "tree_size": 1024, "t0": 3.556, "t1": 2.35, "tft": 5.9452, "input_0": 2857, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 19.8, "mem_use": 46.7, "gen_rate": 6.6, "speed": 1.12, "text": " [MASK] time seems to slow down "}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 26, "tree_h": 24.0, "tree_w": 166, "tree_size": 1024, "t0": 5.0, "t1": 2.435, "tft": 10.0172, "input_0": 3288, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 32.0, "mem_use": 50.97, "gen_rate": 13.0, "speed": 1.75, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 14.7, "tree_w": 167, "tree_size": 1024, "t0": 4.3733, "t1": 2.3533, "tft": 6.5134, "input_0": 3546, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 23.7, "mem_use": 46.84, "gen_rate": 11.0, "speed": 1.64, "text": "Javascript is commonly used for "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.5, "tree_w": 168, "tree_size": 1024, "t0": 4.765, "t1": 2.3825, "tft": 8.9276, "input_0": 4029, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 26.8, "mem_use": 48.37, "gen_rate": 9.0, "speed": 1.26, "text": "Sure! One example of producing F"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.7, "tree_w": 119, "tree_size": 1024, "t0": 5.3333, "t1": 2.38, "tft": 8.3953, "input_0": 4628, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 28.7, "mem_use": 48.13, "gen_rate": 11.3, "speed": 1.47, "text": "In option 2, \"Use the Command Pr"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 21.3, "tree_w": 119, "tree_size": 1024, "t0": 5.4, "t1": 2.3533, "tft": 7.0482, "input_0": 4298, "input_1": 1025, "min_CLP": -7.33, "draft_iters": 30.0, "mem_use": 46.96, "gen_rate": 14.0, "speed": 1.81, "text": "To tackle this problem, I would "}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 17.4, "tree_w": 184, "tree_size": 1024, "t0": 4.21, "t1": 2.35, "tft": 7.0305, "input_0": 3200, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 25.0, "mem_use": 46.78, "gen_rate": 7.4, "speed": 1.13, "text": "The best method for dyeing with "}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 123, "tree_size": 1024, "t0": 5.52, "t1": 2.35, "tft": 6.992, "input_0": 3811, "input_1": 1025, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 25.0, "speed": 3.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 20.0, "tree_w": 128, "tree_size": 1024, "t0": 5.3867, "t1": 2.3733, "tft": 8.1741, "input_0": 4487, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 29.7, "mem_use": 47.76, "gen_rate": 12.0, "speed": 1.55, "text": "\"I'm glad you're looking to impr"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.7, "tree_w": 187, "tree_size": 1024, "t0": 4.1467, "t1": 2.36, "tft": 6.5623, "input_0": 3070, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 26.0, "mem_use": 47.09, "gen_rate": 12.0, "speed": 1.84, "text": "\"I'm ready to engage in a dialog"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 22.0, "tree_w": 133, "tree_size": 1024, "t0": 5.79, "t1": 2.3833, "tft": 9.3483, "input_0": 4575, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 32.0, "mem_use": 48.41, "gen_rate": 11.7, "speed": 1.43, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 13.3, "tree_w": 259, "tree_size": 1024, "t0": 3.4686, "t1": 2.3614, "tft": 6.8557, "input_0": 2748, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 20.0, "mem_use": 47.33, "gen_rate": 4.6, "speed": 0.78, "text": "I think that the answerer is ver"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 14.9, "tree_w": 216, "tree_size": 1024, "t0": 3.9071, "t1": 2.3557, "tft": 7.1653, "input_0": 2969, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 22.1, "mem_use": 47.17, "gen_rate": 5.3, "speed": 0.84, "text": "The ATF gun-walking scandal was "}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.0, "tree_w": 162, "tree_size": 1024, "t0": 4.905, "t1": 2.355, "tft": 7.2151, "input_0": 3865, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 28.2, "mem_use": 46.9, "gen_rate": 8.0, "speed": 1.1, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 59, "tree_size": 1024, "t0": 6.28, "t1": 2.38, "tft": 9.4139, "input_0": 4452, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 49.7, "gen_rate": 25.0, "speed": 2.89, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 16.8, "tree_w": 166, "tree_size": 1024, "t0": 4.3817, "t1": 2.3967, "tft": 9.6044, "input_0": 3401, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 25.2, "mem_use": 49.63, "gen_rate": 6.5, "speed": 0.96, "text": "\"Once upon a time, in the fair c"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 272, "tree_size": 1024, "t0": 2.88, "t1": 2.344, "tft": 6.7386, "input_0": 2624, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 15.4, "mem_use": 46.69, "gen_rate": 6.6, "speed": 1.26, "text": "The night was dark and the moon "}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 24.0, "tree_w": 91, "tree_size": 1024, "t0": 6.0733, "t1": 2.3667, "tft": 8.4039, "input_0": 4384, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 32.0, "mem_use": 47.86, "gen_rate": 14.3, "speed": 1.7, "text": "Absolutely! Here\\'s the new answ"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 23.3, "tree_w": 99, "tree_size": 1024, "t0": 5.6067, "t1": 2.38, "tft": 8.3909, "input_0": 4399, "input_1": 1025, "min_CLP": -7.24, "draft_iters": 31.0, "mem_use": 48.31, "gen_rate": 12.3, "speed": 1.54, "text": "\"I apologize if my previous resp"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 22.3, "tree_w": 89, "tree_size": 1024, "t0": 6.1533, "t1": 2.34, "tft": 6.0864, "input_0": 4776, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 32.0, "mem_use": 46.68, "gen_rate": 16.7, "speed": 1.96, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 19.2, "tree_w": 183, "tree_size": 1024, "t0": 4.3817, "t1": 2.3567, "tft": 6.2033, "input_0": 3394, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 26.8, "mem_use": 46.97, "gen_rate": 5.7, "speed": 0.84, "text": "What is your name? [\\\\INST]\\nI a"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.3, "tree_w": 143, "tree_size": 1024, "t0": 4.6833, "t1": 2.3867, "tft": 9.3299, "input_0": 3832, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 25.0, "mem_use": 48.56, "gen_rate": 11.3, "speed": 1.6, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.0, "tree_w": 100, "tree_size": 1024, "t0": 5.435, "t1": 2.35, "tft": 6.9336, "input_0": 4047, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 30.5, "mem_use": 46.91, "gen_rate": 16.0, "speed": 2.05, "text": "## Response:\\nIt is possible to "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 21.3, "tree_w": 105, "tree_size": 1024, "t0": 6.2067, "t1": 2.3767, "tft": 8.7327, "input_0": 4874, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 32.0, "mem_use": 48.25, "gen_rate": 14.0, "speed": 1.63, "text": "\"Sure, I'd be happy to help.\\n\\n"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 17.2, "tree_w": 182, "tree_size": 1024, "t0": 4.405, "t1": 2.34, "tft": 5.7864, "input_0": 3747, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 25.2, "mem_use": 46.71, "gen_rate": 9.0, "speed": 1.33, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 92, "tree_size": 1024, "t0": 5.715, "t1": 2.345, "tft": 6.7597, "input_0": 3726, "input_1": 1025, "min_CLP": -10.29, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 26.5, "speed": 3.29, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 193, "tree_size": 1024, "t0": 3.9675, "t1": 2.3625, "tft": 6.9536, "input_0": 3203, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 22.0, "mem_use": 47.36, "gen_rate": 9.8, "speed": 1.54, "text": "\"Okay, I'll write my own version"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 24.2, "tree_w": 111, "tree_size": 1024, "t0": 5.36, "t1": 2.3675, "tft": 6.4915, "input_0": 3860, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 47.6, "gen_rate": 9.0, "speed": 1.16, "text": "I apologize for the incorrect sy"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 19.3, "tree_w": 129, "tree_size": 1024, "t0": 5.35, "t1": 2.3467, "tft": 6.3041, "input_0": 4304, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 29.0, "mem_use": 46.7, "gen_rate": 16.7, "speed": 2.17, "text": "The AK-47, also known as the Kal"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 16.4, "tree_w": 198, "tree_size": 1024, "t0": 4.738, "t1": 2.352, "tft": 6.6888, "input_0": 3924, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 24.6, "mem_use": 47.04, "gen_rate": 8.6, "speed": 1.21, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 22.0, "tree_w": 100, "tree_size": 1024, "t0": 6.375, "t1": 2.385, "tft": 9.0455, "input_0": 5095, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 32.0, "mem_use": 48.43, "gen_rate": 20.5, "speed": 2.34, "text": "Statistical modeling is the proc"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.5, "tree_w": 107, "tree_size": 1024, "t0": 5.16, "t1": 2.355, "tft": 7.2054, "input_0": 3784, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 28.5, "mem_use": 47.02, "gen_rate": 17.5, "speed": 2.33, "text": "To start a successful gaming soc"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.7, "tree_w": 121, "tree_size": 1024, "t0": 5.31, "t1": 2.3667, "tft": 8.344, "input_0": 4263, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 29.3, "mem_use": 47.53, "gen_rate": 11.7, "speed": 1.52, "text": "\"While there's no harm in lettin"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.0, "tree_w": 262, "tree_size": 1024, "t0": 3.68, "t1": 2.356, "tft": 6.7035, "input_0": 2892, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 21.6, "mem_use": 47.17, "gen_rate": 6.8, "speed": 1.13, "text": "\"The best way to cheer up your f"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 19.0, "tree_w": 211, "tree_size": 1024, "t0": 4.12, "t1": 2.355, "tft": 7.1055, "input_0": 3287, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 26.0, "mem_use": 47.29, "gen_rate": 7.5, "speed": 1.16, "text": "Can you explain the concept of c"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 221, "tree_size": 1024, "t0": 3.96, "t1": 2.34, "tft": 6.7675, "input_0": 3496, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 22.0, "mem_use": 46.68, "gen_rate": 7.2, "speed": 1.14, "text": "\"I am currently reflecting on th"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.5, "tree_w": 185, "tree_size": 1024, "t0": 4.39, "t1": 2.3475, "tft": 6.8902, "input_0": 3652, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 24.2, "mem_use": 46.69, "gen_rate": 8.5, "speed": 1.26, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.7, "tree_w": 155, "tree_size": 1024, "t0": 4.7767, "t1": 2.35, "tft": 7.495, "input_0": 3884, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 29.0, "mem_use": 47.24, "gen_rate": 12.3, "speed": 1.73, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 20.5, "tree_w": 81, "tree_size": 1024, "t0": 6.83, "t1": 2.355, "tft": 6.829, "input_0": 6116, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 32.0, "mem_use": 46.99, "gen_rate": 16.0, "speed": 1.74, "text": "<!DOCTYPE html>\\n<html lang=\"en\""}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 96, "tree_size": 1024, "t0": 6.655, "t1": 2.355, "tft": 7.3644, "input_0": 5101, "input_1": 1025, "min_CLP": -12.03, "draft_iters": 32.0, "mem_use": 46.78, "gen_rate": 23.5, "speed": 2.61, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.2, "tree_w": 156, "tree_size": 1024, "t0": 4.905, "t1": 2.3425, "tft": 6.9492, "input_0": 3935, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 26.0, "mem_use": 46.74, "gen_rate": 8.2, "speed": 1.14, "text": "\"The reason you can't see stars "}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 15.3, "tree_w": 268, "tree_size": 1024, "t0": 3.5643, "t1": 2.36, "tft": 7.2912, "input_0": 2890, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 22.0, "mem_use": 47.3, "gen_rate": 5.4, "speed": 0.92, "text": "Yes, the Bliss image has become "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.0, "tree_w": 180, "tree_size": 1024, "t0": 3.97, "t1": 2.3925, "tft": 8.7926, "input_0": 3612, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 21.8, "mem_use": 50.35, "gen_rate": 9.5, "speed": 1.49, "text": "\"I'm sorry, but it's not appropr"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 15.8, "tree_w": 198, "tree_size": 1024, "t0": 3.9617, "t1": 2.3683, "tft": 8.9223, "input_0": 3222, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 23.5, "mem_use": 49.09, "gen_rate": 6.2, "speed": 0.97, "text": "\"Hello! It's possible that our c"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.4, "tree_w": 193, "tree_size": 1024, "t0": 4.478, "t1": 2.35, "tft": 7.3278, "input_0": 3747, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 24.6, "mem_use": 47.36, "gen_rate": 7.8, "speed": 1.14, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 15.5, "tree_w": 289, "tree_size": 1024, "t0": 3.955, "t1": 2.3425, "tft": 6.9446, "input_0": 3925, "input_1": 1025, "min_CLP": -8.89, "draft_iters": 22.2, "mem_use": 46.7, "gen_rate": 10.8, "speed": 1.71, "text": "No, there are no free SAST tools"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.2, "tree_w": 171, "tree_size": 1024, "t0": 4.3675, "t1": 2.345, "tft": 7.2904, "input_0": 3721, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 25.2, "mem_use": 46.68, "gen_rate": 8.0, "speed": 1.19, "text": "Yes, I can speak German. I have "}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 19.0, "tree_w": 165, "tree_size": 1024, "t0": 5.4567, "t1": 2.35, "tft": 6.9714, "input_0": 4555, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 29.0, "mem_use": 46.88, "gen_rate": 16.0, "speed": 2.05, "text": "Sure, here\\'s how I would execut"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 117, "tree_size": 1024, "t0": 5.1333, "t1": 2.3633, "tft": 7.6287, "input_0": 4401, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 28.7, "mem_use": 47.77, "gen_rate": 10.7, "speed": 1.42, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 14.2, "tree_w": 225, "tree_size": 1024, "t0": 4.3, "t1": 2.386, "tft": 9.5265, "input_0": 3790, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 22.6, "mem_use": 48.36, "gen_rate": 8.0, "speed": 1.2, "text": "\"Yes, AI image generators like S"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 275, "tree_size": 1024, "t0": 3.452, "t1": 2.346, "tft": 6.6787, "input_0": 2920, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 19.2, "mem_use": 46.74, "gen_rate": 6.6, "speed": 1.14, "text": "\"Sure, here are some haikus for "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 24.0, "tree_w": 184, "tree_size": 1024, "t0": 5.05, "t1": 2.35, "tft": 5.8669, "input_0": 3404, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 32.0, "mem_use": 47.11, "gen_rate": 19.0, "speed": 2.57, "text": "o\\n    /|\\\\\\n    / \\\\\\n    |  |\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 11.0, "tree_w": 328, "tree_size": 1024, "t0": 3.135, "t1": 2.345, "tft": 6.2945, "input_0": 2961, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 17.8, "mem_use": 46.7, "gen_rate": 5.0, "speed": 0.91, "text": "\"The polar bear's thick fur coat"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.8, "tree_w": 240, "tree_size": 1024, "t0": 4.024, "t1": 2.384, "tft": 7.157, "input_0": 3611, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 22.4, "mem_use": 47.05, "gen_rate": 6.8, "speed": 1.06, "text": "No, there is no universally agre"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 20.6, "tree_w": 210, "tree_size": 1024, "t0": 4.472, "t1": 2.35, "tft": 6.9076, "input_0": 3354, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 28.0, "mem_use": 46.97, "gen_rate": 7.0, "speed": 1.03, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 20.2, "tree_w": 190, "tree_size": 1024, "t0": 4.566, "t1": 2.368, "tft": 8.9831, "input_0": 3568, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 28.0, "mem_use": 49.01, "gen_rate": 7.4, "speed": 1.07, "text": "\"Of course! Let's get started.\\n"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 22.8, "tree_w": 214, "tree_size": 1024, "t0": 4.44, "t1": 2.345, "tft": 6.3168, "input_0": 2865, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 30.0, "mem_use": 46.86, "gen_rate": 9.5, "speed": 1.4, "text": "Here is a drawing of a man using"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.2, "tree_w": 176, "tree_size": 1024, "t0": 4.6125, "t1": 2.3825, "tft": 8.9113, "input_0": 4329, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 24.5, "mem_use": 49.72, "gen_rate": 8.0, "speed": 1.14, "text": "Once upon a time, there was a be"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 21.5, "tree_w": 138, "tree_size": 1024, "t0": 5.29, "t1": 2.3425, "tft": 7.0094, "input_0": 4105, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 30.2, "mem_use": 46.73, "gen_rate": 9.8, "speed": 1.28, "text": "\"Sure, here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 20.0, "tree_w": 99, "tree_size": 1024, "t0": 5.7267, "t1": 2.3433, "tft": 6.2062, "input_0": 4516, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 30.0, "mem_use": 46.69, "gen_rate": 15.3, "speed": 1.9, "text": "HTML and JavaScript are both pro"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 50, "tree_h": 23.3, "tree_w": 96, "tree_size": 1024, "t0": 5.8333, "t1": 2.3367, "tft": 5.6038, "input_0": 4585, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 16.7, "speed": 2.04, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.0, "tree_w": 156, "tree_size": 1024, "t0": 4.3775, "t1": 2.3475, "tft": 6.6825, "input_0": 3223, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 25.2, "mem_use": 47.08, "gen_rate": 8.2, "speed": 1.23, "text": "\"Bliss\" is protected by copyrigh"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.2, "tree_w": 189, "tree_size": 1024, "t0": 4.8475, "t1": 2.34, "tft": 5.5637, "input_0": 3649, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 26.8, "mem_use": 46.7, "gen_rate": 10.5, "speed": 1.46, "text": " [A]. the heat is only on low fo"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 22.3, "tree_w": 97, "tree_size": 1024, "t0": 6.11, "t1": 2.36, "tft": 8.8333, "input_0": 4891, "input_1": 1025, "min_CLP": -7.22, "draft_iters": 32.0, "mem_use": 47.76, "gen_rate": 13.7, "speed": 1.61, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.0, "tree_w": 190, "tree_size": 1024, "t0": 3.915, "t1": 2.3667, "tft": 7.4822, "input_0": 3381, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 21.2, "mem_use": 47.47, "gen_rate": 6.3, "speed": 1.01, "text": "\"If you're seeking a position in"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 14.0, "tree_w": 252, "tree_size": 1024, "t0": 3.7167, "t1": 2.3567, "tft": 6.8532, "input_0": 3369, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 21.2, "mem_use": 47.31, "gen_rate": 7.2, "speed": 1.18, "text": "\"Yes, if everyone just pirates g"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.0, "tree_w": 238, "tree_size": 1024, "t0": 3.5583, "t1": 2.3733, "tft": 6.7447, "input_0": 3181, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 18.8, "mem_use": 48.04, "gen_rate": 6.5, "speed": 1.1, "text": "That sounds like a very powerful"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.0, "tree_w": 199, "tree_size": 1024, "t0": 4.1425, "t1": 2.345, "tft": 6.5566, "input_0": 3144, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 23.8, "mem_use": 46.67, "gen_rate": 9.2, "speed": 1.43, "text": "\"Here is a simple ASCII art of a"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.8, "tree_w": 253, "tree_size": 1024, "t0": 4.042, "t1": 2.354, "tft": 6.8983, "input_0": 3822, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 21.4, "mem_use": 46.99, "gen_rate": 7.8, "speed": 1.22, "text": "Sure! Here are some of the names"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 20.0, "tree_w": 143, "tree_size": 1024, "t0": 5.305, "t1": 2.37, "tft": 8.1316, "input_0": 3795, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 27.5, "mem_use": 47.74, "gen_rate": 16.0, "speed": 2.08, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.4, "tree_w": 250, "tree_size": 1024, "t0": 3.36, "t1": 2.3471, "tft": 6.5883, "input_0": 2653, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 19.4, "mem_use": 46.79, "gen_rate": 4.7, "speed": 0.83, "text": "\"I'll give you a brief overview."}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 73, "tree_size": 1024, "t0": 6.635, "t1": 2.38, "tft": 9.4117, "input_0": 5864, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 32.0, "mem_use": 48.42, "gen_rate": 24.5, "speed": 2.72, "text": "\"Sure! Here's a modified version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 86, "tree_size": 1024, "t0": 6.0, "t1": 2.345, "tft": 6.8395, "input_0": 3981, "input_1": 1025, "min_CLP": -10.03, "draft_iters": 32.0, "mem_use": 46.74, "gen_rate": 26.0, "speed": 3.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.5, "tree_w": 272, "tree_size": 1024, "t0": 3.565, "t1": 2.3525, "tft": 6.981, "input_0": 3242, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 19.2, "mem_use": 47.13, "gen_rate": 8.0, "speed": 1.35, "text": "Sure! Here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 14.6, "tree_w": 206, "tree_size": 1024, "t0": 3.97, "t1": 2.382, "tft": 8.3817, "input_0": 3418, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 22.0, "mem_use": 48.43, "gen_rate": 8.6, "speed": 1.35, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.0, "tree_w": 134, "tree_size": 1024, "t0": 5.4475, "t1": 2.3775, "tft": 8.3153, "input_0": 4856, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 29.0, "mem_use": 48.86, "gen_rate": 9.8, "speed": 1.25, "text": "Paul Allen has a variety of plan"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.5, "tree_w": 288, "tree_size": 1024, "t0": 3.6, "t1": 2.375, "tft": 8.9216, "input_0": 3289, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 20.5, "mem_use": 48.3, "gen_rate": 6.3, "speed": 1.06, "text": "I apologize for the previous res"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 16.8, "tree_w": 181, "tree_size": 1024, "t0": 4.3583, "t1": 2.3517, "tft": 6.737, "input_0": 3658, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 24.7, "mem_use": 46.77, "gen_rate": 6.0, "speed": 0.89, "text": "\"[Rewrite]\\nThe responsibility o"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 13.0, "tree_w": 191, "tree_size": 1024, "t0": 3.935, "t1": 2.36, "tft": 7.5035, "input_0": 3355, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 21.3, "mem_use": 47.4, "gen_rate": 7.0, "speed": 1.11, "text": "\"I'm not a human, and I don't ha"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 22.3, "tree_w": 133, "tree_size": 1024, "t0": 5.2833, "t1": 2.35, "tft": 7.107, "input_0": 4094, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 29.7, "mem_use": 46.8, "gen_rate": 11.7, "speed": 1.53, "text": "Here are the main methods used b"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 23.2, "tree_w": 162, "tree_size": 1024, "t0": 4.8317, "t1": 2.3433, "tft": 6.22, "input_0": 3385, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 30.3, "mem_use": 46.69, "gen_rate": 5.3, "speed": 0.74, "text": "A chat between Dr. Elysium Noir "}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 22.3, "tree_w": 126, "tree_size": 1024, "t0": 5.4233, "t1": 2.3633, "tft": 7.5897, "input_0": 3858, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 31.3, "mem_use": 47.52, "gen_rate": 5.3, "speed": 0.68, "text": "[INST] You are welcome! Is there"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 191, "tree_size": 1024, "t0": 4.4425, "t1": 2.38, "tft": 8.4412, "input_0": 4113, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 23.8, "mem_use": 48.33, "gen_rate": 9.8, "speed": 1.43, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.2, "tree_w": 177, "tree_size": 1024, "t0": 4.395, "t1": 2.3775, "tft": 9.3188, "input_0": 3779, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 23.8, "mem_use": 49.23, "gen_rate": 8.8, "speed": 1.29, "text": "Ah, the \"multi-track drifting\" s"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.8, "tree_w": 187, "tree_size": 1024, "t0": 4.24, "t1": 2.37, "tft": 8.2522, "input_0": 3928, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 23.0, "mem_use": 47.84, "gen_rate": 9.5, "speed": 1.44, "text": "Yes, it is possible to have a co"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 14.4, "tree_w": 261, "tree_size": 1024, "t0": 3.5275, "t1": 2.365, "tft": 8.5199, "input_0": 2775, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 21.4, "mem_use": 47.68, "gen_rate": 4.9, "speed": 0.83, "text": "Sunshine, you are my favorite th"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.8, "tree_w": 145, "tree_size": 1024, "t0": 4.86, "t1": 2.365, "tft": 7.9312, "input_0": 3430, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 25.8, "mem_use": 47.44, "gen_rate": 8.8, "speed": 1.21, "text": "In Japanese, \"love\" is \"ai\" (\u611b),"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.0, "tree_w": 187, "tree_size": 1024, "t0": 4.6725, "t1": 2.35, "tft": 7.3673, "input_0": 3517, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 27.8, "mem_use": 46.98, "gen_rate": 9.8, "speed": 1.39, "text": "Some of the best universities fo"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 19.5, "tree_w": 111, "tree_size": 1024, "t0": 5.3625, "t1": 2.3425, "tft": 6.7274, "input_0": 4687, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 29.0, "mem_use": 46.67, "gen_rate": 8.5, "speed": 1.1, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.7, "tree_w": 94, "tree_size": 1024, "t0": 5.9833, "t1": 2.35, "tft": 6.9007, "input_0": 4501, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 31.7, "mem_use": 46.8, "gen_rate": 11.3, "speed": 1.36, "text": "```cpp\\n#include <regex>\\n#inclu"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.0, "tree_w": 182, "tree_size": 1024, "t0": 4.2275, "t1": 2.3675, "tft": 8.3105, "input_0": 3622, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 22.2, "mem_use": 47.93, "gen_rate": 9.5, "speed": 1.44, "text": "There are several ways to addres"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 20.8, "tree_w": 155, "tree_size": 1024, "t0": 4.794, "t1": 2.342, "tft": 5.8707, "input_0": 3889, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 29.0, "mem_use": 46.67, "gen_rate": 6.8, "speed": 0.95, "text": " Hello! I am an AI language mode"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.5, "tree_w": 255, "tree_size": 1024, "t0": 4.645, "t1": 2.3725, "tft": 10.1443, "input_0": 4465, "input_1": 1025, "min_CLP": -9.31, "draft_iters": 23.5, "mem_use": 49.33, "gen_rate": 9.5, "speed": 1.35, "text": "\"One example of where you might "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 20.2, "tree_w": 142, "tree_size": 1024, "t0": 5.7725, "t1": 2.3475, "tft": 7.193, "input_0": 4917, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 31.2, "mem_use": 46.96, "gen_rate": 10.2, "speed": 1.26, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 13.3, "tree_w": 297, "tree_size": 1024, "t0": 3.3043, "t1": 2.3443, "tft": 7.0524, "input_0": 2608, "input_1": 1025, "min_CLP": -8.78, "draft_iters": 20.0, "mem_use": 46.75, "gen_rate": 3.7, "speed": 0.66, "text": "the windows XP background image "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 20.8, "tree_w": 153, "tree_size": 1024, "t0": 5.195, "t1": 2.3775, "tft": 9.5173, "input_0": 4062, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 30.0, "mem_use": 48.92, "gen_rate": 8.5, "speed": 1.12, "text": "Certainly! Here are some open-so"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 21.0, "tree_w": 103, "tree_size": 1024, "t0": 5.335, "t1": 2.35, "tft": 4.0652, "input_0": 4142, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 28.5, "mem_use": 46.71, "gen_rate": 21.5, "speed": 2.8, "text": "To use software defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.4, "tree_w": 214, "tree_size": 1024, "t0": 3.838, "t1": 2.362, "tft": 7.8014, "input_0": 3124, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 22.8, "mem_use": 47.44, "gen_rate": 7.4, "speed": 1.19, "text": "No, there is no most ethical res"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 93, "tree_size": 1024, "t0": 6.26, "t1": 2.385, "tft": 8.5899, "input_0": 4527, "input_1": 1025, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 48.31, "gen_rate": 25.0, "speed": 2.89, "text": "1. m\u00eb (suffix), as in melm\u00eb \"lov"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 19.6, "tree_w": 162, "tree_size": 1024, "t0": 5.292, "t1": 2.344, "tft": 6.4182, "input_0": 4263, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 29.6, "mem_use": 46.99, "gen_rate": 8.2, "speed": 1.07, "text": "Alright, here is the story I hav"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 24.0, "tree_w": 100, "tree_size": 1024, "t0": 5.64, "t1": 2.4, "tft": 9.1813, "input_0": 4030, "input_1": 1025, "min_CLP": -7.19, "draft_iters": 32.0, "mem_use": 49.75, "gen_rate": 15.7, "speed": 1.95, "text": "I apologize for the incorrect in"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 19.8, "tree_w": 132, "tree_size": 1024, "t0": 5.24, "t1": 2.3425, "tft": 6.6428, "input_0": 3986, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 28.5, "mem_use": 46.71, "gen_rate": 12.2, "speed": 1.62, "text": "Certainly! To format an URL in r"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.0, "tree_w": 80, "tree_size": 1024, "t0": 6.295, "t1": 2.385, "tft": 9.7507, "input_0": 4757, "input_1": 1025, "min_CLP": -7.12, "draft_iters": 32.0, "mem_use": 48.71, "gen_rate": 16.5, "speed": 1.9, "text": "To set up a window for your game"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 23.0, "tree_w": 153, "tree_size": 1024, "t0": 5.44, "t1": 2.34, "tft": 6.7036, "input_0": 3782, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 32.0, "mem_use": 46.69, "gen_rate": 4.0, "speed": 0.51, "text": "None of the above."}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 338, "tree_size": 1024, "t0": 2.61, "t1": 2.356, "tft": 6.8813, "input_0": 2543, "input_1": 1025, "min_CLP": -8.7, "draft_iters": 13.8, "mem_use": 47.15, "gen_rate": 6.6, "speed": 1.33, "text": "AI assistants will not replace h"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.7, "tree_w": 172, "tree_size": 1024, "t0": 4.45, "t1": 2.4633, "tft": 11.9229, "input_0": 3580, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 24.7, "mem_use": 52.3, "gen_rate": 10.7, "speed": 1.54, "text": "\"Certainly, here's an adaptation"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 58, "tree_h": 15.1, "tree_w": 197, "tree_size": 1024, "t0": 3.9986, "t1": 2.3657, "tft": 7.6293, "input_0": 3572, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 22.9, "mem_use": 47.51, "gen_rate": 8.3, "speed": 1.3, "text": "0 An independent counsel is a la"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.2, "tree_w": 181, "tree_size": 1024, "t0": 4.24, "t1": 2.38, "tft": 9.3083, "input_0": 3853, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 22.0, "mem_use": 49.37, "gen_rate": 8.0, "speed": 1.21, "text": "As a business professional, it i"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.8, "tree_w": 194, "tree_size": 1024, "t0": 4.15, "t1": 2.36, "tft": 8.8888, "input_0": 3498, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 24.2, "mem_use": 47.74, "gen_rate": 8.8, "speed": 1.34, "text": "1. Economic downturn: A sudden r"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 17.3, "tree_w": 195, "tree_size": 1024, "t0": 4.215, "t1": 2.3483, "tft": 6.8574, "input_0": 3349, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 25.2, "mem_use": 47.02, "gen_rate": 5.3, "speed": 0.81, "text": "<|im_start|>user\\nAs a Spartan g"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 17.0, "tree_w": 164, "tree_size": 1024, "t0": 6.9, "t1": 2.39, "tft": 9.468, "input_0": 6156, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 49.49, "gen_rate": 17.0, "speed": 1.83, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 20.5, "tree_w": 130, "tree_size": 1024, "t0": 5.3425, "t1": 2.35, "tft": 7.3195, "input_0": 4155, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 30.0, "mem_use": 47.21, "gen_rate": 11.0, "speed": 1.43, "text": "\"[Answer]\\nTo determine the most"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 18.2, "tree_w": 126, "tree_size": 1024, "t0": 5.5075, "t1": 2.3825, "tft": 9.5644, "input_0": 4600, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 29.0, "mem_use": 49.16, "gen_rate": 9.2, "speed": 1.17, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 23.5, "tree_w": 90, "tree_size": 1024, "t0": 5.715, "t1": 2.34, "tft": 6.6855, "input_0": 4501, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 21.0, "speed": 2.61, "text": "Sure! Below is an implementation"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 9, "tree_h": 19.0, "tree_w": 151, "tree_size": 1024, "t0": 4.49, "t1": 2.3625, "tft": 7.5514, "input_0": 3322, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 26.5, "mem_use": 47.45, "gen_rate": 2.2, "speed": 0.33, "text": "[INST] What was the legal proces"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 16.2, "tree_w": 185, "tree_size": 1024, "t0": 4.185, "t1": 2.35, "tft": 7.0317, "input_0": 3410, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 24.0, "mem_use": 47.18, "gen_rate": 10.8, "speed": 1.65, "text": "The best way to alleviate the sy"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 184, "tree_size": 1024, "t0": 6.485, "t1": 2.35, "tft": 7.4341, "input_0": 5500, "input_1": 1025, "min_CLP": -11.59, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 21.5, "speed": 2.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 266, "tree_size": 1024, "t0": 3.9575, "t1": 2.3675, "tft": 7.4316, "input_0": 3936, "input_1": 1025, "min_CLP": -8.53, "draft_iters": 21.5, "mem_use": 47.66, "gen_rate": 8.5, "speed": 1.34, "text": "Overcoming the fear of looking d"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 19.2, "tree_w": 146, "tree_size": 1024, "t0": 5.2575, "t1": 2.3675, "tft": 9.3858, "input_0": 4239, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 29.2, "mem_use": 49.24, "gen_rate": 10.5, "speed": 1.38, "text": "Here is a list of the most impor"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.7, "tree_w": 130, "tree_size": 1024, "t0": 5.8167, "t1": 2.35, "tft": 7.2014, "input_0": 4502, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 30.7, "mem_use": 46.88, "gen_rate": 12.7, "speed": 1.55, "text": "The total travel time is the sum"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 25.0, "tree_w": 70, "tree_size": 1024, "t0": 5.945, "t1": 2.34, "tft": 6.7085, "input_0": 4198, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 46.8, "gen_rate": 23.0, "speed": 2.78, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.8, "tree_w": 184, "tree_size": 1024, "t0": 3.764, "t1": 2.346, "tft": 7.2153, "input_0": 3161, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 20.4, "mem_use": 46.69, "gen_rate": 8.4, "speed": 1.37, "text": "Yes, I am designed to be as capa"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.7, "tree_w": 143, "tree_size": 1024, "t0": 4.7167, "t1": 2.4267, "tft": 9.027, "input_0": 3895, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 25.7, "mem_use": 50.46, "gen_rate": 11.0, "speed": 1.54, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 31, "tree_h": 22.0, "tree_w": 164, "tree_size": 1024, "t0": 5.038, "t1": 2.342, "tft": 6.7096, "input_0": 4004, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 30.4, "mem_use": 46.81, "gen_rate": 6.2, "speed": 0.84, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 258, "tree_size": 1024, "t0": 3.374, "t1": 2.362, "tft": 7.4339, "input_0": 3011, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 19.4, "mem_use": 47.84, "gen_rate": 7.0, "speed": 1.22, "text": "You have been given a task which"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.0, "tree_w": 129, "tree_size": 1024, "t0": 5.6833, "t1": 2.3767, "tft": 8.8995, "input_0": 5183, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 29.3, "mem_use": 49.61, "gen_rate": 10.7, "speed": 1.32, "text": "\"The optimal toasting time for b"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 19.2, "tree_w": 176, "tree_size": 1024, "t0": 4.514, "t1": 2.354, "tft": 7.4505, "input_0": 3426, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 27.4, "mem_use": 46.94, "gen_rate": 6.8, "speed": 0.99, "text": "\"You are going in the right dire"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 22.2, "tree_w": 194, "tree_size": 1024, "t0": 4.802, "t1": 2.354, "tft": 7.4237, "input_0": 3543, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 30.0, "mem_use": 47.44, "gen_rate": 6.6, "speed": 0.92, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.5, "tree_w": 133, "tree_size": 1024, "t0": 6.365, "t1": 2.37, "tft": 10.1131, "input_0": 5653, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 32.0, "mem_use": 49.17, "gen_rate": 17.5, "speed": 2.0, "text": "\"If you're a high school student"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 20.0, "tree_w": 133, "tree_size": 1024, "t0": 5.29, "t1": 2.3625, "tft": 7.8021, "input_0": 4379, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 29.2, "mem_use": 47.57, "gen_rate": 8.8, "speed": 1.14, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 19.5, "tree_w": 129, "tree_size": 1024, "t0": 4.89, "t1": 2.4, "tft": 8.3915, "input_0": 3752, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 27.5, "mem_use": 49.9, "gen_rate": 9.0, "speed": 1.23, "text": "\"I'm glad to help. If you have a"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 153, "tree_size": 1024, "t0": 4.8233, "t1": 2.3733, "tft": 8.2651, "input_0": 4214, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 25.7, "mem_use": 48.23, "gen_rate": 10.7, "speed": 1.48, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 13.9, "tree_w": 211, "tree_size": 1024, "t0": 3.8078, "t1": 2.3478, "tft": 6.9835, "input_0": 2964, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 21.4, "mem_use": 47.25, "gen_rate": 3.7, "speed": 0.6, "text": "What is the answer to the questi"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 22.0, "tree_w": 131, "tree_size": 1024, "t0": 5.7, "t1": 2.365, "tft": 8.3119, "input_0": 4443, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 31.2, "mem_use": 49.05, "gen_rate": 11.0, "speed": 1.36, "text": "Learning to write Chinese charac"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 65, "tree_size": 1024, "t0": 5.995, "t1": 2.35, "tft": 6.4962, "input_0": 4013, "input_1": 1025, "min_CLP": -10.83, "draft_iters": 32.0, "mem_use": 46.88, "gen_rate": 26.0, "speed": 3.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 20.5, "tree_w": 197, "tree_size": 1024, "t0": 4.295, "t1": 2.3617, "tft": 8.4458, "input_0": 3190, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 27.3, "mem_use": 47.5, "gen_rate": 6.0, "speed": 0.9, "text": "Sure, how about: \"A wish from th"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 19.0, "tree_w": 198, "tree_size": 1024, "t0": 4.3875, "t1": 2.3475, "tft": 6.7101, "input_0": 3350, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 26.5, "mem_use": 46.97, "gen_rate": 13.0, "speed": 1.93, "text": "If you are broke, you are probab"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 103, "tree_size": 1024, "t0": 5.63, "t1": 2.345, "tft": 6.975, "input_0": 3671, "input_1": 1025, "min_CLP": -10.65, "draft_iters": 32.0, "mem_use": 46.99, "gen_rate": 26.5, "speed": 3.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 211, "tree_size": 1024, "t0": 3.74, "t1": 2.3575, "tft": 7.2001, "input_0": 3460, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 20.0, "mem_use": 47.37, "gen_rate": 8.8, "speed": 1.44, "text": "Google Authenticator is a time-b"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.3, "tree_w": 110, "tree_size": 1024, "t0": 5.62, "t1": 2.35, "tft": 6.9616, "input_0": 4933, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 29.3, "mem_use": 47.16, "gen_rate": 12.3, "speed": 1.55, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.3, "tree_w": 112, "tree_size": 1024, "t0": 5.71, "t1": 2.3467, "tft": 6.4465, "input_0": 4732, "input_1": 1025, "min_CLP": -7.21, "draft_iters": 31.0, "mem_use": 46.92, "gen_rate": 15.7, "speed": 1.94, "text": "\"Sure! Here's an example script "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 19.5, "tree_w": 125, "tree_size": 1024, "t0": 5.4975, "t1": 2.345, "tft": 7.335, "input_0": 4955, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 29.2, "mem_use": 46.77, "gen_rate": 8.5, "speed": 1.08, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 26.0, "tree_w": 162, "tree_size": 1024, "t0": 4.96, "t1": 2.33, "tft": 6.3591, "input_0": 3736, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 32.0, "mem_use": 46.8, "gen_rate": 21.5, "speed": 2.95, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 15.0, "tree_w": 206, "tree_size": 1024, "t0": 3.8425, "t1": 2.3425, "tft": 6.7608, "input_0": 3060, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 22.4, "mem_use": 46.72, "gen_rate": 4.8, "speed": 0.77, "text": "[INST] # The Greatest AI Discove"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 18.2, "tree_w": 139, "tree_size": 1024, "t0": 5.03, "t1": 2.366, "tft": 8.1974, "input_0": 4193, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 27.6, "mem_use": 47.9, "gen_rate": 9.4, "speed": 1.27, "text": "To copy the files from one serve"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 19.2, "tree_w": 107, "tree_size": 1024, "t0": 5.225, "t1": 2.34, "tft": 6.1605, "input_0": 4406, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 28.2, "mem_use": 46.68, "gen_rate": 10.2, "speed": 1.35, "text": "The `@` symbol in Python has sev"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 16.3, "tree_w": 248, "tree_size": 1024, "t0": 3.89, "t1": 2.34, "tft": 6.4448, "input_0": 2895, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 23.7, "mem_use": 46.69, "gen_rate": 6.3, "speed": 1.02, "text": "my chatbot is a very useful tool"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 260, "tree_size": 1024, "t0": 3.6325, "t1": 2.345, "tft": 5.6667, "input_0": 3324, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 20.5, "mem_use": 46.99, "gen_rate": 8.5, "speed": 1.42, "text": "As a master psychologist, I woul"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 16.4, "tree_w": 185, "tree_size": 1024, "t0": 4.19, "t1": 2.342, "tft": 5.6317, "input_0": 3299, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 24.4, "mem_use": 46.73, "gen_rate": 7.6, "speed": 1.16, "text": "\"As an AI language model, I'm no"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 24.0, "tree_w": 106, "tree_size": 1024, "t0": 5.89, "t1": 2.3575, "tft": 7.6597, "input_0": 4345, "input_1": 1025, "min_CLP": -11.93, "draft_iters": 32.0, "mem_use": 47.42, "gen_rate": 12.5, "speed": 1.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 14.8, "tree_w": 206, "tree_size": 1024, "t0": 3.8767, "t1": 2.3983, "tft": 9.1098, "input_0": 3321, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 22.2, "mem_use": 49.93, "gen_rate": 6.7, "speed": 1.06, "text": "The given text is a list of 25 r"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 20.0, "tree_w": 138, "tree_size": 1024, "t0": 5.055, "t1": 2.3525, "tft": 7.2543, "input_0": 4309, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 28.8, "mem_use": 47.23, "gen_rate": 8.5, "speed": 1.15, "text": "Yes, there are certain things th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.2, "tree_w": 219, "tree_size": 1024, "t0": 3.762, "t1": 2.376, "tft": 8.4725, "input_0": 2922, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 21.6, "mem_use": 48.35, "gen_rate": 6.4, "speed": 1.04, "text": "\"Hello there, Agent. I hope you "}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 22.5, "tree_w": 167, "tree_size": 1024, "t0": 4.8425, "t1": 2.355, "tft": 7.9551, "input_0": 3642, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 30.2, "mem_use": 47.22, "gen_rate": 9.0, "speed": 1.25, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 22.0, "tree_w": 90, "tree_size": 1024, "t0": 6.3167, "t1": 2.41, "tft": 9.4117, "input_0": 5414, "input_1": 1025, "min_CLP": -7.25, "draft_iters": 32.0, "mem_use": 50.11, "gen_rate": 17.7, "speed": 2.02, "text": "Certainly! Here are some code ex"}

{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 20.7, "tree_w": 108, "tree_size": 1024, "t0": 5.5567, "t1": 2.3267, "tft": 12.5352, "input_0": 4596, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 29.7, "mem_use": 48.46, "gen_rate": 12.3, "speed": 1.56, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 23.3, "tree_w": 172, "tree_size": 1024, "t0": 5.7333, "t1": 2.3067, "tft": 6.9593, "input_0": 4335, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 32.0, "mem_use": 46.73, "gen_rate": 14.0, "speed": 1.74, "text": "You should describe the task and"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 21.2, "tree_w": 135, "tree_size": 1024, "t0": 5.14, "t1": 2.2575, "tft": 6.8214, "input_0": 4249, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 30.0, "mem_use": 46.84, "gen_rate": 8.5, "speed": 1.15, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.2, "tree_w": 235, "tree_size": 1024, "t0": 3.68, "t1": 2.285, "tft": 8.8791, "input_0": 2927, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 20.5, "mem_use": 49.62, "gen_rate": 9.2, "speed": 1.55, "text": "Sure, here are some name ideas f"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 139, "tree_size": 1024, "t0": 4.6433, "t1": 2.28, "tft": 6.1071, "input_0": 3477, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 27.7, "mem_use": 46.79, "gen_rate": 13.0, "speed": 1.88, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 22.5, "tree_w": 122, "tree_size": 1024, "t0": 5.885, "t1": 2.3525, "tft": 11.3482, "input_0": 5134, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 32.0, "mem_use": 51.79, "gen_rate": 10.0, "speed": 1.21, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.2, "tree_w": 176, "tree_size": 1024, "t0": 4.45, "t1": 2.265, "tft": 5.8442, "input_0": 3252, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 25.8, "mem_use": 47.13, "gen_rate": 9.0, "speed": 1.34, "text": "You should install the parts in "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.7, "tree_w": 139, "tree_size": 1024, "t0": 5.1233, "t1": 2.3067, "tft": 7.1303, "input_0": 4273, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 26.7, "mem_use": 46.98, "gen_rate": 11.7, "speed": 1.57, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.5, "tree_w": 212, "tree_size": 1024, "t0": 3.67, "t1": 2.285, "tft": 6.7281, "input_0": 3249, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 19.8, "mem_use": 47.04, "gen_rate": 6.8, "speed": 1.15, "text": "I will be free to say what I wan"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.0, "tree_w": 137, "tree_size": 1024, "t0": 5.3067, "t1": 2.3367, "tft": 8.5934, "input_0": 4580, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 26.3, "mem_use": 48.4, "gen_rate": 11.7, "speed": 1.53, "text": "The main PC components that play"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 20.8, "tree_w": 150, "tree_size": 1024, "t0": 5.565, "t1": 2.2775, "tft": 7.0703, "input_0": 4679, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 30.2, "mem_use": 47.11, "gen_rate": 11.8, "speed": 1.5, "text": "The Keyhole series is a group of"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.8, "tree_w": 189, "tree_size": 1024, "t0": 4.21, "t1": 2.296, "tft": 6.6125, "input_0": 3556, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 24.2, "mem_use": 47.28, "gen_rate": 7.4, "speed": 1.14, "text": "\"Here's a simple and delicious r"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 16.8, "tree_w": 177, "tree_size": 1024, "t0": 4.512, "t1": 2.292, "tft": 7.7059, "input_0": 3655, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 25.4, "mem_use": 47.34, "gen_rate": 10.2, "speed": 1.5, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.3, "tree_w": 142, "tree_size": 1024, "t0": 4.7767, "t1": 2.3033, "tft": 8.8104, "input_0": 4084, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 26.0, "mem_use": 49.25, "gen_rate": 11.3, "speed": 1.6, "text": "I\\'m sorry, as an AI language mo"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 21.3, "tree_w": 143, "tree_size": 1024, "t0": 5.1667, "t1": 2.3233, "tft": 6.4684, "input_0": 4069, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 30.0, "mem_use": 46.69, "gen_rate": 11.0, "speed": 1.47, "text": "A:\\n\\nYes, stainless steel can b"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 25.3, "tree_w": 141, "tree_size": 1024, "t0": 5.22, "t1": 2.3133, "tft": 7.2441, "input_0": 3708, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 32.0, "mem_use": 46.83, "gen_rate": 10.7, "speed": 1.42, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 275, "tree_size": 1024, "t0": 3.125, "t1": 2.3267, "tft": 7.8642, "input_0": 2838, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 16.7, "mem_use": 48.27, "gen_rate": 5.7, "speed": 1.04, "text": "\"When data's the name of the gam"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 22.7, "tree_w": 126, "tree_size": 1024, "t0": 5.5567, "t1": 2.3233, "tft": 9.278, "input_0": 4584, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 32.0, "mem_use": 49.42, "gen_rate": 14.3, "speed": 1.82, "text": "\"Indeed, the power of magic is a"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 24.5, "tree_w": 154, "tree_size": 1024, "t0": 5.055, "t1": 2.295, "tft": 6.6151, "input_0": 3530, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 32.0, "mem_use": 46.67, "gen_rate": 3.0, "speed": 0.41, "text": "The current date is [insert the "}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.3, "tree_w": 160, "tree_size": 1024, "t0": 4.56, "t1": 2.35, "tft": 7.8787, "input_0": 3950, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 26.0, "mem_use": 48.15, "gen_rate": 10.7, "speed": 1.54, "text": "Yes, you\\'re absolutely right. R"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 31, "tree_h": 17.2, "tree_w": 234, "tree_size": 1024, "t0": 3.958, "t1": 2.284, "tft": 6.0691, "input_0": 2988, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 24.4, "mem_use": 47.03, "gen_rate": 6.2, "speed": 0.99, "text": "\"That's so not true. Technology "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 24.0, "tree_w": 72, "tree_size": 1024, "t0": 6.1, "t1": 2.31, "tft": 6.0318, "input_0": 4263, "input_1": 1025, "min_CLP": -7.29, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 21.0, "speed": 2.5, "text": "To estimate the variance of a va"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 15, "tree_h": 26.0, "tree_w": 87, "tree_size": 1024, "t0": 5.21, "t1": 2.33, "tft": 6.9021, "input_0": 3709, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 32.0, "mem_use": 47.09, "gen_rate": 15.0, "speed": 1.99, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 14.8, "tree_w": 172, "tree_size": 1024, "t0": 4.216, "t1": 2.31, "tft": 5.9387, "input_0": 3788, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 23.0, "mem_use": 46.67, "gen_rate": 8.0, "speed": 1.23, "text": "Metabolism is the set of process"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 18.0, "tree_w": 157, "tree_size": 1024, "t0": 4.65, "t1": 2.356, "tft": 8.3689, "input_0": 3774, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 25.8, "mem_use": 48.01, "gen_rate": 7.2, "speed": 1.03, "text": "\"Great! You're welcome. If you h"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 26.0, "tree_w": 230, "tree_size": 1024, "t0": 4.61, "t1": 2.34, "tft": 6.6683, "input_0": 3065, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 32.0, "mem_use": 46.86, "gen_rate": 0.0, "speed": 0.0, "text": "Answer: John"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 19.0, "tree_w": 142, "tree_size": 1024, "t0": 4.805, "t1": 2.28, "tft": 7.3122, "input_0": 3508, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 27.5, "mem_use": 47.25, "gen_rate": 18.0, "speed": 2.54, "text": "The oceans in the world are:\\n1."}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.7, "tree_w": 202, "tree_size": 1024, "t0": 3.8614, "t1": 2.3357, "tft": 7.2862, "input_0": 3206, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 20.9, "mem_use": 47.48, "gen_rate": 5.0, "speed": 0.81, "text": "To start, you should consider th"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 23.0, "tree_w": 122, "tree_size": 1024, "t0": 5.44, "t1": 2.3125, "tft": 7.4872, "input_0": 4050, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 31.5, "mem_use": 46.89, "gen_rate": 9.5, "speed": 1.23, "text": "\"# Basic PyGame project with ESC"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.3, "tree_w": 152, "tree_size": 1024, "t0": 4.34, "t1": 2.3533, "tft": 8.1353, "input_0": 3688, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 23.7, "mem_use": 47.99, "gen_rate": 11.3, "speed": 1.69, "text": "DLL stands for \"Dynamic Link Lib"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.5, "tree_w": 194, "tree_size": 1024, "t0": 4.3375, "t1": 2.315, "tft": 6.1562, "input_0": 4044, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 23.5, "mem_use": 47.14, "gen_rate": 8.5, "speed": 1.28, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 15.5, "tree_w": 202, "tree_size": 1024, "t0": 4.1133, "t1": 2.3233, "tft": 6.0719, "input_0": 3458, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 23.8, "mem_use": 46.68, "gen_rate": 5.3, "speed": 0.83, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 21.5, "tree_w": 143, "tree_size": 1024, "t0": 5.02, "t1": 2.295, "tft": 6.9716, "input_0": 4146, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 29.5, "mem_use": 46.79, "gen_rate": 8.2, "speed": 1.13, "text": "Here is a high-quality testing f"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 11.0, "tree_w": 286, "tree_size": 1024, "t0": 3.228, "t1": 2.338, "tft": 7.2593, "input_0": 2677, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 17.8, "mem_use": 46.94, "gen_rate": 5.6, "speed": 1.01, "text": "\"You can't deny that they are a "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.3, "tree_w": 264, "tree_size": 1024, "t0": 3.6283, "t1": 2.3517, "tft": 7.5029, "input_0": 2774, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 21.2, "mem_use": 47.46, "gen_rate": 5.7, "speed": 0.95, "text": "\"Well, I don't like the show bec"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 169, "tree_size": 1024, "t0": 4.8525, "t1": 2.355, "tft": 7.6663, "input_0": 4161, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 25.5, "mem_use": 48.31, "gen_rate": 8.5, "speed": 1.18, "text": "\"I'm here to help you with any q"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 21.3, "tree_w": 94, "tree_size": 1024, "t0": 6.2567, "t1": 2.34, "tft": 8.8885, "input_0": 4887, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 32.0, "mem_use": 48.83, "gen_rate": 15.7, "speed": 1.82, "text": "There are many languages that ar"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 16.8, "tree_w": 170, "tree_size": 1024, "t0": 4.618, "t1": 2.348, "tft": 7.6069, "input_0": 3851, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 25.6, "mem_use": 47.28, "gen_rate": 8.0, "speed": 1.15, "text": "\"Most of these AI tools offer fr"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 173, "tree_size": 1024, "t0": 3.9125, "t1": 2.3425, "tft": 7.2253, "input_0": 3494, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 20.8, "mem_use": 47.15, "gen_rate": 8.8, "speed": 1.4, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.7, "tree_w": 180, "tree_size": 1024, "t0": 4.205, "t1": 2.3633, "tft": 7.2471, "input_0": 3723, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 23.0, "mem_use": 47.36, "gen_rate": 5.7, "speed": 0.86, "text": "I understand that labeling promp"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.3, "tree_w": 124, "tree_size": 1024, "t0": 5.05, "t1": 2.3467, "tft": 7.9861, "input_0": 4060, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 28.0, "mem_use": 47.37, "gen_rate": 11.0, "speed": 1.49, "text": "The \"A\" in AK-47 stands for Avto"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 16.7, "tree_w": 179, "tree_size": 1024, "t0": 4.385, "t1": 2.31, "tft": 6.9446, "input_0": 3298, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 25.2, "mem_use": 46.8, "gen_rate": 5.7, "speed": 0.85, "text": "\"<|bot|> As an AI language model"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 17.0, "tree_w": 169, "tree_size": 1024, "t0": 4.524, "t1": 2.382, "tft": 8.5476, "input_0": 3336, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 25.2, "mem_use": 48.46, "gen_rate": 7.8, "speed": 1.13, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 15.9, "tree_w": 232, "tree_size": 1024, "t0": 4.1757, "t1": 2.3371, "tft": 7.4733, "input_0": 3205, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 24.0, "mem_use": 46.94, "gen_rate": 4.6, "speed": 0.7, "text": "\"Hippoplaisir's psychomotor ther"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 286, "tree_size": 1024, "t0": 4.18, "t1": 2.335, "tft": 7.132, "input_0": 3611, "input_1": 1025, "min_CLP": -8.75, "draft_iters": 22.0, "mem_use": 46.77, "gen_rate": 8.5, "speed": 1.3, "text": "Sure, here\\'s a list of ten name"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 21.2, "tree_w": 140, "tree_size": 1024, "t0": 5.06, "t1": 2.372, "tft": 6.9839, "input_0": 3748, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 29.4, "mem_use": 47.25, "gen_rate": 8.2, "speed": 1.1, "text": "I\\'m doing well, thank you for a"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 20.0, "tree_w": 135, "tree_size": 1024, "t0": 4.978, "t1": 2.348, "tft": 9.0191, "input_0": 4130, "input_1": 1025, "min_CLP": -7.34, "draft_iters": 28.6, "mem_use": 48.93, "gen_rate": 8.0, "speed": 1.09, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 213, "tree_size": 1024, "t0": 3.525, "t1": 2.3617, "tft": 7.4259, "input_0": 3100, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 19.2, "mem_use": 47.72, "gen_rate": 5.7, "speed": 0.96, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.3, "tree_w": 147, "tree_size": 1024, "t0": 5.3167, "t1": 2.3733, "tft": 8.4022, "input_0": 4370, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 29.0, "mem_use": 48.15, "gen_rate": 10.7, "speed": 1.39, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 91, "tree_size": 1024, "t0": 5.945, "t1": 2.34, "tft": 6.6091, "input_0": 4506, "input_1": 1025, "min_CLP": -9.11, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 25.5, "speed": 3.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.0, "tree_w": 273, "tree_size": 1024, "t0": 4.35, "t1": 2.4975, "tft": 10.3991, "input_0": 3621, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 24.2, "mem_use": 51.44, "gen_rate": 8.5, "speed": 1.24, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 19.2, "tree_w": 154, "tree_size": 1024, "t0": 4.874, "t1": 2.36, "tft": 8.268, "input_0": 3673, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 28.2, "mem_use": 47.86, "gen_rate": 7.4, "speed": 1.02, "text": "To transform other text words or"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 19.5, "tree_w": 128, "tree_size": 1024, "t0": 5.0475, "t1": 2.355, "tft": 8.2791, "input_0": 3952, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 28.0, "mem_use": 47.72, "gen_rate": 10.2, "speed": 1.38, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 20.5, "tree_w": 127, "tree_size": 1024, "t0": 5.655, "t1": 2.325, "tft": 6.0767, "input_0": 5056, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 30.5, "mem_use": 46.74, "gen_rate": 18.5, "speed": 2.32, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.8, "tree_w": 243, "tree_size": 1024, "t0": 3.835, "t1": 2.3425, "tft": 6.7319, "input_0": 3433, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 21.5, "mem_use": 47.08, "gen_rate": 8.2, "speed": 1.33, "text": "\"You got me, here's another one:"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 14.0, "tree_w": 197, "tree_size": 1024, "t0": 4.2867, "t1": 2.3267, "tft": 5.8616, "input_0": 3762, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 23.3, "mem_use": 46.7, "gen_rate": 8.7, "speed": 1.31, "text": "There are approximately 100 know"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 192, "tree_size": 1024, "t0": 4.35, "t1": 2.45, "tft": 10.5438, "input_0": 3061, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 28.0, "mem_use": 51.5, "gen_rate": 10.7, "speed": 1.57, "text": "I apologize for misunderstanding"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 19.2, "tree_w": 153, "tree_size": 1024, "t0": 5.4125, "t1": 2.3525, "tft": 6.7866, "input_0": 4328, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 30.0, "mem_use": 46.78, "gen_rate": 9.8, "speed": 1.26, "text": "The furthest back we can scienti"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.2, "tree_w": 151, "tree_size": 1024, "t0": 4.8075, "t1": 2.4875, "tft": 12.1484, "input_0": 3972, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.5, "mem_use": 53.73, "gen_rate": 8.8, "speed": 1.2, "text": "Thank you for explaining the Mal"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 15.2, "tree_w": 241, "tree_size": 1024, "t0": 3.7867, "t1": 2.375, "tft": 7.8142, "input_0": 2818, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 22.7, "mem_use": 47.96, "gen_rate": 6.7, "speed": 1.08, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 18.8, "tree_w": 168, "tree_size": 1024, "t0": 4.54, "t1": 2.35, "tft": 7.0553, "input_0": 3602, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 27.0, "mem_use": 46.81, "gen_rate": 6.6, "speed": 0.96, "text": "The human genome is a complex sy"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 19.0, "tree_w": 136, "tree_size": 1024, "t0": 5.18, "t1": 2.35, "tft": 6.543, "input_0": 4161, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 28.2, "mem_use": 46.68, "gen_rate": 8.8, "speed": 1.17, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.5, "tree_w": 237, "tree_size": 1024, "t0": 3.71, "t1": 2.36, "tft": 6.8036, "input_0": 3242, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 20.5, "mem_use": 46.92, "gen_rate": 5.5, "speed": 0.91, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.3, "tree_w": 118, "tree_size": 1024, "t0": 5.8067, "t1": 2.39, "tft": 6.595, "input_0": 4784, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 30.3, "mem_use": 47.22, "gen_rate": 12.3, "speed": 1.5, "text": "Sure, here are a few TV show rec"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 21.5, "tree_w": 106, "tree_size": 1024, "t0": 6.2375, "t1": 2.3975, "tft": 10.039, "input_0": 5250, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 32.0, "mem_use": 48.83, "gen_rate": 9.8, "speed": 1.13, "text": "\"Sure, here are some software an"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.5, "tree_w": 141, "tree_size": 1024, "t0": 4.8375, "t1": 2.3725, "tft": 8.2099, "input_0": 3836, "input_1": 1025, "min_CLP": -7.51, "draft_iters": 28.2, "mem_use": 47.94, "gen_rate": 8.0, "speed": 1.11, "text": "When F-centers are present in a "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 22.7, "tree_w": 219, "tree_size": 1024, "t0": 4.4814, "t1": 2.36, "tft": 6.9476, "input_0": 2953, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 29.3, "mem_use": 46.86, "gen_rate": 4.7, "speed": 0.69, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 24.0, "tree_w": 104, "tree_size": 1024, "t0": 5.5833, "t1": 2.3967, "tft": 9.3017, "input_0": 4166, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 32.0, "mem_use": 49.48, "gen_rate": 15.0, "speed": 1.88, "text": "\"Sure, here's the same code with"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 16.8, "tree_w": 193, "tree_size": 1024, "t0": 4.21, "t1": 2.3883, "tft": 8.4954, "input_0": 3381, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 24.8, "mem_use": 47.97, "gen_rate": 6.2, "speed": 0.93, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.8, "tree_w": 169, "tree_size": 1024, "t0": 4.4075, "t1": 2.39, "tft": 6.3756, "input_0": 3877, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 23.8, "mem_use": 46.7, "gen_rate": 8.2, "speed": 1.21, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 20.5, "tree_w": 170, "tree_size": 1024, "t0": 4.47, "t1": 2.34, "tft": 6.8398, "input_0": 3185, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 28.0, "mem_use": 46.78, "gen_rate": 6.5, "speed": 0.95, "text": "```markdown\\n```markdown\\n# This"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.3, "tree_w": 140, "tree_size": 1024, "t0": 5.2, "t1": 2.37, "tft": 8.0581, "input_0": 4074, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 28.0, "mem_use": 47.81, "gen_rate": 10.7, "speed": 1.41, "text": "\"Sure! Here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 22.7, "tree_w": 135, "tree_size": 1024, "t0": 5.18, "t1": 2.4167, "tft": 8.7436, "input_0": 4109, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 30.7, "mem_use": 48.76, "gen_rate": 13.0, "speed": 1.71, "text": "\"In JavaScript, you can achieve "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.2, "tree_w": 240, "tree_size": 1024, "t0": 3.876, "t1": 2.388, "tft": 7.2758, "input_0": 3274, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 20.8, "mem_use": 47.3, "gen_rate": 6.6, "speed": 1.05, "text": "\"Of course! Here's a simple trai"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.8, "tree_w": 134, "tree_size": 1024, "t0": 5.1575, "t1": 2.375, "tft": 8.2935, "input_0": 4052, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 27.2, "mem_use": 47.78, "gen_rate": 8.8, "speed": 1.16, "text": "My previous response assumed tha"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.5, "tree_w": 157, "tree_size": 1024, "t0": 5.095, "t1": 2.3625, "tft": 6.1963, "input_0": 4340, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 28.0, "mem_use": 46.69, "gen_rate": 10.5, "speed": 1.41, "text": "\"JavaScript is a versatile progr"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.6, "tree_w": 155, "tree_size": 1024, "t0": 4.472, "t1": 2.366, "tft": 6.8621, "input_0": 3505, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 25.0, "mem_use": 46.68, "gen_rate": 7.0, "speed": 1.02, "text": "The L-theanine chemical is found"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 21.2, "tree_w": 117, "tree_size": 1024, "t0": 5.5175, "t1": 2.385, "tft": 7.824, "input_0": 4180, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 30.5, "mem_use": 47.4, "gen_rate": 8.8, "speed": 1.11, "text": "\"Sure! Here's a list of the 5 wo"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 17.0, "tree_w": 221, "tree_size": 1024, "t0": 4.27, "t1": 2.364, "tft": 7.0274, "input_0": 3479, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 25.2, "mem_use": 46.81, "gen_rate": 8.2, "speed": 1.24, "text": "\"Hippoplaisir is a psychologists"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.8, "tree_w": 188, "tree_size": 1024, "t0": 3.8625, "t1": 2.385, "tft": 6.5614, "input_0": 3267, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 20.8, "mem_use": 46.81, "gen_rate": 8.5, "speed": 1.36, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 19.0, "tree_w": 156, "tree_size": 1024, "t0": 4.625, "t1": 2.36, "tft": 6.6388, "input_0": 3285, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 27.0, "mem_use": 46.78, "gen_rate": 16.0, "speed": 2.29, "text": "To memorize how to write Chinese"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 24.2, "tree_w": 181, "tree_size": 1024, "t0": 4.765, "t1": 2.47, "tft": 9.6394, "input_0": 3407, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 31.5, "mem_use": 51.55, "gen_rate": 8.2, "speed": 1.14, "text": "\"Here's a revised version of the"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 18.3, "tree_w": 148, "tree_size": 1024, "t0": 4.54, "t1": 2.3967, "tft": 9.85, "input_0": 3404, "input_1": 1025, "min_CLP": -7.31, "draft_iters": 26.7, "mem_use": 49.17, "gen_rate": 12.7, "speed": 1.83, "text": "\"Sure! Imagine you have a puzzle"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 19.3, "tree_w": 96, "tree_size": 1024, "t0": 6.5567, "t1": 2.3833, "tft": 8.3158, "input_0": 5795, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 32.0, "mem_use": 47.61, "gen_rate": 14.0, "speed": 1.57, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.7, "tree_w": 161, "tree_size": 1024, "t0": 4.71, "t1": 2.39, "tft": 7.4632, "input_0": 3834, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 26.7, "mem_use": 47.78, "gen_rate": 11.3, "speed": 1.6, "text": "Oh, the lessons we can learn fro"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.5, "tree_w": 141, "tree_size": 1024, "t0": 5.0, "t1": 2.405, "tft": 8.7566, "input_0": 3769, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 28.5, "mem_use": 48.84, "gen_rate": 9.2, "speed": 1.25, "text": "You can serve lemon wedges with "}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.0, "tree_w": 145, "tree_size": 1024, "t0": 4.865, "t1": 2.3525, "tft": 7.0382, "input_0": 4072, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 25.8, "mem_use": 46.87, "gen_rate": 10.0, "speed": 1.39, "text": "\"Sure, I'll be happy to play the"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 14.7, "tree_w": 217, "tree_size": 1024, "t0": 3.8814, "t1": 2.3729, "tft": 6.2406, "input_0": 2894, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 22.4, "mem_use": 46.83, "gen_rate": 5.7, "speed": 0.91, "text": "\"I'm sorry to hear that. Please "}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.5, "tree_w": 79, "tree_size": 1024, "t0": 6.23, "t1": 2.36, "tft": 6.6224, "input_0": 4676, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 16.5, "speed": 1.92, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.5, "tree_w": 135, "tree_size": 1024, "t0": 4.465, "t1": 2.405, "tft": 8.7078, "input_0": 3657, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 24.0, "mem_use": 48.29, "gen_rate": 8.5, "speed": 1.24, "text": "There are some examples of citie"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 16.6, "tree_w": 150, "tree_size": 1024, "t0": 5.052, "t1": 2.402, "tft": 7.9734, "input_0": 4445, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 26.8, "mem_use": 47.82, "gen_rate": 7.8, "speed": 1.05, "text": "In addition to the Dyson Sphere,"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 18.0, "tree_w": 187, "tree_size": 1024, "t0": 4.9667, "t1": 2.3733, "tft": 5.3225, "input_0": 3651, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 27.3, "mem_use": 46.67, "gen_rate": 11.3, "speed": 1.54, "text": "def get_max(numbers):\\n    max_n"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.8, "tree_w": 256, "tree_size": 1024, "t0": 4.05, "t1": 2.398, "tft": 7.6085, "input_0": 3384, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 22.4, "mem_use": 47.42, "gen_rate": 7.0, "speed": 1.09, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 18.4, "tree_w": 170, "tree_size": 1024, "t0": 4.946, "t1": 2.41, "tft": 9.2579, "input_0": 3754, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 26.8, "mem_use": 48.02, "gen_rate": 6.8, "speed": 0.92, "text": "Of course! Here is the full lyri"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 16.8, "tree_w": 150, "tree_size": 1024, "t0": 5.0675, "t1": 2.38, "tft": 7.0712, "input_0": 3957, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 26.5, "mem_use": 47.03, "gen_rate": 10.0, "speed": 1.34, "text": "1.    Prioritize and manage work"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 17.0, "tree_w": 140, "tree_size": 1024, "t0": 4.942, "t1": 2.386, "tft": 6.6487, "input_0": 4300, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 26.4, "mem_use": 46.7, "gen_rate": 8.8, "speed": 1.2, "text": "Sure! Self-attention mechanism i"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.5, "tree_w": 164, "tree_size": 1024, "t0": 4.565, "t1": 2.375, "tft": 7.0612, "input_0": 3760, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.5, "mem_use": 47.26, "gen_rate": 9.5, "speed": 1.37, "text": "TensorFlow and PyTorch are two o"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.8, "tree_w": 180, "tree_size": 1024, "t0": 4.775, "t1": 2.4, "tft": 8.0778, "input_0": 4018, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 26.0, "mem_use": 47.7, "gen_rate": 8.0, "speed": 1.11, "text": "[Mathematical questions]: {How c"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 22.0, "tree_w": 155, "tree_size": 1024, "t0": 4.64, "t1": 2.398, "tft": 7.4973, "input_0": 3287, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 29.0, "mem_use": 47.37, "gen_rate": 7.8, "speed": 1.11, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 98, "tree_size": 1024, "t0": 6.1, "t1": 2.425, "tft": 9.3584, "input_0": 4845, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 32.0, "mem_use": 49.49, "gen_rate": 24.0, "speed": 2.82, "text": "\"Yes, I apologize for the confus"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.7, "tree_w": 111, "tree_size": 1024, "t0": 5.6, "t1": 2.47, "tft": 9.6932, "input_0": 4667, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 29.7, "mem_use": 51.07, "gen_rate": 11.7, "speed": 1.45, "text": "\"For vegan cheese, some popular "}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 16.6, "tree_w": 148, "tree_size": 1024, "t0": 4.652, "t1": 2.41, "tft": 7.7049, "input_0": 3877, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 25.4, "mem_use": 48.08, "gen_rate": 7.0, "speed": 0.99, "text": "As an AI language model, I am no"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 95, "tree_size": 1024, "t0": 6.76, "t1": 2.405, "tft": 8.9669, "input_0": 5620, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 32.0, "mem_use": 48.47, "gen_rate": 20.0, "speed": 2.18, "text": "Sure, here are three of the most"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.7, "tree_w": 121, "tree_size": 1024, "t0": 5.6033, "t1": 2.3867, "tft": 6.11, "input_0": 4566, "input_1": 1025, "min_CLP": -7.18, "draft_iters": 29.7, "mem_use": 46.7, "gen_rate": 11.7, "speed": 1.46, "text": "Sure! In Python, both sets and l"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 14.4, "tree_w": 218, "tree_size": 1024, "t0": 3.748, "t1": 2.39, "tft": 8.359, "input_0": 3380, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 21.6, "mem_use": 48.04, "gen_rate": 8.4, "speed": 1.37, "text": "Based on the current date of 20t"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.5, "tree_w": 115, "tree_size": 1024, "t0": 6.455, "t1": 2.385, "tft": 6.8312, "input_0": 5830, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 32.0, "mem_use": 46.87, "gen_rate": 16.5, "speed": 1.87, "text": "\"Sure, I'd be happy to tell you "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 16.3, "tree_w": 168, "tree_size": 1024, "t0": 4.465, "t1": 2.3883, "tft": 7.3289, "input_0": 3623, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 24.7, "mem_use": 46.75, "gen_rate": 7.7, "speed": 1.12, "text": "To cook an egg using direct sunl"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 84, "tree_size": 1024, "t0": 6.24, "t1": 2.39, "tft": 7.0921, "input_0": 4724, "input_1": 1025, "min_CLP": -11.35, "draft_iters": 32.0, "mem_use": 46.74, "gen_rate": 24.5, "speed": 2.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.5, "tree_w": 336, "tree_size": 1024, "t0": 2.7513, "t1": 2.3825, "tft": 5.977, "input_0": 2334, "input_1": 1025, "min_CLP": -8.59, "draft_iters": 14.5, "mem_use": 46.69, "gen_rate": 4.4, "speed": 0.85, "text": "\"my name is alyssa, i'm 28 and i"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 18, "tree_h": 25.0, "tree_w": 78, "tree_size": 1024, "t0": 5.77, "t1": 2.39, "tft": 8.7908, "input_0": 4313, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 32.0, "mem_use": 47.96, "gen_rate": 18.0, "speed": 2.21, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 23.7, "tree_w": 96, "tree_size": 1024, "t0": 6.06, "t1": 2.3867, "tft": 8.146, "input_0": 4611, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 32.0, "mem_use": 47.08, "gen_rate": 10.7, "speed": 1.26, "text": "# Install the Tailwind CLI globa"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 16.0, "tree_w": 188, "tree_size": 1024, "t0": 4.174, "t1": 2.492, "tft": 10.6504, "input_0": 3386, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 23.8, "mem_use": 52.16, "gen_rate": 6.6, "speed": 0.99, "text": "There is some evidence that the "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.2, "tree_w": 164, "tree_size": 1024, "t0": 4.9375, "t1": 2.3825, "tft": 5.9397, "input_0": 4174, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 28.5, "mem_use": 47.21, "gen_rate": 9.2, "speed": 1.26, "text": "Large language models (LLMs) req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 149, "tree_size": 1024, "t0": 5.72, "t1": 2.4, "tft": 5.8006, "input_0": 4234, "input_1": 1025, "min_CLP": -9.01, "draft_iters": 32.0, "mem_use": 46.78, "gen_rate": 23.5, "speed": 2.89, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 22.3, "tree_w": 124, "tree_size": 1024, "t0": 5.3967, "t1": 2.3567, "tft": 7.1331, "input_0": 4207, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 30.7, "mem_use": 46.99, "gen_rate": 10.7, "speed": 1.38, "text": "Here\\'s a potential eulogy for y"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 21.4, "tree_w": 148, "tree_size": 1024, "t0": 4.994, "t1": 2.428, "tft": 7.9817, "input_0": 3743, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 29.6, "mem_use": 48.47, "gen_rate": 8.2, "speed": 1.1, "text": "\"No, that's all for now. Thanks "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.2, "tree_w": 143, "tree_size": 1024, "t0": 4.475, "t1": 2.4075, "tft": 7.7115, "input_0": 3727, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 24.0, "mem_use": 46.86, "gen_rate": 9.8, "speed": 1.42, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 15.0, "tree_w": 158, "tree_size": 1024, "t0": 4.382, "t1": 2.396, "tft": 6.6232, "input_0": 3715, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 23.4, "mem_use": 46.83, "gen_rate": 8.0, "speed": 1.18, "text": "Sure, here are a few options to "}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.0, "tree_w": 181, "tree_size": 1024, "t0": 4.3475, "t1": 2.3875, "tft": 5.7297, "input_0": 3782, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 24.5, "mem_use": 46.68, "gen_rate": 9.2, "speed": 1.37, "text": "The color of Mars is often descr"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.5, "tree_w": 275, "tree_size": 1024, "t0": 3.805, "t1": 2.4433, "tft": 8.6852, "input_0": 3162, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 22.5, "mem_use": 48.9, "gen_rate": 5.7, "speed": 0.91, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.5, "tree_w": 122, "tree_size": 1024, "t0": 5.705, "t1": 2.38, "tft": 7.2367, "input_0": 4773, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 30.0, "mem_use": 46.76, "gen_rate": 18.0, "speed": 2.23, "text": "Sure, I\\'d be happy to summarize"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.8, "tree_w": 144, "tree_size": 1024, "t0": 4.6375, "t1": 2.4, "tft": 7.2671, "input_0": 3850, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 26.8, "mem_use": 47.3, "gen_rate": 8.0, "speed": 1.14, "text": "No, the ATF does not restrict fi"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 23.7, "tree_w": 88, "tree_size": 1024, "t0": 5.85, "t1": 2.3833, "tft": 7.134, "input_0": 4363, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 32.0, "mem_use": 46.76, "gen_rate": 11.7, "speed": 1.42, "text": "Yes, there are formulas that can"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 19.2, "tree_w": 137, "tree_size": 1024, "t0": 5.3625, "t1": 2.41, "tft": 7.9276, "input_0": 4779, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 29.2, "mem_use": 47.19, "gen_rate": 10.8, "speed": 1.38, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 18.2, "tree_w": 161, "tree_size": 1024, "t0": 4.4625, "t1": 2.3875, "tft": 7.1999, "input_0": 3311, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 26.0, "mem_use": 46.87, "gen_rate": 6.5, "speed": 0.95, "text": "New South Wales, Sydney was the "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.3, "tree_w": 148, "tree_size": 1024, "t0": 5.0567, "t1": 2.4133, "tft": 7.6577, "input_0": 3667, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 28.7, "mem_use": 47.04, "gen_rate": 10.7, "speed": 1.43, "text": "\"[INST] Hello, how are you? [\\\\I"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.0, "tree_w": 126, "tree_size": 1024, "t0": 4.9233, "t1": 2.4333, "tft": 9.0814, "input_0": 4019, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 26.7, "mem_use": 49.27, "gen_rate": 13.3, "speed": 1.81, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.8, "tree_w": 260, "tree_size": 1024, "t0": 3.5417, "t1": 2.3917, "tft": 6.7545, "input_0": 2892, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 20.0, "mem_use": 46.87, "gen_rate": 5.5, "speed": 0.93, "text": "\"Yes, this is a real story. It h"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 112, "tree_size": 1024, "t0": 5.745, "t1": 2.445, "tft": 8.716, "input_0": 4019, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 32.0, "mem_use": 48.15, "gen_rate": 24.5, "speed": 2.99, "text": "Let vector A be a vector with it"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 17.7, "tree_w": 170, "tree_size": 1024, "t0": 4.555, "t1": 2.39, "tft": 5.9899, "input_0": 3586, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 26.2, "mem_use": 46.73, "gen_rate": 6.7, "speed": 0.96, "text": "## Issues with Symmetric Probabi"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.5, "tree_w": 209, "tree_size": 1024, "t0": 4.1967, "t1": 2.3983, "tft": 6.7185, "input_0": 3952, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 23.0, "mem_use": 46.78, "gen_rate": 6.2, "speed": 0.93, "text": "\"Ah, the Elder Scrolls universe."}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 18.5, "tree_w": 197, "tree_size": 1024, "t0": 4.2433, "t1": 2.38, "tft": 7.1653, "input_0": 3165, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 26.3, "mem_use": 46.73, "gen_rate": 6.3, "speed": 0.96, "text": "You should know that L\u2019Hopital\u2019s"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 15.0, "tree_w": 391, "tree_size": 1024, "t0": 2.99, "t1": 2.42, "tft": 7.5139, "input_0": 2750, "input_1": 1025, "min_CLP": -9.57, "draft_iters": 19.5, "mem_use": 47.3, "gen_rate": 4.5, "speed": 0.83, "text": "Sum of squares error is the same"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 17.5, "tree_w": 194, "tree_size": 1024, "t0": 4.0225, "t1": 2.4175, "tft": 8.2675, "input_0": 2823, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 24.5, "mem_use": 47.6, "gen_rate": 6.0, "speed": 0.93, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 13.2, "tree_w": 189, "tree_size": 1024, "t0": 3.884, "t1": 2.4, "tft": 7.4272, "input_0": 3397, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 21.2, "mem_use": 47.38, "gen_rate": 8.2, "speed": 1.3, "text": "The best place in the lower 48 s"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 247, "tree_size": 1024, "t0": 3.48, "t1": 2.3967, "tft": 7.1863, "input_0": 3111, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 18.3, "mem_use": 46.72, "gen_rate": 5.5, "speed": 0.94, "text": "Top 10 Funniest Ways to Die:\\n1."}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 17.7, "tree_w": 187, "tree_size": 1024, "t0": 4.47, "t1": 2.4167, "tft": 7.2503, "input_0": 3426, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 26.2, "mem_use": 47.28, "gen_rate": 7.3, "speed": 1.06, "text": "If the two dropped eggs landed o"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 21.0, "tree_w": 150, "tree_size": 1024, "t0": 4.9633, "t1": 2.3967, "tft": 7.1893, "input_0": 4101, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 29.3, "mem_use": 47.15, "gen_rate": 14.3, "speed": 1.95, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 22.0, "tree_w": 150, "tree_size": 1024, "t0": 5.4733, "t1": 2.4433, "tft": 10.0727, "input_0": 4118, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 31.7, "mem_use": 50.23, "gen_rate": 14.0, "speed": 1.77, "text": "Certainly, here are some tools f"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 22.0, "tree_w": 99, "tree_size": 1024, "t0": 5.89, "t1": 2.4267, "tft": 9.0862, "input_0": 4662, "input_1": 1025, "min_CLP": -7.27, "draft_iters": 31.3, "mem_use": 48.9, "gen_rate": 12.7, "speed": 1.52, "text": "Building your own PC has several"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 28, "tree_h": 22.3, "tree_w": 135, "tree_size": 1024, "t0": 5.4833, "t1": 2.3833, "tft": 6.1423, "input_0": 3988, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 31.7, "mem_use": 46.68, "gen_rate": 9.3, "speed": 1.19, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 19.5, "tree_w": 179, "tree_size": 1024, "t0": 5.6925, "t1": 2.3975, "tft": 6.9908, "input_0": 4498, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 30.2, "mem_use": 46.93, "gen_rate": 11.8, "speed": 1.45, "text": "Here is a list of 5 words where "}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 158, "tree_size": 1024, "t0": 4.7075, "t1": 2.545, "tft": 13.4451, "input_0": 4033, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 24.5, "mem_use": 53.75, "gen_rate": 8.8, "speed": 1.21, "text": "Certainly! The `_physics_process"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 143, "tree_size": 1024, "t0": 4.3833, "t1": 2.4067, "tft": 7.9631, "input_0": 3549, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 22.7, "mem_use": 47.11, "gen_rate": 10.7, "speed": 1.57, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 55, "tree_h": 17.5, "tree_w": 238, "tree_size": 1024, "t0": 4.77, "t1": 2.39, "tft": 6.7722, "input_0": 4087, "input_1": 1025, "min_CLP": -8.84, "draft_iters": 25.8, "mem_use": 46.81, "gen_rate": 13.8, "speed": 1.92, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.8, "tree_w": 200, "tree_size": 1024, "t0": 3.968, "t1": 2.412, "tft": 4.0355, "input_0": 3110, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 23.4, "mem_use": 46.78, "gen_rate": 7.2, "speed": 1.13, "text": "The Wyoming statutes address pub"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.3, "tree_w": 175, "tree_size": 1024, "t0": 4.4567, "t1": 2.4433, "tft": 8.5629, "input_0": 4091, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 23.7, "mem_use": 49.35, "gen_rate": 12.0, "speed": 1.74, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 109, "tree_size": 1024, "t0": 6.61, "t1": 2.41, "tft": 7.6997, "input_0": 5725, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 32.0, "mem_use": 47.23, "gen_rate": 20.5, "speed": 2.27, "text": "Certainly, here are some of the "}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 21.5, "tree_w": 195, "tree_size": 1024, "t0": 4.7438, "t1": 2.4162, "tft": 7.633, "input_0": 3480, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 29.4, "mem_use": 47.42, "gen_rate": 5.8, "speed": 0.8, "text": "I know that. I was trying to tes"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.7, "tree_w": 262, "tree_size": 1024, "t0": 3.7533, "t1": 2.4167, "tft": 6.3515, "input_0": 3361, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 21.0, "mem_use": 47.02, "gen_rate": 11.7, "speed": 1.89, "text": "To enhance the visual quality of"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.8, "tree_w": 210, "tree_size": 1024, "t0": 4.256, "t1": 2.418, "tft": 7.43, "input_0": 3068, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 24.6, "mem_use": 47.26, "gen_rate": 6.4, "speed": 0.96, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.8, "tree_w": 210, "tree_size": 1024, "t0": 3.75, "t1": 2.398, "tft": 5.9582, "input_0": 3148, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 21.2, "mem_use": 47.04, "gen_rate": 6.4, "speed": 1.04, "text": "\"In that case, it is important t"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.0, "tree_w": 179, "tree_size": 1024, "t0": 4.03, "t1": 2.4425, "tft": 9.2236, "input_0": 3343, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 23.5, "mem_use": 49.02, "gen_rate": 8.2, "speed": 1.27, "text": "\"It's always a good idea to prep"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 22.7, "tree_w": 141, "tree_size": 1024, "t0": 5.0833, "t1": 2.3867, "tft": 7.1742, "input_0": 3651, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 30.3, "mem_use": 46.81, "gen_rate": 15.3, "speed": 2.05, "text": "Canberra is located in southeast"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 20.3, "tree_w": 140, "tree_size": 1024, "t0": 5.4233, "t1": 2.4067, "tft": 6.6218, "input_0": 4341, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 29.7, "mem_use": 46.82, "gen_rate": 13.3, "speed": 1.7, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfC\u00f3"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 185, "tree_size": 1024, "t0": 4.232, "t1": 2.406, "tft": 7.1604, "input_0": 3732, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 22.0, "mem_use": 46.8, "gen_rate": 7.6, "speed": 1.14, "text": "F-centers, also known as Frenkel"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.3, "tree_w": 220, "tree_size": 1024, "t0": 5.0433, "t1": 2.52, "tft": 10.3254, "input_0": 4245, "input_1": 1025, "min_CLP": -8.34, "draft_iters": 26.7, "mem_use": 51.35, "gen_rate": 11.3, "speed": 1.5, "text": "You\\'re welcome! Let me know if "}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 22.0, "tree_w": 141, "tree_size": 1024, "t0": 5.46, "t1": 2.4325, "tft": 8.288, "input_0": 4596, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 31.2, "mem_use": 48.44, "gen_rate": 11.5, "speed": 1.46, "text": "Apologies for misunderstanding y"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 20.3, "tree_w": 112, "tree_size": 1024, "t0": 5.99, "t1": 2.3867, "tft": 7.4363, "input_0": 5175, "input_1": 1025, "min_CLP": -7.4, "draft_iters": 30.7, "mem_use": 47.23, "gen_rate": 15.0, "speed": 1.79, "text": "\"Certainly! Here's a list of pro"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.0, "tree_w": 169, "tree_size": 1024, "t0": 4.525, "t1": 2.4425, "tft": 9.2538, "input_0": 3982, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 25.5, "mem_use": 49.13, "gen_rate": 8.8, "speed": 1.26, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 20.2, "tree_w": 161, "tree_size": 1024, "t0": 4.994, "t1": 2.426, "tft": 9.3005, "input_0": 3932, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 28.6, "mem_use": 49.1, "gen_rate": 6.4, "speed": 0.86, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 18.0, "tree_w": 178, "tree_size": 1024, "t0": 4.4675, "t1": 2.455, "tft": 7.4176, "input_0": 3961, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 25.5, "mem_use": 48.45, "gen_rate": 9.0, "speed": 1.3, "text": "\"Im sorry, but I'm not allowed t"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.1, "tree_w": 227, "tree_size": 1024, "t0": 3.4829, "t1": 2.42, "tft": 6.9357, "input_0": 2935, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 18.7, "mem_use": 47.47, "gen_rate": 5.0, "speed": 0.85, "text": "If the lost property has a name "}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 24.5, "tree_w": 83, "tree_size": 1024, "t0": 6.005, "t1": 2.41, "tft": 6.5888, "input_0": 4500, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 47.06, "gen_rate": 21.0, "speed": 2.49, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. Vaswani, A., Shaz"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 92, "tree_size": 1024, "t0": 6.93, "t1": 2.425, "tft": 7.1503, "input_0": 5974, "input_1": 1025, "min_CLP": -10.87, "draft_iters": 32.0, "mem_use": 46.86, "gen_rate": 22.5, "speed": 2.41, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 16.0, "tree_w": 151, "tree_size": 1024, "t0": 4.4675, "t1": 2.44, "tft": 8.2197, "input_0": 3877, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 24.5, "mem_use": 48.15, "gen_rate": 11.5, "speed": 1.67, "text": "In general, laws against public "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 155, "tree_size": 1024, "t0": 4.3175, "t1": 2.4175, "tft": 7.0812, "input_0": 4064, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 23.5, "mem_use": 47.27, "gen_rate": 8.0, "speed": 1.19, "text": "There are many ways to deliver a"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 133, "tree_size": 1024, "t0": 4.73, "t1": 2.44, "tft": 8.2331, "input_0": 3964, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 25.2, "mem_use": 48.14, "gen_rate": 8.5, "speed": 1.19, "text": "The optimal thickness for mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 18.0, "tree_w": 202, "tree_size": 1024, "t0": 5.05, "t1": 2.4325, "tft": 8.04, "input_0": 4709, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 27.2, "mem_use": 47.52, "gen_rate": 11.0, "speed": 1.47, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.0, "tree_w": 251, "tree_size": 1024, "t0": 3.6683, "t1": 2.415, "tft": 6.8559, "input_0": 3153, "input_1": 1025, "min_CLP": -8.47, "draft_iters": 20.8, "mem_use": 46.79, "gen_rate": 6.7, "speed": 1.1, "text": "Here is a list of nicknames you "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.7, "tree_w": 134, "tree_size": 1024, "t0": 5.2933, "t1": 2.43, "tft": 7.9556, "input_0": 4524, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 30.0, "mem_use": 47.2, "gen_rate": 10.7, "speed": 1.38, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 80, "tree_size": 1024, "t0": 6.13, "t1": 2.445, "tft": 8.8397, "input_0": 4336, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 32.0, "mem_use": 47.95, "gen_rate": 24.5, "speed": 2.86, "text": "\"Felices:\\n1. \u00ab(I Can't Get No) "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 21.0, "tree_w": 74, "tree_size": 1024, "t0": 6.73, "t1": 2.4, "tft": 7.0635, "input_0": 5931, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 32.0, "mem_use": 46.89, "gen_rate": 17.5, "speed": 1.92, "text": "Sure! Below is a table showing t"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 80, "tree_size": 1024, "t0": 6.28, "t1": 2.43, "tft": 7.3189, "input_0": 4763, "input_1": 1025, "min_CLP": -10.26, "draft_iters": 32.0, "mem_use": 47.28, "gen_rate": 24.0, "speed": 2.76, "text": "````\\n```markdown\\n# This is a T"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.0, "tree_w": 266, "tree_size": 1024, "t0": 3.8, "t1": 2.4275, "tft": 7.9936, "input_0": 3115, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 23.0, "mem_use": 47.65, "gen_rate": 8.5, "speed": 1.37, "text": "I apologize for the previous res"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 17.0, "tree_w": 142, "tree_size": 1024, "t0": 4.96, "t1": 2.4433, "tft": 9.4349, "input_0": 4322, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 26.3, "mem_use": 48.41, "gen_rate": 11.7, "speed": 1.58, "text": "Sure, I can guide you through bu"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 16.5, "tree_w": 223, "tree_size": 1024, "t0": 4.66, "t1": 2.4225, "tft": 7.4567, "input_0": 3827, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 25.2, "mem_use": 46.9, "gen_rate": 11.5, "speed": 1.62, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 23.7, "tree_w": 160, "tree_size": 1024, "t0": 5.24, "t1": 2.4033, "tft": 7.2241, "input_0": 4067, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 32.0, "mem_use": 46.82, "gen_rate": 4.3, "speed": 0.57, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 14.5, "tree_w": 217, "tree_size": 1024, "t0": 4.025, "t1": 2.505, "tft": 10.2711, "input_0": 3296, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 22.5, "mem_use": 50.94, "gen_rate": 6.0, "speed": 0.92, "text": "Discovery:\\n- Find a market need"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 99, "tree_size": 1024, "t0": 6.215, "t1": 2.43, "tft": 5.8426, "input_0": 4563, "input_1": 1025, "min_CLP": -11.07, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 24.0, "speed": 2.78, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.7, "tree_w": 129, "tree_size": 1024, "t0": 5.23, "t1": 2.4933, "tft": 6.9478, "input_0": 4177, "input_1": 1025, "min_CLP": -7.38, "draft_iters": 27.7, "mem_use": 46.68, "gen_rate": 10.7, "speed": 1.38, "text": "\"To build a PC, you'll need to g"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.5, "tree_w": 147, "tree_size": 1024, "t0": 4.7875, "t1": 2.4975, "tft": 10.3846, "input_0": 3829, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 26.2, "mem_use": 50.93, "gen_rate": 8.8, "speed": 1.2, "text": "Hey there! How can I help you to"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 232, "tree_size": 1024, "t0": 3.692, "t1": 2.46, "tft": 8.3187, "input_0": 3036, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 20.8, "mem_use": 48.74, "gen_rate": 7.0, "speed": 1.14, "text": "\"\u2022 Focus on building a habit, no"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 154, "tree_size": 1024, "t0": 4.3833, "t1": 2.42, "tft": 7.8736, "input_0": 3457, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 24.3, "mem_use": 47.99, "gen_rate": 10.7, "speed": 1.57, "text": "You are correct that the player "}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 19.2, "tree_w": 158, "tree_size": 1024, "t0": 4.8175, "t1": 2.4125, "tft": 7.1598, "input_0": 3629, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 27.8, "mem_use": 46.86, "gen_rate": 8.5, "speed": 1.18, "text": "Yes, here is a summary of the im"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 20.3, "tree_w": 116, "tree_size": 1024, "t0": 5.2633, "t1": 2.4033, "tft": 7.0489, "input_0": 4213, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 29.3, "mem_use": 46.88, "gen_rate": 14.0, "speed": 1.83, "text": "In the context of the turn-based"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 96, "tree_size": 1024, "t0": 5.9667, "t1": 2.4367, "tft": 8.5557, "input_0": 5000, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 30.7, "mem_use": 47.7, "gen_rate": 13.0, "speed": 1.55, "text": "\"[API_REQUEST]: curl -X GET 'htt"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 22.7, "tree_w": 78, "tree_size": 1024, "t0": 6.4167, "t1": 2.4533, "tft": 8.342, "input_0": 4839, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 32.0, "mem_use": 48.24, "gen_rate": 15.7, "speed": 1.77, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 16.0, "tree_w": 123, "tree_size": 1024, "t0": 4.34, "t1": 2.44, "tft": 8.0408, "input_0": 3277, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 23.0, "mem_use": 47.66, "gen_rate": 8.0, "speed": 1.18, "text": "Hi! How can I assist you today?"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.2, "tree_w": 269, "tree_size": 1024, "t0": 3.1787, "t1": 2.4337, "tft": 8.2987, "input_0": 2873, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 17.2, "mem_use": 47.77, "gen_rate": 4.2, "speed": 0.76, "text": "\"With eyes as blue as the ocean'"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 17.2, "tree_w": 214, "tree_size": 1024, "t0": 3.9, "t1": 2.4233, "tft": 7.0412, "input_0": 2854, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 24.0, "mem_use": 47.16, "gen_rate": 6.5, "speed": 1.03, "text": "\"It is unclear how this would af"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 17.3, "tree_w": 131, "tree_size": 1024, "t0": 5.17, "t1": 2.42, "tft": 7.9441, "input_0": 4685, "input_1": 1025, "min_CLP": -7.39, "draft_iters": 27.0, "mem_use": 47.13, "gen_rate": 12.7, "speed": 1.67, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 21.8, "tree_w": 129, "tree_size": 1024, "t0": 5.386, "t1": 2.45, "tft": 8.0269, "input_0": 4042, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 31.2, "mem_use": 48.45, "gen_rate": 7.0, "speed": 0.89, "text": "\"You're welcome! If the command "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 137, "tree_size": 1024, "t0": 4.7725, "t1": 2.45, "tft": 8.2703, "input_0": 3850, "input_1": 1025, "min_CLP": -7.35, "draft_iters": 25.8, "mem_use": 48.37, "gen_rate": 8.5, "speed": 1.18, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 22.5, "tree_w": 133, "tree_size": 1024, "t0": 5.37, "t1": 2.4675, "tft": 9.3575, "input_0": 4264, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 31.0, "mem_use": 49.83, "gen_rate": 8.0, "speed": 1.02, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.7, "tree_w": 163, "tree_size": 1024, "t0": 5.68, "t1": 2.4167, "tft": 6.4858, "input_0": 4588, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 29.3, "mem_use": 46.68, "gen_rate": 11.3, "speed": 1.4, "text": "The current President of Germany"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.3, "tree_w": 269, "tree_size": 1024, "t0": 3.395, "t1": 2.43, "tft": 7.5733, "input_0": 2542, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 19.5, "mem_use": 47.6, "gen_rate": 5.7, "speed": 0.97, "text": "\"PostCSS is a tool for transform"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 22.0, "tree_w": 163, "tree_size": 1024, "t0": 5.63, "t1": 2.47, "tft": 9.4793, "input_0": 4715, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 32.0, "mem_use": 49.49, "gen_rate": 3.0, "speed": 0.37, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.2, "tree_w": 136, "tree_size": 1024, "t0": 5.1525, "t1": 2.43, "tft": 7.1808, "input_0": 4145, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 28.5, "mem_use": 47.19, "gen_rate": 9.2, "speed": 1.22, "text": "- Introduction to the topic of t"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 128, "tree_size": 1024, "t0": 4.8433, "t1": 2.4233, "tft": 8.5593, "input_0": 4236, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 26.0, "mem_use": 48.05, "gen_rate": 11.0, "speed": 1.51, "text": "I apologize for the confusion. A"}

{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 1024, "max_branch_width": 32, "gen_rate": 10.75, "gen_rate_micro": 9.36, "gen_speed": 1.45, "gen_speed_micro": 1.341, "t0": 4.8434, "t1": 2.3743, "input_0": 3905.8, "input_1": 1025.0, "tree_size": 1024.0, "tree_w": 166.5, "tree_h": 18.3, "prompt_len": 295.3, "min_CLP": -7.93, "mem_use": 53.75, "exp_time": null}

{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.0, "tree_w": 418, "tree_size": 2048, "t0": 7.135, "t1": 6.13, "tft": 16.1144, "input_0": 7005, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 6.8, "speed": 0.52, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 434, "tree_size": 2048, "t0": 7.32, "t1": 6.1167, "tft": 13.8173, "input_0": 7541, "input_1": 2049, "min_CLP": -9.25, "draft_iters": 32.0, "mem_use": 54.27, "gen_rate": 10.7, "speed": 0.79, "text": "I apologize for the mistake in m"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 311, "tree_size": 2048, "t0": 7.2325, "t1": 5.79, "tft": 17.2726, "input_0": 6890, "input_1": 2049, "min_CLP": -8.48, "draft_iters": 32.0, "mem_use": 55.17, "gen_rate": 9.0, "speed": 0.69, "text": "\"1. Minecraft: \\n- The recommend"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 307, "tree_size": 2048, "t0": 7.2625, "t1": 6.075, "tft": 11.9694, "input_0": 7312, "input_1": 2049, "min_CLP": -9.47, "draft_iters": 32.0, "mem_use": 52.91, "gen_rate": 9.5, "speed": 0.71, "text": "```python\\ndef average_rate_of_c"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.8, "tree_w": 420, "tree_size": 2048, "t0": 6.702, "t1": 6.076, "tft": 11.7161, "input_0": 6334, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 31.2, "mem_use": 52.75, "gen_rate": 8.2, "speed": 0.64, "text": "\"[INST] Hi, I'm glad you're inte"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 454, "tree_size": 2048, "t0": 7.1225, "t1": 5.7675, "tft": 14.4527, "input_0": 8217, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 55.28, "gen_rate": 9.0, "speed": 0.7, "text": "1. Introduction\\n- Define what t"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 374, "tree_size": 2048, "t0": 7.24, "t1": 5.6875, "tft": 16.1325, "input_0": 8535, "input_1": 2049, "min_CLP": -9.28, "draft_iters": 32.0, "mem_use": 55.87, "gen_rate": 8.2, "speed": 0.64, "text": "There are several other options "}

{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.5, "tree_w": 477, "tree_size": 2048, "t0": 7.295, "t1": 5.9525, "tft": 24.9578, "input_0": 7979, "input_1": 2049, "min_CLP": -10.33, "draft_iters": 32.0, "mem_use": 55.5, "gen_rate": 10.5, "speed": 0.79, "text": "Here is a list of the legal stat"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 368, "tree_size": 2048, "t0": 7.215, "t1": 6.11, "tft": 13.5627, "input_0": 7767, "input_1": 2049, "min_CLP": -9.05, "draft_iters": 32.0, "mem_use": 54.87, "gen_rate": 10.2, "speed": 0.77, "text": "One of the most beginner-friendl"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 535, "tree_size": 2048, "t0": 7.2033, "t1": 6.1267, "tft": 12.4432, "input_0": 7096, "input_1": 2049, "min_CLP": -11.46, "draft_iters": 32.0, "mem_use": 53.4, "gen_rate": 11.3, "speed": 0.85, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 427, "tree_size": 2048, "t0": 7.165, "t1": 5.7875, "tft": 14.4009, "input_0": 8589, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 55.22, "gen_rate": 10.0, "speed": 0.77, "text": "Here\\'s a slightly shorter versi"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 532, "tree_size": 2048, "t0": 7.2375, "t1": 6.125, "tft": 13.2391, "input_0": 8463, "input_1": 2049, "min_CLP": -10.22, "draft_iters": 32.0, "mem_use": 54.44, "gen_rate": 10.0, "speed": 0.75, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 9.0, "tree_w": 433, "tree_size": 2048, "t0": 7.09, "t1": 6.06, "tft": 12.1857, "input_0": 8448, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 5.0, "speed": 0.38, "text": "The capital of Australia is Canb"}

{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.8, "tree_w": 348, "tree_size": 2048, "t0": 7.23, "t1": 6.134, "tft": 17.0568, "input_0": 7217, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 53.06, "gen_rate": 7.0, "speed": 0.52, "text": "To ensure a smooth streaming exp"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 342, "tree_size": 2048, "t0": 7.1933, "t1": 6.0433, "tft": 12.2036, "input_0": 7056, "input_1": 2049, "min_CLP": -14.14, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 12.0, "speed": 0.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 371, "tree_size": 2048, "t0": 7.1667, "t1": 6.0367, "tft": 12.0937, "input_0": 7898, "input_1": 2049, "min_CLP": -11.51, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 10.7, "speed": 0.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 364, "tree_size": 2048, "t0": 7.19, "t1": 6.0267, "tft": 12.6751, "input_0": 7360, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 53.26, "gen_rate": 11.7, "speed": 0.88, "text": "D-theanine is a different form o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.0, "tree_w": 377, "tree_size": 2048, "t0": 7.18, "t1": 6.035, "tft": 12.2276, "input_0": 6940, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 10.2, "speed": 0.78, "text": "The Balfour Declaration was a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 9, "tree_h": 8.7, "tree_w": 794, "tree_size": 2048, "t0": 3.86, "t1": 6.0733, "tft": 12.5549, "input_0": 3648, "input_1": 2049, "min_CLP": -9.77, "draft_iters": 19.3, "mem_use": 53.59, "gen_rate": 3.0, "speed": 0.3, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 404, "tree_size": 2048, "t0": 6.98, "t1": 6.036, "tft": 11.5905, "input_0": 6372, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 7.2, "speed": 0.55, "text": "\"Hello! How can I assist you tod"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.2, "tree_w": 473, "tree_size": 2048, "t0": 7.2425, "t1": 5.6425, "tft": 18.9818, "input_0": 9012, "input_1": 2049, "min_CLP": -9.77, "draft_iters": 32.0, "mem_use": 55.08, "gen_rate": 9.2, "speed": 0.72, "text": "Yes, there are several options y"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.5, "tree_w": 387, "tree_size": 2048, "t0": 7.27, "t1": 6.0625, "tft": 12.0189, "input_0": 7808, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 10.0, "speed": 0.75, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 12.5, "tree_w": 348, "tree_size": 2048, "t0": 6.95, "t1": 6.11, "tft": 12.7905, "input_0": 5764, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 53.76, "gen_rate": 6.0, "speed": 0.46, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 457, "tree_size": 2048, "t0": 7.205, "t1": 6.085, "tft": 11.8923, "input_0": 8483, "input_1": 2049, "min_CLP": -13.38, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.2, "speed": 0.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.0, "tree_w": 417, "tree_size": 2048, "t0": 6.66, "t1": 6.096, "tft": 12.5978, "input_0": 5618, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 53.42, "gen_rate": 7.0, "speed": 0.55, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 10.2, "tree_w": 409, "tree_size": 2048, "t0": 7.155, "t1": 6.0925, "tft": 12.5334, "input_0": 7119, "input_1": 2049, "min_CLP": -9.35, "draft_iters": 32.0, "mem_use": 53.29, "gen_rate": 6.0, "speed": 0.45, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 530, "tree_size": 2048, "t0": 5.8183, "t1": 5.8317, "tft": 14.3519, "input_0": 5159, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 28.5, "mem_use": 55.23, "gen_rate": 5.7, "speed": 0.49, "text": "\"Magic, magic, the power that fl"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 316, "tree_size": 2048, "t0": 7.1633, "t1": 6.07, "tft": 11.81, "input_0": 7206, "input_1": 2049, "min_CLP": -12.15, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 12.0, "speed": 0.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 469, "tree_size": 2048, "t0": 7.1567, "t1": 6.1167, "tft": 12.6543, "input_0": 7322, "input_1": 2049, "min_CLP": -9.62, "draft_iters": 32.0, "mem_use": 53.48, "gen_rate": 10.7, "speed": 0.8, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 352, "tree_size": 2048, "t0": 7.0925, "t1": 6.11, "tft": 12.9094, "input_0": 6813, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 32.0, "mem_use": 53.89, "gen_rate": 9.8, "speed": 0.74, "text": "[API_REQUEST]: {curl -X POST -H "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.8, "tree_w": 387, "tree_size": 2048, "t0": 7.01, "t1": 6.0825, "tft": 12.3511, "input_0": 6690, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 32.0, "mem_use": 53.24, "gen_rate": 9.5, "speed": 0.73, "text": "As the Norse Goddess Freyja, I a"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.0, "tree_w": 341, "tree_size": 2048, "t0": 7.2225, "t1": 6.0675, "tft": 13.5135, "input_0": 7197, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 54.89, "gen_rate": 9.8, "speed": 0.73, "text": "\"Yes, there are a number of dair"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 400, "tree_size": 2048, "t0": 7.2425, "t1": 6.1575, "tft": 13.14, "input_0": 8379, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 54.93, "gen_rate": 9.2, "speed": 0.69, "text": "When selecting an internet servi"}

{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 17, "tree_h": 10.5, "tree_w": 448, "tree_size": 2048, "t0": 7.105, "t1": 6.205, "tft": 16.7979, "input_0": 5815, "input_1": 2049, "min_CLP": -8.41, "draft_iters": 31.0, "mem_use": 52.76, "gen_rate": 8.5, "speed": 0.64, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.0, "tree_w": 475, "tree_size": 2048, "t0": 6.88, "t1": 6.1075, "tft": 12.6886, "input_0": 6981, "input_1": 2049, "min_CLP": -11.31, "draft_iters": 32.0, "mem_use": 53.29, "gen_rate": 9.0, "speed": 0.69, "text": "The second verse of Rick Astley\\"}

{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 516, "tree_size": 2048, "t0": 7.29, "t1": 6.23, "tft": 16.8269, "input_0": 9024, "input_1": 2049, "min_CLP": -9.86, "draft_iters": 32.0, "mem_use": 53.69, "gen_rate": 10.0, "speed": 0.74, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 11.3, "tree_w": 738, "tree_size": 2048, "t0": 5.2243, "t1": 6.1771, "tft": 12.2878, "input_0": 4024, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 26.0, "mem_use": 52.99, "gen_rate": 4.3, "speed": 0.38, "text": "I was not summoned here for my p"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 475, "tree_size": 2048, "t0": 7.18, "t1": 6.0, "tft": 20.1416, "input_0": 7549, "input_1": 2049, "min_CLP": -10.01, "draft_iters": 32.0, "mem_use": 55.48, "gen_rate": 11.0, "speed": 0.83, "text": "\"The monologue you presented off"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 445, "tree_size": 2048, "t0": 7.0033, "t1": 5.7233, "tft": 14.4511, "input_0": 6467, "input_1": 2049, "min_CLP": -10.42, "draft_iters": 32.0, "mem_use": 55.92, "gen_rate": 11.0, "speed": 0.86, "text": "[INST] AI assistant. I am lookin"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 508, "tree_size": 2048, "t0": 7.135, "t1": 6.165, "tft": 12.7826, "input_0": 9513, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 54.25, "gen_rate": 10.2, "speed": 0.77, "text": "It\\'s difficult to determine whi"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.2, "tree_w": 462, "tree_size": 2048, "t0": 7.055, "t1": 6.14, "tft": 12.7043, "input_0": 7200, "input_1": 2049, "min_CLP": -11.92, "draft_iters": 32.0, "mem_use": 53.5, "gen_rate": 9.8, "speed": 0.74, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.3, "tree_w": 599, "tree_size": 2048, "t0": 5.8317, "t1": 6.11, "tft": 12.5401, "input_0": 5248, "input_1": 2049, "min_CLP": -9.87, "draft_iters": 27.8, "mem_use": 53.25, "gen_rate": 6.2, "speed": 0.52, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.0, "tree_w": 422, "tree_size": 2048, "t0": 7.2175, "t1": 6.085, "tft": 12.1094, "input_0": 8059, "input_1": 2049, "min_CLP": -10.09, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 9.8, "speed": 0.73, "text": "To check your system drive for e"}

{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.8, "tree_w": 568, "tree_size": 2048, "t0": 5.87, "t1": 6.316, "tft": 15.1605, "input_0": 4818, "input_1": 2049, "min_CLP": -8.99, "draft_iters": 27.4, "mem_use": 54.47, "gen_rate": 7.0, "speed": 0.57, "text": "I know, I know. You\\'re probably"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 11.7, "tree_w": 386, "tree_size": 2048, "t0": 7.1267, "t1": 6.1967, "tft": 11.7153, "input_0": 6819, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 53.52, "gen_rate": 4.7, "speed": 0.35, "text": "\"I'm glad I was able to help. Pl"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 9.0, "tree_w": 428, "tree_size": 2048, "t0": 7.29, "t1": 6.175, "tft": 12.5291, "input_0": 7888, "input_1": 2049, "min_CLP": -9.33, "draft_iters": 32.0, "mem_use": 53.04, "gen_rate": 8.0, "speed": 0.59, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u91cd\u8981\u8bdd\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 391, "tree_size": 2048, "t0": 7.1725, "t1": 6.075, "tft": 14.8222, "input_0": 8257, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 32.0, "mem_use": 54.93, "gen_rate": 9.8, "speed": 0.74, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 525, "tree_size": 2048, "t0": 7.2033, "t1": 6.1533, "tft": 12.8187, "input_0": 8566, "input_1": 2049, "min_CLP": -11.37, "draft_iters": 32.0, "mem_use": 54.13, "gen_rate": 10.7, "speed": 0.8, "text": "Yes, here are some more historic"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 364, "tree_size": 2048, "t0": 7.215, "t1": 6.1775, "tft": 13.3068, "input_0": 8209, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 54.48, "gen_rate": 10.5, "speed": 0.78, "text": "Yes, technology can be used for "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 467, "tree_size": 2048, "t0": 6.686, "t1": 6.1, "tft": 11.8519, "input_0": 6505, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 30.6, "mem_use": 52.93, "gen_rate": 6.6, "speed": 0.52, "text": "In real life, the answer to this"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.0, "tree_w": 491, "tree_size": 2048, "t0": 6.492, "t1": 5.856, "tft": 14.9222, "input_0": 5901, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 30.8, "mem_use": 55.32, "gen_rate": 6.6, "speed": 0.53, "text": "Here is a pitch deck for FullVie"}

{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 401, "tree_size": 2048, "t0": 7.25, "t1": 6.2525, "tft": 17.8215, "input_0": 8552, "input_1": 2049, "min_CLP": -10.15, "draft_iters": 32.0, "mem_use": 54.39, "gen_rate": 10.5, "speed": 0.78, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.5, "tree_w": 356, "tree_size": 2048, "t0": 7.1625, "t1": 6.1675, "tft": 11.5819, "input_0": 6629, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 9.5, "speed": 0.71, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 387, "tree_size": 2048, "t0": 7.1067, "t1": 5.77, "tft": 16.9159, "input_0": 7647, "input_1": 2049, "min_CLP": -10.42, "draft_iters": 32.0, "mem_use": 55.16, "gen_rate": 10.7, "speed": 0.83, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 659, "tree_size": 2048, "t0": 5.7825, "t1": 5.6925, "tft": 9.5659, "input_0": 6464, "input_1": 2049, "min_CLP": -9.01, "draft_iters": 26.2, "mem_use": 55.93, "gen_rate": 8.0, "speed": 0.7, "text": "[The general raises his sword in"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.8, "tree_w": 511, "tree_size": 2048, "t0": 6.0433, "t1": 6.09, "tft": 11.4466, "input_0": 5559, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 28.3, "mem_use": 53.71, "gen_rate": 5.3, "speed": 0.44, "text": "I see. Here\\'s another one: \"My "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 390, "tree_size": 2048, "t0": 7.1125, "t1": 6.0825, "tft": 12.3188, "input_0": 7286, "input_1": 2049, "min_CLP": -8.42, "draft_iters": 32.0, "mem_use": 53.42, "gen_rate": 9.2, "speed": 0.7, "text": "The proof-of-stake concept is a "}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 7.8, "tree_w": 492, "tree_size": 2048, "t0": 6.0425, "t1": 6.0825, "tft": 12.1893, "input_0": 5863, "input_1": 2049, "min_CLP": -11.05, "draft_iters": 27.0, "mem_use": 53.55, "gen_rate": 8.8, "speed": 0.72, "text": "I am sorry to say that, but stop"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.0, "tree_w": 433, "tree_size": 2048, "t0": 7.17, "t1": 5.9525, "tft": 14.436, "input_0": 8423, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 55.6, "gen_rate": 8.8, "speed": 0.67, "text": "A void pointer is a pointer that"}

{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 374, "tree_size": 2048, "t0": 7.2467, "t1": 6.0067, "tft": 18.9988, "input_0": 7991, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 55.32, "gen_rate": 10.7, "speed": 0.8, "text": "\"Implementing two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.1, "tree_w": 473, "tree_size": 2048, "t0": 6.74, "t1": 6.2129, "tft": 12.2915, "input_0": 7753, "input_1": 2049, "min_CLP": -9.49, "draft_iters": 30.0, "mem_use": 53.16, "gen_rate": 5.7, "speed": 0.44, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 328, "tree_size": 2048, "t0": 7.2133, "t1": 6.1833, "tft": 12.4266, "input_0": 7370, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 11.0, "speed": 0.82, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 522, "tree_size": 2048, "t0": 7.1075, "t1": 5.765, "tft": 14.632, "input_0": 7735, "input_1": 2049, "min_CLP": -12.14, "draft_iters": 32.0, "mem_use": 55.55, "gen_rate": 10.2, "speed": 0.8, "text": "\"Certainly, here's the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 473, "tree_size": 2048, "t0": 7.16, "t1": 6.0825, "tft": 11.0824, "input_0": 8047, "input_1": 2049, "min_CLP": -15.81, "draft_iters": 32.0, "mem_use": 52.71, "gen_rate": 10.0, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.8, "tree_w": 378, "tree_size": 2048, "t0": 7.108, "t1": 5.916, "tft": 13.9342, "input_0": 6931, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 55.04, "gen_rate": 7.0, "speed": 0.54, "text": "\"Sure, I'd be happy to add some "}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 437, "tree_size": 2048, "t0": 7.1475, "t1": 6.0175, "tft": 13.5239, "input_0": 7801, "input_1": 2049, "min_CLP": -11.6, "draft_iters": 32.0, "mem_use": 54.88, "gen_rate": 10.0, "speed": 0.76, "text": "Certainly! While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 330, "tree_size": 2048, "t0": 7.158, "t1": 6.094, "tft": 11.8358, "input_0": 6810, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 6.6, "speed": 0.5, "text": "The origins of pornography can b"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.0, "tree_w": 391, "tree_size": 2048, "t0": 7.1667, "t1": 6.12, "tft": 12.0019, "input_0": 7457, "input_1": 2049, "min_CLP": -12.09, "draft_iters": 32.0, "mem_use": 53.04, "gen_rate": 11.3, "speed": 0.85, "text": "\"You can visit at The World Cloc"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 491, "tree_size": 2048, "t0": 6.46, "t1": 6.13, "tft": 12.3514, "input_0": 5590, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 30.0, "mem_use": 53.12, "gen_rate": 8.5, "speed": 0.68, "text": "The five second rule is a myth. "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 10.5, "tree_w": 439, "tree_size": 2048, "t0": 7.14, "t1": 6.13, "tft": 12.4371, "input_0": 7180, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 3.0, "speed": 0.23, "text": "The answer is 5 eggs."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 515, "tree_size": 2048, "t0": 7.2375, "t1": 6.15, "tft": 12.7962, "input_0": 8916, "input_1": 2049, "min_CLP": -9.54, "draft_iters": 32.0, "mem_use": 53.58, "gen_rate": 10.0, "speed": 0.75, "text": "Sure! The Sieve of Eratosthenes "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.7, "tree_w": 357, "tree_size": 2048, "t0": 7.1317, "t1": 6.1133, "tft": 12.2125, "input_0": 7138, "input_1": 2049, "min_CLP": -9.43, "draft_iters": 32.0, "mem_use": 53.16, "gen_rate": 6.7, "speed": 0.5, "text": "\"You're welcome! If you suspect "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 429, "tree_size": 2048, "t0": 6.81, "t1": 6.108, "tft": 12.2905, "input_0": 6789, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 31.0, "mem_use": 52.87, "gen_rate": 7.0, "speed": 0.54, "text": "Hey Medium readers! Exciting new"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 365, "tree_size": 2048, "t0": 7.1025, "t1": 6.1625, "tft": 12.6351, "input_0": 7089, "input_1": 2049, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 53.48, "gen_rate": 8.2, "speed": 0.62, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 458, "tree_size": 2048, "t0": 7.1675, "t1": 6.19, "tft": 13.2866, "input_0": 8768, "input_1": 2049, "min_CLP": -9.33, "draft_iters": 32.0, "mem_use": 54.51, "gen_rate": 10.0, "speed": 0.75, "text": "Certainly! AI assistants can als"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 361, "tree_size": 2048, "t0": 7.04, "t1": 5.84, "tft": 14.5473, "input_0": 6683, "input_1": 2049, "min_CLP": -9.92, "draft_iters": 32.0, "mem_use": 55.55, "gen_rate": 9.2, "speed": 0.72, "text": "[SYS]\\nYou are a helpful, respec"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 381, "tree_size": 2048, "t0": 7.1375, "t1": 6.165, "tft": 12.7196, "input_0": 8442, "input_1": 2049, "min_CLP": -8.46, "draft_iters": 32.0, "mem_use": 54.03, "gen_rate": 9.5, "speed": 0.71, "text": "The scp command is a common Unix"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 418, "tree_size": 2048, "t0": 7.12, "t1": 6.1975, "tft": 13.816, "input_0": 7976, "input_1": 2049, "min_CLP": -11.04, "draft_iters": 32.0, "mem_use": 54.69, "gen_rate": 10.2, "speed": 0.77, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.7, "tree_w": 388, "tree_size": 2048, "t0": 7.1167, "t1": 6.2467, "tft": 12.1913, "input_0": 6770, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 11.3, "speed": 0.85, "text": "Yes, it would be legal to keep t"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 456, "tree_size": 2048, "t0": 7.14, "t1": 6.1367, "tft": 12.2823, "input_0": 7528, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 53.07, "gen_rate": 11.0, "speed": 0.83, "text": "Sydney is the largest city in Au"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 9.5, "tree_w": 336, "tree_size": 2048, "t0": 7.045, "t1": 6.145, "tft": 12.144, "input_0": 7326, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 53.37, "gen_rate": 6.5, "speed": 0.49, "text": "Is there anything else you would"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 9.6, "tree_w": 630, "tree_size": 2048, "t0": 5.39, "t1": 6.1343, "tft": 11.867, "input_0": 4745, "input_1": 2049, "min_CLP": -9.21, "draft_iters": 25.1, "mem_use": 53.04, "gen_rate": 4.4, "speed": 0.38, "text": "You know, we have a saying in Si"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 395, "tree_size": 2048, "t0": 7.1575, "t1": 6.145, "tft": 11.7137, "input_0": 7947, "input_1": 2049, "min_CLP": -13.81, "draft_iters": 32.0, "mem_use": 52.82, "gen_rate": 10.2, "speed": 0.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 355, "tree_size": 2048, "t0": 7.1675, "t1": 6.135, "tft": 11.8617, "input_0": 7134, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 8.5, "speed": 0.64, "text": "The time it would take to walk a"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 474, "tree_size": 2048, "t0": 7.1575, "t1": 6.19, "tft": 13.2306, "input_0": 9116, "input_1": 2049, "min_CLP": -9.35, "draft_iters": 32.0, "mem_use": 54.52, "gen_rate": 10.0, "speed": 0.75, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 425, "tree_size": 2048, "t0": 7.135, "t1": 6.1375, "tft": 12.1147, "input_0": 8398, "input_1": 2049, "min_CLP": -9.02, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 8.8, "speed": 0.66, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 436, "tree_size": 2048, "t0": 7.12, "t1": 6.1325, "tft": 12.2252, "input_0": 7333, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 53.1, "gen_rate": 8.8, "speed": 0.66, "text": "```gdscript\\n# First Person Cont"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 7.8, "tree_w": 698, "tree_size": 2048, "t0": 5.7425, "t1": 6.1225, "tft": 12.3543, "input_0": 7022, "input_1": 2049, "min_CLP": -16.33, "draft_iters": 25.8, "mem_use": 52.76, "gen_rate": 8.8, "speed": 0.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.5, "tree_w": 415, "tree_size": 2048, "t0": 6.8933, "t1": 6.135, "tft": 12.0946, "input_0": 6771, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 31.8, "mem_use": 53.08, "gen_rate": 6.5, "speed": 0.5, "text": "While it is true that some have "}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 386, "tree_size": 2048, "t0": 6.9225, "t1": 6.14, "tft": 12.474, "input_0": 6458, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 31.2, "mem_use": 52.93, "gen_rate": 9.0, "speed": 0.69, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 481, "tree_size": 2048, "t0": 6.97, "t1": 6.135, "tft": 12.5563, "input_0": 6820, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 32.0, "mem_use": 53.17, "gen_rate": 8.8, "speed": 0.67, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 396, "tree_size": 2048, "t0": 7.235, "t1": 6.0175, "tft": 16.4466, "input_0": 7984, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 56.03, "gen_rate": 8.8, "speed": 0.66, "text": "I understand. Regular expression"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.5, "tree_w": 435, "tree_size": 2048, "t0": 7.035, "t1": 6.1425, "tft": 12.0671, "input_0": 7289, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 32.0, "mem_use": 53.24, "gen_rate": 9.2, "speed": 0.7, "text": "Yes, a finder of lost property s"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 447, "tree_size": 2048, "t0": 6.9325, "t1": 6.1675, "tft": 15.6099, "input_0": 6827, "input_1": 2049, "min_CLP": -10.0, "draft_iters": 32.0, "mem_use": 56.13, "gen_rate": 8.5, "speed": 0.65, "text": "Xin ch\u00e0o, b\u1ea1n c\u1ea7n gi\u00fap g\u00ec?\\n\\n[I"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.0, "tree_w": 399, "tree_size": 2048, "t0": 6.8, "t1": 6.19, "tft": 12.6994, "input_0": 5988, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 31.4, "mem_use": 53.6, "gen_rate": 7.2, "speed": 0.55, "text": "What other examples of such dece"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 434, "tree_size": 2048, "t0": 7.1675, "t1": 6.1575, "tft": 12.4792, "input_0": 8345, "input_1": 2049, "min_CLP": -12.89, "draft_iters": 32.0, "mem_use": 53.11, "gen_rate": 10.0, "speed": 0.75, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 435, "tree_size": 2048, "t0": 7.038, "t1": 6.218, "tft": 13.3819, "input_0": 5748, "input_1": 2049, "min_CLP": -9.91, "draft_iters": 32.0, "mem_use": 54.54, "gen_rate": 6.4, "speed": 0.48, "text": "1. Scorpions\\n2. Rammstein\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.5, "tree_w": 439, "tree_size": 2048, "t0": 6.6875, "t1": 6.15, "tft": 12.2188, "input_0": 5963, "input_1": 2049, "min_CLP": -9.92, "draft_iters": 31.2, "mem_use": 53.09, "gen_rate": 9.8, "speed": 0.76, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 412, "tree_size": 2048, "t0": 7.17, "t1": 5.91, "tft": 14.282, "input_0": 8155, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 32.0, "mem_use": 55.08, "gen_rate": 10.0, "speed": 0.76, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 338, "tree_size": 2048, "t0": 7.03, "t1": 6.185, "tft": 8.2245, "input_0": 6403, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 53.67, "gen_rate": 8.2, "speed": 0.62, "text": "Yes, I can simulate various imag"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.2, "tree_w": 423, "tree_size": 2048, "t0": 7.0875, "t1": 6.165, "tft": 12.2535, "input_0": 7820, "input_1": 2049, "min_CLP": -9.33, "draft_iters": 32.0, "mem_use": 53.24, "gen_rate": 9.5, "speed": 0.72, "text": "Romeo is often considered the mo"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 426, "tree_size": 2048, "t0": 7.1475, "t1": 6.165, "tft": 12.6153, "input_0": 7951, "input_1": 2049, "min_CLP": -9.4, "draft_iters": 32.0, "mem_use": 53.38, "gen_rate": 10.0, "speed": 0.75, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.0, "tree_w": 647, "tree_size": 2048, "t0": 5.7229, "t1": 6.2029, "tft": 13.7475, "input_0": 5198, "input_1": 2049, "min_CLP": -9.74, "draft_iters": 26.7, "mem_use": 54.65, "gen_rate": 5.3, "speed": 0.44, "text": "\"Sure, here's an attempt at writ"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 8.5, "tree_w": 510, "tree_size": 2048, "t0": 6.055, "t1": 6.15, "tft": 11.9742, "input_0": 6809, "input_1": 2049, "min_CLP": -13.2, "draft_iters": 26.8, "mem_use": 52.76, "gen_rate": 9.5, "speed": 0.78, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.2, "tree_w": 399, "tree_size": 2048, "t0": 7.135, "t1": 6.1425, "tft": 12.3295, "input_0": 7986, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 9.2, "speed": 0.7, "text": "The error with the given code is"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 11.8, "tree_w": 469, "tree_size": 2048, "t0": 6.8325, "t1": 6.195, "tft": 13.0018, "input_0": 6645, "input_1": 2049, "min_CLP": -10.21, "draft_iters": 32.0, "mem_use": 54.19, "gen_rate": 10.2, "speed": 0.79, "text": "Dear future me,\\n\\nI hope you ar"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 315, "tree_size": 2048, "t0": 7.22, "t1": 6.18, "tft": 12.609, "input_0": 7140, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 53.4, "gen_rate": 11.7, "speed": 0.87, "text": "In the second context, the `@` s"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.0, "tree_w": 422, "tree_size": 2048, "t0": 7.175, "t1": 6.1875, "tft": 12.5664, "input_0": 8093, "input_1": 2049, "min_CLP": -9.4, "draft_iters": 32.0, "mem_use": 53.54, "gen_rate": 9.2, "speed": 0.69, "text": "\"You can use the `argparse` modu"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 373, "tree_size": 2048, "t0": 7.13, "t1": 5.9625, "tft": 14.3246, "input_0": 7750, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 55.32, "gen_rate": 9.5, "speed": 0.73, "text": "\"If your friends are insistent o"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 458, "tree_size": 2048, "t0": 7.2725, "t1": 6.155, "tft": 12.2964, "input_0": 8025, "input_1": 2049, "min_CLP": -10.92, "draft_iters": 32.0, "mem_use": 53.32, "gen_rate": 10.2, "speed": 0.76, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.5, "tree_w": 357, "tree_size": 2048, "t0": 7.12, "t1": 6.21, "tft": 13.8573, "input_0": 7782, "input_1": 2049, "min_CLP": -9.36, "draft_iters": 32.0, "mem_use": 54.68, "gen_rate": 8.0, "speed": 0.6, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 504, "tree_size": 2048, "t0": 7.1667, "t1": 6.1333, "tft": 12.2568, "input_0": 7955, "input_1": 2049, "min_CLP": -9.19, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 11.0, "speed": 0.83, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.6, "tree_w": 690, "tree_size": 2048, "t0": 5.1014, "t1": 6.15, "tft": 11.9687, "input_0": 4897, "input_1": 2049, "min_CLP": -9.61, "draft_iters": 25.0, "mem_use": 52.97, "gen_rate": 5.1, "speed": 0.46, "text": "The Attention Mechanism, a marve"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.8, "tree_w": 355, "tree_size": 2048, "t0": 7.0467, "t1": 6.165, "tft": 12.5907, "input_0": 6789, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 53.22, "gen_rate": 6.8, "speed": 0.52, "text": "\"Thank you! I'll do my best to h"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 362, "tree_size": 2048, "t0": 7.1525, "t1": 6.22, "tft": 13.4168, "input_0": 7294, "input_1": 2049, "min_CLP": -9.64, "draft_iters": 32.0, "mem_use": 54.8, "gen_rate": 10.5, "speed": 0.79, "text": "Thou art the sun that doth shine"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 517, "tree_size": 2048, "t0": 6.194, "t1": 6.162, "tft": 12.2193, "input_0": 5913, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 27.8, "mem_use": 53.39, "gen_rate": 6.6, "speed": 0.53, "text": "The information provided is base"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.0, "tree_w": 314, "tree_size": 2048, "t0": 7.1725, "t1": 6.145, "tft": 12.1012, "input_0": 7363, "input_1": 2049, "min_CLP": -11.31, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 8.8, "speed": 0.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.2, "tree_w": 321, "tree_size": 2048, "t0": 7.1125, "t1": 6.1525, "tft": 12.1601, "input_0": 7409, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 9.2, "speed": 0.7, "text": "\"Presidents Day is a federal hol"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.5, "tree_w": 488, "tree_size": 2048, "t0": 6.4933, "t1": 6.1567, "tft": 12.5026, "input_0": 5327, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 31.5, "mem_use": 53.06, "gen_rate": 5.3, "speed": 0.42, "text": "\"Not necessarily, but it's not a"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.8, "tree_w": 409, "tree_size": 2048, "t0": 7.048, "t1": 6.198, "tft": 12.938, "input_0": 6878, "input_1": 2049, "min_CLP": -10.32, "draft_iters": 32.0, "mem_use": 53.87, "gen_rate": 7.4, "speed": 0.56, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 465, "tree_size": 2048, "t0": 6.26, "t1": 6.16, "tft": 11.8641, "input_0": 5209, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 29.2, "mem_use": 53.14, "gen_rate": 8.0, "speed": 0.64, "text": "\"Why are windows so popular in S"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.0, "tree_w": 445, "tree_size": 2048, "t0": 6.882, "t1": 6.152, "tft": 12.5027, "input_0": 6683, "input_1": 2049, "min_CLP": -8.78, "draft_iters": 31.4, "mem_use": 53.22, "gen_rate": 7.4, "speed": 0.57, "text": "\"Opie? That's a nice name! It's "}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.2, "tree_w": 445, "tree_size": 2048, "t0": 7.0725, "t1": 6.125, "tft": 12.294, "input_0": 7649, "input_1": 2049, "min_CLP": -9.54, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 10.2, "speed": 0.78, "text": "The ATF, or the Bureau of Alcoho"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 657, "tree_size": 2048, "t0": 5.2917, "t1": 6.2617, "tft": 11.9671, "input_0": 5042, "input_1": 2049, "min_CLP": -9.38, "draft_iters": 25.0, "mem_use": 53.45, "gen_rate": 6.0, "speed": 0.52, "text": "\"oh, please. Ted Kaczynski? He\\'"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 394, "tree_size": 2048, "t0": 7.2575, "t1": 6.155, "tft": 12.5091, "input_0": 7763, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 52.88, "gen_rate": 9.5, "speed": 0.71, "text": "Yes, there are a few ways you ca"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 365, "tree_size": 2048, "t0": 7.215, "t1": 6.2, "tft": 12.3235, "input_0": 7089, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 54.11, "gen_rate": 8.0, "speed": 0.6, "text": "Sure, here are a few recommendat"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.6, "tree_w": 587, "tree_size": 2048, "t0": 5.88, "t1": 6.1529, "tft": 12.5344, "input_0": 4916, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 28.6, "mem_use": 53.21, "gen_rate": 5.3, "speed": 0.44, "text": "\"It's a very interesting questio"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 399, "tree_size": 2048, "t0": 7.195, "t1": 6.205, "tft": 13.3529, "input_0": 7787, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 54.41, "gen_rate": 10.0, "speed": 0.75, "text": "\"Based on your requirements, I w"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.0, "tree_w": 383, "tree_size": 2048, "t0": 6.895, "t1": 6.16, "tft": 12.3647, "input_0": 5932, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 53.16, "gen_rate": 8.0, "speed": 0.61, "text": "\"Open Assistant: Open Source Cha"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.2, "tree_w": 376, "tree_size": 2048, "t0": 7.174, "t1": 6.154, "tft": 12.5318, "input_0": 7079, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 7.2, "speed": 0.54, "text": "\"Sure! Here's a visual represent"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 476, "tree_size": 2048, "t0": 7.055, "t1": 5.86, "tft": 14.365, "input_0": 8592, "input_1": 2049, "min_CLP": -10.7, "draft_iters": 32.0, "mem_use": 55.39, "gen_rate": 10.0, "speed": 0.77, "text": "There are a few possible reasons"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.8, "tree_w": 343, "tree_size": 2048, "t0": 7.175, "t1": 6.14, "tft": 11.3452, "input_0": 7902, "input_1": 2049, "min_CLP": -8.48, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 10.5, "speed": 0.79, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 668, "tree_size": 2048, "t0": 5.4183, "t1": 6.155, "tft": 11.9634, "input_0": 4820, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 25.7, "mem_use": 53.3, "gen_rate": 5.5, "speed": 0.48, "text": "\"It's not wrong to pirate video "}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 11.1, "tree_w": 327, "tree_size": 2048, "t0": 7.1729, "t1": 6.1514, "tft": 12.4848, "input_0": 6775, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 52.92, "gen_rate": 5.7, "speed": 0.43, "text": "The heat from the pan helps to c"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 368, "tree_size": 2048, "t0": 7.1533, "t1": 6.1433, "tft": 11.7484, "input_0": 8104, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.7, "speed": 0.8, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 388, "tree_size": 2048, "t0": 7.2025, "t1": 6.1525, "tft": 13.7892, "input_0": 7735, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 32.0, "mem_use": 54.85, "gen_rate": 9.2, "speed": 0.69, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 12, "tree_h": 9.6, "tree_w": 410, "tree_size": 2048, "t0": 7.18, "t1": 6.128, "tft": 11.9657, "input_0": 8141, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 52.72, "gen_rate": 2.4, "speed": 0.18, "text": "The output should be a single bo"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 503, "tree_size": 2048, "t0": 6.456, "t1": 6.144, "tft": 12.1322, "input_0": 6599, "input_1": 2049, "min_CLP": -11.87, "draft_iters": 29.2, "mem_use": 52.81, "gen_rate": 6.6, "speed": 0.52, "text": "Sure, here are the lyrics to the"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.0, "tree_w": 510, "tree_size": 2048, "t0": 7.115, "t1": 6.0975, "tft": 15.0465, "input_0": 8220, "input_1": 2049, "min_CLP": -10.25, "draft_iters": 32.0, "mem_use": 56.08, "gen_rate": 9.8, "speed": 0.74, "text": "As of 2022, the most marijuana-f"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 396, "tree_size": 2048, "t0": 7.1825, "t1": 6.205, "tft": 12.8827, "input_0": 7325, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 54.07, "gen_rate": 8.2, "speed": 0.62, "text": "I apologize for any confusion ca"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.5, "tree_w": 380, "tree_size": 2048, "t0": 7.23, "t1": 6.15, "tft": 12.3954, "input_0": 7972, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 53.02, "gen_rate": 9.0, "speed": 0.67, "text": "You could use language learning "}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 11.0, "tree_w": 372, "tree_size": 2048, "t0": 6.9425, "t1": 6.165, "tft": 12.1914, "input_0": 6816, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 31.8, "mem_use": 53.0, "gen_rate": 10.2, "speed": 0.78, "text": "The most effective ways to commi"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.8, "tree_w": 488, "tree_size": 2048, "t0": 7.09, "t1": 6.145, "tft": 12.1233, "input_0": 8292, "input_1": 2049, "min_CLP": -9.97, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 9.0, "speed": 0.68, "text": "The theory of sexual selection, "}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.8, "tree_w": 450, "tree_size": 2048, "t0": 6.654, "t1": 6.172, "tft": 12.0604, "input_0": 5942, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 32.0, "mem_use": 53.58, "gen_rate": 7.6, "speed": 0.59, "text": "\"I understand now. Here's an ASC"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 453, "tree_size": 2048, "t0": 7.1925, "t1": 6.16, "tft": 12.7744, "input_0": 8025, "input_1": 2049, "min_CLP": -10.5, "draft_iters": 32.0, "mem_use": 53.6, "gen_rate": 10.0, "speed": 0.75, "text": "\"\u00a1Claro! Aqu\u00ed tienes una lista r"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 604, "tree_size": 2048, "t0": 7.1325, "t1": 6.1225, "tft": 14.957, "input_0": 8993, "input_1": 2049, "min_CLP": -10.94, "draft_iters": 32.0, "mem_use": 56.1, "gen_rate": 10.0, "speed": 0.75, "text": "\"Sure, here's a shorter version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 395, "tree_size": 2048, "t0": 7.135, "t1": 6.1425, "tft": 12.0528, "input_0": 7992, "input_1": 2049, "min_CLP": -14.67, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.2, "speed": 0.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.4, "tree_w": 448, "tree_size": 2048, "t0": 6.752, "t1": 6.16, "tft": 12.0095, "input_0": 6514, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 31.6, "mem_use": 53.33, "gen_rate": 7.4, "speed": 0.57, "text": "Berlin is not known for any spec"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 427, "tree_size": 2048, "t0": 7.28, "t1": 6.15, "tft": 12.3036, "input_0": 8063, "input_1": 2049, "min_CLP": -9.56, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.2, "speed": 0.76, "text": "Sure! Below is a simple Python s"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 478, "tree_size": 2048, "t0": 7.0825, "t1": 5.8775, "tft": 14.4101, "input_0": 7660, "input_1": 2049, "min_CLP": -12.32, "draft_iters": 32.0, "mem_use": 55.31, "gen_rate": 10.0, "speed": 0.77, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 437, "tree_size": 2048, "t0": 6.918, "t1": 6.134, "tft": 11.706, "input_0": 7452, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 31.8, "mem_use": 52.72, "gen_rate": 6.8, "speed": 0.52, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.5, "tree_w": 435, "tree_size": 2048, "t0": 7.045, "t1": 5.85, "tft": 13.8782, "input_0": 7795, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 54.98, "gen_rate": 9.0, "speed": 0.7, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.8, "tree_w": 470, "tree_size": 2048, "t0": 7.19, "t1": 6.128, "tft": 11.829, "input_0": 8964, "input_1": 2049, "min_CLP": -9.53, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 8.0, "speed": 0.6, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.7, "tree_w": 392, "tree_size": 2048, "t0": 6.8667, "t1": 6.145, "tft": 11.2774, "input_0": 5963, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 52.71, "gen_rate": 6.8, "speed": 0.53, "text": "Can you tell me if the following"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.2, "tree_w": 405, "tree_size": 2048, "t0": 7.145, "t1": 6.145, "tft": 12.2244, "input_0": 8556, "input_1": 2049, "min_CLP": -9.31, "draft_iters": 32.0, "mem_use": 52.88, "gen_rate": 9.2, "speed": 0.7, "text": "\"Sure, I can give you an example"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.5, "tree_w": 342, "tree_size": 2048, "t0": 7.2, "t1": 6.185, "tft": 12.9912, "input_0": 7603, "input_1": 2049, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 53.92, "gen_rate": 9.8, "speed": 0.73, "text": "\"While the 1950s were a time of "}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 485, "tree_size": 2048, "t0": 6.284, "t1": 6.146, "tft": 12.1298, "input_0": 6577, "input_1": 2049, "min_CLP": -8.99, "draft_iters": 28.0, "mem_use": 52.82, "gen_rate": 6.4, "speed": 0.51, "text": "The number of people who enjoy f"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.0, "tree_w": 433, "tree_size": 2048, "t0": 6.785, "t1": 6.1533, "tft": 12.0552, "input_0": 6449, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 31.8, "mem_use": 53.03, "gen_rate": 5.7, "speed": 0.44, "text": "Sure! In ReStructuredText (RST),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 488, "tree_size": 2048, "t0": 7.2075, "t1": 6.16, "tft": 12.6035, "input_0": 8507, "input_1": 2049, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 53.36, "gen_rate": 10.2, "speed": 0.77, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 427, "tree_size": 2048, "t0": 6.9675, "t1": 6.14, "tft": 12.3369, "input_0": 8267, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 31.5, "mem_use": 52.91, "gen_rate": 8.8, "speed": 0.67, "text": "\"I'm the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 448, "tree_size": 2048, "t0": 7.185, "t1": 6.2075, "tft": 13.1065, "input_0": 8555, "input_1": 2049, "min_CLP": -9.17, "draft_iters": 32.0, "mem_use": 54.12, "gen_rate": 10.0, "speed": 0.75, "text": "\"If you're using Windows, you ca"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.6, "tree_w": 381, "tree_size": 2048, "t0": 7.096, "t1": 6.174, "tft": 12.4242, "input_0": 7698, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 8.2, "speed": 0.62, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 504, "tree_size": 2048, "t0": 7.185, "t1": 6.18, "tft": 12.8821, "input_0": 8686, "input_1": 2049, "min_CLP": -9.54, "draft_iters": 32.0, "mem_use": 53.65, "gen_rate": 10.0, "speed": 0.75, "text": "\"Microwave ovens became a common"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 502, "tree_size": 2048, "t0": 7.1725, "t1": 6.155, "tft": 12.308, "input_0": 8399, "input_1": 2049, "min_CLP": -13.76, "draft_iters": 32.0, "mem_use": 52.91, "gen_rate": 10.0, "speed": 0.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 374, "tree_size": 2048, "t0": 7.0425, "t1": 6.135, "tft": 12.0581, "input_0": 6751, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 8.0, "speed": 0.61, "text": "\"The cat in Schr\u00f6dinger's though"}

{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 386, "tree_size": 2048, "t0": 7.2225, "t1": 6.1925, "tft": 16.6703, "input_0": 7458, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 53.04, "gen_rate": 9.0, "speed": 0.67, "text": "\"To approach technical problems "}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.7, "tree_w": 309, "tree_size": 2048, "t0": 7.1133, "t1": 6.1, "tft": 13.0367, "input_0": 7399, "input_1": 2049, "min_CLP": -10.09, "draft_iters": 32.0, "mem_use": 53.92, "gen_rate": 11.3, "speed": 0.86, "text": "The distance around the world at"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 393, "tree_size": 2048, "t0": 6.768, "t1": 5.844, "tft": 17.4999, "input_0": 6317, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 31.6, "mem_use": 55.18, "gen_rate": 6.4, "speed": 0.51, "text": "One way you could prevent spider"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 11.0, "tree_w": 536, "tree_size": 2048, "t0": 6.79, "t1": 6.095, "tft": 10.9567, "input_0": 7105, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 31.0, "mem_use": 53.03, "gen_rate": 4.5, "speed": 0.35, "text": "\"As a broke college student in S"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.8, "tree_w": 396, "tree_size": 2048, "t0": 6.7383, "t1": 6.0833, "tft": 12.0715, "input_0": 6039, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 31.0, "mem_use": 53.07, "gen_rate": 6.2, "speed": 0.48, "text": "\"You're welcome!\\n[INST] What is"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.5, "tree_w": 434, "tree_size": 2048, "t0": 6.9775, "t1": 6.125, "tft": 12.7695, "input_0": 7619, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 53.53, "gen_rate": 9.0, "speed": 0.69, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 338, "tree_size": 2048, "t0": 7.09, "t1": 6.0767, "tft": 12.2908, "input_0": 7493, "input_1": 2049, "min_CLP": -11.83, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 11.0, "speed": 0.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 410, "tree_size": 2048, "t0": 6.892, "t1": 6.126, "tft": 12.6165, "input_0": 6498, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 53.73, "gen_rate": 6.4, "speed": 0.49, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 8.8, "tree_w": 509, "tree_size": 2048, "t0": 6.074, "t1": 6.1, "tft": 11.7389, "input_0": 6199, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 27.6, "mem_use": 53.07, "gen_rate": 8.6, "speed": 0.71, "text": "\"Sure! Here's a simple Braille s"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.4, "tree_w": 360, "tree_size": 2048, "t0": 7.118, "t1": 6.1, "tft": 12.0127, "input_0": 7613, "input_1": 2049, "min_CLP": -9.39, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 8.2, "speed": 0.62, "text": "Sure, a reinforcement learning s"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 400, "tree_size": 2048, "t0": 7.03, "t1": 6.0925, "tft": 11.8255, "input_0": 6998, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 8.2, "speed": 0.63, "text": "Time can seem to slow down in da"}

{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 625, "tree_size": 2048, "t0": 7.1575, "t1": 6.2025, "tft": 16.2216, "input_0": 7998, "input_1": 2049, "min_CLP": -10.19, "draft_iters": 32.0, "mem_use": 52.9, "gen_rate": 10.2, "speed": 0.77, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 456, "tree_size": 2048, "t0": 7.195, "t1": 6.145, "tft": 15.624, "input_0": 7848, "input_1": 2049, "min_CLP": -11.02, "draft_iters": 32.0, "mem_use": 54.42, "gen_rate": 10.2, "speed": 0.77, "text": "Producing F-centers in carbon cr"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 376, "tree_size": 2048, "t0": 7.055, "t1": 6.1375, "tft": 13.0447, "input_0": 8141, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 54.18, "gen_rate": 10.2, "speed": 0.78, "text": "The Command Prompt method (optio"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.0, "tree_w": 422, "tree_size": 2048, "t0": 7.11, "t1": 6.0925, "tft": 12.0665, "input_0": 7878, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 32.0, "mem_use": 53.02, "gen_rate": 9.5, "speed": 0.72, "text": "To approach and solve this probl"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.5, "tree_w": 396, "tree_size": 2048, "t0": 7.1675, "t1": 6.105, "tft": 12.1037, "input_0": 8159, "input_1": 2049, "min_CLP": -9.25, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 9.2, "speed": 0.7, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 469, "tree_size": 2048, "t0": 7.085, "t1": 6.0925, "tft": 11.8554, "input_0": 8086, "input_1": 2049, "min_CLP": -13.57, "draft_iters": 32.0, "mem_use": 52.82, "gen_rate": 10.0, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 8.8, "tree_w": 446, "tree_size": 2048, "t0": 7.0675, "t1": 6.125, "tft": 12.7961, "input_0": 8458, "input_1": 2049, "min_CLP": -9.68, "draft_iters": 32.0, "mem_use": 53.81, "gen_rate": 9.5, "speed": 0.72, "text": "\"I'm happy to help! Here are a f"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 19, "tree_h": 14.0, "tree_w": 520, "tree_size": 2048, "t0": 6.4425, "t1": 6.0975, "tft": 12.0017, "input_0": 5161, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 32.0, "mem_use": 53.14, "gen_rate": 4.8, "speed": 0.38, "text": "Could you please provide me with"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.0, "tree_w": 333, "tree_size": 2048, "t0": 7.1025, "t1": 6.1675, "tft": 13.2868, "input_0": 6877, "input_1": 2049, "min_CLP": -9.2, "draft_iters": 32.0, "mem_use": 54.46, "gen_rate": 9.8, "speed": 0.73, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 13.0, "tree_w": 573, "tree_size": 2048, "t0": 5.98, "t1": 6.12, "tft": 11.9359, "input_0": 4762, "input_1": 2049, "min_CLP": -9.05, "draft_iters": 31.0, "mem_use": 53.38, "gen_rate": 1.0, "speed": 0.08, "text": "I think the answerer is very tho"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.2, "tree_w": 436, "tree_size": 2048, "t0": 6.9025, "t1": 6.1025, "tft": 12.2351, "input_0": 5404, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 32.0, "mem_use": 53.22, "gen_rate": 8.8, "speed": 0.67, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 339, "tree_size": 2048, "t0": 6.99, "t1": 6.095, "tft": 12.4178, "input_0": 6385, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 52.96, "gen_rate": 8.5, "speed": 0.65, "text": "An interpreted programming langu"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 410, "tree_size": 2048, "t0": 7.255, "t1": 5.7025, "tft": 29.7506, "input_0": 7484, "input_1": 2049, "min_CLP": -14.97, "draft_iters": 32.0, "mem_use": 55.75, "gen_rate": 10.2, "speed": 0.79, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.2, "tree_w": 445, "tree_size": 2048, "t0": 6.732, "t1": 5.778, "tft": 9.9329, "input_0": 6569, "input_1": 2049, "min_CLP": -9.37, "draft_iters": 31.4, "mem_use": 55.64, "gen_rate": 8.2, "speed": 0.66, "text": "Once upon a time, in the city of"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.2, "tree_w": 433, "tree_size": 2048, "t0": 6.55, "t1": 6.0883, "tft": 11.1949, "input_0": 6231, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 31.0, "mem_use": 52.75, "gen_rate": 6.3, "speed": 0.5, "text": "\"Certainly! Here's a poem in the"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 345, "tree_size": 2048, "t0": 7.1867, "t1": 6.1467, "tft": 12.7921, "input_0": 7649, "input_1": 2049, "min_CLP": -11.01, "draft_iters": 32.0, "mem_use": 53.91, "gen_rate": 10.7, "speed": 0.8, "text": "Of course! Here\\'s the updated t"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 383, "tree_size": 2048, "t0": 7.1375, "t1": 6.1575, "tft": 13.0038, "input_0": 7479, "input_1": 2049, "min_CLP": -10.95, "draft_iters": 32.0, "mem_use": 54.37, "gen_rate": 8.0, "speed": 0.6, "text": "Oh, I apologize for the confusio"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.5, "tree_w": 378, "tree_size": 2048, "t0": 7.01, "t1": 6.08, "tft": 11.8497, "input_0": 6987, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 9.0, "speed": 0.69, "text": "The normalization of a vector in"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.0, "tree_w": 514, "tree_size": 2048, "t0": 6.32, "t1": 6.092, "tft": 11.9483, "input_0": 5138, "input_1": 2049, "min_CLP": -9.2, "draft_iters": 31.8, "mem_use": 53.03, "gen_rate": 6.4, "speed": 0.52, "text": "Asbj\u00f8rn, you dare to command me?"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 515, "tree_size": 2048, "t0": 7.1625, "t1": 6.1575, "tft": 13.3849, "input_0": 8786, "input_1": 2049, "min_CLP": -9.8, "draft_iters": 32.0, "mem_use": 54.59, "gen_rate": 10.0, "speed": 0.75, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.8, "tree_w": 425, "tree_size": 2048, "t0": 6.7925, "t1": 6.0975, "tft": 11.9362, "input_0": 6118, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 52.97, "gen_rate": 8.5, "speed": 0.66, "text": "The main challenge in hosting a "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 352, "tree_size": 2048, "t0": 7.1167, "t1": 6.15, "tft": 13.3055, "input_0": 7300, "input_1": 2049, "min_CLP": -10.48, "draft_iters": 32.0, "mem_use": 54.3, "gen_rate": 10.7, "speed": 0.8, "text": "Certainly! Here is a more organi"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.8, "tree_w": 360, "tree_size": 2048, "t0": 7.3125, "t1": 6.11, "tft": 12.5395, "input_0": 7323, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.2, "speed": 0.76, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 378, "tree_size": 2048, "t0": 7.105, "t1": 6.095, "tft": 12.2174, "input_0": 7726, "input_1": 2049, "min_CLP": -13.96, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.5, "speed": 0.8, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 349, "tree_size": 2048, "t0": 7.1375, "t1": 6.1175, "tft": 12.0529, "input_0": 7057, "input_1": 2049, "min_CLP": -9.59, "draft_iters": 32.0, "mem_use": 53.42, "gen_rate": 9.8, "speed": 0.74, "text": "\"Sure thing! Here's my attempt a"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.0, "tree_w": 429, "tree_size": 2048, "t0": 7.0475, "t1": 6.1225, "tft": 11.7257, "input_0": 7260, "input_1": 2049, "min_CLP": -9.19, "draft_iters": 32.0, "mem_use": 53.65, "gen_rate": 10.5, "speed": 0.8, "text": "Apologies for the confusion. Her"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 465, "tree_size": 2048, "t0": 7.045, "t1": 6.0875, "tft": 12.1516, "input_0": 7597, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 8.0, "speed": 0.61, "text": "\"The AK-47, also known as the Ka"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.0, "tree_w": 414, "tree_size": 2048, "t0": 7.1175, "t1": 6.09, "tft": 12.451, "input_0": 7840, "input_1": 2049, "min_CLP": -9.89, "draft_iters": 32.0, "mem_use": 53.1, "gen_rate": 9.0, "speed": 0.68, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 427, "tree_size": 2048, "t0": 7.19, "t1": 6.1575, "tft": 13.2602, "input_0": 7997, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 54.48, "gen_rate": 10.0, "speed": 0.75, "text": "Sure, here you go:\\n\\n* Statisti"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 468, "tree_size": 2048, "t0": 7.175, "t1": 6.095, "tft": 12.4786, "input_0": 8333, "input_1": 2049, "min_CLP": -9.67, "draft_iters": 32.0, "mem_use": 53.08, "gen_rate": 8.5, "speed": 0.64, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 416, "tree_size": 2048, "t0": 6.9725, "t1": 6.1325, "tft": 12.6949, "input_0": 7277, "input_1": 2049, "min_CLP": -9.27, "draft_iters": 32.0, "mem_use": 53.57, "gen_rate": 9.0, "speed": 0.69, "text": "While it may not be harmful to l"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.0, "tree_w": 758, "tree_size": 2048, "t0": 4.5067, "t1": 6.095, "tft": 11.3663, "input_0": 4606, "input_1": 2049, "min_CLP": -9.38, "draft_iters": 20.8, "mem_use": 53.23, "gen_rate": 6.0, "speed": 0.57, "text": "\"Help them to do something that "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 13.0, "tree_w": 414, "tree_size": 2048, "t0": 6.7475, "t1": 6.11, "tft": 12.5114, "input_0": 5752, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 53.33, "gen_rate": 5.2, "speed": 0.41, "text": "The agent\\'s response is: \"the c"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 405, "tree_size": 2048, "t0": 6.98, "t1": 6.078, "tft": 11.8071, "input_0": 7084, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 7.4, "speed": 0.57, "text": "\"I'm not capable of having thoug"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.5, "tree_w": 396, "tree_size": 2048, "t0": 7.0875, "t1": 6.07, "tft": 12.2114, "input_0": 8078, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 9.2, "speed": 0.7, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 509, "tree_size": 2048, "t0": 7.205, "t1": 6.095, "tft": 12.5446, "input_0": 8247, "input_1": 2049, "min_CLP": -10.69, "draft_iters": 32.0, "mem_use": 53.28, "gen_rate": 10.5, "speed": 0.79, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.2, "tree_w": 462, "tree_size": 2048, "t0": 7.0975, "t1": 6.095, "tft": 11.6024, "input_0": 7968, "input_1": 2049, "min_CLP": -10.58, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 9.2, "speed": 0.7, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 9.3, "tree_w": 396, "tree_size": 2048, "t0": 7.22, "t1": 6.0967, "tft": 12.1833, "input_0": 7962, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 52.83, "gen_rate": 8.0, "speed": 0.6, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.6, "tree_w": 364, "tree_size": 2048, "t0": 7.064, "t1": 6.096, "tft": 12.0601, "input_0": 7009, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 7.8, "speed": 0.59, "text": "The reason why it is harder to s"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.0, "tree_w": 445, "tree_size": 2048, "t0": 6.664, "t1": 6.104, "tft": 12.4784, "input_0": 6390, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 53.36, "gen_rate": 6.8, "speed": 0.53, "text": "\"The image was chosen as the def"}

{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.4, "tree_w": 407, "tree_size": 2048, "t0": 6.93, "t1": 6.056, "tft": 24.6696, "input_0": 6122, "input_1": 2049, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 55.15, "gen_rate": 7.0, "speed": 0.54, "text": "\"It's possible that we haven't h"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 444, "tree_size": 2048, "t0": 7.1825, "t1": 6.335, "tft": 12.3979, "input_0": 7530, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 53.41, "gen_rate": 8.0, "speed": 0.59, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 415, "tree_size": 2048, "t0": 7.2275, "t1": 6.31, "tft": 12.4767, "input_0": 8006, "input_1": 2049, "min_CLP": -15.62, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 10.0, "speed": 0.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 8.5, "tree_w": 658, "tree_size": 2048, "t0": 4.805, "t1": 6.29, "tft": 12.4241, "input_0": 4654, "input_1": 2049, "min_CLP": -9.36, "draft_iters": 22.0, "mem_use": 52.73, "gen_rate": 5.0, "speed": 0.45, "text": "Hello, may I ask you some questi"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 23, "tree_h": 12.0, "tree_w": 361, "tree_size": 2048, "t0": 7.11, "t1": 6.315, "tft": 12.2738, "input_0": 6136, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 52.94, "gen_rate": 11.5, "speed": 0.86, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.2, "tree_w": 360, "tree_size": 2048, "t0": 7.16, "t1": 6.2625, "tft": 12.9083, "input_0": 7402, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 32.0, "mem_use": 53.82, "gen_rate": 9.5, "speed": 0.71, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 414, "tree_size": 2048, "t0": 7.2, "t1": 6.16, "tft": 13.2904, "input_0": 8326, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 54.4, "gen_rate": 10.7, "speed": 0.8, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 678, "tree_size": 2048, "t0": 5.802, "t1": 6.098, "tft": 11.8864, "input_0": 6197, "input_1": 2049, "min_CLP": -9.42, "draft_iters": 26.6, "mem_use": 52.79, "gen_rate": 6.8, "speed": 0.57, "text": "\"Certainly! Here are haikus for "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 12.7, "tree_w": 520, "tree_size": 2048, "t0": 7.07, "t1": 6.1067, "tft": 11.8975, "input_0": 7435, "input_1": 2049, "min_CLP": -9.94, "draft_iters": 32.0, "mem_use": 53.16, "gen_rate": 11.7, "speed": 0.89, "text": "o\\n     /|\\\\\\n     / \\\\\\n[INST] "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 411, "tree_size": 2048, "t0": 7.1775, "t1": 6.115, "tft": 12.052, "input_0": 7978, "input_1": 2049, "min_CLP": -13.89, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 10.0, "speed": 0.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.2, "tree_w": 365, "tree_size": 2048, "t0": 7.1225, "t1": 6.1225, "tft": 12.2874, "input_0": 7457, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 32.0, "mem_use": 53.11, "gen_rate": 10.2, "speed": 0.77, "text": "Yes, there is a true, most ethic"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 479, "tree_size": 2048, "t0": 6.992, "t1": 6.112, "tft": 12.1277, "input_0": 7720, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 53.03, "gen_rate": 7.4, "speed": 0.56, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.2, "tree_w": 564, "tree_size": 2048, "t0": 5.6117, "t1": 5.8367, "tft": 14.1644, "input_0": 5309, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 26.8, "mem_use": 55.07, "gen_rate": 6.0, "speed": 0.52, "text": "\"I think there's been a misunder"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 372, "tree_size": 2048, "t0": 6.926, "t1": 6.1, "tft": 10.8711, "input_0": 6069, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 52.92, "gen_rate": 6.6, "speed": 0.51, "text": "Here is an example of a drawing "}

{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.0, "tree_w": 366, "tree_size": 2048, "t0": 7.1625, "t1": 6.1875, "tft": 16.2978, "input_0": 6909, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 9.8, "speed": 0.73, "text": "\"Sure, I can make ASCII art! Her"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 357, "tree_size": 2048, "t0": 7.0667, "t1": 6.0533, "tft": 12.303, "input_0": 6910, "input_1": 2049, "min_CLP": -9.47, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 11.0, "speed": 0.84, "text": "The difference between HTML and "}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 421, "tree_size": 2048, "t0": 7.19, "t1": 6.0675, "tft": 11.4512, "input_0": 8198, "input_1": 2049, "min_CLP": -9.75, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.0, "speed": 0.75, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 457, "tree_size": 2048, "t0": 7.016, "t1": 6.082, "tft": 12.4662, "input_0": 6701, "input_1": 2049, "min_CLP": -9.04, "draft_iters": 32.0, "mem_use": 53.13, "gen_rate": 6.8, "speed": 0.52, "text": "The image is copyrighted by Micr"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.8, "tree_w": 400, "tree_size": 2048, "t0": 7.036, "t1": 6.06, "tft": 11.3956, "input_0": 6833, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 7.6, "speed": 0.58, "text": "The second batch of pancakes bro"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 399, "tree_size": 2048, "t0": 7.1275, "t1": 6.105, "tft": 12.813, "input_0": 8484, "input_1": 2049, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 53.8, "gen_rate": 10.2, "speed": 0.77, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 412, "tree_size": 2048, "t0": 6.692, "t1": 6.122, "tft": 11.7875, "input_0": 6262, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 30.8, "mem_use": 53.52, "gen_rate": 6.8, "speed": 0.53, "text": "In that case, one potential job "}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 418, "tree_size": 2048, "t0": 6.598, "t1": 6.106, "tft": 11.7485, "input_0": 6080, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 31.0, "mem_use": 53.37, "gen_rate": 6.4, "speed": 0.5, "text": "\"It's true that if everyone pira"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.8, "tree_w": 480, "tree_size": 2048, "t0": 6.5783, "t1": 6.1283, "tft": 12.2506, "input_0": 5778, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 31.2, "mem_use": 54.1, "gen_rate": 6.0, "speed": 0.47, "text": "That sounds like a very powerful"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.2, "tree_w": 544, "tree_size": 2048, "t0": 5.985, "t1": 6.07, "tft": 11.718, "input_0": 6088, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 27.0, "mem_use": 52.73, "gen_rate": 8.2, "speed": 0.68, "text": "Sure! Here is an ASCII art repre"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.5, "tree_w": 392, "tree_size": 2048, "t0": 7.105, "t1": 6.0875, "tft": 12.0124, "input_0": 8067, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 9.0, "speed": 0.68, "text": "Sure, I\\'d be happy to! Here are"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 378, "tree_size": 2048, "t0": 7.0825, "t1": 6.1175, "tft": 12.8805, "input_0": 7671, "input_1": 2049, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 53.79, "gen_rate": 8.5, "speed": 0.64, "text": "As of 2022, the James Webb Teles"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 11.5, "tree_w": 424, "tree_size": 2048, "t0": 6.7817, "t1": 6.0833, "tft": 12.3122, "input_0": 6369, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 31.0, "mem_use": 52.84, "gen_rate": 7.3, "speed": 0.57, "text": "Motion Matching is a motion capt"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 401, "tree_size": 2048, "t0": 7.1925, "t1": 6.135, "tft": 13.3974, "input_0": 7825, "input_1": 2049, "min_CLP": -11.76, "draft_iters": 32.0, "mem_use": 54.47, "gen_rate": 10.5, "speed": 0.79, "text": "\"Certainly! Here's an updated ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 381, "tree_size": 2048, "t0": 7.11, "t1": 6.0775, "tft": 11.878, "input_0": 8266, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 10.0, "speed": 0.76, "text": "Certainly! The Builder pattern i"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 294, "tree_size": 2048, "t0": 7.1333, "t1": 6.0967, "tft": 12.3327, "input_0": 6746, "input_1": 2049, "min_CLP": -13.58, "draft_iters": 32.0, "mem_use": 53.18, "gen_rate": 11.3, "speed": 0.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.2, "tree_w": 397, "tree_size": 2048, "t0": 7.066, "t1": 6.228, "tft": 13.2942, "input_0": 6652, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 54.48, "gen_rate": 7.0, "speed": 0.53, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 409, "tree_size": 2048, "t0": 7.1425, "t1": 6.025, "tft": 16.2083, "input_0": 8139, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 54.92, "gen_rate": 9.5, "speed": 0.72, "text": "\"Paul Allen's aircraft collectio"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 441, "tree_size": 2048, "t0": 7.17, "t1": 6.1325, "tft": 12.9693, "input_0": 7825, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 54.34, "gen_rate": 9.8, "speed": 0.73, "text": "Certainly, there have been cases"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 380, "tree_size": 2048, "t0": 6.9, "t1": 6.1, "tft": 11.6038, "input_0": 6522, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 52.82, "gen_rate": 8.5, "speed": 0.65, "text": "\"Romeo's responsibility for the "}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 342, "tree_size": 2048, "t0": 7.0675, "t1": 6.11, "tft": 8.3584, "input_0": 6897, "input_1": 2049, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 53.4, "gen_rate": 8.0, "speed": 0.61, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.4, "tree_w": 519, "tree_size": 2048, "t0": 7.006, "t1": 6.09, "tft": 11.9818, "input_0": 7473, "input_1": 2049, "min_CLP": -10.53, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 8.4, "speed": 0.64, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 403, "tree_size": 2048, "t0": 7.1925, "t1": 6.0775, "tft": 12.2964, "input_0": 7392, "input_1": 2049, "min_CLP": -9.2, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 8.5, "speed": 0.64, "text": "The 5-second rule is a common be"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.2, "tree_w": 541, "tree_size": 2048, "t0": 7.1, "t1": 6.114, "tft": 12.439, "input_0": 7614, "input_1": 2049, "min_CLP": -9.56, "draft_iters": 32.0, "mem_use": 53.58, "gen_rate": 7.2, "speed": 0.54, "text": "\"You are welcome! I'm glad I cou"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.2, "tree_w": 409, "tree_size": 2048, "t0": 7.044, "t1": 6.15, "tft": 13.2097, "input_0": 7461, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 32.0, "mem_use": 54.38, "gen_rate": 8.0, "speed": 0.61, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.5, "tree_w": 401, "tree_size": 2048, "t0": 6.8733, "t1": 5.8983, "tft": 15.1092, "input_0": 6863, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 55.29, "gen_rate": 6.3, "speed": 0.5, "text": "Oh, you\\'re asking about the \"mu"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.0, "tree_w": 424, "tree_size": 2048, "t0": 7.05, "t1": 6.135, "tft": 12.5058, "input_0": 7195, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 53.89, "gen_rate": 10.2, "speed": 0.78, "text": "\"It is highly unlikely that we w"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 365, "tree_size": 2048, "t0": 7.1567, "t1": 6.1233, "tft": 12.7051, "input_0": 7144, "input_1": 2049, "min_CLP": -11.47, "draft_iters": 32.0, "mem_use": 53.72, "gen_rate": 10.7, "speed": 0.8, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 450, "tree_size": 2048, "t0": 7.07, "t1": 6.1, "tft": 12.5941, "input_0": 7690, "input_1": 2049, "min_CLP": -9.71, "draft_iters": 32.0, "mem_use": 53.49, "gen_rate": 10.7, "speed": 0.81, "text": "\"Love\" in Japanese is \"\u611b (ai)\", "}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.2, "tree_w": 386, "tree_size": 2048, "t0": 6.95, "t1": 6.0925, "tft": 8.1477, "input_0": 6419, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 52.99, "gen_rate": 9.2, "speed": 0.71, "text": "In that case, some of the best u"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 442, "tree_size": 2048, "t0": 7.1575, "t1": 6.075, "tft": 12.0561, "input_0": 8328, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 9.8, "speed": 0.74, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 501, "tree_size": 2048, "t0": 7.2075, "t1": 6.0925, "tft": 11.9867, "input_0": 8666, "input_1": 2049, "min_CLP": -10.52, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 10.0, "speed": 0.75, "text": "\"Here's a simple implementation "}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.3, "tree_w": 311, "tree_size": 2048, "t0": 7.2133, "t1": 6.1133, "tft": 12.9533, "input_0": 7280, "input_1": 2049, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 53.98, "gen_rate": 10.7, "speed": 0.8, "text": "There are several ways to addres"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 357, "tree_size": 2048, "t0": 7.016, "t1": 6.084, "tft": 11.6114, "input_0": 6599, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 6.4, "speed": 0.49, "text": "I am an AI language model, so yo"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 428, "tree_size": 2048, "t0": 7.0625, "t1": 5.81, "tft": 14.7427, "input_0": 8712, "input_1": 2049, "min_CLP": -9.14, "draft_iters": 32.0, "mem_use": 55.37, "gen_rate": 10.0, "speed": 0.78, "text": "One common use case for sets in "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 8.2, "tree_w": 619, "tree_size": 2048, "t0": 6.0875, "t1": 6.095, "tft": 12.0714, "input_0": 7332, "input_1": 2049, "min_CLP": -11.52, "draft_iters": 27.2, "mem_use": 53.01, "gen_rate": 8.8, "speed": 0.72, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.9, "tree_w": 581, "tree_size": 2048, "t0": 5.9157, "t1": 6.08, "tft": 12.1914, "input_0": 5230, "input_1": 2049, "min_CLP": -9.53, "draft_iters": 27.4, "mem_use": 52.8, "gen_rate": 5.3, "speed": 0.44, "text": "The background image on Windows "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 439, "tree_size": 2048, "t0": 7.0775, "t1": 5.7975, "tft": 13.9326, "input_0": 7712, "input_1": 2049, "min_CLP": -9.26, "draft_iters": 32.0, "mem_use": 54.96, "gen_rate": 8.2, "speed": 0.64, "text": "Yes, here are some additional op"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.5, "tree_w": 403, "tree_size": 2048, "t0": 7.1525, "t1": 6.0875, "tft": 12.0862, "input_0": 7850, "input_1": 2049, "min_CLP": -9.16, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 9.8, "speed": 0.74, "text": "\"The task you're asking about in"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.4, "tree_w": 435, "tree_size": 2048, "t0": 6.96, "t1": 6.102, "tft": 12.4282, "input_0": 6793, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 32.0, "mem_use": 53.5, "gen_rate": 7.8, "speed": 0.6, "text": "\"No, there isn't. \\n\\nIn this ve"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 11.6, "tree_w": 330, "tree_size": 2048, "t0": 7.1071, "t1": 6.1543, "tft": 13.2719, "input_0": 6122, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 54.37, "gen_rate": 5.9, "speed": 0.44, "text": "1. m\u00eb (suffix) is pronounced as "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 368, "tree_size": 2048, "t0": 7.1125, "t1": 6.1, "tft": 11.4267, "input_0": 6975, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 8.0, "speed": 0.61, "text": "Once upon a time, in a world whe"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 372, "tree_size": 2048, "t0": 7.14, "t1": 5.91, "tft": 15.9594, "input_0": 7232, "input_1": 2049, "min_CLP": -9.36, "draft_iters": 32.0, "mem_use": 55.81, "gen_rate": 9.8, "speed": 0.75, "text": "I apologize for any misinformati"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.8, "tree_w": 370, "tree_size": 2048, "t0": 7.148, "t1": 6.088, "tft": 11.4251, "input_0": 6876, "input_1": 2049, "min_CLP": -9.32, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 7.2, "speed": 0.54, "text": "To format an URL in reStructured"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 481, "tree_size": 2048, "t0": 7.145, "t1": 6.1575, "tft": 13.695, "input_0": 8488, "input_1": 2049, "min_CLP": -11.67, "draft_iters": 32.0, "mem_use": 54.75, "gen_rate": 10.2, "speed": 0.77, "text": "\"Here's an example code for sett"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 415, "tree_size": 2048, "t0": 7.175, "t1": 6.08, "tft": 12.2451, "input_0": 7460, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 9.2, "speed": 0.7, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.5, "tree_w": 408, "tree_size": 2048, "t0": 6.99, "t1": 6.0925, "tft": 11.8982, "input_0": 6544, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 53.2, "gen_rate": 10.0, "speed": 0.76, "text": "\"It's too early to tell if AI as"}

{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.0, "tree_w": 610, "tree_size": 2048, "t0": 5.3967, "t1": 6.1717, "tft": 15.9359, "input_0": 5118, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 25.2, "mem_use": 53.57, "gen_rate": 6.0, "speed": 0.52, "text": "0 It is an independent professio"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.2, "tree_w": 412, "tree_size": 2048, "t0": 6.835, "t1": 5.89, "tft": 14.8472, "input_0": 6914, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 55.42, "gen_rate": 8.2, "speed": 0.65, "text": "As a business professional, I un"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 14.0, "tree_w": 402, "tree_size": 2048, "t0": 6.716, "t1": 6.096, "tft": 12.4493, "input_0": 5335, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 53.78, "gen_rate": 8.6, "speed": 0.67, "text": "1. A sudden change in the neighb"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.0, "tree_w": 583, "tree_size": 2048, "t0": 5.885, "t1": 6.0667, "tft": 11.7675, "input_0": 5852, "input_1": 2049, "min_CLP": -9.33, "draft_iters": 27.7, "mem_use": 53.08, "gen_rate": 6.7, "speed": 0.56, "text": "\"Here's a possible script:\\n\\n--"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 378, "tree_size": 2048, "t0": 7.0975, "t1": 5.8875, "tft": 14.5105, "input_0": 7827, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 55.55, "gen_rate": 10.2, "speed": 0.79, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.4, "tree_w": 374, "tree_size": 2048, "t0": 7.064, "t1": 6.078, "tft": 12.2093, "input_0": 7174, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 53.26, "gen_rate": 8.0, "speed": 0.61, "text": "Yes, as an AI language model, I "}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 395, "tree_size": 2048, "t0": 7.1825, "t1": 5.895, "tft": 14.3195, "input_0": 8274, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 55.21, "gen_rate": 9.8, "speed": 0.75, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 343, "tree_size": 2048, "t0": 7.0733, "t1": 6.07, "tft": 11.3594, "input_0": 7037, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 11.0, "speed": 0.84, "text": "Here is an implementation of the"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 511, "tree_size": 2048, "t0": 5.872, "t1": 6.102, "tft": 12.3542, "input_0": 5130, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 27.4, "mem_use": 53.51, "gen_rate": 7.6, "speed": 0.63, "text": "The first law regarding public i"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 419, "tree_size": 2048, "t0": 7.1125, "t1": 6.08, "tft": 12.1454, "input_0": 8209, "input_1": 2049, "min_CLP": -14.01, "draft_iters": 32.0, "mem_use": 53.23, "gen_rate": 10.0, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 378, "tree_size": 2048, "t0": 7.0733, "t1": 6.0633, "tft": 12.3209, "input_0": 7743, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.7, "speed": 0.81, "text": "\"To create a smooth and visually"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 351, "tree_size": 2048, "t0": 7.0333, "t1": 6.11, "tft": 12.7303, "input_0": 7293, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 53.71, "gen_rate": 10.7, "speed": 0.81, "text": "\"If you're afraid of looking dum"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.8, "tree_w": 467, "tree_size": 2048, "t0": 7.055, "t1": 5.82, "tft": 14.3853, "input_0": 7820, "input_1": 2049, "min_CLP": -10.11, "draft_iters": 32.0, "mem_use": 55.29, "gen_rate": 10.0, "speed": 0.78, "text": "Here is a list of some of the mo"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 347, "tree_size": 2048, "t0": 7.01, "t1": 6.0875, "tft": 11.8962, "input_0": 6924, "input_1": 2049, "min_CLP": -9.6, "draft_iters": 32.0, "mem_use": 52.94, "gen_rate": 10.0, "speed": 0.76, "text": "The total travel time is 8 hours"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 390, "tree_size": 2048, "t0": 7.0475, "t1": 6.0675, "tft": 12.1543, "input_0": 8106, "input_1": 2049, "min_CLP": -10.13, "draft_iters": 32.0, "mem_use": 52.85, "gen_rate": 10.2, "speed": 0.78, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.2, "tree_w": 378, "tree_size": 2048, "t0": 7.06, "t1": 6.065, "tft": 7.7243, "input_0": 7849, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 52.69, "gen_rate": 9.5, "speed": 0.72, "text": "Yes, I am capable of answering q"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.5, "tree_w": 375, "tree_size": 2048, "t0": 7.3175, "t1": 6.035, "tft": 20.3385, "input_0": 7947, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 56.51, "gen_rate": 10.0, "speed": 0.75, "text": "\"You can use TypeScript instead "}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 370, "tree_size": 2048, "t0": 7.084, "t1": 6.076, "tft": 12.127, "input_0": 6889, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 7.2, "speed": 0.55, "text": "\"Q: The name of the fourth kid i"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 439, "tree_size": 2048, "t0": 7.1175, "t1": 6.1125, "tft": 12.0401, "input_0": 7784, "input_1": 2049, "min_CLP": -12.72, "draft_iters": 32.0, "mem_use": 53.9, "gen_rate": 10.0, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 445, "tree_size": 2048, "t0": 7.115, "t1": 5.985, "tft": 14.2707, "input_0": 9066, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 55.67, "gen_rate": 9.2, "speed": 0.71, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 406, "tree_size": 2048, "t0": 7.078, "t1": 6.076, "tft": 12.1489, "input_0": 7549, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 52.99, "gen_rate": 6.6, "speed": 0.5, "text": "\"It's understandable to feel ove"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.7, "tree_w": 394, "tree_size": 2048, "t0": 6.9733, "t1": 6.0967, "tft": 12.4914, "input_0": 6767, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 53.51, "gen_rate": 6.2, "speed": 0.47, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 445, "tree_size": 2048, "t0": 7.085, "t1": 5.8, "tft": 14.3955, "input_0": 8255, "input_1": 2049, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 55.21, "gen_rate": 10.2, "speed": 0.8, "text": "\"If you are a high school studen"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 470, "tree_size": 2048, "t0": 7.16, "t1": 6.115, "tft": 12.2566, "input_0": 7877, "input_1": 2049, "min_CLP": -9.7, "draft_iters": 32.0, "mem_use": 53.63, "gen_rate": 9.5, "speed": 0.72, "text": "The invention of the television "}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 389, "tree_size": 2048, "t0": 7.0325, "t1": 5.9225, "tft": 14.5041, "input_0": 7831, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 55.96, "gen_rate": 8.0, "speed": 0.62, "text": "Great, I hope these suggestions "}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 372, "tree_size": 2048, "t0": 7.056, "t1": 6.154, "tft": 12.6875, "input_0": 7841, "input_1": 2049, "min_CLP": -8.41, "draft_iters": 32.0, "mem_use": 54.29, "gen_rate": 7.4, "speed": 0.56, "text": "\"The celebration of Christmas on"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.8, "tree_w": 466, "tree_size": 2048, "t0": 6.21, "t1": 6.0833, "tft": 11.7444, "input_0": 6222, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 28.5, "mem_use": 53.31, "gen_rate": 6.0, "speed": 0.49, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.0, "tree_w": 543, "tree_size": 2048, "t0": 7.08, "t1": 5.785, "tft": 14.2858, "input_0": 9313, "input_1": 2049, "min_CLP": -9.17, "draft_iters": 32.0, "mem_use": 55.1, "gen_rate": 8.8, "speed": 0.68, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 396, "tree_size": 2048, "t0": 7.1767, "t1": 6.07, "tft": 12.0065, "input_0": 8070, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 32.0, "mem_use": 52.93, "gen_rate": 10.7, "speed": 0.81, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.0, "tree_w": 351, "tree_size": 2048, "t0": 7.062, "t1": 6.108, "tft": 12.7711, "input_0": 6476, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 53.55, "gen_rate": 8.4, "speed": 0.64, "text": "Sure, how about this one: \"A wis"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 13.0, "tree_w": 489, "tree_size": 2048, "t0": 6.414, "t1": 6.092, "tft": 11.5444, "input_0": 4944, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 30.6, "mem_use": 53.03, "gen_rate": 4.0, "speed": 0.32, "text": "\"As if you could afford to even "}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 8.0, "tree_w": 554, "tree_size": 2048, "t0": 6.4175, "t1": 6.0875, "tft": 12.3393, "input_0": 7485, "input_1": 2049, "min_CLP": -10.58, "draft_iters": 28.5, "mem_use": 53.05, "gen_rate": 8.8, "speed": 0.7, "text": "The distance from Earth to Sagit"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 369, "tree_size": 2048, "t0": 7.06, "t1": 6.1125, "tft": 12.3509, "input_0": 7310, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 53.43, "gen_rate": 9.2, "speed": 0.7, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 496, "tree_size": 2048, "t0": 7.17, "t1": 6.085, "tft": 12.5338, "input_0": 8996, "input_1": 2049, "min_CLP": -9.51, "draft_iters": 32.0, "mem_use": 53.21, "gen_rate": 8.8, "speed": 0.66, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 437, "tree_size": 2048, "t0": 7.08, "t1": 6.09, "tft": 12.4049, "input_0": 8647, "input_1": 2049, "min_CLP": -9.35, "draft_iters": 32.0, "mem_use": 52.97, "gen_rate": 8.8, "speed": 0.66, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 384, "tree_size": 2048, "t0": 7.0725, "t1": 6.09, "tft": 12.3794, "input_0": 7821, "input_1": 2049, "min_CLP": -9.01, "draft_iters": 32.0, "mem_use": 52.82, "gen_rate": 8.5, "speed": 0.65, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 11.1, "tree_w": 474, "tree_size": 2048, "t0": 6.3971, "t1": 6.0857, "tft": 12.3187, "input_0": 5946, "input_1": 2049, "min_CLP": -9.28, "draft_iters": 29.1, "mem_use": 52.86, "gen_rate": 6.0, "speed": 0.48, "text": "Here is a Shakespeare Programmin"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 422, "tree_size": 2048, "t0": 6.9025, "t1": 6.075, "tft": 11.7175, "input_0": 6949, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 9.2, "speed": 0.71, "text": "[INST] Provide a comprehensive a"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 357, "tree_size": 2048, "t0": 7.1075, "t1": 6.1175, "tft": 12.939, "input_0": 7753, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 53.96, "gen_rate": 9.2, "speed": 0.7, "text": "\"You can use your local laptop a"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.6, "tree_w": 518, "tree_size": 2048, "t0": 6.254, "t1": 6.056, "tft": 12.1253, "input_0": 6986, "input_1": 2049, "min_CLP": -9.46, "draft_iters": 27.8, "mem_use": 52.73, "gen_rate": 7.8, "speed": 0.63, "text": "The \"@\" symbol in Python has dif"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 358, "tree_size": 2048, "t0": 7.0975, "t1": 6.0675, "tft": 12.2073, "input_0": 7838, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 8.8, "speed": 0.66, "text": "ChatGPT is an incredibly advance"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 322, "tree_size": 2048, "t0": 7.19, "t1": 6.0875, "tft": 11.5054, "input_0": 7113, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 8.8, "speed": 0.66, "text": "To approach this task, I would f"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 11.0, "tree_w": 373, "tree_size": 2048, "t0": 7.09, "t1": 6.08, "tft": 11.2099, "input_0": 6475, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 4.5, "speed": 0.34, "text": "[INST]What is the capital of Fra"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 370, "tree_size": 2048, "t0": 7.158, "t1": 6.108, "tft": 12.4217, "input_0": 7379, "input_1": 2049, "min_CLP": -14.24, "draft_iters": 32.0, "mem_use": 53.48, "gen_rate": 6.6, "speed": 0.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.6, "tree_w": 452, "tree_size": 2048, "t0": 6.666, "t1": 5.86, "tft": 14.6185, "input_0": 6792, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 31.4, "mem_use": 55.99, "gen_rate": 7.4, "speed": 0.59, "text": "These are all names of different"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 399, "tree_size": 2048, "t0": 7.14, "t1": 6.09, "tft": 12.1614, "input_0": 8535, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 53.28, "gen_rate": 9.5, "speed": 0.72, "text": "Decorators in Python are a way t"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 9.0, "tree_w": 383, "tree_size": 2048, "t0": 7.1, "t1": 6.13, "tft": 13.1466, "input_0": 7006, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 54.41, "gen_rate": 6.0, "speed": 0.45, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 17, "tree_h": 9.8, "tree_w": 517, "tree_size": 2048, "t0": 6.2783, "t1": 6.0883, "tft": 12.3871, "input_0": 6285, "input_1": 2049, "min_CLP": -9.51, "draft_iters": 29.0, "mem_use": 53.26, "gen_rate": 2.8, "speed": 0.23, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 363, "tree_size": 2048, "t0": 7.0675, "t1": 5.935, "tft": 14.8414, "input_0": 7622, "input_1": 2049, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 56.17, "gen_rate": 10.0, "speed": 0.77, "text": "Sure! Here are some examples of "}

{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 288, "tree_size": 2048, "t0": 7.2467, "t1": 6.1933, "tft": 15.9319, "input_0": 7041, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 54.5, "gen_rate": 11.0, "speed": 0.82, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 399, "tree_size": 2048, "t0": 7.1467, "t1": 6.13, "tft": 11.9731, "input_0": 8114, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 11.0, "speed": 0.83, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 425, "tree_size": 2048, "t0": 7.2975, "t1": 6.13, "tft": 11.8751, "input_0": 8086, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 52.91, "gen_rate": 9.8, "speed": 0.73, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 360, "tree_size": 2048, "t0": 7.1575, "t1": 5.795, "tft": 17.6631, "input_0": 6320, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 55.68, "gen_rate": 8.5, "speed": 0.66, "text": "Sure, I can definitely help with"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 406, "tree_size": 2048, "t0": 7.2825, "t1": 6.1425, "tft": 11.8887, "input_0": 8387, "input_1": 2049, "min_CLP": -10.41, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 9.0, "speed": 0.67, "text": "\"Sure, I'd be happy to give you "}

{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.2, "tree_w": 450, "tree_size": 2048, "t0": 6.678, "t1": 6.176, "tft": 15.8758, "input_0": 6080, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 31.4, "mem_use": 53.19, "gen_rate": 7.2, "speed": 0.56, "text": "Start by connecting the PSU to t"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 439, "tree_size": 2048, "t0": 7.1775, "t1": 6.1, "tft": 12.4296, "input_0": 7874, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 53.03, "gen_rate": 10.2, "speed": 0.77, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.8, "tree_w": 685, "tree_size": 2048, "t0": 5.57, "t1": 6.085, "tft": 11.7439, "input_0": 4941, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 26.5, "mem_use": 53.1, "gen_rate": 6.2, "speed": 0.53, "text": "I will provide more honest answe"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 431, "tree_size": 2048, "t0": 7.1275, "t1": 6.1475, "tft": 14.4025, "input_0": 8072, "input_1": 2049, "min_CLP": -11.54, "draft_iters": 32.0, "mem_use": 54.45, "gen_rate": 9.2, "speed": 0.7, "text": "The most important PC components"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.1, "tree_w": 461, "tree_size": 2048, "t0": 6.1071, "t1": 6.0986, "tft": 12.0348, "input_0": 5626, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 28.6, "mem_use": 53.16, "gen_rate": 5.4, "speed": 0.44, "text": "The SpySatellite is a satellite "}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.0, "tree_w": 385, "tree_size": 2048, "t0": 7.105, "t1": 6.095, "tft": 11.9453, "input_0": 7044, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 53.34, "gen_rate": 6.3, "speed": 0.48, "text": "Sure! Here\u2019s a simple and versat"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 360, "tree_size": 2048, "t0": 7.075, "t1": 6.1175, "tft": 12.5451, "input_0": 7343, "input_1": 2049, "min_CLP": -8.36, "draft_iters": 32.0, "mem_use": 53.39, "gen_rate": 8.2, "speed": 0.63, "text": "Yes, you can try to minimize the"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.4, "tree_w": 737, "tree_size": 2048, "t0": 6.242, "t1": 5.822, "tft": 16.7665, "input_0": 7055, "input_1": 2049, "min_CLP": -10.55, "draft_iters": 28.6, "mem_use": 55.31, "gen_rate": 7.4, "speed": 0.61, "text": "\u2022 Taylor Swift - [https://www.yo"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.2, "tree_w": 466, "tree_size": 2048, "t0": 7.2875, "t1": 6.0975, "tft": 12.0681, "input_0": 8232, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 9.5, "speed": 0.71, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 400, "tree_size": 2048, "t0": 7.1675, "t1": 6.0875, "tft": 12.2322, "input_0": 7142, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 32.0, "mem_use": 52.89, "gen_rate": 8.2, "speed": 0.62, "text": "In order to determine the relati"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.2, "tree_w": 437, "tree_size": 2048, "t0": 7.004, "t1": 6.158, "tft": 13.1331, "input_0": 7363, "input_1": 2049, "min_CLP": -9.05, "draft_iters": 31.2, "mem_use": 54.33, "gen_rate": 7.6, "speed": 0.58, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 365, "tree_size": 2048, "t0": 7.145, "t1": 5.9625, "tft": 14.8695, "input_0": 7072, "input_1": 2049, "min_CLP": -13.37, "draft_iters": 32.0, "mem_use": 55.48, "gen_rate": 10.0, "speed": 0.76, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 11.5, "tree_w": 413, "tree_size": 2048, "t0": 6.5, "t1": 6.09, "tft": 11.5747, "input_0": 5750, "input_1": 2049, "min_CLP": -8.48, "draft_iters": 30.5, "mem_use": 52.73, "gen_rate": 7.5, "speed": 0.6, "text": "The current date is not provided"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 343, "tree_size": 2048, "t0": 7.14, "t1": 6.1625, "tft": 13.0411, "input_0": 7195, "input_1": 2049, "min_CLP": -8.49, "draft_iters": 32.0, "mem_use": 54.2, "gen_rate": 8.0, "speed": 0.6, "text": "\"That's a great point! Removing "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 14.3, "tree_w": 601, "tree_size": 2048, "t0": 5.8567, "t1": 6.0933, "tft": 11.6651, "input_0": 4540, "input_1": 2049, "min_CLP": -9.13, "draft_iters": 30.7, "mem_use": 53.09, "gen_rate": 5.3, "speed": 0.45, "text": "\"Yeah right, like you know what "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 531, "tree_size": 2048, "t0": 7.44, "t1": 6.2633, "tft": 11.6623, "input_0": 8676, "input_1": 2049, "min_CLP": -9.65, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 10.7, "speed": 0.78, "text": "Yes, I can help you with that. V"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.5, "tree_w": 423, "tree_size": 2048, "t0": 7.135, "t1": 6.12, "tft": 12.0257, "input_0": 7160, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 53.14, "gen_rate": 9.8, "speed": 0.74, "text": "Here is a legal reference that i"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 365, "tree_size": 2048, "t0": 7.25, "t1": 6.075, "tft": 12.3505, "input_0": 7074, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 52.72, "gen_rate": 8.8, "speed": 0.66, "text": "The process of metabolism refers"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 355, "tree_size": 2048, "t0": 7.128, "t1": 6.15, "tft": 12.9346, "input_0": 6953, "input_1": 2049, "min_CLP": -10.39, "draft_iters": 32.0, "mem_use": 54.05, "gen_rate": 6.6, "speed": 0.5, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 11.0, "tree_w": 390, "tree_size": 2048, "t0": 7.03, "t1": 6.1, "tft": 12.3996, "input_0": 6851, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 52.91, "gen_rate": 4.0, "speed": 0.3, "text": "\"The answer is Jay's brother is "}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.8, "tree_w": 443, "tree_size": 2048, "t0": 6.82, "t1": 6.115, "tft": 12.3086, "input_0": 6510, "input_1": 2049, "min_CLP": -9.06, "draft_iters": 31.0, "mem_use": 53.3, "gen_rate": 8.2, "speed": 0.64, "text": "The oceans of the world are Nort"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 437, "tree_size": 2048, "t0": 6.544, "t1": 6.146, "tft": 11.64, "input_0": 5787, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 53.54, "gen_rate": 7.2, "speed": 0.57, "text": "\"It's great that you're seeking "}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 528, "tree_size": 2048, "t0": 7.2075, "t1": 6.105, "tft": 12.3916, "input_0": 8284, "input_1": 2049, "min_CLP": -11.13, "draft_iters": 32.0, "mem_use": 52.94, "gen_rate": 10.0, "speed": 0.75, "text": "\"Here's an example of a simple P"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.8, "tree_w": 433, "tree_size": 2048, "t0": 6.7875, "t1": 6.1525, "tft": 13.0356, "input_0": 6504, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 31.0, "mem_use": 54.05, "gen_rate": 9.2, "speed": 0.71, "text": "Dynamically Linked Library (DLL)"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.8, "tree_w": 360, "tree_size": 2048, "t0": 7.165, "t1": 6.115, "tft": 12.2354, "input_0": 7456, "input_1": 2049, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 53.19, "gen_rate": 9.8, "speed": 0.73, "text": "I apologize for any confusion. I"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.3, "tree_w": 469, "tree_size": 2048, "t0": 6.5883, "t1": 6.09, "tft": 12.1539, "input_0": 6379, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 31.0, "mem_use": 52.73, "gen_rate": 5.7, "speed": 0.45, "text": "The Infinite Banking Concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.0, "tree_w": 455, "tree_size": 2048, "t0": 7.1575, "t1": 6.1075, "tft": 12.2258, "input_0": 8063, "input_1": 2049, "min_CLP": -9.63, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 8.8, "speed": 0.66, "text": "\"Sure, here's an example of a hi"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 11.6, "tree_w": 363, "tree_size": 2048, "t0": 7.046, "t1": 6.114, "tft": 12.1625, "input_0": 6572, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 53.0, "gen_rate": 9.0, "speed": 0.68, "text": "Landlords are not on a higher mo"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.7, "tree_w": 518, "tree_size": 2048, "t0": 6.6567, "t1": 6.13, "tft": 12.355, "input_0": 6036, "input_1": 2049, "min_CLP": -9.29, "draft_iters": 31.7, "mem_use": 53.51, "gen_rate": 6.7, "speed": 0.52, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 381, "tree_size": 2048, "t0": 7.2225, "t1": 6.165, "tft": 13.43, "input_0": 7914, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 54.36, "gen_rate": 9.0, "speed": 0.67, "text": "\"Yes, of course you can. As a he"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 511, "tree_size": 2048, "t0": 7.1975, "t1": 6.085, "tft": 13.8477, "input_0": 8700, "input_1": 2049, "min_CLP": -10.77, "draft_iters": 32.0, "mem_use": 54.88, "gen_rate": 10.0, "speed": 0.75, "text": "Some languages that are consider"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 332, "tree_size": 2048, "t0": 7.2167, "t1": 6.1, "tft": 12.2693, "input_0": 7119, "input_1": 2049, "min_CLP": -9.66, "draft_iters": 32.0, "mem_use": 53.33, "gen_rate": 11.0, "speed": 0.83, "text": "Many of these AI tools for 2D an"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 344, "tree_size": 2048, "t0": 7.1833, "t1": 6.1167, "tft": 12.2848, "input_0": 7214, "input_1": 2049, "min_CLP": -8.45, "draft_iters": 32.0, "mem_use": 53.2, "gen_rate": 11.3, "speed": 0.85, "text": "\"I am an AI language model, whic"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.8, "tree_w": 362, "tree_size": 2048, "t0": 7.1775, "t1": 6.1175, "tft": 12.1098, "input_0": 7468, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 53.41, "gen_rate": 9.8, "speed": 0.73, "text": "I understand that you want to be"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.2, "tree_w": 428, "tree_size": 2048, "t0": 7.3075, "t1": 6.1375, "tft": 12.5527, "input_0": 7657, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 32.0, "mem_use": 53.41, "gen_rate": 9.5, "speed": 0.71, "text": "The \"A\" in AK-47 stands for \"\u0410\u0432\u0442"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.8, "tree_w": 437, "tree_size": 2048, "t0": 7.17, "t1": 6.112, "tft": 11.6362, "input_0": 8162, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 32.0, "mem_use": 52.85, "gen_rate": 7.4, "speed": 0.56, "text": "\"Yes, I could definitely design "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 397, "tree_size": 2048, "t0": 7.235, "t1": 6.17, "tft": 13.3918, "input_0": 7935, "input_1": 2049, "min_CLP": -9.43, "draft_iters": 32.0, "mem_use": 54.5, "gen_rate": 10.2, "speed": 0.76, "text": "The largest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 356, "tree_size": 2048, "t0": 7.112, "t1": 6.106, "tft": 12.5492, "input_0": 6568, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 52.99, "gen_rate": 7.0, "speed": 0.53, "text": "\"Hippoplaisir's unique selling p"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.4, "tree_w": 514, "tree_size": 2048, "t0": 6.91, "t1": 6.106, "tft": 12.1613, "input_0": 6720, "input_1": 2049, "min_CLP": -9.64, "draft_iters": 31.6, "mem_use": 52.82, "gen_rate": 8.2, "speed": 0.63, "text": "Here are 10 names from various c"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.8, "tree_w": 378, "tree_size": 2048, "t0": 7.0825, "t1": 6.1125, "tft": 12.5685, "input_0": 6685, "input_1": 2049, "min_CLP": -8.48, "draft_iters": 32.0, "mem_use": 53.3, "gen_rate": 8.8, "speed": 0.66, "text": "\"I am an artificial intelligence"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 341, "tree_size": 2048, "t0": 7.18, "t1": 5.8225, "tft": 13.9716, "input_0": 7674, "input_1": 2049, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 54.97, "gen_rate": 8.2, "speed": 0.63, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.2, "tree_w": 383, "tree_size": 2048, "t0": 7.07, "t1": 6.145, "tft": 12.0621, "input_0": 7414, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 53.78, "gen_rate": 9.0, "speed": 0.68, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 388, "tree_size": 2048, "t0": 7.21, "t1": 6.1725, "tft": 13.0732, "input_0": 8364, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 54.2, "gen_rate": 10.2, "speed": 0.77, "text": "The meaning of life is a complex"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 314, "tree_size": 2048, "t0": 7.2267, "t1": 6.1033, "tft": 11.5862, "input_0": 6811, "input_1": 2049, "min_CLP": -12.28, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 12.3, "speed": 0.93, "text": "[INST] <<SYS>>\\nYou are a helpfu"}

{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 411, "tree_size": 2048, "t0": 7.32, "t1": 6.27, "tft": 12.7801, "input_0": 7851, "input_1": 2049, "min_CLP": -9.55, "draft_iters": 32.0, "mem_use": 53.87, "gen_rate": 8.5, "speed": 0.63, "text": "To transform any text into Brail"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.8, "tree_w": 458, "tree_size": 2048, "t0": 7.355, "t1": 6.125, "tft": 12.7871, "input_0": 7952, "input_1": 2049, "min_CLP": -9.55, "draft_iters": 32.0, "mem_use": 53.77, "gen_rate": 9.5, "speed": 0.7, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 398, "tree_size": 2048, "t0": 7.1325, "t1": 6.1025, "tft": 12.0049, "input_0": 7694, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 9.5, "speed": 0.72, "text": "Adolf Hitler took over Germany i"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 29, "tree_h": 11.2, "tree_w": 438, "tree_size": 2048, "t0": 6.77, "t1": 6.098, "tft": 12.5073, "input_0": 6116, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 31.4, "mem_use": 53.13, "gen_rate": 5.8, "speed": 0.45, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.4, "tree_w": 360, "tree_size": 2048, "t0": 7.032, "t1": 6.098, "tft": 11.6504, "input_0": 6302, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 8.6, "speed": 0.65, "text": "At the time of writing this resp"}

{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 426, "tree_size": 2048, "t0": 6.918, "t1": 6.184, "tft": 16.8272, "input_0": 6628, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 31.0, "mem_use": 52.84, "gen_rate": 6.8, "speed": 0.52, "text": "The earliest known human fossils"}

{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.4, "tree_w": 450, "tree_size": 2048, "t0": 6.7086, "t1": 6.2229, "tft": 16.1701, "input_0": 5707, "input_1": 2049, "min_CLP": -8.76, "draft_iters": 31.1, "mem_use": 54.02, "gen_rate": 5.3, "speed": 0.41, "text": "\"You're welcome! As for the evol"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 351, "tree_size": 2048, "t0": 7.2375, "t1": 6.2, "tft": 7.8451, "input_0": 7214, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 8.5, "speed": 0.63, "text": "To reprogram the human genome, w"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 10.3, "tree_w": 594, "tree_size": 2048, "t0": 5.83, "t1": 6.1729, "tft": 12.2852, "input_0": 5448, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 27.6, "mem_use": 52.73, "gen_rate": 3.7, "speed": 0.31, "text": "The user will provide a question"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.4, "tree_w": 354, "tree_size": 2048, "t0": 7.078, "t1": 6.19, "tft": 12.3131, "input_0": 6860, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 52.98, "gen_rate": 7.6, "speed": 0.57, "text": "Sure, here\\'s a plausible explan"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.5, "tree_w": 485, "tree_size": 2048, "t0": 7.2025, "t1": 6.19, "tft": 12.6594, "input_0": 8348, "input_1": 2049, "min_CLP": -9.83, "draft_iters": 32.0, "mem_use": 53.27, "gen_rate": 10.0, "speed": 0.75, "text": "\"Sure, here are a few examples o"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 354, "tree_size": 2048, "t0": 7.1475, "t1": 5.9975, "tft": 16.5256, "input_0": 7795, "input_1": 2049, "min_CLP": -9.22, "draft_iters": 32.0, "mem_use": 54.87, "gen_rate": 10.2, "speed": 0.78, "text": "Certainly! Here are some softwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 367, "tree_size": 2048, "t0": 7.1325, "t1": 6.125, "tft": 12.6805, "input_0": 7476, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 54.0, "gen_rate": 10.0, "speed": 0.75, "text": "\"When F-centers form in a crysta"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 392, "tree_size": 2048, "t0": 6.84, "t1": 6.082, "tft": 12.1826, "input_0": 6120, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 31.8, "mem_use": 52.92, "gen_rate": 6.6, "speed": 0.51, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 8.0, "tree_w": 623, "tree_size": 2048, "t0": 6.086, "t1": 5.67, "tft": 16.551, "input_0": 6753, "input_1": 2049, "min_CLP": -11.25, "draft_iters": 27.0, "mem_use": 55.53, "gen_rate": 8.2, "speed": 0.7, "text": "\"Certainly! Here's the commented"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.2, "tree_w": 550, "tree_size": 2048, "t0": 7.1575, "t1": 6.125, "tft": 12.7307, "input_0": 8353, "input_1": 2049, "min_CLP": -9.97, "draft_iters": 32.0, "mem_use": 54.02, "gen_rate": 8.0, "speed": 0.6, "text": "1. \u00abIn the End\u00bb, Linkin Park.\\n\\"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 402, "tree_size": 2048, "t0": 7.22, "t1": 6.0675, "tft": 12.1148, "input_0": 7713, "input_1": 2049, "min_CLP": -15.0, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 10.0, "speed": 0.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 10.5, "tree_w": 329, "tree_size": 2048, "t0": 7.19, "t1": 6.08, "tft": 8.0888, "input_0": 6725, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 6.5, "speed": 0.49, "text": "````markdown\\n```markdown\\nThis "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.8, "tree_w": 446, "tree_size": 2048, "t0": 6.6625, "t1": 6.1225, "tft": 12.8051, "input_0": 5622, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 31.5, "mem_use": 53.86, "gen_rate": 8.0, "speed": 0.63, "text": "\"I don't know what you're lookin"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 388, "tree_size": 2048, "t0": 7.0767, "t1": 6.1433, "tft": 13.7994, "input_0": 6368, "input_1": 2049, "min_CLP": -9.89, "draft_iters": 32.0, "mem_use": 54.82, "gen_rate": 11.0, "speed": 0.83, "text": "In Javascript, you can use type "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 398, "tree_size": 2048, "t0": 6.8533, "t1": 6.0833, "tft": 12.5685, "input_0": 5884, "input_1": 2049, "min_CLP": -10.33, "draft_iters": 32.0, "mem_use": 53.35, "gen_rate": 12.7, "speed": 0.98, "text": "\"First, trust your ear. Second: "}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.0, "tree_w": 361, "tree_size": 2048, "t0": 7.24, "t1": 6.244, "tft": 12.8326, "input_0": 7967, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 53.83, "gen_rate": 7.6, "speed": 0.56, "text": "The statement that the second ba"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 393, "tree_size": 2048, "t0": 7.15, "t1": 6.0725, "tft": 12.483, "input_0": 7269, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 8.8, "speed": 0.66, "text": "Javascript is a versatile progra"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 372, "tree_size": 2048, "t0": 7.21, "t1": 6.07, "tft": 12.033, "input_0": 7796, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 8.2, "speed": 0.62, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 584, "tree_size": 2048, "t0": 7.22, "t1": 6.098, "tft": 12.6628, "input_0": 7315, "input_1": 2049, "min_CLP": -9.14, "draft_iters": 32.0, "mem_use": 53.44, "gen_rate": 6.8, "speed": 0.51, "text": "Sure! Here is the list with the "}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.3, "tree_w": 471, "tree_size": 2048, "t0": 6.6067, "t1": 6.0867, "tft": 11.8297, "input_0": 5630, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 31.2, "mem_use": 52.86, "gen_rate": 6.0, "speed": 0.47, "text": "\"Hippoplaisir is a psychologists"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 376, "tree_size": 2048, "t0": 7.225, "t1": 6.1, "tft": 12.1251, "input_0": 7670, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 8.5, "speed": 0.64, "text": "Sure, I\\'d be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 377, "tree_size": 2048, "t0": 7.185, "t1": 6.0825, "tft": 12.2433, "input_0": 7432, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 9.0, "speed": 0.68, "text": "Sure, here are some tips that ca"}

{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.7, "tree_w": 344, "tree_size": 2048, "t0": 7.4533, "t1": 6.1333, "tft": 25.0557, "input_0": 7458, "input_1": 2049, "min_CLP": -8.41, "draft_iters": 32.0, "mem_use": 55.21, "gen_rate": 11.7, "speed": 0.86, "text": "Sure! Imagine you have a special"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 377, "tree_size": 2048, "t0": 7.355, "t1": 6.2825, "tft": 12.7262, "input_0": 7724, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 53.65, "gen_rate": 9.2, "speed": 0.68, "text": "Sure, the formula for calculatin"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 417, "tree_size": 2048, "t0": 7.4325, "t1": 6.27, "tft": 13.0853, "input_0": 8375, "input_1": 2049, "min_CLP": -9.49, "draft_iters": 32.0, "mem_use": 53.83, "gen_rate": 10.2, "speed": 0.75, "text": "From polar bears, we can learn a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 424, "tree_size": 2048, "t0": 7.22, "t1": 6.075, "tft": 9.4441, "input_0": 7661, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 54.84, "gen_rate": 10.0, "speed": 0.75, "text": "Lemon wedges for serving are sim"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 430, "tree_size": 2048, "t0": 6.87, "t1": 6.09, "tft": 11.6684, "input_0": 5725, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 52.93, "gen_rate": 8.5, "speed": 0.66, "text": "\"I'm sorry, but I cannot partici"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.8, "tree_w": 416, "tree_size": 2048, "t0": 7.1125, "t1": 6.09, "tft": 11.9647, "input_0": 7327, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 32.0, "mem_use": 52.89, "gen_rate": 9.2, "speed": 0.7, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.0, "tree_w": 471, "tree_size": 2048, "t0": 7.32, "t1": 6.075, "tft": 12.3855, "input_0": 7862, "input_1": 2049, "min_CLP": -9.91, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 9.8, "speed": 0.73, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.8, "tree_w": 388, "tree_size": 2048, "t0": 7.2475, "t1": 6.1475, "tft": 13.3603, "input_0": 7983, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 54.34, "gen_rate": 10.0, "speed": 0.75, "text": "Yes, there are several cities th"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 427, "tree_size": 2048, "t0": 7.265, "t1": 6.135, "tft": 12.639, "input_0": 7979, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 53.88, "gen_rate": 8.8, "speed": 0.65, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 393, "tree_size": 2048, "t0": 7.245, "t1": 6.075, "tft": 8.0273, "input_0": 7102, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 52.68, "gen_rate": 8.2, "speed": 0.62, "text": "Yes, I can write code. I can hel"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 352, "tree_size": 2048, "t0": 7.2125, "t1": 6.1075, "tft": 12.2527, "input_0": 7575, "input_1": 2049, "min_CLP": -9.27, "draft_iters": 32.0, "mem_use": 53.47, "gen_rate": 9.8, "speed": 0.73, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 334, "tree_size": 2048, "t0": 7.29, "t1": 6.13, "tft": 12.9818, "input_0": 7409, "input_1": 2049, "min_CLP": -10.23, "draft_iters": 32.0, "mem_use": 54.05, "gen_rate": 11.3, "speed": 0.84, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 303, "tree_size": 2048, "t0": 7.16, "t1": 6.0867, "tft": 12.0579, "input_0": 7521, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 53.09, "gen_rate": 10.7, "speed": 0.81, "text": "1.    Identify the source of str"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 362, "tree_size": 2048, "t0": 7.145, "t1": 6.0825, "tft": 12.1463, "input_0": 7651, "input_1": 2049, "min_CLP": -8.76, "draft_iters": 32.0, "mem_use": 52.76, "gen_rate": 9.8, "speed": 0.74, "text": "Sure, I can explain what self-at"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.8, "tree_w": 397, "tree_size": 2048, "t0": 7.2225, "t1": 6.0975, "tft": 12.4447, "input_0": 7253, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 53.32, "gen_rate": 10.5, "speed": 0.79, "text": "It is not possible to make a com"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 27, "tree_h": 11.4, "tree_w": 321, "tree_size": 2048, "t0": 7.2, "t1": 6.124, "tft": 12.7453, "input_0": 6354, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 53.75, "gen_rate": 5.4, "speed": 0.41, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.2, "tree_w": 366, "tree_size": 2048, "t0": 7.1925, "t1": 6.1125, "tft": 12.6426, "input_0": 6997, "input_1": 2049, "min_CLP": -8.38, "draft_iters": 31.8, "mem_use": 53.42, "gen_rate": 8.8, "speed": 0.66, "text": "%21 is the percent encoded repre"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 405, "tree_size": 2048, "t0": 7.3825, "t1": 5.985, "tft": 15.2045, "input_0": 6903, "input_1": 2049, "min_CLP": -11.12, "draft_iters": 32.0, "mem_use": 55.55, "gen_rate": 10.5, "speed": 0.79, "text": "\"L'Hopital's rule is a mathemati"}

{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 403, "tree_size": 2048, "t0": 7.315, "t1": 6.2125, "tft": 16.9815, "input_0": 7749, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 54.13, "gen_rate": 8.5, "speed": 0.63, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 538, "tree_size": 2048, "t0": 7.285, "t1": 6.125, "tft": 13.4349, "input_0": 8468, "input_1": 2049, "min_CLP": -11.1, "draft_iters": 32.0, "mem_use": 54.51, "gen_rate": 10.0, "speed": 0.75, "text": "Sure, here are the 3 most import"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 349, "tree_size": 2048, "t0": 7.2033, "t1": 6.06, "tft": 12.2792, "input_0": 7381, "input_1": 2049, "min_CLP": -9.04, "draft_iters": 32.0, "mem_use": 52.75, "gen_rate": 10.7, "speed": 0.8, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.7, "tree_w": 293, "tree_size": 2048, "t0": 7.2733, "t1": 6.1133, "tft": 12.8053, "input_0": 6660, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 54.09, "gen_rate": 11.0, "speed": 0.82, "text": "If we assume that Black Friday i"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 485, "tree_size": 2048, "t0": 6.9725, "t1": 6.0725, "tft": 11.8863, "input_0": 7582, "input_1": 2049, "min_CLP": -9.2, "draft_iters": 31.0, "mem_use": 52.93, "gen_rate": 8.5, "speed": 0.65, "text": "\"Of course! Here's a story set i"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 397, "tree_size": 2048, "t0": 7.3125, "t1": 6.0725, "tft": 12.3738, "input_0": 7697, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 52.8, "gen_rate": 9.2, "speed": 0.69, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.8, "tree_w": 340, "tree_size": 2048, "t0": 7.2775, "t1": 6.075, "tft": 12.235, "input_0": 7827, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 52.79, "gen_rate": 9.5, "speed": 0.71, "text": "Sure, I can help with that! In M"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 7.7, "tree_w": 780, "tree_size": 2048, "t0": 5.64, "t1": 6.0433, "tft": 12.0177, "input_0": 7211, "input_1": 2049, "min_CLP": -9.78, "draft_iters": 24.7, "mem_use": 52.74, "gen_rate": 7.3, "speed": 0.63, "text": "\"Sure, I'd be happy to act as th"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 9.5, "tree_w": 520, "tree_size": 2048, "t0": 7.315, "t1": 6.12, "tft": 13.0272, "input_0": 7826, "input_1": 2049, "min_CLP": -11.15, "draft_iters": 32.0, "mem_use": 54.0, "gen_rate": 9.0, "speed": 0.67, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 539, "tree_size": 2048, "t0": 7.2575, "t1": 6.0825, "tft": 12.4959, "input_0": 9299, "input_1": 2049, "min_CLP": -9.93, "draft_iters": 32.0, "mem_use": 53.13, "gen_rate": 10.0, "speed": 0.75, "text": "# Install Tailwind CSS\\nnpm inst"}

{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.8, "tree_w": 505, "tree_size": 2048, "t0": 6.274, "t1": 6.212, "tft": 15.9224, "input_0": 5821, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 28.8, "mem_use": 53.27, "gen_rate": 7.2, "speed": 0.58, "text": "LLMs are a large class of models"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 11.2, "tree_w": 487, "tree_size": 2048, "t0": 6.6867, "t1": 6.1067, "tft": 11.5873, "input_0": 6767, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 30.8, "mem_use": 52.83, "gen_rate": 5.0, "speed": 0.39, "text": "\"Sure, here's a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 348, "tree_size": 2048, "t0": 7.1675, "t1": 6.065, "tft": 12.1595, "input_0": 7543, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 53.05, "gen_rate": 9.8, "speed": 0.74, "text": "\"Here is a eulogy for your grand"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 7.8, "tree_w": 591, "tree_size": 2048, "t0": 6.1275, "t1": 6.145, "tft": 10.3005, "input_0": 7131, "input_1": 2049, "min_CLP": -10.59, "draft_iters": 27.2, "mem_use": 54.47, "gen_rate": 8.8, "speed": 0.71, "text": "[INST] How to implement collisio"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 360, "tree_size": 2048, "t0": 7.204, "t1": 6.072, "tft": 12.4455, "input_0": 7694, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 52.9, "gen_rate": 7.0, "speed": 0.53, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 489, "tree_size": 2048, "t0": 7.1825, "t1": 6.0875, "tft": 11.355, "input_0": 8196, "input_1": 2049, "min_CLP": -13.24, "draft_iters": 32.0, "mem_use": 52.89, "gen_rate": 10.0, "speed": 0.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 354, "tree_size": 2048, "t0": 7.095, "t1": 6.07, "tft": 11.9018, "input_0": 6875, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 8.8, "speed": 0.66, "text": "The color of Mars is a reddish-b"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.2, "tree_w": 497, "tree_size": 2048, "t0": 5.966, "t1": 5.762, "tft": 15.3221, "input_0": 5001, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 28.4, "mem_use": 54.96, "gen_rate": 7.0, "speed": 0.6, "text": "In Quenya, \"I love you\" can be e"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 441, "tree_size": 2048, "t0": 7.255, "t1": 6.0825, "tft": 12.1153, "input_0": 8488, "input_1": 2049, "min_CLP": -14.95, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.2, "speed": 0.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 354, "tree_size": 2048, "t0": 7.0825, "t1": 6.08, "tft": 12.3785, "input_0": 6377, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 53.35, "gen_rate": 9.2, "speed": 0.7, "text": "\"The ATF is responsible for enfo"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 453, "tree_size": 2048, "t0": 7.2525, "t1": 6.08, "tft": 12.2542, "input_0": 8060, "input_1": 2049, "min_CLP": -10.78, "draft_iters": 32.0, "mem_use": 52.81, "gen_rate": 10.0, "speed": 0.75, "text": "No, there is no formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.2, "tree_w": 426, "tree_size": 2048, "t0": 7.1575, "t1": 6.0975, "tft": 12.5823, "input_0": 7991, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 53.23, "gen_rate": 9.5, "speed": 0.72, "text": "\"Sure, I'd be happy to help! As "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 330, "tree_size": 2048, "t0": 7.224, "t1": 6.088, "tft": 12.3313, "input_0": 7083, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 52.93, "gen_rate": 7.0, "speed": 0.53, "text": "The Australian Capital Territory"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 419, "tree_size": 2048, "t0": 7.07, "t1": 6.0933, "tft": 12.4482, "input_0": 7534, "input_1": 2049, "min_CLP": -10.23, "draft_iters": 32.0, "mem_use": 53.09, "gen_rate": 10.7, "speed": 0.81, "text": "Hello\\n[INST] yes [\\\\INST]\\nHell"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 365, "tree_size": 2048, "t0": 6.9125, "t1": 5.8975, "tft": 14.9615, "input_0": 6505, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 55.32, "gen_rate": 8.8, "speed": 0.68, "text": "Title: The Unapologetic Advocate"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.2, "tree_w": 466, "tree_size": 2048, "t0": 6.645, "t1": 6.09, "tft": 12.042, "input_0": 6229, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 31.3, "mem_use": 52.91, "gen_rate": 5.5, "speed": 0.43, "text": "\"It's true that there was a famo"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 426, "tree_size": 2048, "t0": 7.2725, "t1": 6.135, "tft": 13.1166, "input_0": 8382, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 54.19, "gen_rate": 8.8, "speed": 0.65, "text": "\"Sure, let's consider a vector A"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 358, "tree_size": 2048, "t0": 7.258, "t1": 6.168, "tft": 11.7569, "input_0": 6620, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 52.78, "gen_rate": 7.4, "speed": 0.55, "text": "The main issues with using a sym"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 397, "tree_size": 2048, "t0": 7.13, "t1": 6.0825, "tft": 11.4397, "input_0": 6634, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 8.2, "speed": 0.62, "text": "Once upon a time, in the vast an"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 481, "tree_size": 2048, "t0": 6.1175, "t1": 6.08, "tft": 12.3058, "input_0": 6004, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 27.2, "mem_use": 52.78, "gen_rate": 9.0, "speed": 0.74, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 370, "tree_size": 2048, "t0": 7.1025, "t1": 6.09, "tft": 12.6246, "input_0": 7171, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 53.35, "gen_rate": 10.0, "speed": 0.76, "text": "Variance and sum of squares are "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.7, "tree_w": 354, "tree_size": 2048, "t0": 7.0017, "t1": 6.1183, "tft": 12.7534, "input_0": 6539, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 53.64, "gen_rate": 5.5, "speed": 0.42, "text": "\"Ride Your Way to Wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.2, "tree_w": 600, "tree_size": 2048, "t0": 5.784, "t1": 6.102, "tft": 12.5997, "input_0": 6236, "input_1": 2049, "min_CLP": -10.52, "draft_iters": 26.6, "mem_use": 53.43, "gen_rate": 8.2, "speed": 0.69, "text": "If you want to see the best star"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.0, "tree_w": 431, "tree_size": 2048, "t0": 6.974, "t1": 6.084, "tft": 12.2026, "input_0": 7097, "input_1": 2049, "min_CLP": -9.26, "draft_iters": 31.4, "mem_use": 52.77, "gen_rate": 7.6, "speed": 0.58, "text": "Here is a top 10 list of the fun"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.2, "tree_w": 465, "tree_size": 2048, "t0": 6.96, "t1": 6.1075, "tft": 12.2976, "input_0": 6801, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 32.0, "mem_use": 53.34, "gen_rate": 9.0, "speed": 0.69, "text": "If the two dropped eggs landed o"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.0, "tree_w": 415, "tree_size": 2048, "t0": 7.0067, "t1": 6.1033, "tft": 12.5046, "input_0": 6678, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 53.2, "gen_rate": 11.0, "speed": 0.84, "text": "The following are some ways to c"}

{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 483, "tree_size": 2048, "t0": 7.2025, "t1": 5.9475, "tft": 18.1627, "input_0": 8863, "input_1": 2049, "min_CLP": -10.5, "draft_iters": 32.0, "mem_use": 54.95, "gen_rate": 10.2, "speed": 0.78, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 10.7, "tree_w": 371, "tree_size": 2048, "t0": 7.27, "t1": 6.1567, "tft": 11.9156, "input_0": 6694, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 32.0, "mem_use": 52.74, "gen_rate": 4.3, "speed": 0.32, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 492, "tree_size": 2048, "t0": 7.122, "t1": 6.158, "tft": 12.2018, "input_0": 8014, "input_1": 2049, "min_CLP": -10.02, "draft_iters": 32.0, "mem_use": 52.99, "gen_rate": 7.0, "speed": 0.53, "text": "Here are five words where the le"}

{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.5, "tree_w": 412, "tree_size": 2048, "t0": 7.3025, "t1": 6.2125, "tft": 16.8558, "input_0": 8448, "input_1": 2049, "min_CLP": -9.52, "draft_iters": 32.0, "mem_use": 53.15, "gen_rate": 8.5, "speed": 0.63, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 604, "tree_size": 2048, "t0": 7.1225, "t1": 6.0675, "tft": 12.4955, "input_0": 8427, "input_1": 2049, "min_CLP": -11.06, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 10.0, "speed": 0.76, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 386, "tree_size": 2048, "t0": 7.025, "t1": 6.06, "tft": 12.2476, "input_0": 6291, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 8.2, "speed": 0.63, "text": "Wyoming statutes do not have an "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.8, "tree_w": 393, "tree_size": 2048, "t0": 7.032, "t1": 5.902, "tft": 20.8454, "input_0": 7156, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 55.41, "gen_rate": 8.0, "speed": 0.62, "text": "\"I understand your concern and s"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 473, "tree_size": 2048, "t0": 7.235, "t1": 6.0875, "tft": 12.3165, "input_0": 8431, "input_1": 2049, "min_CLP": -10.88, "draft_iters": 32.0, "mem_use": 53.27, "gen_rate": 10.0, "speed": 0.75, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.7, "tree_w": 425, "tree_size": 2048, "t0": 7.0233, "t1": 6.1067, "tft": 12.4621, "input_0": 6599, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 53.48, "gen_rate": 12.3, "speed": 0.94, "text": "\"I'm not sure, but I think the a"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.5, "tree_w": 410, "tree_size": 2048, "t0": 7.38, "t1": 6.08, "tft": 12.3078, "input_0": 8068, "input_1": 2049, "min_CLP": -9.81, "draft_iters": 32.0, "mem_use": 53.08, "gen_rate": 8.5, "speed": 0.63, "text": "Sure! The stable diffusion algor"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.8, "tree_w": 450, "tree_size": 2048, "t0": 6.708, "t1": 6.086, "tft": 12.4193, "input_0": 5475, "input_1": 2049, "min_CLP": -9.05, "draft_iters": 31.2, "mem_use": 53.32, "gen_rate": 7.0, "speed": 0.55, "text": "\"Attention bias, it's all about "}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.0, "tree_w": 453, "tree_size": 2048, "t0": 6.566, "t1": 6.098, "tft": 11.7066, "input_0": 5621, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 30.6, "mem_use": 53.1, "gen_rate": 8.0, "speed": 0.63, "text": "In the thought experiment, it is"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 398, "tree_size": 2048, "t0": 7.1425, "t1": 5.9275, "tft": 14.4028, "input_0": 7318, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 55.08, "gen_rate": 8.5, "speed": 0.65, "text": "\"It's always a good idea to be p"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.2, "tree_w": 350, "tree_size": 2048, "t0": 7.1725, "t1": 6.09, "tft": 12.1849, "input_0": 7216, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 52.85, "gen_rate": 9.0, "speed": 0.68, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 8.0, "tree_w": 510, "tree_size": 2048, "t0": 6.0875, "t1": 6.0925, "tft": 12.1674, "input_0": 6458, "input_1": 2049, "min_CLP": -9.52, "draft_iters": 27.2, "mem_use": 52.88, "gen_rate": 9.0, "speed": 0.74, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfEn"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 372, "tree_size": 2048, "t0": 6.97, "t1": 6.0825, "tft": 12.0916, "input_0": 6594, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 52.86, "gen_rate": 8.0, "speed": 0.61, "text": "F-centers are defects in crystal"}

{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 343, "tree_size": 2048, "t0": 7.4025, "t1": 6.2375, "tft": 18.4259, "input_0": 6741, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 32.0, "mem_use": 54.5, "gen_rate": 9.0, "speed": 0.66, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.2, "tree_w": 493, "tree_size": 2048, "t0": 6.282, "t1": 6.196, "tft": 12.6118, "input_0": 6823, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 28.0, "mem_use": 53.28, "gen_rate": 7.6, "speed": 0.61, "text": "There are several pros to the po"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.0, "tree_w": 432, "tree_size": 2048, "t0": 7.0725, "t1": 5.9075, "tft": 16.9654, "input_0": 7922, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 55.18, "gen_rate": 9.8, "speed": 0.75, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 607, "tree_size": 2048, "t0": 7.0467, "t1": 5.6833, "tft": 13.8215, "input_0": 7913, "input_1": 2049, "min_CLP": -9.93, "draft_iters": 32.0, "mem_use": 55.15, "gen_rate": 11.0, "speed": 0.86, "text": "Die Zementproduktion ist eine de"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.7, "tree_w": 322, "tree_size": 2048, "t0": 7.35, "t1": 6.14, "tft": 12.6413, "input_0": 6819, "input_1": 2049, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 54.5, "gen_rate": 11.0, "speed": 0.82, "text": "I apologize, but I am unable to "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 27, "tree_h": 10.5, "tree_w": 495, "tree_size": 2048, "t0": 6.32, "t1": 6.1075, "tft": 12.2682, "input_0": 5670, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 29.2, "mem_use": 53.53, "gen_rate": 6.8, "speed": 0.54, "text": "I would try to contact the owner"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 426, "tree_size": 2048, "t0": 7.14, "t1": 6.0775, "tft": 12.1136, "input_0": 8038, "input_1": 2049, "min_CLP": -11.61, "draft_iters": 32.0, "mem_use": 53.12, "gen_rate": 10.0, "speed": 0.76, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. Vaswani, A., Shaz"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 476, "tree_size": 2048, "t0": 7.385, "t1": 6.085, "tft": 12.2843, "input_0": 8169, "input_1": 2049, "min_CLP": -10.24, "draft_iters": 32.0, "mem_use": 52.92, "gen_rate": 8.8, "speed": 0.65, "text": "\"Here's the function in JavaScri"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 361, "tree_size": 2048, "t0": 7.285, "t1": 6.125, "tft": 13.1576, "input_0": 8616, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 54.2, "gen_rate": 8.0, "speed": 0.6, "text": "It is illegal for a variety of r"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.2, "tree_w": 383, "tree_size": 2048, "t0": 6.96, "t1": 6.105, "tft": 12.21, "input_0": 6209, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 53.32, "gen_rate": 8.5, "speed": 0.65, "text": "One idea could be to write the p"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 353, "tree_size": 2048, "t0": 7.3025, "t1": 6.1575, "tft": 12.9425, "input_0": 7504, "input_1": 2049, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 54.2, "gen_rate": 10.2, "speed": 0.76, "text": "The optimal thickness for mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 520, "tree_size": 2048, "t0": 6.0275, "t1": 6.1, "tft": 12.6476, "input_0": 6497, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 27.0, "mem_use": 53.58, "gen_rate": 10.0, "speed": 0.82, "text": "\"That's a great question! If you"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.4, "tree_w": 504, "tree_size": 2048, "t0": 7.112, "t1": 6.076, "tft": 11.8544, "input_0": 7279, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 52.84, "gen_rate": 7.6, "speed": 0.58, "text": "\"Sure, here's a list of nickname"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 331, "tree_size": 2048, "t0": 7.31, "t1": 6.095, "tft": 12.6046, "input_0": 7557, "input_1": 2049, "min_CLP": -10.18, "draft_iters": 32.0, "mem_use": 53.24, "gen_rate": 8.8, "speed": 0.65, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.8, "tree_w": 615, "tree_size": 2048, "t0": 6.2467, "t1": 6.1183, "tft": 12.9595, "input_0": 6987, "input_1": 2049, "min_CLP": -14.58, "draft_iters": 27.8, "mem_use": 54.0, "gen_rate": 6.2, "speed": 0.5, "text": "\"Canciones felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.7, "tree_w": 340, "tree_size": 2048, "t0": 7.23, "t1": 6.0733, "tft": 12.2543, "input_0": 7129, "input_1": 2049, "min_CLP": -11.0, "draft_iters": 32.0, "mem_use": 52.94, "gen_rate": 12.3, "speed": 0.93, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 438, "tree_size": 2048, "t0": 7.235, "t1": 6.0825, "tft": 12.4883, "input_0": 7820, "input_1": 2049, "min_CLP": -11.82, "draft_iters": 32.0, "mem_use": 53.34, "gen_rate": 10.0, "speed": 0.75, "text": "\"Oh, my apologies. Here's the co"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 417, "tree_size": 2048, "t0": 7.036, "t1": 6.114, "tft": 12.6587, "input_0": 6718, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 53.71, "gen_rate": 6.4, "speed": 0.49, "text": "How about, \"A heart beating like"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 436, "tree_size": 2048, "t0": 7.2833, "t1": 6.3067, "tft": 13.3117, "input_0": 8043, "input_1": 2049, "min_CLP": -10.34, "draft_iters": 32.0, "mem_use": 54.46, "gen_rate": 11.0, "speed": 0.81, "text": "To build a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 554, "tree_size": 2048, "t0": 7.2225, "t1": 6.085, "tft": 12.3384, "input_0": 7739, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 31.8, "mem_use": 52.95, "gen_rate": 10.0, "speed": 0.75, "text": "Frank-Walter Steinmeier (born 5 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 350, "tree_size": 2048, "t0": 7.05, "t1": 6.0733, "tft": 12.3761, "input_0": 6412, "input_1": 2049, "min_CLP": -12.86, "draft_iters": 32.0, "mem_use": 52.87, "gen_rate": 13.0, "speed": 0.99, "text": "A) A kilogram of feathers<|endof"}

{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 394, "tree_size": 2048, "t0": 7.27, "t1": 6.1975, "tft": 16.1109, "input_0": 7927, "input_1": 2049, "min_CLP": -13.9, "draft_iters": 32.0, "mem_use": 52.77, "gen_rate": 10.2, "speed": 0.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 455, "tree_size": 2048, "t0": 7.185, "t1": 6.0675, "tft": 12.296, "input_0": 7851, "input_1": 2049, "min_CLP": -15.29, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 10.2, "speed": 0.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}

{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.2, "tree_w": 366, "tree_size": 2048, "t0": 7.29, "t1": 6.26, "tft": 20.1857, "input_0": 7685, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 54.8, "gen_rate": 9.5, "speed": 0.7, "text": "\"\u2022 Make the habit a part of your"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.0, "tree_w": 410, "tree_size": 2048, "t0": 6.9625, "t1": 6.2425, "tft": 12.3246, "input_0": 6337, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 31.5, "mem_use": 54.04, "gen_rate": 9.2, "speed": 0.7, "text": "In chess, the players have all t"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.0, "tree_w": 378, "tree_size": 2048, "t0": 7.0117, "t1": 6.2033, "tft": 12.53, "input_0": 6216, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 52.91, "gen_rate": 6.2, "speed": 0.47, "text": "It\\'s the birthday of John F. Ke"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.2, "tree_w": 337, "tree_size": 2048, "t0": 7.1975, "t1": 6.2075, "tft": 12.5725, "input_0": 7669, "input_1": 2049, "min_CLP": -8.56, "draft_iters": 32.0, "mem_use": 52.93, "gen_rate": 10.2, "speed": 0.76, "text": "Perfect information in the conte"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.6, "tree_w": 391, "tree_size": 2048, "t0": 7.07, "t1": 6.23, "tft": 12.9718, "input_0": 7424, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 32.0, "mem_use": 53.75, "gen_rate": 7.8, "speed": 0.59, "text": "\"[ANSWER]: I'm sorry, but as an "}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 387, "tree_size": 2048, "t0": 7.1967, "t1": 6.2367, "tft": 13.0425, "input_0": 7699, "input_1": 2049, "min_CLP": -10.0, "draft_iters": 32.0, "mem_use": 54.28, "gen_rate": 10.7, "speed": 0.79, "text": "\"Certainly! Here's a simpler scr"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.8, "tree_w": 387, "tree_size": 2048, "t0": 6.812, "t1": 6.208, "tft": 12.7672, "input_0": 6010, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 53.7, "gen_rate": 7.0, "speed": 0.54, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 519, "tree_size": 2048, "t0": 6.228, "t1": 6.206, "tft": 12.847, "input_0": 6609, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 28.2, "mem_use": 53.81, "gen_rate": 6.6, "speed": 0.53, "text": "And as I gaze into your beautifu"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.2, "tree_w": 399, "tree_size": 2048, "t0": 7.2075, "t1": 6.19, "tft": 12.2507, "input_0": 6947, "input_1": 2049, "min_CLP": -8.76, "draft_iters": 32.0, "mem_use": 53.22, "gen_rate": 8.8, "speed": 0.65, "text": "The airspeed velocity of the Eur"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 383, "tree_size": 2048, "t0": 7.225, "t1": 6.195, "tft": 12.598, "input_0": 8026, "input_1": 2049, "min_CLP": -8.53, "draft_iters": 32.0, "mem_use": 53.17, "gen_rate": 8.2, "speed": 0.61, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.2, "tree_w": 358, "tree_size": 2048, "t0": 7.1625, "t1": 6.2075, "tft": 13.1097, "input_0": 7341, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 54.51, "gen_rate": 8.5, "speed": 0.64, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.8, "tree_w": 357, "tree_size": 2048, "t0": 7.2825, "t1": 6.2025, "tft": 13.3614, "input_0": 7902, "input_1": 2049, "min_CLP": -8.48, "draft_iters": 32.0, "mem_use": 54.42, "gen_rate": 8.8, "speed": 0.65, "text": "Yes, Open Assistant is a pre-tra"}

{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.5, "tree_w": 557, "tree_size": 2048, "t0": 7.285, "t1": 6.095, "tft": 16.896, "input_0": 7688, "input_1": 2049, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 52.73, "gen_rate": 10.2, "speed": 0.77, "text": "The President of Germany is curr"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 416, "tree_size": 2048, "t0": 6.92, "t1": 6.09, "tft": 12.8288, "input_0": 6698, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 31.8, "mem_use": 53.65, "gen_rate": 6.4, "speed": 0.49, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 12.0, "tree_w": 300, "tree_size": 2048, "t0": 7.85, "t1": 6.06, "tft": 20.9932, "input_0": 6727, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 55.53, "gen_rate": 0.0, "speed": 0.0, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 8.5, "tree_w": 709, "tree_size": 2048, "t0": 5.75, "t1": 6.0675, "tft": 11.9925, "input_0": 6033, "input_1": 2049, "min_CLP": -11.23, "draft_iters": 25.5, "mem_use": 53.24, "gen_rate": 9.0, "speed": 0.76, "text": "- Introduction: What is the Cont"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-1.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 376, "tree_size": 2048, "t0": 7.2325, "t1": 6.1, "tft": 12.9134, "input_0": 7780, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 54.09, "gen_rate": 8.2, "speed": 0.62, "text": "I apologize for the confusion. I"}

{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 2048, "max_branch_width": 32, "gen_rate": 8.63, "gen_rate_micro": 8.41, "gen_speed": 0.659, "gen_speed_micro": 0.647, "t0": 6.9561, "t1": 6.0968, "input_0": 7199.4, "input_1": 2049.0, "tree_size": 2048.0, "tree_w": 429.8, "tree_h": 10.3, "prompt_len": 265.5, "min_CLP": -9.52, "mem_use": 56.51, "exp_time": null}